{
  "status": "ok",
  "message-type": "work",
  "message-version": "1.0.0",
  "message": {
    "indexed": {
      "date-parts": [
        [
          2024,
          7,
          21
        ]
      ],
      "date-time": "2024-07-21T07:49:48Z",
      "timestamp": 1721548188248
    },
    "reference-count": 0,
    "publisher": "Association for the Advancement of Artificial Intelligence (AAAI)",
    "issue": "05",
    "license": [
      {
        "start": {
          "date-parts": [
            [
              2020,
              4,
              3
            ]
          ],
          "date-time": "2020-04-03T00:00:00Z",
          "timestamp": 1585872000000
        },
        "content-version": "unspecified",
        "delay-in-days": 0,
        "URL": "https://www.aaai.org"
      }
    ],
    "content-domain": {
      "domain": [],
      "crossmark-restriction": false
    },
    "short-container-title": [
      "AAAI"
    ],
    "abstract": "<jats:p>A code generation system generates programming language code based on an input natural language description. State-of-the-art approaches rely on neural networks for code generation. However, these code generators suffer from two problems. One is the long dependency problem, where a code element often depends on another far-away code element. A variable reference, for example, depends on its definition, which may appear quite a few lines before. The other problem is structure modeling, as programs contain rich structural information. In this paper, we propose a novel tree-based neural architecture, TreeGen, for code generation. TreeGen uses the attention mechanism of Transformers to alleviate the long-dependency problem, and introduces a novel AST reader (encoder) to incorporate grammar rules and AST structures into the network. We evaluated TreeGen on a Python benchmark, HearthStone, and two semantic parsing benchmarks, ATIS and GEO. TreeGen outperformed the previous state-of-the-art approach by 4.5 percentage points on HearthStone, and achieved the best accuracy among neural network-based approaches on ATIS (89.1%) and GEO (89.6%). We also conducted an ablation test to better understand each component of our model.</jats:p>",
    "DOI": "10.1609/aaai.v34i05.6430",
    "type": "journal-article",
    "created": {
      "date-parts": [
        [
          2020,
          6,
          29
        ]
      ],
      "date-time": "2020-06-29T19:06:30Z",
      "timestamp": 1593457590000
    },
    "page": "8984-8991",
    "source": "Crossref",
    "is-referenced-by-count": 85,
    "title": [
      "TreeGen: A Tree-Based Transformer Architecture for Code Generation"
    ],
    "prefix": "10.1609",
    "volume": "34",
    "author": [
      {
        "given": "Zeyu",
        "family": "Sun",
        "sequence": "first",
        "affiliation": []
      },
      {
        "given": "Qihao",
        "family": "Zhu",
        "sequence": "additional",
        "affiliation": []
      },
      {
        "given": "Yingfei",
        "family": "Xiong",
        "sequence": "additional",
        "affiliation": []
      },
      {
        "given": "Yican",
        "family": "Sun",
        "sequence": "additional",
        "affiliation": []
      },
      {
        "given": "Lili",
        "family": "Mou",
        "sequence": "additional",
        "affiliation": []
      },
      {
        "given": "Lu",
        "family": "Zhang",
        "sequence": "additional",
        "affiliation": []
      }
    ],
    "member": "9382",
    "published-online": {
      "date-parts": [
        [
          2020,
          4,
          3
        ]
      ]
    },
    "container-title": [
      "Proceedings of the AAAI Conference on Artificial Intelligence"
    ],
    "original-title": [],
    "link": [
      {
        "URL": "https://ojs.aaai.org/index.php/AAAI/article/download/6430/6286",
        "content-type": "application/pdf",
        "content-version": "vor",
        "intended-application": "text-mining"
      },
      {
        "URL": "https://ojs.aaai.org/index.php/AAAI/article/download/6430/6286",
        "content-type": "unspecified",
        "content-version": "vor",
        "intended-application": "similarity-checking"
      }
    ],
    "deposited": {
      "date-parts": [
        [
          2022,
          11,
          4
        ]
      ],
      "date-time": "2022-11-04T00:24:18Z",
      "timestamp": 1667521458000
    },
    "score": 1,
    "resource": {
      "primary": {
        "URL": "https://ojs.aaai.org/index.php/AAAI/article/view/6430"
      }
    },
    "subtitle": [],
    "short-title": [],
    "issued": {
      "date-parts": [
        [
          2020,
          4,
          3
        ]
      ]
    },
    "references-count": 0,
    "journal-issue": {
      "issue": "05",
      "published-online": {
        "date-parts": [
          [
            2020,
            6,
            16
          ]
        ]
      }
    },
    "URL": "http://dx.doi.org/10.1609/aaai.v34i05.6430",
    "relation": {},
    "ISSN": [
      "2374-3468",
      "2159-5399"
    ],
    "issn-type": [
      {
        "value": "2374-3468",
        "type": "electronic"
      },
      {
        "value": "2159-5399",
        "type": "print"
      }
    ],
    "subject": [],
    "published": {
      "date-parts": [
        [
          2020,
          4,
          3
        ]
      ]
    }
  }
}