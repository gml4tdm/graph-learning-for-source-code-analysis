{
  "raw": [
    "{\n  \"paper-id\": 242,\n  \"pdf-id\": 337,\n  \"graphs\": {\n    \"class-diagram\": {\n      \"name\": \"class dependency network\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"classes\",\n      \"edge-type\": \"dependencies\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"cluster\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\",\n        \"similarity based; aggregate similar classes into modules\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"modularization\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Cluster classes into modules\",\n      \"working-granularity\": \"graph clustering\",\n      \"application\": \"Software modularisation\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster\",\n      \"task\": \"modularization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
    "{\n  \"paper-id\": 244,\n  \"pdf-id\": 339,\n  \"graphs\": {\n    \"delta-pdg\": {\n      \"name\": \"\\\\delta-ndg\",\n      \"description\": \"start with two separate graphs, merge based on unchanged nodes\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"commit\"\n        }\n      ],\n      \"vertex-type\": \"statement\",\n      \"edge-type\": \"control dependence/data dependence/name flow\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"cluster\": {\n      \"name\": \"Agglomerative Clustering\",\n      \"architecture-attributes\": [\n        \"agglomerative clustering w/ Weisfeiler-Lehman kernel for similarity\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"commit-untangling\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Cluster graph into separate commits\",\n      \"working-granularity\": \"Graph Clustering\",\n      \"application\": \"Untangling (decomposing) composite commits\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"\\\\delta-ndg\",\n      \"model\": \"cluster\",\n      \"task\": \"commit-untangling\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
    "{\n  \"paper-id\": 251,\n  \"pdf-id\": 352,\n  \"graphs\": {\n    \"ext-dependency-graph\": {\n      \"name\": \"Extended Component Dependency Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"component\",\n      \"edge-type\": \"logic dependency (composition, delegation etc)/co-evolution [all edges have back edges]\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"edges are weighted\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"clustering\": {\n      \"name\": \"Bunch Graph Clustering\",\n      \"architecture-attributes\": [\n        \"bunch graph clustering algorithm\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"refactoring\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"cluster components into low coupling / high cohesion subgraphs\",\n      \"working-granularity\": \"graph clustering (into subgraphs)\",\n      \"application\": \"software architecture refactoring\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ext-dependency-graph\",\n      \"model\": \"clustering\",\n      \"task\": \"refactoring\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
    "{\n  \"paper-id\": 247,\n  \"pdf-id\": 343,\n  \"graphs\": {\n    \"object-usage-graph\": {\n      \"name\": \"Object Usage Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"action (API invocation; e.g java.lang.String.new) or control (eg. while)\",\n      \"edge-type\": \"(temporal) usage order/data dependency\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"cluster\": {\n      \"name\": \"Spectral Clustering\",\n      \"architecture-attributes\": [\n        \"spectral-clustering w/ shortest path kernel for similarity\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"usage-example-mining\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Cluster similar graphs together\",\n      \"working-granularity\": \"graph clustering\",\n      \"application\": \"Mining API usage examples\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"object-usage-graph\",\n      \"model\": \"cluster\",\n      \"task\": \"usage-example-mining\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
    "{\n  \"paper-id\": 241,\n  \"pdf-id\": 336,\n  \"graphs\": {\n    \"class-diagram\": {\n      \"name\": \"class dependency network\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"classes\",\n      \"edge-type\": \"dependencies\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"cluster-1\": {\n      \"name\": \"Label Propagation\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-2\": {\n      \"name\": \"Louvain Algorithm\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-3\": {\n      \"name\": \"Leiden Algorithm\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-4\": {\n      \"name\": \"Speaker-Listener Label Propagation\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-5\": {\n      \"name\": \"Leading Eigenvector Algorithm\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-6\": {\n      \"name\": \"Girvan-Newman algorithm\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-7\": {\n      \"name\": \"Markov clustering\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-8\": {\n      \"name\": \"Rber pots algoritmh\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-9\": {\n      \"name\": \"Rb pots algoritmh\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-10\": {\n      \"name\": \"Walktrap\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-11\": {\n      \"name\": \"Chinesewhispers\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"microservice-identification\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Cluster graph into candidate microservices\",\n      \"working-granularity\": \"Graph Clustering\",\n      \"application\": \"Microservice decomposition\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-1\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-2\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-3\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-4\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-5\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-6\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-7\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-8\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-9\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-10\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-11\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
    "{\n  \"paper-id\": 238,\n  \"pdf-id\": 333,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"commit graph\",\n      \"description\": \"separate graphs are created for old and new code, which are then merged based on common nodes.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"commit\"\n        }\n      ],\n      \"vertex-type\": \"statements\",\n      \"edge-type\": \"control flow/data flow/name flow [data flow considering variable names]/sub-token co-occurrence\",\n      \"vertex-features\": \"node value BERT\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified, presumable adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Graph convolution _operator_ (!not network!) (k-th order GCN; X' = (I - 0.5*L)^k X, with L the graph Laplacian)\",\n        \"affinity propagation clustering (similarity = euclidean distance)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"commit-untangling\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Cluster graph into separate commits\",\n      \"working-granularity\": \"Graph Clustering\",\n      \"application\": \"Untangling (decomposing) composite commits\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": null,\n      \"model\": null,\n      \"task\": null,\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
    "{\n  \"paper-id\": 248,\n  \"pdf-id\": 347,\n  \"graphs\": {\n    \"fcg\": {\n      \"name\": \"fcg\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"function\",\n      \"edge-type\": \"function call\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"mc-cluster\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Heuristic Monte-carlo (randomised order) clustering\",\n        \"Actually has multiple implementations\"\n      ]\n    },\n    \"greedy-cluster\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Heuristic greedy (e.g. highest degree first) clustering\",\n        \"Actually has multiple implementations\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"migration\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"cluster nodes together\",\n      \"working-granularity\": \"graph (node) clustering\",\n      \"application\": \"Cluster functional (structured programming) functions together into candidate class method for migration to an OOP language\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"fcg\",\n      \"model\": \"mc-cluster\",\n      \"task\": \"migration\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"gch\",\n      \"model\": \"greedy-cluster\",\n      \"task\": \"migration\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
    "{\n  \"paper-id\": 252,\n  \"pdf-id\": 353,\n  \"graphs\": {\n    \"class-graph\": {\n      \"name\": \"Weighted Directed Class Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"class\",\n      \"edge-type\": \"inheritance coupling/method coupling/data coupling\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"edges are weighted (e.g number of method called)\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"clustering\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"edge weight sensitive [custom] clustering algorithm\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"architecture-recovery\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"cluster classes into modules (clusters)\",\n      \"working-granularity\": \"graph (node) clustering\",\n      \"application\": \"high-level software architecture reconstruction\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"class-graph\",\n      \"model\": \"clustering\",\n      \"task\": \"architecture-recovery\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
    "{\n  \"paper-id\": null,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"bipartite network\",\n      \"artefacts\": [\n        {\n          \"name\": \"github repositories\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"github user data\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"repositories/users\",\n      \"edge-type\": \"contributes\",\n      \"vertex-features\": \"for users: potential passwords/keys, occurrences of string \\\"password\\\" in a file, sensitive filetypes.\\n\\nfor repos: vulnerability type(s) detected by scanner tool (secret leakage, classical vulnerabilities such as sql, etc.)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"The bipartite network is projected into two mono-partite networks (user network and repo network)\\n\\nGraphs are encoded using text associated deep walk\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"K-means clustering\",\n      \"architecture-attributes\": [\n        \"k means\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"clustering\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Cluster nodes together\",\n      \"working-granularity\": \"graph clustering\",\n      \"application\": \"identification of groups of vulnerable repositories and users (proactively identify vulnerable communities)\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"clustering\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
    "{\n  \"paper-id\": 269,\n  \"pdf-id\": 69,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Dependency Files\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"library\",\n      \"edge-type\": \"dependency\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix / general connectivity\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"graph filtering with symmetric absorbing random walks\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"task\": {\n      \"training-objective\": \"Solving stability equation (not entirely sure on the details)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Not entirely sure\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Library recommendation\",\n      \"supervision\": \"self-supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"task\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
    "{\n  \"paper-id\": 270,\n  \"pdf-id\": 188,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Separate graphlets based on old/new and different snippets in commits. Take union. May not be a connected graph\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"commit\"\n        }\n      ],\n      \"vertex-type\": \"unique node per node type (srcML)\",\n      \"edge-type\": \"node has child node of type\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"graph-level network metrics\",\n      \"other-features\": \"software engineering metrics about diff\"\n    }\n  },\n  \"models\": {\n    \"rf\": {\n      \"name\": \"random forest\",\n      \"architecture-attributes\": [\n        \"random forest\"\n      ]\n    },\n    \"knn\": {\n      \"name\": \"knn\",\n      \"architecture-attributes\": [\n        \"k-nearest neighbors\"\n      ]\n    },\n    \"lr\": {\n      \"name\": \"logistic regression\",\n      \"architecture-attributes\": [\n        \"logistic regression\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"bug-detection\": {\n      \"training-objective\": \"classify commit as buggy or not buggy\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"classify commit as buggy or not buggy\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"buggy commit detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"rf\",\n      \"task\": \"bug-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph\",\n      \"model\": \"knn\",\n      \"task\": \"bug-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph\",\n      \"model\": \"lr\",\n      \"task\": \"bug-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
    "{\n  \"paper-id\": 271,\n  \"pdf-id\": 205,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"method\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node type (syntax), node code tokens (internal)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"source code tokens and sub-tokens in method name\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"transformer\",\n        \"encoder/decoder\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarisation\": {\n      \"training-objective\": \"given a method, predict a summary\",\n      \"training-granularity\": \"x-to-sequence\",\n      \"working-objective\": \"given a method, predict a summary\",\n      \"working-granularity\": \"x-to-sequence\",\n      \"application\": \"code summarisation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarisation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
    "{\n  \"paper-id\": 272,\n  \"pdf-id\": 220,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"method\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"not clearly specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"source code tokens\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"embedding layers\",\n        \"encoder/decoder\",\n        \"gru\",\n        \"attention\",\n        \"ConvGNN\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarisation\": {\n      \"training-objective\": \"given a method, predict a summary\",\n      \"training-granularity\": \"x-to-sequence\",\n      \"working-objective\": \"given a method, predict a summary\",\n      \"working-granularity\": \"x-to-sequence\",\n      \"application\": \"code summarisation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarisation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}"
  ],
  "refinements": [
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 133,\n  \"pdf-id\": 176,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"one-hot encoding of node type\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"network\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Repeated modules of: GCNN, MinCutPool, Dropout\\nAverage Pool\\nFNN\\nFNN w/ Sigmoid\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"bug-detection\": {\n      \"training-objective\": \"Classify code sample as buggy or not buggy\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify code sample as buggy or not buggy\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Bug Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"network\",\n      \"task\": \"bug-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 111,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Mix of AST, CFG, DFG, NCS\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"functions\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"NCS Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Node type encoded using label encoding\\nSource code encoded using word2vec\\nthe two encodings are concatenated\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"devign\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Copy original features, pad with zeros \\nGAT layers (w/ SUM aggregation)\\nPooling through 1D convolutions:\\n  Z_1 = \\\\sigma(H_T, X) (node matrix, original features); Z_{\\\\ell} = \\\\sigma(Z_{\\\\ell-1})\\n  Y_1 = \\\\sigma(H_T), Y_{\\\\ell} = \\\\sigma(Y_{\\\\ell-1})\\n  Where \\\\sigma(x) = MaxPool(ReLU(Conv1D(x)))\\ny = sigmoid(AVG(MLP(Z_{\\\\ell) \\\\cdot MLP(Y_{\\\\ell}))))\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"devign\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 190,\n  \"pdf-id\": 253,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Next Token Edge\",\n          \"details\": \"NCS\"\n        },\n        {\n          \"name\": \"Last Lexical Use Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Unclear how nodes are encoded\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"query-graph\": {\n      \"name\": \"Parse Tree\",\n      \"description\": \"Text is first transformed using T5 transformer\",\n      \"artefacts\": [\n        {\n          \"name\": \"Summary of the source code (training) or query (working)\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Token\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Constituency Symbol\",\n          \"details\": \"e.g. \\\"VB\\\" (verb)\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Constituency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Word Ordering Edge\",\n          \"details\": \"Undirected\"\n        }\n      ],\n      \"vertex-features\": \"Unclear how nodes are encoded\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) RGCN module for graph encoding\\n2) Cross-attention similarity; Compute score for \\\"matching\\\" w/ code for every query token:\\n    e_{i,G} = \\\\frac{1}{N}\\\\sum_{j = 1}^N cosine-similarity(q_i, c_j)c_j\\n    (q: query node embedding, c: code node embedding)\\n3) Compute q_i' = [(q_i - e_{i,G}) \\\\odot (e_{i,G} - q_i); q_i \\\\odot e_{i,G}]\\n4) Do the same to compute c_i' for the code node embeddings \\n5) Compute H_q = MaxPool(FC({q_i' | 1 <= i <= M}))\\n6) Compute H_e = MaxPool(FC({c_i' | 1 <= i <= N}))\\n7) Compute cosine similarity between H_q and H_e\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-search\": {\n      \"training-objective\": \"Maximise similarity of related (summary, code) pairs; minimise similarity of unrelated (summary, code) pairs\",\n      \"training-granularity\": \"Graph Regression (?)\",\n      \"working-objective\": \"Output similarity scores of (query, code) pairs\",\n      \"working-granularity\": \"Graph Regression (?)\",\n      \"application\": \"Code Search\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + query-graph\",\n      \"model\": \"model\",\n      \"task\": \"code-search\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 180,\n  \"pdf-id\": 234,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST augmented with information from markdown\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"snippets from Jupyter notebooks\"\n        },\n        {\n          \"name\": \"Markdown Text\",\n          \"details\": \"Natural language from Markdown from the Jupyter notebooks\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Virtual / classification token ([CLS])\",\n          \"details\": \"Always at the start of the token sequence\"\n        },\n        {\n          \"name\": \"Markdown token node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Classification ([CLS]) Edge\",\n          \"details\": \"Every node is connected to the [CLS] node\"\n        },\n        {\n          \"name\": \"Markdown Edge\",\n          \"details\": \"For a given snippet, each AST node in its AST is connected \\nto a node for every token the most recent markdown block \\n(occurring within 3 blocks)\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"The entire graph is sequenced using depth-first traversal,\\nbeginning with [CLS]\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Transformer based encoder \\n  i) Masked multi-head attention w/ residual connections and normalisation\\n  ii) FNN w/ residual connections and normalisation\\n  iii) Dimensionality reduction \\n2) Output for [CLS] token is passed through FNN layer w/ softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-classification\": {\n      \"training-objective\": \"Given a code sample, classify it into one of the classes.\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given a code sample, classify it into one of the classes.\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Program Classification \\n\\nSpecifically, classify a program according to its purpose in the data science pipeline;\\nimport, wrangle, explore, model, evaluate\",\n      \"supervision\": \"Supervised\"\n    },\n    \"reconstruction\": {\n      \"training-objective\": \"Given the output p of the model (from the softmax), \\nreconstruct the output for [CLS] using a learnable matrix R as R * p\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Pre-training\",\n      \"supervision\": \"Unsupervised (self-supervised)\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-classification + reconstruction\",\n      \"comments\": \"The reconstruction task is meant to fine-tune the model\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 150,\n  \"pdf-id\": 199,\n  \"graphs\": {\n    \"augmented-ast\": {\n      \"name\": \"Augmented AST\",\n      \"description\": \"AST augmented with additional edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"method\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"Undirected\"\n        },\n        {\n          \"name\": \"Computed From\",\n          \"details\": \"Undirected\"\n        },\n        {\n          \"name\": \"Last Use\",\n          \"details\": \"Undirected\"\n        },\n        {\n          \"name\": \"Returns To\",\n          \"details\": \"Undirected; Node in return statement points to the return type declaration in a method\"\n        },\n        {\n          \"name\": \"Next Token Edge\",\n          \"details\": \"Undirected; Connect nodes on the same level in sequential order (perhaps not named to aptly)\"\n        }\n      ],\n      \"vertex-features\": \"Not specified\",\n      \"edge-features\": \"When I say undirected, I mean back-edges are added\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Summary generated thus far (in tokens) is also given as input\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Two parallel inputs (encoders)\\n  i) Code is tokenized using Byte Pair Encoding (generating sub-tokens), and passed through a pre-trained RoBERTa model,\\n      where the RoBERTa model was pretrained _by the authors_ on a contrastive learning task.\\n  ii) AST is input into a slightly modified GAT, which computed e_{ij} according to   \\n        e_{ij} = a^T LeakyReLU(W[h_i || h_j]), as opposed to e_{ij} = LeakyReLU(a^t[W h_i || W h_j])\\n2) Decoder (summary thus far as input)\\n  i) Embedding Layer\\n  ii) Enrich with positional encoding \\n  iii) Masked multi-head self-attention w/ residual connection and normalisation\\n  iv) Multi-head attention w/ residual connection and normalisation \\n    K: output of the token encoder\\n    V: output of graph encoder\\n    Q: output of the embedding layer \\n  v) FNN w/ residual connection and normalisation\\n  vi) Pointer Generator\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"training-granularity\": \"Graph + Sequence to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"working-granularity\": \"Graph + Sequence to Sequence\",\n      \"application\": \"Code summarization (Generating comments for Python code)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"augmented-ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 170,\n  \"pdf-id\": 223,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"n/a\",\n      \"description\": \"Hypergraph based on AST\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Internal node (non-token)\"\n        },\n        {\n          \"name\": \"Identifier Node\",\n          \"details\": \"Token node\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Directed Hyper Edge\",\n          \"details\": \"If a node aggregates multiple items in e.g. a list,\\nthen the items in the list are connected to the parent \\nnode using a hyper edge (going _from_ multiple children _to_ the parent).\\n\\nEdges have distinct types, based on the type of relation \\nbetween parent and children (e.g. \\\"elements\\\" for list elements).\"\n        }\n      ],\n      \"vertex-features\": \"Node value (payload)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Let n = (\\\\mu, x) denote a node of type \\\\mu with value x \\nLet e = (\\\\rho, S(e), T(e)) denote an edge of type \\\\rho with tails S(e) and head T(e)\\n\\n1) Embedding of nodes using embedding layers according to\\n    d_n = Embed_{\\\\mu}(x) \\n2) Embedding of edges using embedding layer according to\\n    d_e = Embed_{edge}(\\\\rho)\\n3) h_n^0 = W_{\\\\mu}d_n + b_{\\\\mu}\\n4) Heterogeneous Directed Hypergraph Convolutional Layer (HDHGConv) (L layers)\\n    i) Message Aggregation From Nodes to Hyper-Edges \\n        - Compute message according to \\n            m^{\\\\ell}_{n,e} = \\\\begin{cases}\\n                W^{\\\\ell}_{head}h_n^{\\\\ell-1} + b^{\\\\ell}_{head} & n \\\\in S(e) \\\\\\\\\\n                W^{\\\\ell}_{tail}h_n^{\\\\ell-1} + b^{\\\\ell}_{tail} & n = T(e) \\\\\\\\\\n            \\\\end{cases}\\n        - The directed hyper-edge e gathers messages frm tail nodes and head \\n          node using attention. For a message, attention is computed using \\n          d_e and m^{\\\\ell}_{n,e}.\\n          Messages are then aggregated using an attention weighted sum w/ learnable matrix\\n          in order to obtain o_e^{\\\\ell}\\n        - New embedding becomes q_e^{\\\\ell} = o_e^{\\\\ell} + W_z^{\\\\ell} d_e + b_z^{\\\\ell}\\n    ii) Message Aggregation From Hyper-Edges to Nodes\\n        - First two step identical to those for nodes -> edges, resulting in v_n^{\\\\ell} \\n        - New embedding computed according to \\n            h_n^{\\\\ell} = ELU(GraphNorm(W^{\\\\ell}_{u1}v_n^{\\\\ell} + W^{\\\\ell}_{u2}h_n^{\\\\ell - 1} + b_u^{\\\\ell}))\\n5) Attention-weighted sum pooling of node embeddings \\n    a_n = softmax(g^t h_n^L), where g is a learnable vector \\n6) MLP w/ Softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-classification\": {\n      \"training-objective\": \"Classify program into one of multiple categories\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify program into one of multiple categories\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Code Classification\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-classification\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 160,\n  \"pdf-id\": 210,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"First of all, for each node, its type, content, and position (line nr, column),\\nare combined into a string and embedded using a document embedding (flair)\\n\\nPaths from the root to leaf nodes are extracted, and embedded in the same way.\\n\\nPath embeddings are added to node embeddings to augment them.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"First, we introduce the Residual Self-Attention Mechanism Sub-layer (RSM),\\n  which takes input embeddings X and adjacency matrix A:\\n    i) K = GNN(X, A); Q = GNN(X, A); V = GNN(X, A);\\n    ii) Attn = softmax(Q * K^T / sqrt(d_k) + Attn_{prev});\\n    iii) H' = GCN((Attn, V), A)     (no clue how they combine V and attention, or why that's meaningful) \\n    iv) H = X + H'\\n\\nActual network: \\n  stack of the following:\\n    X' = LayerNorm(X + RSM(X, A))\\n    H = LayerNorm(X' + GCN(X', A))\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"ast-level-prediction\": {\n      \"training-objective\": \"Given a node, predict its level (depth) in the tree\",\n      \"training-granularity\": \"Node regression\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Graph / Node embedding (through pre-training)\",\n      \"supervision\": \"Self-supervised / Supervised (can automatically generate labels)\"\n    },\n    \"node-relationship-optimisation\": {\n      \"training-objective\": \"Given node triplet (anchor, positive (node on same level), negative (node on lower leven)), \\nmake sure anchor and positive are more similar than anchor and negative,\\ntaking into account the level difference between the anchor and negative node.\",\n      \"training-granularity\": \"node embedding\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Graph / Node embedding (through pre-training)\",\n      \"supervision\": \"Self-supervised / Supervised (can automatically generate labels)\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": null,\n      \"comments\": \"The two tasks are used to pre-train the model.\\n\\nThe model is then meant to be used on downstream tasks. \\nExamples given in the paper are:\\n  1) Augment with an FNN layer and do code classification\\n  2) Embed code and train a new classifier, for e.g. code clone detection \\n  3) Embed code for use in e.g. clustering\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 151,\n  \"pdf-id\": 200,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"The string represented by each node is embedded using word embeddings,\\nto obtain a matrix per node.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Basic Block\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"The instructions in basic clock are one-hot encoded\\nto obtain a matrix per node.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"adg\": {\n      \"name\": \"ADG (API Dependency Graph)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"API Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Dependency Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Every graph is input in a network of the following type:\\n  GCN w/ ReLU \\n  GCN w/ Softmax\\n\\nCFG and ADG nodes are matched to the AST nodes. Keep only \\nmatches nodes. \\n\\nThe embeddings of all matches node are concatenated,\\nand max pooling is applied.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"source-code-classification\": {\n      \"training-objective\": \"Given a sample, classify it as the correct class\",\n      \"training-granularity\": \"Graph Multi-class classification\",\n      \"working-objective\": \"Given a sample, classify it as the correct class\",\n      \"working-granularity\": \"Graph Multi-class classification\",\n      \"application\": \"Program Classification\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + cfg + adg\",\n      \"model\": \"model\",\n      \"task\": \"source-code-classification\",\n      \"comments\": \"The source code classification task is an example application. \\nThe graph is used as a general framework useful for different tasks.\"\n    }\n  ],\n  \"comments\": [\n    \"Unclear if the max-pooling is applied over all nodes, or per node.\",\n    \"If the max-pooling is applied per node, then it is unclear how the global pooling for the classification task was done\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 202,\n  \"pdf-id\": 271,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST with additional edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Next Token Edge\",\n          \"details\": \"NCS\"\n        },\n        {\n          \"name\": \"Hub Edge (My name; does not have a name in the paper)\",\n          \"details\": \"Connects node with types which generally have \\nmany child nodes (e.g. ClassDeclaration, MethodDeclaration)\"\n        }\n      ],\n      \"vertex-features\": \"Word vectors are used to encode node (unclear what exactly is encoded; could be node type for internal nodes, token for leafs)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency List\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gcn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN\\nMax pooling\\nSimilarity Score (unclear if part of network or separate)\"\n      }\n    },\n    \"gat\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GAT \\nMax Pooling \\nSimilarity Score (unclear if part of network or separate)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"clone-detection\": {\n      \"training-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"training-granularity\": \"Graph Classification (?)\",\n      \"working-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"working-granularity\": \"Graph Classification (?)\",\n      \"application\": \"Code Clone Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"gcn\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph\",\n      \"model\": \"gat\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 62,\n  \"pdf-id\": 89,\n  \"graphs\": {\n    \"interation-graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Bipartite graph relating users and repositories (temporal graph)\",\n      \"artefacts\": [\n        {\n          \"name\": \"Users\",\n          \"details\": \"from github\"\n        },\n        {\n          \"name\": \"Repositories\",\n          \"details\": \"from github\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"User\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Repository\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Vulnerability\",\n          \"details\": \"Denotes the introduction of a vulnerability in a repository by a user\\n\\nEvery interaction is annotated with a time (normalised to [0, 1]) at \\nwhich the interaction occurred.\"\n        }\n      ],\n      \"vertex-features\": \"Note: all features are time dependent! i.e. they change over time \\n\\nFor users;\\n  - Number of repositories owned\\n  - Number of repositories starred\\n  - Number of comments made by a user\\n  - Number of public repositories starred by a user\\n  - Number of vulnerabilities introduced _before this interaction_\\n  - Cumulative severity score of introduced vulnerabilities \\n\\nFor repositories;\\n  - Primary language used in the repository\\n  - Boolean indicating whether the repository has been forked \\n  - Number of open issues \\n  - Number of stars \\n  - Number of people watching \\n  - Number of forks \\n  - Number of pull requests \\n  - Size of the repository \\n  - Cumulative amount of vulnerability introduced _before this interaction_\\n  - Cumulative severity score of introduced vulnerabilities\",\n      \"edge-features\": \"Severity score, time t\",\n      \"connectivity-features\": \"Adjacency matrix (time dependent)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"network\": {\n      \"type\": {\n        \"name\": \"SeCoPe\",\n        \"architecture\": \"Variant of CoPe, with \\\\alpha set to the eigenvector centrality of the matrix A_k\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-prevention\": {\n      \"training-objective\": \"Predict future vulnerabilities introduced by users\",\n      \"training-granularity\": \"Link Prediction\",\n      \"working-objective\": \"Predict future vulnerabilities introduced by users\",\n      \"working-granularity\": \"Link Prediction\",\n      \"application\": \"Predict Vulnerabilities Introduced by Specific Users (and identify high-risk contributors)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"interaction-graph\",\n      \"model\": \"network\",\n      \"task\": \"vulnerability-prevention\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 25,\n  \"pdf-id\": 38,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"n/a\",\n      \"description\": \"Interconnected ASTs with data flow and control flow edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"Source code taken from multiple source files.\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"First, file containing unit tests are parsed. \\nTest _bodies_ are isolated and used to construct the initial graph.\\nThe graph is expanded by including the AST bodies of all (possibly non-test)\\nmethods called in the unit test.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data flow edge\",\n          \"details\": \"No details given\"\n        },\n        {\n          \"name\": \"Control flow edge\",\n          \"details\": \"No details given\"\n        }\n      ],\n      \"vertex-features\": \"Not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Gated Graph Convolutional Layer Aggregation layer based on node type. Let T denote all node types and let h_t denote the mean embedding of all nodes of type t \\\\in T. Then, the layer output is given by o = sum_{t \\\\in T} attention(h_t) Encoder Layer\\nSimple decoder is used to decode the method name.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"name-prediction\": {\n      \"training-objective\": \"Predict the name of a unit test, given the graph representation.\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Predict the name of a unit test, given the graph representation.\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Name generation for automatically generated unit tests.\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"name-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": [\n    \"Badly written paper\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 58,\n  \"pdf-id\": 82,\n  \"graphs\": {\n    \"code-property-graph\": {\n      \"name\": \"Code Property Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Some AST nodes, specifically those without \\nchild nodes and only contain AST edges,\\nare pruned.\\n\\nContent of AST nodes is simplified. \\nIn particular, user defined names are \\nreplaced with standardised placeholders.\\nExamples: F<i> for functions, V<i> for variables.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Payload of node encoded using Word2Vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GGNN layer \\nGCN powered SAGPool layer (attention based pooling) -> outputs key (important) subgraph and remainder subgraph\\nkey subgraph to global pooling layer \\nremainder subgraph to max pooling layer\\nresulting embeddings are concatenated to obtain graph embedding\\nMPL w/ sigmoidal activation for final output\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Given a graph representing a method, determine if is contains a vulnerability\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given a graph representing a method, determine if is contains a vulnerability\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 149,\n  \"pdf-id\": 198,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Every node has three attributes:\\nx: Depth \\ny: left-to-right sequential position of its parent in the layer\\nz: left-to-right sequential position among its siblings\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"Each edge has the (x, y, z) attribute as its destination node as attributes\"\n        }\n      ],\n      \"vertex-features\": \"(x, y, z), and the token payload (type or token)\\nNote: vertices are used on their own, not as part of a graph\",\n      \"edge-features\": \"(x, y, z), and the pair of token payloads (type or token) of the nodes it is connecting \\nNote: edges are used on their own, not as part of a graph\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"The comment generated thus far (in token form) is also used as an input.\\nEach token is enhanced with positional information describing its location in the sequence.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Transformer based architecture \\n\\nEach type of input (node, vertex, token) is passed through an embedding layer.\\nThe node/edge/token is embedded, and its position is embedded. Finally, \\nboth embeddings are combined using a (weighted) sum; E = E_o * \\\\sqrt{d} + E_{pos}\\n\\nEdge embeddings and vertex embeddings are both passed through separate encoders created out of units with the following structure:\\n  1) Multi-head self attention w/ residual connections and normalisation\\n  2) FNN w/ residual connections and normalisation\\n\\nComment generated thus far is put into a decoder created out of units with the following structure:\\n  1) Masked multi-head self attention w/ residual connections and normalisation\\n  2) multi-head attention, with as input the output of the edge encoder, w/ residual connections and normalisation\\n  3) multi-head attention, with as input the output of the vertex encoder, w/ residual connections and normalisation\\n  4) FNN w/ residual connections and normalisation\\n\\nLinear Layer\\nSoftmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"training-granularity\": \"Graph to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"working-granularity\": \"Graph to Sequence\",\n      \"application\": \"Code summarization (Generating comments for Python code)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 184,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"sigma-0\": {\n      \"name\": \"$\\\\sigma$-0 graph\",\n      \"description\": \"Mostly based on PDG, but with more variety in node types\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Entry Node\",\n          \"details\": \"Entrypoint of control flow into the graph\"\n        },\n        {\n          \"name\": \"Exit Node\",\n          \"details\": \"Exit point of control flow from the graph\"\n        },\n        {\n          \"name\": \"Data Node\",\n          \"details\": \"Represent data, e.g. constants, variables, literals\"\n        },\n        {\n          \"name\": \"Action Node\",\n          \"details\": \"Represent actions, e.g. function calls, operators, etc.\"\n        },\n        {\n          \"name\": \"Control Node\",\n          \"details\": \"Represent control points, e.g branches, looping\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Entry Node: \\\"ENTRY\\\"\\nExit Node: \\\"EXIT\\\" \\nVariable Node: name of the variable type \\nControl Node: Name of control structure (e.g. \\\"IF\\\")\\nAction node: not specified \\n\\nFeatures encoded using fast text, and average of tokens is used\",\n      \"edge-features\": \"Regular Control edge: Not specified \\nException control edge (catch): type of exception\\ndata edge: receiver, parameter, definition, condition, qualifier \\n\\nFeatures encoded using fast text, and average of tokens is used\",\n      \"connectivity-features\": \"Method not specified \\n\\nreverse edges are added\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"sigma-1\": {\n      \"name\": \"$\\\\sigma$-1 graph\",\n      \"description\": \"Mostly based on $\\\\sigma$-0 graph, but with additional information\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Entry Node\",\n          \"details\": \"Entrypoint of control flow into the graph\"\n        },\n        {\n          \"name\": \"Exit Node\",\n          \"details\": \"Exit point of control flow from the graph\"\n        },\n        {\n          \"name\": \"Data Node\",\n          \"details\": \"Represent data, e.g. constants, variables, literals\"\n        },\n        {\n          \"name\": \"Action Node\",\n          \"details\": \"Represent actions, e.g. function calls, operators, etc.\"\n        },\n        {\n          \"name\": \"Control Node\",\n          \"details\": \"Represent control points, e.g branches, looping\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Edge\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Data Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Variable Usage Edges\",\n          \"details\": \"Multiple types, but unclear. At least FirstUse and LastUse\"\n        },\n        {\n          \"name\": \"Node Aliasing\",\n          \"details\": \"Not explained\"\n        },\n        {\n          \"name\": \"Control Dependence Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Same as $\\\\sigma$-0, but Node types (according to AST) are also used as features\",\n      \"edge-features\": \"Regular Control edge: Not specified \\nException control edge (catch): type of exception\\ndata edge: receiver, parameter, definition, condition, qualifier \\n\\nFeatures encoded using fast text, and average of tokens is used\",\n      \"connectivity-features\": \"Method not specified \\n\\nreverse edges are added\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"RGCN\\nRGCN\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"embedding\": {\n      \"training-objective\": \"Minimise loss function with multiple aspects;\\n1) Nodes in the same metapath  random walk should have similar embeddings\\n2) nodes of equal type should be more similar than nodes of different types \\n3) motif signals\\n4) Similar nodes should have similar embeddings\",\n      \"training-granularity\": \"Graph Embedding\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Embedding (pre-)training\",\n      \"supervision\": \"Unknown\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"sigma-0\",\n      \"model\": \"model\",\n      \"task\": \"embedding\",\n      \"comments\": \"The models are pre-trained using the embedding tasks, \\nand can later be fine-tuned for downstream tasks.\\n\\nThe paper does this using the examples of method name prediction,\\nand link prediction (of removed links)\"\n    },\n    {\n      \"graph\": \"sigma-0\",\n      \"model\": \"model\",\n      \"task\": \"embedding\",\n      \"comments\": \"The models are pre-trained using the embedding tasks, \\nand can later be fine-tuned for downstream tasks.\\n\\nThe paper does this using the examples of method name prediction,\\nand link prediction (of removed links)\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 1,\n  \"pdf-id\": 3,\n  \"graphs\": {\n    \"dataflow-1\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST with added control and data flow edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code (methods)\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"Edges between different uses of the same variable.\\n\\nType 1: Starting from the declaration, each usage of the \\nvariable points to the next usage.\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"Edges between Statement node. \\nEvery statement node points to all statements node which can \\nimmediately follow it in execution. \\nExample: fallible operations pointing to the next statement,\\nbut also the encapsulating catch block.\"\n        }\n      ],\n      \"vertex-features\": \"Node type is one-hot encoded.\\n\\nThe source code snippets corresponding to every node \\n(including comments) is represented as a sequence of \\ntokens, where every token is encoded using CodeBERT.\\n\\nThe average vector of all encoded tokens is computed,\\nand concatenated to the one-hot encoded node type.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"dataflow-2\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST with added control and data flow edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code (methods)\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"Edges between different uses of the same variable.\\n\\nType 2: The declaration of a variable points to every usage of that variable.\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"Edges between Statement node. \\nEvery statement node points to all statements node which can \\nimmediately follow it in execution. \\nExample: fallible operations pointing to the next statement,\\nbut also the encapsulating catch block.\"\n        }\n      ],\n      \"vertex-features\": \"Node type is one-hot encoded.\\n\\nThe source code snippets corresponding to every node \\n(including comments) is represented as a sequence of \\ntokens, where every token is encoded using CodeBERT.\\n\\nThe average vector of all encoded tokens is computed,\\nand concatenated to the one-hot encoded node type.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"dataflow-3\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST with added control and data flow edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code (methods)\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"Edges between different uses of the same variable.\\n\\nType 3: The declaration of a variable points to every usage of that variable.\\nAdditionally, starting from the declaration, each usage of the \\nvariable points to the next usage. (combined type 1 and type 2)\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"Edges between Statement node. \\nEvery statement node points to all statements node which can \\nimmediately follow it in execution. \\nExample: fallible operations pointing to the next statement,\\nbut also the encapsulating catch block.\"\n        }\n      ],\n      \"vertex-features\": \"Node type is one-hot encoded.\\n\\nThe source code snippets corresponding to every node \\n(including comments) is represented as a sequence of \\ntokens, where every token is encoded using CodeBERT.\\n\\nThe average vector of all encoded tokens is computed,\\nand concatenated to the one-hot encoded node type.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN Layer [Kipf] (size 128)\\nDMoNPooling Layer (# clusters: 150)\\nk-GNN Layer (w/ ReLU)\\nDMoNPooling Layer (# clusters: 150)\\nk-GNN Layer (w/ ReLU)\\nDMoNPooling Layer (# clusters: 150)\\nk-GNN Layer (w/ ReLU)\\nMulti Layer Perceptron w/ Log-softmax output (1 hidden layer of size 64; 3 layers total)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"readability-prediction\": {\n      \"training-objective\": \"Classify graph (method) as Readable/Neutral/Unreadable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify graph (method) as Readable/Neutral/Unreadable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Code Readability Classification\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"training\": {\n    \"experiment\": {\n      \"train-test-split\": \"n/a\",\n      \"cross-validation\": {\n        \"used\": true,\n        \"details\": \"5-fold cross validation.\\n  \\n3 folds for training, 1 for validation, 1 for testing.\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"batch size\",\n          \"value\": 15\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.0001\n        },\n        {\n          \"name\": \"epochs\",\n          \"value\": 200\n        }\n      ],\n      \"hyper-parameter-selection\": \"search\",\n      \"search-tuned-hyper-parameters\": [\n        \"number of clusters in pooling layers\",\n        \"number of gcn layers\",\n        \"number of pooling/k-gnn layer pairs\",\n        \"gcn layer size\",\n        \"perceptron layer size\",\n        \"batch size\",\n        \"learning rate\"\n      ],\n      \"evaluation-details\": \"During cross validation, train for 200 epochs each time \\nand record best result on test set.\\n  \\nAfter cross validation, take average of the five results \\nfor final performance score.\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"precision\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"recall\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"f1-score\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"MCC\",\n          \"type\": \"metric\",\n          \"details\": \"Matthews Correlation Coefficient\"\n        },\n        {\n          \"name\": \"AUC\",\n          \"type\": \"metric\",\n          \"details\": \"Area Under Curve (ROC)\"\n        }\n      ]\n    }\n  },\n  \"datasets\": {\n    \"scalabrino\": {\n      \"name\": \"n/a\",\n      \"description\": \"Existing dataset curated by other researchers,\\nconsisting of Java methods with valid syntax,\\nwhere each method is 10 to 50 lines long.\\nEvery method is annotated with the readability of the method.\",\n      \"source\": [\n        \"jUnit\",\n        \"Hibernate\",\n        \"jFreeChart\",\n        \"ArgoUML\"\n      ],\n      \"labelling\": \"Manually annotated\",\n      \"size\": 200,\n      \"is-pre-existing\": true\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"dataflow-1\",\n      \"model\": \"model\",\n      \"task\": \"readability-prediction\",\n      \"training\": \"experiment\",\n      \"dataset\": \"scalabrino\",\n      \"comments\": \"n/a\"\n    },\n    {\n      \"graph\": \"dataflow-2\",\n      \"model\": \"model\",\n      \"task\": \"readability-prediction\",\n      \"training\": \"experiment\",\n      \"dataset\": \"scalabrino\",\n      \"comments\": \"n/a\"\n    },\n    {\n      \"graph\": \"dataflow-3\",\n      \"model\": \"model\",\n      \"task\": \"readability-prediction\",\n      \"training\": \"experiment\",\n      \"dataset\": \"scalabrino\",\n      \"comments\": \"n/a\"\n    }\n  ],\n  \"comments\": [\n    \"Inconsistent in reporting the number of pooling/k-gnn pairs (some parts say 2, others 3)\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 196,\n  \"pdf-id\": 261,\n  \"graphs\": {\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"Edges sometimes have labels, e.g. labelled \\\"true\\\" or \\\"false\\\" for conditionals\"\n        }\n      ],\n      \"vertex-features\": \"Tokens in node encoded using word2vec\",\n      \"edge-features\": \"Encoded using word2vec (0 padded if empty)\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"pdg\": {\n      \"name\": \"PDG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"Annotated with variable name\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"sometimes have labels, e.g. labelled \\\"true\\\" or \\\"false\\\" for conditionals\"\n        }\n      ],\n      \"vertex-features\": \"Tokens in node encoded using word2vec\",\n      \"edge-features\": \"Encoded using word2vec (0 padded if empty)\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Node Internal Multi-head Attention (aggregate token vectors into a single vector)\\n    For a node V_j with tokens {v_1, v_2, ..., v_N}, compute\\n    i) e_i = a(W v_i)\\n    ii) a_i = softmax(e_i)\\n    iii) Do this K times to obtain K vectors a^k of length N with attention coefficients for every token\\n    iv) Aggregate according to \\n      h_j = ELU(W_o (concat_{k = 1}^K W^ k V_j (a^k)^ T))\\n2) Multi-head GAT \\n3) Edge Pooling (edge scores according to e_{ij} = W (h_i || h_j || f_{ij}) + b, where f_{ij} is the edge feature \\n4) GAT \\n5) Edge Pooling (edge scores according to e_{ij} = W (h_i || h_j || f_{ij}) + b, where f_{ij} is the edge feature \\n6) Fusion of outputs of (1), (3), and (5)\\n    i) To every output, apply GlobalAttention as pooling operation\\n          r = \\\\sum_{n = 1}^N softmax(h_{gate}(x_n)) \\\\odot h_{\\\\Theta}(x_n) (where the two h_{...} functions are neural networks)\\n    ii) Concatenate the 3 pooled vectors \\n7) Bidirectional LSTM \\n8) For the two input code snippets, concatenate the outputs of the two LSTMs \\n9) FNN w/ softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"clone-detection\": {\n      \"training-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"training-granularity\": \"Graph Classification (?)\",\n      \"working-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"working-granularity\": \"Graph Classification (?)\",\n      \"application\": \"Code Clone Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"model\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 41,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"api-enhanced-ast\": {\n      \"name\": \"API Enhanced AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"A new AST node _type_ is added for every API called;\\ni.e. every function call node gains a new child node whose\\ntype is equal to the API name\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Node type is encoded using Word2Vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"tree-cnn\": {\n      \"type\": {\n        \"name\": \"Tree-based convolution\",\n        \"architecture\": \"Siamese Tree-based convolution network with MLP output layer\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-cloned-detection\": {\n      \"training-objective\": \"Given two graphs, determine whether they are semantic clones\",\n      \"training-granularity\": \"Pairwise graph classification (?)\",\n      \"working-objective\": \"Given two graphs, determine whether they are semantic clones\",\n      \"working-granularity\": \"Pairwise graph classification (?)\",\n      \"application\": \"Semantic Code Clone Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"api-enhanced-ast\",\n      \"model\": \"tree-cnn\",\n      \"task\": \"code-cloned-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 108,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"code-property-graph\": {\n      \"name\": \"Code Property Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Node type is one-hot encoded \\nSource code is encoded by summing word2vec vectors of all tokens in the fragment \\nThe two encodings are concatenated\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix (?)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN followed by SAGPool (T layers)\\nSum Pooling\\nFNN Layer\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify code as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify code as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 191,\n  \"pdf-id\": 254,\n  \"graphs\": {\n    \"pdg\": {\n      \"name\": \"PDG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Method\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"Has as attribute the variable involved in the dependency\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Special traversal algorithm is used to sequence the graph.\\nThe process is reversible (i.e. retains some form of the structural information);\\nthe content of every node is then placed in its place in the sequence. \\n\\nThe method name is tokenised; the sequence is used as a feature \\n\\nTokens in the method body are used as a feature\\n\\nCode summary/query is tokenised and used as a feature\"\n    }\n  },\n  \"models\": {\n    \"multi-modal-model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Code Token Input (note: tokens are considered as being unordered)\\n  i) Embedding Layer \\n  ii) MLP per token \\n  iii) Max pooling over all MLP outputs \\n2) Method Name Encoder\\n  i) Embedding Layer\\n  ii) Bidirectional LSTM\\n  iii) Maxpooling over pairwise concatenated hidden states of the two LSTM directions\\n3) Graph Encoder\\n  i) Embedding Layer (embed items in PDG sequence)\\n  ii) Bidirectional LSTM \\n  iii) Maxpooling over pairwise concatenated hidden states of the two LSTM directions\\n4) Attention based fusion of outputs of (1,2,3) (weighted sum)\\n5) Summary/query encoder\\n  i) Embedding Layer\\n  ii) Bidirectional LSTM\\n  iii) Maxpooling over pairwise concatenated hidden states of the two LSTM directions\"\n      }\n    },\n    \"graph-enhanced-code-bert\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"CodeBERT with as input [CLS] <summary/query tokens> [SEP] <pdg sequence tokens>\\noutput is binary softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-search\": {\n      \"training-objective\": \"Maximise similarity between related (code, summary) pairs; minimise similarity between unrelated paris\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Output embeddings for [cosine] similarity based code search\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code Search\",\n      \"supervision\": \"Supervised\"\n    },\n    \"code-search-binary\": {\n      \"training-objective\": \"Classify (code, summary) pairs as either related or unrelated\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Classify (code, query) pairs as related or unrelated\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code Search\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"multi-modal-model\",\n      \"task\": \"code-search\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"graph-enhanced-code-bert\",\n      \"task\": \"code-search-binary\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 53,\n  \"pdf-id\": 76,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"method\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Node content is encoded using Word2Vec\\n\\nNote that all nodes, even e.g. BlockStm, are considered \\nto contain a text payload (e.g. \\\"{}\\\")\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"For every graph, the minimum set of long paths covering \\nall nodes in the AST is computed.\\nHere, a long path is a path from one leaf node to another,\\nvia the root, possibly sharing one or multiple nodes along \\nthe path.\\n\\nDuring the generation of training data,\\nIf a long path contains a node which was present in a \\nbug/vulnerability fix, all embeddings in the path\\nare multiplied by a weight w.\\n\\nFor the GRU model, the nodes in a long path are seen \\nas a sequence of token.\\n\\nFor the CNN model, the nodes in a long path are combined \\ninto a matrix.\\n\\nJoint model, with two parallel paths:\\n  1) Attention-based GRU layer\\n  2) Attention-based CNN layer followed by FNN\\nBoth paths are combined w/ a multi-head attention layer. \\n\\nThis method is used to encode every path into a (local) vector.\\n\\nFor every long path, the nodes in the PDG and DFG (partially) \\ncovered by the long path are extracted, and formed into two matrices.\\nThese matrices (global) are multiplied with the local vector and \\nthen concatenated in order to obtain a vector \\nwith both local and global information for each path.\\n\\nThe vectors for each path are then concatenated in order to obtain a\\nmatrix representing the entire method, with additional global information.\"\n    },\n    \"pdg\": {\n      \"name\": \"Program Dependence Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Multiple methods\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"PDG Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Vertices encoded using node2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"dfg\": {\n      \"name\": \"Data Flow Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Multiple methods\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Vertices encoded using node2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"cnn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"CNN w/ Max pooling, followed by an FNN layer with softmax.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"bug-detection\": {\n      \"training-objective\": \"Given a method, predict whether it contains a bug\",\n      \"training-granularity\": \"n/a (Ambiguous; Graph embedding, node embedding, graph classification)\",\n      \"working-objective\": \"Given a method, predict whether it contains a bug\",\n      \"working-granularity\": \"n/a (Ambiguous; Graph embedding, node embedding, graph classification)\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + pdg + dfg\",\n      \"model\": \"cnn\",\n      \"task\": \"bug-detection\",\n      \"comments\": \"Unclear how exactly the local path vectors are obtained;\\nunclear how the model is trained.\\nSpecifically, it is unclear what training objective was used.\\nThe repository uses categorical cross entropy and sigmoid activation,\\nwhich seems odd, given that this ought to be an embedding task.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 71,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"ucpg\": {\n      \"name\": \"Unified Code Property Graph (UCPG)\",\n      \"description\": \"Combination of code property graph, control flow, and NCS\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Function Call Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"NCS Edge\",\n          \"details\": \"Natural code sequence edge\"\n        }\n      ],\n      \"vertex-features\": \"Node content encoded using doc2vec\",\n      \"edge-features\": \"Unidirectional edges are converted to bidirectional edges/backedges are added.\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"network\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN\\nSome pooling with average and max pooling, also attention based summing, also incoming skip connections from all pooling(?) layers\\nFNN layer \\nsoftmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vul-detection\": {\n      \"training-objective\": \"Classify code sample as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify code sample as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ucpg\",\n      \"model\": \"network\",\n      \"task\": \"vul-detection\",\n      \"comments\": \"Very unclear what the exact network architecture is.\\n\\nThe authors talk about \\\"Convolutional pooling modules\\\"; not sure what they mean.\\n\\nThe authors first describe attention-weighted summing as pooling, but \\nthen go on to explain pooling with skip connections from _every pooling layer_.\\nHowever, they describe a matrix (node embedding matrix) output from every layer,\\nwhile their described pooling mechanism outputs a vector.\\n\\nBased on their reference to [17], this may just be described incorrectly;\\nthey first do max and average pooling based on skip connections \\nfrom the _graph convolutional layers_, and then perform the \\nattention-weighted summing after that.\\n\\nHowever, this still leaves ambiguity and possible room for error; \\nevery such pooling layer performs average and max pooling on the \\nnode embedding matrix itself, leading to a graph embedding \\ncorresponding to every GCN (or pooling?) module; it is not clear\\nhow these are combined, and how they relate to the aforementioned \\nattention-weighted summing.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 175,\n  \"pdf-id\": 228,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Mix of AST, CFG, DFG, NCS\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"functions\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Certain node types are merged. Nodes representing the same variables are merged.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"NCS Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Source code in node tokenised and \\nencoded using word2vec. \\nFinal vector is average of token embeddings.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Edge-Aware GCN\\n    i) Every edge type b has, in every layer, a weight matrix W_b = a_b V\\n        Where a is a learnable vector and V is a linear transformation.\\n    ii) Message passing:\\n        h_i^(l+1) = \\\\sigma(\\\\sum_b \\\\sum_{j \\\\in N_b(i)} \\\\frac{1}{c_{i,b}} W_b^{\\\\ell}h^{\\\\ell}_{j} + W_0^{\\\\ell}h^{\\\\ell}_{i})\\n    iii) Attention for each edge:\\n        w^{k,\\\\ell}_{i,j} = softmax_j \\\\frac{h_i^{k,\\\\ell} \\\\cdot h_j{k,\\\\ell}}{\\\\sqrt{d_k}}\\n    iv) Aggregation:\\n        A_i^{\\\\ell} = concat_{k = 1}^P (\\\\sum_{j \\\\in N(i)} w^{k,\\\\ell}_{i,j} h_j^{k,\\\\ell})W_h^{\\\\ell} + h_i^{\\\\ell - 1}\\n        h_i^{\\\\ell} = W_2^{\\\\ell}\\\\sigma(W_1^{\\\\ell}A_i^{\\\\ell}) + A_i^{\\\\ell}\\n        (Note: latter is FNN w/ residual connection)\\n2) Aggregate node embeddings into matrix \\n3) Pass matrix through to parallel CNN layers, 1 with small kernel other with large (capture long range node dependencies);\\n    pass result of each through batch normalisation, and add them together\\n4) FNN (2 layer) w/ softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 131,\n  \"pdf-id\": 174,\n  \"graphs\": {\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"To avoid confusion, remember that the artefacts in the \\n\\\"artefacts\\\" section are not related _beforehand_, but their\\nrelatedness must be predicted\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"files\"\n        },\n        {\n          \"name\": \"Bug Report\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Punctuation in statements is removed, names are broken up,\\ntokens are encoded using word2vec, and put into a matrix.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Bug reports are preprocessed (standard NLP steps),\\nand encoded as matrix of word vectors using word2vec\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Two parallel inputs:\\n  i) Bug Report\\n      1D CNN\\n      Max Pooling\\n  ii) Control Flow Graph\\n      - Statement Encoder: CNN1D + Maxpool\\n      - Information Propagation:\\n          The following update rule is applied for T time steps.\\n          For the first time step, only the root node (entry point), is \\\"active\\\".\\n          After a time step, the children of all active nodes _also_ become active.\\n\\n          z'_v^t = average of hidden states of incoming nodes \\n          x_v^t, z_v^t = \\\\begin{cases}\\n            GRU(x_v^{t-1}, z'_v^{t}) & v is active \\\\\\\\ \\n            x_v^{t - 1}, z_v^{t - 1} & otherwise \\n          \\\\end{cases}\\n\\n      - Information Aggregation \\n          u = \\\\frac{1}{|V} \\\\sum_{v \\\\in V} GRU(x_v^T, x_v^0)\\n          (i.e. GRU applied to the initial node embedding after the statement encoder, \\n          and the node embedding after T time steps)\\n2) Fuse using FNN\\n3) Prediction\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"bug-localisation\": {\n      \"training-objective\": \"Given a (source file, bug report) pair, predict whether the bugs occurs in the given file\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a (source file, bug report) pair, predict whether the bugs occurs in the given file\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Bug localisation\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"model\",\n      \"task\": \"bug-localisation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 49,\n  \"pdf-id\": 70,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"for GGNN model:\\n  Three separate mechanics:\\n  1) Ordinal encoding of node type\\n  2) Ordinal encoding of node type + Ordinal encoding of the tokens in the node \\n  3) Ordinal encoding of node type + average word2vec encoding of tokens in the node\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"For the LSTM model:\\n  1) tokenisation,\\n      abstraction of literaturs,\\n      removal of uncommon identifiers, \\n      splitting snake and camel case into separate words\\n  2) Converting into a stream of tokens\"\n    },\n    \"pdg\": {\n      \"name\": \"PDG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"PDG Node\",\n          \"details\": \"Forward and backward slicing is performed to only keep relevant nodes\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"for GGNN model:\\n  Three separate mechanics:\\n  1) Ordinal encoding of node type\\n  2) Ordinal encoding of node type + encoded variant of some additional info (e.g. functions mentioned by node)\\n  3) Ordinal encoding of node type + average word2vec encoding of tokens in the node\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"For the LSTM model:\\n  1) tokenisation,\\n      abstraction of literaturs,\\n      removal of uncommon identifiers, \\n      splitting snake and camel case into separate words\\n      remove certain uninformative node types\\n  2) Converting into a stream of tokens\"\n    }\n  },\n  \"models\": {\n    \"lstm\": {\n      \"type\": {\n        \"name\": \"LSTM\",\n        \"architecture\": \"LSTM\"\n      }\n    },\n    \"ggnn\": {\n      \"type\": {\n        \"name\": \"GGNN\",\n        \"architecture\": \"GGNN\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"report-filtering\": {\n      \"training-objective\": \"Classify code report as true/false positive\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify code report as true/false positive\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Filter out false positives from static source analysis tools\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"lstm\",\n      \"task\": \"report-filtering\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"ggnn\",\n      \"task\": \"report-filtering\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 177,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"fda\": {\n      \"name\": \"FDA\",\n      \"description\": \"Mixture of AST, FCG, and DFG\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge - LastUse\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge - Compute\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge - Formal\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge - Return\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge - Operand\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Function Call Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Unclear what node features are used\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) GGANN - Combination of GGNN and GAT\\n  - Every edge has a hidden state \\n  i) Edge hidden state update\\n    h'_{ij}^{t + 1} = MLP(h'_{ij}^t, h_i^t, h_j^t)\\n  ii) Propagation Matrix Computation (computed matrix for specific connection)\\n    B^{t + 1} = MLP(h'_{ij}^{t})\\n  iii) Attention\\n    a_{ij} = softmax(Attention(h_i^t, h_j^t))\\n  iv) Aggregation\\n    m_i^{t + 1} = \\\\sum_{j \\\\in N_i} a_{ij} B^{t + 1} h_j^t\\n  v) GRU\\n    h_i^{t + 1} = GRU(h_i^t, m_i^{t + 1})\\n2) Pooling according to\\n  h_G is initialised \\n  h_G = \\\\sum_{i \\\\in V} f(h_i^T, h_G) \\\\odot g(h_i^T)\\n  Here, f is a neural network serving as a soft attention mechanism (compute similarity score),\\n  and g is a neural network \\n3) output; y = softmax(h_G)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"program-classification\": {\n      \"training-objective\": \"Given a sample (program), classify it into one of multiple categories\",\n      \"training-granularity\": \"Graph Multi-class Classification\",\n      \"working-objective\": \"Given a sample (program), classify it into one of multiple categories\",\n      \"working-granularity\": \"Graph Multi-class Classification\",\n      \"application\": \"Program Classification (student programs)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"fda\",\n      \"model\": \"model\",\n      \"task\": \"program-classification\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 69,\n  \"pdf-id\": 97,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"directed\"\n        }\n      ],\n      \"vertex-features\": \"Node type and Node payload tokens are encoded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Stacked adjacency tensor.\\n\\nFor every graph, the adjacency matrix is determined.\\nThe four matrices are then combined into a third order tensor.\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"cfg\": {\n      \"name\": \"Control Flow Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"Edges representing control flow between basic blocks\"\n        }\n      ],\n      \"vertex-features\": \"Node type and Node payload tokens are encoded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Stacked adjacency tensor.\\n\\nFor every graph, the adjacency matrix is determined.\\nThe four matrices are then combined into a third order tensor.\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"dfg\": {\n      \"name\": \"Data Flow Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"Edges represent subsequent modification or access of the same variables\"\n        }\n      ],\n      \"vertex-features\": \"Node type and Node payload tokens are encoded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Stacked adjacency tensor.\\n\\nFor every graph, the adjacency matrix is determined.\\nThe four matrices are then combined into a third order tensor.\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"ncs\": {\n      \"name\": \"Natural Code Sequence\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Code Sequence Edge\",\n          \"details\": \"Edge from one AST leaf node to the next\"\n        }\n      ],\n      \"vertex-features\": \"Node type and Node payload tokens are encoded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Stacked adjacency tensor.\\n\\nFor every graph, the adjacency matrix is determined.\\nThe four matrices are then combined into a third order tensor.\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"circle-ggnn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Gated Graph Tensor Neural Network\\n  Adaptation of GGNN to tensor setting. \\n  Tensors facilitate inter- and intra-graph information exchange.\\nMLP on concatenation of initial features and final output of GNN part \\nMLP on final output of GNN part\\nElement-wise multiplication of MLP outputs\\nAveraging of element-wise multiplication outputs\\nSigmoid\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify samples as vulnerable/not vulnerable\",\n      \"training-granularity\": \"Graph Classification (multiple graphs per sample)\",\n      \"working-objective\": \"Classify samples as vulnerable/not vulnerable\",\n      \"working-granularity\": \"Graph Classification (multiple graphs per sample)\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + cfg + dfg + ncs\",\n      \"model\": \"circle-ggnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 8,\n  \"pdf-id\": 15,\n  \"graphs\": {\n    \"seqgraph\": {\n      \"name\": \"SeqGraph\",\n      \"description\": \"Graph containing syntactic and control flow information\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST node with code abstraction\",\n          \"details\": \"AST nodes, but e.g. literals are replaces with a LITERAL marker.\\nThe nodes corresponding to the buggy line (directly connected by NextToken edges),\\nare enclosed by START_BUG and END_BUG markers.\"\n        }\n      ],\n      \"vertex-features\": \"Word2Vec is used to encode the tokens.\\nThen, those tokens are further encoded using a BiLSTM encoder.\",\n      \"edge-type\": [\n        {\n          \"name\": \"NextToken\",\n          \"details\": \"Connects two tokens that are next to each other in the document.\"\n        }\n      ],\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": null,\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"fag\": {\n      \"name\": \"Flow-augmented graph\",\n      \"description\": \"Graph containing syntactic and control flow information\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST node with code abstraction\",\n          \"details\": \"AST nodes, but e.g. literals are replaces with a LITERAL marker.\\nThe nodes corresponding to the buggy line (directly connected by NextToken edges),\\nare enclosed by START_BUG and END_BUG markers.\"\n        }\n      ],\n      \"vertex-features\": \"Word2Vec is used to encode the tokens.\\nThen, those tokens are further encoded using a BiLSTM encoder.\",\n      \"edge-type\": [\n        {\n          \"name\": true,\n          \"details\": \"Denotes that one jumps from one node to another if the condition of which the \\nfirst node is a part, is true.\"\n        },\n        {\n          \"name\": false,\n          \"details\": \"Denotes that one jumps from one node to another if the condition of which the \\nfirst node is a part, is false.\"\n        },\n        {\n          \"name\": \"UseBy\",\n          \"details\": \"Connects last assignment of a variable to all its subsequent uses\"\n        },\n        {\n          \"name\": \"DefineIn\",\n          \"details\": \"Connects the declaration of a variable to places where it is assigned to.\"\n        },\n        {\n          \"name\": \"NextToken\",\n          \"details\": \"Connects two tokens that are next to each other in the document.\"\n        },\n        {\n          \"name\": \"CallBy\",\n          \"details\": \"Connects a caller to the function it is calling\"\n        }\n      ],\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": null,\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Encoder/decoder architecture using GNN for the encoder and RNN for the decoder.\\nEncoder architecture; 2 GCN layers [Kipf]\\nDecoder architecture; not clearly described Uses copy (using pointer network) and coverage mechanism for decoding\\nFinally, beam searched is used to select top-k alternatives\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"fixing\": {\n      \"training-objective\": \"Construct the correct fix for the bug\",\n      \"training-granularity\": \"Graph Embedding (encoder), sequence reconstruction (decoder)\",\n      \"working-objective\": \"Construct the correct fix for the bug\",\n      \"working-granularity\": \"Graph Embedding (encoder), sequence reconstruction (decoder)\",\n      \"application\": \"Code fix generation\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"training\": {\n    \"training\": {\n      \"train-test-split\": {\n        \"train\": 0.8,\n        \"test\": 0.1,\n        \"validation\": 0.1\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"encoder dropout\",\n          \"value\": 0.2\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.001\n        },\n        {\n          \"name\": \"optimizer\",\n          \"value\": \"adam\"\n        },\n        {\n          \"name\": \"batch size\",\n          \"value\": 4\n        },\n        {\n          \"name\": \"epochs\",\n          \"value\": 5\n        },\n        {\n          \"name\": \"embedding size\",\n          \"value\": 300\n        },\n        {\n          \"name\": \"decoder dropout\",\n          \"value\": 0.3\n        }\n      ],\n      \"hyper-parameter-selection\": \"grid search\",\n      \"search-tuned-hyper-parameters\": [\n        \"number of gcn layers\",\n        \"dropout\",\n        \"learning rate\"\n      ],\n      \"evaluation-details\": \"Evaluated with beam size 5.\\nUse top-1 to compute accuracy\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"accuracy\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"BLEU-1\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"BLEU-2\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"BLEU-3\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"BLEU-4\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        }\n      ]\n    }\n  },\n  \"datasets\": {\n    \"dataset\": {\n      \"name\": \"n/a\",\n      \"description\": \"Dataset of bug fixes where this is only one \\nAST node different between the buggy and fixed versions.\\nCommits were identified using the keywords \\\"bug\\\", \\\"fix\\\",\\nand \\\"resolve\\\".\",\n      \"source\": [\n        \"Open source JavaScript projects on GitHub\"\n      ],\n      \"labelling\": \"Automated based on file difference\",\n      \"size\": 119975,\n      \"is-pre-existing\": false\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"seqgraph\",\n      \"model\": \"model\",\n      \"task\": \"fixing\",\n      \"training\": \"training\",\n      \"dataset\": \"dataset\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fag\",\n      \"model\": \"model\",\n      \"task\": \"fixing\",\n      \"training\": \"training\",\n      \"dataset\": \"dataset\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 209,\n  \"pdf-id\": 279,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST with additional data- and control flow edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"smart contract\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Next Node\",\n          \"details\": \"Added if two nodes are adjacent in the depth first traversal of the AST\"\n        },\n        {\n          \"name\": \"Next Token\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Condition True\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Condition False\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"While Exec\",\n          \"details\": \"Connect root of condition subtree to root of body subtree\"\n        },\n        {\n          \"name\": \"For Exec\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Last Read\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Last Write\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Next Use\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Unclear what exactly is used as feature. \\nSeems to be token for leaf nodes, nonterminal for non-leaf nodes.\\nPaper does not mention specific features.\\n\\nUnclear how feature are encoded.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) GraphSAGE\\n2) SAGPool\\n3) GraphSAGE\\n4) SAGPool\\n5) GraphSAGE\\n6) SAGPool\\n7) Outputs of (2), (4), (6) are aggregated using unspecified readout function, and summed together \\n8) MLP\\n9) Softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Given a graph, classify it as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given a graph, classify it as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection in Smart Contracts\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 87,\n  \"pdf-id\": 120,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"A network with a learnable embedding layer and 5 FNN layers is used\\nto learn node embeddings. \\nGiven the parent node type and the top-4 immediate child node types,\\npredict the node type itself.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gcn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN Layer (3x)\\nPooling Layer (concatenation of max and average pooling)\\nFNN Layer (2x)\"\n      }\n    },\n    \"graphsage\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GraphSAGE Layer (3x)\\nPooling Layer (concatenation of max and average pooling)\\nFNN Layer (2x)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable/not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample as vulnerable/not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"graphsage\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 32,\n  \"pdf-id\": 45,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Computed using word embeddings\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"mtn-a\": {\n      \"type\": {\n        \"name\": \"MTN-a\",\n        \"architecture\": \"Based on Child-sum Tree-LSTM, but instead of summing all the children in the first step\\n(computing \\\\tilde{h}_j, use a custom child-order aware function\\nSome examples: tanh activation for a fixed number of child nodes, normal LSTM for a nested block, etc.\\n\\nThis means that every node type has a special, dedicated type of MTN unit.\\n\\nAll MTN unit types share the W, U, and b parameters.\"\n      }\n    },\n    \"mtn-b\": {\n      \"type\": {\n        \"name\": \"MNT-b\",\n        \"architecture\": \"Same as MTN-a, but the parameters W, U, b are _not_ shared between different LSTM types.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"program-classification\": {\n      \"training-objective\": \"Given a program, classify what it is doing\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given a program, classify what it is doing\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Program Classification\",\n      \"supervision\": \"Supervised\"\n    },\n    \"clone-detection\": {\n      \"training-objective\": \"Given two programs, determine if they are functionally identical\",\n      \"training-granularity\": \"Graph Classification (?)\",\n      \"working-objective\": \"Given two programs, determine if they are functionally identical\",\n      \"working-granularity\": \"Graph Classification (?)\",\n      \"application\": \"Clone Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"mtn-a\",\n      \"task\": \"program-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"mtn-a\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"mtn-b\",\n      \"task\": \"program-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"mtn-b\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 92,\n  \"pdf-id\": 127,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code (path/commit)\",\n          \"details\": \"Patch is split up into pre- and post- change function. An AST is made for both.\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Paths from start to end nodes are constructed,\\nwhere the path must always pass through the root of \\nthe changed (added/deleted) subtree.\\n\\nTwo types of paths:\\n1) within change; start and end are both leaf nodes in the \\n    changed subtree\\n2) within context: start is a leaf node in the changed subtree,\\n    end is a leaf node in the unchanged remainder of the tree.\\n\\nBoth path types are randomly sampled in a 1:1 ratio.\"\n    },\n    \"dependency-parse-graph\": {\n      \"name\": \"Dependency Parse Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Commit Message\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Token\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Dependency Edge\",\n          \"details\": \"Denotes the types of dependencies between tokens (words) (e.g. adjective modifies)\"\n        },\n        {\n          \"name\": \"Neigh Edge\",\n          \"details\": \"Connects the last token in a sentence to the first token in the next sentence\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Model with two input paths: \\n1) Paths (AST based features)\\n  i) Node types are encoded using a learnable embedding \\n      layer, then passed through a bidirectional LSTM.\\n  ii) The tokens of the start and end nodes are computed through \\n      through tokenization, embedded through a learnable embedding\\n      layer, and summed up.\\n  iii) Path and token features are concatenated \\n  iv) FNN\\n  v) Normalisation\\n\\n2) Dependency Parse Graph \\n  i) Tokens embedded using learnable embedding layer\\n  ii) GGNN\\n  iii) FNN\\n  iv) Maxpool\\n\\nStreams combined through concatenation\\nFNN\\nSigmoid\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vul-fix-detection\": {\n      \"training-objective\": \"Classify patch as fixing or not vulnerability fixing\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify patch as fixing or not vulnerability fixing\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Identify \\\"silent\\\" patches fixing vulnerabilities\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + dependency-parse-graph\",\n      \"model\": \"model\",\n      \"task\": \"vul-fix-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 103,\n  \"pdf-id\": 139,\n  \"graphs\": {\n    \"spg\": {\n      \"name\": \"Slice Property Graph\",\n      \"description\": \"Similar to code property graph, but with program slicing.\\n\\nFirst, AST is used to detect SyVC's. \\nThese are used as a basis for slicing in the PDG.\\nNext, a graph with data, control, and function call dependence edges is created.\\n\\nNote: one function may have multiple slices.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Also function focussed, but not exclusively\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Dependence Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependence Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Function Call Dependence Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Statements in nodes are tokenized, encoded using word2vec,\\nand enhanced with positional labels. \\n\\nNode types are one-hot encoded.\",\n      \"edge-features\": \"Edges are labelled according to type (d \\\\in D)\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"Three subgraphs are created by considering different edge types\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"First, tokens are put through a multi-head attention mechanism to \\ncome up with node embeddings for the statements.\\n\\nThese are concatenated with the node type, and passed through a FNN layer.\\n\\nThe four graphs (main SPG and 3 subgraphs) are passed through multiple (L) rounds of R-GCN.\\n\\nL+1 node embeddings (including initial) are concatenated for every node _per graph separately_.\\n\\nPooling _separately per graph_ according to attention mechanism:\\n  1) z_i^G = \\\\sigma\\\\left(\\\\sum_{d in D} \\\\sum_{v_j \\\\in N_j^d} \\\\frac{1}{|N_j^d| h_j^G\\\\Theta_d^G + h_i^G\\\\Theta_o^G\\\\right)\\n    (where $\\\\Theta_d^G$ and $\\\\Theta_o^G$ are learnable parameters)\\n  2) a_i^G = softmax(z_i^G)\\n  3) S_G = \\\\sum_{v \\\\ in V_G} a_i^G h_i^G\\n\\nSubgraphs are pooled through attention mechanism:\\n  1) r_{sub} = S_{sub}^T W_r S_{SPG}\\n    (with W_r a learnable matrix)\\n  2) a_{sub} = softmax(r_{sub})\\n  3) S_{SA} = \\\\sum_{sub} a_{sub} S_{sub}\\n\\nConcatenate S_G and S_{SA} \\nFNN \\nSoftmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"slice-level-vulnerability-detection\": {\n      \"training-objective\": \"Classify sample (slice) as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample (slice) as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection (slice level)\",\n      \"supervision\": \"Supervised\"\n    },\n    \"function-level-vulnerability-detection\": {\n      \"training-objective\": \"Classify sample (slice) as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample (slice) as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection (function level)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"spg\",\n      \"model\": \"model\",\n      \"task\": \"slice-level-vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"spg\",\n      \"model\": \"model\",\n      \"task\": \"function-level-vulnerability-detection\",\n      \"comments\": \"Training is the same as for slice-level-vulnerability-detection.\\nIt is just a matter of how predictions are used.\\nA function is considered vulnerable if at least one of its \\nslices was predicted as vulnerable.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 15,\n  \"pdf-id\": 25,\n  \"graphs\": {\n    \"code-meta-model\": {\n      \"name\": \"n/a\",\n      \"description\": \"Based on a meta model for source code and design patterns defined in \\n\\nMario Luca Bernardi, Marta Cimitile, and Giuseppe Di Lucca. 2014. Design\\npattern detection using a DSL-driven graph matching approach. Journal of\\nSoftware: Evolution and Process 26, 12 (2014), 1233\\u20131266. https://doi.org/\\n10.1002/smr.1674\\n\\nThis describes graphs for source code.\\n\\nFor source code specifically, k-hop neighbourhoods are extracted from the\\nsystem (metamodel) graph.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Nodes from meta-model\\n\\nGraphs are centered around pivotal nodes (classes, interfaces, methods);\\nother types of nodes are thus ignored.\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Edges from meta-model\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a (unclear how node embeddings are initialised)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"pattern-meta-model\": {\n      \"name\": \"n/a\",\n      \"description\": \"Based on a meta model for source code and design patterns defined in \\n\\nMario Luca Bernardi, Marta Cimitile, and Giuseppe Di Lucca. 2014. Design\\npattern detection using a DSL-driven graph matching approach. Journal of\\nSoftware: Evolution and Process 26, 12 (2014), 1233\\u20131266. https://doi.org/\\n10.1002/smr.1674\\n\\nThis describes graphs for design patterns\",\n      \"artefacts\": [\n        {\n          \"name\": \"Design Pattern Specifications\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Nodes from meta-model.\\n\\nGraphs are centered around pivotal nodes (classes, interfaces, methods);\\nother types of nodes are thus ignored.\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Edges from meta-model\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a (unclear how node embeddings are initialised)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Exact model not specified, but some encoder/decoder setup\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"design-pattern-mining\": {\n      \"training-objective\": \"Embed graphs such that subgraphs are embedded to the lower-left of their parents\",\n      \"training-granularity\": \"Subgraph matching\",\n      \"working-objective\": \"Embed graphs such that subgraphs are embedded to the lower-left of their parents\",\n      \"working-granularity\": \"Subgraph matching\",\n      \"application\": \"Design pattern mining\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-meta-model + pattern-meta-model\",\n      \"model\": \"model\",\n      \"task\": \"design-pattern-mining\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 55,\n  \"pdf-id\": 78,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"methods\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Continuous Binary Tree\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"Obtained by taking the continuous binary tree \\nrepresentation of the AST (root), and passing\\nit to a VAE.\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"log-reg\": {\n      \"type\": {\n        \"name\": \"Logistic Regression\",\n        \"architecture\": \"n/a\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"smell-detection\": {\n      \"training-objective\": \"Classify code (graph) as smell/not smell\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify code (graph) as smell/not smell\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Smell Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"log-reg\",\n      \"task\": \"smell-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 33,\n  \"pdf-id\": 46,\n  \"graphs\": {\n    \"augmented-ast\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST with additional control and data flow edges. Note that all edges are undirected\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Next token\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Computed From\",\n          \"details\": \"e.g. assigment target to expression\"\n        },\n        {\n          \"name\": \"Guarded By\",\n          \"details\": \"Edge from each variable in an if-block to the condition of the if-block\"\n        },\n        {\n          \"name\": \"Jump\",\n          \"details\": \"Edge between variables with control dependencies\"\n        },\n        {\n          \"name\": \"Last Use\",\n          \"details\": \"Edge between uses of the same variable\"\n        },\n        {\n          \"name\": \"Last Lexical Use\",\n          \"details\": \"Edge between uses of variable with the same name in different branches of a conditional\"\n        }\n      ],\n      \"vertex-features\": \"Vertex payload (instruction, token, node type) is encoded using Word2Vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"For every edge type, a separate adjacency matrix is created, where \\nback-edges are added for every edge (i.e. the adjacency matrix is symmetric).\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"cdfg\": {\n      \"name\": \"CDFG (Control-Data Flow Graph)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"IR instructions and types\",\n          \"details\": \"Variable names are replaced with their type\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Sequential IR flow\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data flow\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control flow\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Vertex payload (instruction, token, node type) is encoded using Word2Vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"For every edge type, a separate adjacency matrix is created, where \\nback-edges are added for every edge (i.e. the adjacency matrix is symmetric).\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"poem-gnn\": {\n      \"type\": {\n        \"name\": \"Poem-GNN\",\n        \"architecture\": \"Node embeddings updated according to\\nh_v^{t + 1}) = \\\\sigma\\\\left(MPL_1\\\\left(\\\\right\\\\sum_{\\\\ell}\\\\sum_{(u,v) \\\\in A_{\\\\ell}} MPL_{\\\\ell}(h_u^t)\\\\right)\\n\\nWhere $\\\\ell$ sums over all relation graphs.\\n\\nFinal global representation given by \\n\\n\\\\text{CONCAT}\\\\left(\\\\sum_{i = 1}^m \\\\left(h_{v,i}^t \\\\mid v \\\\in G_i \\\\right) \\\\mid t = 0, 1, \\\\hdots, n \\\\right)\\n\\n$m$ is the number of relation graphs, $n$ the number of neighbourhood aggregation iterations.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"heterogeneous-mapping\": {\n      \"training-objective\": \"Classify whether program should run on or gpu\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify whether program should run on or gpu\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Determine if OpenCL kernel should run on CPU or GPU\",\n      \"supervision\": \"Supervised\"\n    },\n    \"thread-coarsening\": {\n      \"training-objective\": \"For a given program, output the thread coarsening factor (discrete number from set of options)\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"For a given program, output the thread coarsening factor (discrete number from set of options)\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Determine thread coarsening factor in OpenCL\",\n      \"supervision\": \"supervised\"\n    },\n    \"loop-vectorisation\": {\n      \"training-objective\": \"Pick best parameter pair from a set of options\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Pick best parameter pair from a set of options\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Determine parameters (vectorisation factor, interleaving factor) for loop vectorisation\",\n      \"supervision\": \"Supervised\"\n    },\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify input graph as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify input graph as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"augmented-ast + cdfg\",\n      \"model\": \"poem-gnn\",\n      \"task\": \"heterogeneous-mapping\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"augmented-ast + cdfg\",\n      \"model\": \"poem-gnn\",\n      \"task\": \"thread-coarsening\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"augmented-ast + cdfg\",\n      \"model\": \"poem-gnn\",\n      \"task\": \"loop-vectorisation\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"augmented-ast + cdfg\",\n      \"model\": \"poem-gnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": [\n    \"Generic model which is trained on downstream tasks\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 68,\n  \"pdf-id\": 95,\n  \"graphs\": {\n    \"aast\": {\n      \"name\": \"\\\\alpha AST (Annotated AST)\",\n      \"description\": \"AST representing a commit, i.e. a change from old to new code.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code (commit)\",\n          \"details\": null\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Nodes from both the AST of the old and the new code are present.\\n\\nNodes are annotated with \\\"unchanged\\\", \\\"added\\\", or \\\"deleted\\\"\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"Edges are annotated with \\\"unchanged\\\", \\\"added\\\", or \\\"deleted\\\"\"\n        }\n      ],\n      \"vertex-features\": \"Node content embedded using word2vec.\\nChange action (unchanged/added/deleted) is one hot encoded \\n\\ncontent and action embeddings are concatenated.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"network\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GAT Layers \\nPool by computing average of all node representations \\nMLP\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"fix-detection\": {\n      \"training-objective\": \"Classify given commit as vulnerability fixing or non-fixing\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify given commit as vulnerability fixing or non-fixing\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Identifying commit which fix vulnerabilities\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"aast\",\n      \"model\": \"network\",\n      \"task\": \"fix-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 171,\n  \"pdf-id\": 224,\n  \"graphs\": {\n    \"dfg\": {\n      \"name\": \"DFG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Temporary Operand\",\n          \"details\": \"temporary \\\"variables\\\" that only exists in program execution\"\n        },\n        {\n          \"name\": \"Non-temporary Operand\",\n          \"details\": \"Variable/constant that explicitly exists in code\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Operation Edge\",\n          \"details\": \"Data flow for operators\"\n        },\n        {\n          \"name\": \"Function Edge\",\n          \"details\": \"data flow for arguments and return  values\"\n        }\n      ],\n      \"vertex-features\": \"Operation/operand types are one-hot encoded\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"slightly altered compared to normal; different types of nodes\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Operation in Source code\",\n          \"details\": \"including standard operations, function calls, returns\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"PosNext\",\n          \"details\": \"Conditional Jumps in loops or branches.\"\n        },\n        {\n          \"name\": \"NegNext\",\n          \"details\": \"Conditional Jumps in loops or branches.\"\n        },\n        {\n          \"name\": \"IterJump\",\n          \"details\": \"Connect end of loop to begin\"\n        },\n        {\n          \"name\": \"CallNext\",\n          \"details\": \"From function call operation to first operation in called function\"\n        },\n        {\n          \"name\": \"ReturnNext\",\n          \"details\": \"From last operation in called function to operations right after function call\"\n        },\n        {\n          \"name\": \"Next\",\n          \"details\": \"Denote most common execution order\"\n        }\n      ],\n      \"vertex-features\": \"Operation/operand types are one-hot encoded\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"read-write-graph\": {\n      \"name\": \"Read-write Graph (RWG)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Operand\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Operation\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Read\",\n          \"details\": \"From operand to operations; operations required to compute the operand\"\n        },\n        {\n          \"name\": \"Write\",\n          \"details\": \"From operations to operand; variables receiving the operation result\"\n        }\n      ],\n      \"vertex-features\": \"Operation/operand types are one-hot encoded\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"combined-graph\": {\n      \"name\": \"Combination of DFG, CFG and RWG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Temporary Operand\",\n          \"details\": \"temporary \\\"variables\\\" that only exists in program execution\"\n        },\n        {\n          \"name\": \"Non-temporary Operand\",\n          \"details\": \"Variable/constant that explicitly exists in code\"\n        },\n        {\n          \"name\": \"Operation in Source code\",\n          \"details\": \"including standard operations, function calls, returns\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Operation Edge\",\n          \"details\": \"Data flow for operators\"\n        },\n        {\n          \"name\": \"Function Edge\",\n          \"details\": \"data flow for arguments and return  values\"\n        },\n        {\n          \"name\": \"PosNext\",\n          \"details\": \"Conditional Jumps in loops or branches.\"\n        },\n        {\n          \"name\": \"NegNext\",\n          \"details\": \"Conditional Jumps in loops or branches.\"\n        },\n        {\n          \"name\": \"IterJump\",\n          \"details\": \"Connect end of loop to begin\"\n        },\n        {\n          \"name\": \"CallNext\",\n          \"details\": \"From function call operation to first operation in called function\"\n        },\n        {\n          \"name\": \"ReturnNext\",\n          \"details\": \"From last operation in called function to operations right after function call\"\n        },\n        {\n          \"name\": \"Next\",\n          \"details\": \"Denote most common execution order\"\n        },\n        {\n          \"name\": \"Read\",\n          \"details\": \"From operand to operations; operations required to compute the operand\"\n        },\n        {\n          \"name\": \"Write\",\n          \"details\": \"From operations to operand; variables receiving the operation result\"\n        }\n      ],\n      \"vertex-features\": \"Operation/operand types are one-hot encoded\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) For each graph:\\n  i) GGNN (edge-type specific message passing function)  \\n  ii) Max pooling over node representations \\n2) Concatenate the four graph representations\\n3) [downstream tasks] MLP (2 layers) w/ some activation (e.g. softmax, sigmoid)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"algorithmic-problem-classification\": {\n      \"training-objective\": \"Classify given program into a fixed set of types\",\n      \"training-granularity\": \"Multi-class Classification (of multiple graphs)\",\n      \"working-objective\": \"Classify given program into a fixed set of types\",\n      \"working-granularity\": \"Multi-class Classification (of multiple graphs)\",\n      \"application\": \"Algorithm Problem Classification (Code Classification)\",\n      \"supervision\": \"Supervised\"\n    },\n    \"algorithmic-problem-classification-2\": {\n      \"training-objective\": \"Outputs which algorithms are used in a program\",\n      \"training-granularity\": \"Multi-label Classification (of multiple graphs)\",\n      \"working-objective\": \"Outputs which algorithms are used in a program\",\n      \"working-granularity\": \"Multi-label Classification (of multiple graphs)\",\n      \"application\": \"Algorithm Problem Classification (Code Classification)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"dfg + cfg + read-write-graph + combined-graph\",\n      \"model\": \"mode\",\n      \"task\": \"algorithmic-problem-classification + algorithmic-problem-classification-2\",\n      \"comments\": \"The model is meant as a general setup, with program classification being \\nused as an example downstream task.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 183,\n  \"pdf-id\": 238,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast (some node types are removed)\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"not content (embedded by model)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Graph2Seq w/ beam search (not greedy search)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"program-repair\": {\n      \"training-objective\": \"Given a buggy method, generate a fixed version\",\n      \"training-granularity\": \"graph to sequence\",\n      \"working-objective\": \"Given a buggy method, generate a fixed version\",\n      \"working-granularity\": \"graph to sequence\",\n      \"application\": \"Automated program repair\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"program-repair\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 34,\n  \"pdf-id\": 47,\n  \"graphs\": {\n    \"augmented-ast\": {\n      \"name\": \"n/a\",\n      \"description\": \"Combination of AST, PDF, and CFG\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Nodes\",\n          \"details\": \"Some degree of abstraction is applied to the node labels. \\nSpecifically, concrete identifiers are replaced by abstract ones.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"Edge from statement to every possible next statement\"\n        },\n        {\n          \"name\": \"Data Dependence Edge\",\n          \"details\": \"Assignment points to all variables usages\"\n        },\n        {\n          \"name\": \"Control Dependence Edge\",\n          \"details\": \"Edge from one statement which is affected by another (e.g. increment in loop body)\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"A graph is represented using a bag of subgraphs feature.\\n\\nRoughly, every subgraph of size i is assigned a label. \\nThe feature vector is generated using some control parameter h;\\nthe final feature vector consists of a \\\"vector\\\" of all sets of subgraphs \\nof size 1, 2, ..., h.\\n\\n(Note: slightly inaccurate for simplicity))\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"svm\": {\n      \"type\": {\n        \"name\": \"SVM\",\n        \"architecture\": \"SVM with a kernel function based on Generalised Jaccard Similarity:\\n\\nK(G_1, G_2) = \\\\frac{1}{h + 1}\\\\sum_{i = 0}^h GJac(B^i_{G_1}, B^i_{G_2})\\n\\nHere, B^{i}_{G} is the set of subgraphs of size i in G.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"binary-recommendation\": {\n      \"training-objective\": \"Given a code representation, predict whether the fixed verification tool is appropriate for the given code\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given a code representation, predict whether the fixed verification tool is appropriate for the given code\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"verification tool recommendation (For a fixed tool)\",\n      \"supervision\": \"Supervised\"\n    },\n    \"ranked-recommendation\": {\n      \"training-objective\": \"Pairwise ranking; determine which tool is more suitable for the given code\",\n      \"training-granularity\": \"Pairwise ranking of graphs (Binary Graph Classification)\",\n      \"working-objective\": \"Pairwise ranking; determine which tool is more suitable for the given code\",\n      \"working-granularity\": \"Pairwise ranking of graphs (Binary Graph Classification)\",\n      \"application\": \"verification tool recommendation ranking. \\n\\nOne classifier for every pair of tools; must say whether \\nthe first tool is better than the second one for the given code.\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"augmented-ast\",\n      \"model\": \"svm\",\n      \"task\": \"binary-recommendation\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"augmented-ast\",\n      \"model\": \"svm\",\n      \"task\": \"ranked-recommendation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 99,\n  \"pdf-id\": 135,\n  \"graphs\": {\n    \"unique-token-focussed-construction-codebert\": {\n      \"name\": \"Unique Token Focussed Construction\",\n      \"description\": \"Each unique token has a node,\\nand two tokens are connected if they\\nco-occur in a sliding window of size v.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Token\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Co-occurrence Edge\",\n          \"details\": \"within a sliding window of size v\"\n        }\n      ],\n      \"vertex-features\": \"Tokens embedded using token embedding layer of CodeBERT\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified (adjacency matrix?)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": null\n    },\n    \"unique-token-focussed-construction-grapcodebert\": {\n      \"name\": \"Unique Token Focussed Construction\",\n      \"description\": \"Each unique token has a node,\\nand two tokens are connected if they\\nco-occur in a sliding window of size v.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Token\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Co-occurrence Edge\",\n          \"details\": \"within a sliding window of size v\"\n        }\n      ],\n      \"vertex-features\": \"Tokens embedded using token embedding layer of GrapCodeBERT\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified (adjacency matrix?)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": null\n    },\n    \"index-focussed-construction-codebert\": {\n      \"name\": \"Index-Focussed Construction\",\n      \"description\": \"All tokens are represented as a sequence,\\nand two nodes are connected if they occur within\\na sliding window of size v\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Token\",\n          \"details\": \"Not necessarily unique\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Co-occurrence Edge\",\n          \"details\": \"within a sliding window of size v\"\n        }\n      ],\n      \"vertex-features\": \"Tokens embedded using token embedding layer of CodeBERT\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified (adjacency matrix?)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": null\n    },\n    \"index-focussed-construction-grapcodebert\": {\n      \"name\": \"Index-Focussed Construction\",\n      \"description\": \"All tokens are represented as a sequence,\\nand two nodes are connected if they occur within\\na sliding window of size v\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Token\",\n          \"details\": \"Not necessarily unique\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Co-occurrence Edge\",\n          \"details\": \"within a sliding window of size v\"\n        }\n      ],\n      \"vertex-features\": \"Tokens embedded using token embedding layer of GrapCodeBERT\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified (adjacency matrix?)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": null\n    }\n  },\n  \"models\": {\n    \"gcn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN w/ residual connections \\nPooling:\\n  i) Soft attention mechanism\\n    e_v = \\\\sigma(w^Th_v + b) \\\\cdot \\\\phi(Wh_v + b)\\n  ii) Pooling through one of the following (all combinations tried)\\n    e_g = \\\\sum_{v \\\\in V} e_v + MaxPool(V)\\n    e_g = \\\\sum_{v \\\\in V} e_v \\\\cdot MaxPool(V)\\n    e_g = \\\\sum_{v \\\\in V} e_v \\\\mid\\\\mid MaxPool(V)\\nsoftmax\"\n      }\n    },\n    \"ggnn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GGNN\\nPooling:\\n  i) Soft attention mechanism\\n    e_v = \\\\sigma(w^Th_v + b) \\\\cdot \\\\phi(Wh_v + b)\\n  ii) Pooling through one of the following (all combinations tried)\\n    e_g = \\\\sum_{v \\\\in V} e_v + MaxPool(V)\\n    e_g = \\\\sum_{v \\\\in V} e_v \\\\cdot MaxPool(V)\\n    e_g = \\\\sum_{v \\\\in V} e_v \\\\mid\\\\mid MaxPool(V)\\nsoftmax \"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"unique-token-focussed-construction-codebert\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"unique-token-focussed-construction-graphcodebert\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"index-focussed-construction-codebert\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"index-focussed-construction-graphcodebert\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"unique-token-focussed-construction-codebert\",\n      \"model\": \"ggnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"unique-token-focussed-construction-graphcodebert\",\n      \"model\": \"ggnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"index-focussed-construction-codebert\",\n      \"model\": \"ggnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"index-focussed-construction-graphcodebert\",\n      \"model\": \"ggnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 182,\n  \"pdf-id\": 237,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": null,\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Various matrices are derived from the AST:\\n  1) Shortest path length; M_{ij} denotes the shortest path length from node i to node j (assuming undirected nodes)\\n  2) Ancestor distance; D_{ij} denotes the signed distance between \\\"familial\\\" nodes i and node j in the ast\\n  3) Sibling Distance; D_{ij} denotes the signed distance between sibling nodes i and node j in the ast\\n  4) Personalised PageRank scores \\nAll matrices are \\\"encoded\\\" by applying sinusoidal encoding to them. \\n\\nEvery token in the input is associated with an AST node (for the positional encoding).\\nAST node type is added to the token.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"modified transformer (encoder/decoder) architecture w/ pointer network\",\n        \"shortest path length, ancestor distance, sibling distance, personalised pagerank score matrices are used for positional encoding\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary of the code.\",\n      \"training-granularity\": \"x-to-sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary of the code.\",\n      \"working-granularity\": \"x-to-sequence\",\n      \"application\": \"Code summarization.\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 59,\n  \"pdf-id\": 85,\n  \"graphs\": {\n    \"code-property-graph\": {\n      \"name\": \"Code Property Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Node type one-hot encoded\\nStatement fragments/tokens encoded using word2vec \\none-hot and word2vec embeddings are concatenated\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"network\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Federated Learning Setup; 1) clients receive initial weights from server 2) clients use own data to update weights; send updated weights to server 3) server aggregates weights from all clients and updates weights; sends to clients 4) goto 2\\nClient network architecture; Jump-structured GAT Let x_{JG} = sum of the concatenated node features from every GAT layer out = MaxPool(Conv1D(x_{JG})) FNN Layer\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Given a graph, classify it as vulnerable or non-vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given a graph, classify it as vulnerable or non-vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection without disclosing private dataset to other parties\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"network\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 77,\n  \"pdf-id\": 107,\n  \"graphs\": {\n    \"patch-cpg\": {\n      \"name\": \"PatchCPG\",\n      \"description\": \"A variant of the code property graph for representing patches\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Constructed based on commits, but also uses full source code.\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"AST Nodes are obtained by taking files which were modified in the commit,\\nand excluding all unchanged functions (as a means to include global variables\\nin the resulting graphs).\\n\\nThe amount of nodes is further reduced through program slicing,\\nthough this is only done following data- and control edges.\\n\\nNodes are marked as \\\"added\\\", \\\"deleted\\\", or \\\"context\\\"\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"Edges are marked as \\\"added\\\", \\\"deleted\\\", or \\\"context\\\"\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"Edges are marked as \\\"added\\\", \\\"deleted\\\", or \\\"context\\\"\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"Edges are marked as \\\"added\\\", \\\"deleted\\\", or \\\"context\\\"\"\n        }\n      ],\n      \"vertex-features\": \"1) Number of characters in the node payload \\n2) version (added/deleted/context)\\n3) number of function calls \\n4) number of variables \\n5) number of number (constants)\\n6) number of strings\\n7) number of pointers \\n8) number of arrays\\n9) number of NULL identifiers \\n10) Boolean indicating if the node if a conditional\\n11) Boolean indicating if the node if a loop\\n12) Boolean indicating if the node if a jump statement \\n13) Number of arithmetic operators\\n14) Number of relational (comparison) operators\\n15) Number of logical operators\\n16) Number of bitwise operators\\n17) Boolean indicating if the node contains the API name of memory operations\\n18) Boolean indicating if the node contains the API name of string operations\\n19) Boolean indicating if the node contains the API name of lock operations\\n20) Boolean indicating if the node contains the API name of system operations\",\n      \"edge-features\": \"Edge type is one-hot encoded \\nversion info encoded according to \\\"added\\\" -> [0, 1], \\\"deleted\\\" -> [1, 0], \\\"context\\\" -> [1, 1]\\nThe two vectors are concatenated\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Multi-attributed graph convolutional layers (3)\\n  This means that 5 subgraphs are created, where for subgraph i, \\n  the i-th edge feature is used to determine if that edge is \\n  present in subgraph i.\\nMean and Max pooling to obtain two graph embedding vectors \\nconcatenate graph embedding vectors \\ndropout layer \\nMLP\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"patch-detection\": {\n      \"training-objective\": \"Classify patch as security fixing/not fixing\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify patch as security fixing/not fixing\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"automatically detect patches/commits introducing security fixes\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"patch-cpg\",\n      \"model\": \"model\",\n      \"task\": \"patch-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 205,\n  \"pdf-id\": 275,\n  \"graphs\": {\n    \"fa-ast\": {\n      \"name\": \"FA-AST (Flow-augmented AST)\",\n      \"description\": \"AST with additional edges (all edges undirected)\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Child Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"AST Parent Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Next Sibling Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Next Token Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Next Use Edge\",\n          \"details\": \"Connect variable to its next use\"\n        },\n        {\n          \"name\": \"If Edge\",\n          \"details\": \"Connect if statement to its condition, ThenStatement, and ElseStatement\"\n        },\n        {\n          \"name\": \"While Edge\",\n          \"details\": \"Connect while statement to its condition and body\"\n        },\n        {\n          \"name\": \"For Edge\",\n          \"details\": \"Connect for statement to its control, and body\"\n        },\n        {\n          \"name\": \"Sequential Execution Edge\",\n          \"details\": \"Sequential execution between statements _in a code block_\"\n        }\n      ],\n      \"vertex-features\": \"Unclear what exactly is used. Seems to be at least the actual token payload for leaf nodes.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gnn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Embedding Layer\\nGGNN (no  edge type specific stuff)\\nReadout using: h_G = MLP(\\\\sum_(i \\\\in V) \\\\sigma(MLP_{gate}(h_i^T)) \\\\odot MLP(h_i^T))))\\nCosine similarity of the two input programs\"\n      }\n    },\n    \"gmn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Embedding Layer \\nGraph Matching Network \\nReadout using: h_G = MLP(\\\\sum_(i \\\\in V) \\\\sigma(MLP_{gate}(h_i^T)) \\\\odot MLP(h_i^T))))\\nCosine similarity of the two input programs\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"clone-detection\": {\n      \"training-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"training-granularity\": \"Graph Classification (?)\",\n      \"working-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"working-granularity\": \"Graph Classification (?)\",\n      \"application\": \"Code Clone Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"fa-ast\",\n      \"model\": \"gnn\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fa-ast\",\n      \"model\": \"gmn\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 73,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"code-property-graph\": {\n      \"name\": \"Code Property Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Node type is encoded as a scalar \\nTokens in a node are embedded using word2vec; vectors per token are averaged \\nnode type and payload embedding are concatenated\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix (?)\",\n      \"graph-features\": \"Graph is rendered as an image.\\nEach node has sa different colour,\\nand has the line number of its corresponding statement as its content. \\nDifferent edge types have different colours and line types.\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"multi-modal-model\": {\n      \"type\": {\n        \"name\": null,\n        \"architecture\": \"1) Global Image Encoder SwinV2, followed by an FNN layer 2) Positional Encoder Use character recognition to determine node locations in terms of bounding boxes FNN layer 3) Code Encoder Each statement (node content) is encoded using pre-trained UniXcoder 4) Multi-model Graph Encoder Graph passed to GAT network with encoded code (3) as node embeddings FNN layer Node embeddings are combined with bounding boxes (2), and a new graph is constructed, where the presence of an edge R_{ij} between nodes i and j is computed as f(v_i)g(v_j), where f and g are FNN layers, and v_i and v_j are node embeddings (including bounding box information). New graph is passed through GCN Compute average of all node embeddings\\nConcatenate outputs of (1), (3), and (4) (NOT (2)) FNN w/ softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify code sample as vulnerable/not vulnerable\",\n      \"training-granularity\": \"Graph Classification (ish)\",\n      \"working-objective\": \"Classify code sample as vulnerable/not vulnerable\",\n      \"working-granularity\": \"Graph Classification (ish)\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"multi-modal-model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 164,\n  \"pdf-id\": 215,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"method\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Tokens are split into subtokens\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Child Edge\",\n          \"details\": \"Regular AST Edge\"\n        },\n        {\n          \"name\": \"Next Token Edge\",\n          \"details\": \"NCS\"\n        },\n        {\n          \"name\": \"Subtoken Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Last Lexical Use Edge\",\n          \"details\": \"Connect identifiers to their most recent use\"\n        }\n      ],\n      \"vertex-features\": \"Not specified how initial node features are computed\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"keyword-extractor\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) GGNN (edge-type dependent f for messages)\\n2) Weighted sum of node embeddings. \\n    r_g = \\\\sum_{v \\\\in V} \\\\sigma(W_i[h_v, X_v]) \\\\cdot (W_j h_v)\\n    (X_v: initial node features, h_v: node representation from GGNN)\\n3) Output per node: y_v = \\\\sigma(W_e h_v + b_e)\"\n      }\n    },\n    \"decoder\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Bidirectional LSTM network which uses the copy mechanism from transformers.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"keyword-extraction\": {\n      \"training-objective\": \"Identify overlapping tokens between method name and method body\\n(classify each node as \\\"overlapping\\\" or \\\"not overlapping\\\")\",\n      \"training-granularity\": \"Node Classification\",\n      \"working-objective\": \"Identify overlapping tokens between method name and method body\\n(classify each node as \\\"overlapping\\\" or \\\"not overlapping\\\")\",\n      \"working-granularity\": \"Node Classification\",\n      \"application\": \"Keyword Extraction (for user in other classifier)\",\n      \"supervision\": \"Supervised\"\n    },\n    \"method-name-generation\": {\n      \"training-objective\": \"Generate a name for the given method\",\n      \"training-granularity\": \"Neural Code Translation\",\n      \"working-objective\": \"Generate a name for the given method\",\n      \"working-granularity\": \"Neural Code Translation\",\n      \"application\": \"Method Name Generation\",\n      \"supervision\": \"Supervised (Self-supervised)\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"keyword-extractor + decoder\",\n      \"task\": \"keyword-extraction + method-name-generation\",\n      \"comments\": \"Use the keywords extracted to aid the method name generation.\"\n    }\n  ],\n  \"comments\": [\n    \"The r_g in the keyword extractor is never used; I believe that is in line with the source paper they got the method from.\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 28,\n  \"pdf-id\": 41,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"recursive-vae\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"One variational auto-encoder for every type of AST node.\\nEmbeddings are computed recursively; first leave nodes, then their parents.\\nLeaf nodes have no payload, so the model only learns the structure.\\nBoth the encoder and decoder are single layer FNN models, with tanh and sigmoidal activation respectively.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vae-training\": {\n      \"training-objective\": \"Minimise reconstruction loss\",\n      \"training-granularity\": \"Graph representation learning\",\n      \"working-objective\": \"Graph encoding\",\n      \"working-granularity\": \"Graph encoding\",\n      \"application\": \"Graph encoding\",\n      \"supervision\": \"self-supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"recursive-vae\",\n      \"task\": \"vae-training\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 6,\n  \"pdf-id\": 11,\n  \"graphs\": {\n    \"code-property-graph\": {\n      \"name\": \"Code Property Graph\",\n      \"description\": \"AST augmented with control and data flow information.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code (arbitrary snippets)\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"Points from one statement node to every other statement node which can immediately follow it.\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"Declaration node points to all statement nodes using the declared variable.\"\n        }\n      ],\n      \"vertex-features\": \"1) Collect node types and tokens (snippets from leaf nodes) by traversing the network\\n2) Train Word2Vec on the corpus of node types and tokens, and project all to d-dimensional space\\n3) Concatenate the embeddings for the node type and lexical tokens. For nodes without lexical tokens, use the zero vector.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"iterative-updater\": {\n      \"type\": {\n        \"name\": \"CPGNN (CPG-based Neural Network)\",\n        \"architecture\": \"Based on GNN/GCN.\\nIterative scheme, starting with the embeddings e^0 as described for the node features. Then, updated according to the following rules;\\ne^{\\\\ell + 1}_n = \\\\text{LeakyReLU}\\\\left((e_n^\\\\ell \\\\mid\\\\mid e_{N_n}^{\\\\ell})W_g^{\\\\ell}\\\\right)\\nN_n = \\\\{ m \\\\mid (m, n) \\\\in E \\\\}\\ne_{N_n}^{\\\\ell} = \\\\sum_{m \\\\in N_n} \\\\alpha(m, n) e_m^{\\\\ell}\\n\\\\alpha(m, n) = \\\\frac{1}{\\\\sqrt{|N_m| \\\\times |N_n|}}\\nAfter set amount of iterations, for every node, concatenate the embeddings for every iterations into a single vector.\\nTo compute a representation for a full graph, use mean-pooling on the embeddings for all nodes in the graph.\\nNote that \\\\mid\\\\mid represents concatenation\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-clone-detection\": {\n      \"training-objective\": \"Code clone detection; predict \\\"distance\\\" between snippets w/ threshold\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Code clone detection; predict \\\"distance\\\" between snippets w/ threshold\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Source Code Functional Similarity Detection\",\n      \"supervision\": \"Supervised\"\n    },\n    \"source-code-classification\": {\n      \"training-objective\": \"Source code classification into different types\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Source code classification into different types\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Source Code Functional Similarity Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"training\": {\n    \"code-clone-detection-settings\": {\n      \"train-test-split\": {\n        \"train\": 0.8,\n        \"test\": 0.1,\n        \"validation\": 0.1\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"loss\",\n          \"value\": \"binary cross entropy\"\n        },\n        {\n          \"name\": \"optimizer\",\n          \"value\": \"adam\"\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.1\n        },\n        {\n          \"name\": \"epochs\",\n          \"value\": 30\n        },\n        {\n          \"name\": \"dropout\",\n          \"value\": 0.1\n        },\n        {\n          \"name\": \"weight initialisation\",\n          \"value\": \"Xavier\"\n        }\n      ],\n      \"hyper-parameter-selection\": \"grid search\",\n      \"search-tuned-hyper-parameters\": \"not specified\",\n      \"evaluation-details\": \"Evaluated by extending the network with an FNN layer computing\\nthe distance between two embeddings. Sigmoidal activation.\\n(input is thus _two_ snippets)\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"precision\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"recall\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"f1-score\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"auc\",\n          \"type\": \"metric\",\n          \"details\": \"area under curve\"\n        }\n      ]\n    },\n    \"source-code-classification-settings\": {\n      \"train-test-split\": {\n        \"train\": 0.8,\n        \"test\": 0.1,\n        \"validation\": 0.1\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"loss\",\n          \"value\": \"cross-entropy\"\n        },\n        {\n          \"name\": \"optimizer\",\n          \"value\": \"adam\"\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.1\n        },\n        {\n          \"name\": \"epochs\",\n          \"value\": 250\n        },\n        {\n          \"name\": \"dropout\",\n          \"value\": 0.1\n        },\n        {\n          \"name\": \"weight initialisation\",\n          \"value\": \"Xavier\"\n        }\n      ],\n      \"hyper-parameter-selection\": \"grid search\",\n      \"search-tuned-hyper-parameters\": \"not specified\",\n      \"evaluation-details\": \"Evaluated by extending the network with an FNN layer for \\nclassification. Softmax activation.\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"macro precision\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"macro recall\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"macro f1-score\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"accuracy\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        }\n      ]\n    }\n  },\n  \"datasets\": {\n    \"oj-clone-classification\": {\n      \"name\": \"OJ-Clone\",\n      \"description\": \"Based on OJ-Clone, a dataset of 52000 C programs belonging to 104\\ndifferent programming tasks.\",\n      \"source\": [\n        \"OJ-Clone dataset (collected from pedagogical online judge system)\"\n      ],\n      \"labelling\": \"Yes; not specified\",\n      \"size\": 52000,\n      \"is-pre-existing\": true\n    },\n    \"oj-clone-clone\": {\n      \"name\": \"n/a\",\n      \"description\": \"Based on OJ-Clone, a dataset of 52000 C programs belonging to 104 \\ndifferent programming tasks.\\n\\nUsed only first 15000 programming tasks.\\n\\nPrograms solving the same task are considered clones.\\n\\nForming pairs of programs results in the final dataset.\",\n      \"source\": [\n        \"Based on OJ-Clone dataset (collected from pedagogical online judge system)\"\n      ],\n      \"labelling\": \"Yes; not specified\",\n      \"size\": 319800,\n      \"is-pre-existing\": true\n    },\n    \"bcb\": {\n      \"name\": \"BigCloneBench\",\n      \"description\": \"Based on BigCloneBench, a dataset of clone and non-clone pairs. \\n\\nDown-sampled to result at a dataset of 71677 clone pairs.\",\n      \"source\": [\n        \"BigCloneBench dataset (collected from Java projects)\"\n      ],\n      \"labelling\": \"Yes; not specified\",\n      \"size\": 71677,\n      \"is-pre-existing\": true\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"iterative-updater\",\n      \"task\": \"source-code-classification\",\n      \"training\": \"source-code-classification-settings\",\n      \"dataset\": \"oj-clone-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"iterative-updater\",\n      \"task\": \"code-clone-detection\",\n      \"training\": \"code-clone-detection-settings\",\n      \"dataset\": \"oj-clone-clone\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"iterative-updater\",\n      \"task\": \"code-clone-detection\",\n      \"training\": \"code-clone-detection-settings\",\n      \"dataset\": \"bcb\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": [\n    \"On a personal note, I think this approach does prevent the over-squashing problem\",\n    \"Not 100% clear whether the code clone network uses two parallel inputs\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 157,\n  \"pdf-id\": 207,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Tokens are split into subtokens with separate nodes\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"undirected\"\n        }\n      ],\n      \"vertex-features\": null,\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Tokenised Code is also used as input.\\n\\nPrevious summary tokens are also given as input\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"encoder/decoder setup\\n\\n1) Two parallel encoders\\n  i) Code token input \\n    - Embedding Layer \\n    - Bidirectional GRU\\n    - Parallel to the GRU, a linear layer \\n    - Add GRU and linear layer output \\n  ii) Graph Input\\n    - Embedding Layer \\n    - GAT (Specifically, output of multiple Graph Attention Layers applied in 1-hop neighbourhoods are concatenated, then another graph attention layer)\\n    - Bidirectional GRU (on pre-order traversal of AST)\\n2) Decoder\\n    - For both the graph encoder output and token encoder output, compute attention scores according to \\n      e_{ij} = U_a^T \\\\tanh(W_a[h_{i - 1}, s_j]) (h_{i-1}; previous decoder hidden state -- s_j; encoder hidden state)\\n      a_{ij} = softmax(e_{ij})\\n    - Compute context vector according to \\n      c_i = \\\\sum_{j = 1}^n a_{ij} T_j + p \\\\sum_{j = 1}^N a'_{ij} V_j \\n\\n      Here, T_j is the embedding of the j-th token, V_j the embedding of the j-th node,\\n      p = \\\\sigma(y^{softmax}(h_{i - 1}))\\n    - Embedding Layer for previous generated summary token\\n    - Concatenate embedded summary token and context vector\\n    - GRU \\n    - Linear Layer (input: GRU output concatenated with context vector)\\n    - Softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"training-granularity\": \"Graph + Sequence to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"working-granularity\": \"Graph + Sequence to Sequence\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 89,\n  \"pdf-id\": 123,\n  \"graphs\": {\n    \"code-property-like-graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Network of statements, where every statement has its AST subtree attached\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement Node\",\n          \"details\": \"All type names are fully expanded. Variable names are replaced with their fully expanded type.\"\n        },\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"Between statements\"\n        },\n        {\n          \"name\": \"PDG Edge\",\n          \"details\": \"Between statements\"\n        }\n      ],\n      \"vertex-features\": \"Node content is encoded using doc2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GGNN GAT GGNN GAT GGNN GAT FNN (output per _statement_ node)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"exception-detection\": {\n      \"training-objective\": \"Classify nodes (statements) as throwing no exception, or predict exception type\",\n      \"training-granularity\": \"Multi Class Node Classification\",\n      \"working-objective\": \"Classify nodes (statements) as throwing no exception, or predict exception type\",\n      \"working-granularity\": \"Multi Class Node Classification\",\n      \"application\": \"Detect (Prevent) Exceptions which will occur at runtime (in Java)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-property-like-graph\",\n      \"model\": \"model\",\n      \"task\": \"exception-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 57,\n  \"pdf-id\": 81,\n  \"graphs\": {\n    \"fcg\": {\n      \"name\": \"Function Call Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Function\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Call Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Function Name, encoded using Word2Vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"vpr\": {\n      \"name\": \"Vulnerability Property Graph\",\n      \"description\": \"Code property graph enhanced for vulnerability detection\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Token Edge\",\n          \"details\": \"Edge from one token (leaf node) to the next\"\n        }\n      ],\n      \"vertex-features\": \"Features based on AST payload; identifiers, keywords, names, types etc. (yes, the paper says etcetera).\\n\\nEncoded using Word2Vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Several GAT layers \"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-scoring\": {\n      \"training-objective\": \"Given a graph with a vulnerability, predict its severity (from 4 options)\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given a graph with a vulnerability, predict its severity (from 4 options)\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Severity Assessment\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"fch + vpr\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-scoring\",\n      \"comments\": \"Two things are unclear:\\n1) Are the graphs merged? If so, how? If not, what is the purpose of having two?\\n2) The paper mentions random initialisation of node features. What is that about!?\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 24,\n  \"pdf-id\": 37,\n  \"graphs\": {\n    \"cag-word2vec\": {\n      \"name\": \"CAG (Code Aggregate Graph)\",\n      \"description\": \"Combination of AST, CFG, PDG (Program Dependence Graph), DT (Dominator Tree), and PDT (Post-dominator Tree)\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Seemingly method level\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge (Tree labels; true, false, empty)\",\n          \"details\": \"Edge from one statement ot other statements that may directly follow it\"\n        },\n        {\n          \"name\": \"Dominator Edge\",\n          \"details\": \"Edge from a node to every node that it dominates\"\n        },\n        {\n          \"name\": \"Post-dominator Edge\",\n          \"details\": \"Edge from a node to every node that is post-dominates\"\n        },\n        {\n          \"name\": \"Data Dependence Edge\",\n          \"details\": \"Edge from variable declaration to all its uses\"\n        }\n      ],\n      \"vertex-features\": \"Code statement and node type are encoded using Word2Vec (CBOW)\\n\\nThis is concatenated with a one-hot encoding of the node type.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"cag-fasttext\": {\n      \"name\": \"CAG (Code Aggregate Graph)\",\n      \"description\": \"Combination of AST, CFG, PDG (Program Dependence Graph), DT (Dominator Tree), and PDT (Post-dominator Tree)\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Seemingly method level\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge (Tree labels; true, false, empty)\",\n          \"details\": \"Edge from one statement ot other statements that may directly follow it\"\n        },\n        {\n          \"name\": \"Dominator Edge\",\n          \"details\": \"Edge from a node to every node that it dominates\"\n        },\n        {\n          \"name\": \"Post-dominator Edge\",\n          \"details\": \"Edge from a node to every node that is post-dominates\"\n        },\n        {\n          \"name\": \"Data Dependence Edge\",\n          \"details\": \"Edge from variable declaration to all its uses\"\n        }\n      ],\n      \"vertex-features\": \"Code statement and node type are encoded using FastText \\n\\nThis is concatenated with a one-hot encoding of the node type.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"cag-glove\": {\n      \"name\": \"CAG (Code Aggregate Graph)\",\n      \"description\": \"Combination of AST, CFG, PDG (Program Dependence Graph), DT (Dominator Tree), and PDT (Post-dominator Tree)\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Seemingly method level\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge (Tree labels; true, false, empty)\",\n          \"details\": \"Edge from one statement ot other statements that may directly follow it\"\n        },\n        {\n          \"name\": \"Dominator Edge\",\n          \"details\": \"Edge from a node to every node that it dominates\"\n        },\n        {\n          \"name\": \"Post-dominator Edge\",\n          \"details\": \"Edge from a node to every node that is post-dominates\"\n        },\n        {\n          \"name\": \"Data Dependence Edge\",\n          \"details\": \"Edge from variable declaration to all its uses\"\n        }\n      ],\n      \"vertex-features\": \"Code statement and node type are encoded using GloVe\\n\\nThis is concatenated with a one-hot encoding of the node type.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gcn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN architecture, followed by global attention pooling, followed by MLP\"\n      }\n    },\n    \"ggnn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GGNN architecture, followed by global attention pooling, followed by MLP\"\n      }\n    },\n    \"gin\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GIN (graph isomorphism) architecture, followed by global attention pooling, followed by MLP\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify methods as vulnerable/not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify methods as vulnerable/not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cag-word2vec\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cag-word2vec\",\n      \"model\": \"ggnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cag-word2vec\",\n      \"model\": \"gin\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cag-fasttext\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cag-fasttext\",\n      \"model\": \"ggnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cag-fasttext\",\n      \"model\": \"gin\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cag-glove\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cag-glove\",\n      \"model\": \"ggnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cag-glove\",\n      \"model\": \"gin\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": [\n    \"Unclear which model combination were exactly explored; I would assume all, but that might be incorrect.\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 94,\n  \"pdf-id\": 130,\n  \"graphs\": {\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"PHP files\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Content of statement nodes is tokenized\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Original source code snippet is parsed into a sequence of tokens.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Two inputs:\\n1) Token sequence representation \\n    i) Embedding Layer\\n    ii) Bidirectional GRU\\n2) CFG \\n    i) Embedding Layer \\n    ii) GCN\\n    iii) Edge Pooling\\n\\nStreams are concatenated \\nMLP\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-classification\": {\n      \"training-objective\": \"Classify sample (graph) as safe/XSS/SQL injection/OSCI\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample (graph) as safe/XSS/SQL injection/OSCI\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-classification\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 81,\n  \"pdf-id\": 112,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Program Dependency Graph with additional heterogeneous information\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"methods\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Method Node\",\n          \"details\": \"Represents the method. Only one such node exists in the graph\"\n        },\n        {\n          \"name\": \"Statement Node\",\n          \"details\": \"b/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"Connects successive statements\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"Connects statements where the execution of one is controlled by the other\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"Connects statements with variables to the statement where the variable is defined\"\n        },\n        {\n          \"name\": \"Include Edge\",\n          \"details\": \"Edge from Method Node to Statement Node\"\n        }\n      ],\n      \"vertex-features\": \"Method Node Features; 1) LOC -- Amount of statements in the method 2) CC -- McCabe's Cyclomatic Complexity of the method 3) PC -- Parameter count of the method 4) LCOM1 to LCOM4 -- Four type of cohesion metrics propoposed by Charalampidou\\nStatement Node Features; 1) ABCL --  Metric proposed by Fitzpatrick, representing the type of statement (assignment, branch, condition, loop) 2) FUC -- Amount of fields used in a statement 3) LMUC -- Total amount of local (same class) methods used in the statement 4) PUC -- Number of parameters used in the statement 5) NBD -- Nesting depth of the statement 6) VUC -- Amount of variables used in a statement 7) WC -- Word count of the statement\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gcn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN\\nGCN \\nFNN\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"long-method-detection\": {\n      \"training-objective\": \"Classify method as long/not long\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify method as long/not long\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Long Method (Complicated methods violating single responsibility) detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"gcn\",\n      \"task\": \"long-method-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 168,\n  \"pdf-id\": 221,\n  \"graphs\": {\n    \"fcg\": {\n      \"name\": \"Function Call Graph\",\n      \"description\": null,\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Function\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Call Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"Edge weights calculated using Ricci curvature\",\n      \"connectivity-features\": \"Not  specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"embedding\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Riemannian stochastic gradient descent to \\ncompute embedding vectors based on a hyperbolic loss function.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"embedding\": {\n      \"training-objective\": \"Minimise loss function\",\n      \"training-granularity\": \"Node embedding\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Embedding of nodes in hyperbolic space\",\n      \"supervision\": \"Unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"fcg\",\n      \"model\": \"embedding\",\n      \"task\": \"embedding\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": [\n    \"Technique can be used on downstream tasks, such as clustering or link prediction using e.g. logistic regression\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 85,\n  \"pdf-id\": 117,\n  \"graphs\": {\n    \"pdg\": {\n      \"name\": \"PDG\",\n      \"description\": \"Check \\\"other-features\\\" for details;\\nThe paper does not really use graphs, but things derived \\nfrom full graphs.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": null\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Dependence Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependence Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"So-called value-flow paths are extracted from the PDG.\\n\\nA guarded value-flow path consists of a sequence of program\\nstatements representing a def-use chain between variables, with the\\nguard on each edge between two statements to indicate control-flow\\ntransfer conditions.\\n\\nPaths are put into a network which maps them to vectors.\\nA path is fed twice into the network, with different dropout masks.\\nA contrastive loss is used.\\n\\nThe network first encoded the statements based on AST subtrees.\\nEach node in the AST subtree corresponding to the statement\\nis initialised using Code2Vec.\\n\\nNext, each nodes embedding is updated according to its\\nown embedding and those of its children, using an\\nattention-weighted sum.\\nThe attention weights for node $i$ and its children $C_i$ are computed according to \\n\\n  a_{ij} = \\\\frac{\\\\exp(\\\\sigma(e_{ij}))}{\\\\sum_{k \\\\in C_i \\\\cup i} \\\\exp(\\\\sigma(e_{ik}))}\\n  e_{ij} = a^T_s[W^a v_{n_i} \\\\mid\\\\mid W^a v_{n_j}] \\\\cdot \\\\sigma((W^av_{n_1})^T(W^a v_{n_j}))\\n  Where a_s and W are a learnable matrix and learnable vector.\\n\\nFinally, all nodes are aggregated according to:\\n\\nv_{sm} = \\\\frac{1}{N}\\\\sum_{i = 1}^N v'_{n_i} \\\\mid\\\\mid \\\\max_{j = 1}^N v'_{n_j}\\n\\nNext, all statement embeddings are passed through a bidirectional GRU layer.\\n\\nThe hidden states of the GRU layer are summed using an attention-weighted sum.\\n\\nThe trained model is used to encode value-flow paths for later use.\\n\\nDeep learning model is used to select top-k paths. \\nInfeasible value flow paths (cannot occur based on if guards) are filtered out.\"\n    }\n  },\n  \"models\": {\n    \"detection-model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Multi-head Attention\\nAdd + Normalisation \\nFNN \\nAdd + Normalisation\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable/not vulnerable\",\n      \"training-granularity\": \"Binary Classification (not of graphs)\",\n      \"working-objective\": \"Classify sample as vulnerable/not vulnerable\",\n      \"working-granularity\": \"Binary Classification (not of graphs)\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"detection-model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 56,\n  \"pdf-id\": 79,\n  \"graphs\": {\n    \"ipg\": {\n      \"name\": \"Inter-procedural Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Dependence Edge\",\n          \"details\": \"From PDG\"\n        },\n        {\n          \"name\": \"Data Dependence Edge\",\n          \"details\": \"From PDG\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Function Call Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Nodes represent statements, which consists of tokens.\\nNodes are embedding by summing the embeddings of the tokens, \\nwhere tokens are embedded using a learnable embedding.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"Sample subgraphs using vulnerability-specific program slicing;\\nIdentify start and end of possible vulnerability, and select \\nthe graph of all paths between the two.\\n\\nExtract six subgraphs for: \\n  1) buffer overflow\\n  2) memory leak\\n  3) null pointer dereference\\n  4) integer overflow\\n  5) use after free \\n  6) double free\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Ensemble of multiple models.\\nSix submodels, each of which takes in a number of subgraphs of _one_ of the specific types; 1) Trainable Embedding Layer 2) GGNN (SUM + GRU) layers 3) FNN layer for each node embedding 4) Max pooling to obtain graph embedding 5) self-attention based weighted sum aggregation 6) FNN layer w/ sigmoid activation\\nGNN model, which takes as input the inter-procedural graph; 1) Trainable Embedding Layer 2) GGNN (SUM + GRU) layers 3) FNN layer for each node embedding 4) Max pooling to obtain graph embedding 5) FNN layer w/ sigmoid activation\\nAll models are combined through summing and normalising.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vul-detection\": {\n      \"training-objective\": \"For a given piece of code, output which vulnerabilities it contains\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"For a given piece of code, output which vulnerabilities it contains\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ipg\",\n      \"model\": \"model\",\n      \"task\": \"vul-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 90,\n  \"pdf-id\": 125,\n  \"graphs\": {\n    \"pdg\": {\n      \"name\": \"PDG\",\n      \"description\": \"Using slicing, every PDG is split into multiple slice subgraphs\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"Comments removed, user defined names are normalised.\\nProgram slicing based on sensitive APIs, arrays,\\nintegers, and pointers is performed.\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Dependence Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependence Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Statement embedded using sent2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Using slicing, every PDG is split into multiple slice subgraphs\",\n      \"graph-features\": \"Using slicing, every PDG is split into multiple slice subgraphs.\\n\\nThe subgraph-model is used to filter subgraphs; \\nthe 25% of subgraphs with the lowest predicted probabilities \\nof containing a vulnerability are dropped.\\n\\nThe remaining subgraphs are passed to the \\\"full\\\" model.\",\n      \"other-features\": \"Using slicing, every PDG is split into multiple slice subgraphs\"\n    }\n  },\n  \"models\": {\n    \"subgraph-model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"x_i = initial feature values \\nh_i = GGNN(x_i)\\nc_i = [h_i, x_i]\\ny_1 = MaxPool(ReLU(Conv(MaxPool(ReLU(Conv(h_i)))))))\\ny_2 = MaxPool(ReLU(Conv(MaxPool(ReLU(Conv(c_i)))))))\\nb = MLP(y_1) \\\\cdot MLP(y_2)\\ny = sigmoid(MeanPool(b))\"\n      }\n    },\n    \"full\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"x_i = initial feature values \\nh_i = GGNN(x_i)\\nc_subgraph_i = [AveragePool(h_i), AveragePool(x_i)]\\no_i = Attention Layer (fuses all c_subgraph_i in to one vector C)\\ny_1 = MaxPool(ReLU(Conv(MaxPool(ReLU(Conv(o_i)))))))\\ny_2 = MaxPool(ReLU(Conv(MaxPool(ReLU(Conv(c_i)))))))\\nb = MLP(y_1) \\\\cdot MLP(y_2)\\ny = sigmoid(MeanPool(b))\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify code sample (function) as vulnerable/not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify code sample (function) as vulnerable/not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"subgraph-model + full\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": \"The paper mentions using attention to fuse everything in a single vector;\\nthat does not seem to be the case based on the code.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 141,\n  \"pdf-id\": 186,\n  \"graphs\": {\n    \"augmented-ast\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST augmented with additional information\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Variable Node\",\n          \"details\": \"One node for each variable.\\nAll occurrences of a variable are attached to the unique note for that variable\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Child Edge\",\n          \"details\": \"Regular AST Edge\"\n        },\n        {\n          \"name\": \"Sibling Edge\",\n          \"details\": \"Connect child node to its sibling successor (represent order or \\\"arguments\\\" for an AST Node)\"\n        },\n        {\n          \"name\": \"Read Edge\",\n          \"details\": \"Used to connect a variable occurrence to the unique node for that variable\"\n        },\n        {\n          \"name\": \"Write Edge\",\n          \"details\": \"Used to connect a variable occurrence to the unique node for that variable\"\n        },\n        {\n          \"name\": \"Chronological Edge\",\n          \"details\": \"Establish order between nodes referencing the same variable name\"\n        }\n      ],\n      \"vertex-features\": \"Not specified what is used for node features\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Two inputs; typically faulty program and correct program.\\nEncoded in parallel:\\n  R-GCN, LayerNormalisation, ReLU (5x Repeated w/ the same weights)\\nFor each possible pairing of (unique) variable nodes (a, b) \\n(where a is from the faulty program and b is from the correct program),\\ncompute the dot product between a and b; arrange all dot products in a matrix,\\nand compute row-wise softmax \\n(entry m_{ij} denote the probability that variable i in the faulty program maps to variable j in the correct program).\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"variable-mapping\": {\n      \"training-objective\": \"Map variables to one program to variables in another program\",\n      \"training-granularity\": \"n/a (similar to either node classification or link prediction, but not quite)\",\n      \"working-objective\": \"Map variables to one program to variables in another program\",\n      \"working-granularity\": \"n/a (similar to either node classification or link prediction, but not quite)\",\n      \"application\": \"Variable Mapping (can be used for downstream tasks such as program repair)\",\n      \"supervision\": \"Supervised (but training data can be automatically generated by mutating progams)\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"augmented-ast\",\n      \"model\": \"model\",\n      \"task\": \"variable-mapping\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 211,\n  \"pdf-id\": 281,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Graph representing program elements in a smart contract. \\nIt is not entirely clear what constitutes a program element.\\nIt seems to be variables and function invocations, based on the \\nproposed node features.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"smart contract\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Core Node\",\n          \"details\": \"Critical for vulnerability detection (e.g. money transfer, call.value)\"\n        },\n        {\n          \"name\": \"Normal Node\",\n          \"details\": \"Nodes that are not marked as core\"\n        },\n        {\n          \"name\": \"Fallback Node\",\n          \"details\": \"Simulates fallback function of a contract\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Fallback Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Depend on node type:\\n  1) Function Invocation Nodes\\n      i) Function Identifier\\n      ii) Caller Address\\n      iii) Node Type\\n      iv) Flag indicating whether the function has limited access (e.g. must be owner)\\n\\n  2) Variable/fallback nodes\\n      i) Identifier\\n      ii) Node Type\\n\\n  Next, feedback and normal nodes are removed. \\n  Their features are \\\"assigned\\\" to the nearest core\\n  node (to multiple in case of multiple closest core nodes).\\n  The removed edges become self-loops on the core nodes. \\n\\n  As a result, only core vertices remain, and they have \\n  three sets of features:\\n  1) Self-features (their original ones)\\n  2) In-features: all features from normal nodes that\\n      were pointing toward the core node\\n  3) Out-features: all features from normal nodes that\\n      were pointed away from the core node\\n\\n  It is unclear how exactly the features are _encoded_\",\n      \"edge-features\": \"Order (sequential order in the function), edge type\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Various hand-crafted/expert features are used (0/1 values indicating existence of certain patterns)\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Two parallel inputs\\n  i) Expert features \\n    - FNN\\n    - Convolution \\n    - Max Pooling\\n  ii) Graph structure\\n    - Temporal Message Passing\\n      Initial node embedding: h_i^0 = node features \\n      \\n      Each time step, a message is propagated along one edge, in temporal order.\\n      at time step k, we have\\n\\n      m_k = W_k(h_{sk} || t_k) + b_k  (h_{sh}: state of start node; t_k: edge type)\\n      h_{ek}' = \\\\tanh(U m_k + Z h_{ek + b_1)\\n      h_{ek}'' = softmax(R h_{ek}' + b_2)\\n\\n    - Readout\\n      s_i = h_i^T || h_i^0    (concat initial and final features)\\n      g_i = softmax(W_{g2}(\\\\tanh(b_{g1} + W_{g1}s_i)) + b_{g2})\\n      o_i = softmax(W_{o2}(\\\\tanh(b_{o1} + W_{o1}s_i)) + b_{o2})\\n      G_r = FullyConnectedLayer(\\\\sum_i o_i \\\\odot g_i)\\n    - Convolution\\n    - Max Pooling\\n2) Concatenate Graph and Expert Features extracted in (i) and (ii)\\n3) FNN (x3)\\n4) Sigmoid\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Given a graph, classify it as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given a graph, classify it as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection in Smart Contracts\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 192,\n  \"pdf-id\": 255,\n  \"graphs\": {\n    \"apdg\": {\n      \"name\": \"APDG (Advanced PDG)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": null\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Method Declaration\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Parameter\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Unary Expression\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Variable Declaration Expression\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Method Call Expression\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Assign Expression\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Construction Declaration\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Try Statement\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Class Or Interface Declaration\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Condition\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Return Statement\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Assert Statement\",\n          \"details\": null\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Dependence Edge\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Control Dependence -- Child\",\n          \"details\": \"Essentially an AST Edge\"\n        },\n        {\n          \"name\": \"Control Dependence -- Next Statement\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Control Dependence -- Judge\",\n          \"details\": \"True/False branches of if; back to condition for loop; denote conditional flow control\"\n        }\n      ],\n      \"vertex-features\": \"Graph Node is a set of (unordered) tokens (obtained from camel case for every node)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Summary (Training) or query (working) is also used as feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Summary Encoder\\n  i) Embedding Layer\\n  ii) Tokens (per node) encoded using a bidirectional LSTM,\\n      where hidden states for time t are added,\\n      and the final embedding is obtained through max pooling\\n2) Graph Encoder\\n  i) Embedding Layer\\n  ii) Tokens (per node) encoded using an MLP followed by max pooling\\n  iii) GGNN w/ attention mechanism for edge _types_\\n3) Cosine similarity\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-search\": {\n      \"training-objective\": \"Maximise similarity of related (summary, code) pairs; minimise similarity of unrelated (summary, code) pairs\",\n      \"training-granularity\": \"Graph Regression (?)\",\n      \"working-objective\": \"Output similarity scores of (query, code) pairs\",\n      \"working-granularity\": \"Graph Regression (?)\",\n      \"application\": \"Code Search\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"apdg\",\n      \"model\": \"model\",\n      \"task\": \"code-search\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 66,\n  \"pdf-id\": 93,\n  \"graphs\": {\n    \"lfast\": {\n      \"name\": \"LFAST (Loop-Flow Abstract Syntax Tree)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Only a small selection of AST nodes from the original AST \\nis kept; only the \\\"loop oriented\\\" ones, which are either\\npart of a loop or within a k-hop neighbourhood of a node \\nwhich is part of a loop.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Node features are based on three basic features:\\n  1) Node payload (1 token) encoded using word2vec\\n  2) Node type is encoded using Label Encoding\\n  3) positional encoding: position of i-th token in code is encoded as a vector\\n    [sin(w_0 * i), cos(w_0 * i), sin(w_1 * i), cos(w_1 * i), ...]\\n\\n  Final node feature vector is given by CONCAT(type, payload + position)\",\n      \"edge-features\": \"Edge type: syntax, control, or data. Encoded using Label Encoding\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"lcvd-gcn\": {\n      \"type\": {\n        \"name\": \"LCVD (GCN)\",\n        \"architecture\": \"1) Node Embedding Module; repetitions of following:\\n  i) Self-attention sublayer\\n    Compute self-attention as in GAT, but with multi-head attention\\n  ii) Add and normalise self attention output with self attention input (skip/residual connection)\\n  iii) Graph Convolutional Sublayer\\n2) Pooling Module\\n  Let h denote the embedded graph; let x denote the original node features; Let * denote elementwise multiplication\\n  i) Compute g_1 = MLP(\\n      LeakyReLU(MaxPool(Concat(h, x))) * LeakyReLU(MaxPool(x))\\n    )\\n  ii) Compute g_2 = MLP(\\n      LeakyReLU(AvgxPool(Concat(h, x))) * LeakyReLU(AvgPool(x))\\n    )\\n  iii) Output g = g_1 * g_2\\n3) sigmoid(MLP(ReLU(g)))\"\n      }\n    },\n    \"lcvd-ggnn\": {\n      \"type\": {\n        \"name\": \"LCVD (GGNN)\",\n        \"architecture\": \"Same as LCVD-GCN, but with GGNN instead of GCN\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify function as vulnerable or non-vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify function as vulnerable or non-vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"lfast\",\n      \"model\": \"lcvd-gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"lfast\",\n      \"model\": \"lcvd-ggnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 127,\n  \"pdf-id\": 170,\n  \"graphs\": {\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"To avoid confusion, remember that the artefacts in the \\n\\\"artefacts\\\" section are not related _beforehand_, but their\\nrelatedness must be predicted\",\n      \"artefacts\": [\n        {\n          \"name\": \"Bug report\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"Every function in a source file has its own PDG\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Statements in nodes are encoded using CodeBERT.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Source code text is also used as input.\\n\\nBug report text is cleaned up (e.g. formatting removal)\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Three parallel inputs:\\n  i) Bug Report Text \\n    Encoded using the Transformer encoder (Viswani et al.),\\n    and taking the output of the [CLS] token by the \\n    final layer as the final embedding.\\n  ii) Source Code Text \\n    Encoded by fine-tuning the CodeBERT model,\\n    and taking the output of the [CLS] token by the \\n    final layer as the final embedding.\\n  iii) CFH\\n    First, statements are encoded further by one \\n    layer of the (encoder) Transformer architecture as defined by \\n    Visawni et al., followed by Max pooling. \\n\\n    The CFG is then encoded by 6 layers of the encoder \\n    of the Transformer architecture, with one adjustment;\\n    attention is made structure aware by computing it as \\n\\n    att = softmax(\\\\frac{QK^T}{\\\\sqrt{d_k}} + M)V\\n\\n    Where $M_{ij} = 0$ is there is an edge between nodes $i$ and $j$,\\n    and $\\\\infty$ otherwise.\\n2) concatenation \\n3) FNN\\n4) BatchNormalisation\\n5) FNN\\n6) FNN\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"bug-localisation\": {\n      \"training-objective\": \"Predict whether the bug in the given report is correlated with the given source file\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Predict whether the bug in the given report is correlated with the given source file\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Bug localisation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"model\",\n      \"task\": \"bug-localisation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 159,\n  \"pdf-id\": 209,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Every node has three attributes:\\nx: Depth \\ny: left-to-right sequential position of its parent in the layer\\nz: left-to-right sequential position among its siblings (-1 for lexical nodeS)\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"(x, y, z), and the code token itself (type or token)\",\n      \"edge-features\": \"\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Tokenised code is used as a feature, where each token is enhanced with positional information\\n\\nThe comment generated thus far (in token form) is also used as an input.\\nEach token is enhanced with positional information describing its location in the sequence.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Transformer based architecture \\n\\n1) All inputs (nodes, tokens, summary thus far) are embedded as a weighted sum of \\n    their position and semantic payload. \\n\\n2) Source Code Encoder:\\n    i) Multi-head self attention w/ residual connections and normalisation\\n    ii) FNN w/ residual connections and normalisation\\n\\n3) Graph Encoder \\n    i) GraphSAGE w/ ReLU \\n    ii) Residual connections and normalisation\\n\\n4) Decoder (takes as input content generated thus far)\\n    i) Masked Multi-head self attention w/ residual connections and normalisation\\n    ii) Multi-head attention w/ residual connections and normalisation\\n        Attention inputs K, V come from graph encoder \\n    iii) Multi-head attention w/ residual connections and normalisation\\n        Attention inputs K, V come from source code encoder \\n    iv) FNN w/ residual connections and normalisation\\n\\n5) Multi-source Pointer-Generator Network\\n    i) Decoder output e'_s transformed according to: p_v = softmax(Linear(e'_s))\\n    ii) Multihead attention where Q = e'_s and K, V equal the output of the graph encoder\\n        \\\\delta_n = Att(Q, K, V)\\n        a_c = softmax(mean(a_1, \\\\hdots))\\n        a_i = softmax(\\\\frac{KW_i^Q(KW_i^K)^T}{\\\\sqrt{d}})(VW_i^V)\\n    iii) Multihead attention where Q = e'_s and K, V equal the output of the source code encoder (see above)\\n    iv) Probability for token w according to\\n        p_c(w) = \\\\sum_{i: w_i = w} a_{c, i}\\n        (similar for p_n(w))\\n    v) p_s(w) = \\\\lambda_v p_w(w) + \\\\lambda_n p_n(w) + \\\\lambda_c p_c(w)\\n        where [\\\\lambda_v, \\\\lambda_n, \\\\lambda_c] = softmax(Linear([e'_s, \\\\delta_n, \\\\delta_c]))\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"training-granularity\": \"Graph + sequence to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"working-granularity\": \"Graph + sequence to Sequence\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 156,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Simplified AST\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"Pairs of files; One old file and a revised version\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Some statement (internal) nodes are removed\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Word embedding is used to encode nodes. \\n\\nUnclear what exactly (node type, token payload) is encoded.\\nThe images in the paper suggests that the node type is encoded\\nfor internal nodes, and the payload for lexical nodes.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) GCN (w/ LeakyReLU) (outputs h_v)\\n2) Attention \\n  b_v = \\\\sum_{u \\\\in V} h_v^T h_u\\n  a_v = softmax(b_v)\\n3) Attention weighted sum: r = \\\\sum_{v \\\\in V} a_v h_v\\n4) Subtract difference of old and revised files: r = r_O - r_R \\n5) Softmax(Wr + b)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"automated-code-review\": {\n      \"training-objective\": \"Given old and revised code, classify \\\"the change\\\" as \\\"reject\\\" or \\\"accept\\\"\",\n      \"training-granularity\": \"Graph Classification, but not quite\",\n      \"working-objective\": \"Given old and revised code, classify \\\"the change\\\" as \\\"reject\\\" or \\\"accept\\\"\",\n      \"working-granularity\": \"Graph Classification, but not quite\",\n      \"application\": \"Automated Code Review\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"automated-code-review\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 29,\n  \"pdf-id\": 42,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Combination of a graph showing module/class/function/method/field/variable relations\\nand an abstract syntax tree.\\n\\nNote that although vertices represent different things, in practice, there is only 1 vertex type.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Module\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Class\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Function\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Method\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Class Field\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Module Variable\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"AST Type\",\n          \"details\": \"Every AST Node has a type node pointing to it.\\nFor instance, every function definition has an incoming edge from the \\\"FunctionDef\\\" node.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Define\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Use\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Type use\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Import\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Call\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Import\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"AST Type Edge\",\n          \"details\": \"Every AST Node has a type node pointing to it.\\nFor instance, every function definition has an incoming edge from the \\\"FunctionDef\\\" node.\"\n        }\n      ],\n      \"vertex-features\": \"Not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Source code is tokenized. A FastText model is trained on the tokens.\\nThe tokens are encoded using FastText.\\n\\nFor every token, prefix and suffix information is collected.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Two models are used.\\n\\n1) GNN model\\n  RGCN -- Relational GCN\\n  Used to learn graph embeddings for individual tokens.\\n\\n  Trained using node name prediction, variable use prediction, and next call prediction.\\n\\n2) CNN model w/ 2 dense layers \\n  Takes as input, for every token, the prefix info, suffix info, fasttext embedding, graph embedding\\n  BILUO output scheme\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"type-prediction\": {\n      \"training-objective\": \"Named Entity Recognition\",\n      \"training-granularity\": \"BILUO\",\n      \"working-objective\": \"Named Entity Recognition\",\n      \"working-granularity\": \"BILUO\",\n      \"application\": \"Predict types of variable in code\",\n      \"supervision\": \"supervised\"\n    },\n    \"node-name-prediction\": {\n      \"training-objective\": \"Predict names of  nodes\",\n      \"training-granularity\": \"Node Prediction\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Node Embedding\",\n      \"supervision\": \"Self-supervised / unsupervised\"\n    },\n    \"variable-use-prediction\": {\n      \"training-objective\": \"Predict variables used by a function\",\n      \"training-granularity\": \"Not specified\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Node Embedding\",\n      \"supervision\": \"Self-supervised / unsupervised\"\n    },\n    \"next-call-prediction\": {\n      \"training-objective\": \"Given a function, predict the next function called\",\n      \"training-granularity\": \"Not specified\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Node Embedding\",\n      \"supervision\": \"Self-supervised / unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"type-prediction + node-name-prediction + variable-use-prediction + next-call-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 194,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": null\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Token representation of the code is used as feature\"\n    },\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": null\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"See AST\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Token Sequence Encoder \\n  i) Embedding Layer\\n  ii) LSTM \\n  iii) Attention; a_i^{tok} = softmax(g(f(h_i), u)), with u a learnable vector \\n  iv) Sum based on a_i^{tok}\\n2) AST Encoder\\n  i) Tree-LSTM\\n  ii) Attention (same as for token)\\n  iii) Sum based on a_i^{ast}\\n3) CF Encoder\\n  i) GGNN \\n  ii) Attention; a_i^{cfg} = sigmoid(g(f(h_i), u))\\n  iii) Sum based on a_i^{cfg}\\n4) Concatenate \\n5) Linear layer \\n6) Description Encoder \\n  i) LSTM; last hidden state used as output\\n7) Cosine similarity between outputs of (5) and (6)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-search\": {\n      \"training-objective\": \"Maximise similarity of related (summary, code) pairs; minimise similarity of unrelated (summary, code) pairs\",\n      \"training-granularity\": \"Graph Regression (?)\",\n      \"working-objective\": \"Output similarity scores of (query, code) pairs\",\n      \"working-granularity\": \"Graph Regression (?)\",\n      \"application\": \"Code Search\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + cfg\",\n      \"model\": \"model\",\n      \"task\": \"code-search\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 10,\n  \"pdf-id\": 18,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"In this setting, the source code is obtained from decompiled byte code.\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Generic and specific node type \\n(e.g. a variable of specific type \\\"Variable\\\" has generic type \\\"Expression\\\")\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"auto-encoder\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Graph Convolutional Auto-Encoder w/ dot product decoder,\\nfor learning graph embeddings.\"\n      }\n    },\n    \"agent\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Reinforcement learning agent which takes in a graph embedding\\n(from auto-encoder),\\nand outputs the next program transformation.\\n\\nMaskable PPO, using MLP as policy holder.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"embedding\": {\n      \"training-objective\": \"Minimise reconstruction error\",\n      \"training-granularity\": \"Graph embedding\",\n      \"working-objective\": \"Graph Embedding\",\n      \"working-granularity\": \"Graph Embedding\",\n      \"application\": \"Graph Embedding\",\n      \"supervision\": \"Self supervised/unsupervised\"\n    },\n    \"program-improvement\": {\n      \"training-objective\": \"Apply program transformations optimising some pre-specified metric.\\n\\nAgent reward is the (signed) delta between the input program and the output program.\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Apply program transformations optimising some pre-specified metric.\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Improve programs (initially obtained from decompilation)\\nby applying program transformations.\",\n      \"supervision\": \"Supervised (Reinforcement Learning)\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"auto-encoder + agent\",\n      \"task\": \"embedding + program-improvement\",\n      \"comments\": \"mapping from tasks to models -- embedding -> auto-encoder, agent -> program-improvement\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 123,\n  \"pdf-id\": 165,\n  \"graphs\": {\n    \"cfg\": {\n      \"name\": \"Control Flow Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Statements in nodes are tokenized\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"n/a Tokens are encoded using trainable embedding layer For each node, the token sequence is passed through Bidirectional LSTM; node embedding is average of hidden states.\\nNodes are sequenced in a breadth-first traversal order of the CFG. The network used is a variant of LSTM, but with some specific modification. Specifically, the hidden state of a node depends on the hidden state of its predecessors. Edges in the sequence can be forward (towards the end) or backward, towards the beginning. In the first sweep, the forward direction is processed. Next the backward direction.\\nNodes with API calls are marked. Nodes are passed through attention mechanism, where marked nodes get higher weights. Weights are used to sum node embeddings.\\nFNN w/ sigmoid\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"control-flow-bug-detection\": {\n      \"training-objective\": \"Classify sample as buggy or not buggy\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample as buggy or not buggy\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Detect control-flow related bugs\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"model\",\n      \"task\": \"control-flow-bug-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 129,\n  \"pdf-id\": 172,\n  \"graphs\": {\n    \"ast-within\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"File\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Only method calls (incl. class creation), declarations, and control flow nodes are kept.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Content of tokens is put into a sequence\"\n    },\n    \"ast-cross\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"File\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Only method calls (incl. class creation), declarations, and control flow nodes are kept.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Node types are put into a sequence\"\n    },\n    \"class-dependency-network\": {\n      \"name\": \"Class Dependency Network (CDN)\",\n      \"description\": \"Serves as the \\\"larger\\\" context (``external features'') for the file.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Files/project\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Class\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Dependency\",\n          \"details\": \"Inheritance/implementation, fields (A has field of type B), method invocation (A calls method of B)\"\n        }\n      ],\n      \"vertex-features\": \"Various static code analysis metrics (e.. LOC, afferent coupling, CBO)\\nNetwork metrics generated using node2vec.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"encoder\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Two inputs:\\n  1) Tokens \\n    Embedding Layer  \\n    CNN w/ ReLU \\n    Max pooling\\n  2) Graph \\n    GCN w/ ReLU\\n    GCN\\nWeighted concatenation; concat(\\\\alpha * TextEmbedding, (1 - alpha) * GraphEmbedding)\\nFNN Layer w/ ReLU \\nSoftmax \\n\\nNOTE: this model is used to compute embeddings used by a downstream model\\nNOTE: for embedding, the outputs of the FNN layer _before_ ReLU are used.\"\n      }\n    },\n    \"random-forest\": {\n      \"type\": {\n        \"name\": \"Random Forest\",\n        \"architecture\": \"Random Forest\"\n      }\n    },\n    \"mlp\": {\n      \"type\": {\n        \"name\": \"Multi-Layer Perceptron\",\n        \"architecture\": \"MLP\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"within-project-defect-prediction\": {\n      \"training-objective\": \"encoder model: Predict sample as defect or not defect \\nrandom forest: Predict sample as defect or not defect\",\n      \"training-granularity\": \"Embedding and Classification\",\n      \"working-objective\": \"encoder model: Compute embedding of code sample \\nrandom forest: Predict sample as defect or not defect\",\n      \"working-granularity\": \"Embedding and Classification\",\n      \"application\": \"Defect prediction (file-level), in the same project\",\n      \"supervision\": \"Supervised\"\n    },\n    \"cross-project-defect-prediction\": {\n      \"training-objective\": \"encoder model: Predict sample as defect or not defect \\nmlp: Predict sample as defect or not defect\",\n      \"training-granularity\": \"Embedding and Classification\",\n      \"working-objective\": \"encoder model: Compute embedding of code sample \\nmlp: Predict sample as defect or not defect\",\n      \"working-granularity\": \"Embedding and Classification\",\n      \"application\": \"Defect prediction (file-level), in a different [foreign] project\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + class-dependency-network\",\n      \"model\": \"encoder + random-forest\",\n      \"task\": \"within-project-defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast + class-dependency-network\",\n      \"model\": \"encoder + mlp\",\n      \"task\": \"cross-project-defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 83,\n  \"pdf-id\": 115,\n  \"graphs\": {\n    \"compact-abstract-graph\": {\n      \"name\": \"Compact Abstract Graph\",\n      \"description\": null,\n      \"artefacts\": [\n        {\n          \"name\": \"Source code method\",\n          \"details\": null\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node (Normal)\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"AST Node (Merged)\",\n          \"details\": \"Any \\\"linear\\\" sequence of nodes which form a direct chain\\nwithout other incoming edges, are merged into one.\\nThe root node cannot be part of a chain,\\nand leaf nodes cannot be part of a chain.\"\n        },\n        {\n          \"name\": \"AST Node (Aggregated)\",\n          \"details\": \"Any node aggregating _only_ a set of linear chains (length >= 1),\\nis turned into a single node combining all chains.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Next Token Edge\",\n          \"details\": \"Each token points to the next token\"\n        },\n        {\n          \"name\": \"Inverted AST Edge\",\n          \"details\": \"Inverted so all AST edges point \\\"upward\\\" towards the root node\"\n        },\n        {\n          \"name\": \"Root Edge\",\n          \"details\": \"Each leaf node has an edge pointing to the root node\"\n        }\n      ],\n      \"vertex-features\": \"Node content encoded using MPNet. Specifically;\\nNormal nodes; embedded as is \\nMerged nodes; average of all contained nodes \\nAggregated Nodes; \\\\frac{1}{k}\\\\sum_{i=1}^k\\\\left(\\\\frac{1}{n_i}\\\\sum_{j = 1}^{n_1} MPNet(T_{ij})\\\\right)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency List (directed)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gcn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN (two layers)\\nGlobal Soft Attention Layer (for Pooling)\"\n      }\n    },\n    \"gat\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GAT (two layers)\\nGlobal Soft Attention Layer (for Pooling)\"\n      }\n    },\n    \"unimp\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Unified Message Passing Model (two layers)\\nGlobal Soft Attention Layer (for Pooling)\"\n      }\n    },\n    \"armaconv\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"ARMAConv (two layers)\\nGlobal Soft Attention Layer (for Pooling)\"\n      }\n    },\n    \"res-gated-gcn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"ResGatedGCN (two layers)\\nGlobal Soft Attention Layer (for Pooling)\"\n      }\n    },\n    \"feastnet\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"FeaStNet (two layers)\\nGlobal Soft Attention Layer (for Pooling)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify graph as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify graph as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"compact-abstract-graph\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"compact-abstract-graph\",\n      \"model\": \"gat\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"compact-abstract-graph\",\n      \"model\": \"unimp\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"compact-abstract-graph\",\n      \"model\": \"armaconv\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"compact-abstract-graph\",\n      \"model\": \"res-gated-gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"compact-abstract-graph\",\n      \"model\": \"feastnet\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 105,\n  \"pdf-id\": 142,\n  \"graphs\": {\n    \"xfg\": {\n      \"name\": \"n/a\",\n      \"description\": \"Obtained from PDG through slicing based on system API calls \\nand statements containing arithmetic operations\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Dependence Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependence Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Names are normalised\\nStatements encoded using doc2vec (DM-PV)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gcn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN Layer \\nTop-k pooling layer \\np_1 = MeanPool || maxPool\\nGCN \\nTop-k pooling layer\\np_2 = MeanPool || maxPool\\np_1 + p_2 \\nMLP\\nSoftmax\"\n      }\n    },\n    \"gat\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GAT Layer \\nTop-k pooling layer \\np_1 = MeanPool || maxPool\\nGAT \\nTop-k pooling layer\\np_2 = MeanPool || maxPool\\np_1 + p_2 \\nMLP\\nSoftmax\"\n      }\n    },\n    \"k-gnn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"k-GNN Layer \\nTop-k pooling layer \\np_1 = MeanPool || maxPool\\nk-GNN \\nTop-k pooling layer\\np_2 = MeanPool || maxPool\\np_1 + p_2 \\nMLP\\nSoftmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample (slice) as vulnerable or non-vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample (slice) as vulnerable or non-vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"xfg\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": \"Experiment was repeated with multiple datasets containing different types of vulnerabilities\"\n    },\n    {\n      \"graph\": \"xfg\",\n      \"model\": \"gat\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": \"Experiment was repeated with multiple datasets containing different types of vulnerabilities\"\n    },\n    {\n      \"graph\": \"xfg\",\n      \"model\": \"k-gnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": \"Experiment was repeated with multiple datasets containing different types of vulnerabilities\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 95,\n  \"pdf-id\": 131,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"PDG enhanced with call information\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"Slicing (based on sys API calls and pointer variables) is performed to reduce the amount of nodes\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data flow (dependence) Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control flow (dependence) Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Call Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Return Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Statements in nodes encoded using doc2vec\",\n      \"edge-features\": \"Back-edges are added.\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"fs-gnn\": {\n      \"type\": {\n        \"name\": \"FS-GNN (Flow Sensitive GNN)\",\n        \"architecture\": \"Model with edge-type specific features.\\n\\nembeddings for edge type r:\\n\\nh^{\\\\ell}_r = \\\\sum_{b = 1}^B a^{\\\\ell}_{br}v^{\\\\ell}_b\\n\\nHere, $a^{\\\\ell}_{br}$ are edge-type specific learnable weights,\\nand $v^{\\\\ell}_b$ are learnable basis vectors \\n\\nNode embeddings updated according to:\\n\\nh^{\\\\ell + 1}_v = f\\\\left(\\\\sum_{(u, r) \\\\in N(v)} W^{\\\\ell}_{\\\\lambda(r)}\\\\phi(h^{\\\\ell}_u, h^{\\\\ell}_r)\\\\right)\\n\\nHere, $u$ denotes a neighbour node, and $r$ denotes the edge type.\\n$W^{\\\\ell}_{\\\\lambda(r)}$ is an edge type specific learnable weight matrix.\\n$\\\\phi$ is a composition operator (e.g. addition, subtraction, multiplication, etc.)\\n\\nDuring training, at this point, GraphSMOTE is used to generate graphs\\nwhich have a more balanced distribution of vulnerable and non-vulnerable nodes.\\n\\nsoftmax for predictions.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify each node (statement) as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Node Classification\",\n      \"working-objective\": \"Classify each node (statement) as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Node Classification\",\n      \"application\": \"(Memory related) vulnerability detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"fs-gnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 100,\n  \"pdf-id\": 136,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Mixture of AST and CFG.\\n\\nCode slicing is performed based on function calls,\\narithmetic expressions, pointer usage, and array usage.\\nSlicing was done based on control and data dependencies. \\n\\nEvery function may result into multiple code slices!\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Source code slice from function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Token\",\n          \"details\": \"Each unique token has a vertex\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Co-occurrence edge\",\n          \"details\": \"Edge between tokens if they co-occur in a sliding window of some given size\"\n        }\n      ],\n      \"vertex-features\": \"Tokens encoded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GGNN\\nFor each node, compute \\nh_v = \\\\sigma(MLP(h_v^t)) \\\\sigmoid \\\\tanh(MLP(h_v^t)) (first term serves as a soft attention mechanism)\\nh_g = \\\\frac{1}{|V|} \\\\sum_{v \\\\in V} h_v + MaxPool(V)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample (graph corresponding to slice) as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample (graph corresponding to slice) as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 116,\n  \"pdf-id\": 155,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"AST Nodes are sequenced using \\ndepth first traversal.\\n\\nFed into the following network:\\nEmbedding Layer \\nLSTM\\nLSTM \\nFNN w/ ReLU \\nFNN w/ Linear\\n\\nGoal is to predict the \\\"essential complexity\\\",\\na proxy task of predicting a metric associated \\nwith vulnerabilities. \\n\\nThe outputs of the last LSTM layer are used as \\ngraph representations.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"Random Forest\",\n        \"architecture\": \"Random Forest\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify samples as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Classification (not graph); Graph Regression\",\n      \"working-objective\": \"Classify samples as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Classification (not graph); Graph Regression\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 199,\n  \"pdf-id\": 267,\n  \"graphs\": {\n    \"tree-graph\": {\n      \"name\": \"Tree Graph\",\n      \"description\": \"Simplified version of AST\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node Type Node\",\n          \"details\": \"Every node type in the AST has _one_ node in the tree graph\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Edge\",\n          \"details\": \"There is an edge between two node types in the tree graph \\nif and only if there exists an edge between two nodes of \\nthose types in the original AST.\"\n        }\n      ],\n      \"vertex-features\": \"1) Degree Centrality\\n2) Katz Centrality \\n3) Betweenness Centrality\\n4) Eigenvector Centrality\\n5) Closeness Centrality\\n6) Harmonic Centrality\\n7) Mean Centrality: average of the six above\\n8) Concatenate Centrality: concatenation of the first six\\n\\nEach centrality measure is tested _individually_.\\nThe feature vectors (obtained by concatenating the measures \\nfor all [72] node types) for two code samples asre concatenated \\nand passed to a classifier.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"knn\": {\n      \"type\": {\n        \"name\": \"KNN\",\n        \"architecture\": \"n/a\"\n      }\n    },\n    \"dt\": {\n      \"type\": {\n        \"name\": \"Decision Tree\",\n        \"architecture\": \"n/a\"\n      }\n    },\n    \"rf\": {\n      \"type\": {\n        \"name\": \"Random Forest\",\n        \"architecture\": \"n/a\"\n      }\n    },\n    \"lr\": {\n      \"type\": {\n        \"name\": \"Logistic Regression\",\n        \"architecture\": \"n/a\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"clone-detection\": {\n      \"training-objective\": \"Determine whether the two given code samples are semantic clones\",\n      \"training-granularity\": \"Graph Classification (?)\",\n      \"working-objective\": \"Determine whether the two given code samples are semantic clones\",\n      \"working-granularity\": \"Graph Classification (?)\",\n      \"application\": \"Code Clone Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"tree-graph\",\n      \"model\": \"knn\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"tree-graph\",\n      \"model\": \"dt\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"tree-graph\",\n      \"model\": \"rf\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"tree-graph\",\n      \"model\": \"lr\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 134,\n  \"pdf-id\": 177,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"The information in a node is divided into three \\\"perspectives\\\":\\nPerspective 0: node type    (e.g. \\\"MethodDeclaration\\\")  \\nPerspective 1: Node value   (e.g. Method name)\\nPerspective 2: Additional Information (e.g. Method visibility)\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Literals are generalised. \\nNames are split up based on camel case naming,\\nregardless of perspective.\\n\\nAn unsupervised training procedure is used to encode node types.\\nThe training is essentially equivalent to word2vec training \\n(with negative sampling), but the neighbourhood of tokens is \\ndetermine using certain structural patterns in the AST.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"First, node features are computed. \\nThen, all node embeddings are put into a linear sequence to obtain a matrix.\"\n    }\n  },\n  \"models\": {\n    \"network\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Conv (2d)\\nMax pooling \\nFNN\\nSigmoid\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"bug-detection\": {\n      \"training-objective\": \"Classify sample as buggy or clean\",\n      \"training-granularity\": \"\\\\\\\"Graph\\\\\\\" Classification\",\n      \"working-objective\": \"Classify sample as buggy or clean\",\n      \"working-granularity\": \"\\\\\\\"Graph\\\\\\\" Classification\",\n      \"application\": \"Software Defect Prediction\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"network\",\n      \"task\": \"bug-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 26,\n  \"pdf-id\": 39,\n  \"graphs\": {\n    \"pdg\": {\n      \"name\": \"Program Dependency Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"PDG Node\",\n          \"details\": \"Nodes are created for AST nodes containing \\n1) method calls\\n2) assignment\\n3) control statements \\n4) declarations \\n5) API field access \\n\\nFurthermore, every node involving a type has the type name fully expanded (e.g. java.lang.String)\"\n        },\n        {\n          \"name\": \"Hole\",\n          \"details\": \"Node in the graph for which a type must be predicted.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"PDG Edge\",\n          \"details\": \"Both data and control flow edges\"\n        },\n        {\n          \"name\": \"Prediction Flow Dependency Edge\",\n          \"details\": \"Edge from a node in the PDF to the hole\"\n        }\n      ],\n      \"vertex-features\": \"n/a (embedding layer)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Textual elements are extracted. Specifically:\\n1) The name of the method in which a prediction is made. Compound name (e.g. getFileLine) are split into individual words.\\n2) All (full) names of all API classes used in the method\\n3) Variable Names\"\n    }\n  },\n  \"models\": {\n    \"gat\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Double model setup. A graph embedding is learned using a GAT network.\\n\\nThe textual elements are encoded using an LSTM network, to obtain\\nthree separate vectors which are concatenated.\\n\\nThe textual and structural embeddings are fused and fed into a MLP.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"api-recommendation\": {\n      \"training-objective\": \"Given a method with a hole node, predict the API to be used in the hole node\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a method with a hole node, predict the API to be used in the hole node\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"API recommendation\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"gat\",\n      \"task\": \"api recommendation\",\n      \"comments\": \"Although the hole is a node, the full graph is embedded; this is not node prediction.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 47,\n  \"pdf-id\": 67,\n  \"graphs\": {\n    \"user-file-interaction-graph\": {\n      \"name\": \"User-file interaction graph\",\n      \"description\": \"Models interactions between users and files in open source systems.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Contributor Data\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Source Code File\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"User\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Contributed to\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Vertex features are initialised with user embeddings for users,\\nand the structure-enhanced file representations for source files.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"The source code of files is partitioned into N_C code segments,\\nwhich are encoded using CodeBERT.\\n\\nA number N_Q of historical users are sampled and encoded.\\n\\nFor every file, the code segments (C) and users (U) are used \\nto compute (and learn) attention weights h, which are used \\nto compute the _file attention representation_ h = a^T C\"\n    },\n    \"user-repository-interaction-graph\": {\n      \"name\": \"User-project interaction graph\",\n      \"description\": \"Models interactions between users and projects in open source systems.\\n\\nNote that multiple such graphs may exists based on multiple \\ninteraction types (\\\"behaviours\\\").\",\n      \"artefacts\": [\n        {\n          \"name\": \"Repository\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Contributor Data\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Repository\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"User\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Contributed to\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Vertex features are initialised with user embeddings for users,\\nand the structure-enhanced repository representations for projects.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"repository-graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Graph representation of repositories\",\n      \"artefacts\": [\n        {\n          \"name\": \"Repository\",\n          \"details\": \"Source files, directories, repository information\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Source File\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Directory\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Repository\",\n          \"details\": \"Used as \\\"root\\\" node\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"n/a (Parent)\",\n          \"details\": \"Each node (e.g. file) is connected to its parent. \\nTop-level nodes are connected to the repository nodes.\"\n        }\n      ],\n      \"vertex-features\": \"Files use the file attention representation based on the \\nuser-file interaction graph.\\n\\nFor directories, their names are split up into words,\\nwhich are encoded using TF-IDF.\\n\\nRepository features are obtained by combining\\nproject owners, creation timestamps, and top 5 \\nprogramming languages.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"structural-features\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Uses vertex features from Graph representation of repositories        \\n\\nA 3 layer GAT is used to learn _structure-enhanced node representations_\"\n      }\n    },\n    \"user-files\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Uses vertex features from user-file graphs \\n\\nLightGCN is used to compute higher order embeddings.\\n\\nFor each node, the embeddings for each layer (including initial embeddings)\\n  are averaged to obtain the final embeddings.\"\n      }\n    },\n    \"user-projects\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Uses vertex features from user-projects graphs \\n\\nLightGCN is used to compute higher order embeddings.\\n\\nFor each node, the embeddings for each layer (including initial embeddings)\\nare averaged to obtain the final embeddings.\"\n      }\n    },\n    \"prediction-file\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Aggregate the user embeddings from all user/project graphs over all behaviours for every user i; call this z_i*\\n2) Aggregate the repository embeddings from all repository graphs over all behaviours for every project i; call this r_i*\\n3) Compute u_i = MLP(u_i^* \\\\mid\\\\mid z*), where u_i^* is the final user embedding from the user/file graph.\\n4) Compute v_j = MLP(v_j^* \\\\mid\\\\mid r_{\\\\phi(j)}*), \\n    where v_j^* is the final file embedding from the user/file graph,\\n    and r_{\\\\phi(j)}* the aggregated embedding (step 2) from the project file v_j belongs to.\\n5) Compute user/file affinity score s_F(i, j) = u_i^Tv_j\"\n      }\n    },\n    \"prediction-project\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Compute user/project affinity score s_P(i, j, t) = z_{i,t}^Tr_{j,t}\\n\\n(See prediction-file for variable meaning)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"recommendation\": {\n      \"training-objective\": \"Compute affinity scores between users and files/repositories,\\nwhile minimising the BPR loss, as well as a contrastive loss\",\n      \"training-granularity\": \"Node embedding / score optimisation\",\n      \"working-objective\": \"Compute affinity scores between users and files/repositories\",\n      \"working-granularity\": \"Node embedding / score optimisation\",\n      \"application\": \"Three applications:\\n1) Recommend files for a developer to work on (in the same project)\\n2) Recommend other projects for a developer to work on (cross project recommendation)\\n3) Recommend files for new developers to work on (cold start recommendation )\",\n      \"supervision\": \"Supervised (somewhat)\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"user-file-interaction-graph + user-repositories-interaction-graph + repository-graph\",\n      \"model\": \"structural-features + user-files + user-projects + prediction\",\n      \"task\": \"recommendation\",\n      \"comments\": \"The tricky thing here is that there are many components which are all combined into \\na single object when training; all trainable components seem to be combined into \\na single network. Additionally, the model is optimised for all tasks at once,\\nwith the loss function having both contrastive and affinity scoring \\ncomponents.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 201,\n  \"pdf-id\": 269,\n  \"graphs\": {\n    \"fc-pdg\": {\n      \"name\": \"Fused Clone PDG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Code Clone Source Code\",\n          \"details\": \"For a given pair of code clones, where one has been modified,\\nthree artefacts are used:\\n1) Original code of the changed clone \\n2) Modified code of the changed clone\\n3) Code of the other clone\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"Every node has a triple-vector (Existence Vector), \\nindicating whether that node is present in the PDG \\nof every included code snippet.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Dependence Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependence Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Execution Edge\",\n          \"details\": \"Represent order of node execution\"\n        },\n        {\n          \"name\": \"Mapping Edge\",\n          \"details\": \"Edge connecting two \\\"corresponding\\\" nodes originating from the PDGs of two code snippets,\\nbut which do not contain the exact same statement\"\n        }\n      ],\n      \"vertex-features\": \"Code encoded using CodeBERT; vector concatenated with the existence vector\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"RGCN\\nMean Pooling \\nFNN w/ Softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"propagation-prediction\": {\n      \"training-objective\": \"Given a sample (code clone pair), determine whether the clones are propagation-required or propagation-free\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given a sample (code clone pair), determine whether the clones are propagation-required or propagation-free\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Change Propagation Requirement Prediction (i.e. given a change, determine whether changes in one clone must be propagated to the other)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"fc-pdf\",\n      \"model\": \"model\",\n      \"task\": \"propagation-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 210,\n  \"pdf-id\": 280,\n  \"graphs\": {\n    \"line-graph\": {\n      \"name\": \"Line Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"Smart Contracts\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Line\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Function Edge\",\n          \"details\": \"Connect first and last lines of function declaration\"\n        },\n        {\n          \"name\": \"Control Edge\",\n          \"details\": \"end to end connections between control blocks (if/for/while)\"\n        },\n        {\n          \"name\": \"Sequential Edge\",\n          \"details\": \"Connect lines in top to bottom order\"\n        },\n        {\n          \"name\": \"Variable Edge\",\n          \"details\": \"Connect nodes containing the same variables\"\n        },\n        {\n          \"name\": \"Modifier Edge\",\n          \"details\": \"connect definitions of modifiers to their corresponding uses\"\n        },\n        {\n          \"name\": \"Reentrancy Edge\",\n          \"details\": \"Connect nodes contain \\\"call.value\\\" to all other nodes belonging to the same function\"\n        }\n      ],\n      \"vertex-features\": \"Text content of every line is used as feature (after preprocessing; normalisation of identifiers etc)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not explicitly specified, but seems to be 6 adjacency matrices\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Modified Transformer Encoder Architecture\\n  If the original transformer is expressed as \\n\\n    e_{ij} = \\\\frac{(x_iW_Q)(x_jW_K)^T)}{\\\\sqrt{d}}\\n    a_{ij} = softmax_j(e_{ij})\\n    z_i = \\\\sum_{j = 1}^n a_{ij}(x_jW^v)\\n\\n  Then it is now modified to become \\n\\n    g_p = EmbeddingLayer(edge type p)W_p + c_p \\n    b_{ij} = \\\\sum_{k = 1}^6 k_p * g_p (k_p: indicator whether there is an edge of type p between i and j)\\n    e_{ij} = \\\\frac{(x_iW_Q)(x_jW_K)^T)}{\\\\sqrt{d}} + b_{ij}\\n    a_{ij} = softmax_j(e_{ij})\\n    z_i = (\\\\sum_{j = 1}^n a_{ij}(x_jW^v)) \\\\odot (x_iW_R)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Given a sample, classify it as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Classification\",\n      \"working-objective\": \"Given a sample, classify it as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Classification\",\n      \"application\": \"Vulnerability Detection in Smart Contracts\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"line-graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 197,\n  \"pdf-id\": 262,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Mix of AST, CFG, DF G\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"file\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Input: pair of code graphs \\n\\n1) GCN (each graph individually) \\n2) Attention to compute weighted average of node embeddings for each graph\\n3) Both resulting features are both passed to \\n    i) Graph Matching Network\\n    ii) Pairwise Node Comparison \\n4) Results are added\\n5) FNN (output: similarity score)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"clone-detection\": {\n      \"training-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"training-granularity\": \"Graph Classification (?)\",\n      \"working-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"working-granularity\": \"Graph Classification (?)\",\n      \"application\": \"Code Clone Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 104,\n  \"pdf-id\": 141,\n  \"graphs\": {\n    \"not-ast\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Variable names are normalised.\\nNode payload embedded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Discrete Fourier Transform applied to features \\nGIN (Graph Isomorphism Network)\\nSelf-Attention \\nAttention-weighted sum pooling of node embeddings\\nFNN\\nDropout\\nFNN \\nSoftmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify samples as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify samples as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"not-ast\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": \"Graph description unclear. There may be other edge types in addition to the ones listed.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 146,\n  \"pdf-id\": 195,\n  \"graphs\": {\n    \"hsg\": {\n      \"name\": \"Heterogeneous Syntax Graph\",\n      \"description\": \"AST with explicitly heterogeneous edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Some nodes (e.g. \\\"Block\\\") are removed to reduce tree size\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Child Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"AST Parent Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"AST Left Sibling Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"AST Right Sibling Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Next Data Flow Node Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Previous Data Flow Node Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Previous Leaf Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Next Leaf Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Identifiers in nodes are split up\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"The goal of the model is to predict the next token in the summary.\\nAs such, the summary generated thus far is also an input.\"\n    }\n  },\n  \"models\": {\n    \"het-cos\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"0) Embedding Layers for summary tokens and nodes \\n1) Graph Encoder:\\n  i) Heterogeneous GraphSAGE (see 145.yaml)\\n  ii) Concatenate node embeddings \\n  iii) ReLU\\n  iv) Residual Connection + Normalisation  (and then outputted is a node embedding matrix)\\n2) Summary Decoder\\n  i) Masked multi-head self-attention w/ residual connection and layer normalisation \\n  ii) Multi-head attention (decoding over learned nodes) w/ residual connection and layer normalisation\\n  iii) FNN w/ residual connection and layer normalisation\\n3) multi-head attention based copying mechanism \\n  i) for the m-th output token with decoder output e,\\n      compute p_v = Softmax(Linear(e))\\n  ii) Multi-head attention over e and graph encoder output to derive p_n\\n  iii) Compute weighted sum of p_v and p_n\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"training-granularity\": \"Graph to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"working-granularity\": \"Graph to Sequence\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"hsg\",\n      \"model\": \"het-cos\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 13,\n  \"pdf-id\": 21,\n  \"graphs\": {\n    \"fast\": {\n      \"name\": \"FAST (Flow of Abstract Syntax Tree)\",\n      \"description\": \"Hybrid of control flow graph, call graph, and abstract syntax tree\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Basic Block\",\n          \"details\": \"Extracted from the AST. \\n\\nEach block represents a control flow transfer.\\nSlightly more course-grained than the control flow graph,\\nbecause e.g. assignment statements do not have dedicated nodes.\"\n        },\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Intra-procedural Edge\",\n          \"details\": \"Represents control flow between basic block.\\n\\nA Basis block points to every basic block that may follow it.\"\n        },\n        {\n          \"name\": \"Inter-procedural Edge\",\n          \"details\": \"Comes in two types: Call Edge and Return Edge.\\n\\nCall Edge: Edge from a basic block calling a function, to the \\n            first block (\\\"start block\\\") of the called function.\\n\\nReturn Edge: Edge from a basic block returning from a function, \\n        to the basic block in that called the function.\"\n        },\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Block/AST Edge\",\n          \"details\": \"Edge connecting a basic block to an AST node. \\nUnclear whether this is actually considered as a different \\ntype of edge by the authors. \\nAnyway, connects a basic block to the sub-tree of the AST \\n\\\"contained\\\" in said block.\"\n        }\n      ],\n      \"vertex-features\": \"AST nodes are embedded using Word2Vec\\n\\nSpecifically, for non-leave nodes, the type is encoded (no payload);\\nLeave nodes have no type but have a payload (token) that is encoded.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Per block, a log message is assumed to be given. \\nEvery word in the message is embedded using Word2Vec.\\nA final feature vector is obtained through averaging all these embeddings.\"\n    }\n  },\n  \"models\": {\n    \"tell-sigmoid\": {\n      \"type\": {\n        \"name\": \"TELL\",\n        \"architecture\": \"Let CONCAT(n; s_1, s_2, ...) denote model from paper 6, without the max-pooling operation \\nused to combine multiple node embeddings into a single graph embedding,\\nwith the GCN/concat step applied n times, where each layer i has hidden size s_i.\\n\\nFirst, for every block, its AST is embedded into a graph by\\ncombining the CONCAT(2; 64, 32) network with an average pooling operation over all nodes.\\n\\nNext, the CONCAT(3; 64, 32, 16) model is used without pooling to compute embeddings\\nfor all basic blocks, where the initial embedding for each basic block\\nis the embedding for each AST.\\n\\nThen, for every block i with node embedding h_i^* and \\nlog message embedding q_i, the predicted log level is given by \\n\\ny = sigmoid((h_^* W_t \\\\mid\\\\mid q_i W_p)W_f + b_f)\\n\\nHere, W_t and W_p are weights which transform their\\n\\\"input\\\" vectors to d-dimensional space. W_f transforms the \\nconcatenated 2d-dimensional vector to 5 dimensional space.\\n\\nNote: labels are encoded on an \\\"ordinal\\\" scale like\\n[1, 0, 0, 0, 0], [1, 1, 0, 0, 0], [1, 1, 1, 0, 0] etc\"\n      }\n    },\n    \"tell-softmax\": {\n      \"type\": {\n        \"name\": \"TELL\",\n        \"architecture\": \"Let CONCAT(n; s_1, s_2, ...) denote model from paper 6, without the max-pooling operation \\nused to combine multiple node embeddings into a single graph embedding,\\nwith the GCN/concat step applied n times, where each layer i has hidden size s_i.\\n\\nFirst, for every block, its AST is embedded into a graph by\\ncombining the CONCAT(2; 64, 32) network with an average pooling operation over all nodes.\\n\\nNext, the CONCAT(3; 64, 32, 16) model is used without pooling to compute embeddings\\nfor all basic blocks, where the initial embedding for each basic block\\nis the embedding for each AST.\\n\\nThen, for every block i with node embedding h_i^* and \\nlog message embedding q_i, the predicted log level is given by \\n\\ny = softmax((h_^* W_t \\\\mid\\\\mid q_i W_p)W_f + b_f)\\n\\nHere, W_t and W_p are weights which transform their\\n\\\"input\\\" vectors to d-dimensional space. W_f transforms the \\nconcatenated 2d-dimensional vector to 5 dimensional space.\\n\\nNote: labels are one-hot encoded\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"training-objective\": {\n      \"training-objective\": \"For every code block, predict a log level (trace/debug/info/warn/error)\",\n      \"training-granularity\": \"Node Classification (not quite, because of the additional information in the last step, but close enough)\",\n      \"working-objective\": \"For every code block, predict a log level (trace/debug/info/warn/error)\",\n      \"working-granularity\": \"Node Classification (not quite, because of the additional information in the last step, but close enough)\",\n      \"application\": \"Log level prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"training\": {\n    \"training\": {\n      \"train-test-split\": {\n        \"train\": 0.6,\n        \"test\": 0.2,\n        \"validation\": 0.2\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"loss\",\n          \"value\": \"binary cross-entropy\"\n        },\n        {\n          \"name\": \"optimizer\",\n          \"value\": \"adam\"\n        },\n        {\n          \"name\": \"epochs\",\n          \"value\": 100\n        },\n        {\n          \"name\": \"batch size\",\n          \"value\": 16\n        },\n        {\n          \"name\": \"dropout\",\n          \"value\": 0.2\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.1\n        },\n        {\n          \"name\": \"(initial) embedding size (d) (for AST _and_ tokens)\",\n          \"value\": 64\n        }\n      ],\n      \"hyper-parameter-selection\": \"grid search\",\n      \"search-tuned-hyper-parameters\": [\n        \"learning rate\",\n        \"(initial) embedding size (d) (for AST _and_ tokens)\",\n        \"number of GCN layers\"\n      ],\n      \"evaluation-details\": \"For sigmoidal activation, the \\\"highest\\\" 1 in the output was \\nused as the predicted log level.\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"auc\",\n          \"type\": \"metric\",\n          \"details\": \"area under curve\"\n        },\n        {\n          \"name\": \"AOD\",\n          \"type\": \"metric\",\n          \"details\": \"average ordinal distance score\"\n        },\n        {\n          \"name\": \"accuracy\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        }\n      ]\n    }\n  },\n  \"datasets\": {\n    \"cassandra\": {\n      \"name\": \"n/a\",\n      \"description\": \"Dataset of logged blocks from the Cassandra project.\",\n      \"source\": [\n        \"Cassandra\"\n      ],\n      \"labelling\": \"Automatic by parsing code\",\n      \"size\": 1317,\n      \"is-pre-existing\": false\n    },\n    \"elastic-search\": {\n      \"name\": \"n/a\",\n      \"description\": \"Dataset of logged blocks from the ElasticSearch project.\",\n      \"source\": [\n        \"ElasticSearch\"\n      ],\n      \"labelling\": \"Automatic by parsing code\",\n      \"size\": 5363,\n      \"is-pre-existing\": false\n    },\n    \"flink\": {\n      \"name\": \"n/a\",\n      \"description\": \"Dataset of logged blocks from the Flink project.\",\n      \"source\": [\n        \"Flink\"\n      ],\n      \"labelling\": \"Automatic by parsing code\",\n      \"size\": 2475,\n      \"is-pre-existing\": false\n    },\n    \"hbase\": {\n      \"name\": \"n/a\",\n      \"description\": \"Dataset of logged blocks from the HBase project.\",\n      \"source\": [\n        \"HBase\"\n      ],\n      \"labelling\": \"Automatic by parsing code\",\n      \"size\": 5146,\n      \"is-pre-existing\": false\n    },\n    \"jmeter\": {\n      \"name\": \"n/a\",\n      \"description\": \"Dataset of logged blocks from the JMeter project.\",\n      \"source\": [\n        \"JMeter\"\n      ],\n      \"labelling\": \"Automatic by parsing code\",\n      \"size\": 1762,\n      \"is-pre-existing\": false\n    },\n    \"kafka\": {\n      \"name\": \"n/a\",\n      \"description\": \"Dataset of logged blocks from the Kafka project.\",\n      \"source\": [\n        \"Kafka\"\n      ],\n      \"labelling\": \"Automatic by parsing code\",\n      \"size\": 1426,\n      \"is-pre-existing\": false\n    },\n    \"karaf\": {\n      \"name\": \"n/a\",\n      \"description\": \"Dataset of logged blocks from the Karaf project.\",\n      \"source\": [\n        \"Karaf\"\n      ],\n      \"labelling\": \"Automatic by parsing code\",\n      \"size\": 698,\n      \"is-pre-existing\": false\n    },\n    \"wicket\": {\n      \"name\": \"n/a\",\n      \"description\": \"Dataset of logged blocks from the Wicket project.\",\n      \"source\": [\n        \"Wicket\"\n      ],\n      \"labelling\": \"Automatic by parsing code\",\n      \"size\": 408,\n      \"is-pre-existing\": false\n    },\n    \"zookeeper\": {\n      \"name\": \"n/a\",\n      \"description\": \"Dataset of logged blocks from the ZooKeeper project.\",\n      \"source\": [\n        \"ZooKeeper\"\n      ],\n      \"labelling\": \"Automatic by parsing code\",\n      \"size\": 1496,\n      \"is-pre-existing\": false\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-sigmoid\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"cassandra\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-sigmoid\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"elastic-search\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-sigmoid\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"flink\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-sigmoid\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"hbase\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-sigmoid\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"jmeter\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-sigmoid\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"kafka\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-sigmoid\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"karaf\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-sigmoid\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"wicket\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-sigmoid\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"zookeeper\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-softmax\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"cassandra\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-softmax\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"elastic-search\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-softmax\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"flink\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-softmax\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"hbase\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-softmax\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"jmeter\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-softmax\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"kafka\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-softmax\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"karaf\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-softmax\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"wicket\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fast\",\n      \"model\": \"tell-softmax\",\n      \"task\": \"training-objective\",\n      \"training\": \"training\",\n      \"dataset\": \"zookeeper\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 153,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST with additional edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Next Subtree Edge\",\n          \"details\": \"Connects node on the same level\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Not specified\",\n      \"edge-features\": \"Edge type\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Source code is used as input\\n\\nCode summary generated thus far is used as input.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Source code encoder -- Based on Transformer\\n  i) Multi-head self-attention with relative positional encoding w/ residual connection and normalisation \\n    Multi-head attention details:\\n      Q = XW_q, K = XW_k, V = XW_v\\n      R_{t - j} = [..., sin((t - j)/1000^{2i/d_k})cos((t - j)/1000^{2i/d_k}), ...]^T\\n      A^{rel}_{t,j} = Q_t^TK_j + Q_t^TR_{t - j} + u^TK_j + v^TR_{t - j}\\n      attention(Q, K, V) = softmax(A^{rel})V_j\\n  \\n      t: index of target token\\n      j: index of context token \\n      u, v: learnable parameters \\n      R: relative positional encoding \\n  \\n      A_n = A^{rel} / sqrt(d_k) + A_{n - 1}\\n      head_n = softmax(A_n)V_n\\n      concat(head_1, head_2, ..., head_n)W_o\\n  ii) FNN w/ residual connection and normalisation\\n2) Graph Encoder \\n  i) Heterogeneous GAT (HGAT) w/ (pre-activation) residual connections.\\n      Note that the residual connection effectively passes through a linear layer.\\n      The attention scores also have residual connections \\n3) Feature fusion\\n  i) H' = MultiHeadAttention(H_{text}, K_M, V_M)  (where K_M, V_M come from the graph encoder)\\n  ii) l = \\\\sigma(W*H' + U*H)      (gate)\\n  iii) F = H + l*H'\\n4) Decoder\\n  i) code summary thus far is inputted into masked multi-head self-attention w/ residual connections and normalisation\\n  ii) multi-head attention w/ residual connections and normalisation\\n      K and Q are obtained from feature fusion\\n  iii) FNN w/ residual connections and normalisation\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"training-granularity\": \"Graph + Sequence to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"working-granularity\": \"Graph + Sequence to Sequence\",\n      \"application\": \"Code summarization (Generating comments for Python code)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": \"Missing details about 1) features for graph, and 2) output of the network\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 185,\n  \"pdf-id\": 242,\n  \"graphs\": {\n    \"sfg\": {\n      \"name\": \"Semantic Flow Graph (SFG)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Changesets (for bug localisation)\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Variable Node\",\n          \"details\": \"One for every _occurrence_ of a variable in the source code.\"\n        },\n        {\n          \"name\": \"Control Instruction Node\",\n          \"details\": \"For control structures such as if (if would have IfCondition, IfThen, IfElse, IfConverge)\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Sequential Computation Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Mask matrix for attention\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"1) Comment Input Sequence\\n    A (doc) comment associated with the source code, as tokens, beginning with the classification token [CLS]\\n2) Source Code Input Sequence\\n    [C] Cleaned source code tokens [SEP]\\n3) Node List \\n    [N] List of nodes \\n4) Type List \\n    [T] Type information of nodes -- out of list of 55 possible types \\n5) Role List \\n  [R] Role information of nodes -- out of list of 43 possible roles [SEP]\\n\\nFor bug localisation, the bug report is also given as feature\"\n    }\n  },\n  \"models\": {\n    \"semantic-code-bert\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Transformer encoder w/ Graph-guided masked attention (as in GraphCodeBERT)\"\n      }\n    },\n    \"fault-localization-model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Bug report encoded using BERT -> q_feature \\n2) Code sample encoded using SemanticCodeBERT (semantic-code-bert model) -> c_feature\\n3) Apply MLP:\\n  q_model = MLP(q_feature)  (where MLP has batch normalisation)\\n  c_model = MLP(c_feature)  (where MLP has batch normalisation)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"masked-language-modelling\": {\n      \"training-objective\": \"Given an input with masked source code tokens, predict the tokens in the masked spots\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Model pre-training\",\n      \"supervision\": \"Self-supervised / Unsupervised\"\n    },\n    \"node-alignment\": {\n      \"training-objective\": \"Given an input with masked edges, predict the masked edges\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Model pre-training\",\n      \"supervision\": \"Self-supervised / Unsupervised\"\n    },\n    \"type-prediction\": {\n      \"training-objective\": \"Given an input with masked node type information, predict the links between nodes and their types\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Model pre-training\",\n      \"supervision\": \"Self-supervised / Unsupervised\"\n    },\n    \"role-prediction\": {\n      \"training-objective\": \"Given an input with masked node role information, predict the links between nodes and their roles\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Model pre-training\",\n      \"supervision\": \"Self-supervised / Unsupervised\"\n    },\n    \"fault-localisation\": {\n      \"training-objective\": \"Given an input bug report and changeset, compute feature vectors such that\\n  1) For positive (report, changeset pairs) (i.e. changeset introduced the bug),\\n      the cosine similarity between q_model and c_model is maximised \\n  2) For negative (report, changeset pairs) (i.e. changeset did not introduce the bug),\\n      the cosine similarity between q_model and c_model is minimised\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Encode bug reports and changesets for similarity comparison\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Fault Localisation\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"sfg\",\n      \"model\": \"semantic-code-bert + fault-localization-model\",\n      \"task\": \"masked-language-modelling + node-alignment + type-prediction + role-prediction + fault-localisation\",\n      \"comments\": \"The four pre-training tasks are used to pre-train the model, which is then used for fault localisation.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 216,\n  \"pdf-id\": 286,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"smart contract\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"AST is normalised (normalise identifiers), serialized (depth first order), and encoded using word2vec\"\n    },\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"smart contract\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Basic Block  (statement)\",\n          \"details\": \"consecutive operations without jump\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Encode statements using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) AST passed through TextCNN\\n2) CFG passed through GCN\\n3) Pooling after GCN is done but not explicitly specified\\n4) AST and GCN embeddings are concatenated \\n5) Presumable MLP\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Given a sample, classify it as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification (but w/ multiple graphs)\",\n      \"working-objective\": \"Given a sample, classify it as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification (but w/ multiple graphs)\",\n      \"application\": \"Vulnerability Detection in Smart Contracts\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": null,\n      \"model\": null,\n      \"task\": null,\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 84,\n  \"pdf-id\": 116,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Mix of AST and CFG\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Javascript\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Ast Edge\",\n          \"details\": \"Directed\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Node content is split up into \\\"words\\\", and embedded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Taint analysis is applied to the program. \\nResulting sub-program text is split up into \\\"words\\\" and embedded using word2vec,\\nand put into a sequence of vectors\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Dual input model:\\n1) Graph Input\\n  GCN\\n  Graph embedding computed according to \\n    h_G = \\\\frac{1}{|v|}\\\\left(p\\\\sum_{v \\\\in V_s} h_v + q\\\\sum_{v \\\\in V \\\\setminus V_s} h_v\\\\right)\\n    Where V_s is the subset of nodes detected to contain sensitive function call or output,\\n    and p and q are weighs.\\n\\n2) Code Sequence Input\\n  Bidirectional LSTM\\n  Dropout Layer\\n  Self-attention Layer\\n  FNN Layer \\n  Normalisation Layer \\n\\nResulting embeddings are concatenated and passed through MLP\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"xss-detecting\": {\n      \"training-objective\": \"Classify code sample as safe or not\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify code sample as safe or not\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"XSS Detection in JavaScript\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"xss-detecting\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 78,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"co-occurrence-graph\": {\n      \"name\": \"Co-occurrence Graph\",\n      \"description\": null,\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Source code is first sliced based data (parameters)\\npassed to \\\"dangerous\\\" functions.\\nNames are standardised.\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Token in snippet\",\n          \"details\": \"Every unique token gets a single node\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Edge\",\n          \"details\": \"Every token is connected to every other token that \\noccurs within 2 tokens of itself in the \\noriginal source code.\"\n        }\n      ],\n      \"vertex-features\": \"Tokens are embedded using a word embedding (not further specified)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Pointwise mutual information between different tokens is computed\\nto compute up with a weighted adjacency matrix.\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Tokens are embedded using a word embedding (not further specified),\\nin sequence as input for the GRU model\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Network has two inputs; 1) token input is passed to bidirectional GRU layer, followed by an attention layer. 2) The graph is passed to a GGNN, followed by a readout layer. The readout is performed as follows; x_v = \\\\sigma(attention(h_v) \\\\cdot \\\\tanh(f(h_v)) h_G = \\\\sum_{v \\\\in V} x_v \\\\cdot Maxpool(x_v)\\nHere, f is a nonlinear transformation.\\nOutputs of input models are concatenated, then passed to a dense layer, then passed to softmax.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify graph as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify graph as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"co-occurrence-graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 3,\n  \"pdf-id\": 6,\n  \"graphs\": {\n    \"syntactic-dependency-parse\": {\n      \"name\": \"n/a\",\n      \"description\": \"Based on syntactic dependency parsing from NLP\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code (methods)\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST leaf nodes\",\n          \"details\": \"During evaluation, tokens in the leaf nodes were lowered,\\nnon-identifier tokens were removed, and rare tokens were \\nalso removed, thus reducing the number of nodes present \\nin the final graph.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"n/a\",\n          \"details\": \"For every (source, target) pair (v1, v2) of AST nodes, \\nfind the least common ancestor of v1 and v2 in the AST.\\nThe edge label is given by \\n1) taking every node in the path from v1 to the ancestor,\\n  and adding an \\\"up\\\" arrow after every node type name\\n2) Taking every node in the path from the ancestor to v2,\\n  and adding an \\\"down\\\" arrow after every node type name\\n3) Concatenating all nodes in the path (as described above)\\n  using \\\"-\\\" symbols.\\n\\nIf the path is longer than some threshold, it is ignored.\\nOtherwise, the edge is present in the final graph.\"\n        }\n      ],\n      \"vertex-features\": \"Not specified, nor specified how vertex features are initialised\",\n      \"edge-features\": \"Not specified\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"GCN\",\n        \"architecture\": \"Spatial GCN layer (size 128) with edge-wise gating.\\n\\nGCN output is defined as:\\n\\nh_{w_t}^\\\\ell = f\\\\left(\\\\sum_{w_c \\\\in C_{w_t} g^\\\\ell_{e_{w_c,w_t}} \\\\times \\\\left(W^\\\\ell_{e_{w_c,w_t}} h^\\\\ell_{w_c} + b^\\\\ell_{e_{w_c,w_t}}\\\\right)\\\\right)\\n\\nWhere g is the edge-wise gating (assigning weight to edges), defined as \\n\\ng^\\\\ell_{e_{w_c,w_t}} = \\\\sigma\\\\left(W^\\\\ell_{e_{w_c,w_t}} h^\\\\ell_{w_c} + b^\\\\ell_{e_{w_c,w_t}}\\\\right)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"embedding\": {\n      \"training-objective\": \"Given the context tokens (neighbour tokens), predict the target token.\",\n      \"training-granularity\": \"Node Embedding\",\n      \"working-objective\": \"Given a token, compute an embedding\",\n      \"working-granularity\": \"Node Embedding\",\n      \"application\": \"Task-agnostic code embedding (e.g. average of sum token embeddings to compute embedding for snippet)\",\n      \"supervision\": \"unsupervised (self-supervised)\"\n    }\n  },\n  \"training\": {\n    \"training\": {\n      \"train-test-split\": \"n/a\",\n      \"cross-validation\": \"n/a\",\n      \"hyper-parameters\": [\n        {\n          \"name\": \"epochs\",\n          \"value\": 1\n        },\n        {\n          \"name\": \"loss\",\n          \"value\": \"\\\\sum_{w_t \\\\in V} \\\\log P(w_t \\\\mid C_{w_t}) \\n  \\nwhere\\n\\nP(w_t \\\\mid C_{w_t}) = \\\\frac{\\\\exp(v_{w_t}^T h_{w_t}}{\\\\sum_{w_t' \\\\in V} \\\\exp(v_{w_t'}^T h_{w_t'})}\\n  \\nwhere v is the target embedding (and h the hidden representation)\"\n        },\n        {\n          \"name\": \"max edge path length\",\n          \"value\": 8\n        },\n        {\n          \"name\": \"max number of nodes in graph\",\n          \"value\": 100\n        },\n        {\n          \"name\": \"max number of edges in graph\",\n          \"value\": 800\n        },\n        {\n          \"name\": \"window (maximum distance between current token and neighbour tokens)\",\n          \"value\": 5\n        },\n        {\n          \"name\": \"batch size\",\n          \"value\": 64\n        },\n        {\n          \"name\": \"dropout\",\n          \"value\": 0\n        },\n        {\n          \"name\": \"neg (number of negative samples used when updating the weights of the model)\",\n          \"value\": 5\n        }\n      ],\n      \"hyper-parameter-selection\": \"epochs based on literature\",\n      \"search-tuned-hyper-parameters\": \"n/a\",\n      \"evaluation-details\": \"Evaluate on six downstream tasks.\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"code comment generation\",\n          \"type\": \"downstream task\",\n          \"details\": \"Using a neural network, evaluated using 10-fold cross validation.\"\n        },\n        {\n          \"name\": \"code authorship identification\",\n          \"type\": \"downstream task\",\n          \"details\": \"Using a neural network, evaluated using 10-fold cross validation.\"\n        },\n        {\n          \"name\": \"code clone detection\",\n          \"type\": \"downstream task\",\n          \"details\": \"Using a neural network, evaluated using 10-fold cross validation.\"\n        },\n        {\n          \"name\": \"source code classification\",\n          \"type\": \"downstream task\",\n          \"details\": \"Using a neural network, evaluated using 10-fold cross validation.\"\n        },\n        {\n          \"name\": \"logging statement prediction\",\n          \"type\": \"downstream task\",\n          \"details\": \"Using a neural network, evaluated using 10-fold cross validation.\"\n        },\n        {\n          \"name\": \"software defect prediction\",\n          \"type\": \"downstream task\",\n          \"details\": \"Using logistic regression, evaluated using 10-fold cross validation.\"\n        }\n      ]\n    }\n  },\n  \"datasets\": {\n    \"java-small\": {\n      \"name\": \"Java-small\",\n      \"description\": \"Dataset of Java method snippets.\\n\\nInitially contained 665115 samples,\\nbut ones with too large graphs were removed.\",\n      \"source\": [\n        \"Open source Github projects\"\n      ],\n      \"labelling\": \"n/a\",\n      \"size\": 637108,\n      \"is-pre-existing\": true\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"syntactic-dependency-parse\",\n      \"model\": \"model\",\n      \"task\": \"embedding\",\n      \"training\": \"training\",\n      \"dataset\": \"java-small\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": [\n    \"Loss function is unclear; what are the target embeddings? Also, why does it depend on all nodes (V) and now C_{w_t}?\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 112,\n  \"pdf-id\": 151,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Graph structure for use in variable misuse prediction.\\nA graph structure is build for every single possible variable\\nwhich can be substituted in the spot of interest. \\nA graph structure with the node at the point of interest removed is \\nalso built.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Function (C#)\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST  Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"NCS Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"(Data Flow) Last Use\",\n          \"details\": \"Connect variable use with all previous reads and definitions with (still) the same value\"\n        },\n        {\n          \"name\": \"(Data Flow) Last Write\",\n          \"details\": \"Connect use of variable with all its definitions\"\n        },\n        {\n          \"name\": \"(Data Flow) Last Lexical Use\",\n          \"details\": \"Represent the shortcut in reversed token chain between nearest entries of the specified variable\"\n        },\n        {\n          \"name\": \"(Data Flow) Computed From\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"(Data Flow) Formal Args\",\n          \"details\": \"Connect actual arguments and formal parameters of a method\"\n        },\n        {\n          \"name\": \"(Data Flow) Next Operand\",\n          \"details\": \"Connect operands of a single operation and parameters of a method (in lexical order)\"\n        }\n      ],\n      \"vertex-features\": \"Syntax tokens have their node type encoded using word2vec Token tokens have their tokens and language type (variable/property/field) encoded using word2vec.\\nFor encoding, text (camel case, underscores) is split up, and the final vector is the average.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Message passing, with a learnable message \\\"creation\\\" function per edge type.\\n  (exact function is unclear)\\nNodes also use LSTM to take into account previous states.\\n\\nFor each candidate, its representation is concatenated \\nwith the representation of the empty graph.\\n\\nThe result is passed through a linear layer to compute \\nthe probability of the candidate being the correct variable\\nto substitute.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"var-misuse\": {\n      \"training-objective\": \"Given multiple graphs with some spot of interest, \\ndetermine for each variable whether it should \\nbe substituted into the spot of interest (See also graph and model description)\",\n      \"training-granularity\": \"Graph classification, but not quite\",\n      \"working-objective\": \"Given multiple graphs with some spot of interest, \\ndetermine for each variable whether it should \\nbe substituted into the spot of interest (See also graph and model description)\",\n      \"working-granularity\": \"Graph classification, but not quite\",\n      \"application\": \"Variable Misuse Repair\",\n      \"supervision\": \"(Self-)Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"var-misuse\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 22,\n  \"pdf-id\": 35,\n  \"graphs\": {\n    \"s-ast\": {\n      \"name\": \"S-AST\",\n      \"description\": \"AST with control flow information and subtokens\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"Method level\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST non-leave node\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"AST leave node\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"API Invocation node\",\n          \"details\": \"e.g. \\\"Method Invocation\\\" node in the AST.\"\n        },\n        {\n          \"name\": \"Subtoken Node\",\n          \"details\": \"Every identifier in a node (e.g \\\"getLarger\\\") is split into subtokens (\\\"get\\\", \\\"L\\\", \\\"arger\\\").\\nFirst first one (\\\"get\\\") is kept as the parent node in place of the identifier; \\nthe other subtokens are kept as child nodes.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Leaf Edge\",\n          \"details\": \"Edge to the next leaf node (which may be of type \\\"Subtoken\\\" in case of a subtoken parent node)\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"Edge to next usage of a variable, starting from declaration\"\n        },\n        {\n          \"name\": \"Subtoken Edge\",\n          \"details\": \"Edge between subtoken child and parent node\"\n        }\n      ],\n      \"vertex-features\": \"Not specified/unclear how initial embedding are intialised\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"1) Leaf Edges and edges linking variables are removed \\n2) Graph is partitioned into subtrees, where each subtree represents a statement\\n3) Subtrees are grouped (left-to-right) into subgraphs based on their size using a threshold lamda\\n4) Leaf Edges and variable linking edges are re-instated per subgraph\",\n      \"other-features\": \"The raw code of the method is converted to AST. The token types (or payloads for leaves)\\nare linearised through pre-order traversal. The API description is aded to this text.\"\n    }\n  },\n  \"models\": {\n    \"gnn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Two parallel models, trained separately.\\n\\nFirst model:\\n  1) Partitioned graphs are passed to a GGNN (w/ GRU and a MLP for transforming neighbour embeddings; that's normal GGNN IIRC)\\n  2) Each partitioned graph is passed to the GGNN, in order.\\n  3) Each output of the GNN is fed, in sequence, through a unidirectional LSTM \\n  4) The entire graph is fed through the GGNN (call the output C)\\n  5) The final output of the LSTM is fused with C through concatenation \\n\\nSecond Model:\\n  1) The syntactic information w/ API description is passed through CodeBERT.\\n\\nFinally, the graph embedding and CodeBERT output are fused through concatenation.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Summarise the functionality of a method\",\n      \"training-granularity\": \"Text generation based on graph embedding\",\n      \"working-objective\": \"Summarise the functionality of a method\",\n      \"working-granularity\": \"Text generation based on graph embedding\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    },\n    \"clone-detection\": {\n      \"training-objective\": \"Given two programs, determine whether they implement the same functionality\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given two programs, determine whether they implement the same functionality\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code Clone Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"s-ast\",\n      \"model\": \"gnn\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"s-ast\",\n      \"model\": \"gnn\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 204,\n  \"pdf-id\": 274,\n  \"graphs\": {\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Basic Block\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/ a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"The node centrality is computed for every node.\\nThis centrality is \\\"assigned\\\" to every token in the node.\\nThe centralitities of the same token in different blocks are summed.\\nThese tokens are encoded using word2vec; \\nThe word vectors are multiplied with the summed node centrality.\\nThis sequence is used as the model input.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GRU \\nResulting embeddings of the two code snippets are combined;\\ncosine similarity\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"clone-detection\": {\n      \"training-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code Clone Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"model\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 16,\n  \"pdf-id\": 27,\n  \"graphs\": {\n    \"sc-ast\": {\n      \"name\": \"Statement-centered AST\",\n      \"description\": null,\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": null\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Statement Node\",\n          \"details\": \"Statement node (one of the following must be met):\\n1) Node is expression statement, declaration statement, or branching statement (break, continue, return)\\n  --> This definition makes sure a statement contains no statement in its subtree (because if/for/while excluded)\\n2) A node represents an expression in a program and its parent node is a decision or loop statement.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge (directed, augmented)\",\n          \"details\": \"Use normal AST edges (directed), _but_ when a statement \\nnode is detected, reverse the direction of all edges in \\nthe subtree(s) of the statement node, so that they point\\nto the statement node.\"\n        }\n      ],\n      \"vertex-features\": \"Not specified\",\n      \"edge-features\": \"Edge type (up or down); encoding not specified\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"pcan\": {\n      \"type\": {\n        \"name\": \"Path context augmented network\",\n        \"architecture\": \"GGNN Layer\\nKey-Value Self-attention layer\\n  Given statements m and k, we have \\n    \\\\alpha_{m,k} = \\\\frac{\\\\exp(\\\\Psi(e_m, e_k))}{\\\\sum_{l = 1}^N \\\\exp(\\\\Psi(e_m, e_l))}\\n    \\\\Psi(e_m, e_k) = \\\\langle W_{Query}e_m, W_{key} e_k \\\\rangle\\n  \\n  Embeddings e_m updated to s_m according to:\\n\\n    s_m = \\\\sum_{k=1}^N \\\\alpha_{m,k} W_{value} e_k\\nAggregation layer (average of all statement vectors)\\n\\nAlthough the method is proposed as a general method, it is evaluated \\non code clone detection, with the following addition to the network:\\n\\n1) Two code clones are separately passed through the network (the _same_ network),\\n2) the resulting two embeddings are subtracted and the L2 norm is computed.\\n3) The L2 norm is passed through a sigmoid function\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"clone-detection\": {\n      \"training-objective\": \"For two given graphs, determine if they are clones or not.\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"For two given graphs, determine if they are clones or not.\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Code clone detection\",\n      \"supervision\": \"supervised\"\n    },\n    \"code-classification\": {\n      \"training-objective\": \"For a given graph, determine the class of the graph.\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"For a given graph, determine the class of the graph.\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Code classification\",\n      \"supervision\": \"supervised\"\n    },\n    \"method-naming\": {\n      \"training-objective\": \"For a given graph, determine the method name.\",\n      \"training-granularity\": \"Graph-based Generation\",\n      \"working-objective\": \"For a given graph, determine the method name.\",\n      \"working-granularity\": \"Graph-based Generation\",\n      \"application\": \"Method name detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"training\": {\n    \"training-setup-oj-clone\": {\n      \"train-test-split\": {\n        \"train\": 0.6,\n        \"test\": 0.2,\n        \"validation\": 0.2\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [],\n      \"hyper-parameter-selection\": \"n/a\",\n      \"search-tuned-hyper-parameters\": \"n/a\",\n      \"evaluation-details\": \"n/a\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"precision\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"recall\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"f1-score\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        }\n      ]\n    },\n    \"training-setup-bbc\": {\n      \"train-test-split\": {\n        \"train\": 0.8,\n        \"test\": 0.1,\n        \"validation\": 0.1\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [],\n      \"hyper-parameter-selection\": \"n/a\",\n      \"search-tuned-hyper-parameters\": \"n/a\",\n      \"evaluation-details\": \"n/a\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"precision\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"recall\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"f1-score\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        }\n      ]\n    },\n    \"training-setup-oj-class\": {\n      \"train-test-split\": {\n        \"train\": 0.6,\n        \"test\": 0.2,\n        \"validation\": 0.2\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"loss\",\n          \"value\": \"cross-entropy\"\n        }\n      ],\n      \"hyper-parameter-selection\": \"n/a\",\n      \"search-tuned-hyper-parameters\": \"n/a\",\n      \"evaluation-details\": \"Logits obtained by Wr + b (r is embedding); apparently no softmax used?\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"precision\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"recall\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"f1-score\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        }\n      ]\n    },\n    \"training-method-naming\": {\n      \"train-test-split\": {\n        \"train\": \"Not specified\",\n        \"test\": \"Not specified\",\n        \"validation\": \"Not specified\"\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [],\n      \"hyper-parameter-selection\": \"n/a\",\n      \"search-tuned-hyper-parameters\": \"n/a\",\n      \"evaluation-details\": \"encoder/decoder setup. Unclear what decoder is used\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"precision\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"recall\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"f1-score\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        }\n      ]\n    }\n  },\n  \"datasets\": {\n    \"oj-clone\": {\n      \"name\": \"n/a\",\n      \"description\": \"Based on OJClone, containing programs from 104 different classes.\\n\\nPrograms are said to be clones if they belong to \\nthe same class.\\n\\nDownsampled to only use the first 15 classes,\\nwhich results in 28,000,000 clone pairs,\\nof which 50000 are randomly sampled.\",\n      \"source\": [\n        \"Online judge systems\"\n      ],\n      \"labelling\": \"Yes; not specified\",\n      \"size\": 50000,\n      \"is-pre-existing\": true\n    },\n    \"oj-clone-full\": {\n      \"name\": \"OJClone\",\n      \"description\": \"Dataset containing 52000 progams from 104 classes\",\n      \"source\": [\n        \"Online judge systems\"\n      ],\n      \"labelling\": \"Yes; not specified\",\n      \"size\": 52000,\n      \"is-pre-existing\": true\n    },\n    \"bcb\": {\n      \"name\": \"BigCloneBench\",\n      \"description\": \"Dataset of java methods containing true \\nand false clone pairs.\\n\\nDownsampled to 9134 code fragments,\\nrandomly sampled pairs from the total\\namount of paired fragments.\",\n      \"source\": [\n        \"BigCloneBench (Java systems)\"\n      ],\n      \"labelling\": \"Yes; not specified\",\n      \"size\": \"125000 (approximately)\",\n      \"is-pre-existing\": true\n    },\n    \"java-small\": {\n      \"name\": \"Java-small\",\n      \"description\": \"dataset of Java methods\",\n      \"source\": [\n        \"Not specified\"\n      ],\n      \"labelling\": \"n/a\",\n      \"size\": 500000,\n      \"is-pre-existing\": true\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"sc-ast\",\n      \"model\": \"pcan\",\n      \"task\": \"clone-detection\",\n      \"training\": \"training-setup-oj-clone\",\n      \"dataset\": \"oj-clone\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"sc-ast\",\n      \"model\": \"pcan\",\n      \"task\": \"clone-detection\",\n      \"training\": \"training-setup-bbc\",\n      \"dataset\": \"bcb\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"sc-ast\",\n      \"model\": \"pcan\",\n      \"task\": \"code-classification\",\n      \"training\": \"training-setup-oj-class\",\n      \"dataset\": \"oj-clone-full\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"sc-ast\",\n      \"model\": \"pcan\",\n      \"task\": \"method-naming\",\n      \"training\": \"training-method-naming\",\n      \"dataset\": \"java-small\",\n      \"comments\": \"Unclear how they used precision/recall/f1-score to evaluate this\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 198,\n  \"pdf-id\": 266,\n  \"graphs\": {\n    \"pdg\": {\n      \"name\": \"PDG\",\n      \"description\": \"b/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Dependence Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependence Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"One-hot encoding of statement type\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) For each Node (note: parts (ii-v) are ran twice; once for control edges, once for data edges):\\n  i) Linear Layer \\n  ii) Graph-based attention Layer 1\\n      - e_{ij} = \\\\alpha(W h_i, W h_j)\\n      - a_{ij} = softmax(e_{ij})\\n      - h_i' = \\\\concat_k^{heads} \\\\sigma(\\\\sum_{j \\\\in N(u)} a_{ij}^k W^k h_j)\\n  iii) Graph-based attention Layer 1\\n      - e_{ij} = \\\\alpha(W h_i, W h_j)\\n      - a_{ij} = softmax(e_{ij})\\n      - h_i'' = \\\\sum_k^{heads} \\\\sigma(\\\\sum_{j \\\\in N(u)} a_{ij}^k W^k h_j')\\n  iv) h_i'' passed to LSTM; back to (ii) for some amount of rounds \\n  v) Concatenate LSTM output for every round \\n2) Add control- and data dependence based representations; H = H_c + H_d \\n3) G = \\\\alpha(MLP(H)) \\\\odot MLP(H)\\n4) Concatenate graph embeddings for the two input graphs to obtain F\\n5) F'  = \\\\alpha(MLP(F))\\n6) Similarity = \\\\alpha(MLP(F'))\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"clone-detection\": {\n      \"training-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"training-granularity\": \"Graph Classification (?)\",\n      \"working-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"working-granularity\": \"Graph Classification (?)\",\n      \"application\": \"Code Clone Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 63,\n  \"pdf-id\": 90,\n  \"graphs\": {\n    \"pdg\": {\n      \"name\": \"Program Dependency Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement or Control Predicate\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Node features are trained using a modified node2vec,\\nwhich learns embeddings for the individual tokens in \\neach node.\\n\\nLater, these embeddings per node are combined to come \\nup with node embeddings.\",\n      \"edge-features\": \"Separate from the vertex features, another set of \\nnode features (not based on node payload) is \\ncomputed using node2vec.\\n\\nEdge features are computed by subtracting the \\nstart node embedding from the end node embedding,\\nfor every edge.\",\n      \"connectivity-features\": \"Not Specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"network\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"BiGGNN (Bidirectional Graph Gated Neural Network)\\nFNN Layer \\nSoftmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable or non-vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample as vulnerable or non-vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"pdf\",\n      \"model\": \"network\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": \"Not entirely clear if they also did multi-class classification,\\nsince softmax was used. The text only suggests single-class.\\n\\nNot entirely clear how graph classification was done \\nwithout a pooling layer.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 126,\n  \"pdf-id\": 169,\n  \"graphs\": {\n    \"pdg\": {\n      \"name\": \"PDG\",\n      \"description\": \"All source files in a project are processed.\\nFurthermore, every function in a source file is \\nrepresented using its own graph.\\n\\nGiven a bug report, the model must pinpoint the file \\nwith the defect;\\n\\nTo avoid confusion, remember that the artefacts in the \\n\\\"artefacts\\\" section are not related _beforehand_, but their\\nrelatedness must be predicted\",\n      \"artefacts\": [\n        {\n          \"name\": \"Bug report\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"Every function in a source file has its own PDG\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Dependence Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependence Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"Graphs Represented using Graph2Vec.\\n\\nAll graph representations are aggregated into a single vector \\nthrough k-medoids with Hausdorff distance\",\n      \"other-features\": \"Summary and description of bug reports are encoded using word2vec.\\n\\nContent of source code files is encoded using word2vec,\\nafter removal of keywords and splitting up identifiers.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Encoded issue fed into CNN w/ Max pooling \\n2) Encoded source code fed into\\n  deeply separable convolution,\\n  followed by pooling,\\n  followed by convolution,\\n  followed by pooling\\n3) Source code, bug report, and graph embeddings are concatenated.\\n4) MLP\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"bug-localisation\": {\n      \"training-objective\": \"Predict file containing the reported bug\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Predict file containing the reported bug\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Software Defect Localisation\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model\",\n      \"task\": \"bug-localisation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 165,\n  \"pdf-id\": 217,\n  \"graphs\": {\n    \"code-property-graph\": {\n      \"name\": \"Code Property Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Node content is used as feature\",\n      \"edge-features\": \"Edge type is used as feature\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"For a given code sample c, the most similar _known_\\n(code, summary) sample (c', s') is used as features,\\nwhere c' is also represented using a graph.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Encoder/Decoder Architecture\\n\\nEncoder:\\n  It is unclear how the node and edge features are computed,\\n  but the text seems to imply a learnable embedding layer.\\n  \\n  1) Embedding Layer for Tokens in Node \\n  2) Embedding Layer for Edge types \\n  3) BiLSTM over tokens to obtain node features (feature = concatenation of the last hidden states of the two LSTMs)\\n  4) Compute A = \\\\exp(ReLU(H_cW^C)ReLU(H_{c'}W^Q)^T) (H_c, H_{c'}: initial graph representations\\n  5) H'_c = z A H_{c'} (z: similarity)\\n  6) comp = H_c + H'_c\\n  7) Encode s' using BiLSTM; encoding is the sequence of hidden states of the LSTM, multiplied by z \\n  8) Compute B_{v,u} = (ReLU(h_v^TW^Q)(ReLU(h_u^TW^K) + ReLU(e_{v,u}^TW^R))^T) / \\\\sqrt{d}\\n      Where h_v, h_u are node states from comp, for all pairs (v, u) (regardless of connectivity)\\n      If v and u are not connected, e_{v,u} = 0\\n  9) Combine all B_{v,u} to obtain \\\"dynamic graph adjacency matrix\\\" B\\n  10) Row normalise according to B' = softmax(B)\\n  11) n rounds of Hybrid GNN over the dynamic (B) and static (original) graphs:\\n      i) Initial Node States from comp\\n      ii) Static Message Passing:\\n        h_v^k = \\\\sum_{u \\\\in N(v)} h_u^{k - 1}\\n      iii) Dynamic Message Passing:\\n        h'_v^k = \\\\sum_{u} B'_{v,u}(W^V h'_u^{k - 1} + W^Fe_{v,u})\\n      iv) f_v^k = GRU(f_v^{k - 1}, Fuse(h_v^k, h'_v^k))\\n          Where Fuse(a, b) = z \\\\cdot a + (1 - z) \\\\cdot b\\n          Where z = \\\\sigma(W_Z[a, b, a \\\\cdot b, a - b] + b_z)\\n  12) Max pooling over f_v^n\\n\\n  General idea behind B: Use structure aware global attention to\\n  dynamically construct a graph which captures global relations \\n  better than the regular graph.\\n  \\nDecoder:\\n  - Input is [f_{v_1}^n, f_{v_2}^n, ..., f_{v_m}^n, <embedding of summary s'>]\\n  - Initial hidden state: Graph representation concatenated with the last\\n      weighted (according to z) hidden state of the BiLSTM encoder for s'\\n  - Attention-based LSTM decoder \\n  - Beam Search\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary.\",\n      \"training-granularity\": \"Graph to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary.\",\n      \"working-granularity\": \"Graph to Sequence\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 139,\n  \"pdf-id\": 182,\n  \"graphs\": {\n    \"program-feedback-graph\": {\n      \"name\": \"Program Feedback Graph\",\n      \"description\": null,\n      \"artefacts\": [\n        {\n          \"name\": \"Compiler Feedback\",\n          \"details\": \"Line number i_err and error message m_err\"\n        },\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Token\",\n          \"details\": \"Token in the compiler error message. Specifically, the tokens \\nfound between quotation marks. (e.g. object \\\"a\\\" of type \\\"x\\\" has no attribute \\\"y\\\")\"\n        },\n        {\n          \"name\": \"Token\",\n          \"details\": \"Token from code. Specifically, variable names and occurrences of tokens\\nextracted from the error message.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Token Edge\",\n          \"details\": \"Undirected edge between identical tokens\"\n        }\n      ],\n      \"vertex-features\": \"Lines in the source code are tokenized\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Compiler message is tokenized \\nCompiler line number is used as feature\"\n    }\n  },\n  \"models\": {\n    \"network\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Based on the code, it seems all tokens are embedded using the same embedding layer (not entirely clear)\\n2) Each code line is embedded using LSTM^1_code; compiler message encoded using LSTM^1_msg \\n3) To the output of LSTM_code for every token, the line number offset i_err - i is concatenated \\n    At this point, the token embeddings are denoted h_{x_{ij}} (j-th token in the i-th line of code),\\n    and h_{m_{\\\\ell}}\\n4) Message propagation using GAT\\n5) Apply Another round of LSTM through LSTM^2_code and LSTM^2_msg;\\n    Each line is embedded as the concatenation of \\n      i) The final hidden state of LSTM^2_code (outputted for the last token in the line)\\n      ii) The final hidden state of LSTM^2_msg (outputted for the last token in the compiler message)\\n6) s_1, s_2, \\\\hdots, s_L = LSTM^3_{code}(r_1, r_2, \\\\hdots, r_L)\\n7) p(line k is wrong | s_1, s_2, \\\\hdots, s_L) = softmax(MLP(s_1, s_2, \\\\hdots, s_L))\\n8) Repair is given by s_k fed to a pointer-generator decoder\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"program-repair\": {\n      \"training-objective\": \"Given a program, compiler error message, and compiler error line number\\n  1) Determine the actual wrong line of code \\n  2) output the correct line of code\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a program, compiler error message, and compiler error line number\\n  1) Determine the actual wrong line of code \\n  2) output the correct line of code\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Automated program repair\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"program-feedback-graph\",\n      \"model\": \"network\",\n      \"task\": \"program-repair\",\n      \"comments\": \"The authors call the approach self-supervised because the dataset is synthetically generated\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 50,\n  \"pdf-id\": 71,\n  \"graphs\": {\n    \"dependency-graph\": {\n      \"name\": \"Dependency Graph\",\n      \"description\": null,\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Module\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Dependency\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"For every pair of nodes, compute the following features:\\n  1) topological features (common neighbours, Salton, Sorensen, Adamic-Adar, Katz, SimRank, Russel-Rao, Resource Allocation)\\n  2) content-based features:\\n      i) For every class in a module, compute the BoW representation of\\n          field attributes, method names, names of invoked methods, parameter names, comments, and JavaDoc documentation\\n      ii) Recursively take the union of class-based BoW representations to obtain the module-level BoW representation\\n      iii) Compute similarity between the two module-level BoW representations using cosine similarity\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"svm-with-automaton\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"SVM for link prediction.\\n\\nFalse positives were penalised using a learning automaton;\\nif a false positive is predicted for multiple successive \\nversions of a project, the automaton lowers the \\nconfidence outputted by the classifier.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"architectural-smell-prediction\": {\n      \"training-objective\": \"Given two pairs of (the same!) nodes from versions n and n+1, \\nwhere there is no dependency between between the nodes in version n, \\ndetermine based on the features in version n whether there will be a \\ndependency between the nodes in version n+1\",\n      \"training-granularity\": \"Link Prediction\",\n      \"working-objective\": \"Given a pair of nodes from version n,\\npredict whether there will be a dependency between the nodes in version n+1\",\n      \"working-granularity\": \"Link Prediction\",\n      \"application\": \"Predicting the emergence of architectural smells\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"dependency-graph\",\n      \"model\": \"svm-with-automaton\",\n      \"task\": \"training-objective\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 140,\n  \"pdf-id\": 185,\n  \"graphs\": {\n    \"code-change-genealogy\": {\n      \"name\": \"Code Change Genealogy\",\n      \"description\": \"Graph representing the dependencies between code changes. \\nRoughly speaking, a code change is related to the previously \\nmost recent related code change, for some definition \\nof relatedness. For instance, when a call to a method is added,\\nthe change may be related to the last change modifying \\n(the signature of) said method.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code Changes\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Code Change\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Change Dependency Edge\",\n          \"details\": \"According to the rules of Herzig et al.\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Random walks over the graph are used.\\nA random walk produces a sequence of nodes,\\nwhich can be seen as a sentence. \\nA collection of random walks thus makes for a corpus of \\\"sentences\\\",\\nsimilar to what word2vec was trained on.\\n\\nFor the semantic-model task, the changed tokens (as a sequence)\\nper change are also included as features.\"\n    }\n  },\n  \"models\": {\n    \"cbow\": {\n      \"type\": {\n        \"name\": \"Continuous Bag of Words (CBOW)\",\n        \"architecture\": \"CBOW\"\n      }\n    },\n    \"c-skipgram\": {\n      \"type\": {\n        \"name\": \"Skipgram\",\n        \"architecture\": \"Continuos Skipgram\"\n      }\n    },\n    \"semantic-model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Takes as input the sequence of changes, and the token sequence belonging to the target. 1) Predict the context given the target, as in skipgram 2) in parallel, train the tokens as in CBOW. Also jointly train a vector representing the entire change, similar to doc2vec 3) Combine the two vector representations.\"\n      }\n    },\n    \"svm\": {\n      \"type\": {\n        \"name\": \"SVM\",\n        \"architecture\": \"SVM (! for downstream task !)\"\n      }\n    },\n    \"logistic-regression\": {\n      \"type\": {\n        \"name\": \"Logistic Regression\",\n        \"architecture\": \"Logistic Regression (! for downstream task !)\"\n      }\n    },\n    \"nn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"FNN (! for downstream task !)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"cbow-task\": {\n      \"training-objective\": \"Given the context change node, predict the target node (no tokens used)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Obtain embeddings for nodes\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Node embedding\",\n      \"supervision\": \"Unsupervised / Self-supervised\"\n    },\n    \"skipgram-task\": {\n      \"training-objective\": \"Given the target change node, predict the context nodes (no tokens used)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Obtain embeddings for nodes\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Node embedding\",\n      \"supervision\": \"Unsupervised / Self-supervised\"\n    },\n    \"semantic-model-task\": {\n      \"training-objective\": \"Minimise loss function\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Obtain embeddings for nodes\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Node embedding\",\n      \"supervision\": \"Unsupervised / Self-supervised\"\n    },\n    \"defect-prediction\": {\n      \"training-objective\": \"Given a node, classify it as defect introducing or not  (! downstream task !)\",\n      \"training-granularity\": \"Node Classification\",\n      \"working-objective\": \"Given a node, classify it as defect introducing or not (! downstream task !)\",\n      \"working-granularity\": \"Node Classification\",\n      \"application\": \"Node classification\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-change-genealogy\",\n      \"model\": \"cbow + nn/svm/logistic-regression(?)\",\n      \"task\": \"cbow-task + defect-prediction(?)\",\n      \"comments\": \"The structural-only variant was tested with all downstream models,\\nbut it is unclear whether cbow or skipgram was used\"\n    },\n    {\n      \"graph\": \"code-change-genealogy\",\n      \"model\": \"c-skipgram + nn/svm/logistic-regression\",\n      \"task\": \"skipgram-task + defect-prediction(?)\",\n      \"comments\": \"The structural-only variant was tested with all downstream models,\\nbut it is unclear whether cbow or skipgram was used\"\n    },\n    {\n      \"graph\": \"code-change-genealogy\",\n      \"model\": \"semantic-model + nn/svm/logistic-regression\",\n      \"task\": \"semantic-model-task + defect-prediction\",\n      \"comments\": \"Tested with all downstream models\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 80,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"code-property-graph\": {\n      \"name\": \"Code Property Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"tag; node type/role -- one hot encoded op; encoding for some program operations (e.g. conditional, jump) -- one hot encoded func; reflects relationship with specific functions -- one hot encoded lite; describes involved parameters -- one hot encoded type; type parameter in C/C++ (16 fixed options) -- one hot encoded\\nNode tokens encoded using Word2vec\\nall features are concatenated\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix (?)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Z = GCN layers \\nNormalisation(Z + \\\\theta) (\\\\theta is learnable) --> IS Scores (Influence Scores)\\nceil(k*n) nodes with highest IS scores are kept \\nBiLSTM on ranked list of kept nodes \\nMLP\\nsoftmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify function as vulnerable/not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify function as vulnerable/not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 138,\n  \"pdf-id\": 181,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"For terminal nodes, content (names) and type \\nare both split up.\\n\\nFor non-terminal nodes, the mode typs is used as a feature (no splitting)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Cross block paths are extracted, \\nwhere a cross block path is a path from one \\nterminal node to another terminal node,\\nwhere the top node of the path defines a block\\nstructure (e.g. if block), and both nodes \\nare nested under said top node,\\nOR\\nthe left and right paths belong to two\\ndifferent parallel block structures \\n(e.g. two consecutive blocks nested in a block).\\nCertain amount of paths is sampled.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Two inputs\\n  i) Terminal nodes \\n    Embedding Layer (?)\\n      For terminal nodes, content and type of the node are encoded using BiLSTM (separately)\\n  ii) Path \\n    The path is encoded using BiLSTM.\\n2) The six outputs (two x name vector, 2x type vector, vectors of left and right path) are concatenated\\n3) FC layer w/ tanh activation\\n4) Attention weighted sum of path vectors \\n5) Softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"defect-prediction\": {\n      \"training-objective\": \"Classify sample as buggy or not buggy\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample as buggy or not buggy\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Defect prediction\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 125,\n  \"pdf-id\": 167,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Some node types are discarded, others are kept\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"Seen as undirected\"\n        }\n      ],\n      \"vertex-features\": \"Node \\\"strings\\\" mapped to numerical vectors; unclear what this means exactly\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Embedding Layer \\n2) 3x (GIN Layer; BatchNormalisation; ReLU; Dropout)\\n3) Transformer Layer \\n  H_0 = H_G + PE_{sin} + PE_{Laplace}\\n  H'_{n} = MultiHeadAttention(Linear(H_{n-1})) + H_{n-1}\\n  H_N = FNN(Linear(H'_{n-1})) + H'_{n-1}\\n\\n  Here, PE_{sin} is a matrix satisfying\\n    PE_{sin}(i,2j) = sin(i/10000^{2j / d})\\n    PE_{sin}(i,2j+1) = cos(i/10000^{2j / d})\\n\\n  PE_{Laplace} is a matrix satisfying \\n    PE_{Laplace} = Linear(concat(\\\\lambda_m, x_{n,m}))\\n    where \\\\lambda_m is the m-th lowest eigenvector of the graph Laplace matrix\\n    and x_{n,m} is the n-th element of the eigenvector corresponding to \\\\lambda_m\\n\\n4) Special token at the end of transformer input, whose embedding is used for prediction;\\n  y = sigmoid(FullyConnectedLayer(H_last))\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"defect-prediction\": {\n      \"training-objective\": \"Classify sample as buggy or not buggy\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample as buggy or not buggy\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Defect Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 162,\n  \"pdf-id\": 212,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Heterogeneous graph mapping tokens to \\\"sentences\\\"\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Sentence Node\",\n          \"details\": \"For Java code, a sentence is a statement. For control statement, the portion before the opening { is used as a sentence.\\nFor Python code, each line is considered a sentence.\"\n        },\n        {\n          \"name\": \"Token Node\",\n          \"details\": \"Represents a single token. One unique node for every unique token\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"sentence/token edge\",\n          \"details\": \"connects a sentence node to every token contained in said sentence\"\n        }\n      ],\n      \"vertex-features\": \"Node payload, embedded using embedding layers\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Previously generated tokens are used as input.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Encoder/decoder architecture, based on transformer.\\n\\nEncoder:\\n  1) Embedding Layer to encode nodes \\n  2) Nodes are enhanced with relative positional encoding \\n  3) multi-head self-attention w/ residual connections and normalisation \\n  4) Position-wise FNN w/ residual connections and normalisation\\n\\nGraph Network:\\n  1) Output of embedding layer is used to initialise token nodes \\n  2) Output of encoder is used to initialise sentence nodes \\n  3) GAT \\n\\nDecoder: \\n  1) Embedding Layer  \\n  2) Positional Encoding (absolute)\\n  3) Masked multi-head self-attention w/ residual connections and normalisation\\n  4) Multi-head attention with outputs from GAT w/ residual connections and normalisation\\n  5) Position-wise FNN w/ residual connections and normalisation\\n  6) Linear Layer \\n  7) Softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"training-granularity\": \"Graph to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"working-granularity\": \"Graph to Sequence\",\n      \"application\": \"Code summarization (Generating comments)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 200,\n  \"pdf-id\": 268,\n  \"graphs\": {\n    \"lr-fa-ast\": {\n      \"name\": \"LR-FA-AST (Less Redundancy Flow Augmented AST)\",\n      \"description\": \"Flow-augmented AST with pruning applied.\\nSpecifically, only \\\"important\\\" nodes and their edges \\nare kept, where important nodes are nodes dealing \\nwith variable/method declarations, and control structures (e.g. if, loops)\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Certain node types are pruned (see description)\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Block Edge\",\n          \"details\": \"Edges between the child node of block structures\"\n        },\n        {\n          \"name\": \"Conditional Edge\",\n          \"details\": \"Edges between child nodes of control structures (e.g. while, if)\"\n        },\n        {\n          \"name\": \"Leaf Edge\",\n          \"details\": \"Edges between (successive) leaf nodes\"\n        },\n        {\n          \"name\": \"Control Edge\",\n          \"details\": \"Edges for function calls(?)\"\n        }\n      ],\n      \"vertex-features\": \"Unclear; presumably node type based on images in the paper\",\n      \"edge-features\": \"Edges have weights; unclear how they are computed. It seems to be the edge type\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Node Embedding Layer \\n2) Edge Embedding Layer\\n3) The two inputs graphs are joined (as in, two separate disjoint graphs, but in the same graph representation) \\n4) Message passing:\\n  i) message generation: m_{ij} = ReLU(W[h_i^t; h_j^t; e_{ij}] + b)\\n  ii) Aggregation: h_i^{t+1}' = \\\\sigma(W * (h_i^t \\\\mid\\\\mid \\\\sum_j m_{ij} h_j^t) + b)\\n  iii) GRU: h_i^{t + 1} = GRU(h_i^{t + 1}', h_i^t)\\n5) Nodes are separated per (original) graph \\n6) Some attention mechanism is used to pool features; unclear what exactly \\n7) Cosine similarity\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"clone-detection\": {\n      \"training-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"training-granularity\": \"Graph Classification (?)\",\n      \"working-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"working-granularity\": \"Graph Classification (?)\",\n      \"application\": \"Code Clone Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"lr-fa-ast\",\n      \"model\": \"model\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 132,\n  \"pdf-id\": 175,\n  \"graphs\": {\n    \"ast-within\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"File\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Only method calls (incl. class creation), declarations, and control flow nodes are kept.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Content of tokens is put into a sequence\"\n    },\n    \"class-dependency-network\": {\n      \"name\": \"Class Dependency Network (CDN)\",\n      \"description\": \"Serves as the \\\"larger\\\" context for the file.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Files/project\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Class\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Dependency\",\n          \"details\": null\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"Graph encoded using node2vec\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"ast-encoder\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Encoder for the token sequence obtained from the AST \\nConvolutional Layer \\nMax pooling \\nfully connected Layer\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"dataset-selection\": {\n      \"training-objective\": \"Not specified in the paper how the encoders are trained\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Projects (target project and source projects) are encoded, \\nsimilarity between source files in the target and source projects\\nare computed, best source project is selected based on combining \\nthe top-k most similar files from the source project.\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Given a target project one wants to predict faults in (using cross project bug prediction),\\nfind the most suitable source dataset to train a classifier on.\",\n      \"supervision\": \"Not able to determine\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + class-dependency-network\",\n      \"model\": \"ast-encoder\",\n      \"task\": \"dataset-selection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 37,\n  \"pdf-id\": 50,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Source code comments\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Not specified (unclear how node embeddings are initialised)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Text inputs (source code, comments) are inputted into a pre-trained BERT model\\n2) AST is inputted into a tree-LSTM \\n3) Results are inputted into three parallel attention layers \\n4) Each attention layer is fed into a task-specific output layer\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"author-attribution\": {\n      \"training-objective\": \"Given a code snippet, predict its author (from a known list)\",\n      \"training-granularity\": \"Graph + Source code (Text) Classification\",\n      \"working-objective\": \"Given a code snippet, predict its author (from a known list)\",\n      \"working-granularity\": \"Graph + Source code (Text) Classification\",\n      \"application\": \"Author Attribution\",\n      \"supervision\": \"Supervised\"\n    },\n    \"comment-classification\": {\n      \"training-objective\": \"Determine whether code comment is reliable\",\n      \"training-granularity\": \"Graph + Source code (Text) Classification\",\n      \"working-objective\": \"Determine whether code comment is reliable\",\n      \"working-granularity\": \"Graph + Source code (Text) Classification\",\n      \"application\": \"Comment Classification\",\n      \"supervision\": \"Supervised\"\n    },\n    \"duplicate-function-detection\": {\n      \"training-objective\": \"Given two code snippets, predict if they are functional duplicates\",\n      \"training-granularity\": \"Graph Classification (?)\",\n      \"working-objective\": \"Given two code snippets, predict if they are functional duplicates\",\n      \"working-granularity\": \"Graph Classification (?)\",\n      \"application\": \"Duplicate Function Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"author-attribution + comment-classification + duplicate-function-detection\",\n      \"comments\": \"A single model is trained on all three tasks, so that the shared part may benefit from joint knowledge.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 76,\n  \"pdf-id\": 106,\n  \"graphs\": \"Arbitrary Graphs (?)\",\n  \"models\": {\n    \"code-transformer\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Transformer (encoder/decoder) setup with BART like-architecture\\n(6 encoder layers, 6 decoder layers, 2 heads/layers)\"\n      }\n    },\n    \"vgae\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Variational Graph Autoencoder\\n\\nEncoder: GCN \\n\\nFor decoding, latent representation is split into two,\\nand passed to two different decoders:\\n\\n1) Node decoder: \\n    GCN (Graph Deconvolutional Network)\\n    Reconstruct node embedding matrix \\n\\n2) Edge decoder\\n  Further split latent representation, and use two \\n  dot product decoders. \\n  First one reconstructs the upper-diagonal part of the \\n  adjacency matrix, the second one the sub-diagonal part.\\n  This is necessary because due to their symmetric structure,\\n  regular dot product decoders can only construct undirected \\n  adjacency matrices.\\n  Note: graphs are assumed not to have self-loops.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-construction\": {\n      \"training-objective\": \"Given a graph, construct its code\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a graph, construct its code\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Construct source code from a given code graph\",\n      \"supervision\": \"Self-supervised\"\n    },\n    \"variational-autoencoder\": {\n      \"training-objective\": \"Given a graph, reconstruct it, minimising the reconstruction loss\",\n      \"training-granularity\": \"Latent Space Graph Embedding\",\n      \"working-objective\": \"Given a latent space representation, construct the corresponding graph\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Using SMOTE to interpolate between latent space representations of graphs,\\nand generating new synthetic code graph samples, whose \\\"source code\\\" can \\neven be reconstructed through the code-transformer\",\n      \"supervision\": \"Self-supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"n/a\",\n      \"model\": \"code-transformer + vgae\",\n      \"task\": \"code-construction + variational-autoencoder\",\n      \"comments\": \"Essentially works on arbitrary code graphs\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 147,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"cfg\": {\n      \"name\": \"Control Flow Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Natural Sequence Edge\",\n          \"details\": \"natural control flow\"\n        },\n        {\n          \"name\": \"True Edge\",\n          \"details\": \"True branch of conditional\"\n        },\n        {\n          \"name\": \"False Edge\",\n          \"details\": \"False branch of conditional\"\n        }\n      ],\n      \"vertex-features\": \"Tokens in nodes are embedded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Identifier names in tokens are split up; punctuation is removed \\nTokens from the code are encoded using word2vec.\\n\\nAlready generated words are encoded using word2vec.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Two parallel inputs:\\n  i) Tokens -- Fed Into Transformer encoder \\n      - Multi-head self attention w/ residual connection and layer normalisation \\n      - Positional FNN w/ residual connection and layer normalisation\\n  ii) Graph Nodes\\n      - Tokens in nodes are passed through BiLSTM to generate node embeddings\\n2) Node embeddings are passed through GNN\\n  i) GAT \\n  ii) Each node embedding is passed through FNN w/ residual connection and layer normalisation\\n3) Already generated words are passed to a multi-head self attention layer w/ residual connection and layer normalisation\\n4) graph embedding and embedding of generated words are combined in multi-head attention module \\n5) token embedding and embedding of generated words are combined in multi-head attention module\\n6) output of the two multi-head attention modules is concatenated\\n7) Linear layer \\n8) Softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"training-granularity\": \"Graph + Sequence to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"working-granularity\": \"Graph + Sequence to Sequence\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 60,\n  \"pdf-id\": 86,\n  \"graphs\": {\n    \"control-flow-chart\": {\n      \"name\": \"Control Flow Chart\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Local block\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Line\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix (?)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"The code block (not the nodes; the entire block)\\nis tokenized using the pretrained BPE tokenizer from CodeBERT.\\nThese tokens are passed to the pre-embedding\\npart of the network.\"\n    }\n  },\n  \"models\": {\n    \"rgan\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"One network with four parts.\\nPre-embedding stage; Code block is passed to embedding layer Bidirectional LSTM Self attention layer\\nThis part of the network generates a vector representation of every line, which are used as the node features in the GNN part.\\nControl Flow Chart is passed to GNN; GAT layers with skip connections\\nPooling (Mean Biaffine Attention Pooling Module); h_{mean} = \\\\frac{1}{n} \\\\sum_{i = 1}^n h_i h_{fi} = h_i^T \\\\cdot W e_i = h_{fi}^T \\\\cdot h_{mean} + h_i^T \\\\cdot u a_i = softmax(e_i) = \\\\frac{\\\\exp(e_i)}{\\\\sum_{j = 0}^n \\\\exp(e_j)} h_g = \\\\sum_{i = 0}^n a_i \\\\cdot h_{fi}\\nHere, W is a learnable matrix, u is a learnable vector, and h_g is the pooled (graph) representation.\\nClassifier; MLP\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify graph as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify graph as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"control-flow-chart\",\n      \"model\": \"rgan\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 176,\n  \"pdf-id\": 230,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Node types are used as features (encoded using embedding layer)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Pre-order traversal sequence of node types\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Two parallel inputs:\\n  i) Sequence AST Encoder -- Takes pre-order sequence as input\\n    - Embedding Layer \\n    - Self Attention \\n    - Bidirectional LSTM\\n    - Concatenate final hidden states of the two directions of \\n        LSTM to compute h_{SAST}\\n  ii) Graph Encoder\\n    - GCN\\n    - Pooling unclear, but some vector h_{GAST} is computed \\n2) Concatenate h_{SAST} and h_{GAST}\\n3) Fully connected layer w/ Softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"program-classification\": {\n      \"training-objective\": \"Given a sample (program), classify it into one of multiple categories\",\n      \"training-granularity\": \"Graph Multi-class Classification\",\n      \"working-objective\": \"Given a sample (program), classify it into one of multiple categories\",\n      \"working-granularity\": \"Graph Multi-class Classification\",\n      \"application\": \"Program Classification (cross language)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"program-classification\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 207,\n  \"pdf-id\": 277,\n  \"graphs\": {\n    \"code-property-graph\": {\n      \"name\": \"Code Property Graph\",\n      \"description\": \"Slicing is applied based on vulnerable functions and vulnerable data\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"smart contracts\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Tokens encoded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"9 handcrafted expert features are used\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Two parallel inputs\\n  i) Handcrafted features \\n    - Convolution\\n    - Max Pooling -> P_r \\n  ii) Graph \\n    - GGNN (not edge-type specific)\\n    - Hierarchical self-attention graph pooling layer -> H_{top-k}\\n    - Compute H_global = \\\\sum_{i \\\\in V} Softmax(MLP(h_i^T)) * h_i\\n    - S_r = H_{top-k} + H_global\\n2) X_r = [P_r; S_r]\\n3) FNN w/ Sigmoid on X_r\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Given a graph, classify it as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given a graph, classify it as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection in Smart Contracts\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 21,\n  \"pdf-id\": 34,\n  \"graphs\": {\n    \"fa-ast\": {\n      \"name\": \"FA-AST (Flow-Augmented AST)\",\n      \"description\": null,\n      \"artefacts\": [\n        {\n          \"name\": \"Source code (file)\",\n          \"details\": null\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Purely syntactic nodes (e.g. \\\"{\\\") removed\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST child\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"AST parent\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"FA Next Token\",\n          \"details\": \"Connects one terminal leaf node to next terminal leaf node\"\n        },\n        {\n          \"name\": \"FA Next Sibling\",\n          \"details\": \"Connects each node to its next sibling\"\n        },\n        {\n          \"name\": \"FA Next Use\",\n          \"details\": \"Connects a node representing a variable to the next use of said variable\"\n        },\n        {\n          \"name\": \"FA If Flow\",\n          \"details\": \"Connects condition of if statement with code block that is executed if the condition is true\"\n        },\n        {\n          \"name\": \"FA Else Flow\",\n          \"details\": \"Connects condition of if statement with code block that is executed if the condition is false\"\n        },\n        {\n          \"name\": \"FA While Flow\",\n          \"details\": \"Connects condition of while statement with code block that is executed while the condition is true.\\n\\nThe block also has a FA Next Use back to the condition\"\n        },\n        {\n          \"name\": \"FA For Flow\",\n          \"details\": \"Connects condition of for statement with code block that is executed while the condition is true.\\n\\nThe block also has a FA Next Use back to the condition\"\n        },\n        {\n          \"name\": \"FA Next Statement Flow\",\n          \"details\": \"Edge to the directly following statement\"\n        }\n      ],\n      \"vertex-features\": \"na / Not specified (unclear how embeddings are initialised)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"tap-gnn-gcn\": {\n      \"type\": {\n        \"name\": \"TEP-GNN\",\n        \"architecture\": \"3-layer GCN w/ ReLU\\nglobal max pooling\\nlinear layer\"\n      }\n    },\n    \"tap-gnn-ggnn\": {\n      \"type\": {\n        \"name\": \"TEP-GNN\",\n        \"architecture\": \"3-layer GGNNN w/ ReLU\\nglobal max pooling\\nlinear layer\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"runtime-prediction\": {\n      \"training-objective\": \"Given a graph representing a file of unit test, predict the runtime\",\n      \"training-granularity\": \"Graph Regression\",\n      \"working-objective\": \"Given a graph representing a file of unit test, predict the runtime\",\n      \"working-granularity\": \"Graph Regression\",\n      \"application\": \"Unit Test Runtime Prediction\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"fa-ast\",\n      \"model\": \"tap-gnn-gcn\",\n      \"task\": \"runtime-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"fa-ast\",\n      \"model\": \"tap-gnn-ggnn\",\n      \"task\": \"runtime-prediction\",\n      \"comments\": \"Only used as a baseline to evaluate the benefits of GCN\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 9,\n  \"pdf-id\": 16,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"tree-transformer\": {\n      \"type\": {\n        \"name\": \"Tree-Transformer\",\n        \"architecture\": \"Idea: Compute embeddings, then propagate information up, then down, then pooling.\\n\\nTrainable Embedding Layer (for embedding nodes)\\nBottom-up Propagation Unit:\\n  - For a leave node, output is unchanged \\n  - For a non-leave node i, the output depends on the node embedding e_i, \\n      and the embeddings of the children nodes (as computed by  the recursive propagation unit)\\n      H_{c,i} = (h_{i,1}, h_{i,2}, ..., h_{i,n}).\\n    i) H_{c,i}' = MultiHead_f(H_{c,i}, H_{c,i}, H_{c,i})    (fraternal self-attention multi-head w/ TUPE position encoding; model sibling dependencies; 4 attention heads)\\n    ii) H_{c,i}' = LayerNorm(H_{c,i}' + H_{c,i})            (normalization)\\n    iii) A = MultiHead_p(e_i, H_{c,i}', H_{c,i}')           (parental multi-head attention; model parent-child dependencies; 4 attention heads)\\n    iv) A' = LayerNorm(A + e_i)                             (normalization)\\n    v)  h_{i} = LayerNorm(FNN(A') + A')                     (feed-forward network)\\nTop-down Propagation Unit:\\n  - For the root node, f_i = h_i (output of the bottom-up propagation unit)\\n  - For every root with top-down representation f_i, \\n      f_i is used to compute the top-down representations F_{c,i} of i's children.\\n    i) F_{c,i}' = LayerNorm(1 \\\\cdot f_i + H_{c,i})\\n    ii) F_{c,i} = LayerNorm(FNN(F_{c,i}') + F_{c,i}')\\n\\\"Global attention pooling function\\\" (actual name from literature) to compute tree representation:\\n  h = sum_{i \\\\in V} softmax(W f_i) \\\\odot f_i\\n\\n  Where W is a learnable vector and \\\\odot is element-wise multiplication.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"program-classification\": {\n      \"training-objective\": \"Classify graph into program type\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify graph into program type\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Program Classification\",\n      \"supervision\": \"Supervised\"\n    },\n    \"wrong-operator\": {\n      \"training-objective\": \"Identify incorrect binary operator node and predict correct one\",\n      \"training-granularity\": \"Node Classification/Prediction\",\n      \"working-objective\": \"Identify incorrect binary operator node and predict correct one\",\n      \"working-granularity\": \"Node Classification/Prediction\",\n      \"application\": \"Wrong Operator Localisation and Repair\",\n      \"supervision\": \"Supervised\"\n    },\n    \"type-inference\": {\n      \"training-objective\": \"Assign Label (type) to Tree Nodes\",\n      \"training-granularity\": \"Node Classification\",\n      \"working-objective\": \"Assign Label (type) to Tree Nodes\",\n      \"working-granularity\": \"Node Classification\",\n      \"application\": \"Type Inference\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"training\": {\n    \"program-classification-poj\": {\n      \"train-test-split\": {\n        \"train\": 0.7,\n        \"test\": 0.1,\n        \"validation\": 0.2\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"Node Embedding Dimension\",\n          \"value\": 128\n        },\n        {\n          \"name\": \"optimiser\",\n          \"value\": \"adam\"\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.002\n        },\n        {\n          \"name\": \"optimiser warm up steps\",\n          \"value\": 2000\n        }\n      ],\n      \"hyper-parameter-selection\": \"not specified\",\n      \"search-tuned-hyper-parameters\": \"n/a\",\n      \"evaluation-details\": \"n/a\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"accuracy\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        }\n      ]\n    },\n    \"program-classification-java-250\": {\n      \"train-test-split\": {\n        \"train\": 0.6,\n        \"test\": 0.2,\n        \"validation\": 0.2\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"Node Embedding Dimension\",\n          \"value\": 256\n        },\n        {\n          \"name\": \"optimiser\",\n          \"value\": \"adam\"\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.002\n        },\n        {\n          \"name\": \"optimiser warm up steps\",\n          \"value\": 2000\n        }\n      ],\n      \"hyper-parameter-selection\": \"not specified\",\n      \"search-tuned-hyper-parameters\": \"n/a\",\n      \"evaluation-details\": \"n/a\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"accuracy\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        }\n      ]\n    },\n    \"program-classification-python-800\": {\n      \"train-test-split\": {\n        \"train\": 0.6,\n        \"test\": 0.2,\n        \"validation\": 0.2\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"Node Embedding Dimension\",\n          \"value\": 256\n        },\n        {\n          \"name\": \"optimiser\",\n          \"value\": \"adam\"\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.002\n        },\n        {\n          \"name\": \"optimiser warm up steps\",\n          \"value\": 2000\n        }\n      ],\n      \"hyper-parameter-selection\": \"not specified\",\n      \"search-tuned-hyper-parameters\": \"n/a\",\n      \"evaluation-details\": \"n/a\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"accuracy\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        }\n      ]\n    },\n    \"program-classification-cpp-1000\": {\n      \"train-test-split\": {\n        \"train\": 0.6,\n        \"test\": 0.2,\n        \"validation\": 0.2\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"Node Embedding Dimension\",\n          \"value\": 256\n        },\n        {\n          \"name\": \"optimiser\",\n          \"value\": \"adam\"\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.002\n        },\n        {\n          \"name\": \"optimiser warm up steps\",\n          \"value\": 2000\n        }\n      ],\n      \"hyper-parameter-selection\": \"not specified\",\n      \"search-tuned-hyper-parameters\": \"n/a\",\n      \"evaluation-details\": \"n/a\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"accuracy\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        }\n      ]\n    },\n    \"program-classification-cpp-1400\": {\n      \"train-test-split\": {\n        \"train\": 0.6,\n        \"test\": 0.2,\n        \"validation\": 0.2\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"Node Embedding Dimension\",\n          \"value\": 256\n        },\n        {\n          \"name\": \"optimiser\",\n          \"value\": \"adam\"\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.002\n        },\n        {\n          \"name\": \"optimiser warm up steps\",\n          \"value\": 2000\n        }\n      ],\n      \"hyper-parameter-selection\": \"not specified\",\n      \"search-tuned-hyper-parameters\": \"n/a\",\n      \"evaluation-details\": \"n/a\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"accuracy\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        }\n      ]\n    },\n    \"wrong-operator\": {\n      \"train-test-split\": {\n        \"train\": 0.6,\n        \"test\": 0.33,\n        \"validation\": 0.07\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"Node Embedding Dimension\",\n          \"value\": 256\n        },\n        {\n          \"name\": \"optimiser\",\n          \"value\": \"adam\"\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.002\n        },\n        {\n          \"name\": \"optimiser warm up steps\",\n          \"value\": 2000\n        }\n      ],\n      \"hyper-parameter-selection\": \"not specified\",\n      \"search-tuned-hyper-parameters\": \"n/a\",\n      \"evaluation-details\": \"n/a\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"accuracy\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        }\n      ]\n    },\n    \"type-inference\": {\n      \"train-test-split\": {\n        \"train\": 0.9208,\n        \"test\": 0.0422,\n        \"validation\": 0.03698\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"Node Embedding Dimension\",\n          \"value\": 256\n        },\n        {\n          \"name\": \"optimiser\",\n          \"value\": \"adam\"\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.002\n        },\n        {\n          \"name\": \"optimiser warm up steps\",\n          \"value\": 2000\n        }\n      ],\n      \"hyper-parameter-selection\": \"not specified\",\n      \"search-tuned-hyper-parameters\": \"n/a\",\n      \"evaluation-details\": \"n/a\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"accuracy\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        }\n      ]\n    }\n  },\n  \"datasets\": {\n    \"poj\": {\n      \"name\": \"POJ\",\n      \"description\": \"Program classification dataset with 104 classes of programs.\",\n      \"source\": [\n        \"Student programming platforms\"\n      ],\n      \"labelling\": \"not specified\",\n      \"size\": 52000,\n      \"is-pre-existing\": true\n    },\n    \"java-250\": {\n      \"name\": \"Java250\",\n      \"description\": \"Program classification dataset with 250 classes of programs.\",\n      \"source\": [\n        \"Part of CodeNet Dataset\"\n      ],\n      \"labelling\": \"not specified\",\n      \"size\": 75000,\n      \"is-pre-existing\": true\n    },\n    \"python-800\": {\n      \"name\": \"Python800\",\n      \"description\": \"Program classification dataset with 800 classes of programs.\",\n      \"source\": [\n        \"Part of CodeNet Dataset\"\n      ],\n      \"labelling\": \"not specified\",\n      \"size\": 240000,\n      \"is-pre-existing\": true\n    },\n    \"cpp-1000\": {\n      \"name\": \"C++1000\",\n      \"description\": \"Program classification dataset with 1000 classes of programs.\",\n      \"source\": [\n        \"Part of CodeNet Dataset\"\n      ],\n      \"labelling\": \"not specified\",\n      \"size\": 500000,\n      \"is-pre-existing\": true\n    },\n    \"cpp-1400\": {\n      \"name\": \"C++1400\",\n      \"description\": \"Program classification dataset with 1400 classes of programs.\",\n      \"source\": [\n        \"Part of CodeNet Dataset\"\n      ],\n      \"labelling\": \"not specified\",\n      \"size\": 420000,\n      \"is-pre-existing\": true\n    },\n    \"wrong-operator\": {\n      \"name\": \"Wrong Operator\",\n      \"description\": \"Synthetic dataset based on the dataset released by CuBERT.\\n\\nMeant for wrong operator localisation and repair.\",\n      \"source\": [\n        \"based on dataset released by CuBERT\"\n      ],\n      \"labelling\": \"not specified\",\n      \"size\": 258727,\n      \"is-pre-existing\": false\n    },\n    \"type-inference\": {\n      \"name\": \"ManyTypes4TypeScript\",\n      \"description\": \"Type Inference dataset for Typescript, with some filtering on graph size applied.\",\n      \"source\": [\n        \"Open Source Github Projects\"\n      ],\n      \"labelling\": \"not specified\",\n      \"size\": 660450,\n      \"is-pre-existing\": true\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"tree-transformer\",\n      \"task\": \"program-classification\",\n      \"training\": \"program-classification-poj\",\n      \"dataset\": \"poj\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"tree-transformer\",\n      \"task\": \"program-classification\",\n      \"training\": \"program-classification-java-250\",\n      \"dataset\": \"java-250\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"tree-transformer\",\n      \"task\": \"program-classification\",\n      \"training\": \"program-classification-python-800\",\n      \"dataset\": \"python-800\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"tree-transformer\",\n      \"task\": \"program-classification\",\n      \"training\": \"program-classification-cpp-1000\",\n      \"dataset\": \"cpp-1000\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"tree-transformer\",\n      \"task\": \"program-classification\",\n      \"training\": \"program-classification-cpp-1400\",\n      \"dataset\": \"cpp-1400\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"tree-transformer\",\n      \"task\": \"wrong-operator\",\n      \"training\": \"wrong-operator\",\n      \"dataset\": \"wrong-operator\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"tree-transformer\",\n      \"task\": \"type-inference\",\n      \"training\": \"type-inference\",\n      \"dataset\": \"type-inference\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 195,\n  \"pdf-id\": 260,\n  \"graphs\": {\n    \"flow-enriched-ast\": {\n      \"name\": \"Flow-Enriched AST\",\n      \"description\": \"AST with control and data flow\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": null\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"undirected\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"undirected\"\n        },\n        {\n          \"name\": \"Data Flow Edge -- LastRead\",\n          \"details\": \"undirected\"\n        },\n        {\n          \"name\": \"Data Flow Edge -- LastWrite\",\n          \"details\": \"undirected\"\n        },\n        {\n          \"name\": \"Data Flow Edge -- ComputeFrom\",\n          \"details\": \"undirected\"\n        }\n      ],\n      \"vertex-features\": \"One-hot encoded node type\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"(note: separate GCN module for every language)\\n\\n1) Node feature passed through linear layer \\n2) Blocks of GCN followed by LSTM (LSTM used to learn from historic node representations?)\\n    Final LSTM output is used for final node representation \\n3) Compute H_a: concatenation of all node feature matrices after each GCN iteration \\n    (required for unsupervised learning)\\n4) set2set graph pooling layer on output of last GCN/LSTM round \\n5) Representations for pair of input snippets is concatenated, passed through FNN w/ sigmoid\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-clone-detection\": {\n      \"training-objective\": \"Given two code snippets, determine whether they are semantic clones\",\n      \"training-granularity\": \"Graph Classification (?)\",\n      \"working-objective\": \"Given two code snippets, determine whether they are semantic clones\",\n      \"working-granularity\": \"Graph Classification (?)\",\n      \"application\": \"Cross Language Code Clone Detection\",\n      \"supervision\": \"Supervised\"\n    },\n    \"embedding\": {\n      \"training-objective\": \"maximise mutual information (MI) between H_a and all H_a^i (local AST substructures)\",\n      \"training-granularity\": \"Graph Embedding Learning\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Representation (pre-)learning\",\n      \"supervision\": \"Unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"flow-enriched-ast\",\n      \"model\": \"model\",\n      \"task\": \"code-clone-detection + embedding\",\n      \"comments\": \"As far as I understand, the embedding task is used to improve performance in an unsupervised manner\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 14,\n  \"pdf-id\": 22,\n  \"graphs\": {\n    \"rep-hg\": {\n      \"name\": \"Rep-HG\",\n      \"description\": \"Heterogeneous graph structure connecting repositories,\\nusers, and topics (tags) on Github.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code (repository)\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Metadata (repository)\",\n          \"details\": \"Non-source code artefacts in a repository (e.g. README file)\"\n        },\n        {\n          \"name\": \"User Profile Data\",\n          \"details\": \"Bio information. E.g. name, description, contact information\"\n        },\n        {\n          \"name\": \"Topic\",\n          \"details\": \"Topic on Github\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Repository\",\n          \"details\": \"Comprises two types of artefacts\"\n        },\n        {\n          \"name\": \"User\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Topic\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"R1; repository-belongto-user\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"R2; repository-contain-topic\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"R3; repository-forkby-user\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"R4; repository-starby-user\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"For repository nodes, all metadata and source code is combined into a single feature vector using BERT.\\nFor users, the user profile data as well as the _metadata_ of repositories belonging to the user are combined into a single feature vector using BERT.\\nThe topic is encoded as a single feature vector using BERT.\\nUsing the above features as-is will be referred to as the regular HG-graph, or node view.\\nThree meta-paths are also used. There are i) Repo --forkby--> User --forky^-1--> Repo i) Repo --starby--> User --starby^-1--> Repo i) Repo --contain--> Topic --contain^-1--> Repo\\nEach meta path is used separately in combination with random walk with restart in order to sample a subgraph defined by the meta-path.\",\n      \"edge-features\": null,\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"embedder\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"For parts 1, 2 below, possibly heterogeneous embeddings are transformed \\nto a common space according to \\n\\nx_i = X_i W_{T_i}\\n\\nHere, X_i are the features of node i, T_i the type of node i, \\nW_{T_i} the weight matrix for type T_i, and x_i the new node features.\\n\\nThe main decoder consists of multiple parallel pipelines: \\n  1) A 2-layer GCN (size 200) (w/ ReLU) encoder for the HG-Rep graph, which optimises a loss L_{orig,node}\\n  2) A 2-layer GCN (size 200) (w/ ReLU) encoder for the HG-Rep graph, which is trained in an adversarial setting,\\n      which optimises a loss L_{adv,node}.\\n\\n      The adversarial step is a PGD attack (adversarial perturbation attack),\\n      which finds a perturbation \\\\delta of the node embeddings such that\\n      L_{adv,node}(x + \\\\delta \\\\mid \\\\theta) is maximised (where x is the input graph/original embeddings).\\n  3) A 2-layer GCN (size 200) (w/ ReLU) encoder for the meta-path subgraphs, which optimises a loss L_{orig,mp}\\n  4) A 2-layer GCN (size 200) (w/ ReLU) encoder for the meta-path subgraphs, which is trained in an adversarial setting,\\n      which optimises a loss L_{adv,mp}.\\n\\n  The weights between pipelines (1, 2) and (3, 4) are shared. Unclear if it is all the same GNN. This is most likely the case\\n\\n  The losses are then aggregated according to:\\n\\n  L_{adv} = \\\\sum_{i \\\\in V} \\\\left|\\\\lambda_{adv}L_{adv,node} + (1 - \\\\lambda_{adv})L_{adv,mp}\\\\right|\\n  \\n  L_{orig} = \\\\sum_{i \\\\in V} \\\\left|\\\\lambda_{orig}L_{orig,node} + (1 - \\\\lambda_{orig})L_{orig,mp}\\\\right|\\n  \\n  where \\\\lambda_{adv} and \\\\lambda_{orig} are hyperparameters.\\n\\n  These two losses are then finally aggregated according to:\\n\\n  L_{dual} = \\\\alpha L_{adv} + (1 - \\\\alpha) L_{orig}\\n\\n  where \\\\alpha is a hyperparameter.\\n\\n  \\n  For downstream tasks, knowledge distillation is used.\\n  The goal is to combine the unsupervised knowledge from the encoder\\n  with the supervised knowledge from the downstream task.\\n\\n  First, a student model with architecture identical to the \\n  encoder (\\\"teacher model\\\") is initialised with the learnt \\n  parameters of the teach model.\\n\\n  Then, the student model is trained to minimise the following loss:\\n\\n  L = \\\\beta L_{task} + (1 - \\\\beta) L_{kd}\\n\\n  Where\\n    \\\\beta is a hyperparameter\\n    L_{kd} = \\\\sum_{v_o,v_i\\\\in V} L_h(\\\\phi^T(z_o, z_i), \\\\phi^S(z_o, z_i))\\n    \\\\phi^T(z_o, z_i) = \\\\frac{1}{u}||z_o - z_i||^2 , with u a normalisation constant and z_o and z_i the embeddings of the teacher model\\n    \\\\phi^S(z_o, z_i) = \\\\frac{1}{u}||z_o - z_i||^2, with u a normalisation constant and z_o and z_i the embeddings of the student model\\n    L_h(a, b) = \\\\begin{cases}\\n      \\\\frac{1}{2}(a - b)^2 & |a - b| \\\\le 1 \\\\\\\\\\n      |a - b| - 1/2 & |a - b| > 1\\n    \\\\end{cases} (Huber loss)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"embedding\": {\n      \"training-objective\": \"Minimise the contrastive loss function (project similar samples close together; dissimilar samples further apart)\",\n      \"training-granularity\": \"Graph Embedding\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Repository Embedding\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"training\": {\n    \"embedding-computation\": {\n      \"train-test-split\": \"n/a\",\n      \"cross-validation\": \"n/a\",\n      \"hyper-parameters\": [\n        {\n          \"name\": \"optimizer\",\n          \"value\": \"adam\"\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.001\n        },\n        {\n          \"name\": \"weight decay\",\n          \"value\": 1e-06\n        },\n        {\n          \"name\": \"Node view temperature t_{nd}\",\n          \"value\": 0.6\n        },\n        {\n          \"name\": \"Meta path view temperature t_{mp}\",\n          \"value\": 0.6\n        },\n        {\n          \"name\": \"\\\\lambda_{adv}\",\n          \"value\": 0.5\n        },\n        {\n          \"name\": \"\\\\lambda_{orig}\",\n          \"value\": 0.5\n        },\n        {\n          \"name\": \"\\\\alpha\",\n          \"value\": 0.7\n        },\n        {\n          \"name\": \"\\\\beta\",\n          \"value\": 0.7\n        },\n        {\n          \"name\": \"epochs\",\n          \"value\": 500\n        },\n        {\n          \"name\": \"early stopping patience\",\n          \"value\": 50\n        },\n        {\n          \"name\": \"number of contrastive pairs K in node view\",\n          \"value\": 10\n        },\n        {\n          \"name\": \"batch size\",\n          \"value\": 2000\n        },\n        {\n          \"name\": \"L_{adv,node}^i (loss for node i)\",\n          \"value\": \"-log \\\\frac{\\\\sum_{j \\\\in V_i^l \\\\exp\\\\left(sim(\\\\tilde{z_i}, \\\\tilde{z_j})/t_{nd}\\\\right)}}{\\\\sum_{j \\\\in V_i^s \\\\exp\\\\left(sim(\\\\tilde{z_i}, \\\\tilde{z_j})/t_{nd}\\\\right)}} \\n\\nV_i^l; K most similar nodes. \\nV_i^s; K least similar nodes. \\nsim; cosine similarity\"\n        },\n        {\n          \"name\": \"L_{adv,mp}^i (loss for meta path i)\",\n          \"value\": \"-log \\\\frac{\\\\exp(sim(h_i^{p_l}, h_j^{p_m})/t_{mp})}{\\\\sum_{k=1}^{2n} \\\\Theta[i \\\\ne k]\\\\exp(sim(h_i^{p_l}, h_k^{p_m})/t_{mp})}\\n\\nHere, h_i^{p_l}; node i in the meta path p_l\\n\\\\Theta: indicator function\"\n        }\n      ],\n      \"hyper-parameter-selection\": \"experimenting\",\n      \"search-tuned-hyper-parameters\": [\n        \"Number of contrastive pairs K\",\n        \"\\\\alpha\",\n        \"\\\\beta\"\n      ],\n      \"evaluation-details\": \"Evaluated on two downstream tasks (malicious repository detection and repository link prediction)\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"Accuracy\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"f1-score\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Malicious Repository Detection\",\n          \"type\": \"downstream task\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Repository Link Prediction\",\n          \"type\": \"downstream task\",\n          \"details\": \"Done by removing a certain percentage of edges (20%, 80%) from the graph\\nbefore embedding training; only R3 and R4 edges.\"\n        }\n      ]\n    }\n  },\n  \"datasets\": {\n    \"embedding-dataset\": {\n      \"name\": \"n/a\",\n      \"description\": \"Dataset of github repositories, users, and topics,\\nwith repositories labelled as malware/not malware.\\n\\nDataset contains 3341 malicious repositories,\\n6682 benign repositories.\",\n      \"source\": [\n        \"GitHub\"\n      ],\n      \"labelling\": \"Done by having experts examine the output of running VirusTotal on repositories.\",\n      \"size\": \"Single graph with 110865 nodes and 899600 edges\",\n      \"is-pre-existing\": false\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"rep-hg\",\n      \"model\": \"embedder\",\n      \"task\": \"embedding\",\n      \"training\": \"embedding-computation\",\n      \"dataset\": \"embedding-dataset\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": [\n    \"A lot of details in the paper are up to interpretation\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 101,\n  \"pdf-id\": 137,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"undirected\"\n        }\n      ],\n      \"vertex-features\": \"Tokens encoded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"n/a First, note embeddings passed through attention mechanism followed by FNN GCN ReLU Softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"fault-localisation\": {\n      \"training-objective\": \"Given a graph, identify the node(s?) corresponding to the faulty statement\",\n      \"training-granularity\": \"Node classification\",\n      \"working-objective\": \"Given a graph, identify the node(s?) corresponding to the faulty statement\",\n      \"working-granularity\": \"Node classification\",\n      \"application\": \"Fault Localisation\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"fault-localisation\",\n      \"comments\": \"Unclear if there is only one faulty node per graph or multiple.\\nSimilarly, it is unclear whether only a single node is predicted \\nas being faulty, or multiple. I get the feeling it is the latter, \\nbut I am not sure.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 203,\n  \"pdf-id\": 272,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST with additional edges. \\n\\nThere might be more edges than listed in the list below. \\nThe paper is unclear about this.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"If Edge\",\n          \"details\": \"Connects If statement node with condition and block\"\n        },\n        {\n          \"name\": \"For Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"While Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Graph Attention Layer (as used in GAT), with averaging in the final step (not concatenation)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"clone-detection\": {\n      \"training-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"training-granularity\": \"Graph Classification (?)\",\n      \"working-objective\": \"Given two code samples, determine whether they are semantic clones\",\n      \"working-granularity\": \"Graph Classification (?)\",\n      \"application\": \"Code Clone Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 135,\n  \"pdf-id\": 178,\n  \"graphs\": {\n    \"augmented-code-property-graph\": {\n      \"name\": \"Augmented Code Property Graph\",\n      \"description\": \"Code property graph, including call information\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"file\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Three main attributes; 1) node type, 2) node code, 3) node location \\n\\nNodes are pruned:\\n1) Nodes with syntactic elements which are characteristics of certain bugs are selected\\n2) All nodes making up the statements these nodes are part of are selected \\n3) all nodes making up statements with data and call relationships to these statements are selected.\\n4) For all selected nodes, a nearest neighbour set is computed \\n5) All selected nodes are kept \\n\\nThe result is multiple possible graphs per file.\\nFurthermore, each graph is associated with a certain defect type.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"Every edge has three main attributes; 1) source node, 2) destination node, 3) edge type\\nNote that the node type is actually one of 24 possible types (the four shown here is a simplification)\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"Every edge has three main attributes; 1) source node, 2) destination node, 3) edge type\\nNote that the node type is actually one of 24 possible types (the four shown here is a simplification)\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"Every edge has three main attributes; 1) source node, 2) destination node, 3) edge type\\nNote that the node type is actually one of 24 possible types (the four shown here is a simplification)\"\n        },\n        {\n          \"name\": \"Call Edge\",\n          \"details\": \"Every edge has three main attributes; 1) source node, 2) destination node, 3) edge type\\nNote that the node type is actually one of 24 possible types (the four shown here is a simplification)\"\n        }\n      ],\n      \"vertex-features\": \"The tokens in the node value are encoded using word2vec,\\nand combined using kernel PCA.\\n\\nnode type is embedded using integer,\\n\\nThe two embeddings are concatenated.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"(sparse) adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gcn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Repeated modules of: [GCN, ReLU, BathNormalisation, Linear, Linear]\\nMLP\\nSoftmax\"\n      }\n    },\n    \"gin\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Repeated modules of: [GIN, ReLU, BathNormalisation, Linear, Linear]\\nMLP\\nSoftmax\"\n      }\n    },\n    \"sgc\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Repeated modules of: [SGC (Simplified Graph Convolutional Network), ReLU, BathNormalisation, Linear, Linear]\\nMLP\\nSoftmax\"\n      }\n    },\n    \"gat\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Repeated modules of: [GAT, ReLU, BathNormalisation, Linear, Linear]\\nMLP\\nSoftmax\"\n      }\n    },\n    \"graphsage\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Repeated modules of: [GraphSAGE, ReLU, BathNormalisation, Linear, Linear]\\nMLP\\nSoftmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"defect-prediction\": {\n      \"training-objective\": \"Given a sample, predict as defect or not defect\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given a sample, predict as defect or not defect\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Defect Prediction\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"augmented-code-property-graph\",\n      \"model\": \"gcn\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"augmented-code-property-graph\",\n      \"model\": \"gin\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"augmented-code-property-graph\",\n      \"model\": \"sgc\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"augmented-code-property-graph\",\n      \"model\": \"gat\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"augmented-code-property-graph\",\n      \"model\": \"graphsage\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 98,\n  \"pdf-id\": 134,\n  \"graphs\": {\n    \"code-property-graph\": {\n      \"name\": \"Code Property Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Concatenate word2vec embeddings of tokens\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Nodes are sequenced in a way preserving \\ntoken order from original code;\\nCorresponding feature vectors now \\nform a sequence of feature vectors\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Two separate models (trained independently):\\n\\n1) Graph Input\\n  GGNN network\\n  MLP \\n  Softmax (pointer network style)\\n\\n2) Sequenced data\\n  Transformer model \\n  MLP \\n  Softmax (pointer network style)\\n\\nEnsemble created by averaging predicted probabilities.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Assign a probability to every node of it containing a probability;\\nnode with highest probability is taken as one which was \\npredicted as vulnerable (argmax).\\nDummy node is added which signifies a prediction of not vulnerable.\",\n      \"training-granularity\": \"Node Identification/Node Classification (?)\",\n      \"working-objective\": \"Assign a probability to every node of it containing a probability;\\nnode with highest probability is taken as one which was \\npredicted as vulnerable (argmax).\\nDummy node is added which signifies a prediction of not vulnerable.\",\n      \"working-granularity\": \"Node Identification/Node Classification (?)\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 86,\n  \"pdf-id\": 118,\n  \"graphs\": {\n    \"sliced-sdg\": {\n      \"name\": \"SDG (Sub-dependence Graph)\",\n      \"description\": \"Program Dependence Graph with slicing applied;\\nonly those nodes _from which_ a dangerous function\\ncall is reachable, are kept.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"Names in the code are normalised\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Flow Dependency Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Statements are encoded using doc2vec (PV-DM)\",\n      \"edge-features\": null,\n      \"connectivity-features\": null,\n      \"graph-features\": null,\n      \"other-features\": null\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN Layer\\nTop-k Graph Pooling Layer\\nAttention Layer\\n\\nFor each layer $k$, the following output is computed: \\n  s^k = \\\\frac{1}{N_k}\\\\sum_{i = 1}^{N_k} x_{k,i} \\\\mid\\\\mid \\\\max_{1 \\\\le j \\\\le N_k} x_{k,j}\\n\\n  Here, $N_k$ is the number of nodes in layer $k$.\\n\\nFinal embedding:\\n  y = \\\\sum_{k = 1}^{K} s^k\\n\\nMLP(y)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable/not vulnerable\",\n      \"training-granularity\": \"Graph Classification (Binary)\",\n      \"working-objective\": \"Classify sample as vulnerable/not vulnerable\",\n      \"working-granularity\": \"Graph Classification (Binary)\",\n      \"application\": \"Vulnerability Detection in PHP code\",\n      \"supervision\": \"Supervised\"\n    },\n    \"vulnerability-classification\": {\n      \"training-objective\": \"Classify sample in a vulnerability category or as not vulnerable\",\n      \"training-granularity\": \"Multi-class Graph Classification\",\n      \"working-objective\": \"Classify sample in a vulnerability category or as not vulnerable\",\n      \"working-granularity\": \"Multi-class Graph Classification\",\n      \"application\": \"Vulnerability Detection in PHP code\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"sliced-sdg\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 18,\n  \"pdf-id\": 29,\n  \"graphs\": {\n    \"augmented-ast\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST with various augmentations\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST node\",\n          \"details\": \"Basic structure is AST, with some simplifications:\\n\\n1) mentions of the same variable inside the name function are merged into a single node\\n2) mentions of the same function/class in a file are merged into a single node\\n3) All constants are erased and replaced with one global (shared) node \\n3) All identifiers are suffixed with their (inner-most) scope\"\n        },\n        {\n          \"name\": \"Subword node\",\n          \"details\": \"Identifiers in code are split into subwords, and each subword is represented by a separate node\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Next/Prev edge\",\n          \"details\": \"Next/prev edges between successive expressions\"\n        },\n        {\n          \"name\": \"Control block edge\",\n          \"details\": \"All expressions in a control block (e.g. if) link back to the parent control operator (e.g. if)\"\n        },\n        {\n          \"name\": \"function call edge (cross-file)\",\n          \"details\": \"Function callee is linked to called function\"\n        },\n        {\n          \"name\": \"Inheritance edge (cross-file)\",\n          \"details\": \"Child class is linked to parent class\"\n        },\n        {\n          \"name\": \"Import edge (cross-file)\",\n          \"details\": \"Link items in one file to items from other files\"\n        },\n        {\n          \"name\": \"Subword edge\",\n          \"details\": \"Edge from every subword (e.g. \\\"a\\\") to all nodes containing that subword (e.g. \\\"a@FunctionDef_scale\\\")\"\n        }\n      ],\n      \"vertex-features\": \"Not specified (unclear how initial vector representation is determined)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gnn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"RGCN w/ ReLU (Relational Graph Convolutional Network)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"auto-encoder\": {\n      \"training-objective\": \"Reconstruct the connections in the network from node embedding\",\n      \"training-granularity\": \"Edge prediction (?)\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Node Embedding for Type Prediction (hence, node embedding for use in downstream task)\",\n      \"supervision\": \"Unsupervised (Self-supervised)\"\n    },\n    \"name-prediction\": {\n      \"training-objective\": \"Predict the (masked) names of node representing function and variable names\",\n      \"training-granularity\": \"Node prediction\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Node Embedding for Type Prediction (hence, node embedding for use in downstream task)\",\n      \"supervision\": \"Unsupervised (Self-supervised)\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"augmented-ast\",\n      \"model\": \"gnn\",\n      \"task\": \"auto-encoder\",\n      \"comments\": \"Combined w/ name-prediction to pre-train the model\"\n    },\n    {\n      \"graph\": \"augmented-ast\",\n      \"model\": \"gnn\",\n      \"task\": \"name-prediction\",\n      \"comments\": \"Combined w/ auto-encoder to pre-train the model\"\n    }\n  ],\n  \"comments\": [\n    \"The paper does not explain all concepts clearly\",\n    \"the image in the paper seemingly contradicts the text\",\n    \"The construction of the graph is ambiguous (e.g. direction of edges)\",\n    \"Auto-encoder setup is strange (strange loss, no reference to the standard graph auto encoder)\",\n    \"Strange loss function is used\",\n    \"This paper is very low quality\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 154,\n  \"pdf-id\": 203,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Code tokens (in sequence) are also used as separate input.\\n\\nComment generated thus far (in tokens) is also given as input.\"\n    }\n  },\n  \"models\": {\n    \"g-trans\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Two parallel encoders:\\n  i) Graph Encoder\\n    - Embedding Layer\\n    - GGNN \\n  ii) Token Encoder (Regular Transformer Encoder)\\n    - Embedding Layer \\n    - Self multi-head attention w/ residual connections and normalisation\\n    - FNN (2x layers w/ Relu) w/ residual connections and normalisation\\n2) Decoder\\n  i) Embedding Layer (for comment)\\n  ii) Multi-head self-attention\\n  iii) Multi-head attention with K and V derived from graph\\n  iv) Multi-head attention with K and V derived from tokens \\n  v) FNN\\n  vi) Copy mechanism (Ahmad et al. 2020) \\n      (copy distribution generated using last decoder output\\n      and output of token encoder. Last decoder output used to obtain final distribution)\"\n      }\n    },\n    \"g-trans-modified\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Two parallel encoders:\\n  i) Graph Encoder\\n    - Embedding Layer\\n    - GGNN \\n  ii) Token Encoder (Regular Transformer Encoder)\\n    - Embedding Layer \\n    - Self multi-head attention w/ residual connections and normalisation\\n    - FNN (2x layers w/ Relu) w/ residual connections and normalisation\\n2) Decoder\\n  i) Embedding Layer (for comment)\\n  ii) Multi-head self-attention\\n  iii) Multi-head attention with K and V derived from tokens \\n  iv) Multi-head attention with K and V derived from graph\\n  v) FNN\\n  vi) Copy mechanism (Ahmad et al. 2020) \\n      (copy distribution generated using last decoder output \\n        and output of graph node encoder. Last decoder output used to obtain final distribution)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"comment-generation\": {\n      \"training-objective\": \"Given a code snippet, generate a comment.\\nDone token-by-token; previous tokens are also given as input\",\n      \"training-granularity\": \"Graph + Sequence to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a comment.\\nDone token-by-token; previous tokens are also given as input\",\n      \"working-granularity\": \"Graph + Sequence to Sequence\",\n      \"application\": \"Code summarization (Comment Generation)\",\n      \"supervision\": \"Supervised\"\n    },\n    \"method-name-generation\": {\n      \"training-objective\": \"Given a code snippet, generate a method name.\\nDone token-by-token; previous tokens are also given as input\",\n      \"training-granularity\": \"Graph + Sequence to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a method name.\\nDone token-by-token; previous tokens are also given as input\",\n      \"working-granularity\": \"Graph + Sequence to Sequence\",\n      \"application\": \"Code summarization (Method Name Generation)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"g-trans\",\n      \"task\": \"comment-generation\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"g-trans-modified\",\n      \"task\": \"method-name-generation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 114,\n  \"pdf-id\": 153,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"AST is linearised using depth first traversal\\nto obtain sequence of tokens.\\n\\nTokens are encoded using word2vec\\n\\nSequence used as input for following network: \\nLSTM\\nGlobal Max Pooling\\nFNN Layer w/ tanh\\nFNN Layer w/ linear \\nFNN Layer w/ sigmoid\\n\\nafter training, the last two layers are removed \\nin order to obtain function level representations.\\n\\nThe network is trained on the vulnerability \\ndetection task. After training, it is used for embedding.\"\n    }\n  },\n  \"models\": {\n    \"rf\": {\n      \"type\": {\n        \"name\": \"Random Forest\",\n        \"architecture\": \"Random Forest\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable/not vulnerable\",\n      \"training-granularity\": \"Classification (not graph)\",\n      \"working-objective\": \"Classify sample as vulnerable/not vulnerable\",\n      \"working-granularity\": \"Classification (not graph)\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"rf\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 11,\n  \"pdf-id\": 19,\n  \"graphs\": {\n    \"api-context-graph\": {\n      \"name\": \"API Context Graph\",\n      \"description\": \"Describes (Java STD) API usages and their context\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code (method)\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"API method call\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"API field access\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Variable declaration\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Assignment\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Unit\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Hole\",\n          \"details\": \"Hole to be filled in with an API recommendation. Should be _1_ node in the graph.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"S\",\n          \"details\": \"There is an edge (u, v) of type S in one of two cases:\\n  1) v is the Hole node and u represents a statement directly preceding the hole.\\n  2) u is the Hole node and v represents a statement directly following the hole.\"\n        },\n        {\n          \"name\": \"CD\",\n          \"details\": \"There is a direct data flow and a direct control flow from the source to the target node\"\n        },\n        {\n          \"name\": \"C\",\n          \"details\": \"There is a control flow from the source to the target node, but no data flow\"\n        },\n        {\n          \"name\": \"D\",\n          \"details\": \"There is a data flow from the source to the target node, but no control flow\"\n        }\n      ],\n      \"vertex-features\": \"Node names are generated based upon a set or rules; \\n\\n1) Declaration -> [Full Class Name].Declaration (String str -> java.lang.String.Declaration)\\n2) Declaration w/ constant assignment -> [Full Class Name].Constant \\n3) Declaration w/ null assignment -> [Full Class Name].Null\\n4) Declaration w/ object creation -> [Full Class Name].new([parameter types])\\n5) API Method Call -> [Full Method Name]([parameter types])\\n6) API Field Access -> [Full Field Name]\\n7) Control unit -> [Name] (if -> if)\\n8) Nested API method call/field access (e.g. call inside call) -> list calls following above rules, inner to outer\\n9) cascading method calls/field access -> Keep cascading structure; only expand initial call\\n(note: cascading = chained)\",\n      \"edge-features\": \"Edge labels are not used as features\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Names as described for vertex features are tokenized by;\\n1) removing trailing numbers\\n2) splitting on underscores, numbers, dollar signs, camelCasing\\n3) duplicate and meaningless (single letter) tokens are discarded\\n4) remaining tokens are encoded using GloVe\"\n    }\n  },\n  \"models\": {\n    \"apirec-cst\": {\n      \"type\": {\n        \"name\": \"APIRec-CST\",\n        \"architecture\": \"Starts with two parallel paths:\\n  1) Takes as input the edges and graphs.\\n    i) Embedding layer is used to encode node labels \\n    ii) Uses GGNNs (unclear how many)\\n  2) Takes as input the bag of tokens \\n    i) Tokens embedding using trainable embedding layer\\n    ii) Each token passes through multiple FNN layers (3 layers, all of size 300)\\n    iii) All resulting embeddings are summed \\nTwo paths are joined with a concatenation layer\\nFNN layer with tanh activation\\noutput of last FNN layer is passed to softmax function\"\n      }\n    },\n    \"apirec-so\": {\n      \"type\": {\n        \"name\": \"APIRec-SO\",\n        \"architecture\": \"Takes as input the edges and graphs.\\ni) Embedding layer is used to encode node labels \\nii) Uses GGNNs (unclear how many)\\niii) Softmax output\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"api-recommendation\": {\n      \"training-objective\": \"Predict API\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Predict API\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"API recommendation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"training\": {\n    \"training\": {\n      \"train-test-split\": {\n        \"train\": 0.9,\n        \"test\": 0.0,\n        \"validation\": 0.1\n      },\n      \"cross-validation\": {\n        \"used\": false,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"hole size (max size of the hole in nodes; a control structure such as \\\"if\\\" and all its children count as a single node)\",\n          \"value\": 5\n        },\n        {\n          \"name\": \"node label embedding sie\",\n          \"value\": 300\n        },\n        {\n          \"name\": \"token embedding size\",\n          \"value\": 300\n        },\n        {\n          \"name\": \"dropout\",\n          \"value\": 0.75\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.005\n        },\n        {\n          \"name\": \"batch size\",\n          \"value\": 256\n        }\n      ],\n      \"hyper-parameter-selection\": \"trial experiments\",\n      \"search-tuned-hyper-parameters\": \"not specified\",\n      \"evaluation-details\": \"model is trained until validation accuracy does not improve for 5 epochs.\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"accuracy\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"top-k accuracy\",\n          \"type\": \"metric\",\n          \"details\": \"k = 1, 5, 10\"\n        },\n        {\n          \"name\": \"mean reciprocal rank\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"task completion time\",\n          \"type\": \"metric (user study)\",\n          \"details\": \"Time it takes developers to complete a task with the given tool\"\n        },\n        {\n          \"name\": \"test completion rate\",\n          \"type\": \"metric (user study)\",\n          \"details\": \"Fraction of tasks developers were able to complete using the given tool.\"\n        }\n      ]\n    }\n  },\n  \"datasets\": {\n    \"dataset\": {\n      \"name\": \"n/a\",\n      \"description\": \"Dataset of API context graphs and corresponding bag of tokens,\\nwith holes in the graph and appropriate tokens removed.\",\n      \"source\": [\n        \"All open source Java projects on GiHub with 1000 stars or more\"\n      ],\n      \"labelling\": \"Automatically by removing nodes from generated API context graphs, based on edge type.\",\n      \"size\": 7109777,\n      \"is-pre-existing\": false\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"api-context-graph\",\n      \"model\": \"apirec-cst\",\n      \"task\": \"api-recommendation\",\n      \"training\": \"training\",\n      \"dataset\": \"dataset\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"api-context-graph\",\n      \"model\": \"apirec-so\",\n      \"task\": \"api-recommendation\",\n      \"training\": \"training\",\n      \"dataset\": \"dataset\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": [\n    \"Does _not_ use a test set!!!\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 128,\n  \"pdf-id\": 171,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"The AST of the old and of the new function are both extracted. \\nThree subtrees are extracted\\n  1) The old (buggy) subtree\\n  2) The new (fixed) subtree\\n  3) The common context\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"patch\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"The tokens of leaf nodes are extracted as features.\\nNames are split up\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"All paths from the AST connecting two leaf nodes are extracted.\\nIf multiple paths are possible, the shorted is used.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) AST encoding\\n  Two learnable embeddings: one for node type, one for (sub-)tokens.\\n  The tokens in the path (_excluding_ the node tokens) are encoded\\n  as a single vector using LSTM. The resulting vector is concatenated \\n  with the token vectors.\\n  Paths for a single tree are combined using attention:\\n    z_i = \\\\tanh(W_f V_i)\\n    a_i = \\\\frac{\\\\exp(z_i^T \\\\cdot a)}{\\\\sum_{j = 1}^n \\\\exp(z_j^T \\\\cdot a)}\\n    E = \\\\sum_{i = 1}^k a_i \\\\cdot z_i\\n2) Concatenate vectors for buggy method and context\\n3) Concatenate vectors for fixed method and context\\n4) Combine the two vectors by concatenating:\\n  i) The result of adding the two vectors \\n  ii) The result of subtracting the two vectors\\n  iii) The Hadamard product of the two vectors\\n  iv) The cosine similarity of the two vectors (just a single number)\\n  v) Bilinear model (Tanenbaum et al.)\\n5) FNN\\n6) FNN\\n7) Softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"patch-correctness-assessment\": {\n      \"training-objective\": \"Predict whether the given fix for a bug is correct\",\n      \"training-granularity\": \"Graph Classification (somewhat; 3 graphs are given)\",\n      \"working-objective\": \"Predict whether the given fix for a bug is correct\",\n      \"working-granularity\": \"Graph Classification (somewhat; 3 graphs are given)\",\n      \"application\": \"Patch correctness assessment\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"patch-correctness-assessment\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 193,\n  \"pdf-id\": 258,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Next Token Edge\",\n          \"details\": \"NCS\"\n        },\n        {\n          \"name\": \"Last Lexical Use Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Unclear how nodes are encoded\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"query-graph\": {\n      \"name\": \"Parse Tree\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Summary of the source code (training) or query (working)\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Token\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Constituency Symbol\",\n          \"details\": \"e.g. \\\"VB\\\" (verb)\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Constituency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Word Ordering Edge\",\n          \"details\": \"Undirected\"\n        }\n      ],\n      \"vertex-features\": \"Unclear how nodes are encoded\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) RGCN module for graph encoding\\n2) Cross-attention similarity; Compute score for \\\"matching\\\" w/ code for every query token:\\n    e_{i,G} = \\\\frac{1}{N}\\\\sum_{j = 1}^N cosine-similarity(q_i, c_j)c_j\\n    (q: query node embedding, c: code node embedding)\\n3) Compute q_i' = [(q_i - e_{i,G}) \\\\odot (e_{i,G} - q_i); q_i \\\\odot e_{i,G}]\\n4) Do the same to compute c_i' for the code node embeddings \\n5) Compute H_q = MaxPool(FC({q_i' | 1 <= i <= M}))\\n6) Compute H_e = MaxPool(FC({c_i' | 1 <= i <= N}))\\n7) Compute cosine similarity between H_q and H_e\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-search\": {\n      \"training-objective\": \"Maximise similarity of related (summary, code) pairs; minimise similarity of unrelated (summary, code) pairs\",\n      \"training-granularity\": \"Graph Regression (?)\",\n      \"working-objective\": \"Output similarity scores of (query, code) pairs\",\n      \"working-granularity\": \"Graph Regression (?)\",\n      \"application\": \"Code Search\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + query-graph\",\n      \"model\": \"model\",\n      \"task\": \"code-search\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 12,\n  \"pdf-id\": 20,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"one-hot encoding of AST node type\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": null,\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gcn-graph\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN Layer GCN Layer GCN Layer GCN Layer Mean pooling of all node embeddings FNN Layer FNN Layer FNN Layer (size 2, softmax)\"\n      }\n    },\n    \"gat-graph\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GAT Layer w/ ReLU GAT Layer w/ ReLU GAT Layer w/ ReLU GAT Layer w/ ReLU Mean pooling of all node embeddings FNN Layer FNN Layer FNN Layer (size 2, softmax)\"\n      }\n    },\n    \"gcn-node\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN Layer GCN Layer GCN Layer GCN Layer\"\n      }\n    },\n    \"gat-node\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GAT Layer w/ ReLU GAT Layer w/ ReLU GAT Layer w/ ReLU GAT Layer w/ ReLU (size 1)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"non-termination-graph\": {\n      \"training-objective\": \"Classify code sample as terminating or non-terminating\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify code sample as terminating or non-terminating\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Detection of non-terminating code\",\n      \"supervision\": \"supervised\"\n    },\n    \"non-termination-node\": {\n      \"training-objective\": \"Identify node causing non-termination\",\n      \"training-granularity\": \"Node Classification\",\n      \"working-objective\": \"Identify node causing non-termination\",\n      \"working-granularity\": \"Node Classification\",\n      \"application\": \"Identification of cause of non-termination\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"training\": {\n    \"training-graph\": {\n      \"train-test-split\": {\n        \"train\": 0.8,\n        \"test\": 0.2,\n        \"validation\": 0.0\n      },\n      \"cross-validation\": {\n        \"used\": true,\n        \"details\": \"not specified\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"loss\",\n          \"value\": \"cross-entropy\"\n        },\n        {\n          \"name\": \"optimizer\",\n          \"value\": \"adam\"\n        },\n        {\n          \"name\": \"learning-rate\",\n          \"value\": 0.0001\n        },\n        {\n          \"name\": \"weight regularization\",\n          \"value\": \"is used (exact settings not specified)\"\n        }\n      ],\n      \"hyper-parameter-selection\": \"tuning\",\n      \"search-tuned-hyper-parameters\": [\n        \"amount of GNN layers\"\n      ],\n      \"evaluation-details\": \"Used cross validation (unclear how many folds).\\nUsed early stopping to find \\\"minimum validation loss\\\"; exact settings not given.\\nEach training session was repeated 10 times.\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"AUPR\",\n          \"type\": \"metric\",\n          \"details\": \"Area under precision/recall curve\"\n        },\n        {\n          \"name\": \"AUC\",\n          \"type\": \"metric\",\n          \"details\": \"Area under ROC curve\"\n        },\n        {\n          \"name\": \"mAP\",\n          \"type\": \"matrix\",\n          \"details\": \"Mean average precision\"\n        }\n      ]\n    },\n    \"training-node\": {\n      \"train-test-split\": {\n        \"train\": 0.72,\n        \"test\": 0.28,\n        \"validation\": 0.0\n      },\n      \"cross-validation\": {\n        \"used\": true,\n        \"details\": \"n/a\"\n      },\n      \"hyper-parameters\": [\n        {\n          \"name\": \"loss\",\n          \"value\": \"focal\"\n        },\n        {\n          \"name\": \"optimizer\",\n          \"value\": \"adam\"\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.001\n        }\n      ],\n      \"hyper-parameter-selection\": \"tuning\",\n      \"search-tuned-hyper-parameters\": [\n        \"amount of GNN layers\"\n      ],\n      \"evaluation-details\": \"Used cross validation (unclear how many folds).\\nUsed early stopping to find \\\"minimum validation loss\\\"; exact settings not given.\\nEach training session was repeated 10 times.\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"Jaccard Coefficient (Intersection over Union)\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Dice Coefficient\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Node-wise accuracy\",\n          \"type\": \"metrix\",\n          \"details\": \"n/a\"\n        }\n      ]\n    }\n  },\n  \"datasets\": {\n    \"ds-sv-comp\": {\n      \"name\": \"DS-SV-COMP\",\n      \"description\": \"C programs from the SV-COMP 2022 competition. \\nContains both terminating and non-terminating programs.\\nOnly used for testing\",\n      \"source\": [\n        \"Dataset from SV-COMP 2022 competition\"\n      ],\n      \"labelling\": \"Yes; not specified\",\n      \"size\": 249,\n      \"is-pre-existing\": true\n    },\n    \"ds-term-comp\": {\n      \"name\": \"DS-TERM-COMP\",\n      \"description\": \"C programs from the Termination Competition. \\nContains terminating and non-terminating programs.\\nOnly used for testing.\",\n      \"source\": [\n        \"Dataset from Termination Competition\"\n      ],\n      \"labelling\": \"Yes; not specified\",\n      \"size\": 150,\n      \"is-pre-existing\": true\n    },\n    \"ds-1\": {\n      \"name\": \"DS1\",\n      \"description\": \"Synthetically generated programs based on DS-TERM-COMP and DS-SV-COMP dataset.\\nContains both terminating and non-terminating C programs.\",\n      \"source\": [\n        \"synthetically generated from DS-TERM-COMP and DS-SV-COMP\"\n      ],\n      \"labelling\": \"Yes; automatically based on fuzzing\",\n      \"size\": 950,\n      \"is-pre-existing\": false\n    },\n    \"ds-2\": {\n      \"name\": \"DS2\",\n      \"description\": \"Contains both terminating and non-terminating Python programs.\",\n      \"source\": [\n        \"synthetically generated\"\n      ],\n      \"labelling\": \"Yes; automatically based on fuzzing\",\n      \"size\": 950,\n      \"is-pre-existing\": false\n    },\n    \"ds-seg-py1\": {\n      \"name\": \"DS-Seg-Py1\",\n      \"description\": \"Synthetically generated Python programs containing nested loops,\\nat least one of which is non-terminating.\",\n      \"source\": [\n        \"synthetically generated\"\n      ],\n      \"labelling\": \"Yes; automatically based on fuzzing\",\n      \"size\": 230,\n      \"is-pre-existing\": false\n    },\n    \"ds-seg-c\": {\n      \"name\": \"DS-Seg-C\",\n      \"description\": \"Synthetically generated C programs containing nested loops,\\nat least one of which is non-terminating.\",\n      \"source\": [\n        \"synthetically generated\"\n      ],\n      \"labelling\": \"Yes; automatically based on fuzzing\",\n      \"size\": 230,\n      \"is-pre-existing\": false\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"gcn-graph\",\n      \"task\": \"non-termination-graph\",\n      \"training\": \"training-graph\",\n      \"dataset\": \"ds-1 + ds-2 + ds-sv-comp + ds-term-comp\",\n      \"comments\": \"Papers does not clearly specify how the models were trained (all data combined, or separated);\"\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"gat-graph\",\n      \"task\": \"non-termination-graph\",\n      \"training\": \"training-graph\",\n      \"dataset\": \"ds-1 + ds-2 + ds-sv-comp + ds-term-comp\",\n      \"comments\": \"Papers does not clearly specify how the models were trained (all data combined, or separated);\"\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"gcn-node\",\n      \"task\": \"non-termination-node\",\n      \"training\": \"training-node\",\n      \"dataset\": \"ds-seg-py1\",\n      \"comments\": \"n/a\"\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"gcn-node\",\n      \"task\": \"non-termination-node\",\n      \"training\": \"training-node\",\n      \"dataset\": \"ds-seg-c\",\n      \"comments\": \"n/a\"\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"gat-node\",\n      \"task\": \"non-termination-node\",\n      \"training\": \"training-node\",\n      \"dataset\": \"ds-seg-py1\",\n      \"comments\": \"n/a\"\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"gat-node\",\n      \"task\": \"non-termination-node\",\n      \"training\": \"training-node\",\n      \"dataset\": \"ds-seg-c\",\n      \"comments\": \"n/a\"\n    }\n  ],\n  \"comments\": [\n    \"Labelling for DS1 and DS2 is not guaranteed to be accurate due to automation\",\n    \"Unclear if datasets were merged for training, or disjoint. Assuming first.\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 119,\n  \"pdf-id\": 161,\n  \"graphs\": {\n    \"socio-technical-graph\": {\n      \"name\": \"Augmented Socio-Technical Graph\",\n      \"description\": \"Graph spanning and combining multiple repositories\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Repository (including pull requests)\"\n        },\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"File\"\n        },\n        {\n          \"name\": \"User Data\",\n          \"details\": \"Comments\"\n        },\n        {\n          \"name\": \"Work Items\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Pull Request\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Work Item\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Author\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Reviewer\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"File\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Repository\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Token\",\n          \"details\": \"Tokens occurring in e.g. pull requests\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"creates\",\n          \"details\": \"author creates a pull request\"\n        },\n        {\n          \"name\": \"reviews\",\n          \"details\": \"created between reviewer and pull request\"\n        },\n        {\n          \"name\": \"contains\",\n          \"details\": \"repository contains pull request\"\n        },\n        {\n          \"name\": \"changes\",\n          \"details\": \"pull request changes file\"\n        },\n        {\n          \"name\": \"linked to\",\n          \"details\": \"pull request linked to work item\"\n        },\n        {\n          \"name\": \"comments on\",\n          \"details\": \"between pull request and reviewer\"\n        },\n        {\n          \"name\": \"parent of\",\n          \"details\": \"between work item nodes\"\n        },\n        {\n          \"name\": \"Token Edge\",\n          \"details\": \"Edge between e.g. a pull request and a token,\\nor between two tokens based on pointwise mutual information.\"\n        }\n      ],\n      \"vertex-features\": \"Information is one-hot encoded (?)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"R-GCN\\nR-GCN\\ndot product between nodes to compute link likeliness\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"recommendation\": {\n      \"training-objective\": \"Recommend Reviewers for pull requests by predicting a link between a reviewer and a pull request\",\n      \"training-granularity\": \"Link Prediction\",\n      \"working-objective\": \"Recommend Reviewers for pull requests by predicting a link between a reviewer and a pull request\",\n      \"working-granularity\": \"Link Prediction\",\n      \"application\": \"Recommend Reviewers for pull requests\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"socio-technical-graph\",\n      \"model\": \"model\",\n      \"task\": \"recommendation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 179,\n  \"pdf-id\": 233,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"directed\"\n        }\n      ],\n      \"vertex-features\": \"Node type and Node payload tokens are encoded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Stacked adjacency tensor.\\n\\nFor every graph, the adjacency matrix is determined.\\nThe four matrices are then combined into a third order tensor.\\n\\nSelf connections are added to all graphs\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"cfg\": {\n      \"name\": \"Control Flow Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"Edges representing control flow between basic blocks\"\n        }\n      ],\n      \"vertex-features\": \"Node type and Node payload tokens are encoded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Stacked adjacency tensor.\\n\\nFor every graph, the adjacency matrix is determined.\\nThe four matrices are then combined into a third order tensor.\\n\\nSelf connections are added to all graphs\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"dfg\": {\n      \"name\": \"Data Flow Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"Edges represent subsequent modification or access of the same variables\"\n        }\n      ],\n      \"vertex-features\": \"Node type and Node payload tokens are encoded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Stacked adjacency tensor.\\n\\nFor every graph, the adjacency matrix is determined.\\nThe four matrices are then combined into a third order tensor.\\n\\nSelf connections are added to all graphs\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"ncs\": {\n      \"name\": \"Natural Code Sequence\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Code Sequence Edge\",\n          \"details\": \"Edge from one AST leaf node to the next\"\n        }\n      ],\n      \"vertex-features\": \"Node type and Node payload tokens are encoded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Stacked adjacency tensor.\\n\\nFor every graph, the adjacency matrix is determined.\\nThe four matrices are then combined into a third order tensor.\\n\\nSelf connections are added to all graphs\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"var-misuse-model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Graph Tensor Convolution Neural Network (GTCN)\\n  H^{t + 1} = \\\\sigma(fold(Circ(A) \\\\cdot Matvec(H^t) \\\\times_{3}) W^t)\\n\\n  effectively achieves inter-graph communication through the Circ(.) operation.\\n  (correlations between graphs)\\n\\n2) For each node, \\n    its initial embedding, GTCN embedding, and node embeddings of candidates\\n    are passed through a linear layer w/ softmax.\"\n      }\n    },\n    \"code-prediction-model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Graph Tensor Convolution Neural Network (GTCN)\\n  H^{t + 1} = \\\\sigma(fold(Circ(A) \\\\cdot Matvec(H^t) \\\\times_{3}) W^t)\\n\\n  effectively achieves inter-graph communication through the Circ(.) operation.\\n  (correlations between graphs)\\n\\n2) For each node, \\n    Based on node embeddings, either predict a token from the (pretrained)\\n    global embedding, or a local token from the input graph.\"\n      }\n    },\n    \"vulnerability-detection-model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Graph Tensor Convolution Neural Network (GTCN)\\n  H^{t + 1} = \\\\sigma(fold(Circ(A) \\\\cdot Matvec(H^t) \\\\times_{3}) W^t)\\n\\n  effectively achieves inter-graph communication through the Circ(.) operation.\\n  (correlations between graphs)\\n\\n2) MLP\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"variable-misuse-detection\": {\n      \"training-objective\": \"Given a slot (node for which variable must be predicted), select the \\ncorrect candidate out of all type-correct options (other nodes in the graph)\",\n      \"training-granularity\": \"Node Classification (?)\",\n      \"working-objective\": \"Given a slot (node for which variable must be predicted), select the \\ncorrect candidate out of all type-correct options (other nodes in the graph)\",\n      \"working-granularity\": \"Node Classification (?)\",\n      \"application\": \"Variable Misuse Detection\",\n      \"supervision\": \"Supervised\"\n    },\n    \"code-prediction\": {\n      \"training-objective\": \"Predict the next token(s)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Predict the next token(s)\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Source code prediction\",\n      \"supervision\": \"Supervised\"\n    },\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification (multiple graphs per sample)\",\n      \"working-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification (multiple graphs per sample)\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + cfg + dfg + ncs\",\n      \"model\": \"var-misuse-model\",\n      \"task\": \"variable-misuse-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast + cfg + dfg + ncs\",\n      \"model\": \"code-prediction-model\",\n      \"task\": \"code-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast + cfg + dfg + ncs\",\n      \"model\": \"vulnerability-detection-model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 230,\n  \"pdf-id\": 9,\n  \"graphs\": {\n    \"distribution-based-weighting\": {\n      \"name\": \"Weighted Directed Class Coupling Network (WDCCN)\",\n      \"description\": \"Graph representing different types of coupling between classes,\\nwith different weights depending on the type of coupling.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code (project)\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Class\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"LVA\",\n          \"details\": \"Local Variable; For edge (u, v), class u contains a local variable of type v in a method.\"\n        },\n        {\n          \"name\": \"GVA\",\n          \"details\": \"Global Variable; For edge (u, v), class u contains a field of type v.\"\n        },\n        {\n          \"name\": \"INH\",\n          \"details\": \"Inheritance;  For edge (u, v), class u inherits from class v.\"\n        },\n        {\n          \"name\": \"IMP\",\n          \"details\": \"Implementation; For edge (u, v), class u implements interface v.\"\n        },\n        {\n          \"name\": \"PAR\",\n          \"details\": \"Parameter; For edge (u, v), class u contains method with a parameter of type v.\"\n        },\n        {\n          \"name\": \"RET\",\n          \"details\": \"Return; For edge (u, v), class u contains method with a return type of type v.\"\n        },\n        {\n          \"name\": \"INS\",\n          \"details\": \"Instantiates; For edge (u, v), class u instantiates class v.\"\n        },\n        {\n          \"name\": \"ACC\",\n          \"details\": \"Access; For edge (u, v), class u accesses a field of class v\"\n        },\n        {\n          \"name\": \"MEC\",\n          \"details\": \"Method Call; For edge (u, v), class u calls a method of class v.\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"Edge features based on distribution with which coupling occurs in a project.\\n\\nLet N denote the intra-package coupling of some type, and M the inter-package coupling.\\nThen, the weight is defined as:\\n\\n10 if N > 0 and M = 0\\n1 if N = M = 0\\nround(0.5 + 10 * N / (N + M)) otherwise\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"ordinal-scale-based-weighting\": {\n      \"name\": \"Weighted Directed Class Coupling Network (WDCCN)\",\n      \"description\": \"Graph representing different types of coupling between classes,\\nwith different weights depending on the type of coupling.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code (project)\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Class\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"LVA\",\n          \"details\": \"Local Variable; For edge (u, v), class u contains a local variable of type v in a method.\"\n        },\n        {\n          \"name\": \"GVA\",\n          \"details\": \"Global Variable; For edge (u, v), class u contains a field of type v.\"\n        },\n        {\n          \"name\": \"INH\",\n          \"details\": \"Inheritance;  For edge (u, v), class u inherits from class v.\"\n        },\n        {\n          \"name\": \"IMP\",\n          \"details\": \"Implementation; For edge (u, v), class u implements interface v.\"\n        },\n        {\n          \"name\": \"PAR\",\n          \"details\": \"Parameter; For edge (u, v), class u contains method with a parameter of type v.\"\n        },\n        {\n          \"name\": \"RET\",\n          \"details\": \"Return; For edge (u, v), class u contains method with a return type of type v.\"\n        },\n        {\n          \"name\": \"INS\",\n          \"details\": \"Instantiates; For edge (u, v), class u instantiates class v.\"\n        },\n        {\n          \"name\": \"ACC\",\n          \"details\": \"Access; For edge (u, v), class u accesses a field of class v\"\n        },\n        {\n          \"name\": \"MEC\",\n          \"details\": \"Method Call; For edge (u, v), class u calls a method of class v.\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"Edge weights based on existing ordinal rankings in literature,\\nre-mapped to correspond to the proposed edge types.\\n  \\nWeights:\\nLVA: 1\\nGVA: 5.5\\nINH: 9\\nIMP: 10\\nPAR: 1\\nRET: 1\\nINS: ignored \\nACC: ignored \\nMEC: 1\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"empirical-weighting\": {\n      \"name\": \"Weighted Directed Class Coupling Network (WDCCN)\",\n      \"description\": \"Graph representing different types of coupling between classes,\\nwith different weights depending on the type of coupling.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code (project)\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Class\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"LVA\",\n          \"details\": \"Local Variable; For edge (u, v), class u contains a local variable of type v in a method.\"\n        },\n        {\n          \"name\": \"GVA\",\n          \"details\": \"Global Variable; For edge (u, v), class u contains a field of type v.\"\n        },\n        {\n          \"name\": \"INH\",\n          \"details\": \"Inheritance;  For edge (u, v), class u inherits from class v.\"\n        },\n        {\n          \"name\": \"IMP\",\n          \"details\": \"Implementation; For edge (u, v), class u implements interface v.\"\n        },\n        {\n          \"name\": \"PAR\",\n          \"details\": \"Parameter; For edge (u, v), class u contains method with a parameter of type v.\"\n        },\n        {\n          \"name\": \"RET\",\n          \"details\": \"Return; For edge (u, v), class u contains method with a return type of type v.\"\n        },\n        {\n          \"name\": \"INS\",\n          \"details\": \"Instantiates; For edge (u, v), class u instantiates class v.\"\n        },\n        {\n          \"name\": \"ACC\",\n          \"details\": \"Access; For edge (u, v), class u accesses a field of class v\"\n        },\n        {\n          \"name\": \"MEC\",\n          \"details\": \"Method Call; For edge (u, v), class u calls a method of class v.\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"Weights fine-tuned based on performance in architecture reconstruction.\\n  \\nWeights:\\nLVA: 1\\nGVA: 3\\nINH: 3\\nIMP: 4\\nPAR: 3\\nRET: 3\\nINS: 2 \\nACC: 2 \\nMEC: 2\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"classrank\": {\n      \"type\": {\n        \"name\": \"ClassRank\",\n        \"architecture\": \"Page-rank like algorithm, which uses the equation:\\n\\n\\\\text{PR(u)} = \\\\frac{(1 - d)\\\\text{wDeg}(u)\\\\text{Deg}(u)}{\\\\text{wDegSum \\\\times }\\n\\\\text{PR(u)} = \\\\frac{(1 - d)\\\\text{wDeg}(u)\\\\text{Deg}(u)}{\\\\text{wDegSum \\\\times DegSum} + d\\\\sum_{v \\\\in N(u)} \\\\frac{\\\\text{PR}(v)w(v, u)}{\\\\text{wOutDeg(v)}}\\n\\nHere:\\n  PR(x): Page rank value of node x \\n  wDeg(x): Weighted degree (in + out degree) of node x \\n  Deg(x): Unweighted degree (in + out degree) of node x\\n  wDegSum: Sum of weighted degrees of all node\\n  DegSum: Sum of unweighted degrees of all node\\n  N(x): Neighbors of node x\\n  w(x, y): Weight of edge(s) between nodes x and y\\n  wOutDeg(x): Out degree of node x\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"ranking\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Rank classes according to their importance\",\n      \"working-granularity\": \"Node Ranking\",\n      \"application\": \"Documentation Effort Prioritisation\",\n      \"supervision\": \"Unsupervised\"\n    }\n  },\n  \"training\": {\n    \"experiment\": {\n      \"train-test-split\": \"n/a\",\n      \"cross-validation\": \"n/a\",\n      \"hyper-parameters\": [\n        {\n          \"name\": \"d\",\n          \"value\": 0.85\n        },\n        {\n          \"name\": \"cbo (CBO threshold for filtering rules)\",\n          \"value\": 0\n        },\n        {\n          \"name\": \"nom (NOM threshold for filtering rules)\",\n          \"value\": 0\n        },\n        {\n          \"name\": \"loc (LOC threshold for filtering rules)\",\n          \"value\": 2\n        }\n      ],\n      \"hyper-parameter-selection\": \"Based on literature (d)\",\n      \"search-tuned-hyper-parameters\": \"n/a\",\n      \"evaluation-details\": \"Evaluate with different top-k% ranked items\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"precision\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"recall\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"f1-score\",\n          \"type\": \"metric\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"RSS (ranking score sum)\",\n          \"type\": \"metric\",\n          \"details\": \"Sum of all top-k ranked items\"\n        }\n      ]\n    }\n  },\n  \"datasets\": {\n    \"group-1\": {\n      \"name\": \"n/a\",\n      \"description\": \"Projects used by McBurney et al. \\n\\nContains classes labelled as either important or unimportant.\",\n      \"source\": [\n        \"NanoXML\",\n        \"jExcelAPI\",\n        \"JGraphT\"\n      ],\n      \"labelling\": \"not specified\",\n      \"size\": 931,\n      \"is-pre-existing\": true\n    },\n    \"group-2\": {\n      \"name\": \"n/a\",\n      \"description\": \"Projects used by Liu et al. \\n\\nContains classes labelled as either important or unimportant.\",\n      \"source\": [\n        \"Apache Ant\",\n        \"Argo UML\",\n        \"jEdit\",\n        \"jHotDraw\",\n        \"jMeter\",\n        \"wro4j\"\n      ],\n      \"labelling\": \"Labels derived from existing design documentation (``labelled by developers'')\",\n      \"size\": 4199,\n      \"is-pre-existing\": true\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"distribution-based-weighting\",\n      \"model\": \"classrank\",\n      \"task\": \"ranking\",\n      \"training\": \"experiment\",\n      \"dataset\": \"group-1\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"distribution-based-weighting\",\n      \"model\": \"classrank\",\n      \"task\": \"ranking\",\n      \"training\": \"experiment\",\n      \"dataset\": \"group-2\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ordinal-scale-based-weighting\",\n      \"model\": \"classrank\",\n      \"task\": \"ranking\",\n      \"training\": \"experiment\",\n      \"dataset\": \"group-1\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ordinal-scale-based-weighting\",\n      \"model\": \"classrank\",\n      \"task\": \"ranking\",\n      \"training\": \"experiment\",\n      \"dataset\": \"group-2\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"empirical-weighting\",\n      \"model\": \"classrank\",\n      \"task\": \"ranking\",\n      \"training\": \"experiment\",\n      \"dataset\": \"group-1\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"empirical-weighting\",\n      \"model\": \"classrank\",\n      \"task\": \"ranking\",\n      \"training\": \"experiment\",\n      \"dataset\": \"group-2\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": [\n    \"The page rank algorithm is also combined with simple filtering rules based on the CBO, NOM, and LOC metrics.\",\n    \"Using the rule-based filtering, exceptions are always filtered out.\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 42,\n  \"pdf-id\": 60,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Traverse AST in BFS order.\\nFor every node, output the pair (parent payload, node payload).\\n\\nThe resulting text is then tokenized (four different ways; see paper for details).\\n\\nFor BOW models, the tokens are used to compute a BOW representation \\n(4 different ways; see paper for details).\"\n    }\n  },\n  \"models\": {\n    \"bow\": {\n      \"type\": {\n        \"name\": \"Naive Bayes\",\n        \"architecture\": \"Naive Bayes\"\n      }\n    },\n    \"embedding\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Embedding Layer (takes in matrix of tokenized words) Flattening Layer Softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-correctness\": {\n      \"training-objective\": \"Classify sample as correct or incorrect\",\n      \"training-granularity\": \"Classification (not graph)\",\n      \"working-objective\": \"Classify sample as correct or incorrect\",\n      \"working-granularity\": \"Classification (not graph)\",\n      \"application\": \"Code correctness prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"bow\",\n      \"task\": \"code-correctness\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"embedding\",\n      \"task\": \"code-correctness\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 130,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"code-non\": {\n      \"name\": \"Code-NoN (network of networks)\",\n      \"description\": \"Control Flow Graph in which each node is an AST.\\n\\nTo avoid confusion, remember that the artefacts in the \\n\\\"artefacts\\\" section are not related _beforehand_, but their\\nrelatedness must be predicted\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Bug Report\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST\",\n          \"details\": \"A full blown AST corresponding to the basic block in the original CFG,\\nconsisting of AST nodes and AST edges. \\nThe AST nodes are referred to as token nodes,\\nwhile the CFG nodes are referred to as block nodes.\\n\\nIn token nodes, compound names are split up.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"From a bug report (summary + description),\\nso-called \\\"bug clues\\\" are extracted,\\nwhich are encoded using word2vec\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Parallel inputs:\\n  1) Bug Clue\\n      Apply convolutional filters (varying sizes)\\n      Max-pooling per filter\\n  2) Code-Non\\n      Token nodes embedded using trainable embedding layer initialised using word2vec\\n      DGP is applied to each AST network, with mean pooling to represent each AST as a single vector.\\n      DGP is then applied to the CFG network, with the previous AST vectors as node embeddings.\\n      Every possible execution path CFG is represented as a vector using mean pooling.\\nEvery combination of (bug clue, execution path) are fed into a bi-affine classifier\\nMaximum relevancy score (from bi-affine classifier) of each clue is summed to obtain final score for (report, file) pair.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"bug-localisation\": {\n      \"training-objective\": \"Given a bug report and source file, predict whether the given file is associated wih the given bug\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a bug report and source file, predict whether the given file is associated wih the given bug\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Bug localisation\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-non\",\n      \"model\": \"model\",\n      \"task\": \"bug-localisation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 17,\n  \"pdf-id\": 28,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Control flow graph with data flow and AST subtrees\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": null\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST node\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Basic Block node\",\n          \"details\": \"Not entirely clear whether this is a node type on its own.\\n\\nEvery basic block is represented using an AST.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Call flow edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Exception flow edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data flow edge\",\n          \"details\": \"Links variable definitions to their uses\"\n        },\n        {\n          \"name\": \"Exception Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Sequential Execution Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Conditional True Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Conditional False Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"mfgnn\": {\n      \"type\": {\n        \"name\": \"Multi-Flow Graph Neural Network (MFGNN)\",\n        \"architecture\": \"Tree-based CNN (TBCNN), adjusted to assign higher weights to deeper nodes, is used to learn local features. \\n\\nContextual features are used using a layer based on GAT, called Attention-based GNN for DAGs (AGN4D),\\nwhich can handle directed graphs and multiple edge types. Initial inputs are the local features.\\n\\nLocal and contextual features are fused using max-pooling.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"program-classification\": {\n      \"training-objective\": \"Given the representation of a program, classify it into one of the classes.\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given the representation of a program, classify it into one of the classes.\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Program Classification\",\n      \"supervision\": \"Supervised\"\n    },\n    \"within-project-defect-prediction\": {\n      \"training-objective\": \"Classify source code as defective/not defective\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify source code as defective/not defective\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Source code defect detection (in the same project)\",\n      \"supervision\": \"Supervised\"\n    },\n    \"cross-project-defect-prediction\": {\n      \"training-objective\": \"Classify source code as defective/not defective\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify source code as defective/not defective\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Source code defect detection (in a different project)\",\n      \"supervision\": \"Supervised\"\n    },\n    \"functional-code-clone-detection\": {\n      \"training-objective\": \"Given two programs, determine if they implement the same functionality\",\n      \"training-granularity\": \"Graph Classification (?)\",\n      \"working-objective\": \"Given two programs, determine if they implement the same functionality\",\n      \"working-granularity\": \"Graph Classification (?)\",\n      \"application\": \"Code Clone Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"mfgnn\",\n      \"task\": \"program-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph\",\n      \"model\": \"mfgnn\",\n      \"task\": \"within-project-defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph\",\n      \"model\": \"mfgnn\",\n      \"task\": \"cross-project-defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph\",\n      \"model\": \"mfgnn\",\n      \"task\": \"functional-code-clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 102,\n  \"pdf-id\": 138,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Combination of AST and CFG\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"User defined names are normalised \\nNode type one-hot encoded \\ncontent of node is the average of the word2vec embeddings of all tokens in the content\\nthe two embeddings are concatenated\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gcn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN\\nx_g = \\\\sum_{v \\\\in V} softmax(MPL(h_v)) \\\\cdot MLP(h_v)\\nMLP \\nsigmoid\"\n      }\n    },\n    \"gat\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GAT\\nx_g = \\\\sum_{v \\\\in V} softmax(MPL(h_v)) \\\\cdot MLP(h_v)\\nMLP \\nsigmoid\"\n      }\n    },\n    \"ggnn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GGNN\\nx_g = \\\\sum_{v \\\\in V} softmax(MPL(h_v)) \\\\cdot MLP(h_v)\\nMLP \\nsigmoid\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify samples as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify samples as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection (in C/C++ source code)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph\",\n      \"model\": \"gat\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph\",\n      \"model\": \"ggnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 97,\n  \"pdf-id\": 133,\n  \"graphs\": {\n    \"code-property-graph-plus\": {\n      \"name\": \"CPG+\",\n      \"description\": \"Code property graph with NCS edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Natural Code Sequence Edge (NCS)\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Tokenize, normalize names, average word2vec vector of all tokens per node.\\nConcatenate that with node type encoded as integer.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Parallel paths for the separate subgraphs based on edge type. For subgraph r,\\na node i is updated according to:\\n\\nh_{i,r}^{t + 1} = concat_{k = 1}^K \\\\sigma\\\\left(\\\\sum_{j \\\\in N(i) a_{ij}^{r^k}W^k h_{j,r}^t\\\\right)\\n\\nHere, a_{ij}^{r^k} is the attention weight for node j and W^k the corresponding\\nweight matrix. We are summing over K because multi-head attention is used.\\nAttention computed according to:\\n  a_{ij}^r = softmax(e_{ij}^r)\\n  e_{ij}^r = m(Wh_{i,r}^t \\\\mid\\\\mid Wh_{j,r}^t)\\n  Where m is an operation mapping a vector to a scalar, \\n  and W is a shared parameter _increasing_ the dimension of the embedding\\n\\nAfter message passing rounds,\\nnode embeddings are averaged per node over all graphs.\\nNext, average pooling to combine all node embeddings \\nMLP\\nsigmoid\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"training-objective\": {\n      \"training-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-property-graph-plus\",\n      \"model\": \"model\",\n      \"task\": \"training-objective\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 144,\n  \"pdf-id\": 192,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST with various additional edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Syntax Node\",\n          \"details\": \"internal node/corresponds to nonterminal\"\n        },\n        {\n          \"name\": \"Syntax Token\",\n          \"details\": \"leaf node/contains program tokens\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Child Edge\",\n          \"details\": \"AST Edge (undirected)\"\n        },\n        {\n          \"name\": \"Next Token Edge\",\n          \"details\": \"NCS (undirected)\"\n        },\n        {\n          \"name\": \"Last Read Edge\",\n          \"details\": \"For syntax tokens corresponding to variables,\\nwe connect those tokens to all possible places \\nthe variable could have been read last. \\n(undirected)\"\n        },\n        {\n          \"name\": \"Last Write Edge\",\n          \"details\": \"For syntax tokens corresponding to variables,\\nwe connect those tokens to all possible places \\nthe variable could have been written to last.\\n(undirected)\"\n        },\n        {\n          \"name\": \"Computed From\",\n          \"details\": \"In an assignment v = expr, connect v to all\\nvariables used in the expression\\n(undirected)\"\n        },\n        {\n          \"name\": \"Last Lexical Use\",\n          \"details\": \"Connect occurrences of same variable in different \\ndata flow, e.g. if (...) { ... v ... } else { ... v ... }\\n(undirected)\"\n        },\n        {\n          \"name\": \"Returns To\",\n          \"details\": \"Connect return token to the method declaration (undirected)\"\n        },\n        {\n          \"name\": \"Formal Arg Name\",\n          \"details\": \"Connect actual arguments the formal arguments;\\ne.g. given bar(x) and bar(Integer y), connect x to y\\n(undirected)\"\n        },\n        {\n          \"name\": \"Guarded By\",\n          \"details\": \"Connect every variable token guarded by a conditional (if) \\nto the guard expression \\n(undirected)\"\n        },\n        {\n          \"name\": \"Guarded By Negation\",\n          \"details\": \"Connect every variable token guarded by the negation of a \\nconditional (else) to the guard expression \\n(undirected)\"\n        }\n      ],\n      \"vertex-features\": \"Syntax nodes use the node type name as a text feature.\\nSyntax tokens use the program content as a text feature.\\n\\nText payload is split into subtokens, each of which is \\nembedded (unclear how); average of embedding is computed.\\n\\nAll types are embedded using a trainable embedding layer.\\nEach variable has a type, which is encoded as the \\nelement-wise maximum of that type, and all its super-types\\n(including implementation relations).\",\n      \"edge-features\": \"In case of the var-misuse task, some adjustments are made to the graph:\\n1) The node corresponding to the slot is removed, and replaced with a context node\\n2) All LastUse, LastWrite, LastLexicalUse, and GuardedBy edges to the context node are removed \\n3) For every possible candidate variable, a new node is added, connected by the \\n    LastUse, LastWrite, and LastLexicalUse edges of the old node\",\n      \"connectivity-features\": \"adjacency list\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"ggnn-var-naming\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Embedding Layer for types \\nconcat with text embedding (unclear if done in preprocessing or in network)\\nLinear layer (to obtain node embeddings)\\nGGNN\\naverage representation for all <SLOT> tokens\\nGRU\"\n      }\n    },\n    \"ggnn-var-misuse\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Embedding Layer for types \\nconcat with text embedding (unclear if done in preprocessing or in network)\\nLinear layer (to obtain node embeddings)\\nGGNN\\nFor every candidate variable, concatenate its node representation with \\n  that of the context node, pass it through a linea linear,\\n  and use argmax to select the best candidate.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"var-naming\": {\n      \"training-objective\": \"Given a graph, where for one variable all nodes are replaced with a special [SLOT],\\noutput a suggested name for the variable\",\n      \"training-granularity\": \"Graph To Sequence\",\n      \"working-objective\": \"Given a graph, where for one variable all nodes are replaced with a special [SLOT],\\noutput a suggested name for the variable\",\n      \"working-granularity\": \"Graph To Sequence\",\n      \"application\": \"Variable Name Prediction\",\n      \"supervision\": \"(Self-)Supervised\"\n    },\n    \"var-misuse\": {\n      \"training-objective\": \"Given a graph, where one variable usage is replaced,\\noutput the correct variable to be used in that place\",\n      \"training-granularity\": \"Node classification, but not quite\",\n      \"working-objective\": \"Given a graph, where one variable usage is replaced,\\noutput the correct variable to be used in that place\",\n      \"working-granularity\": \"Node classification, but not quite\",\n      \"application\": \"Variable Misuse Repair\",\n      \"supervision\": \"(Self-)Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"ggnn-var-naming\",\n      \"task\": \"var-naming\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph\",\n      \"model\": \"ggnn-var-misuse\",\n      \"task\": \"var-misuse\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 206,\n  \"pdf-id\": 276,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"CFG where each \\\"node\\\" has its own AST subtree\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"Smart contract\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement (CFG)\",\n          \"details\": \"Each such node has an AST tree as \\\"value\\\".\\n\\nEach statement has as type, based on the type \\nof the root of its AST subtree.\\nFor some types (e.g. Assignment), more analysis is \\nperformed to refine  the type (e.g. \\\"Memory Assignment\\\")\"\n        },\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Only occurs as the child of a CFG Node\"\n        },\n        {\n          \"name\": \"Virtual Function Node\",\n          \"details\": \"All CFG node in the graph has an edge to this node\"\n        },\n        {\n          \"name\": \"Virtual Loop Node\",\n          \"details\": \"All CFG nodes in a loop point to a Virtual Loop Node\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"Edge between CFG Nodes\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"Edge between CFG Nodes\"\n        },\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"Edge between AST Nodes\"\n        }\n      ],\n      \"vertex-features\": \"InferCode is used to encode nodes in AST subtrees,\\nand to encode the statement type of each CFG node\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Child-Sum Tree-LSTM to learn AST subtree embeddings (use embedding of root node) -> h_i^{syn}\\n2) Multi-head attention (K heads) between types of adjacent nodes:\\n    \\\\phi(h_i^{type}, h_j^{type}) = \\\\frac{1}{K} \\\\sum_{k = 1}^ K a_{ij}^k\\n    with a_ij = softmax(e_{ij}); a_ij = LeakyReLU(a^k[W h_i^{type}; W h_j^{type}))\\n    with a a learnable parameter, and j ranging over all neighbours of i \\n3) GCN inspired message passing:\\n    h_i^{sem} = \\\\sum_{j \\\\in N(i)} \\\\delta(\\\\phi(h_i^{type}, h_j^{type})W h_j^{syn})\\n4) For each node, compute MLP(h_i^{syn} \\\\mid\\\\mid h_i^{sem})\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify each node as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Node Classification\",\n      \"working-objective\": \"Classify each node as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Node Classification\",\n      \"application\": \"Statement level vulnerability detection in smart contracts\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": null,\n      \"model\": null,\n      \"task\": null,\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 20,\n  \"pdf-id\": 32,\n  \"graphs\": {\n    \"pdg\": {\n      \"name\": \"PDG (Program Dependence Graph)\",\n      \"description\": \"Based on Jimple IR\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Multiple files\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Instruction\",\n          \"details\": \"Based on the Jimple instructions\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data flow edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control flow edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Method call edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Embedding instructions (as learned by the Lexical Embedding Model)\",\n      \"edge-features\": \"n/a (edge type)\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Each Jimple instruction is split into subwords.\\nA Word2Vec model is trained on the subwords.\"\n    }\n  },\n  \"models\": {\n    \"model-gcn\": {\n      \"type\": {\n        \"name\": \"GraphCode2Vec\",\n        \"architecture\": \"Two parts 1) Lexical Embedding Using Bidirectional LSTM network with subword embeddings as input to learn Jimple instruction embeddings. Use element-wise addition to compute program embedding\\n2) Dependence Embedding GCN Layers to learn per-node embeddings Global attention pooling to learn program embedding\\nConcatenation to fuse lexical and dependence embeddings\"\n      }\n    },\n    \"model-graph-sage\": {\n      \"type\": {\n        \"name\": \"GraphCode2Vec\",\n        \"architecture\": \"Two parts 1) Lexical Embedding Using Bidirectional LSTM network with subword embeddings as input to learn Jimple instruction embeddings. Use element-wise addition to compute program embedding\\n2) Dependence Embedding GraphSAGE Layers to learn per-node embeddings Global attention pooling to learn program embedding\\nConcatenation to fuse lexical and dependence embeddings\"\n      }\n    },\n    \"model-gat\": {\n      \"type\": {\n        \"name\": \"GraphCode2Vec\",\n        \"architecture\": \"Two parts 1) Lexical Embedding Using Bidirectional LSTM network with subword embeddings as input to learn Jimple instruction embeddings. Use element-wise addition to compute program embedding\\n2) Dependence Embedding GAT Layers to learn per-node embeddings Global attention pooling to learn program embedding\\nConcatenation to fuse lexical and dependence embeddings\"\n      }\n    },\n    \"model-gin\": {\n      \"type\": {\n        \"name\": \"GraphCode2Vec\",\n        \"architecture\": \"Two parts 1) Lexical Embedding Using Bidirectional LSTM network with subword embeddings as input to learn Jimple instruction embeddings. Use element-wise addition to compute program embedding\\n2) Dependence Embedding GIN (graph isomorphism network) Layers to learn per-node embeddings Global attention pooling to learn program embedding\\nConcatenation to fuse lexical and dependence embeddings\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"node-classification\": {\n      \"training-objective\": \"Predict node type given its embedding\",\n      \"training-granularity\": \"Node classification\",\n      \"working-objective\": \"Embed nodes (to perform graph embedding via pooling)\",\n      \"working-granularity\": \"Compute node embedding (to be combined via pooling)\",\n      \"application\": \"Graph Embedding\",\n      \"supervision\": \"self-supervised\"\n    },\n    \"contex-prediction\": {\n      \"training-objective\": \"Predict masked node given surrounding context\",\n      \"training-granularity\": \"Node Prediction/Context Prediction\",\n      \"working-objective\": \"Embed nodes (to perform graph embedding via pooling)\",\n      \"working-granularity\": \"Compute node embedding (to be combined via pooling)\",\n      \"application\": \"Graph Embedding\",\n      \"supervision\": \"self-supervised\"\n    },\n    \"variational-graph-encoding\": {\n      \"training-objective\": \"Encode/Decode graph structures\",\n      \"training-granularity\": \"Graph Encoding/Decoding\",\n      \"working-objective\": \"Encode graph\",\n      \"working-granularity\": \"Graph Embedding\",\n      \"application\": \"Graph Embedding\",\n      \"supervision\": \"self-supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model-gcn\",\n      \"task\": \"node-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model-gcn\",\n      \"task\": \"context-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model-gcn\",\n      \"task\": \"variational-graph-encoding\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model-graph-sage\",\n      \"task\": \"node-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model-graph-sage\",\n      \"task\": \"context-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model-graph-sage\",\n      \"task\": \"variational-graph-encoding\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model-gat\",\n      \"task\": \"node-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model-gat\",\n      \"task\": \"context-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model-gat\",\n      \"task\": \"variational-graph-encoding\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model-gin\",\n      \"task\": \"node-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model-gin\",\n      \"task\": \"context-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model-gin\",\n      \"task\": \"variational-graph-encoding\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": [\n    \"The use of instructions is simply a means of representing semantic information.\",\n    \"Evaluated on several downstream tasks, including method name prediction\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 208,\n  \"pdf-id\": 278,\n  \"graphs\": {\n    \"propagation-chain\": {\n      \"name\": \"Propagation Chain\",\n      \"description\": \"Denotes relationships between different variables.\\n\\nThe graph described below is further trimmed based on \\ncertain \\\"key information\\\". The information nor the process \\nis described in detail.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Smart contracts\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Variable at token\",\n          \"details\": \"Each node represents the occurrence of variable, identified with its index in the sequence of program tokens\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Value Comes From\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Value Computed From\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified (Mask Matrix)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"The token sequence of the source code (CT)\\nThe positions of the tokens in the source code \\nThe sequence of variables in the source code (V)\\nThe positions of the variables.\\nCT and V are concatenated to obtain I_1; the position sets are concatenated to obtain I_2.\\n\\nFor every variable\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Join Layer: X_0 = [I_1, I_2]\\n2) Masked Multi-head attention\\n3) Normalisation Layer\\n4) Transformer Layers, where each multi-head attention head uses the 0/-\\\\infty mask matrix \\n5) Normalisation Layer\\n6) Linear Layer\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Given a graph, classify it as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given a graph, classify it as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection in Smart Contracts\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"propagation-chain\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 145,\n  \"pdf-id\": 194,\n  \"graphs\": {\n    \"hsg\": {\n      \"name\": \"Heterogeneous Syntax Graph\",\n      \"description\": \"AST with explicitly heterogeneous edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Child Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"AST Parent Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"AST Left Sibling Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"AST Right Sibling Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Next Data Flow Node Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Previous Data Flow Node Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Not clearly specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Each token is enhanced with its line number and position (in terms of tokens) in the line it came from.\\n\\nThe goal of the model is to predict the next token in the summary.\\nAs such, the summary generated thus far is also an input.\"\n    }\n  },\n  \"models\": {\n    \"het-sum\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Base architecture is encoder-decoder transformer, with additional information from the HSG\\n\\n1) Embedding Layers\\n    i) Encode Nodes\\n    ii) Encode summary tokens\\n    iii) Loose tokens (enhanced w/ line and position) are embedded, where the embedding\\n        is the sum of the token embedding, and the embeddings of the position information components.\\n2) [Code Token Encoder] (1.iii) are fed into two Transformer Layers (2x):\\n    i) Multihead attention w/ residual connections and normalisation (H^k_c = LayerNorm(E_c^{k-1} + Attention(E_c^{k-1}, E_c^{k-1}, E_c^{k-1})))\\n    ii) FNN w/ residual connections and normalisation (E_c^k = LayerNorm(H_c^k + FNN(H_c^k)))\\n3) [HSG Encoder] (1.i) is passed through (6 repetitions of):\\n    o) Embedding from (2.ii) is added to the existing embeddings in the graph\\n    i) Heterogeneous GraphSAGE\\n        - Neighbours are aggregated by edge type\\n        - The aggregated groups are transformed using a matrix multiplication\\n        - The transformed groups are then again aggregated \\n        - The aggregated vector is added to the previous node embedding, which has also been multiplied by a learnable matrix\\n    ii) Node states are concatenated (into node embedding matrix)\\n    iii) ReLU\\n    iv) Residual Connection and Normalisation  (and then outputted is a node embedding matrix)\\n4) [Summary Decoder] (1.ii) is passed through (6x repetitions of):\\n    i) Masked MultiHead Self-Attention w/ Residual Connections and Normalisation \\n    ii) Masked Multihead Attention w/ Residual Connections and Normalisation.\\n        Q and K are output of graph encoder \\n    iii) Masked Multihead Attention w/ Residual Connections and Normalisation\\n        Q and K are output of token encoder\\n    iv) FNN w/ residual connections and normalisation\\n5) outputs of (2), (3), and (4) are fed into multi-source pointer generator\\n    (note; omitting lots of details here since it will not be relevant for the SMS)\\n    i) output of (4) is used to compute p_v = Softmax(Linear(...))\\n    ii) Output of (2) and (3) are passed through multi-head attention layers,\\n          Where V is the output of (4)\\n    iii) Concat + Linear Layer to compute weights \\n    iv) Compute weighted softmax sum\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"training-granularity\": \"Graph + Sequence to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"working-granularity\": \"Graph + Sequence to Sequence\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"hsg\",\n      \"model\": \"het-sum\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 35,\n  \"pdf-id\": 48,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"Based on bag of graphs (Silva et al.)\\n\\nFirst, authors define Nodes of Interest (NOIs).\\nThese NOIs are used to capture three types of GOIs:\\n\\n1) NOI w/ source code text \\n2) Trees with the NOI as their root\\n3) Shortest path from AST root to the NOI\\n\\nFor each GOI, concatenate all node payloads (text) and hash them. \\n\\nNext, for each NOI, generate a feature vector of all GOI corresponding\\nto the NOI by concatenating the hashes. \\n\\nSince number of NOI is variable, sample a fixed number through \\nrandom sampling with replacement. \\n\\nCluster vectors using K-means.\\n\\nGenerate graph features by creating a histogram of how many \\nNOI of each type (cluster) are present in the graph.\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"svm\": {\n      \"type\": {\n        \"name\": \"SVM\",\n        \"architecture\": \"SVM\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"cryptograpy-misuse-detection\": {\n      \"training-objective\": \"Classify given graph as secure or insecure\",\n      \"training-granularity\": \"Binary Graph Classification\",\n      \"working-objective\": \"Classify given graph as secure or insecure\",\n      \"working-granularity\": \"Binary Graph Classification\",\n      \"application\": \"Cryptography Misuse Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"svm\",\n      \"task\": \"cryptograpy-misuse-detection\",\n      \"comments\": \"n/a\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 188,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"program-graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST with various additional edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Syntax Node\",\n          \"details\": \"internal node/corresponds to nonterminal\"\n        },\n        {\n          \"name\": \"Syntax Token\",\n          \"details\": \"leaf node/contains program tokens\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Child Edge\",\n          \"details\": \"AST Edge\"\n        },\n        {\n          \"name\": \"Subtoken Edge\",\n          \"details\": \"Sub token\"\n        },\n        {\n          \"name\": \"Next Token Edge\",\n          \"details\": \"NCS\"\n        },\n        {\n          \"name\": \"Last Read Edge\",\n          \"details\": \"For syntax tokens corresponding to variables,\\nwe connect those tokens to all possible places \\nthe variable could have been read last.\"\n        },\n        {\n          \"name\": \"Last Write Edge\",\n          \"details\": \"For syntax tokens corresponding to variables,\\nwe connect those tokens to all possible places \\nthe variable could have been written to last.\"\n        },\n        {\n          \"name\": \"Computed From\",\n          \"details\": \"In an assignment v = expr, connect v to all\\nvariables used in the expression\"\n        }\n      ],\n      \"vertex-features\": \"Unclear how tokens are embedded\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"summary-graph\": {\n      \"name\": \"Dependency Parse Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Summary of code (training), query for search (testing)\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Token\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Dependency Edge\",\n          \"details\": \"One of 49 different types\"\n        },\n        {\n          \"name\": \"Next Token Edge\",\n          \"details\": \"NCS\"\n        },\n        {\n          \"name\": \"Subtoken Edge\",\n          \"details\": \"Sub token\"\n        }\n      ],\n      \"vertex-features\": \"Unclear how tokens are embedded\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"n/a i) Bidirectional GGNN ii) Global max pooling -> h^g iii) Multi-head self attention where Q = K = V = embedding matrices for tokens over GGNN output iv) Mean max pooling over attention output -> h^c v) r = concat(h^g, h^c)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-search\": {\n      \"training-objective\": \"Maximise similarity between matching (summary, code) pairs, minimise similarity between unrelated pairs\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Output vectors for code and query for similarity based  code search\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code Search\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"program-graph + summary-graph\",\n      \"model\": \"model\",\n      \"task\": \"code-search\",\n      \"comments\": \"Program and Summary graphs are encoded by two models with different parameters (i.e. no shared weights), but the same architecture\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 161,\n  \"pdf-id\": 211,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"All paths from the root to a terminal node are extracted, where\\n  1) the root has a value (content), 2) the leaf has a value (content), 3) the other nodes only have types.\\n\\n  Types are one-hot encoded.\\n\\nPreviously generated tokens are also given as input.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Encoder/decoder architecture. \\n\\nEncoder:\\n  1) Root value and leaf value are embedded through an embedding layer.\\n  2) Positional information is added to path embeddings according to \\n      PE(pos, 2i) = sin(pos/10000^(2i/d)) and PE(pos, 2i+1) = cos(pos/10000^(2i/d))\\n  \\n      There is PE_{intra}, where the position is the depth in the path,\\n      and PE_{inter}, where the position is the path index (left to right).\\n  3) Paths are aggregated using attention;\\n      i) x' = x + PE_{intra}   (x: path embedding)\\n      ii) a_i = softmax((x'^TW_{qi})(x'^TW_{ki})^T / \\\\sqrt{d})(x'^TW_{vi})\\n      iii) a = concat(a_1, \\\\hdots, a_h)W_o    (multi-head)\\n      iv) The actual aggregation is unspecified, but presumably it is weighted sum\\n  4) Compute S = [RF, s_1 + LF_1 + PE_{inter,1}, hdots]\\n        where RF is the embedding of the root value, s_i is the embedding \\n        of path i (from step 3), LF_i is the embedding of the leaf value.\\n  5) Z = f(S), where f is the same attention mechanism as in step 3.\\n\\nDecoder:\\n  1) Z passed through multi-head attention to generate K and V matrices \\n  2) Previously generated tokens put through multi-head attention to generate Q matrix.\\n  3) Compute context vector c_t using Q, K, V matrices \\n  4) Linear Layer \\n  5) Softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"training-granularity\": \"Graph to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"working-granularity\": \"Graph to Sequence\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 72,\n  \"pdf-id\": 101,\n  \"graphs\": {\n    \"code-property-graph\": {\n      \"name\": \"Code Property Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Node type is encoded as a scalar \\nTokens in a node are embedded using word2vec; vectors per token are averaged \\nnode type and payload embedding are concatenated\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix (?)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"network\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"During training, takes as input two code samples;\\n  1) labelled sample s from source domain \\n  2) unlabelled sample t from target domain\\n\\ns and t are both processed through the following layers:\\n\\nGGNN network \\nCombine node embeddings \\n  i) concatenating initial features with learned embeddings\\n  ii) multiplying each obtained combined feature vector with a learnable matrix W \\n  iii) Summing the resulting vectors\\nMLP\\n\\nNext, outputs s' and t' are processed somewhat separately;\\n\\no_1 = MLP(s')\\no_2 = MLP(s', t')\\n\\nDuring training, a loss combining o_1 and o_2 is minimised;\\nDuring the working phase, only the output o_1 is used.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"cross-domain-vulnerability-detection\": {\n      \"training-objective\": \"Two training objectives minimised through a joint loss;\\nFirst of all, code samples must be classified as vulnerable or non-vulnerable (o_1);\\nSecond, the output o_2 is scored according to MMD -- Maximum Mean Discrepancy;\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify code samples as vulnerable or non-vulnerable (o_1)\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection in new projects/domains, adapted from existing datasets (few shot learning)\",\n      \"supervision\": \"Supervised (and a bit unsupervised I guess)\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"network\",\n      \"task\": \"cross-domain-vulnerability-detection\",\n      \"comments\": \"There are some small details which are unclear.\\nSpecifically, it is unclear whether the graph embedding part and the \\nsubsequent MLP are part of the same network or not.\\nI am assuming they are, since no separate loss of training \\nsetup is mentioned for the graph embedding part.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 163,\n  \"pdf-id\": 213,\n  \"graphs\": {\n    \"pdg\": {\n      \"name\": \"PDG\",\n      \"description\": \"based on Java compiled to (Jimple) IR\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Method\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"Jimple; Intermediate Representation\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Dependence Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependence Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Random walk is used to generate a bag of paths from the PDG.\\nEach path n_1 e_1 n_2 e_2 ... is seen as a sentence. \\nNode are replaced by their statements, edges with their type (data or control).\\nNLP preprocessing (tokenization, name splitting, remove non-alphabet characters,\\nremove locals, transform to lower case).\\n\\nThe IR is represented as a sequence and enhanced with type information.\\nSpecifically, the type of the instruction, and every token in the IR \\nstatement is prefixed with its nonterminal type according to the Jimple grammar. \\n\\nFirst comment of JavaDoc comment describing the method is also included as input.\\n\\nAll \\\"sentences\\\" obtained this way are combined into a single set of |N| + |P| + 1 sentences.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Transformer based encoder/decoder setup.\\n\\nEncoder:\\n  1) Embedding Layer\\n  2) Add positional Encoding \\n  3) FNN\\n  4) Add more positional encoding \\n  6) Transformer Encoder \\n\\nDecoder:\\n  1) Transformer decoder\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"method-name-generation\": {\n      \"training-objective\": \"Generate a name for the given method\",\n      \"training-granularity\": \"Neural Code Translation\",\n      \"working-objective\": \"Generate a name for the given method\",\n      \"working-granularity\": \"Neural Code Translation\",\n      \"application\": \"Method Name Generation\",\n      \"supervision\": \"Supervised (Self-supervised)\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model\",\n      \"task\": \"method-name-generation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 148,\n  \"pdf-id\": 197,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST with data flow information\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Nodes are one-hot encoded.\\n\\nUnclear what specifically is encoded.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Source code is tokenizes line-by-line, with CamelCase and under_scores split up. Tokens are one-hot encoded.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"encoder/decoder setup.\\n\\n0) All token- and node embeddings are multiplied by a matrix; unclear if part of the network\\n1) AST Encoder (N: Node embedding Matrix, A: binary adjacency Matrix)\\n  i) Three parallel inputs:\\n    - [G] Global Self Attention; Q = NW_Q, K = NW_K, V = NW_V\\n    - [S} Structure Induced Self-Attention; Softmax(\\\\frac{A \\\\cdot QK^T}{\\\\sqrt{d}})V   (Q, K, V not clearly defined)\\n    - [L] Local Self Attention: Softmax(\\\\frac{M \\\\cdot QK^T}{\\\\sqrt{d}})V   \\n      (Q, K, V not clearly defined)\\n      (M: window matrix; constrain computation to node pairs in window distance)\\n  ii) Mean pooling is applied G, S, and L to obtain G', S', L'\\n  iii) s_G, s_S, s_L = sum([G', S', L'] \\\\cdot [G', S', L']^T) (LHS: scalar values)\\n  iv) a = \\\\sigma(s_G * W_g), b = \\\\sigma(s_S * W_s), c = \\\\sigma(s_L * W_l) (W_{g,s,l}: trainable scalars)\\n  v) out = ReLU(FNN(a*G + b*S + c*L))\\n2) Hierarchical Sequence Encoder (recall: input is a sequence of sub-sequences of tokens)\\n  i) Each token is passed through a self-attention layer\\n  ii) Every subsequence is passed through LSTM; where the final hidden state per subsequence is used to represent that sequence (I think)\\n  iii) Self-attention \\n  iv) LSTM (2D matrix output)\\n3) Encoder outputs are concatenated \\n4) Bidirectional Decoder (generate both in left and right direction)\\n  i) embeddings thus far are combined with positional embedding, and passed through embedding layers (one left direction input, one right direction)\\n  ii) Both embeddings are passed through multi-head self-attention \\n  iii) For each embedding, compute FNN_softmax(FNN_relu(...))\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary (note; sequence generated thus far _not_ given as input; entire sequence generated \\\"at once\\\")\",\n      \"training-granularity\": \"Graph + Sequence to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary (note; sequence generated thus far _not_ given as input; entire sequence generated \\\"at once\\\")\",\n      \"working-granularity\": \"Graph + Sequence to Sequence\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": [\n    \"Some details in explanation might be unclear; check paper if necessary\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 218,\n  \"pdf-id\": 288,\n  \"graphs\": {\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"Control flow graph extracted from the bytecode of a smart contract\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"smart contract\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Entry Point\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"New Variable\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"If\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Expression\",\n          \"details\": \"assignment without declaration\"\n        },\n        {\n          \"name\": \"EndIf\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Return\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"True Branch Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"False Branch Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"TF/IDF weighted sum of the Word2Vec embeddings in the opcodes of a node\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Two parallel inputs\\n  i) Graph Input\\n    - GCN\\n    - GCN\\n    - Average Pooling\\n  ii) Adjacency Matrix\\n    - CNN\\n2) Concatenate \\n3) FNN\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Given a graph, classify it as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given a graph, classify it as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection in Smart Contracts\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 93,\n  \"pdf-id\": 128,\n  \"graphs\": {\n    \"vdrg\": {\n      \"name\": \"Vulnerability Dependence Representation Graph (VDRG)\",\n      \"description\": \"Based on PDG\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Dependence Edge\",\n          \"details\": \"Regular Control Dependence Edge\"\n        },\n        {\n          \"name\": \"Vulnerability Control Dependence Edge\",\n          \"details\": \"Control Dependence Edge pointing to a statement \\nwhich was marked as syntactically being potentially vulnerable (SyVC).\\n\\nControl Dependence Edges are marked as Vulnerability Control Dependence Edges\\nif one of the following is true:\\n1) The edge points to a statement that is marked as syntactically potentially vulnerable.\\n2) The edge transitively points to a statement that is marked as syntactically potentially vulnerable.\"\n        },\n        {\n          \"name\": \"Data Dependence Edge\",\n          \"details\": \"Regular Data Dependence Edge\"\n        },\n        {\n          \"name\": \"Vulnerability Data Dependence Edge\",\n          \"details\": \"Data Dependence Edge pointing to a statement \\nwhich was marked as syntactically being potentially vulnerable (SyVC).\\n\\nData Dependence Edges are marked as Vulnerability Data Dependence Edges\\nif one of the following is true:\\n1) The edge points to a statement that is marked as syntactically potentially vulnerable.\\n2) The edge transitively points to a statement that is marked as syntactically potentially vulnerable.\"\n        }\n      ],\n      \"vertex-features\": \"Names are normalised.\\n\\nNode are encoded using word2vec.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Globally, the network uses \\nattention with weights based on edge type,\\nand some message passing scheme.\\nFinal, global pooling is applied\\n\\nExact algorithm:\\n\\nh = 2\\nfor t in V:\\n  for s in N(t):\\n    for i in range(0, h + 1):\\n      K^i(s) = K_Linear^i_{\\\\tau(s)}(H^{init}[s])\\n      Q^i(t) = Q_Linear^i_{\\\\tau(t)}(H^{init}[t])\\n      e = (s, t)\\n      ATT_head^i(s, e, t) = (K^i(s)W^{ATT}_{phi(e)}Q^i(t)^T) * \\\\frac{\\\\mu_{<\\\\tau(s),\\\\phi(e),\\\\tau(t)>}}{\\\\sqrt{d}}\\n    Attention_{HGT}(s, e, t) = softmax(concat_{i \\\\in [1, h]}(ATT_head^i(s, e, t)))\\n    for i in range(0, h + 1):\\n      MSG_Head^i(s, e, t) = M_Linear^i_{\\\\tau(s)}(H^{init}[s])W^{MSG}_{phi(e)}\\n    Message_{HGT}(s, e, t) = concat_{i \\\\in [1, h]}(MSG_Head^i(s, e, t))\\n  H'(t) = \\\\oplus_{s \\\\in N(t)} (Attention_{HGT}(s, e, t) \\\\cdot Message_{HGT}(s, e, t))\\n  H(t) = ReLU(A_Linear_{\\\\tau(t)}(\\\\sigma(H'(t))) + H^{init}[t])\\nH = \\\\oplus_{t \\\\in V} H(t)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify graph (function) as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify graph (function) as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"vdrg\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 155,\n  \"pdf-id\": 204,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST with additional edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Child\",\n          \"details\": \"Regular AST Edge\"\n        },\n        {\n          \"name\": \"Subtoken\",\n          \"details\": \"From a token (AST leaf node) to its subtokens (after splitting)\"\n        },\n        {\n          \"name\": \"Next Token\",\n          \"details\": \"NCS\"\n        },\n        {\n          \"name\": \"Last Lexical Use\",\n          \"details\": \"Connect occurrence of variable name to its most recent previous occurrence\"\n        }\n      ],\n      \"vertex-features\": null,\n      \"edge-features\": null,\n      \"connectivity-features\": null,\n      \"graph-features\": null,\n      \"other-features\": \"During training, ground truth token is given as input x'_j;\\nduring testing, previous token x'_j is given as input.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"encoder/decoder setup where steps 1-9 form the encoder,\\nand the remainder the decoder.\\n\\n1) GGNN (w/ edge-type specific function to compute messages)\\n2) Pooling according to \\n    r_g = \\\\sum_{v \\\\in V} \\\\sigma(W_i[h_v, h^0_v]) \\\\cdot W_j h_v\\n    (h_v: embedding after GGNN, h^0_v: initial node embedding)\\n3) g_v = FNN[1 layer, sigmoid]([h_v, r_g])\\n4) f_v = g_v \\\\cdot h_v \\n5) L_0 = W_I[F, X] + b_I (F: aggregated f_v, X: initial node embedding)\\n6) L_1 = PReLU(Conv1D(L_0))\\n7) L_f = PReLU(Conv1D(L_1))\\n8) r_c = AveragePool(L_f)\\n9) r = W_e[r_g, r_c] + b_e\\n10) s_j = LSTM(s_{j - 1}, x'_j)\\n11) e_{v,j} = V_a \\\\tanh(W_a[s_j, f_v] + b_a)\\n12) a_{v,j} = softmax(e_{v,j})\\n13) c_j = \\\\sum_{v \\\\in V} a_{v,j} f_v\\n14) P_{vocab} = softmax(Linear(Linear([s_j, c_j]))\\n15) P_{atten}(w) = \\\\sum_{v \\\\in V: w_v = w} a_{v,j} \\n16) P^j_{gen} = \\\\sigmoid(W_s s_j + W_c c_j + W_x x'_j + b_{gen})\\n17) P_{salience} = softmax(Conv1D(L_f \\\\cdot s_j)) (element-wise product)\\n18) P_{copy} = P_{atten}(w) + P_{salience}(w)\\n19) P(w) = P^j_{gen}P_{vocab(w) + (1 - P^j_{gen})P_{copy}(w)\\n\\n(Intuitively, P^j_{gen} is the probability of copying an (unknown)\\nword from the input\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"method-naming\": {\n      \"training-objective\": \"Given a code snippet, generate a method name.\\nDone token-by-token; previous tokens are also given as input\",\n      \"training-granularity\": \"Graph to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a method name.\\nDone token-by-token; previous tokens are also given as input\",\n      \"working-granularity\": \"Graph to Sequence\",\n      \"application\": \"Code summarization (Method Name Generation)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"method-naming\",\n      \"comments\": \"It is unclear how the graph encoder output \\\"r\\\" is used in the decoder\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 48,\n  \"pdf-id\": 68,\n  \"graphs\": {\n    \"dev-network\": {\n      \"name\": \"n/a\",\n      \"description\": \"Network connecting developers, issues, source files, and tags assigned to issues.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Issues\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"User Data\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"Files\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Developer\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Issue\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Source File\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Issue Tag\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Labelled\",\n          \"details\": \"Connects issues with their labels\"\n        },\n        {\n          \"name\": \"Review\",\n          \"details\": \"Linked Developers with Issues they were involved in\"\n        },\n        {\n          \"name\": \"Commit\",\n          \"details\": \"Link developers to source files they committed\"\n        },\n        {\n          \"name\": \"Similar\",\n          \"details\": \"Link issues to possibly related source files, based on cosine similarity (len(issue & code) / len(code))\"\n        }\n      ],\n      \"vertex-features\": \"Nodes are embedded of numerical vectors with equal dimensions for all node types.\\n\\nFor issues, they are encoded using Word2Vec, by taking the average of all words in the issue description.\\n\\nDevelopers are encoded by taking the average of the embeddings of all the issues created by the developer.\\n\\nEmbeddings for other nodes are not discussed.\",\n      \"edge-features\": \"Various meta paths are used\",\n      \"connectivity-features\": \"Adjacency matrix\",\n      \"graph-features\": \"Link and node masking are applied.\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gat\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Let E denote initial node embeddings.\\n\\nEvery node embedding is passed through several GAT layers,\\nwhere there is a GAT stack for every meta path.\\n\\nFor every issue or developer node, there will be a number \\nof embeddings equal to the number of metapaths.\\nEmbeddings are fused using an attention mechanism.\\n\\nDeveloper/issue embedding pairs are concatenated \\nand passed through a MLP to predict issue/developer suitability.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"training\": {\n      \"training-objective\": \"Dual training objective:\\n1) minimise contrastive loss \\n2) predict correct (developer, issue) pairs\",\n      \"training-granularity\": \"Node (Pair) Classification\",\n      \"working-objective\": \"Predict suitable developer for an issue\",\n      \"working-granularity\": \"Node (Pair) Classification\",\n      \"application\": \"Developer recommendation for issues\",\n      \"supervision\": \"Supervised, Self supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"dev-network\",\n      \"model\": \"gat\",\n      \"task\": \"training\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 5,\n  \"pdf-id\": 10,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"AST\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code (method)\",\n          \"details\": \"adjustable\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"One-hot encoding of node type\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Edge Index List (Adjacency List)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gvae\": {\n      \"type\": {\n        \"name\": \"GVAE\",\n        \"architecture\": \"GCN Layer [Kipf] w/ ReLU (size 100) GCN Layer [Kipf] w/ ReLU (size 20) Split into two separate GCN Layers [Kipf] (size 10) - First layer computes means - Second layer computes log of the standard deviations\\nCombine results to obtained final output, through re-parametrization; draw e ~ N(0, 1) and compute mu + sigma * e for various e; resulting in matrix output.\\nDecoding is done by computing the dot product ZZ^T\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"embedding\": {\n      \"training-objective\": \"Minimise reconstruction error (reconstruction using dot-product)\",\n      \"training-granularity\": \"Graph Embedding\",\n      \"working-objective\": \"Graph Embedding\",\n      \"working-granularity\": \"Graph Embedding\",\n      \"application\": \"Graph Embedding\",\n      \"supervision\": \"unsupervised (self-supervised)\"\n    }\n  },\n  \"training\": {\n    \"training\": {\n      \"train-test-split\": \"n/a\",\n      \"cross-validation\": \"n/a\",\n      \"hyper-parameters\": [\n        {\n          \"name\": \"loss\",\n          \"value\": \"\\\\mathbb{E}_{q(Z \\\\mid X, A)} \\\\left(\\\\log p(A \\\\mid Z) - D_{KL}(q(Z \\\\mid X, A) \\\\mid\\\\mid p(Z))\\\\right)\"\n        },\n        {\n          \"name\": \"latent space size\",\n          \"value\": 10\n        },\n        {\n          \"name\": \"optimizer\",\n          \"value\": \"adam\"\n        },\n        {\n          \"name\": \"learning rate\",\n          \"value\": 0.001\n        },\n        {\n          \"name\": \"batch size\",\n          \"value\": 10\n        },\n        {\n          \"name\": \"epochs\",\n          \"value\": 30\n        }\n      ],\n      \"hyper-parameter-selection\": \"not specified\",\n      \"search-tuned-hyper-parameters\": \"n/a\",\n      \"evaluation-details\": \"evaluated on downstream task\",\n      \"evaluation-methods\": [\n        {\n          \"name\": \"code clone detection\",\n          \"type\": \"downstream task\",\n          \"details\": \"compared latent vectors using centroid distance, variance distance, and size distance to detect code clones.\"\n        }\n      ]\n    }\n  },\n  \"datasets\": {\n    \"projects\": {\n      \"name\": \"n/a\",\n      \"description\": \"Dataset of open source java projects\",\n      \"source\": [\n        \"ANTLR\",\n        \"Apache Ant\",\n        \"ArgoUML\",\n        \"CAROL\",\n        \"DNSjava\",\n        \"Hibernate\",\n        \"JDK\",\n        \"JHotDraw\"\n      ],\n      \"labelling\": \"not specified\",\n      \"size\": \"unclear\",\n      \"is-pre-existing\": true\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"gvae\",\n      \"task\": \"embedding\",\n      \"training\": \"training\",\n      \"dataset\": \"projects\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 186,\n  \"pdf-id\": 246,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"The AST is traversed (depth first order), and the resulting sequence of \\nAST node is used as the AST representation (types for internal nodes,\\ntokens for leaf nodes)\\n\\nThe original sequence of code tokens is also used as a feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Variational Auto Encoder w/ 2 encoders and 1 decoder  \\n\\n1) Token encoder -- generates latent representation w/ von Mises-Fisher (vMF) distribution\\n  i) Bidirectional LSTM\\n  ii) Two parallel FNNs \\n      - One generates \\\\mu \\n      - One generates \\\\kappa\\n2) AST Encoder -- generates Gaussian latent representation\\n  i) Bidirectional LSTM\\n  ii) Two parallel FNNs\\n        - One generates \\\\mu\\n        - One generates \\\\sigma^2\\n\\n3) Decoder \\n  i) LSTM \\n  ii) FNN w/ Softmax \\n\\nFor cross language learning, \\nthere is a language-specific (ast encoder, token encoder, decoder) triple \\nper language.\\n\\nThere are also a shared token encoder and decoder. \\nThe token encoder aims to output the same as the language-specific encoder,\\nin a student/teacher setup. The output of the shared encoder and the \\nlanguage specific AST encoder are passed to the shared decoder,\\nwhich aims to given the same output as the language specific decoder \\n(student/teacher setup).\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"embedding\": {\n      \"training-objective\": \"Minimise reconstruction loss\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Model pre-training\",\n      \"supervision\": \"Unsupervised / Self-supervised\"\n    },\n    \"cross-language-program-translation\": {\n      \"training-objective\": \"Given the source snippet in language A, generate the target snippet in language B\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given the source snippet in language A, generate the target snippet in language B\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Cross Language Program Translation\",\n      \"supervision\": \"Supervised\"\n    },\n    \"cross-language-code-clone-detection\": {\n      \"training-objective\": \"Given two code snippets, maximise their cosine similarity (computed based on shared encoder output)\\nif they are semantic clones, minimise it otherwise\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Output vector representation useful for code clone detection\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Cross Language Code Clone Detection\",\n      \"supervision\": \"Supervised\"\n    },\n    \"cross-language-code-search\": {\n      \"training-objective\": \"Given two code snippets, encode them (using shared encoder),\\nconcatenate, and put through FNN, and output a label denoting the unique functionality of that pair\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given two code snippets, encode them (using shared encoder),\\nconcatenate, and put through FNN, and output a label denoting the unique functionality of that pair\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Cross Language Code to Code Search\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"embedding + cross-language-program-translation\",\n      \"comments\": \"The `embedding` task is used for pretraining; the other task is used for fine-tuning.\"\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"embedding + cross-language-code-clone-detection\",\n      \"comments\": \"The `embedding` task is used for pretraining; the other task is used for fine-tuning.\"\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"embedding + cross-language-code-search\",\n      \"comments\": \"The `embedding` task is used for pretraining; the other task is used for fine-tuning.\"\n    }\n  ],\n  \"comments\": [\n    \"I don't fully understand the code search task\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 38,\n  \"pdf-id\": 54,\n  \"graphs\": {\n    \"type-dependency-graph\": {\n      \"name\": \"Type Dependency Graph\",\n      \"description\": \"Hypergraph representing relationships between types.\\n\\nIn this hypergraph, each edge may connect an arbitrary number of vertices.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Type\",\n          \"details\": \"Some types are intermediary/placeholder types, e.g. introduced for untyped var declarations.\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Bool(a)\",\n          \"details\": \"True if a is used as a Boolean\"\n        },\n        {\n          \"name\": \"Subtype(a, b)\",\n          \"details\": \"a is a subtype of b\"\n        },\n        {\n          \"name\": \"Assign(a, b)\",\n          \"details\": \"b is assigned to a\"\n        },\n        {\n          \"name\": \"Function(a, b_1, b_2, ..., b_k, b*)\",\n          \"details\": \"a is a function taking b_1, b_2, ..., b_k as arguments, and returning b*\"\n        },\n        {\n          \"name\": \"Call(a, b*, b_1, b_2,, ..., b_k)\",\n          \"details\": \"The result of calling function of type b* with arguments b_1, b_2, ..., b_k is assigned to a\"\n        },\n        {\n          \"name\": \"Object_{l_1, \\\\hdots, l_k}(a, b_1, ..., b_k)\",\n          \"details\": \"a is an object {l_1 -> b_1,  \\\\hdots, l_k -> b_k}\"\n        },\n        {\n          \"name\": \"Access_l(a, b)\",\n          \"details\": \"a = b.l\"\n        },\n        {\n          \"name\": \"Name_l(a)\",\n          \"details\": \"a has name l\"\n        },\n        {\n          \"name\": \"NameSimilar(a, b)\",\n          \"details\": \"a and b have similar names\\n\\nThe names of a and b are considered similar if their sets of tokens have nonempty intersection.\\nTokenization occurs by splitting on underscores, camelcase, and numbers, and then converting\\nto lowercase.\"\n        },\n        {\n          \"name\": \"Usage_l((a*, b*), (a_1, b_1), ..., (a_k, b_k))\",\n          \"details\": \"Usages involving name l\"\n        }\n      ],\n      \"vertex-features\": \"Nodes corresponding to constants (with known type) are set to a vector which is never updated further.\\n\\nOther nodes are all initialised with the same generic vector.\",\n      \"edge-features\": \"Edge features are based on identifier names (i.e. l_k).\\nEach name is tokenized (as explained above). \\nEach token occurring > 1 times is kept as-is.\\nOther tokens are mapped randomly to one of the <Unknown-i> tokens,\\nwhere 0 <= i <= 50\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Node and identifier embeddings trainable.\\n\\nWorks using a message passing/aggregation scheme.\\n\\nMessage passing comes in three forms:\\n1) For edges with a fixed number of nodes,\\n    all embeddings of all nodes and identifiers involved are passed\\n    through a MPL\\n2) For edges with a variable number of nodes, but not pairs,\\n    The set of messages for a are computed as {MPL_a(v_{l_j} \\\\mid\\\\mid v_{b_j}) \\\\mid j = 1, ..., k}.\\n    The message for each b_j is computed as MLP_b(v_{l_j} \\\\mid\\\\mid v_{a})\\n3) For edges with a variable number of node pairs,\\n    A dot-product based attention mechanism is used to compute messages.\\n\\nAggregation is done similar to GAT, with the difference being that \\nattention weights are computed using a dot product, not a linear model.\\n\\nFinally, a prediction layer MPL(v_n, u_n) is to compute a compatability \\nscore for each type. Here, u_n is the embedding for the type, and v_n\\nis a trainable vector for the library the type comes from. \\nFor user defined types, v_n = u_n.\\n\\nA softmax layer is used to compute the scores to probability distribution.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"type-prediction\": {\n      \"training-objective\": \"Predict types of nodes w/ unknown type\",\n      \"training-granularity\": \"Node Classification related, but not quite\",\n      \"working-objective\": \"Predict types of nodes w/ unknown type\",\n      \"working-granularity\": \"Node Classification related, but not quite\",\n      \"application\": \"Type prediction for converting dynamically typed to statically typed code\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"type-dependency-graph\",\n      \"model\": \"model\",\n      \"task\": \"type-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 74,\n  \"pdf-id\": 104,\n  \"graphs\": {\n    \"pdg\": {\n      \"name\": \"PDG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Line\",\n          \"details\": \"Comments are omitted \\nnormalise names (VAR0, FUN1)\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Lines of code encoded using sent2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"Structure Aware Transformer\",\n        \"architecture\": \"Structure Aware Transformer\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify code sample as vulnerable or non-vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify code sample as vulnerable or non-vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": \"n/a\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 96,\n  \"pdf-id\": 132,\n  \"graphs\": {\n    \"ccg\": {\n      \"name\": \"Code Composite Graph (CCG)\",\n      \"description\": \"Mix of AST, CFG, and DFG\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Node token encoded using word2vec\\nNode type encoded using label encoding \\nBoth encodings are concatenated\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"bgnn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Edges are considered in both directions.\\n\\nGGNN\\n\\nFinal node embeddings are passed through:\\nConv\\nReLU \\nMaxPool\\nMLP\\nSigmoid\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify graph as vulnerable / not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify graph as vulnerable / not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ccg\",\n      \"model\": \"bgnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 67,\n  \"pdf-id\": 94,\n  \"graphs\": {\n    \"control-flow-chart\": {\n      \"name\": \"Control Flow Chart\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Local block\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Line\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"The code block (not the nodes; the entire block)\\nis tokenized using the pretrained BPE tokenizer from CodeBERT.\\nThese tokens are passed to the pre-embedding\\npart of the network.\"\n    }\n  },\n  \"models\": {\n    \"rgan\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"One network with four parts.\\nPre-embedding stage; Code block is passed to embedding layer Bidirectional LSTM\\nThis part of the network generates a vector representation of every line, which are used as the node features in the GNN part.\\nControl Flow Chart is passed to GNN; GCN with skip connections\\nPooling (Mean Biaffine Attention Pooling Module); h_{mean} = \\\\frac{1}{n} \\\\sum_{i = 1}^n h_i h_{fi} = h_i^T \\\\cdot W e_i = h_{fi}^T \\\\cdot h_{mean} + h_i^T \\\\cdot u a_i = softmax(e_i) = \\\\frac{\\\\exp(e_i)}{\\\\sum_{j = 0}^n \\\\exp(e_j)} h_g = \\\\sum_{i = 0}^n a_i \\\\cdot h_{fi}\\nHere, W is a learnable matrix, u is a learnable vector, and h_g is the pooled (graph) representation.\\nClassifier; MLP\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify graph as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify graph as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"control-flow-chart\",\n      \"model\": \"rgan\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 121,\n  \"pdf-id\": 163,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow EDge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Node type (nonterminal, terminal, or value (contains actual token)) is used as feature\\nType of syntactic node is used as feature \\n\\nUnclear what exact features are used, and how they are encoded.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GraphSAGE\\nGraphSAGE\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"bug-localisation\": {\n      \"training-objective\": \"Classify node as buggy or not buggy\",\n      \"training-granularity\": \"Node Classification\",\n      \"working-objective\": \"Classify node as buggy or not buggy\",\n      \"working-granularity\": \"Node Classification\",\n      \"application\": \"Bug Localisation\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"bug-localisation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 19,\n  \"pdf-id\": 30,\n  \"graphs\": {\n    \"heterogeneous-contract-graph\": {\n      \"name\": \"Heterogeneous Contract Graph\",\n      \"description\": \"Combination of heterogeneous control flow and heterogeneous call graphs at multiple levels of granularity.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Source code of smart contracts\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Different node types for different control flow (e.g ENTRY_POINT, NEW_VARIABLE, RETURN, IF, END_IF, FUNCTION_START)\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"FALLBACK_NODE\",\n          \"details\": \"Node to represent the call to a fallback function\"\n        },\n        {\n          \"name\": \"FUNCTION_NAME\",\n          \"details\": \"Node to represent the name of a function;\\nused combined with INTERNAL_CALL/EXTERNAL_CALL to represent FCG information,\\nand is connected to the ENTRY_POINT of a function (and thus forms the merging points for call and control flow graphs)\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Different types for control flow (e.g. TRUE, FALSE, NEXT)\",\n          \"details\": null\n        },\n        {\n          \"name\": \"INTERNAL_CALL\",\n          \"details\": \"Call to function within the same smart contract\"\n        },\n        {\n          \"name\": \"EXTERNAL_CALL\",\n          \"details\": \"Call to function in another smart contract\"\n        }\n      ],\n      \"vertex-features\": \"One-hot encoded node types, _but_ that is not used for most evaluations\",\n      \"edge-features\": \"All length 2 meta-paths for all pairs of node types are extracted. Not used for all evaluations. \\n(Note -- length 2 meta path is like A -> B -> C)\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"mando-one-hot\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"General setup:\\n1) Nodes are embedded by the Topological Graph Neural Network (TGNN) Component\\n2) Node embeddings are, combined with the extracted meta paths, used in the \\n  Node-level attention heterogeneous graph neural network component (NLAHTGNN).\\n3) Output of NLAHTGNN is fed through MLP for downstream tasks.\\n\\nNLAHTGNN -- based on HAN, but with adjustments.\\nIn particular, the network type used can handle multiple dynamic customised metapaths \\nwithout pre-defining the list of input metapaths.\\n\\nTGNN used: one-hot encoding of node type\"\n      }\n    },\n    \"mando-line\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"General setup:\\n1) Nodes are embedded by the Topological Graph Neural Network (TGNN) Component\\n2) Node embeddings are, combined with the extracted meta paths, used in the \\n  Node-level attention heterogeneous graph neural network component (NLAHTGNN).\\n3) Output of NLAHTGNN is fed through MLP for downstream tasks.\\n\\nNLAHTGNN -- based on HAN, but with adjustments.\\nIn particular, the network type used can handle multiple dynamic customised metapaths \\nwithout pre-defining the list of input metapaths.\\n\\nTGNN used: LINE\"\n      }\n    },\n    \"mando-node2vec\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"General setup:\\n1) Nodes are embedded by the Topological Graph Neural Network (TGNN) Component\\n2) Node embeddings are, combined with the extracted meta paths, used in the \\n  Node-level attention heterogeneous graph neural network component (NLAHTGNN).\\n3) Output of NLAHTGNN is fed through MLP for downstream tasks.\\n\\nNLAHTGNN -- based on HAN, but with adjustments.\\nIn particular, the network type used can handle multiple dynamic customised metapaths \\nwithout pre-defining the list of input metapaths.\\n\\nTGNN used: Node2Vec\"\n      }\n    },\n    \"mando-metapath2vec\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"General setup:\\n1) Nodes are embedded by the Topological Graph Neural Network (TGNN) Component\\n2) Node embeddings are, combined with the extracted meta paths, used in the \\n  Node-level attention heterogeneous graph neural network component (NLAHTGNN).\\n3) Output of NLAHTGNN is fed through MLP for downstream tasks.\\n\\nNLAHTGNN -- based on HAN, but with adjustments.\\nIn particular, the network type used can handle multiple dynamic customised metapaths \\nwithout pre-defining the list of input metapaths.\\n\\nTGNN used: Metapath2vec\"\n      }\n    },\n    \"mando-gcn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"General setup:\\n1) Nodes are embedded by the Topological Graph Neural Network (TGNN) Component\\n2) Node embeddings are, combined with the extracted meta paths, used in the \\n  Node-level attention heterogeneous graph neural network component (NLAHTGNN).\\n3) Output of NLAHTGNN is fed through MLP for downstream tasks.\\n\\nNLAHTGNN -- based on HAN, but with adjustments.\\nIn particular, the network type used can handle multiple dynamic customised metapaths \\nwithout pre-defining the list of input metapaths.\\n\\nTGNN used: GCN\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"contract-level-analysis\": {\n      \"training-objective\": \"Classify smart contracts as vulnerable/not vulnerable (for the attention network part)\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify smart contracts as vulnerable/not vulnerable (for the attention network part)\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Smart Contract Vulnerability Detection\",\n      \"supervision\": \"supervised\"\n    },\n    \"statement-level-analysis\": {\n      \"training-objective\": \"Identify vulnerable lines in smart contracts which are guaranteed to contain vulnerabilities (for the attention network part)\",\n      \"training-granularity\": \"Node Classification\",\n      \"working-objective\": \"Identify vulnerable lines in smart contracts which are guaranteed to contain vulnerabilities (for the attention network part)\",\n      \"working-granularity\": \"Node Classification\",\n      \"application\": \"Smart Contract Vulnerability Identification\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"heterogeneous-contract-graph\",\n      \"model\": \"mando-one-hot\",\n      \"task\": \"contract-level-analysis\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"heterogeneous-contract-graph\",\n      \"model\": \"mando-one-hot\",\n      \"task\": \"statement-level-analysis\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"heterogeneous-contract-graph\",\n      \"model\": \"mando-nod2vec\",\n      \"task\": \"contract-level-analysis\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"heterogeneous-contract-graph\",\n      \"model\": \"mando-node2vec\",\n      \"task\": \"statement-level-analysis\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"heterogeneous-contract-graph\",\n      \"model\": \"mando-line\",\n      \"task\": \"contract-level-analysis\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"heterogeneous-contract-graph\",\n      \"model\": \"mando-line\",\n      \"task\": \"statement-level-analysis\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"heterogeneous-contract-graph\",\n      \"model\": \"mando-metapath2vec\",\n      \"task\": \"contract-level-analysis\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"heterogeneous-contract-graph\",\n      \"model\": \"mando-metapath2vec\",\n      \"task\": \"statement-level-analysis\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"heterogeneous-contract-graph\",\n      \"model\": \"mando-gcn\",\n      \"task\": \"contract-level-analysis\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"heterogeneous-contract-graph\",\n      \"model\": \"mando-gcn\",\n      \"task\": \"statement-level-analysis\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 120,\n  \"pdf-id\": 162,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Graph representing a commit.\\nBased on the \\\"hunks\\\" (added and removed lines)\\nfrom a commit.\\n\\nBoth hunks are parsed into ASTs,\\ncalled the old and new AST.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"commit\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Code Node\",\n          \"details\": \"Either an AST node, \\nor a result of the fact that\\nSnake and camel case names are split up; the tokens are added as child nodes of the original AST node\"\n        },\n        {\n          \"name\": \"Edit Node\",\n          \"details\": \"Several different types:\\nV_ADD: For nodes not present in the old AST, but which are present in the new AST\\nV_DEL: Connect a node which is present in the old AST, but not in the new AST\\nV_MOVE: Connect two nodes present in both ASTs, but the subtree has moved in the new AST\\nV_UPDATE: Connect two nodes present in both ASTs, but the content of the node was updated in the new AST.\\nV_MATCH: Connect two nodes present in both AST, with matching location and content\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Edit Edge\",\n          \"details\": \"Each edit node is connect to two AST nodes using edit edges\"\n        },\n        {\n          \"name\": \"Token Node\",\n          \"details\": \"The leaf nodes in the AST (containing the tokens) are connected in token (NCS) order\"\n        }\n      ],\n      \"vertex-features\": null,\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Encoder/Decoder setup.\\n\\nEncoder uses Trainable embedding layer, followed by GCN layers w/ residual connections and normalisation\\n\\nDecoder uses the decoder of a Transformer model, which takes as input the \\nalready generated output, and the next output of the encoder. The output of the transformer is,\\ncombined with the output of the encoder, fed into multiple layers, including an attention mechanism,\\nin order to generate the next token.\\n\\nFor details, see full paper.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"commit-message-generation\": {\n      \"training-objective\": \"Given a commit, (re-)construct its commit message (the first sentence)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a commit, generate a commit message (the first sentence)\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Commit Message Generation\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"commit-message-generation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 172,\n  \"pdf-id\": 225,\n  \"graphs\": {\n    \"heterogeneous-program-graph\": {\n      \"name\": \"Heterogeneous Program Graph (HPG)\",\n      \"description\": \"Based on AST\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Every node has a type and a value.\\nThe type is the composite or primitive type of the node (e.g. statement),\\nthe value is either the Constructor (e.g. FunctionDef, for a statement in the\\nAbstract Syntax Description Language (ASDL), or the token payload \\nof the node (leaf nodes)\"\n        },\n        {\n          \"name\": \"Subtoken\",\n          \"details\": \"Two variants:\\nshared subtokens (one node for every _unique_ subtoken),\\nor separate subtoken node per occurrence\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Child\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Next Sibling Edge\",\n          \"details\": null\n        },\n        {\n          \"name\": \"Next Token Edge\",\n          \"details\": null\n        },\n        {\n          \"name\": \"AST Parent\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Previous Sibling Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Previous Token Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Subtoken of\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Subtoken of reversed\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"type and value\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"hgt\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Embedding Layer \\n2) Positional Encoding Layer, based on \\\\sin() of the position in the depth first traversal of the AST \\n3) Add output of embedding layer and positional encoding layer\\n4) Heterogeneous Message Passing\\n    1) Considering a node t, which has a neighbour s of type tau(t) connected through e with type \\\\phi(e), \\n        Compute message head according to M^k(s, e, t) = Linear_{\\\\tau(t)}(h_s^{k - 1}) W^M_{phi(e)}\\n    2) Concatenate multiple independent message head to obtain Message \\n    3) Compute unnormalised attention score\\n        A^k(s, e, t) = (K^k(s) W^A_{\\\\phi(e)} (Q^k(t))^T) \\\\frac{\\\\mu_{\\\\tau(s),\\\\phi(e),\\\\tau(t)}}{\\\\sqrt{d}}\\n        \\\\mu is some trainable parameter \\n    4) Normalise using softmax \\n    5) Aggregate message by summing using attention scores as weights \\n    6) Residual connection\\n5) Downstream tasks specific part\\n    1) decoder with pointer network and copy mechanism for generation tasks \\n    2) global attention pooling w/ MLP for classification\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"method-name-prediction\": {\n      \"training-objective\": \"Generate a name for the given method\",\n      \"training-granularity\": \"Neural Code Translation (Graph To Sequence)\",\n      \"working-objective\": \"Generate a name for the given method\",\n      \"working-granularity\": \"Neural Code Translation (Graph To Sequence)\",\n      \"application\": \"Method Name Generation\",\n      \"supervision\": \"Supervised\"\n    },\n    \"code-classification\": {\n      \"training-objective\": \"Classify code snippet into one of several categories\",\n      \"training-granularity\": \"Graph Multi-class classification\",\n      \"working-objective\": \"Classify code snippet into one of several categories\",\n      \"working-granularity\": \"Graph Multi-class classification\",\n      \"application\": \"Program Classification\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"heterogeneous-program-graph\",\n      \"model\": \"hgt\",\n      \"task\": \"method-name-prediction + code-classification\",\n      \"comments\": \"The model is a general one meant for downstream tasks, where the given tasks are examples used in the paper for evaluation.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 178,\n  \"pdf-id\": 232,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"Each AST is split into subtrees.\\nSpecifically, each composite structure (e.g. if, while)\\nis replaced with a placeholder node, and the \\ncorresponding subtree is isolated from its parent tree.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"unclear how nodes in tokens are initially embedded\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"Structure tree (tree representing how all subtrees fit together) \\nis also used as graph.\",\n      \"other-features\": \"Raw code snippets are used as features\\n\\nFor code search, a query is given in text form.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Raw code snippet tokens encoded using transformer encoder\\n2) Subtrees passed to a tree-based (bottom up) RNN (RvNN):\\n    i) h_i^{t + 1} = \\\\tanh(W^C c_i^t + \\\\frac{1}{|CH^t(v_i)} \\\\sum_{j \\\\in CH^t(v_i)} W^A h_j^t)\\n      (h = hidden states, CH = children, c = token embedding)\\n    ii) After all nodes updated, compute dimension-wise max-pooling to obtain tree representation\\n3) Same scheme is applied to the structure tree (tree representing how all subtrees fit together),\\n      but c_i now denote the embeddings of sub-trees.\\n4.1) for summarisation, encoded tokens and encoded AST are passed to transformer decoder w/ copy mechanism\\n4.2) for code search, the embedding of the root of the structure tree, and the embedding\\n    of the [CLS] token from the last encoder layer are concatenated and passed through a linear layer.\\n\\n    Query encoded using transformer encoder \\n\\n    The scalar product is used to compute similarity between the code and query vectors.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary.\",\n      \"training-granularity\": \"Graph to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary.\",\n      \"working-granularity\": \"Graph to Sequence\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    },\n    \"code-search\": {\n      \"training-objective\": \"Maximise similarity between _related_ code snippet and queries (compared to unrelated pairs)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Compute similarity of code snippets and query\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code search\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-search\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 88,\n  \"pdf-id\": 121,\n  \"graphs\": {\n    \"pdg\": {\n      \"name\": \"PDG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Dependence Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow  Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Self Loop\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Statements are encoded using CodeBERT\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"The entire function is encoded using CodeBERT\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Graph input fed to GAT \\n\\nGAT output multiplied by function embedding\\n\\nMLP\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify nodes as vulnerable/not vulnerable\",\n      \"training-granularity\": \"Node Classification\",\n      \"working-objective\": \"Classify nodes as vulnerable/not vulnerable\",\n      \"working-granularity\": \"Node Classification\",\n      \"application\": \"Statement-level Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 213,\n  \"pdf-id\": 283,\n  \"graphs\": {\n    \"heterogeneous-contract-graph\": {\n      \"name\": \"Heterogeneous Contract Graph\",\n      \"description\": \"Combination of heterogeneous control flow and heterogeneous call graphs at multiple levels of granularity.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Source code of smart contracts\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"ROOT (cfg node)\",\n          \"details\": \"Entry point of the control flow graph of a function\"\n        },\n        {\n          \"name\": \"BASIC (cfg node)\",\n          \"details\": \"Basic block\"\n        },\n        {\n          \"name\": \"DISPATCHER (cfg node)\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"LEAF (cfg node)\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"EXIT (cfg node)\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"FALLBACK NODE (cfg node)\",\n          \"details\": \"Node to represent the call to a fallback function\"\n        },\n        {\n          \"name\": \"FUNCTION_NAME\",\n          \"details\": \"Node to represent the name of a function;\\nused combined with INTERNAL_CALL/EXTERNAL_CALL to represent FCG information,\\nand is connected to the ENTRY_POINT of a function (and thus forms the merging points for call and control flow graphs)\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Different types for control flow (e.g. TRUE, FALSE, NEXT)\",\n          \"details\": null\n        },\n        {\n          \"name\": \"INTERNAL_CALL\",\n          \"details\": \"Call to function within the same smart contract\"\n        },\n        {\n          \"name\": \"EXTERNAL_CALL\",\n          \"details\": \"Call to function in another smart contract\"\n        }\n      ],\n      \"vertex-features\": \"Four different schemes of generating node features, used separately:\\n  1) One-hot encoded node types\\n  2) metapath2vec (random walk + skipgram)\\n  3) LINE \\n  4) node2vec\",\n      \"edge-features\": \"All length 2 meta-paths for all pairs of node types are extracted. (Note -- length 2 meta path is like A -> B -> C)\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Transformer-like model, but with special Heterogeneous Graph Transformer layers \\n\\nFor every triple (s_1, t, s_2), where t is the target node and s_1 and s_2 are neighbours according to\\nthe metapath relation, \\n  1) compute attention scores based on the node embeddings and edge types\\n  2) Compute messages from s_1, s_2 based on node embeddings and edge types\\n  3) Combine od embedding of t with the messages from s_1, s_2 using the computed attention scores \\n\\nPooling (for graph classification) not specified \\n\\nMLP (graph and node-wise, depending on the task)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"coarse-grained-vulnerability-detection\": {\n      \"training-objective\": \"Classify graph as vulnerable or not vulnerable (per vulnerability type)\",\n      \"training-granularity\": \"graph classification (seems to be multi-label, not 100% sure)\",\n      \"working-objective\": \"Classify graph as vulnerable or not vulnerable (per vulnerability type)\",\n      \"working-granularity\": \"graph classification (seems to be multi-label, not 100% sure)\",\n      \"application\": \"vulnerability detection\",\n      \"supervision\": \"supervised\"\n    },\n    \"fine-grained-vulnerability-detection\": {\n      \"training-objective\": \"Classify node as vulnerable or not vulnerable (per vulnerability type)\",\n      \"training-granularity\": \"node classification (seems to be multi-label, not 100% sure)\",\n      \"working-objective\": \"Classify node as vulnerable or not vulnerable (per vulnerability type)\",\n      \"working-granularity\": \"node classification (seems to be multi-label, not 100% sure)\",\n      \"application\": \"vulnerability detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"heterogeneous-contract-graph\",\n      \"model\": \"model\",\n      \"task\": \"coarse-grained-vulnerability-detection\",\n      \"comments\": \"the main idea is a two-step approach; first detect _whether_ a graph is vulnerable, then _where_ it is vulnerable\"\n    },\n    {\n      \"graph\": \"heterogeneous-contract-graph\",\n      \"model\": \"model\",\n      \"task\": \"fine-grained-vulnerability-detection\",\n      \"comments\": \"the main idea is a two-step approach; first detect _whether_ a graph is vulnerable, then _where_ it is vulnerable\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 36,\n  \"pdf-id\": 49,\n  \"graphs\": {\n    \"graph-1\": {\n      \"name\": \"n/a\",\n      \"description\": \"modified control flow graph\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Token\",\n          \"details\": \"CFG is created based on statements, then every statement is split into tokens\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow\",\n          \"details\": \"CFG is created based on statements, then every statement is split into tokens\"\n        },\n        {\n          \"name\": \"Next Token (statement)\",\n          \"details\": \"Connect consecutive tokens in a statement\"\n        }\n      ],\n      \"vertex-features\": \"token\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"graph-2\": {\n      \"name\": \"n/a\",\n      \"description\": \"modified control flow graph, where multiple control flow graphs of calling/callee functions are combined\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"statement\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow\",\n          \"details\": \"CFG is created based on statements\"\n        }\n      ],\n      \"vertex-features\": \"tokens (in the statement)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"ginn\": {\n      \"type\": {\n        \"name\": \"Graph Internal Neural Network (GINN)\",\n        \"architecture\": \"GINN has three basic operations:\\n1) Partitioning:\\n    Partition the graph into disjoint intervals,\\n    and perform message passing _but only between nodes in the same interval_\\n\\n    Nodes which are on their own in an interval are not updated \\n2) Heightening:\\n    Generate a next graph where each node represents an interval in the previous graph.\\n\\n    The embedding for each node is computed by aggregating node embeddings \\n    from the intervals in the old graph.\\n3) Lowering:\\n    Generate a lower-order graph from the heightened graph. (inverse operation)\\n\\n    Embeddings are computed based on the embeddings of the nodes in the \\n    higher order graph.\\n\\nGINN performs partitioning + heightening until the graph only contains \\na single interval in which partitioning is performed. Then, lowering + partitioning\\nis performed until the original graph is recovered.\"\n      }\n    },\n    \"variable-misuse-detection-model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Learnable Embedding Layer \\nGINN\\nSoftmax (2 vectors as output)\"\n      }\n    },\n    \"method-naming-model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Encoder:\\n  Learnable Embedding Layer \\n  GINN\\nDecoder:\\n  RNN w/ attention\"\n      }\n    },\n    \"null-pointer-dereference-detection-model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Learnable Embedding Layer \\nRNN to learn node embeddings \\nGINN\\nnode aggregation (exact method unclear) \\nFNN\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"variable-misuse-detection\": {\n      \"training-objective\": \"Given a program, determine 1) which variable usage is incorrect, and 2) which (existing) variable should be used\",\n      \"training-granularity\": \"pointer-like network for pointing to node\",\n      \"working-objective\": \"Given a program, determine 1) which variable usage is incorrect, and 2) which (existing) variable should be used\",\n      \"working-granularity\": \"pointer-like network for pointing to node\",\n      \"application\": \"Variable misuse prediction\",\n      \"supervision\": \"supervised\"\n    },\n    \"method-naming\": {\n      \"training-objective\": \"Given a method, generate a name\",\n      \"training-granularity\": \"graph to sequence\",\n      \"working-objective\": \"Given a method, generate a name\",\n      \"working-granularity\": \"graph to sequence\",\n      \"application\": \"Method naming\",\n      \"supervision\": \"supervised\"\n    },\n    \"null-pointer-dereference-detection\": {\n      \"training-objective\": \"determine if the given code sample (graph) has a null pointer dereference bug or not\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"determine if the given code sample (graph) has a null pointer dereference bug or not\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"null pointer dereference detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph-1\",\n      \"model\": \"ginn + variable-misuse-detection-model\",\n      \"task\": \"variable-misuse-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph-1\",\n      \"model\": \"ginn + method-naming-model\",\n      \"task\": \"method-naming\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph-2\",\n      \"model\": \"ginn + null-pointer-dereference-detection-model\",\n      \"task\": \"null-pointer-dereference-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 167,\n  \"pdf-id\": 219,\n  \"graphs\": {\n    \"augmented-ast\": {\n      \"name\": \"Augmented AST\",\n      \"description\": \"AST augmented with additional edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"method\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"Undirected\"\n        },\n        {\n          \"name\": \"Computed From\",\n          \"details\": \"Undirected\"\n        },\n        {\n          \"name\": \"Last Use\",\n          \"details\": \"Undirected\"\n        },\n        {\n          \"name\": \"Returns To\",\n          \"details\": \"Undirected; Node in return statement points to the return type declaration in a method\"\n        },\n        {\n          \"name\": \"Next Token Edge\",\n          \"details\": \"Undirected; Connect nodes on the same level in sequential order (perhaps not named to aptly)\"\n        }\n      ],\n      \"vertex-features\": \"Not specified\",\n      \"edge-features\": \"When I say undirected, I mean back-edges are added\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Summary generated thus far (in tokens) is also given as input\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Two parallel inputs (encoders)\\n  i) Code is tokenized using Byte Pair Encoding (generating sub-tokens),\\n      and passed through a transformer encoder \\n  ii) AST is input into a slightly modified GAT, which computed e_{ij} according to   \\n        e_{ij} = a^T LeakyReLU(W[h_i || h_j]), as opposed to e_{ij} = LeakyReLU(a^t[W h_i || W h_j])\\n2) Decoder (summary thus far as input)\\n  i) Embedding Layer\\n  ii) Enrich with positional encoding \\n  iii) Masked multi-head self-attention w/ residual connection and normalisation\\n  iv) Multi-head attention w/ residual connection and normalisation \\n    K: output of the token encoder\\n    V: output of graph encoder\\n    Q: output of the embedding layer \\n  v) FNN w/ residual connection and normalisation\\n  vi) Pointer Generator\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"training-granularity\": \"Graph + Sequence to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary.\\nDone token-by-token; previous tokens are also given as input\",\n      \"working-granularity\": \"Graph + Sequence to Sequence\",\n      \"application\": \"Code summarization (Generating comments for Python code)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"augmented-ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 30,\n  \"pdf-id\": 43,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"AST with some simplifications;\\n1) only function are kept\\n2) all functions are aggregated under a single root node\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Encoded using Embedding Layer\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Embedding Layer Alternating (child sum) Tree-LSTM network FNN layer\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"performance-prediction\": {\n      \"training-objective\": \"Given two graphs, determine which one corresponds to faster code\",\n      \"training-granularity\": \"Graph Classification (?)\",\n      \"working-objective\": \"Given two graphs, determine which one corresponds to faster code\",\n      \"working-granularity\": \"Graph Classification (?)\",\n      \"application\": \"Code Performance Prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"performance-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": [\n    \"Not 100% clear to me whether the tree network is trained separately or jointly (i.e. in the name network)\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 39,\n  \"pdf-id\": 57,\n  \"graphs\": {\n    \"dataflow-enriched-ast\": {\n      \"name\": \"Dataflow Enriched AST (AST+DF)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Nodes of types ImplicitCastExpr and DeclRefExpr are merged\\nwith their AST edge successor to reduce graph diameter.\\n\\nNodes are two-tuples (type, property), where\\nthe property is \\n1) data type (Function, FunctionArg, DeclStmt)\\n2) operator (Operator)\\n3) function name (CallExpr)\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"Edge from every usage of a variable to its definition\"\n        }\n      ],\n      \"vertex-features\": \"n/a (used embedding layer)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"cdfg-call-mem\": {\n      \"name\": \"CDFG + CALL + MEM\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"LLVM IR Instructions\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"MEM Edge\",\n          \"details\": \"Store/load dependencies\"\n        },\n        {\n          \"name\": \"CALL Edge\",\n          \"details\": \"Dependencies to return values of functions\"\n        }\n      ],\n      \"vertex-features\": \"n/a (used embedding layer)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gnn-ast\": {\n      \"type\": {\n        \"name\": \"GNN-AST\",\n        \"architecture\": \"Trainable Embedding Layer\\nGGNN Layers \\nLearnable MPL to map node embeddings to higher dimension\\nglobal attention sum pooling (weighted sum based on attention)\\nMPL for final output\"\n      }\n    },\n    \"gnn-cdfg\": {\n      \"type\": {\n        \"name\": \"GNN-CDFG\",\n        \"architecture\": \"Trainable Embedding Layer\\nGGNN Layers \\nLearnable MPL to map node embeddings to higher dimension\\nglobal attention sum pooling (weighted sum based on attention)\\nMPL for final output\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"cpu-gpu-mapping\": {\n      \"training-objective\": \"Given a graph, classify as cpu or gpu\",\n      \"training-granularity\": \"Binary Graph Classification\",\n      \"working-objective\": \"Given a graph, classify as cpu or gpu\",\n      \"working-granularity\": \"Binary Graph Classification\",\n      \"application\": \"Determine whether to run OpenCl kernel on CPU or GPU\",\n      \"supervision\": \"Supervised\"\n    },\n    \"thread-coarsening\": {\n      \"training-objective\": \"Determine thread coarsening factor from a set of options\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Determine thread coarsening factor from a set of options\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Determine thread coarsening factors\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"dataflow-enriched-ast\",\n      \"model\": \"gnn-ast\",\n      \"task\": \"cpu-gpu-mapping\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"dataflow-enriched-ast\",\n      \"model\": \"gnn-ast\",\n      \"task\": \"thread-coarsening\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cdfg-call-mem\",\n      \"model\": \"gnn-cdfg\",\n      \"task\": \"cpu-gpu-mapping\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cdfg-call-mem\",\n      \"model\": \"gnn-cdfg\",\n      \"task\": \"thread-coarsening\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 32,\n  \"pdf-id\": 36,\n  \"graphs\": {\n    \"token-graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": null\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Tokens\",\n          \"details\": \"Source code is tokenized. Every token has a node\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Edge\",\n          \"details\": \"There exists an edge between successive tokens.\\n\\nTODO: This is probably not right but I do not understand \\nwhat the authors mean by \\\"co-occurrence\\\"\"\n        }\n      ],\n      \"vertex-features\": \"Tokens are embedding using BERT\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gcn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN layers \\nUnspecified aggregation function\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify code as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify code as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"token-graph\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 82,\n  \"pdf-id\": 114,\n  \"graphs\": {\n    \"modified-code-property-graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Code Property Graph with an additional edge type\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"dangerous function calls are identified and program slicing is performed based on their parameters.\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Dependency Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"CAD (Control And Data) Edge\",\n          \"details\": \"When in the PDG, there would be both control and data dependency edges between two nodes.\"\n        }\n      ],\n      \"vertex-features\": \"Node content is encoded using word2vec\",\n      \"edge-features\": \"Edge type is encoded using an ordinal encoding\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Static taint analysis (path of input data) of source code;\\nstatements encountered are put in sequence and embedded using word2vec.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Two input paths:\\n1)\\n  (operating on taint analysis input)\\n  \\n  Bidirectional LSTM \\n  Attention Layer\\n  Dropout Layer \\n  FNN Layer \\n  Normalisation Layer \\n  Dropout Layer\\n  FNN Layer \\n  Attention Layer \\n\\n2)\\n  GGNN Layer \\n  Normalisation Layer\\n  Attention Layer\\n  Dropout Layer \\n  GGNN Layer \\n  Mean pooling of all node embeddings\\n\\nOutputs are concatenated \\n\\nThese high level features are passed to XGBoost\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable/not vulnerable\",\n      \"training-granularity\": \"Binary Classification (not of graphs)\",\n      \"working-objective\": \"Classify sample as vulnerable/not vulnerable\",\n      \"working-granularity\": \"Binary Classification (not of graphs)\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    },\n    \"vulnerability-classification\": {\n      \"training-objective\": \"Classify sample in a vulnerability category or as not vulnerable\",\n      \"training-granularity\": \"Multi-class Classification (not of graphs)\",\n      \"working-objective\": \"Classify sample in a vulnerability category or as not vulnerable\",\n      \"working-granularity\": \"Multi-class Classification (not of graphs)\",\n      \"application\": \"Vulnerability Detection and classification\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"modified-code-property-graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"modified-code-property-graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-classification\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 91,\n  \"pdf-id\": 126,\n  \"graphs\": {\n    \"ddg\": {\n      \"name\": \"Data Dependency Graph\",\n      \"description\": \"A cross method data dependency graph.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Methods\\n\\nSpecifically, for every method (core method),\\nwhich is either vulnerable or not vulnerable,\\na set of method _called by that method_\\n(directly or indirectly) are also\\ncollected in order to come up with the graph.\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Unclear\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Dependency Edge\",\n          \"details\": \"Data dependency edge as in PDG.\\n\\nThe graph is cross method, meaning calling relationships \\nare used to determine cross-method data dependencies.\"\n        }\n      ],\n      \"vertex-features\": \"Source code is normalised, and encoded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"r-gcn-att\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Every node embedding is passed through a convolutional layer \\nR-GCN (Relation GCN) layers \\nAttention Layer \\nR-GCN\\nSoftmax for normalising attention weights \\nWeighted sum using attention weights\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify method as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify method as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ddg\",\n      \"model\": \"r-gcn-att\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 142,\n  \"pdf-id\": 187,\n  \"graphs\": {\n    \"global-graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Graph describing and connecting multiple Python packages\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Packages\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Function\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Class field\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Class\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Module\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Class Method\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Non-indexed Symbol\",\n          \"details\": \"Not clearly explained\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Call\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Define/contain\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Type use\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Import\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Inherit\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"rgcn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Embedding Layer\\nRGCN\\nFor every node pair, concatenate embeddings\\nFNN\"\n      }\n    },\n    \"gat\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Embedding Layer\\nGAT\\nFor every node pair, concatenate embeddings \\nFNN\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"sce-name-prediction\": {\n      \"training-objective\": \"unclear how this works exactly\",\n      \"training-granularity\": \"Link Prediction\",\n      \"working-objective\": \"unclear how this works exactly\",\n      \"working-granularity\": \"Link Prediction\",\n      \"application\": \"Predict Names of Source Code Elements\",\n      \"supervision\": \"supervised\"\n    },\n    \"variable-prediction\": {\n      \"training-objective\": \"unclear how this works exactly\",\n      \"training-granularity\": \"Link Prediction\",\n      \"working-objective\": \"unclear how this works exactly\",\n      \"working-granularity\": \"Link Prediction\",\n      \"application\": \"Variable name prediction\",\n      \"supervision\": \"supervised\"\n    },\n    \"next-function-prediction\": {\n      \"training-objective\": \"unclear how this works exactly\",\n      \"training-granularity\": \"Link Prediction\",\n      \"working-objective\": \"unclear how this works exactly\",\n      \"working-granularity\": \"Link Prediction\",\n      \"application\": \"Predicting Next function to be called [after current function]\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"global-graph\",\n      \"model\": \"rgcn\",\n      \"task\": \"sce-name-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"global-graph\",\n      \"model\": \"rgcn\",\n      \"task\": \"variable-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"global-graph\",\n      \"model\": \"rgcn\",\n      \"task\": \"next-function-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"global-graph\",\n      \"model\": \"gat\",\n      \"task\": \"sce-name-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"global-graph\",\n      \"model\": \"gat\",\n      \"task\": \"variable-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"global-graph\",\n      \"model\": \"gat\",\n      \"task\": \"next-function-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 113,\n  \"pdf-id\": 152,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Child Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Next Token Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Computed From Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Last Use Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Guarded By Negation Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Guarded By Edge\",\n          \"details\": \"e.g. Edge to surrounding if statement\"\n        },\n        {\n          \"name\": \"Jump Edge\",\n          \"details\": \"e.g. from if to else\"\n        }\n      ],\n      \"vertex-features\": \"Normalise names.\\nNode type and tokens encoded using word2vec\\n(return) type of variables, functions, constants encoded using word2vec\\ntype and type/payload embeddings concatenated.\",\n      \"edge-features\": null,\n      \"connectivity-features\": \"Adjacency matrices (one for each edge type; 9 in total)\",\n      \"graph-features\": null,\n      \"other-features\": null\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Initial embeddings through FNN\\n2) _within_ graph message aggregation as in GGNN\\n3) _between_ graph message aggregation based on GGNN principles. Specifically\\n    1) each node receives incoming message which are the sum of all incoming \\n        messages in _all_ graphs.\\n    2) Layer-wise highway gating\\n      T(h_v^t) = \\\\sigma(h_v^t W_T^t + b_T^t)\\n      h'_v^{t + 1} = T(h_v^t) \\\\cdot h_v^{t+1} + (1 - T(h_v^t)) \\\\cdot h_v^t (w/ \\\\cdot elementwise)\\n4) Readout\\n  Concatenate the graph embedding from every aggregation iteration (including initial features)\\n  Where the graph embedding for a single aggregation is the sum over all graphs over \\n  the some unspecified pooling operation over all nodes in the graph\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    },\n    \"vulnerability-classification\": {\n      \"training-objective\": \"Predict the type of a vulnerability\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Predict the type of a vulnerability\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Classification (to reduce checking for developers to specific types)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-classification\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 187,\n  \"pdf-id\": 248,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"BERT for embedding nodes\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Sequence input is given. Per task this is:\\n  1) Comment and code for comment classification\\n  2) code and author for author attribution \\n  3) 2x code for duplicate function detection\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Sequence Encoder \\n  i) Bidirectional Transformer \\n  ii) Attention mechanism, weighted sum of token embeddings \\n2) AST Encoder \\n  i) Tree-LSTM\\n  ii) Attention mechanism, weighted usm of node embeddings \\n  iii) For duplicate function detection, there are two AST embeddings, \\n        which are combined through concatenation in an FNN layer\\n3) Concatenate vectors\\n4) Task-specific output layer\\n  i) Comment Classification: Fnn w/ softmax \\n  ii) Author Attribution: MLP w/ Softmax \\n  iii) Function Clone Detection: Linear Layer (similarity score)\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"comment-classification\": {\n      \"training-objective\": \"Given a pair of code and comment, determine whether the comment is reliable (for the given code)\",\n      \"training-granularity\": \"Graph Classification but not quite\",\n      \"working-objective\": \"Given a pair of code and comment, determine whether the comment is reliable (for the given code)\",\n      \"working-granularity\": \"Graph Classification but not quite\",\n      \"application\": \"Model pre-training\",\n      \"supervision\": \"Supervised\"\n    },\n    \"author-attribution\": {\n      \"training-objective\": \"Given a pair of code and author, determine whether the author wrote the code\",\n      \"training-granularity\": \"Graph Classification but not quite\",\n      \"working-objective\": \"Given a pair of code and author, determine whether the author wrote the code\",\n      \"working-granularity\": \"Graph Classification but not quite\",\n      \"application\": \"Model pre-training\",\n      \"supervision\": \"Supervised\"\n    },\n    \"duplicate-function-detection\": {\n      \"training-objective\": \"Given two functions, determine whether they are duplicates\",\n      \"training-granularity\": \"Graph Classification (but w/ multiple graphs)\",\n      \"working-objective\": \"Given two functions, determine whether they are duplicates\",\n      \"working-granularity\": \"Graph Classification (but w/ multiple graphs)\",\n      \"application\": \"Model pre-training\",\n      \"supervision\": \"Supervised\"\n    },\n    \"library-classification\": {\n      \"training-objective\": \"Given a code snippets, determine whether it uses OpenCV or Spring\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given a code snippets, determine whether it uses OpenCV or Spring\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Library Classification\",\n      \"supervision\": \"Supervised\"\n    },\n    \"algorithm-classification\": {\n      \"training-objective\": \"Classify code snippet into one of multiple categories\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify code snippet into one of multiple categories\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Algorithm Classification\",\n      \"supervision\": \"Supervised\"\n    },\n    \"bug-detection\": {\n      \"training-objective\": \"Given a code snippet, determine whether it is contains a bug\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Given a code snippet, determine whether it is contains a bug\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Bug Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"mode\",\n      \"task\": \"comment-classification + author-attribution + duplicate-function-detection + library-classification\",\n      \"comments\": \"Pre-trained on the first three tasks, fine-tuned/evaluated on the last one\"\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"mode\",\n      \"task\": \"comment-classification + author-attribution + duplicate-function-detection + algorithm-classification\",\n      \"comments\": \"Pre-trained on the first three tasks, fine-tuned/evaluated on the last one\"\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"mode\",\n      \"task\": \"comment-classification + author-attribution + duplicate-function-detection + bug-detection\",\n      \"comments\": \"Pre-trained on the first three tasks, fine-tuned/evaluated on the last one\"\n    }\n  ],\n  \"comments\": [\n    \"The method is supposed to be general, with fine-tuning on specific tasks\"\n  ]\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 169,\n  \"pdf-id\": 222,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"AST with data flow information\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"Data flow between leaf nodes\"\n        }\n      ],\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Adjacency Matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Code tokens are one-hot encoded (unclear how  this works)\"\n    }\n  },\n  \"models\": {\n    \"network\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"GCN\\nadd GCN w/ token input \\nTransformer encoder\\nTransformer decoder\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a piece of code, generate a summary\",\n      \"training-granularity\": \"x-to-sequence\",\n      \"working-objective\": \"Given a piece of code, generate a summary\",\n      \"working-granularity\": \"x-to-sequence\",\n      \"application\": \"code summarization\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"network\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 137,\n  \"pdf-id\": 180,\n  \"graphs\": {\n    \"ast-program\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Whole program\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"For terminal nodes:\\n  Node content (name, e.g. getMaxInt) and node type are both\\n  split up based on camel casing, resulting in two matrices.\\n\\nFor internal nodes, the mode typs is used as a feature (no splitting)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Short path (t, p, n): path p from terminal node t to internal node n with >= 2 children.\\nPath pair (t_s, p_s, t_e, p_e): Two short paths with same internal node \\nSpan of a path pair: Let c_k denote the k-th child of the shared internal node of the two\\n                      short paths. Suppose p_s leads through c_i and p_e leads through c_j.\\n                      Then the span of the path pair is defined as j - i\\nLength of a pair path: |p_s| + |p_e| + 1\\nNumber of shor paths is reduced by limiting length and span.\"\n    },\n    \"ast-method\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Method\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"For terminal nodes:\\n  Node content (name, e.g. getMaxInt) and node type are both\\n  split up based on camel casing, resulting in two matrices.\\n\\nFor internal nodes, the mode typs is used as a feature (no splitting)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Short path (t, p, n): path p from terminal node t to internal node n with >= 2 children.\\nPath pair (t_s, p_s, t_e, p_e): Two short paths with same internal node \\nSpan of a path pair: Let c_k denote the k-th child of the shared internal node of the two\\n                      short paths. Suppose p_s leads through c_i and p_e leads through c_j.\\n                      Then the span of the path pair is defined as j - i\\nLength of a pair path: |p_s| + |p_e| + 1\\nNumber of shor paths is reduced by limiting length and span.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Two separate inputs:\\n  i) Tokens (Terminal Nodes)\\n    Trainable Embedding Layer\\n    Encoded token t according to: CONCAT(BiLSTM(embedded type of t), BiLSTM(embedded name of t))\\n  ii) Paths\\n    Trainable Embedding Layer \\n    Each Path separately encoded using BiLSTM\\n2) Concat vectors\\n  c_i = \\\\tanh(W * concat(embed(t_s), embed(p_s), embed(t_e), embed(p_e)) + b)\\n3) Path-vectors are summed using attention:\\n  a_i = \\\\frac{\\\\exp(c_i^T a)}{\\\\sum_j \\\\exp(c_j^T a)}\\n  C = \\\\sum_i a_i c_i\\n4) Softmax\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"defect-prediction\": {\n      \"training-objective\": \"Classify sample as defect or not defect\",\n      \"training-granularity\": \"Graph Classification\",\n      \"working-objective\": \"Classify sample as defect or not defect\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Defect Prediction\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast-program\",\n      \"model\": \"model\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast-method\",\n      \"model\": \"model\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 173,\n  \"pdf-id\": 226,\n  \"graphs\": {\n    \"sg\": {\n      \"name\": \"Structure Graph (SG)\",\n      \"description\": \"Essentially an AST\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Nodes representing variables are replaced with the types of those variables\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Child Edge\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"AST Parent Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Encode tokens (either actual tokens or node type) using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"edfg\": {\n      \"name\": \"Execution Data Flow Graph\",\n      \"description\": \"Based on AST\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Nodes representing variables are replaced with the types of those variables\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Route Edge\",\n          \"details\": \"Denotes execution flow between nodes (incl. branching)\"\n        },\n        {\n          \"name\": \"Value Edge\",\n          \"details\": \"Connects nodes representing variables to nodes providing the values for those variables\"\n        }\n      ],\n      \"vertex-features\": \"Encode tokens (either actual tokens or node type) using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Not specified how edge embeddings are initialised\\n\\n1) SG is fed to T-GCN\\n    i) Nodes are enhanced with positional embedding base on sin/cos (Viswani et al.),\\n        where \\\"pos\\\" is the hierarchical position of the node; (pos, 2d) -> sin(pos / 10000^{2d/F}), \\n        (pos, 2d + 1) -> cos(pos/10000^{2d/F})\\n    ii) Positional encoding and word embedding are concatenated \\n    iii) GCN which also takes edge embeddings into account:\\n        h_{c,i}^{ell + 1} = sigma(b^{\\\\ell} + sum_{j \\\\in N(i)} \\\\frac{1}{c_{ij}}(h_{c,j}^{\\\\ell} + m_{c,ij})W_c^{\\\\ell})\\n        (where m is the edge embedding)\\n        c_{ij} = \\\\sqrt{|N_i|}\\\\sqrt{|N_j|}\\n2) EDFG is fed to E-GAT\\n    i) Like GAT, but aggregated edge embeddings too like in T-GCN\\n3) Fuse vectors per node using gating mechanism \\n4) Sum pooling\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-classification\": {\n      \"training-objective\": \"Classify code snippet into one of several categories\",\n      \"training-granularity\": \"Classification (of multiple graphs)\",\n      \"working-objective\": \"Classify code snippet into one of several categories\",\n      \"working-granularity\": \"Classification (of multiple graphs)\",\n      \"application\": \"Code Classification\",\n      \"supervision\": \"Supervised\"\n    },\n    \"code-clone-detection\": {\n      \"training-objective\": \"Given a pair of programs, output whether they implement the same functionality\",\n      \"training-granularity\": \"Classification (of multiple graphs)\",\n      \"working-objective\": \"Given a pair of programs, output whether they implement the same functionality\",\n      \"working-granularity\": \"Classification (of multiple graphs)\",\n      \"application\": \"(Functional) Code Clone Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"sg + edfg\",\n      \"model\": \"model\",\n      \"task\": \"code-classification + code-clone-detection\",\n      \"comments\": \"The paper presents a general framework, evaluated on the two downstream tasks.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 166,\n  \"pdf-id\": 218,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Embedding Layer for AST Nodes (unclear what exactly is encoded)\\n2) ConvGNN (H = g_v^{k - 1} + \\\\sum_{u \\\\in N(v)} g_u^{k - 1}; g_v^k = FNN(H))\\n3) Transformer-XL (to find important tokens in the graph)\\n4) Output of Transformer-XL is fed into linear layer, then softmax.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate a summary.\",\n      \"training-granularity\": \"Graph to Sequence\",\n      \"working-objective\": \"Given a code snippet, generate a summary.\",\n      \"working-granularity\": \"Graph to Sequence\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 158,\n  \"pdf-id\": 208,\n  \"graphs\": {\n    \"crg\": {\n      \"name\": \"Code Relationship Graph (CRG)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"Method\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"Tokens are decomposed into sub-tokens\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Child\",\n          \"details\": \"AST Edge\"\n        },\n        {\n          \"name\": \"Next Token\",\n          \"details\": \"NCS\"\n        },\n        {\n          \"name\": \"Last Use\",\n          \"details\": \"Connect variable to all possible last uses\"\n        },\n        {\n          \"name\": \"Computed From\",\n          \"details\": \"Connect expression node to all variables occurring in it\"\n        },\n        {\n          \"name\": \"Return To\",\n          \"details\": \"Connect return tokens to method declaration\"\n        },\n        {\n          \"name\": \"Subtoken Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Not explicitly specified what is encoded/used as features, but \\nfigures suggest node type for internal node, and content (tokens) for other nodes.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Token sequence is used as input.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Token input embedded using embedding layer, encoded using GRU\\n2) Graph encoder\\n  i) Nodes embedded using embedding layer\\n  ii) R-GCN\\n  iii) GGNN (to obtain time-series like behaviour, similar to GRU; not node type dependent messaging)\\n3) Select nodes containing nodes occurring in the token sequence to obtain equal length sequences \\n4) For every node, we have a sequence of hidden states. For every hidden state index j, pairwise join node and token sequences (h_j, h'_j) etc\\n5) Compute sequence of the pairwise joined sets as output \\n5) Decoder\\n  i) Attention \\n  ii) Pointer network\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"method-name-generation\": {\n      \"training-objective\": \"Given a method body, generate the target name for the method\",\n      \"training-granularity\": \"X-to-sequence\",\n      \"working-objective\": \"Given a method body, generate the target name for the method\",\n      \"working-granularity\": \"X-to-sequence\",\n      \"application\": \"method name generation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"crg\",\n      \"model\": \"model\",\n      \"task\": \"method-name-generation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 143,\n  \"pdf-id\": 190,\n  \"graphs\": {\n    \"augmented-ast\": {\n      \"name\": \"Augmented AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"Undirected\"\n        },\n        {\n          \"name\": \"Next Token Edge (NCS)\",\n          \"details\": \"Undirected\"\n        },\n        {\n          \"name\": \"Computed From\",\n          \"details\": \"Undirected\"\n        },\n        {\n          \"name\": \"Last Read\",\n          \"details\": \"Undirected; connect use of variable to all possible moments of last read\"\n        },\n        {\n          \"name\": \"Last Write\",\n          \"details\": \"Undirected; connect use of variable to all possible moments of last write\"\n        },\n        {\n          \"name\": \"Returns To\",\n          \"details\": \"Undirected; Node in return statement points to the return type declaration in a method\"\n        },\n        {\n          \"name\": \"Last Scope Use\",\n          \"details\": \"Undirected; point variable to previous use in the scope\"\n        },\n        {\n          \"name\": \"Last Field Lex\",\n          \"details\": \"Undirected; Connect field access to the last of use said field\"\n        },\n        {\n          \"name\": \"Field\",\n          \"details\": \"Undirected; point field access to the point the field was declared\"\n        }\n      ],\n      \"vertex-features\": \"node type is one-hot encoded\",\n      \"edge-features\": \"edge type is one-hot encoded\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"Global graph state is one-hot encoded (unclear what is)\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"Uses the basic concept of a \\\"Graph Network Block\\\",\\nwhich takes as input node embeddings V, edge embeddings E, and global vector u,\\nand updates these to obtain V', E', and u' according to:\\n  1) For each e_k \\\\in E: e'_k = \\\\phi^e(e_k, v_{source}, v_{target}, u)\\n  2) For each v_k \\\\in V: v'_k = \\\\phi^v(\\\\rho^{e \\\\rightarrow v}(E'_k), v_k, u)\\n      Where E'_k is the set of incoming edges of v_k\\n  3) V' = {v'_1, ..., v'_n}\\n  4) E' = {e'_1, ..., e'_m}\\n  5) u' = \\\\phi^u(\\\\rho^{e \\\\rightarrow u}(E'), \\\\rho^{v \\\\rightarrow u}(V'), u)\\n\\nThe paper does not further specify the six function \\\\phi^x, \\\\rho^x. \\n\\nEncoder-decoder setup:\\n\\nV'_0, E'_0, u'_0 = f_{enc}(V_0, E_0, u_0)\\n\\nNext, 10 recurrent units which operate according to:\\n  V_t, E_t, u_t = f_{dec}(V'_{t-1}, E'_{t-1}, u'_{t-1})\\n  V'_{t + 1},  E'_{t + 1}, u'_{t + 1} = f_{core}([V'_0, V'_t], [E'_0, E'_t], [u'_0, u'_t])\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"embedding\": {\n      \"training-objective\": \"Minimise reconstruction loss\",\n      \"training-granularity\": \"Graph Embedding\",\n      \"working-objective\": \"Embed graphs into latent space\",\n      \"working-granularity\": \"Graph Embedding\",\n      \"application\": \"Graph Embedding (goal -- cluster latent representations to classify programs in unsupervised manner)\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"augmented-ast\",\n      \"model\": \"model\",\n      \"task\": \"embedding\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 61,\n  \"pdf-id\": 88,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"User-defined names are normalised (e.g. METHOD1, VAR3)\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"directed\"\n        }\n      ],\n      \"vertex-features\": \"Node type is encoded on an ordinal scale,\\nwhere a type has a higher number if it occurs \\nmore frequently.\\nRarely occurring type are assigned the number 0.\\n\\nLexical content of nodes is encoded by taking \\nthe average of the word2vec values of the tokens in the node.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Stacked adjacency tensor.\\n\\nFor every graph, the adjacency matrix is determined.\\nThe four matrices are then combined into a third order tensor.\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"cfg\": {\n      \"name\": \"Control Flow Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"User-defined names are normalised (e.g. METHOD1, VAR3)\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Control Flow Edge\",\n          \"details\": \"Edge from statement to every statement that may be executed directly after it.\"\n        }\n      ],\n      \"vertex-features\": \"Node type is encoded on an ordinal scale,\\nwhere a type has a higher number if it occurs \\nmore frequently.\\nRarely occurring type are assigned the number 0.\\n\\nLexical content of nodes is encoded by taking \\nthe average of the word2vec values of the tokens in the node.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Stacked adjacency tensor.\\n\\nFor every graph, the adjacency matrix is determined.\\nThe four matrices are then combined into a third order tensor.\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"dfg\": {\n      \"name\": \"Data Flow Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"User-defined names are normalised (e.g. METHOD1, VAR3)\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"Edge from assignment to every use of that variable. \\n\\nNote; due to the use of if-statements, some uses may have \\nmultiple _incoming_ edges\"\n        }\n      ],\n      \"vertex-features\": \"Node type is encoded on an ordinal scale,\\nwhere a type has a higher number if it occurs \\nmore frequently.\\nRarely occurring type are assigned the number 0.\\n\\nLexical content of nodes is encoded by taking \\nthe average of the word2vec values of the tokens in the node.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Stacked adjacency tensor.\\n\\nFor every graph, the adjacency matrix is determined.\\nThe four matrices are then combined into a third order tensor.\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"ncs\": {\n      \"name\": \"Natural Code Sequence\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"User-defined names are normalised (e.g. METHOD1, VAR3)\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"Code Sequence Edge\",\n          \"details\": \"Edge from one AST leaf node to the next\"\n        }\n      ],\n      \"vertex-features\": \"Node type is encoded on an ordinal scale,\\nwhere a type has a higher number if it occurs \\nmore frequently.\\nRarely occurring type are assigned the number 0.\\n\\nLexical content of nodes is encoded by taking \\nthe average of the word2vec values of the tokens in the node.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Stacked adjacency tensor.\\n\\nFor every graph, the adjacency matrix is determined.\\nThe four matrices are then combined into a third order tensor.\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"circle-ggnn\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"CircleGGNN layers \\nInput output of GGNN layer concatenated with initial features into Conv1D (w/ ReLU) + MaxPooling layer\\nMLP \\n\\nCircleGGNN is a version of GGNN adapted for tensor inputs, \\nwhere messages are not only propagated in an intra-graph manner,\\nbut also in an inter-graph manner.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify samples as vulnerable/not vulnerable\",\n      \"training-granularity\": \"Graph Classification (multiple graphs per sample)\",\n      \"working-objective\": \"Classify samples as vulnerable/not vulnerable\",\n      \"working-granularity\": \"Graph Classification (multiple graphs per sample)\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + cfg + dfg + ncs\",\n      \"model\": \"circle-ggnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 118,\n  \"pdf-id\": 160,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"For each method in a commit, a PDG of both the old \\nand new version of that method is constructed.\\n\\nThe PDGs are sliced based on the nodes changed in \\nthe commit.\\n\\nAll graphs are represented as a sequence \\nL = (s, p_1, \\\\hdots, p_x, n_1, \\\\hdots, n_y, t_1, \\\\hdots, t_z)\\n\\ns is the sliced graph, p_i are control flow paths, n_i are statements,\\nand t_i are tokens.\\n\\n(Note: many of the edge types/relations boil down to: control and dependence edges)\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source Code\",\n          \"details\": \"Diff\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"Code Change Slice Node\",\n          \"details\": \"Represents the sliced graph\"\n        },\n        {\n          \"name\": \"Path\",\n          \"details\": \"Represents a control flow path in the sliced graph,\\nfrom the \\\"root\\\" node (method entry) to an exit point (i.e. return, throw, etc)\"\n        },\n        {\n          \"name\": \"Statement\",\n          \"details\": \"Statement in the source code\"\n        },\n        {\n          \"name\": \"Token\",\n          \"details\": \"Token in the source code\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"R1 - Control Flow Path\",\n          \"details\": \"Edge between code change slide node and path node\"\n        },\n        {\n          \"name\": \"R2 - Control Flow Path (2)\",\n          \"details\": \"Edge between control flow path and nodes contained in said path\"\n        },\n        {\n          \"name\": \"R3 - Changed node relation\",\n          \"details\": \"Denote a relation (data or dependency) between two changed nodes.\"\n        },\n        {\n          \"name\": \"R4 - Data Dependency\",\n          \"details\": \"Denote data dependency between two nodes which are members of \\nN_{change} \\\\cup N_{ctrl}, \\nwhere the first set is the set of changed nodes,\\nand the second is the set of nodes with a control dependency on \\nsome node in the set of changed nodes\"\n        },\n        {\n          \"name\": \"R5 - Data Dependency\",\n          \"details\": \"Denote data dependency between two nodes from N_{data},\\nWhere N_{data} is the set of nodes with a data dependency on \\nsome node in the set of changed nodes\"\n        },\n        {\n          \"name\": \"R6 - Control Dependency\",\n          \"details\": \"Denote control dependency between two nodes which are members of \\nN_{change} \\\\cup N_{data}, \\nwhere the first set is the set of changed nodes,\\nand the second is the set of nodes with a data dependency on \\nsome node in the set of changed nodes\"\n        },\n        {\n          \"name\": \"R7 - Control Dependency\",\n          \"details\": \"Denote control dependency between two nodes from N_{ctrl},\\nWhere N_{ctrl} is the set of nodes with a control dependency on \\nsome node in the set of changed nodes\"\n        },\n        {\n          \"name\": \"R8 - Token Edge\",\n          \"details\": \"Edge between statement and the nodes of tokens it contains\"\n        }\n      ],\n      \"vertex-features\": \"Token nodes are encoded using a word embedding.\\n\\nOther node types are encoded as zeros.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"i) First, we introduce the positional encoding PE of the input sequence L,\\n    which represents a graph B.\\n\\n    The positional encoding is defined for statement and token nodes, \\n    and is defined as follows:\\n  \\n    PE = [PE^1; PE^2; ...; PE^{|L|]\\n  \\n    where PE^i the positional encoding of the i-th statement or token node,\\n    defined as \\n\\n    PE^i = concat_{v \\\\in N(i)} r_{i,v}\\n\\n    Where r_{i,v} is a trainable parameter dependent on the relation\\n    between i and v (different parameters for R3, R4/R5, R6/R7, R8)\\n\\nii) We introduce the transformer layer leveraged by the model:\\n    \\n    G^n = Normalise(GSA(B, H^{n-1}) + H^{n-1})\\n    H^n = Normalise(FNN(G^n) + G^n)\\n\\n    Where GSA is a multihead graph self-attention mechanism defined as:\\n\\n    A^{n - 1} = [A_1^{n - 1}; A_2^{n - 1}; ...; A_{|L|}^{n - 1}]\\n    A_i^{n - 1} = \\\\concat_{v \\\\in N(i)} h_v^{n - 1}}\\n    Q_i = H^{n - 1}W_i^Q \\n    K_i = A^{n - 1}W_i^K\\n    V_i = A^{n - 1}W_i^V\\n    head_i = softmax(\\\\frac{Q_i(K_i + PE)^T}{\\\\sqrt{d_k}} + M)V_i\\n    GSA(B, H^{n - 1}) = [head_1, head_2, ..., head_{a}]W_n^O \\n\\n    Note that A_i^{n - 1} is also an output of the transformer \\n    layer, and is used in the next layer.\\n\\n    M is a masking matrix, with m_{ij} = 0 if there is an edge between\\n    nodes i and j, and $m_{ij} = -\\\\infty$ otherwise.\\n\\niii) Actual model:\\n    H^0 = Initial Features + PE\\n\\n    Then, encoder-decoder architecture with multiple transformer layers\\n    as outlined above.\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"node-reconstruction\": {\n      \"training-objective\": \"Given the context, predict the embedding of a masked node\",\n      \"training-granularity\": \"Node Regression/Node Embedding\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Pretraining, for later fine-tuning on downstream tasks\",\n      \"supervision\": \"Self-supervised\"\n    },\n    \"edge-reconstruction\": {\n      \"training-objective\": \"Predict masked links (compute product of sigmoid of node embeddings)\",\n      \"training-granularity\": \"Link prediction\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Pretraining, for later fine-tuning on downstream tasks\",\n      \"supervision\": \"Self-supervised\"\n    },\n    \"code-change-translation\": {\n      \"training-objective\": \"Given the sequence L_o of an old snippet, construct the sequence L_n of the new snippet\",\n      \"training-granularity\": \"Code change translation\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Pretraining, for later fine-tuning on downstream tasks\",\n      \"supervision\": \"(Self)-supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"node-reconstruction + edge-reconstruction + code-change-translation\",\n      \"comments\": \"Overall goal -- learning representations for code changes; similar to what BERT is for natural language\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 189,\n  \"pdf-id\": 252,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"Code Semantic Representation Graph (CSRG)\",\n      \"description\": \"AST with data flow information\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code with docstring\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": [\n        {\n          \"name\": \"AST Node\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"edge-type\": [\n        {\n          \"name\": \"AST Edge\",\n          \"details\": \"Directed edges are added between leaf nodes \\\"to determine branch statements in the AST\\\" (NOT NCS)\"\n        },\n        {\n          \"name\": \"Data Flow Edge\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-features\": \"Node representations computed using DeepWalk\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Code and summary/query are tokenised and put into a sequence,\\nand tokenised using FastText\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"type\": {\n        \"name\": \"n/a\",\n        \"architecture\": \"1) Code Sequence Encoder\\n  i) Bidirectional LSTM\\n2) Graph Encoder\\n  i) GAT\\n  ii) Average Pooling \\n3) Summary/Query Sequence and Code Sequence are passed through a \\n    self- and cross-attention block (h_doc, h_tok)\\n4) Self-attention to obtain two output vectors:\\n    [a_tok * h_tok, a_graph * h_graph]\\n    [a_lstm * h_lstm, a_doc * h_doc]\"\n      }\n    }\n  },\n  \"tasks\": {\n    \"code-search\": {\n      \"training-objective\": \"Minimise similarity of unrelated (code, summary) pairs, maximise similarity of related pairs\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Embed code and query for similarity based code search\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code Search\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"code-search\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 242,\n  \"pdf-id\": 337,\n  \"graphs\": {\n    \"class-diagram\": {\n      \"name\": \"class dependency network\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"classes\",\n      \"edge-type\": \"dependencies\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"cluster\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\",\n        \"similarity based; aggregate similar classes into modules\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"modularization\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Cluster classes into modules\",\n      \"working-granularity\": \"graph clustering\",\n      \"application\": \"Software modularisation\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster\",\n      \"task\": \"modularization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "cluster$node"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 214,\n  \"pdf-id\": 284,\n  \"graphs\": {\n    \"asg\": {\n      \"name\": \"Abstract Semantic Graph\",\n      \"description\": \"Graph with Control and Data Flow Information\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"Smart Contracts\"\n        }\n      ],\n      \"vertex-type\": \"statement\",\n      \"edge-type\": \"control flow/data flow\",\n      \"vertex-features\": \"not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gnn\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"ggnn\",\n        \"readout through mlp weighted sum\"\n      ]\n    },\n    \"gmn\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"graph matching network (ggnn-based)\",\n        \"readout through mlp weighted sum\",\n        \"compute similarity of graphs\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection-1\": {\n      \"training-objective\": \"classify graph as vulnerable or not vulnerable\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"classify graph as vulnerable or not vulnerable\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"vulnerability detection\",\n      \"supervision\": \"supervised\"\n    },\n    \"vulnerability-detection-2\": {\n      \"training-objective\": \"compute similarity between graphs (unclear what exact objective is)\",\n      \"training-granularity\": \"graph classification (multiple graphs)\",\n      \"working-objective\": \"compute similarity between graphs  (compute similarity to known vulnerable graphs)\",\n      \"working-granularity\": \"graph classification (multiple graphs)\",\n      \"application\": \"vulnerability detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"asg\",\n      \"model\": \"gnn\",\n      \"task\": \"vulnerability-detection-1\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"asg\",\n      \"model\": \"gmn\",\n      \"task\": \"vulnerability-detection-2\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 258,\n  \"pdf-id\": 249,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code (function/method)\",\n          \"details\": \"first compiled to LLVM IR\"\n        }\n      ],\n      \"vertex-type\": \"identifiers in the instructions (some trimmed)\",\n      \"edge-type\": \"control dependence/flow and data dependence/flow\",\n      \"vertex-features\": \"identifiers in the instructions (one hot)\",\n      \"edge-features\": \"edge type\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"code summary/query\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"ggnn (edge type aware)\",\n        \"pooling through soft-attention (\\\\sigma(f(h_i) \\\\cdot a)) weighted sum\",\n        \"summary into embedding layer w/ LSTM w/ attention-weighted sum of hidden states\",\n        \"cosine similarity\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-search\": {\n      \"training-objective\": \"Maximise similarity between related (code, summary) pairs, minimise similarity between unrelated (code, summary) pairs\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given query, find most similar code snippets through similarity\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code search\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"code-search\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 231,\n  \"pdf-id\": 323,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast w/ subtokens\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"content CodeBERT\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"sdg\": {\n      \"name\": \"sdg (system dependence graph)\",\n      \"description\": \"derived from a set of pdgs\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"statement\",\n      \"edge-type\": \"control dependence (data dependence not used)\",\n      \"vertex-features\": \"for each statement, max-pool over embeddings of all nodes in corresponding ast subtree\",\n      \"edges\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"edge type represented using edge-decomposition as in r-gcn\",\n        \"edge-type aware generic message passing scheme; h_v = f(\\\\sum_{(u, r) \\\\in N(v)} W_type(r)\\\\phi(x_u, z_r)) (u - node; r - edge)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"classify statement as vulnerable or non-vulnerable\",\n      \"training-granularity\": \"node classification\",\n      \"working-objective\": \"classify statement as vulnerable or non-vulnerable\",\n      \"working-granularity\": \"node classification\",\n      \"application\": \"statement-level memory vulnerability detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + sdg\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 244,\n  \"pdf-id\": 339,\n  \"graphs\": {\n    \"delta-pdg\": {\n      \"name\": \"\\\\delta-ndg\",\n      \"description\": \"start with two separate graphs, merge based on unchanged nodes\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"commit\"\n        }\n      ],\n      \"vertex-type\": \"statement\",\n      \"edge-type\": \"control dependence/data dependence/name flow\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"cluster\": {\n      \"name\": \"Agglomerative Clustering\",\n      \"architecture-attributes\": [\n        \"agglomerative clustering w/ Weisfeiler-Lehman kernel for similarity\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"commit-untangling\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Cluster graph into separate commits\",\n      \"working-granularity\": \"Graph Clustering\",\n      \"application\": \"Untangling (decomposing) composite commits\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"\\\\delta-ndg\",\n      \"model\": \"cluster\",\n      \"task\": \"commit-untangling\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "cluster$node"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 221,\n  \"pdf-id\": 295,\n  \"graphs\": {\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"php\"\n        }\n      ],\n      \"vertex-type\": \"basic block\",\n      \"edge-type\": \"control flow\",\n      \"vertex-features\": \"vector of counts of occurrences of certain ast node types in the ast sub-tree of the basic block\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"gcn\",\n        \"MinCutPool\",\n        \"no clear readout specified (aside MinCutPool)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"malware-detection\": {\n      \"training-objective\": \"Classify graph as malicious or benign\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Classify graphs as malicious or benign\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"Malicious webshell detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"model\",\n      \"task\": \"malware detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 267,\n  \"pdf-id\": 289,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"smart contracts\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Depth first traversal to generate:\\n1) node type sequence \\n2) node value sequence\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": {\n        \"architecture-attributes\": [\n          \"embedding layer\",\n          \"add the two sequences\",\n          \"transformer encoder\",\n          \"cnn (multiple in parallel) w/ max-pooling and mlp over transformer output\",\n          \"local (node) discriminator; take Transformer encoder output and apply MLP\",\n          \"global (graph) discriminator; cnn module output and apply mlp\",\n          \"decoder; cnn module output with mlp\"\n        ]\n      }\n    }\n  },\n  \"tasks\": {\n    \"real-fake\": {\n      \"training-objective\": \"Given a smart contract, determine whether is was syntactically changed or not\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Pre-training of model\",\n      \"supervision\": \"supervised (self-supervised)\"\n    },\n    \"token-real-fake\": {\n      \"training-objective\": \"Given a smart contract, determine which node were changed (replaced)\",\n      \"training-granularity\": \"node classification\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Pre-training of model\",\n      \"supervision\": \"supervised (self-supervised)\"\n    },\n    \"value-sequence-recovery\": {\n      \"training-objective\": \"Given a smart contract, recover the value sequence\",\n      \"training-granularity\": \"sequence to sequence\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Pre-training of model\",\n      \"supervision\": \"supervised (self-supervised)\"\n    },\n    \"bug-detection\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"embed code snippets for similarity comparison\",\n      \"working-granularity\": \"graph embedding\",\n      \"application\": \"Bug detection through comparing code snippet embeddings with known bugs\",\n      \"supervision\": \"n/a\"\n    },\n    \"code-clone-detection\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"embed code snippets for similarity comparison\",\n      \"working-granularity\": \"graph embedding\",\n      \"application\": \"clone detection through comparing code snippet embeddings with known bugs\",\n      \"supervision\": \"n/a\"\n    },\n    \"code-clustering\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"embed code snippets for clustering\",\n      \"working-granularity\": \"graph embedding\",\n      \"application\": \"clone clustering\",\n      \"supervision\": \"n/a\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"real-fake + token-real-fake + value-sequence-recovery + bug-detection + code-clone-detection + code-clustering\",\n      \"comments\": \"The model is first trained on the embedding task, and can then be used for downstream tasks.\\nThe other three were used by the authors for testing the approach.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 229,\n  \"pdf-id\": 315,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"javascript\"\n        }\n      ],\n      \"vertex-type\": \"ast node\",\n      \"edge-type\": \"ast edge\",\n      \"vertex-features\": \"unclear (not specified)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": null,\n      \"architecture-attributes\": [\n        \"gcn\",\n        \"self attention (unclear how exactly)\",\n        \"graph pooling (not clearly specified) (is also final readout)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"malicious-js-detection\": {\n      \"training-objective\": \"classify graph as malicious or benign\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"classify graph as malicious or benign\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"malicious javascript detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"malicious-js-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 266,\n  \"pdf-id\": 257,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"method\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"nodes put into sequence using breath first search\\n\\nmethod name (split up into sequence) is used as feature \\n\\nsequence of APIs used in the method is used as feature\\n\\nbag of tokens used in the snippets is used as feature \\n\\ncode summary/query is used as feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"embedding layers for all features\",\n        \"for every sequence (ast, method name, apis, tokens, summary/query), apply soft-attention (mlp based) to every element (separately)\",\n        \"fuse features (ast, method name, apis, tokens) through concatenation\",\n        \"multiply fused matrix and summary/query matrix\",\n        \"perform cnn and use max pooling/softmax to compute attention scores; multiple with pre-matrix multiplication features (i.e. fused feature matrix and summary matrix)\",\n        \"cosine similarity with summary embedding\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-search\": {\n      \"training-objective\": \"Maximise similarity between related (code, summary) pairs, minimise similarity between unrelated (code, summary) pairs\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"compute code snippet <-> query similarity\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code search\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-search\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 234,\n  \"pdf-id\": 327,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"ast with data flow\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/data flow/ncs\",\n      \"vertex-features\": \"not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model-encoder\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"parallel network; graph pipeline and raw code pipeline\",\n        \"raw code into pre-trained code model (encoder only)\",\n        \"graph into graph attention layers\",\n        \"output of graph unit injected into encoder layers\",\n        \"only weights in graph part are fine-tuned\"\n      ]\n    },\n    \"model-encoder-decoder\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"parallel network; graph pipeline and raw code pipeline\",\n        \"raw code into pre-trained code model (encoder/decoder)\",\n        \"graph into graph attention layers\",\n        \"output of graph unit incorporated into encoder, decoder, and cross-attention layers\",\n        \"only weights in graph part are fine-tuned\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"for a given piece of code, generate a summary\",\n      \"training-granularity\": \"(graph + code) to sequence\",\n      \"working-objective\": \"for a given piece of code, generate a summary\",\n      \"working-granularity\": \"(graph + code) to sequence\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"supervised\"\n    },\n    \"code-generation\": {\n      \"training-objective\": \"not specified\",\n      \"training-granularity\": \"code to sequence\",\n      \"working-objective\": \"not specified\",\n      \"working-granularity\": \"code to sequence\",\n      \"application\": \"Code generation\",\n      \"supervision\": \"supervised\"\n    },\n    \"code-translation\": {\n      \"training-objective\": \"translate code from one language to another\",\n      \"training-granularity\": \"code to sequence\",\n      \"working-objective\": \"translate code from one language to another\",\n      \"working-granularity\": \"code to sequence\",\n      \"application\": \"Code translation\",\n      \"supervision\": \"supervised\"\n    },\n    \"code-refinement\": {\n      \"training-objective\": \"fix buggy code\",\n      \"training-granularity\": \"code to sequence\",\n      \"working-objective\": \"fix buggy code\",\n      \"working-granularity\": \"code to sequence\",\n      \"application\": \"Code refinement\",\n      \"supervision\": \"supervised\"\n    },\n    \"clone-detection\": {\n      \"training-objective\": \"given two code samples, determine whether they are semantic clones\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"given two code samples, determine whether they are semantic clones\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Clone detection\",\n      \"supervision\": \"supervised\"\n    },\n    \"defect-detection\": {\n      \"training-objective\": \"given a piece of code, determine whether it contains a defect\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"given a piece of code, determine whether it contains a defect\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"Defect detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model-encoder + model-encoder-decoder\",\n      \"task\": \"code-summarization + code-generation + code-translation + code-refinement + clone-detection + defect-detection\",\n      \"comments\": \"The framework is meant to be a general fine-tuning strategy; \\nthe tasks are merely example tasks.\\nIt is not clearly specified which model/task combinations were experimented with\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 237,\n  \"pdf-id\": 332,\n  \"graphs\": {\n    \"change-impact-graph\": {\n      \"name\": \"Change Impact Graph\",\n      \"description\": \"create full graphs (according to vertex/edge types) of old and new code; slice based on changed lines; two input graphs/commit\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"diff\"\n        }\n      ],\n      \"vertex-type\": \"variables/statements/method/classes/package (entities at different levels)\",\n      \"edge-type\": \"data dependence/control dependence/program relations (package member, overwrite, implement, inherit, initialize, data member, param in, param out, etc)\",\n      \"vertex-features\": \"node2vec + one hot node type\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"syntax change type (extracted using ChangeDistiller) is also given as input (encoding unclear)\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"gcn\",\n        \"SortPooling for readout\",\n        \"fusion of graph and syntax change features\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"commit-classification\": {\n      \"training-objective\": \"classify graph (commit) into one of multiple categories\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"classify graph (commit) into one of multiple categories\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"Commit classification (refine ChangeDistiller output)\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"change-impact-graph\",\n      \"model\": \"model\",\n      \"task\": \"commit-classification\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 232,\n  \"pdf-id\": 324,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"tokens (unique) w/ co-occurrence sliding window\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"unique code tokens\",\n      \"edge-type\": \"co-occurrence in sliding window\",\n      \"vertex-features\": \"token CodeBERT / GraphCodeBERT (two different methods proposed)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"gcn w/ residual connections\",\n        \"ggnn (not edge type aware)\",\n        \"soft (mlp-based) self-attention per node\",\n        \"weighted (linear combination) of sum pooling and max pooling\",\n        \"self-attention to graph representation\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"classify graph as vulnerable or not vulnerable\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"classify graph as vulnerable or not vulnerable\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"vulnerability detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 251,\n  \"pdf-id\": 352,\n  \"graphs\": {\n    \"ext-dependency-graph\": {\n      \"name\": \"Extended Component Dependency Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"component\",\n      \"edge-type\": \"logic dependency (composition, delegation etc)/co-evolution [all edges have back edges]\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"edges are weighted\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"clustering\": {\n      \"name\": \"Bunch Graph Clustering\",\n      \"architecture-attributes\": [\n        \"bunch graph clustering algorithm\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"refactoring\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"cluster components into low coupling / high cohesion subgraphs\",\n      \"working-granularity\": \"graph clustering (into subgraphs)\",\n      \"application\": \"software architecture refactoring\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ext-dependency-graph\",\n      \"model\": \"clustering\",\n      \"task\": \"refactoring\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "clustering$node"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 260,\n  \"pdf-id\": 273,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"first compiled to IR\"\n        }\n      ],\n      \"vertex-type\": \"operands/opcode/labels in IR\",\n      \"edge-type\": \"control dependency (or flow; not clearly specified)/data dependency\",\n      \"vertex-features\": \"both exact feature and encoding unclear\",\n      \"edge-features\": \"edge have a weight\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"graph matching network (w/ attention) (aggregation per graph using mlp-based soft-attention weighted sum)\",\n        \"cosine similarity\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"clone-detection\": {\n      \"training-objective\": \"Given two graphs, determine whether they are semantic clones\",\n      \"training-granularity\": \"graph classification (but with two graphs)\",\n      \"working-objective\": \"Given two graphs, determine whether they are semantic clones\",\n      \"working-granularity\": \"graph classification (but with two graphs)\",\n      \"application\": \"code clone detection (cross language)\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 219,\n  \"pdf-id\": 293,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"AST split into subtrees for statements (specific vulnerability related statement types)\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"powershell\"\n        }\n      ],\n      \"vertex-type\": \"AST node\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"word2vec of node content\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": null,\n      \"architecture-attributes\": [\n        \"ast embeddings aggregated in bottom-up fashion using child-sum (W h_n + b_n + \\\\sum_j h_j)\",\n        \"max pool over subtree\",\n        \"bidirectional gru over sequence of sub-tree (statement) embeddings\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"malicious-script-detection\": {\n      \"training-objective\": \"classify sample as malicious or benign\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"classify sample as malicious or benign\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"Malicious Powershell Script Detection (from obfuscated code)\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"malicious-script-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 247,\n  \"pdf-id\": 343,\n  \"graphs\": {\n    \"object-usage-graph\": {\n      \"name\": \"Object Usage Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"action (API invocation; e.g java.lang.String.new) or control (eg. while)\",\n      \"edge-type\": \"(temporal) usage order/data dependency\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"cluster\": {\n      \"name\": \"Spectral Clustering\",\n      \"architecture-attributes\": [\n        \"spectral-clustering w/ shortest path kernel for similarity\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"usage-example-mining\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Cluster similar graphs together\",\n      \"working-granularity\": \"graph clustering\",\n      \"application\": \"Mining API usage examples\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"object-usage-graph\",\n      \"model\": \"cluster\",\n      \"task\": \"usage-example-mining\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "cluster$graph"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 235,\n  \"pdf-id\": 328,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"function -- python\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node type one-hot\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"siamese network\",\n        \"gcn\",\n        \"node-wise similarity matrix score through softmax\",\n        \"further augmented/weighted through mlp w/ tensor operations for added (global) interaction information\",\n        \"final output by summing over one dimension and taking max over the other\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-similarity\": {\n      \"training-objective\": \"compute semantic similarity score for two code snippets\",\n      \"training-granularity\": \"graph regression (two inputs)\",\n      \"working-objective\": \"compute semantic similarity score for two code snippets\",\n      \"working-granularity\": \"graph regression (two inputs)\",\n      \"application\": \"Code Similarity Detection (for vulnerable code clone detection)\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-similarity\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 220,\n  \"pdf-id\": 294,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"javascript\"\n        }\n      ],\n      \"vertex-type\": \"ast node (trimmed)\",\n      \"edge-type\": \"ast edge\",\n      \"vertex-features\": \"node type one-hot\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified (presumably adjacency matrix)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"gcn\",\n        \"graph pooling (reduce amount of nodes by half each time)\",\n        \"average pooling for final readout\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"malicious-js-detection\": {\n      \"training-objective\": \"Classify sample as malicious or benign\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Classify sample as malicious or benign\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"Malicious Javascript Detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"malicious-js-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 241,\n  \"pdf-id\": 336,\n  \"graphs\": {\n    \"class-diagram\": {\n      \"name\": \"class dependency network\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"classes\",\n      \"edge-type\": \"dependencies\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"cluster-1\": {\n      \"name\": \"Label Propagation\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-2\": {\n      \"name\": \"Louvain Algorithm\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-3\": {\n      \"name\": \"Leiden Algorithm\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-4\": {\n      \"name\": \"Speaker-Listener Label Propagation\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-5\": {\n      \"name\": \"Leading Eigenvector Algorithm\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-6\": {\n      \"name\": \"Girvan-Newman algorithm\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-7\": {\n      \"name\": \"Markov clustering\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-8\": {\n      \"name\": \"Rber pots algoritmh\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-9\": {\n      \"name\": \"Rb pots algoritmh\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-10\": {\n      \"name\": \"Walktrap\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    },\n    \"cluster-11\": {\n      \"name\": \"Chinesewhispers\",\n      \"architecture-attributes\": [\n        \"graph clustering algorithm\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"microservice-identification\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Cluster graph into candidate microservices\",\n      \"working-granularity\": \"Graph Clustering\",\n      \"application\": \"Microservice decomposition\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-1\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-2\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-3\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-4\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-5\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-6\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-7\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-8\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-9\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-10\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-diagram\",\n      \"model\": \"cluster-11\",\n      \"task\": \"microservice-identification\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "cluster-1$node@cluster-4$node@cluster-11$node@cluster-9$node@cluster-3$node@cluster-7$node@cluster-8$node@cluster-2$node@cluster-5$node@cluster-6$node@cluster-10$node"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 238,\n  \"pdf-id\": 333,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"commit graph\",\n      \"description\": \"separate graphs are created for old and new code, which are then merged based on common nodes.\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"commit\"\n        }\n      ],\n      \"vertex-type\": \"statements\",\n      \"edge-type\": \"control flow/data flow/name flow [data flow considering variable names]/sub-token co-occurrence\",\n      \"vertex-features\": \"node value BERT\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified, presumable adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Graph convolution _operator_ (!not network!) (k-th order GCN; X' = (I - 0.5*L)^k X, with L the graph Laplacian)\",\n        \"affinity propagation clustering (similarity = euclidean distance)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"commit-untangling\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Cluster graph into separate commits\",\n      \"working-granularity\": \"Graph Clustering\",\n      \"application\": \"Untangling (decomposing) composite commits\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": null,\n      \"model\": null,\n      \"task\": null,\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "model$node"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 257,\n  \"pdf-id\": 184,\n  \"graphs\": {\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"first compiled to bytecode\"\n        }\n      ],\n      \"vertex-type\": \"instruction\",\n      \"edge-type\": \"control flow (incl. function calls)\",\n      \"vertex-features\": \"things like instruction name and operands\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified / n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"embedding layers\",\n        \"Directed graph convolutional neural network (\\\"circular\\\" 1-hop window over graph; for each, sum its and its neighbours embeddings after passing them through linear layer)\",\n        \"max pooling\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"defect-prediction\": {\n      \"training-objective\": \"Classify graph (program) into; correct, runtime exceeded, wrong answer, runtime error\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Classify graph (program) into; correct, runtime exceeded, wrong answer, runtime error\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"Defect Prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"model\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 259,\n  \"pdf-id\": 251,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"first compiled to IR\"\n        }\n      ],\n      \"vertex-type\": \"operands/opcode/labels in IR\",\n      \"edge-type\": \"control dependency/data dependency/oop related links (e.g. link method to object instance)\",\n      \"vertex-features\": \"variables in ir instruction (one hot)\",\n      \"edge-features\": \"edge type\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"code summary/query\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"ggnn (edge type aware)\",\n        \"pooling through soft-attention (\\\\sigma(f(h_i) \\\\cdot a)) weighted sum\",\n        \"summary into embedding layer w/ LSTM w/ attention-weighted sum of hidden states\",\n        \"cosine similarity\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-search\": {\n      \"training-objective\": \"Maximise similarity between related (code, summary) pairs, minimise similarity between unrelated (code, summary) pairs\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given query, find most similar code snippets through similarity\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code search (Cross language)\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"code-search\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 215,\n  \"pdf-id\": 285,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"mix of AST, CFG, PDG\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"smart contract\"\n        }\n      ],\n      \"vertex-type\": \"AST Node (slicing applied)\",\n      \"edge-type\": \"ast/control flow/data dependence/control dependence\",\n      \"vertex-features\": \"tokens encoded using fasttext\",\n      \"edge-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"hierarchical GGNN w/ top-k pooling for subgraph mining and obtaining subgraph embedding per subgraph (H-SAGPool)\",\n        \"global (pre-sagpool) readout w/ softmax-weighted node sum (global attention pooling)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"classify graph as vulnerable or not vulnerable\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"classify graph as vulnerable or not vulnerable\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"vulnerability detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": null,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"csg\": {\n      \"name\": \"code structure graph (csg)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/data dependence/control dependence/control flow/ncs\",\n      \"vertex-features\": \"word2vec (unclear what)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"32 different meta-paths are used (expression, statement, symbol level)\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"node and edge based attention, used to compute meta-path attention\",\n        \"message passing, with messages weighted according to the meta-path attention,  w/ residual connections\",\n        \"combined (added) sum and max pooling\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify graph as vulnerable or not vulnerable\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"classify  graph as vulnerable or not vulnerable\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"vulnerability detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"csg\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 227,\n  \"pdf-id\": 313,\n  \"graphs\": {\n    \"cpg\": {\n      \"name\": \"CPG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/control flow/control dependence/data dependence\",\n      \"vertex-features\": \"node content doc2vec or tf/idf (two different approaches were experimented with)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gcn\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"gcn w/ batch norm\",\n        \"global sum pooling\"\n      ]\n    },\n    \"gat\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"gat w/ batch norm\",\n        \"global sum pooling\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"classify graph as vulnerable or not vulnerable\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"classify graph as vulnerable or not vulnerable\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"vulnerability detection (in android OS source code files)\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cpg\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cpg\",\n      \"model\": \"gat\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 261,\n  \"pdf-id\": 74,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"serialised using depth first traversal; sequence of node types and tokens, encoded using word2vec\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"bidirectional LSTM\",\n        \"global max pooling\",\n        \"mlp\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Vulnerability detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 245,\n  \"pdf-id\": 340,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"incomplete snippet (while live editing)\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"cluster\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"exact algorithm not specified\",\n        \"uses modified weisfeiler-lehman kernel\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"task\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"cluster ASTs into different clusters\",\n      \"working-granularity\": \"graph clustering (cluster multiple graphs)\",\n      \"application\": \"visualise common editing paths when editing code (by visualising how ASTs \\\"move\\\" between clusters due to editing)\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"cluster\",\n      \"task\": \"task\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "cluster$graph"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 262,\n  \"pdf-id\": 80,\n  \"graphs\": {\n    \"pdg\": {\n      \"name\": \"PDG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"statement (names normalised)\",\n      \"edge-type\": \"control dependence/data dependence\",\n      \"vertex-features\": \"statement, encoded using sent2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"for every node, compute degree centrality, closeness centrality, and second order centrality.\\nCreate an RGB image, where each color dimension is a centrality multiplied by the node vector \\n(e.g. red = degree centrality * node vector).\\n\\nAn image (RGB) is obtained by concatenating all node representations.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Conv2D (zeropadded) w/ residual connections, followed by Conv1D w/ max pooling, followed by FC\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Vulnerability detection\",\n      \"supervision\": \"n/a\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 248,\n  \"pdf-id\": 347,\n  \"graphs\": {\n    \"fcg\": {\n      \"name\": \"fcg\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"function\",\n      \"edge-type\": \"function call\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"mc-cluster\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Heuristic Monte-carlo (randomised order) clustering\",\n        \"Actually has multiple implementations\"\n      ]\n    },\n    \"greedy-cluster\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Heuristic greedy (e.g. highest degree first) clustering\",\n        \"Actually has multiple implementations\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"migration\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"cluster nodes together\",\n      \"working-granularity\": \"graph (node) clustering\",\n      \"application\": \"Cluster functional (structured programming) functions together into candidate class method for migration to an OOP language\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"fcg\",\n      \"model\": \"mc-cluster\",\n      \"task\": \"migration\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"gch\",\n      \"model\": \"greedy-cluster\",\n      \"task\": \"migration\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "greedy-cluster$node@mc-cluster$node"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 263,\n  \"pdf-id\": 122,\n  \"graphs\": {\n    \"pdg\": {\n      \"name\": \"PDG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": \"statement (w/ names normalised)\",\n      \"edge-type\": \"control dependence/data dependence\",\n      \"vertex-features\": \"statement, encoded using sent2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"for every node, compute degree centrality, katz centrality, and closeness centrality.\\nCreate an RGB image, where each color dimension is a centrality multiplied by the node vector \\n(e.g. red = degree centrality * node vector).\\n\\nAn image (RGB) is obtained by concatenating all node representations.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"CNN w/ max pooling and fully connected layer\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Vulnerability detection\",\n      \"supervision\": \"n/a\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": null,\n      \"model\": null,\n      \"task\": null,\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 256,\n  \"pdf-id\": 103,\n  \"graphs\": {\n    \"e-pdg\": {\n      \"name\": \"ePDG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"source code is first compiled to LLVM IR\"\n        }\n      ],\n      \"vertex-type\": \"instruction (slicing performed based on vulnerability-correlated instruction types)\",\n      \"edge-type\": \"control flow/dependence and data flow/dependence\",\n      \"vertex-features\": \"operation type, basic function, is instruction part of if-clause (all one-hot)/classical graph metrics\",\n      \"edge-features\": \"edge type / data flow edges have the data type(s) of the dependency as attributes\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"based on structure2vec (fairly generic message passing scheme) w/ classification layer\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"classify each node as vulnerable or not vulnerable\",\n      \"training-granularity\": \"node classification\",\n      \"working-objective\": \"classify each node as vulnerable or not vulnerable\",\n      \"working-granularity\": \"node classification\",\n      \"application\": \"vulnerability detection (line level) and classification (by having a separate model for every vulnerability type)\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"e-pdg\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": \"I feel the paper is not consistent; to me, the model seems to compute a global (graph-level) vector, but the classification seems to be node-wise.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 265,\n  \"pdf-id\": 256,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"method\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"every statement in the tree as follows: e.g. MethodDeclaration(Modifier(protected))(sendMessage)...(body)\\nThis results in a sequence of such statements \\n\\nmethod name (split up into sequence) is used as feature \\n\\nsequence of APIs used in the method is used as feature\\n\\nbag of tokens used in the snippets is used as feature \\n\\ncode summary/query is used as feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"embedding layers for all features\",\n        \"for every sequence (statements, method name, apis, tokens, summary/query), apply soft-attention (mlp based) to every element (separately)\",\n        \"for every feature (statement, name, apis, tokens), multiply matrix with param matrix and summary matrix\",\n        \"perform cnn and use fnn/average pooling/softmax to compute attention scores; multiple with pre-matrix multiplication features\",\n        \"fuse features using soft-attention (mlp-based) weighted sum\",\n        \"cosine similarity with summary embedding\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-search\": {\n      \"training-objective\": \"Maximise similarity between related (code, summary) pairs, minimise similarity between unrelated (code, summary) pairs\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"compute code snippet <-> query similarity\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code search\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-search\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 240,\n  \"pdf-id\": 335,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"cfg\": {\n      \"name\": \"cfg\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"statement/basic block\",\n      \"edge-type\": \"control flow\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"svm-1\": {\n      \"name\": \"SVM\",\n      \"architecture-attributes\": [\n        \"svm\",\n        \"subtree kernel (tree kernel)\"\n      ]\n    },\n    \"svm-2\": {\n      \"name\": \"svm\",\n      \"architecture-attributes\": [\n        \"svm\",\n        \"subset tree kernel (tree kernel)\"\n      ]\n    },\n    \"svm-3\": {\n      \"name\": \"svm\",\n      \"architecture-attributes\": [\n        \"svm\",\n        \"shortest path kernel (graph kernel)\"\n      ]\n    },\n    \"svm-4\": {\n      \"name\": \"svm\",\n      \"architecture-attributes\": [\n        \"svm\",\n        \"random walk kernel (graph kernel)\"\n      ]\n    },\n    \"svm-5\": {\n      \"name\": \"svm\",\n      \"architecture-attributes\": [\n        \"svm\",\n        \"subgraph matching kernel (graph kernel)\"\n      ]\n    },\n    \"svm-6\": {\n      \"name\": \"svm\",\n      \"architecture-attributes\": [\n        \"svm\",\n        \"graphlet kernel (graph kernel)\"\n      ]\n    },\n    \"svm-7\": {\n      \"name\": \"svm\",\n      \"architecture-attributes\": [\n        \"svm\",\n        \"Weisfeiler-Lehman kernel (graph kernel)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"algorithm-classification\": {\n      \"training-objective\": \"Given a program (graph), classify it into one of multiple categories\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Given a program (graph), classify it into one of multiple categories\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"Algorithm Identification\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"svm-1\",\n      \"task\": \"algorithm-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"svm-2\",\n      \"task\": \"algorithm-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"svm-3\",\n      \"task\": \"algorithm-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"svm-4\",\n      \"task\": \"algorithm-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"svm-5\",\n      \"task\": \"algorithm-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"svm-6\",\n      \"task\": \"algorithm-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"svm-7\",\n      \"task\": \"algorithm-classification\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 252,\n  \"pdf-id\": 353,\n  \"graphs\": {\n    \"class-graph\": {\n      \"name\": \"Weighted Directed Class Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"class\",\n      \"edge-type\": \"inheritance coupling/method coupling/data coupling\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"edges are weighted (e.g number of method called)\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"clustering\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"edge weight sensitive [custom] clustering algorithm\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"architecture-recovery\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"cluster classes into modules (clusters)\",\n      \"working-granularity\": \"graph (node) clustering\",\n      \"application\": \"high-level software architecture reconstruction\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"class-graph\",\n      \"model\": \"clustering\",\n      \"task\": \"architecture-recovery\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "clustering$node"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 254,\n  \"pdf-id\": 55,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"classes/interfaces\",\n      \"edge-type\": \"dependencies between classes/interfaces (implements, data access, etc.)\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"edges have weights (fine-tuned using simulated annealing)\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"page-rank\": {\n      \"name\": \"PageRank\",\n      \"architecture-attributes\": [\n        \"page rank (with support for weights)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"key-class-detection\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"rank nodes\",\n      \"working-granularity\": \"node ranking\",\n      \"application\": \"detection of key classes (\\\"hotspots\\\")\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"page-rank\",\n      \"task\": \"key-class-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": 223,\n  \"pdf-id\": 298,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"ast + pdg (pruned)\",\n      \"description\": \"mix of ast and pdg (pruned)\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"javascript\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/control dependence/data dependence\",\n      \"vertex-features\": \"node type word2vec\",\n      \"edge-features\": \"edge type one-hot\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"ggnn (edge type aware)\",\n        \"gat\",\n        \"mean pooling readout\",\n        \"energy function is used to balance local and global information, and in particular, avoid over-smoothing\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"malicious-js-detection\": {\n      \"training-objective\": \"classify graph as malicious or benign\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"classify graph as malicious or benign\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"malicious javascript detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"malicious-js-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-031\",\n  \"pdf-id\": \"sb-042\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"pairs of source code for training\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node type one hot\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"encoder/decoder architecture\",\n        \"encoder Tree-LSTM\",\n        \"decoder; for node type, hidden state into FNN w/ as additional input an attention vector computed on the old ast and the node to be expanded;  for token, node type is fed into trainable embedding followed by LSTM\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"translation\": {\n      \"training-objective\": \"Given a program (in AST form), translate the program to a different AST (different language)\",\n      \"training-granularity\": \"tree to tree\",\n      \"working-objective\": \"Given a program (in AST form), translate the program to a different AST (different language)\",\n      \"working-granularity\": \"tree to tree\",\n      \"application\": \"Program translation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"translation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-028\",\n  \"pdf-id\": \"sb-038\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"type and value (EMPTY value for internal nodes)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"AST linearised using depth first traversal.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"LSTM over sequence input\",\n        \"Context vector computed by multiplying hidden state matrix with attention vector\",\n        \"Create a similar vector, but attention is computed based on a nodes parent (i.e. pass node parent though FNN instead of node itself)\",\n        \"Concat; FNN w/ tanh and FNN w/ softmax\",\n        \"Pointer-mixture network for output\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-completion\": {\n      \"training-objective\": \"Given a code sample, predict node type and value of the next AST node (two identical but fully separate networks)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a code sample, predict node type and value of the next AST node (two identical but fully separate networks)\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code completion\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-completion\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-126\",\n  \"pdf-id\": \"sb-177\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/sibling\",\n      \"vertex-features\": \"type (nonterminal), code tokens (terminal)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"presumably adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"source code text is used as feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"embedding layer\",\n        \"GCN\",\n        \"graph linearised using pre-order traversal of ast edges\",\n        \"transformer encoder and decoder layers (w/ graph embedding as input)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate its summary\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a code snippet, generate its summary\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-010\",\n  \"pdf-id\": \"sb-015\",\n  \"graphs\": {\n    \"api-dependency-graph\": {\n      \"name\": \"API Dependency Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"API\",\n      \"edge-type\": \"Denotes that some output(s) of method A match (type-wise) some input(s) of method B\",\n      \"vertex-features\": \"one-hot encoded\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"code snippet is used as feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Code snippet tokens processed using embedding layer w/ LSTM\",\n        \"Nodes in graphs encoded using LSTM, where the input of the LSTM is the collection of 1- and 2-hop neighbours of a given node\",\n        \"By default, only tokens from the query are used, except for tokens representing APIs; then corresponding node embedding is used by decoder\",\n        \"Decoding through LSTM w/ attention and softmax output\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-generation\": {\n      \"training-objective\": \"Given a text description, generate a code snippet\",\n      \"training-granularity\": \"sequence to sequence\",\n      \"working-objective\": \"Given a text description, generate a code snippet\",\n      \"working-granularity\": \"sequence to sequence\",\n      \"application\": \"Code generation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"api-dependency-graph\",\n      \"model\": \"model\",\n      \"task\": \"code-generation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-021\",\n  \"pdf-id\": \"sb-165\",\n  \"graphs\": {\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"file\"\n        }\n      ],\n      \"vertex-type\": \"statement\",\n      \"edge-type\": \"control flow\",\n      \"vertex-features\": \"tokens in statement\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Bug report is also used as feature \"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"probably uses embedding layers\",\n        \"bug report processed using CNN\",\n        \"CNN over tokens in each node to compute node embeddings\",\n        \"Deep walk (skip gram for graphs based on random walk) over graph\",\n        \"all paths in CFG are traversed using LSTM, followed by mean pooling layer\",\n        \"pool all paths\",\n        \"concatenate with bug report\",\n        \"output\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"bug-localisation\": {\n      \"training-objective\": \"Correctly identify matching (report, file containing bug) pairs\",\n      \"training-granularity\": \"Graph Classification (but not quite)\",\n      \"working-objective\": \"Identify the file in which a given bug occurs\",\n      \"working-granularity\": \"Graph Classification (but not quite)\",\n      \"application\": \"Bug Localisation\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"model\",\n      \"task\": \"bug-localisation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-104\",\n  \"pdf-id\": \"sb-143\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"file\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node type\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"AST is linearised, where only certain node types are kept.\\nNode types are replaced with their code token(s) if they represent identifiers.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"embedding layer\",\n        \"CNN w/ max pooling, flattening, and fnn\",\n        \"sigmoid\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"defect-prediction\": {\n      \"training-objective\": \"Predict file as buggy or not\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Predict file as buggy or not\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Defect Prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-016\",\n  \"pdf-id\": \"sb-023\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"extract arbitrary paths (no specific end node types) from AST,\\nwith filtering based on path length and width (i.e. max distance between sibling nodes used in the same path)\"\n    }\n  },\n  \"models\": {\n    \"model-1\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Central model is a conditional random field P(y | x) = 1 / Z(x) \\\\exp(w^T f(y, x)), where f is some scoring function\",\n        \"w is learned using structured support vector machine on training set\",\n        \"inference of unknown properties using MAP (Maximum a Posteriori)\"\n      ]\n    },\n    \"model-2\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"skipgram but different; not a fixed window size, but neighbours based on related nodes (e.g. a path for a node forms the context)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"variable-name-prediction-1\": {\n      \"training-objective\": \"Learn weight matrix using SVM\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a variable node with unknown name, predict the name of the variable\",\n      \"working-granularity\": \"node prediction / classification\",\n      \"application\": \"variable name prediction\",\n      \"supervision\": \"model dependent\"\n    },\n    \"method-name-prediction-1\": {\n      \"training-objective\": \"Learn weight matrix using SVM\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a method node with unknown name, predict the name of the method\",\n      \"working-granularity\": \"node prediction / classification\",\n      \"application\": \"variable name prediction\",\n      \"supervision\": \"model dependent\"\n    },\n    \"full-type-prediction-1\": {\n      \"training-objective\": \"Learn weight matrix using SVM\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given an expression node with unknown type, predict the type of the expression\",\n      \"working-granularity\": \"node prediction / classification\",\n      \"application\": \"variable name prediction\",\n      \"supervision\": \"model dependent\"\n    },\n    \"variable-name-prediction-2\": {\n      \"training-objective\": \"skip gram learning\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"For unknown nodes, find most similar known nodes to predict name\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"variable name prediction\",\n      \"supervision\": \"model dependent\"\n    },\n    \"method-name-prediction-2\": {\n      \"training-objective\": \"skip gram learning\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"For unknown nodes, find most similar known nodes to predict name\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"variable name prediction\",\n      \"supervision\": \"model dependent\"\n    },\n    \"full-type-prediction-2\": {\n      \"training-objective\": \"skip gram learning\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"For unknown nodes, find most similar known nodes to predict type\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"variable name prediction\",\n      \"supervision\": \"model dependent\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model-1\",\n      \"task\": \"variable-name-prediction-1\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model-1\",\n      \"task\": \"method-name-prediction-1\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model-1\",\n      \"task\": \"full-type-prediction-1\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model-2\",\n      \"task\": \"variable-name-prediction-2\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model-2\",\n      \"task\": \"method-name-prediction-2\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model-2\",\n      \"task\": \"full-type-prediction-2\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-088\",\n  \"pdf-id\": \"sb-171\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node type for nonterminals, source code tokens for terminals\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"The set of paths from the root to each terminal node is used for the features. \\nFor each path, the nodes (type or tokens) are put into sequence. \\n\\nnode location information is used as feature\\n\\nThe original code snippet is tokenised\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Tokens (terminal node, code snippet) are encoded using as the sum of the byte pair encoding of their sub-tokens.\",\n        \"path is used as encoder input\",\n        \"Positional encoding based on node location.\",\n        \"Transformer encoder/decoder architecture.\",\n        \"original code snippet is the input for the decoder\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"tree-masked-language-modelling\": {\n      \"training-objective\": \"Given a tree with masked nodes and code snippet with correspondingly masked tokens, predict the original code snippet\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"model pre-training\",\n      \"supervision\": \"self-supervised\"\n    },\n    \"node-order-prediction\": {\n      \"training-objective\": \"Given a path with possible some swapped nodes, predict whether the order of nodes in the path is correct\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"model pre-training\",\n      \"supervision\": \"self-supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"tree-masked-language-modelling + node-order-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-070\",\n  \"pdf-id\": \"sb-099\",\n  \"graphs\": {\n    \"code-property-graph\": {\n      \"name\": \"cpg\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/control dependence/control flow/data dependence\",\n      \"vertex-features\": \"node type ordinal, node content (encoding unclear)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"node content encoded using bidirectional LSTM\",\n        \"Attention is used to dynamically construct a new adjacency matrix\",\n        \"normal message passing for the input graph\",\n        \"dynamic message passing over the dynamic graph; h^{k+1}' = \\\\sum_j A_{k,j}(h_j^{k}W^V + e_{v,j}W^F)\",\n        \"every round, fuse static and dynamic embeddings and pass through GRU\",\n        \"See paper 165.yaml for full details\",\n        \"task-specific output nog specified\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify a program as vulnerable or not vulnerable\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Classify a program as vulnerable or not vulnerable\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"vulnerability-detection\",\n      \"supervision\": \"supervised\"\n    },\n    \"code-summarization\": {\n      \"training-objective\": \"Generate a summary for a given piece of code\",\n      \"training-granularity\": \"graph to sequence\",\n      \"working-objective\": \"Generate a summary for a given piece of code\",\n      \"working-granularity\": \"graph to sequence\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-023\",\n  \"pdf-id\": \"sb-031\",\n  \"graphs\": {\n    \"augmented-ast\": {\n      \"name\": \"Augmented AST\",\n      \"description\": \"AST w/ additional edges\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast/shared subtoken nodes (one for each unique subtoken) [vocab node]\",\n      \"edge-type\": \"ast/sibling/control flow/data flow\",\n      \"vertex-features\": \"token for vocab nodes, type for ast nodes\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"vocab nodes vectorised using Character-level CNN\",\n        \"node types using embedding layer\",\n        \"ggnn\",\n        \"augmented with MLP for fill-in-the-blank\",\n        \"augmented with mean pooling and GRU for variable naming\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"fill-in-the-blank\": {\n      \"training-objective\": \"Given a graph where one node has been masked, predict the correct variable\",\n      \"training-granularity\": \"Node classification (kinda)\",\n      \"working-objective\": \"Given a graph where one node has no variable, predict the correct variable\",\n      \"working-granularity\": \"Node classification (kinda)\",\n      \"application\": \"Variable usage prediction\",\n      \"supervision\": \"supervised\"\n    },\n    \"variable-naming\": {\n      \"training-objective\": \"Given a graph where one variable has been removed (i.e. it has no name), predict the name\",\n      \"training-granularity\": \"Graph to Sequence\",\n      \"working-objective\": \"Given a graph with an unnamed variable, predict the name for the variable\",\n      \"working-granularity\": \"Graph to Sequence\",\n      \"application\": \"Variable Naming\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"augmented-ast\",\n      \"model\": \"model\",\n      \"task\": \"fill-in-the-blank\",\n      \"comments\": \"The method is supposed to be general, while the two tasks are example evaluation tasks used in the paper\"\n    },\n    {\n      \"graph\": \"augmented-ast\",\n      \"model\": \"model\",\n      \"task\": \"variable naming\",\n      \"comments\": \"The method is supposed to be general, while the two tasks are example evaluation tasks used in the paper\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": null,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast (partial)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"n/a\",\n          \"details\": \"generated by model\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"each node represented by an embedding, unclear how it is computed\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Description of code to be generated is used as feature (embedding unclear).\\n\\nPreviously outputted grammar rules (sequence) are used as features.\\n\\npath from root to next node to expand is used as feature.\\n\\nMethod/function scope is used as feature (nearest enclosing scope)\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"description into CNN w/ residual connections\",\n        \"grammar rules embedded using embedding layers\",\n        \"grammar rules into CNN w/ residual connections\",\n        \"ast into tree-based CNN w/ residual connections\",\n        \"Pre-order sequence of AST nodes from tree-based CNN\",\n        \"ast sequence into CNN w/ residual connections\",\n        \"max pooling over program description\",\n        \"max pooling over ast sequence output\",\n        \"embed function/method scope\",\n        \"various attention-weighted sums, using different max pooling outputs and method scope in the process.\",\n        \"concatenate all max pooling and attention layer outputs\",\n        \"MLP\",\n        \"softmax w/ beam search to determine next rule\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-generation\": {\n      \"training-objective\": \"Given a description, generate code\",\n      \"training-granularity\": \"sequence to graph\",\n      \"working-objective\": \"Given a description, generate code\",\n      \"working-granularity\": \"sequence to graph\",\n      \"application\": \"Code generation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-generation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-074\",\n  \"pdf-id\": \"sb-106\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"version history information\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"developer\",\n      \"edge-type\": \"two devs are connected if they made changes to the same file in the same release\",\n      \"vertex-features\": \"\\\"classical\\\" network metrics (connectivity, centrality, degree, betweenness, closeness)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"For every file in a project, the average, maximum, and sum of the developer metrics \\nof all developers who contributed to that file (overall, not per release; unweighted)\\nare computed. \\n\\nFiles have various other (more traditional) code changes metrics, such as \\ncode churn (# modified lines over history), # updates, # distinct developers\"\n    }\n  },\n  \"models\": {\n    \"negative-binomial-regression\": {\n      \"name\": \"Negative Binomial Regression\",\n      \"architecture-attributes\": [\n        \"negative binomial regression\"\n      ]\n    },\n    \"poisson-regression\": {\n      \"name\": \"Poisson Regression\",\n      \"architecture-attributes\": [\n        \"poisson regression\"\n      ]\n    },\n    \"logistic-regression\": {\n      \"name\": \"Logistic Regression\",\n      \"architecture-attributes\": [\n        \"logistic regression\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"failure-prediction-regression\": {\n      \"training-objective\": \"Given a file, predict the number of expected failures for that file\",\n      \"training-granularity\": \"regression\",\n      \"working-objective\": \"Given a file, predict the number of expected failures for that file\",\n      \"working-granularity\": \"regression\",\n      \"application\": \"Failure Prediction\",\n      \"supervision\": \"supervised\"\n    },\n    \"failure-prediction-classification\": {\n      \"training-objective\": \"Given a file, predict whether the file wil contain at least one failure\",\n      \"training-granularity\": \"classification\",\n      \"working-objective\": \"Given a file, predict whether the file wil contain at least one failure\",\n      \"working-granularity\": \"classification\",\n      \"application\": \"Failure Prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"negative-binomial-regression\",\n      \"task\": \"failure-prediction-regression\",\n      \"comments\": \"The model is used to rank files for prioritisation of bug investigation (based on number of failures)\"\n    },\n    {\n      \"graph\": \"graph\",\n      \"model\": \"poisson-regression\",\n      \"task\": \"failure-prediction-regression\",\n      \"comments\": \"The model is used to rank files for prioritisation of bug investigation (based on number of failures)\"\n    },\n    {\n      \"graph\": \"graph\",\n      \"model\": \"logistic-regression\",\n      \"task\": \"failure-prediction-classification\",\n      \"comments\": \"The model is used to rank files for prioritisation of bug investigation (based on probability)\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-050\",\n  \"pdf-id\": \"sb-072\",\n  \"graphs\": {\n    \"extended-api-usage-graph\": {\n      \"name\": \"Extended API Usage Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"objects/values/method invocations/constructor calls/field access/conditional checks/inheritance\",\n      \"edge-type\": \"call/control flow/sequential execution/synchronization/throw/handle/param\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"The authors make use of a set of discriminative subgraphs; subgraphs indicative of a label.\\nEach graph has a binary vector, where each entry indicates whether some specific discriminative subgraph occurs in the graph.\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"svm\": {\n      \"name\": \"SVM\",\n      \"architecture-attributes\": [\n        \"svm\",\n        \"rbf kernel\",\n        \"w/ novelty detector to detect unknown patterns\"\n      ]\n    },\n    \"knn\": {\n      \"name\": \"KNN\",\n      \"architecture-attributes\": [\n        \"knn\",\n        \"w/ novelty detector to detect unknown patterns\"\n      ]\n    },\n    \"naive-bayes\": {\n      \"name\": \"Naive Bayes\",\n      \"architecture-attributes\": [\n        \"naive bayes\",\n        \"w/ novelty detector to detect unknown patterns\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"api-misuse-detection\": {\n      \"training-objective\": \"Detect misuse of APIs (e.g. read after close on a file, file not closed)\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Detect misuse of APIs (e.g. read after close on a file, file not closed)\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"API misuse detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"extended-api-usage-graph\",\n      \"model\": \"svm\",\n      \"task\": \"api-misuse-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"extended-api-usage-graph\",\n      \"model\": \"knn\",\n      \"task\": \"api-misuse-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"extended-api-usage-graph\",\n      \"model\": \"naive-bayes\",\n      \"task\": \"api-misuse-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-074\",\n  \"pdf-id\": \"sb-106\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"version history information\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"developer\",\n      \"edge-type\": \"two devs are connected if they made changes to the same file in the same release\",\n      \"vertex-features\": \"\\\"classical\\\" network metrics (connectivity, centrality, degree, betweenness, closeness)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"For every file in a project, the average, maximum, and sum of the developer metrics \\nof all developers who contributed to that file (overall, not per release; unweighted)\\nare computed. \\n\\nFiles have various other (more traditional) code changes metrics, such as \\ncode churn (# modified lines over history), # updates, # distinct developers\"\n    }\n  },\n  \"models\": {\n    \"negative-binomial-regression\": {\n      \"name\": \"Negative Binomial Regression\",\n      \"architecture-attributes\": [\n        \"negative binomial regression\"\n      ]\n    },\n    \"poisson-regression\": {\n      \"name\": \"Poisson Regression\",\n      \"architecture-attributes\": [\n        \"poisson regression\"\n      ]\n    },\n    \"logistic-regression\": {\n      \"name\": \"Logistic Regression\",\n      \"architecture-attributes\": [\n        \"logistic regression\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"failure-prediction-regression\": {\n      \"training-objective\": \"Given a file, predict the number of expected failures for that file\",\n      \"training-granularity\": \"regression\",\n      \"working-objective\": \"Given a file, predict the number of expected failures for that file\",\n      \"working-granularity\": \"regression\",\n      \"application\": \"Failure Prediction\",\n      \"supervision\": \"supervised\"\n    },\n    \"failure-prediction-classification\": {\n      \"training-objective\": \"Given a file, predict whether the file wil contain at least one failure\",\n      \"training-granularity\": \"classification\",\n      \"working-objective\": \"Given a file, predict whether the file wil contain at least one failure\",\n      \"working-granularity\": \"classification\",\n      \"application\": \"Failure Prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"negative-binomial-regression\",\n      \"task\": \"failure-prediction-regression\",\n      \"comments\": \"The model is used to rank files for prioritisation of bug investigation (based on number of failures)\"\n    },\n    {\n      \"graph\": \"graph\",\n      \"model\": \"poisson-regression\",\n      \"task\": \"failure-prediction-regression\",\n      \"comments\": \"The model is used to rank files for prioritisation of bug investigation (based on number of failures)\"\n    },\n    {\n      \"graph\": \"graph\",\n      \"model\": \"logistic-regression\",\n      \"task\": \"failure-prediction-classification\",\n      \"comments\": \"The model is used to rank files for prioritisation of bug investigation (based on probability)\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-050\",\n  \"pdf-id\": \"sb-072\",\n  \"graphs\": {\n    \"extended-api-usage-graph\": {\n      \"name\": \"Extended API Usage Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"objects/values/method invocations/constructor calls/field access/conditional checks/inheritance\",\n      \"edge-type\": \"call/control flow/sequential execution/synchronization/throw/handle/param\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"The authors make use of a set of discriminative subgraphs; subgraphs indicative of a label.\\nEach graph has a binary vector, where each entry indicates whether some specific discriminative subgraph occurs in the graph.\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"svm\": {\n      \"name\": \"SVM\",\n      \"architecture-attributes\": [\n        \"svm\",\n        \"rbf kernel\",\n        \"w/ novelty detector to detect unknown patterns\"\n      ]\n    },\n    \"knn\": {\n      \"name\": \"KNN\",\n      \"architecture-attributes\": [\n        \"knn\",\n        \"w/ novelty detector to detect unknown patterns\"\n      ]\n    },\n    \"naive-bayes\": {\n      \"name\": \"Naive Bayes\",\n      \"architecture-attributes\": [\n        \"naive bayes\",\n        \"w/ novelty detector to detect unknown patterns\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"api-misuse-detection\": {\n      \"training-objective\": \"Detect misuse of APIs (e.g. read after close on a file, file not closed)\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Detect misuse of APIs (e.g. read after close on a file, file not closed)\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"API misuse detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"extended-api-usage-graph\",\n      \"model\": \"svm\",\n      \"task\": \"api-misuse-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"extended-api-usage-graph\",\n      \"model\": \"knn\",\n      \"task\": \"api-misuse-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"extended-api-usage-graph\",\n      \"model\": \"naive-bayes\",\n      \"task\": \"api-misuse-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-060\",\n  \"pdf-id\": \"sb-086\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"n/a\",\n      \"description\": \"collection of connected ASTs,\\ncollected based on method call chains\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"file (?)\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"word2vec for node content\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"average pooling over node features\",\n      \"other-features\": \"average pooling over the graph embedding of all ASTs\"\n    },\n    \"cfg\": {\n      \"name\": \"n/a\",\n      \"description\": \"collection of connected CFGs,\\ncollected based on method call chains\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"file (?)\"\n        }\n      ],\n      \"vertex-type\": \"statement/entry/exit\",\n      \"edge-type\": \"control flow\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"graph2vec\",\n      \"other-features\": \"apply graph2vec on the graph of connected cfg\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"mlp\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-clone-detection\": {\n      \"training-objective\": \"Given two code samples, determine if they are clones\",\n      \"training-granularity\": \"graph classification (but two graphs)\",\n      \"working-objective\": \"Given two code samples, determine if they are clones\",\n      \"working-granularity\": \"graph classification (but two graphs)\",\n      \"application\": \"Code clone detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + cfg\",\n      \"model\": \"model\",\n      \"task\": \"code-clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-105\",\n  \"pdf-id\": \"sb-145\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/control flow/control dependence/data dependence/dominator/post dominator\",\n      \"vertex-features\": \"node type (presumably one-hot), code associated with node encoded using word2vec\",\n      \"edge-features\": \"edge type one-hot encoded\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"the heterogeneous graph is split into multiple homogeneous graphs based on edge type\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"gat\",\n        \"attention-weighted sum of the node embeddings of the different graphs\",\n        \"concat initial and learned features for every node; pass through 1D convolution w/ max pooling (twice); pass through MLP\",\n        \"sum transformed node embeddings; sigmoid\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"vuln detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-069\",\n  \"pdf-id\": \"sb-098\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node embeddings are learned by appying continuous skip-gram to the AST structure\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"dependency-tree\": {\n      \"name\": \"dependency tree\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/def-use relations\",\n      \"vertex-features\": \"node type\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"dependency-graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/data flow (different types, e.g. lastUse)\",\n      \"vertex-features\": \"node type\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"tbcnn\": {\n      \"name\": \"TBCNN\",\n      \"architecture-attributes\": [\n        \"TBCNN\",\n        \"Two _separate_ input paths for clone detection\"\n      ]\n    },\n    \"ggnn\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"GGNN\",\n        \"Two _separate_ input paths for clone detection\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"program-classification\": {\n      \"training-objective\": \"Classify a program in one of multiple classes based on its behaviour\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Classify a program in one of multiple classes based on its behaviour\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"Program classification\",\n      \"supervision\": \"supervised\"\n    },\n    \"code-clone-detection\": {\n      \"training-objective\": \"Given two code samples (in different languages), determine if they are clones\",\n      \"training-granularity\": \"graph classification (but two graphs)\",\n      \"working-objective\": \"Given two code samples (in different languages), determine if they are clones\",\n      \"working-granularity\": \"graph classification (but two graphs)\",\n      \"application\": \"Program classification (not sure why the paper does not call it clone detection)\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"tbcnn\",\n      \"task\": \"program-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"tbcnn\",\n      \"task\": \"code-clone-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"dependency-tree\",\n      \"model\": \"tbcnn\",\n      \"task\": \"program-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"dependency-tree\",\n      \"model\": \"tbcnn\",\n      \"task\": \"code-clone-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"dependency-graph\",\n      \"model\": \"ggnn\",\n      \"task\": \"program-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"dependency-graph\",\n      \"model\": \"ggnn\",\n      \"task\": \"code-clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-111\",\n  \"pdf-id\": \"sb-154\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast (binarized)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": \"ast/null nodes (inserted to make a full binary tree out of the ast)\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"every node is represented as a 3-entry vector,\\nwhere the first entry is the ordinal encoding of the node types,\\nand the other two entries carry additional information about the node.\\n\\nnull nodes are encoded as (0, 0, 0)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Note is put into sequence using breadth first traversal\"\n    }\n  },\n  \"models\": {\n    \"mlp\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"MLP\"\n      ]\n    },\n    \"cnn\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"CNN\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable or not\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Classify sample as vulnerable or not\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"mlp\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"cnn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-033\",\n  \"pdf-id\": \"sb-047\",\n  \"graphs\": {\n    \"multilayer-class-network\": {\n      \"name\": \"Multilayer Class Network\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"class\",\n      \"edge-type\": \"class/interface relationships\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"multilayer-package-network\": {\n      \"name\": \"Multilayer Package Network\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"package\",\n      \"edge-type\": \"class/interface relationships (based on the coupling between the classes in the packages)\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"Weights based on the amount of coupling (i.e. amount of involved classes)\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"page-rank like algorithm, applied to every sub-graph obtained by considering the different edge types\",\n        \"final page-rank score obtained as weighted sum of page rank scores over all edge types\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"ranking\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Rank nodes in the graph\",\n      \"working-granularity\": \"Node Ranking\",\n      \"application\": \"Identify most important nodes (Starting nodes) for program understanding\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"multilayer-class-network + multilayer-package-network\",\n      \"model\": \"model\",\n      \"task\": \"ranking\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-017\",\n  \"pdf-id\": \"sb-025\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"javascript\"\n        }\n      ],\n      \"vertex-type\": \"ast (nonterminal nodes only)\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"continuous binary tree\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"javascript\"\n        }\n      ],\n      \"vertex-type\": \"basic block\",\n      \"edge-type\": \"control flow\",\n      \"vertex-features\": \"random vectors\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"cnn over ast (i.e. convolution operation over subtrees)\",\n        \"dynamic pooling\",\n        \"cnn over cfg subgraphs\",\n        \"concatenation w/ softmax\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"malicious-js-detection\": {\n      \"training-objective\": \"Classify sample as malicious or benign\",\n      \"training-granularity\": \"graph classification (w/ 2 input graphs)\",\n      \"working-objective\": \"Classify sample as malicious or benign\",\n      \"working-granularity\": \"graph classification (w/ 2 input graphs)\",\n      \"application\": \"Malicious javascript code detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + cfg\",\n      \"model\": \"model\",\n      \"task\": \"malicious-js-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-084\",\n  \"pdf-id\": \"sb-117\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"some amount of edits must already have been applied\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"1) node type is a feature\\n2) terminals have tokens, split into subtokens \\n3) Each token has its index among its siblings as feature\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Each edit is represented as a path, e.g. \\n1) A MOVE is represented as a path from the root of the subtree being moved, to its new location (eg its left-most sibling)\\n2) UPDATE, INSERT, DELETE have similar path representations.\\n\\nSpecifically, two sets are created: 1) the set of applied edits, 2) the set of all possible edits.\\nBoth are separately encoded\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"encoder/decoder architecture\",\n        \"(encoder) embedding layers\",\n        \"(encoder) index and type encoding are added\",\n        \"(encoder) terminal is encoded as sum of its subtokens embeddings\",\n        \"(encoder) LSTM with path (nonterminal nodes)\",\n        \"(encoder) concat terminal and path embeddings\",\n        \"(encoder) fnn\",\n        \"(encoder) LSTM over all encoded edit paths\",\n        \"(encoder) All possible edits are encoded (!one of the two sets only thus!), and projected it with a operation-specific matrix\",\n        \"(decoder) LSTM over encoded _applied_ edits\",\n        \"(decoder) attention over encoded _applied_ edits\",\n        \"(decoder) pointer network to \\\"point\\\" to edit (out of set of valid edits) (from the encoded edits)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"program-editing\": {\n      \"training-objective\": \"Given a source sample (as AST), with some edits, predict a sequence of edits to transform it into a different AST\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a source sample (as AST), with some edits, predict the following edits\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Program Edit Completion\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"program-editing\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": null,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Complete old and new files are used in order to parse the changed method in full.\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"diff\"\n        },\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"Node types (internal nodes)\\n\\nLeaf nodes are split into sub-tokens\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"For both old and new code, paths between changed tokens are extracted from the \\nASTs obtained from the old/new files.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"encoder/decoder\",\n        \"embedding layers\",\n        \"embed paths using Bidirectional LSTM\",\n        \"leafs encoded by summing embeddings of sub-tokens\",\n        \"Decoder uses Luong attention mechanism applied to the set of paths, and outputs using softmax\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"commit-message-generation\": {\n      \"training-objective\": \"Given the paths for a change, generate a commit message\",\n      \"training-granularity\": \"x to sequence\",\n      \"working-objective\": \"Given the paths for a change, generate a commit message\",\n      \"working-granularity\": \"x to sequence\",\n      \"application\": \"Commit message generation\",\n      \"supervision\": \"supervised (self-supervised)\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"commit-message-generation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-066\",\n  \"pdf-id\": \"sb-093\",\n  \"graphs\": {\n    \"pdg\": {\n      \"name\": \"PDG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"statement\",\n      \"edge-type\": \"control dependence/data dependence\",\n      \"vertex-features\": \"statements as sequences of tokens\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"description of the code is used as feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"embedding layer for tokens\",\n        \"statement embedded as attention-weighted sum\",\n        \"mlp applied to columns of adjacency matrix\",\n        \"for each statement, connect its corresponding row from transformed adjacency matrix\",\n        \"Bidirectional LSTM over combined embeddings (lsat hidden state as code vector)\",\n        \"description encoded using embedding layer, Bidirectional LSTM, and max pooling over hidden states\",\n        \"cosine similarity between code and description vector\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-search\": {\n      \"training-objective\": \"Maximise similarity of related (code, description pairs); minimise similarity of unrelated pairs\",\n      \"training-granularity\": \"graph classification (kinda but not quite)\",\n      \"working-objective\": \"Compute similarity of code and query\",\n      \"working-granularity\": \"graph classification/regression (kinda but not quite)\",\n      \"application\": \"code Search\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model\",\n      \"task\": \"code-search\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-053\",\n  \"pdf-id\": \"sb-075\",\n  \"graphs\": {\n    \"ast-graph\": {\n      \"name\": \"AST graph (constructed from partial AST)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast (but identical nodes are merged)\",\n      \"edge-type\": \"ast (directed)/nodes adjacent in the depth-first traversal sequence of the AST are linked (undirected)\",\n      \"vertex-features\": \"node type and node value (EMPTY for internal nodes) (embedding method unclear); also positional information (distance to right-most node in sequence, which may be 0 if the right-most node is duplicated elsewhere, encoded as vector of repeated entries)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": null\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Concat node type and value; add positional embedding\",\n        \"Blocks of the following three layers:\\n  1) Neighbour Graph Attention Layer -- Similar to GAT. Attention between 1-hop neighbours. \\\"Adjacent node\\\" edges only\\n  2) Global Self-attention Layer -- Attention with node feature matrix \\n  3) parent-child attention layer -- Attention where children receive messages from parents\\n  4) Residual connection\",\n        \"(soft) attention weighted sum of node embeddings\",\n        \"softmax outputs for outputting type and value for next node\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-completion\": {\n      \"training-objective\": \"Given an incomplete AST, predict the next node in the AST (right-most expansion)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given an incomplete AST, predict the next node in the AST (right-most expansion)\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code completion\",\n      \"supervision\": \"supervised (self-)\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast-graph\",\n      \"model\": \"model\",\n      \"task\": \"code-completion\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-002\",\n  \"pdf-id\": \"sb-004\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"ast with additional edges. The AST is the thing being generated by the model.\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/sibling/parent/next-use/next token\",\n      \"vertex-features\": null,\n      \"edge-features\": null,\n      \"connectivity-features\": null,\n      \"graph-features\": null,\n      \"other-features\": \"Context code (which contains the hole to be filled in) is used as feature.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"GGNN (edge-type specific)\",\n        \"Note; goal of the network (per step) is to expand one node\",\n        \"Pick nonterminal node to be expanded 1) use attention + softmax to pick production, 2) use softmax to pick variable(s), 3) use softmax to pick literals\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-generation\": {\n      \"training-objective\": \"Given a code sample (\\\"context\\\") with missing code (\\\"hole\\\"), generate code for the whole by generating an AST\",\n      \"training-granularity\": \"Generative Graph Creation\",\n      \"working-objective\": \"Given a code sample (\\\"context\\\") with missing code (\\\"hole\\\"), generate code for the whole by generating an AST\",\n      \"working-granularity\": \"Generative Graph Creation\",\n      \"application\": \"Code Generation\",\n      \"supervision\": \"Self-supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"code-generation\",\n      \"comments\": \"This description is not very complete. Refer to the paper if necessary\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-008\",\n  \"pdf-id\": \"sb-011\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"Not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"code tokens are used as feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Reinforcement learning with actor-critic network\",\n        \"Code tokens fed into LSTM\",\n        \"AST into tree-based LSTM\",\n        \"Attention-weighted sum of node and token embeddings\",\n        \"Concatenate results of sums\",\n        \"FNN w/ tanh and softmax for output of _actor_ (action; next token)\",\n        \"MLP over actor output for critic (single value output)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code sample, generate a summary\",\n      \"training-granularity\": \"graph to sequence\",\n      \"working-objective\": \"Given a code sample, generate a summary\",\n      \"working-granularity\": \"graph to sequence\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised (reinforcement learning)\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-027\",\n  \"pdf-id\": \"sb-037\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"type (based on image)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"In all instances, identifiers are split into sub-tokens \\n\\nsource code is used as feature.\\n\\nAST is linearised (using brackets to make process reversible; structure based traversal)\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Source code encoded using GRU\",\n        \"AST sequence encoded using GRU\",\n        \"AST and code vectors fused using attention; sum the attention-weighted sum of hidden states\",\n        \"Decoder, using beam search (exact decoder architecture not specified)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"comment-generation\": {\n      \"training-objective\": \"Given a code sample, generate a comment\",\n      \"training-granularity\": \"x to sequence\",\n      \"working-objective\": \"Given a code sample, generate a comment\",\n      \"working-granularity\": \"x to sequence\",\n      \"application\": \"Comment Generation\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"comment-generation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-078\",\n  \"pdf-id\": \"sb-109\",\n  \"graphs\": {\n    \"tri-network\": {\n      \"name\": \"Tri-Network\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"version history information\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"developer/module\",\n      \"edge-type\": \"contribution (developer -> module)/dependency (module -> module) -- both co-evolution and call, but a single edge type/collaboration (developer <-> developer) -- two devs modified the same module\",\n      \"vertex-features\": \"node level network metrics \\n\\nvarious software metrics per node (e.g. cyclomatic complexity, number of LOC, etc)\",\n      \"edge-features\": \"contribution edge is weighted by normalised number of commits \\n\\ndependency is weighted by sum of 1) normalised \\\\# of co-change commits, and 2) normalised number of calls \\n\\ncollaboration is weighted by normalised number of jointly changed modules\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"bayes-net\": {\n      \"name\": \"Bayesian Network\",\n      \"architecture-attributes\": [\n        \"bayesian-network\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"fault-proneness-prediction\": {\n      \"training-objective\": \"Predict module nodes as fault prone or not\",\n      \"training-granularity\": \"Node classification\",\n      \"working-objective\": \"Predict module nodes as fault prone or not\",\n      \"working-granularity\": \"Node classification\",\n      \"application\": \"Fault proneness prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"tri-relation\",\n      \"model\": \"bayes-net\",\n      \"task\": \"fault-proneness-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-064\",\n  \"pdf-id\": \"sb-091\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"split into statement trees; subtrees containing a statement as root\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"word2vec for node type (non-leaf) or lexical payload (leaf)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"see description; split into statement trees; subtrees containing a statement as root \\nstatement trees are ordered in depth first fashion (from the perspective of the full ast)\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"bottom-up computation of nodes in statement trees; h' = \\\\sigma(h + \\\\sum_c h_c + b)\",\n        \"element-wise max pooling over all nodes in statement tree -> sequence of statement tree vectors\",\n        \"Bidirectional GRU over statement tree vectors\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-classification\": {\n      \"training-objective\": \"Classify program into categories based on functionality\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Classify program into categories based on functionality\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"Source code classification\",\n      \"supervision\": \"supervised\"\n    },\n    \"code-clone-detection\": {\n      \"training-objective\": \"Given two code samples, determine if they are clones\",\n      \"training-granularity\": \"graph classification (but two graphs)\",\n      \"working-objective\": \"Given two code samples, determine if they are clones\",\n      \"working-granularity\": \"graph classification (but two graphs)\",\n      \"application\": \"Code clone detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-clone-detection\",\n      \"comments\": \"The method is general purpose; the paper presents two example applications\"\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-classification\",\n      \"comments\": \"The method is general purpose; the paper presents two example applications\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-121\",\n  \"pdf-id\": \"sb-172\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code method\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": null,\n      \"edge-features\": null,\n      \"connectivity-features\": null,\n      \"graph-features\": null,\n      \"other-features\": \"code is split into a sequence of tokens per statement. (identifiers into sub tokens)\\n\\nThe AST is linearised per statement (node type or tokens) (subtree per statement);\\ntokens are split into subtokens\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"encoder/decoder\",\n        \"two identical input paths for code and ast sequence input\",\n        \"learnable embedding layer\",\n        \"bidirectional LSTM _over individual statements_\",\n        \"attention mechanism\",\n        \"bidirectional LSTM over all statements\",\n        \"encoder output is concatenation of 1) hidden state, and 2) current \\\"statement/sentence\\\" embedding\",\n        \"Average final embeddings for code and ast\",\n        \"decoder with LSTM, attention mechanism, and softmax output\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a method, generate a summary\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a method, generate a summary\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": \"unclear how/when previously generated token is fed back (which the paper suggests), but it is not important for the data analysis\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-091\",\n  \"pdf-id\": \"sb-127\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"module\"\n        }\n      ],\n      \"vertex-type\": \"ast (only specific node types are kept)\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node type\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"pre-order traversal sequence of ast nodes.\"\n    }\n  },\n  \"models\": {\n    \"model-1\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"CBOW model\"\n      ]\n    },\n    \"model-2\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Use learned embeddings from model-1 to encode token input\",\n        \"Bidirectional LSTM\",\n        \"max pooling\",\n        \"attention\",\n        \"sigmoid\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"embedding\": {\n      \"training-objective\": \"Given the parent and children of a node (i.e. their types), predict the masked node (type)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"embedding\",\n      \"supervision\": \"self-supervised\"\n    },\n    \"defect-prediction\": {\n      \"training-objective\": \"Classify a module as defective or not\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Classify a module as defective or not\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Defect Prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model-1 + model-2\",\n      \"task\": \"embedding + defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-006\",\n  \"pdf-id\": \"sb-009\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"heterogeneous graph with developers' github and stackoverflow activity\",\n      \"artefacts\": [\n        {\n          \"name\": \"github data\",\n          \"details\": \"projects, user data, topics (\\\"abilities\\\")\"\n        },\n        {\n          \"name\": \"stackoverflow data\",\n          \"details\": \"questions, answers, users, tags (\\\"abilities\\\")\"\n        }\n      ],\n      \"vertex-type\": \"developers/projects/questions/abilities\",\n      \"edge-type\": \"follows (developer -> developer) / answered (Q -> D) / ask (D -> Q) / commit/committed (D <-> P) / label/labelled (P <-> A, Q <-> A)\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"Edges are weighted (1 for most, except \\\\# committ(ed), \\\\# asked/answered)\",\n      \"connectivity-features\": \"transition probability matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": null\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Use random walk with restarts to compute affinity for abilities for a given developer (probability of reaching ability node from developer node)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"ability-mining\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"determine developer affinity for abilities\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Determine developer capabilities from online community data\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"ability-mining\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-045\",\n  \"pdf-id\": \"sb-067\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast (binarised)\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node type and content, both using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"siamese network\",\n        \"tree-based LSTM, but with two feature vectors per node (everywhere where in normal tree-LSTM, a single input is given, a second term is added for the second input)\",\n        \"cosine similarity\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"clone-detection\": {\n      \"training-objective\": \"maximise similarity for related clone pairs, minimise similarity for unrelated pairs\",\n      \"training-granularity\": \"graph regression (but two inputs)\",\n      \"working-objective\": \"output similarity of two programs\",\n      \"working-granularity\": \"graph regression (but two inputs)\",\n      \"application\": \"code clone detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-057\",\n  \"pdf-id\": \"sb-083\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST (binarised)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"tokens (leaf nodes)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"source code text is used as feature\"\n    }\n  },\n  \"models\": {\n    \"model-1\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"text into embedding layer w/ RNN (next term prediction)\"\n      ]\n    },\n    \"model-2\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"recursive neural network\",\n        \"starting from leaf nodes, use an auto-encoder to learn node embeddings; reconstruct child nodes, take encoder output as embedding of parent\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"next-term-prediction\": {\n      \"training-objective\": \"Given a sequence of terms, predict the next term\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"embedding training\",\n      \"supervision\": \"self-supervised\"\n    },\n    \"auto-encoding\": {\n      \"training-objective\": \"Reconstruct the two child nodes\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"embedding training using auto-encoder (hidden layer output becomes parent node embedding)\",\n      \"supervision\": \"self-supervised\"\n    },\n    \"code-clone-detection\": {\n      \"training-objective\": \"Given a pair of source code files, determine whether they are code clones by encoding both (auto-encoder style) and comparing embeddings\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a pair of source code files, determine whether they are code clones by encoding both (auto-encoder style) and comparing embeddings\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"code clone detection\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model-1 + model-2\",\n      \"task\": \"next-term-prediction + auto-encoding + code-clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-093\",\n  \"pdf-id\": \"sb-128\",\n  \"graphs\": {\n    \"class-dependency-network\": {\n      \"name\": \"Class Dependency Network\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"class\",\n      \"edge-type\": \"class or interface dependencies and relationships\",\n      \"vertex-features\": \"nodes are embedded using node2vec.\\n\\nnodes are also annotated with various static code metrics (e.g. # methods)\\n\\nNodes are also annotated with various network metrics.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not explicitly specified, but seems to be adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"gcn\",\n        \"softmax per node\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"defect-prediction\": {\n      \"training-objective\": \"Predict nodes in the network as defective or not defective\",\n      \"training-granularity\": \"node classification\",\n      \"working-objective\": \"Predict nodes in the network as defective or not defective\",\n      \"working-granularity\": \"node classification\",\n      \"application\": \"Defect prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"class-dependency-network\",\n      \"model\": \"model\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-101\",\n  \"pdf-id\": \"sb-139\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"file\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node type, unclear if content (code tokens) are also used, but seems to be only node type\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"AST linearised. Tokens (node type; code tokens unclear if used) are encoded using Glove.\\n\\ntraditional code metrics are also used as features.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"LSTM over linearised AST\",\n        \"LSTM over traditional code metrics (1 numerical input per \\\"time step\\\", hence 18 steps for 18D vector input)\",\n        \"concatenation followed by softmax\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"defect-prediction\": {\n      \"training-objective\": \"Classify file as defective or not.\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Classify file as defective or not.\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"defect-prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-029\",\n  \"pdf-id\": \"sb-040\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Sequence of nonterminal rule expansions used to \\nfrom free (depth first, left-to-right order), is used as feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"encoder / decoder architecture\",\n        \"learnable embedding\",\n        \"encode is LSTM\",\n        \"decoder is LSTM with attention weighted sum of hidden states (softmax over possible rules)\",\n        \"generate next rule to be applied; separate model for generating tokens\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-generation\": {\n      \"training-objective\": \"Given an AST, generate a new AST (edit proposal)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given an AST, generate a new AST (edit proposal)\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Automated code editing\",\n      \"supervision\": \"(self-)supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-generation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-094\",\n  \"pdf-id\": \"sb-132\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"pruned using Louvian community detection algorithm (only \\\"defect related communities\\\" of nodes are kept)\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"module\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node type, exact encoding is unclear. Combined with the topic vector (see \\\"other features\\\"), which is identical for all nodes.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"For each defective module, LDA is used to extract a topic based on subtokens \\nin method names, variable names, class names etc., taking the top-k words.\\nThe topic is encoded using word2vec.\\nI think the topic vectors are then averaged\"\n    }\n  },\n  \"models\": {\n    \"gcn\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"GCN\",\n        \"max pooling\"\n      ]\n    },\n    \"gin\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"GIN\",\n        \"max pooling\"\n      ]\n    },\n    \"sgc\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"SGC\",\n        \"max pooling\"\n      ]\n    },\n    \"gat\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"GAT\",\n        \"max pooling\"\n      ]\n    },\n    \"graph-sage\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"GraphSAGE\",\n        \"max pooling\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"defect-prediction\": {\n      \"training-objective\": \"Classify sample as defective or not\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Classify sample as defective or not\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"Defect prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"gcn\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"gin\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"sgc\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"gat\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"graph-sage\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-022\",\n  \"pdf-id\": \"sb-030\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"(partial) AST\",\n      \"description\": \"Partial AST, further generated during code generation\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"type and value, encoded (not specified, presumably embedding layer) and concatenated\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"depth first traversal of AST nodes; sequence of type (internal) or type/value combinations (leaf).\\n\\nCompute path from root node to node being predicted (i.e. node whose child will be predicted).\\nUse the path as sequence input\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": null,\n      \"architecture-attributes\": [\n        \"encoder/decoder architecture\",\n        \"Transformer-XL encoder\",\n        \"root path into bidirectional LSTM (final two hidden states concatenated)\",\n        \"transformer output and path embedding concatenated\",\n        \"two separate FNN w/ tanh and softmax as output (one for node type, one for node value)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-generation\": {\n      \"training-objective\": \"Given an incomplete AST, predict the next node (type and  value, separately)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given an incomplete AST, predict the next node (type and  value, separately)\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code generation\",\n      \"supervision\": \"supervised (self-supervised)\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-generation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-081\",\n  \"pdf-id\": \"sb-114\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"snippets\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Paths between terminal nodes are extracted from the AST.\\nFor the terminal nodes, tokens are features. \\nThe path itself (sequence of types, interlaced with up/down directions) are also features (i.e. a full path is a single feature)\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"embedding layers for tokens and paths\",\n        \"concat start token, path, and end token embeddings\",\n        \"fnn\",\n        \"attention-weighted sum of path vectors\",\n        \"(if necessary, softmax for prediction)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"method-name-prediction\": {\n      \"training-objective\": \"Given a method, predict its name (from a corpus of possible method names)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a method, predict its name (from a corpus of possible method names)\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Method name prediction\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"method-name-prediction\",\n      \"comments\": \"The method is supposed to be more general, with name prediction being an evaluation application\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-132\",\n  \"pdf-id\": \"sb-183\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast (partial)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"n/a\",\n          \"details\": \"generated by model\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"The AST is represented as a sequence or rule expansions.\",\n      \"other-features\": \"Natural language description of the code to be generated \\n\\nNode to be expanded represented as path from root to node, encoded with the node types\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"character-level embedding of tokens in NL description\",\n        \"embedding layer for rules (incl. their content/expansion)\",\n        \"NL encoder has blocks with following structure; |- 1) self-attention 2) gating mechanism (based on softmax; similar to attention) which fuses NL input with the character embeddings 3) convolution over words\",\n        \"AST Reader with blocks with the following structure; |- 1) Self-attention 2) gating mechanism 3) Attention w/ NL query 4) tree-convolution; a convolution which takes the tree structure into account (lost because in the rule sequence, parents and children may be separated)\",\n        \"Decoder w/ node to be expanded (path) as input. Following structure; |- 1) Attention w/ AST 2) Attention w/ NL query 3) FNN\",\n        \"Final decoder output; softmax + pointer (to copy from query if needed); output next rule\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-generation\": {\n      \"training-objective\": \"Given a natural language description, generate code by generating an AST\",\n      \"training-granularity\": \"sequence to tree\",\n      \"working-objective\": \"Given a natural language description, generate code by generating an AST\",\n      \"working-granularity\": \"sequence to tree\",\n      \"application\": \"code generation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-generation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-039\",\n  \"pdf-id\": \"sb-060\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast (nonterminal nodes only)\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node type\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"nodes are put into bread-first sequence; \\nfor every node, it is replaced by a list consisting of itself and its direct children\\npadding is applied\\nresult: matrix of size (max_subtrees x max_children)\"\n    }\n  },\n  \"models\": {\n    \"model-1\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"embedding layer\",\n        \"cnn\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"test-failure-prediction\": {\n      \"training-objective\": \"Predict whether a program will fail on a given test case\",\n      \"training-granularity\": \"graph classification (kinda)\",\n      \"working-objective\": \"Predict whether a program will fail on a given test case\",\n      \"working-granularity\": \"graph classification (kinda)\",\n      \"application\": \"Test Failure Prediction\",\n      \"supervision\": \"supervised\"\n    },\n    \"bug-localisation\": {\n      \"training-objective\": \"Given a failing program (on some given test case), output the faulty line(s)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a failing program (on some given test case), output the faulty line(s)\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Bug Localisation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model-1\",\n      \"task\": \"test-failure-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model-1\",\n      \"task\": \"bug-localisation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-012\",\n  \"pdf-id\": \"sb-019\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"ast w/ ncs; AST of the old source code\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"diff\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/ncs\",\n      \"vertex-features\": \"not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"graph-2\": {\n      \"name\": \"n/a\",\n      \"description\": \"difference between old and new ast\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"diff\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/added/removed/replaced/unchanged\",\n      \"vertex-features\": \"not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"encoder/decoder architecture\",\n        \"auto-encoder\",\n        \"ggnn encoders (w/ normalised attention-weighted sum for pooling); one for ast of old code, one for the change graph\",\n        \"partial AST state is modelled using an LSTM; receives the two graph embeddings as inputs (and previous decoder output)\",\n        \"decoder generates edit operation or move subtree operation using pointer-like network\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"neural-editing\": {\n      \"training-objective\": \"Given an old AST and change graph (edit representation), generate the new AST\",\n      \"training-granularity\": \"x to tree\",\n      \"working-objective\": \"Given an old AST and change graph (edit representation), generate a new AST\",\n      \"working-granularity\": \"x to tree\",\n      \"application\": \"Edit Representation Learning\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph + graph-2\",\n      \"model\": \"model\",\n      \"task\": \"neural-editing\",\n      \"comments\": \"A secondary goal of the training is to use the second GGNN to learn how to represent edits as vectors\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-040\",\n  \"pdf-id\": \"sb-061\",\n  \"graphs\": {\n    \"customised-ast\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"file\"\n        }\n      ],\n      \"vertex-type\": \"ast (merge certain types, prune some stuff)\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node type encoded using word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"bug report encoded using word2vec \\nraw source code encoded using word2vec\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"cnn over bug report text\",\n        \"cnn over raw source code text\",\n        \"TBCNN over ast\",\n        \"max pooling over all cnn results\",\n        \"concatenation\",\n        \"MLP\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"bug-localisation\": {\n      \"training-objective\": \"Predict whether a bug is present in a given file or not\",\n      \"training-granularity\": \"graph classification (but not quite)\",\n      \"working-objective\": \"Predict whether a bug is present in a given file or not\",\n      \"working-granularity\": \"graph classification (but not quite)\",\n      \"application\": \"Bug localisation\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"customised-ast\",\n      \"model\": \"model\",\n      \"task\": \"bug-localisation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-024\",\n  \"pdf-id\": \"sb-034\",\n  \"graphs\": {\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"basic block\",\n      \"edge-type\": \"control flow\",\n      \"vertex-features\": \"basic block encoded using doc2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"GCN\",\n        \"max pooling\",\n        \"FNN\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify graph as vulnerable or non-vulnerable\",\n      \"training-granularity\": \"Graph classification\",\n      \"working-objective\": \"Classify graph as vulnerable or non-vulnerable\",\n      \"working-granularity\": \"Graph Classification\",\n      \"application\": \"Vulnerability Detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-043\",\n  \"pdf-id\": \"sb-065\",\n  \"graphs\": {\n    \"pdg\": {\n      \"name\": \"PDG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"file\"\n        }\n      ],\n      \"vertex-type\": \"statement (?)\",\n      \"edge-type\": \"control dependence/data dependence\",\n      \"vertex-features\": \"method and field names are encoded using word2vec.\\n\\nnumber of api names \\n\\nnode type \\n\\nVarious network-derived metrics are used\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"title, description, comments of bug report are analysed using LDA;\\n\\\"multiple-hot\\\" vector of present topics is used as feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"decision tree\",\n      \"architecture-attributes\": [\n        \"decision tree\",\n        \"adaboost for meta learning\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"bug-localisation\": {\n      \"training-objective\": \"In a buggy piece of code, identify the buggy statement.\",\n      \"training-granularity\": \"node classification\",\n      \"working-objective\": \"In a buggy piece of code, identify the buggy statement.\",\n      \"working-granularity\": \"node classification\",\n      \"application\": \"bug localisation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"pdg\",\n      \"model\": \"model\",\n      \"task\": \"bug-localisation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-123\",\n  \"pdf-id\": \"sb-174\",\n  \"graphs\": {\n    \"data-flow-graph\": {\n      \"name\": \"Data Flow Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"variable\",\n      \"edge-type\": \"data flow\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"mask matrix (1 for connected nodes, $-\\\\infty$ otherwise)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"code tokens are used as input\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"transformer encoder/decoder architecture\",\n        \"stack of normal encoder layers, followed by a stack or graph augmented encoder layers (MQK^T)\",\n        \"transformer decoder w/ variant of beam search\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"comment-generation\": {\n      \"training-objective\": \"Given a code snippet, generate a comment for it\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a code snippet, generate a comment for it\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Comment Generation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"data-flow-graph\",\n      \"model\": \"model\",\n      \"task\": \"comment-generation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-098\",\n  \"pdf-id\": \"sb-136\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"method\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node type\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"pre-order depth first traversal to create a sequence of nodes.\\nFrom this sequence, n-grams are constructed. \\nBinary encoding of the present n-grams is used as feature.\"\n    }\n  },\n  \"models\": {\n    \"naive-bayes\": {\n      \"name\": \"Naive Bayes\",\n      \"architecture-attributes\": [\n        \"Naive Bayes\"\n      ]\n    },\n    \"rf\": {\n      \"name\": \"Random Forest\",\n      \"architecture-attributes\": [\n        \"Random Forest\"\n      ]\n    },\n    \"dt\": {\n      \"name\": \"Decision Tree\",\n      \"architecture-attributes\": [\n        \"Decision Tree\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"defect-prediction\": {\n      \"training-objective\": \"Classify sample as defective or not\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Classify sample as defective or not\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Defect Prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"naive-bayes\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"rf\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"dt\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-090\",\n  \"pdf-id\": \"sb-122\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": null,\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Paths between two terminals (incl. directions) are used as features\\nFor the terminal nodes, tokens are features. \\nThe path itself (sequence of types, interlaced with up/down directions) are also features (i.e. a full path is a single feature)\"\n    },\n    \"cfg\": {\n      \"name\": \"cfg\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"statement\",\n      \"edge-type\": \"control flow\",\n      \"vertex-features\": null,\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Paths from the method start to either a return statement\\nor earlier visited path (loop structure) are used as features\\n\\nExact details not specified, but based on code2vec we would have that the path (sequence of types) is the feature\"\n    },\n    \"pdg\": {\n      \"name\": \"pdg\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"statement\",\n      \"edge-type\": \"control dependence/data dependence\",\n      \"vertex-features\": null,\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Paths of homogeneous edge type (either all control or all data dependence) (incl. directions)\\nare used as features.\\n\\nExact details not specified, but based on code2vec we would have that the path (sequence of types, incl. directions) is the feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"separate pipeline for every path (ast, cfg, pdg) type\",\n        \"embedding layers for tokens and paths\",\n        \"concat start token, path, and end token embeddings\",\n        \"fnn\",\n        \"attention-weighted sum of path vectors\",\n        \"concatenate the three aggregated path vectors\",\n        \"(if necessary, softmax for prediction)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"method-name-prediction\": {\n      \"training-objective\": \"Given a method, predict its name (from a corpus of possible method names)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a method, predict its name (from a corpus of possible method names)\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Method name prediction\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + cfg + pdg\",\n      \"model\": \"model\",\n      \"task\": \"method-name-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-082\",\n  \"pdf-id\": \"sb-115\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"commit / diff + full files (old / new versions)\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": null,\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"methods from diff are extracted. AST is computed for old and new versions.\\nterminal to terminal paths in the ASTs are computed. Paths present \\nin both old and new version are discarded. \\nFor the terminal nodes, tokens are features. \\nThe path itself (sequence of types, interlaced with up/down directions) are also features (i.e. a full path is a single feature)\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Re-uses the pre-trained code2vec model and applies transfer learning. Rest of bullet points give the code2vec details.\",\n        \"embedding layers for tokens and paths\",\n        \"concat start token, path, and end token embeddings\",\n        \"fnn\",\n        \"attention-weighted sum of path vectors\",\n        \"(if necessary, softmax for prediction)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"security-commit-detection\": {\n      \"training-objective\": \"Given a commit (diff), determine whether it makes a security related fix or change\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a commit (diff), determine whether it makes a security related fix or change\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Security Patch Detection\",\n      \"supervision\": \"Supervised\"\n    },\n    \"method-name-prediction\": {\n      \"training-objective\": \"Given a method, predict its name (from a corpus of possible method names)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Model pre-training\",\n      \"supervision\": \"Supervised\"\n    },\n    \"priority-prediction\": {\n      \"training-objective\": \"Given a commit, predict the priority of its accompanying issue\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Model pre-training\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"method-name-prediction + security-commit-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"priority-prediction + security-commit-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"security-commit-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-042\",\n  \"pdf-id\": \"sb-063\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"file\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"code tokens embedded using GloVe\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified, but presumably adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"bug report is used as feature \\n\\nsource code text is used as a feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"embedding layer followed by bidirectional LSTM for bug report [shared]\",\n        \"gcn for graph [project specific]\",\n        \"cnn w/ pooling (not specified what method) for source code text [shared]\",\n        \"graph and text features are concatenated\",\n        \"relevance score through euclidean distance between bug embedding and source code embedding\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"adversarial-training\": {\n      \"training-objective\": \"!acts on the CNN output! \\n\\ndiscriminate what project the given source code (embedding) comes from.\\n\\nSpecifically, maximise the loss w.r.t. to the weights of an MLP attached to the CNN \\noutput, minimise loss w.r.t. the CNN weights.\\n\\nIntuition: the CNN should remove project-specific information,\\nwhile the MLP should retain that information.\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Pretraining\",\n      \"supervision\": \"supervised\"\n    },\n    \"bug-localisation\": {\n      \"training-objective\": \"Given a bug report and source file, determine if the bug occurs in the given file\",\n      \"training-granularity\": \"graph classification (but not quite)\",\n      \"working-objective\": \"Given a bug report, determine if the bug occurs in the given file\",\n      \"working-granularity\": \"graph classification (but not quite)\",\n      \"application\": \"Bug localisation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"adversarial-training + bug-localisation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-096\",\n  \"pdf-id\": \"sb-134\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"file (I think)\"\n        }\n      ],\n      \"vertex-type\": \"ast (only certain node types are kept)\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"not specified, though images imply type for nonterminals, and tokens for terminals\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"pre-order sequence of nodes, encoded using model-1, is used as input for model-2.\\n\\nHand-crafted detection-related features are used.\"\n    }\n  },\n  \"models\": {\n    \"model-1\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"cbow\"\n      ]\n    },\n    \"model-2\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"CNN w/ max pooling\",\n        \"hand-crafted features are concatenated with vectors extracted by the CNN\",\n        \"TCA\",\n        \"sigmoid\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"embedding\": {\n      \"training-objective\": \"Given the parent and child node, predict  the node itself\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"embedding\",\n      \"supervision\": \"self-supervised\"\n    },\n    \"defect-prediction\": {\n      \"training-objective\": \"Classify sample as  defective or not\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Classify sample as  defective or not\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"defect prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model-1 + model-2\",\n      \"task\": \"embedding + defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-124\",\n  \"pdf-id\": \"sb-175\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast/sub-tokens\",\n      \"edge-type\": \"ast/control flow/ncs/sibling/data flow\",\n      \"vertex-features\": \"node type (nonterminal), token (terminal); encoding not specified\",\n      \"edge-features\": \"edge type (presumably); encoding not specified\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"the source code (raw) is used as feature, encoded using CodeBERT \\n\\nsummary thus far is used as feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"GAT (w/ edge embedding)\",\n        \"modified transformer decoder; attention with  text and graph embeddings is computed separately, results are concatenated\",\n        \"copy mechanism\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code snippet, generate its summary\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a code snippet, generate its summary\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-056\",\n  \"pdf-id\": \"sb-082\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast (binarized)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"source code text is used as feature\"\n    },\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"statement\",\n      \"edge-type\": \"control flow\",\n      \"vertex-features\": \"encoded using doc2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified explicitly, presumably adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"source code text is used as feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"LSTM is used for source text\",\n        \"Tree-LSTM is used for AST\",\n        \"GCN is used for CF G\",\n        \"attention applied to all\",\n        \"Fusion (concat)\",\n        \"output manhatten distance\",\n        \"Siamese network (looks like it, though not stated explicitly)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"clone-detection\": {\n      \"training-objective\": \"Given two graphs, output what types of clones they are, or that they are not clones\",\n      \"training-granularity\": \"graph classification (kinda, two graph inputs)\",\n      \"working-objective\": \"Given two graphs, output what types of clones they are, or that they are not clones\",\n      \"working-granularity\": \"graph classification (kinda, two graph inputs)\",\n      \"application\": \"code clone detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + cfg\",\n      \"model\": \"model\",\n      \"task\": \"clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-065\",\n  \"pdf-id\": \"sb-092\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node type\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"byte code sequence \\n\\nsequence of identifiers and constants from the code\\n\\npre-order sequence of ast node types\"\n    },\n    \"cfg\": {\n      \"name\": \"cfg\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"statement\",\n      \"edge-type\": \"control flow\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"High-Order Proximity preserved Embedding (HOPE) for node embedding; then take average\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"sequence-model-1\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"RNN over tokens / words (training objective unclear)\"\n      ]\n    },\n    \"sequence-model-2\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"auto-encoder\",\n        \"used over encoded pairs of words (encoded using sequence-model-1); given n words, this results in n-1 encoded pairs; recursively keep encoding until one embedding is obtained\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"auto-encoding\": {\n      \"training-objective\": \"Reconstruct input embeddings\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"auto-encoding / embedding\",\n      \"supervision\": \"self-supervised\"\n    },\n    \"code-clone-detection\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given embeddings (variables, byte code, ast using sequence models, cfg using hope), concat embeddings, use euclidean distance to detect clones\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code Clone Detection\",\n      \"supervision\": \"n/a\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + cfg\",\n      \"model\": \"sequence-model-1 + sequence-model-2\",\n      \"task\": \"code-clone-detection + auto-encoding\",\n      \"comments\": \"training task for sequence-model-1 is not clearly specified\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-058\",\n  \"pdf-id\": \"sb-084\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast (binarised)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"leaf node content encoded using word2vec.\\n\\nnode types weighted using tf/idf\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"source code text\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"use bottom-up auto-encoder to learn node embeddings; learn representation for child nodes, use encoder output as parent embedding\",\n        \"final output is sum of the embeddings of all nodes, weighted according to the (normalised) tf/idf weights\",\n        \"detect clones using euclidean distance\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-clone-detection\": {\n      \"training-objective\": \"Given two code samples, determine if they are clones\",\n      \"training-granularity\": \"graph classification (but two graphs)\",\n      \"working-objective\": \"Given two code samples, determine if they are clones\",\n      \"working-granularity\": \"graph classification (but two graphs)\",\n      \"application\": \"Code clone detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code clone detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-055\",\n  \"pdf-id\": \"sb-081\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"text and type\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"embedding layers\",\n        \"TBCNN (output; tensor of shape num_nodes * D)\",\n        \"Capsule Layer (non-linear squash function)\",\n        \"Capsule Model for converting dynamically sized tensor to fixed size tensor\",\n        \"Capsule Module for Output\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-classification\": {\n      \"training-objective\": \"Classify sample (code) into one of multiple classes\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Classify sample (code) into of multiple classes\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"code classification\",\n      \"supervision\": \"supervised\"\n    },\n    \"method-name-prediction\": {\n      \"training-objective\": \"Predict a name for a function/method\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Predict a name for a function/method\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"method name prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-classification\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"method-name-prediction\",\n      \"comments\": \"yes, modelling this as a classification task is correct\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-085\",\n  \"pdf-id\": \"sb-118\",\n  \"graphs\": {\n    \"graph-1\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/data flow/ncs/function call/control flow\",\n      \"vertex-features\": \"not specified\",\n      \"edge-features\": \"edge type\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"graph-2\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"data flow/ncs/function call/control flow\",\n      \"vertex-features\": \"not specified\",\n      \"edge-features\": \"edge type\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"The regular AST is taken, and all connections are \\\"moved down\\\" to the leaf nodes;\\nnon-leaf nodes are removed.\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model-1\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"RNN\",\n        \"GGNN (Edge type specific)\",\n        \"RNN\",\n        \"these layers are not quite specific; the general idea is interleaving layers\",\n        \"pointer network\"\n      ]\n    },\n    \"model-2\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Transformer\",\n        \"GGNN (Edge type specific)\",\n        \"Transformer\",\n        \"these layers are not quite specific; the general idea is interleaving layers\",\n        \"pointer network\"\n      ]\n    },\n    \"model-3\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Transformer w/ attention based on connectivity (edge type specific; biases is added in attention computation based on linear layer)\",\n        \"pointer network\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"var-misuse\": {\n      \"training-objective\": \"Given a graph, generate 2 pointers, one to the variable occurrence with the wrong name, and 1 to _a_ occurrence of the correct variable name\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a graph, generate 2 pointers, one to the variable occurrence with the wrong name, and 1 to _a_ occurrence of the correct variable name\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Variable misuse correction/detection\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph-1\",\n      \"model\": \"model-1\",\n      \"task\": \"var-misuse\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph-1\",\n      \"model\": \"model-2\",\n      \"task\": \"var-misuse\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph-1\",\n      \"model\": \"model-3\",\n      \"task\": \"var-misuse\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph-2\",\n      \"model\": \"model-1\",\n      \"task\": \"var-misuse\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph-2\",\n      \"model\": \"model-2\",\n      \"task\": \"var-misuse\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"graph-2\",\n      \"model\": \"model-3\",\n      \"task\": \"var-misuse\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-106\",\n  \"pdf-id\": \"sb-146\",\n  \"graphs\": {\n    \"cdfg\": {\n      \"name\": \"Crucial Data Flow Graph\",\n      \"description\": \"subgraph of the data flow graph, which only contains vulnerability-related nodes\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"smart contracts\"\n        }\n      ],\n      \"vertex-type\": \"variable\",\n      \"edge-type\": \"data flow\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"mask matrix (?)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Input for the model is: [CLS] <Token Sequence> [SEP] <Variable Sequence>\\nwhere the token sequence is the sequence of source code tokens \\n(and their corresponding positions), and the variable sequence is the sequence of variables\\nin the graph (and their corresponding positions).\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"transformer encoder, where the attention is computed using a 0/\\\\infty mask matrix based on the input graph\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"masked-language-modelling\": {\n      \"training-objective\": \"Masked language modelling\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"model pre-training\",\n      \"supervision\": \"self-supervised\"\n    },\n    \"edge-prediction\": {\n      \"training-objective\": \"Given a graph with some edges masked, predict the missing edges between all unconnected variables (nodes)\",\n      \"training-granularity\": \"link prediction\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"model pre-training\",\n      \"supervision\": \"self-supervised\"\n    },\n    \"node-alignment\": {\n      \"training-objective\": \"Predict masked \\\"edges\\\" between variables and code tokens\",\n      \"training-granularity\": \"Kind of like link prediction, but the code tokens were never explicitly part of the graph -- simply matching code tokens to their occurrence in the graph sequence part of the input\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"model pre-training\",\n      \"supervision\": \"self-supervised\"\n    },\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Given a graph, classify it  as a vulnerability or not\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a graph, classify it  as a vulnerability or not\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"vulnerability detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cdfg\",\n      \"model\": \"model\",\n      \"task\": \"masked-language-modelling + edge-prediction + node-alignment + vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-097\",\n  \"pdf-id\": \"sb-135\",\n  \"graphs\": {\n    \"class-network\": {\n      \"name\": \"Class network\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"class\",\n      \"edge-type\": \"class dependencies (calling relations)\",\n      \"vertex-features\": \"1) Internal node features (e.g. number of methods in class)\\n2) External node features (e.g. out degree, centrality; classical non-global network metrics)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"lda\": {\n      \"name\": \"Linear Discriminant Analysis\",\n      \"architecture-attributes\": [\n        \"Linear Discriminant Analysis\"\n      ]\n    },\n    \"knn\": {\n      \"name\": \"K-Nearest Neighbors\",\n      \"architecture-attributes\": [\n        \"K-Nearest Neighbors\"\n      ]\n    },\n    \"dt\": {\n      \"name\": \"Decision Tree\",\n      \"architecture-attributes\": [\n        \"Decision Tree\"\n      ]\n    },\n    \"lr\": {\n      \"name\": \"Logistic Regression\",\n      \"architecture-attributes\": [\n        \"Logistic Regression\"\n      ]\n    },\n    \"rf\": {\n      \"name\": \"Random Forest\",\n      \"architecture-attributes\": [\n        \"Random Forest\"\n      ]\n    },\n    \"svm\": {\n      \"name\": \"Support Vector Machine\",\n      \"architecture-attributes\": [\n        \"Support Vector Machine\"\n      ]\n    },\n    \"adaboost\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Adaboost\",\n        \"base estimator -- CART classification tree\",\n        \"parameter algorithm -- SAMME.R\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"defect-prediction\": {\n      \"training-objective\": \"Classify node as defective or not\",\n      \"training-granularity\": \"node classification\",\n      \"working-objective\": \"Classify node as defective or not\",\n      \"working-granularity\": \"node classification\",\n      \"application\": \"Defect prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"class-network\",\n      \"model\": \"lda\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-network\",\n      \"model\": \"knn\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-network\",\n      \"model\": \"dt\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-network\",\n      \"model\": \"lr\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-network\",\n      \"model\": \"rf\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-network\",\n      \"model\": \"svm\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"class-network\",\n      \"model\": \"adaboost\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-018\",\n  \"pdf-id\": \"sb-026\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node content encoded using tf-idf / doc2vec (2 sets of experiments)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"cfg\": {\n      \"name\": \"cfg\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"statement\",\n      \"edge-type\": \"control flow\",\n      \"vertex-features\": \"node content encoded using tf-idf / doc2vec (2 sets of experiments)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"cdg\": {\n      \"name\": \"cdg (control dependence graph)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"statement\",\n      \"edge-type\": \"control dependence\",\n      \"vertex-features\": \"node content encoded using tf-idf / doc2vec (2 sets of experiments)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"ddg\": {\n      \"name\": \"ddg (data dependence graph)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"statement\",\n      \"edge-type\": \"data flow\",\n      \"vertex-features\": \"node content encoded using tf-idf / doc2vec (2 sets of experiments)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"gcn\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"gcn\",\n        \"sum pooling\",\n        \"fnn\"\n      ]\n    },\n    \"gat\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"gat\",\n        \"sum pooling\",\n        \"fnn\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"classify sample as vulnerable or not vulnerable\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"classify sample as vulnerable or not vulnerable\",\n      \"working-granularity\": \"graph  classification\",\n      \"application\": \"vulnerability detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cdg\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ddg\",\n      \"model\": \"gcn\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"gat\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"gat\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"cdg\",\n      \"model\": \"gat\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"ddg\",\n      \"model\": \"gat\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-004\",\n  \"pdf-id\": \"sb-006\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"token in AST nodes w/ sub-token splitting (embedding not specified)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"pre-order traversal. At every statement (composite) node, tree is split into sub-trees.\\n\\nCode is used as a feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"encoder/decoder architecture\",\n        \"transformer decoder w/ copy\",\n        \"recursive neural network for ast embedding (combine embeddings of parent and direct children until sub-tree is done; max pooling over nodes in subtree. Move to subtrees one level up)\",\n        \"code encoded using transformer encoder\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code sample, generate a summary\",\n      \"training-granularity\": \"x to sequence\",\n      \"working-objective\": \"Given a summary, generate a code sample\",\n      \"working-granularity\": \"x to sequence\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-067\",\n  \"pdf-id\": \"sb-094\",\n  \"graphs\": {\n    \"cfg\": {\n      \"name\": \"CFG\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"method\"\n        }\n      ],\n      \"vertex-type\": \"basic block (statement)\",\n      \"edge-type\": \"control flow\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"A matrix of features is associated with every method.\\nThree types of entities are present in the graph:\\n1) variables -- features: type, modifiers, additional info (3x one-hot)\\n2) basic blocks (relationship between variable and basic block) -- state: statement type (one-hot)\\n3) variable relationships in blocks [data flow]: 43D vector \\n\\n\\\"pilar\\\" A_{ij} in the feature matrix (actually a tensor) records the \\nrelationships between {block,variable}-i and {block,variable}-j;\\nthe contents in the pilar is either (1), (2), or (3), depending on the\\ntypes of i and j.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"MLP w/ dimensionality reductions and flattening\",\n        \"average pooling\",\n        \"concat both vectors in different orders, fnn, average pooling, softmax\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-clone-detection\": {\n      \"training-objective\": \"Given two code samples, determine if they are clones\",\n      \"training-granularity\": \"graph classification (but two graphs)\",\n      \"working-objective\": \"Given two code samples, determine if they are clones\",\n      \"working-granularity\": \"graph classification (but two graphs)\",\n      \"application\": \"Code clone detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"cfg\",\n      \"model\": \"model\",\n      \"task\": \"code-clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-117\",\n  \"pdf-id\": \"sb-164\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"method (s) (possibly multiple at once)\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"Statement corresponding to node encoded using GloVe\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"Buggy sub-tree is summarised using TreeCaps.\\n\\nFor training, each buggy sub-tree is replaced \\nwith its fixed sub-tree. The pairs of trees \\nare used for the context learning model.\\n\\nFor the working phase, each buggy tree is replaced with its \\nsummarised vector.\\n\\nWe call this the context tree\\n\\nEach node in a buggy sub-tree is multiplied by its context vector;\\nfor the old versions, this is the output of TreeCaps. For new versions,\\nthis is output of TreeCaps (training), or the predicted node from the \\ncontext model (working)\",\n      \"other-features\": \"Bug detector is used to collect buggy statements \\nand suspiciousness scores; consecutive statements are grouped into hunks.\\nBERT is used to determine which hunks must be fixed together.\\nOverall goal: given a function/method with multiple faulty statements (subtrees),\\nfix them all\"\n    }\n  },\n  \"models\": {\n    \"model-1\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"encoder/decoder architecture\",\n        \"encoder layer - child sum Tree-LSTM\",\n        \"attention layer\",\n        \"decoder layer - child sum Tree-LSTM\",\n        \"cycle training (backward mapping decoder -> attention -> encoder)\"\n      ]\n    },\n    \"model-2\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"encoder/decoder architecture\",\n        \"encoder layer - child sum Tree-LSTM\",\n        \"attention layer\",\n        \"decoder layer - child sum Tree-LSTM\",\n        \"cycle training (backward mapping decoder -> attention -> encoder)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"context-learning\": {\n      \"training-objective\": \"From the old (pre-fix) context tree, construct the new (post-fix) context tree (map node embeddings in old to node embeddings in new)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"from the old (pre-fix) context tree, predict the new (post-fix) context tree\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"n/a (auxiliary step)\",\n      \"supervision\": \"self-supervised\"\n    },\n    \"automated-program-repair\": {\n      \"training-objective\": \"Map weighted buggy sub-tree to fixed weighted sub-tree\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Map weighted buggy sub-tree to fixed weighted sub-tree\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"automated program repair\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model-1 + model-2\",\n      \"task\": \"context-learning + automated-program-repair\",\n      \"comments\": \"model-1 for context learning, model-2 for automated program repair.\\n\\nAfter the mapping (APR) phase, weights are removed and tree is used to generate code.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-102\",\n  \"pdf-id\": \"sb-140\",\n  \"graphs\": {\n    \"member-dependency-graph\": {\n      \"name\": \"Member Dependency Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"system\"\n        }\n      ],\n      \"vertex-type\": \"data item (eg shared variables) / function\",\n      \"edge-type\": \"call / return / data flow\",\n      \"vertex-features\": \"code level metrics\",\n      \"edge-features\": \"number of data items transferred in an edge\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"component-dependency-graph\": {\n      \"name\": \"Component Dependency Graph\",\n      \"description\": \"constructed from the member dependency graph; there exists an edge between two components if there exists an edge between two members from each component\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"system\"\n        }\n      ],\n      \"vertex-type\": \"component\",\n      \"edge-type\": \"dependency\",\n      \"vertex-features\": \"metrics describing the \\\"graph structure\\\" in a component (e.g. average internal data flow)\\n\\nsome code level metrics \\n\\nsome network metrics\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"bayesian-network\": {\n      \"name\": \"Bayesian Network\",\n      \"architecture-attributes\": [\n        \"Bayesian Network\"\n      ]\n    },\n    \"naive-bayes\": {\n      \"name\": \"Naive Bayes\",\n      \"architecture-attributes\": [\n        \"Naive Bayes\"\n      ]\n    },\n    \"neural-network\": {\n      \"name\": \"Neural Network\",\n      \"architecture-attributes\": [\n        \"Exact architecture unknown\"\n      ]\n    },\n    \"random-forest\": {\n      \"name\": \"Random Forest\",\n      \"architecture-attributes\": [\n        \"Random Forest\"\n      ]\n    },\n    \"svm\": {\n      \"name\": \"SVM\",\n      \"architecture-attributes\": [\n        \"SVM\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"defect-prediction\": {\n      \"training-objective\": \"Classify components as defective or non-defective\",\n      \"training-granularity\": \"node classification\",\n      \"working-objective\": \"Classify components as defective or non-defective\",\n      \"working-granularity\": \"node classification\",\n      \"application\": \"defect prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"member-dependency-graph + component-dependency-graph\",\n      \"model\": \"bayesian-network\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"member-dependency-graph + component-dependency-graph\",\n      \"model\": \"naive-bayes\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"member-dependency-graph + component-dependency-graph\",\n      \"model\": \"neural-network\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"member-dependency-graph + component-dependency-graph\",\n      \"model\": \"random-forest\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"member-dependency-graph + component-dependency-graph\",\n      \"model\": \"svm\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-009\",\n  \"pdf-id\": \"sb-012\",\n  \"graphs\": {\n    \"split-ast\": {\n      \"name\": \"Split AST\",\n      \"description\": \"First, the CFG is computed.\\nThen, the dominator tree of the CFG is computed.\\nFor every node with more than 2 outgoing edges, its outgoing edges are removed,\\nleading to groups of separate nodes. For every group of nodes, its AST \\nsubtree is computed. (alternative view: the AST is split up according to the graph described above)\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"Node type and value (concatenated)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Source code is used as feature\"\n    }\n  },\n  \"models\": {\n    \"model-1\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Siamese network (input; two AST sub-trees belonging to the same code sample)\",\n        \"child-sum tree-LSTM\",\n        \"Take outputs of the two root nodes, concatenate, sigmoid\"\n      ]\n    },\n    \"model-2\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Use pre-trained model-1 for graph encoding, apply average pooling over nodes\",\n        \"Source code embedded, combined with graph in FNN, positional encoding added\",\n        \"Transformer encoder\",\n        \"Transformer decoder\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"pre-training\": {\n      \"training-objective\": \"Given two sub-trees from the same code sample, predict which one comes first in the dominator tree\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"model pre-training\",\n      \"supervision\": \"supervised\"\n    },\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code sample, generate a summary\",\n      \"training-granularity\": \"x to sequence\",\n      \"working-objective\": \"Given a code sample, generate a summary\",\n      \"working-granularity\": \"x to sequence\",\n      \"application\": \"code summarization\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"split-ast\",\n      \"model\": \"model-1 + model-2\",\n      \"task\": \"pre-training + code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-076\",\n  \"pdf-id\": \"sb-169\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"module\",\n      \"edge-type\": \"data dependency/call dependency\",\n      \"vertex-features\": \"node level network metrics\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"graph level network metrics\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"logistic-regression\": {\n      \"name\": \"Logistic Regression\",\n      \"architecture-attributes\": [\n        \"logistic regression\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"fault-proneness-prediction\": {\n      \"training-objective\": \"Classify node as fault prone or not\",\n      \"training-granularity\": \"node classification\",\n      \"working-objective\": \"Classify node as fault prone or not\",\n      \"working-granularity\": \"node classification\",\n      \"application\": \"Fault Proneness Prediction\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"logistic-regression\",\n      \"task\": \"fault-proneness-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-083\",\n  \"pdf-id\": \"sb-116\",\n  \"graphs\": {\n    \"contextual-flow-graph\": {\n      \"name\": \"Contextual Flow Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"compiled to LLVM IR, which is used for graph construction\"\n        }\n      ],\n      \"vertex-type\": \"variables or label identifiers\",\n      \"edge-type\": \"data flow/data dependence/control flow\",\n      \"vertex-features\": \"values are replaced with their type, identifiers with a special marker\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Statement pairs <= N hops away are extracted from a set of graphs\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"skip gram model\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"embedding\": {\n      \"training-objective\": \"skip-gram training\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"embedding\",\n      \"supervision\": \"self-supervised\"\n    },\n    \"algorithm-classification\": {\n      \"training-objective\": \"Given an embedding, classify the program into a set of categories\",\n      \"training-granularity\": \"classification\",\n      \"working-objective\": \"Given an embedding, classify the program into a set of categories\",\n      \"working-granularity\": \"classification\",\n      \"application\": \"Algorithm classification\",\n      \"supervision\": \"supervised\"\n    },\n    \"compute-device-mapping\": {\n      \"training-objective\": \"Given an embedding, predict whether the program will run faster on CPU or GPU\",\n      \"training-granularity\": \"classification\",\n      \"working-objective\": \"Given an embedding, predict whether the program will run faster on CPU or GPU\",\n      \"working-granularity\": \"classification\",\n      \"application\": \"Compute device mapping\",\n      \"supervision\": \"supervised\"\n    },\n    \"thread-coarsening-factor-prediction\": {\n      \"training-objective\": \"Given an embedding, predict the thread coarsening factor\",\n      \"training-granularity\": \"regression\",\n      \"working-objective\": \"Given an embedding, predict the thread coarsening factor\",\n      \"working-granularity\": \"regression\",\n      \"application\": \"Thread coarsening factor prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"contextual-flow-graph\",\n      \"model\": \"model\",\n      \"task\": \"embedding + algorithm-classification\",\n      \"comments\": \"The method is supposed to be general, with the other tasks being example evaluations\"\n    },\n    {\n      \"graph\": \"contextual-flow-graph\",\n      \"model\": \"model\",\n      \"task\": \"embedding + compute-device-mapping\",\n      \"comments\": \"The method is supposed to be general, with the other tasks being example evaluations\"\n    },\n    {\n      \"graph\": \"contextual-flow-graph\",\n      \"model\": \"model\",\n      \"task\": \"embedding + thread-coarsening-factor-prediction\",\n      \"comments\": \"The method is supposed to be general, with the other tasks being example evaluations\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-100\",\n  \"pdf-id\": \"sb-138\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"file\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"AST is linearised (both types and tokens) using pre-order traversal,\\nwhere only certain node types are included in the sequence.\"\n    },\n    \"software-network\": {\n      \"name\": \"Software network\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"file (in project)\",\n      \"edge-type\": \"dependency or association\",\n      \"vertex-features\": \"vertices encoded using node2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"AST sequence as input\",\n        \"embedding layer\",\n        \"CNN\",\n        \"max pooling layer\",\n        \"fnn layer\",\n        \"for each file, the result of embedding the ast is concatenated to its corresponding node2vec embedding\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"defect-prediction\": {\n      \"training-objective\": \"Classify file as defective or not\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Classify file as defective or not\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Defect prediction\",\n      \"supervision\": \"n/a\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast + software-network\",\n      \"model\": \"model\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-119\",\n  \"pdf-id\": \"sb-167\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/control flow (might well be dependence; not a good distinction is made)/data dependence\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"weighted sum of the three adjacency matrices for the different edge types\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"code tokens are used as input\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"transformer (encoder/decoder)\",\n        \"attention based on graph connectivity (AQK^T in stead of QK^T); each attention layer has a normal attention component and graph attention component, which are summed\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a method, generate a summary\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a method, generate a summary\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-001\",\n  \"pdf-id\": \"sb-001\",\n  \"graphs\": {\n    \"name-graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Graph relation names of program variables\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"program\"\n        }\n      ],\n      \"vertex-type\": \"constants, properties, methods, globals\",\n      \"edge-type\": \"Relations (e.g. L += R, L < R where L = left, R = right; anything relating two names, essentially)/alias relation/may call/may access\",\n      \"vertex-features\": \"Program Element Names\",\n      \"edge-features\": \"Relation Type\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"type-graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Graph relation names of program variables\",\n      \"artefacts\": [\n        {\n          \"name\": \"Source code\",\n          \"details\": \"program\"\n        }\n      ],\n      \"vertex-type\": \"expressions, constants\",\n      \"edge-type\": \"Relations (e.g. L += R, L < R where L = left, R = right; anything relating two names, essentially)/alias relation/may call/may access\",\n      \"vertex-features\": \"data types associated with nodes\",\n      \"edge-features\": \"Relation Type\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Central model is a conditional random field P(y | x) = 1 / Z(x) \\\\exp(w^T f(y, x)), where f is some scoring function\",\n        \"w is learned using structured support vector machine on training set\",\n        \"inference of unknown properties using MAP (Maximum a Posteriori)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"name-prediction\": {\n      \"training-objective\": \"Learn weight matrix using SVM\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Predict names of unknown program elements\",\n      \"working-granularity\": \"node prediction\",\n      \"application\": \"name prediction\",\n      \"supervision\": \"supervised\"\n    },\n    \"type-inference\": {\n      \"training-objective\": \"Learn weight matrix using SVM\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Predict data types of unknown program elements\",\n      \"working-granularity\": \"node prediction\",\n      \"application\": \"type inference\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"name-graph\",\n      \"model\": \"model\",\n      \"task\": \"name-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"type-graph\",\n      \"model\": \"model\",\n      \"task\": \"type-inference\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-025\",\n  \"pdf-id\": \"sb-035\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"nodes encoded using continuous binary tree\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"tree-cnn\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"CNN over tree (e.g. triangular sliding window over tree, e.g. node + direct children)\",\n        \"pooling applied, but exact type not specified\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"program-classification\": {\n      \"training-objective\": \"Classify program into one of multiple classes based on functionality\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Classify program into one of multiple classes based on functionality\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"program classification\",\n      \"supervision\": \"supervised\"\n    },\n    \"bubble-sort-detection\": {\n      \"training-objective\": \"Detect if a program contains a bubble sort\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Detect if a program contains a bubble sort\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"program classification\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"tree-cnn\",\n      \"task\": \"program-classification\",\n      \"comments\": \"The method (the CNN specifically) is meant to be a general method, and the two tasks are example evaluation tasks\"\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"tree-cnn\",\n      \"task\": \"bubble-sort-detection\",\n      \"comments\": \"The method (the CNN specifically) is meant to be a general method, and the two tasks are example evaluation tasks\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-87\",\n  \"pdf-id\": \"sb-170\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"variable\",\n      \"edge-type\": \"data flow (values comes from; directed)\",\n      \"vertex-features\": \"variable name\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"comment (for function, e.g. javadoc) is used as feature\\n\\nfunction source is used as feature \\n\\ngraph is linearised and used as feature \\n\\nsequence starts with [CLS], the three parts are separated with [SEP]\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"multi-layer bidirectional transformer as base model\",\n        \"attention computed based on connectivity using mask matrix (M_{ij} = 0 for connected variable pairs, or if either q_i or k_j represents a comment or word token, -\\\\infty otherwise)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"masked-language-modelling\": {\n      \"training-objective\": \"Masked language modelling (as in BERT)\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"model pre-training\",\n      \"supervision\": \"self-supervised\"\n    },\n    \"edge-prediction\": {\n      \"training-objective\": \"Given samples with masked edges, predict which pairs of variables have missing edges\",\n      \"training-granularity\": \"Link prediction\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"model pre-training\",\n      \"supervision\": \"self-supervised\"\n    },\n    \"node-alignment\": {\n      \"training-objective\": \"Predict masked \\\"edges\\\" between variables and code tokens\",\n      \"training-granularity\": \"Kind of like link prediction, but the code tokens were never explicitly part of the graph -- simply matching code tokens to their occurrence in the graph sequence part of the input\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"model pre-training\",\n      \"supervision\": \"self-supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"masked-language-modelling + edge-prediction + node-alignment\",\n      \"comments\": \"I am not fully sure how the node alignment task works (on an input level); some part of the input is masked, but I do not fully understand how\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-130\",\n  \"pdf-id\": \"sb-181\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"method\"\n        }\n      ],\n      \"vertex-type\": \"all identifiers (incl. node types) are split into subtokens.\\nFor lexical nodes, both the type and token(s) are put in a sequence;\\nfor syntax nodes only the type\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": null,\n      \"edge-features\": null,\n      \"connectivity-features\": null,\n      \"graph-features\": null,\n      \"other-features\": \"code (w/ identifiers split into sub-tokens) is used as feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"Node features computed using CNN\",\n        \"code tokens encoded using bidirectional LSTM (concat states)\",\n        \"Tree-LSTM, followed by self-attention per node\",\n        \"attention-weighted sums of code token embeddings and ast node embeddings\",\n        \"pass previous output through FNN to compute p\",\n        \"Merge c_t = tanh(p * c_{ast} + (1 - p) * c_{code})\",\n        \"softmax(linear(c_t))\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a function, generate its summary\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a function, generate its summary\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-133\",\n  \"pdf-id\": \"sb-184\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"method\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"not clearly specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"encoder/decoder\",\n        \"Modified version of tree-LSTM which also takes order of children into account (\\\"multi-way Tree LSTM\\\")\",\n        \"attention weighted sum of node embeddings\",\n        \"LSTM decoder\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a function, generate its summary\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a function, generate its summary\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-089\",\n  \"pdf-id\": \"sb-121\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"node type and tokens are used as features\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"certain sub-trees are extracted from the AST based on node type. Note that these are used as \\\"labels\\\"; the full AST is used as input.\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"embedding matrices for node type and tokens; fused through linear layer\",\n        \"tree based CNN, but with attention-weighted summing for pooling\",\n        \"Predict probabilities of sub-trees\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"embedding\": {\n      \"training-objective\": \"For each sub-tree type, predict its probability of occurring in the full AST\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"embedding learning\",\n      \"supervision\": \"self-supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"embedding\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-059\",\n  \"pdf-id\": \"sb-085\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"code (token) payload according to a weighted sum of the one-hot encoding of its characters\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"tree based CNN (triangular filter), with weights computed according to continuous binary tree idea\",\n        \"max pooling\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-clone-detection\": {\n      \"training-objective\": \"Given two code samples, determine if they are clones\",\n      \"training-granularity\": \"graph classification (but two graphs)\",\n      \"working-objective\": \"Given two code samples, determine if they are clones\",\n      \"working-granularity\": \"graph classification (but two graphs)\",\n      \"application\": \"Code clone detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-clone-classification\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-127\",\n  \"pdf-id\": \"sb-178\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"source code text is used as feature \\n\\nTerminal to terminal (\\\"relative\\\") paths are extracted (only the nonterminals in the path are used)\\n\\nTerminal to root (\\\"absolute\\\") paths are extracted (only the nonterminals in the path are used)\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"transformer encoder/decoder architecture\",\n        \"Paths embedded using learnable embedding matrix\",\n        \"Paths encoded using bidirectional GRU\",\n        \"Integrate the last state of the bidirectional GRU over the path from token i to token j into attention score a_{ij}\",\n        \"Integrate the term (x_iW^Q)(x_jW^K)^T (where x_i is the output of the GRU for the absolute path of x_i to the root) into attention score a_{ij}\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a function, generate its summary\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a function, generate its summary\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": \"Actually, the paper tests three different schemes; using only relative paths, only absolute paths, and both\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-075\",\n  \"pdf-id\": \"sb-107\",\n  \"graphs\": {\n    \"socio-technical-network\": {\n      \"name\": \"Socio-Technical Network\",\n      \"description\": \"Directed graph\",\n      \"artefacts\": [\n        {\n          \"name\": \"version history information\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"developer/software component\",\n      \"edge-type\": \"contributed to (dev -> component)/contributed by (component -> dev)/depends on (component -> component)\",\n      \"vertex-features\": \"various local (node-level) network metrics (some of which use edge weights)\",\n      \"edge-features\": \"contributed to edge is weighted by the number of commits\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"various global network metrics\",\n      \"other-features\": \"n/a\"\n    },\n    \"dependency-network\": {\n      \"name\": \"Dependency Network\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"software component\",\n      \"edge-type\": \"contributed to (dev -> component)/contributed by (component -> dev)/depends on (component -> component)\",\n      \"vertex-features\": \"various local (node-level) network metrics (some of which use edge weights)\",\n      \"edge-features\": \"contributed to edge is weighted by the number of commits\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"various global network metrics\",\n      \"other-features\": \"n/a\",\n      \"edge type\": \"depends on\"\n    },\n    \"contribution-network\": {\n      \"name\": \"Contribution Network\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"version history information\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"developer/software component\",\n      \"edge-type\": \"contributed to (dev -> component)/contributed by (component -> dev)/depends on (component -> component)\",\n      \"vertex-features\": \"various local (node-level) network metrics (some of which use edge weights)\",\n      \"edge-features\": \"contribution is weighted by the number of commits\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"various global network metrics\",\n      \"other-features\": \"n/a\",\n      \"edge type\": \"contribution\"\n    }\n  },\n  \"models\": {\n    \"logistic-regression\": {\n      \"name\": \"Logistic Regression\",\n      \"architecture-attributes\": [\n        \"logistic regression\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"failure-prediction\": {\n      \"training-objective\": \"Predict which components are fault prone (large amount of bugs)\",\n      \"training-granularity\": \"node classification\",\n      \"working-objective\": \"Predict which components are fault prone (large amount of bugs)\",\n      \"working-granularity\": \"node classification\",\n      \"application\": \"Fault Proneness Prediction\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"socio-technical-network\",\n      \"model\": \"logistic-regression\",\n      \"task\": \"failure-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"dependency-network\",\n      \"model\": \"logistic-regression\",\n      \"task\": \"failure-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"contribution-network\",\n      \"model\": \"logistic-regression\",\n      \"task\": \"failure-prediction\",\n      \"comments\": null\n    },\n    {\n      \"graph\": \"contribution-network + dependency-network\",\n      \"model\": \"logistic-regression\",\n      \"task\": \"failure-prediction\",\n      \"comments\": \"metrics from both graphs are combined\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-011\",\n  \"pdf-id\": \"sb-018\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"field focussed graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"class\"\n        }\n      ],\n      \"vertex-type\": \"methods/fields/constructors/semantic relations (calls, reads, writes, sync, modifier)\",\n      \"edge-type\": \"method/fields/constructors are connected with undirected edges, with a semantic node inbetween them\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"several subgraphs are isolated, by taking all subsets of <= 2 methods/fields/constructors,\\nand extracting the subgraphs reachable from those nodes.\",\n      \"other-features\": \"Every subgraph is encoded using the  Weisfeiler Lehman kernel. \\nThe resulting vectors are combined by first computing three vectors through min/max/mean pooling,\\nand then concatenating these.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"SVM\",\n      \"architecture-attributes\": [\n        \"svm\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"thread-safe-detection\": {\n      \"training-objective\": \"Classify sample (class) as thread safe or not\",\n      \"training-granularity\": \"Graph classification\",\n      \"working-objective\": \"Classify sample (class) as thread safe or not\",\n      \"working-granularity\": \"Graph classification\",\n      \"application\": \"Thread Safety Inference for Automated Documentation Generation\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"thread-safe-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-015\",\n  \"pdf-id\": \"sb-022\",\n  \"graphs\": {\n    \"graph-1\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"repository\"\n        }\n      ],\n      \"vertex-type\": \"repository/token (frequently occurring source code tokens from malicious repositories)\",\n      \"edge-type\": \"source file in repository contains token\",\n      \"vertex-features\": \"node embeddings computed using deepwalk (random walk w/ skipgram)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    },\n    \"graph-2\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"repository\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"user/repository/file\",\n      \"edge-type\": \"user interactions (comment, fork, star, contribute)/repository has file\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"Various (eight) meta paths are used\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"DNN\",\n        \"The loss function includes information from the meta-paths,\\nwith the notion that for all pairs of repositories i, j, the \\nprobability of repository i being malicious should be greater \\nthan the probability of repository j being malicious,\\nif and only if i scores higher on some meta-path based scoring \\ncriteria than j. Specifically, every meta path is (roughly)\\npositively correlated with a repository being malicious.\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"malicious-repository-detection\": {\n      \"training-objective\": \"Classify repositories as malicious or not\",\n      \"training-granularity\": \"node classification\",\n      \"working-objective\": \"Classify repositories as malicious or not\",\n      \"working-granularity\": \"node classification\",\n      \"application\": \"malicious repository detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph-1 + graph-2\",\n      \"model\": \"model\",\n      \"task\": \"malicious-repository-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-072\",\n  \"pdf-id\": \"sb-102\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/ncs\",\n      \"vertex-features\": \"node type one-hot\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"gin (multiple layers; take the average of the max-pool over each layer)\",\n        \"graph embedding fed into LSTM network together with previous hidden state (which represent edit history); used to compute edit type and location\",\n        \"second LSTM (c = LSTM(edit type, LSTM(edit location, history))) to compute embedding used for value or type prediction\",\n        \"pointer network for edit location prediction\",\n        \"value for leaf node predicted using attention mechanism; either copy from local or global dictionary\",\n        \"softmax to assign types for nonterminal nodes\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"program-repair\": {\n      \"training-objective\": \"Given a buggy program (as graph), output a series of graph transformations that result in the graph of a fixed program\",\n      \"training-granularity\": \"graph to sequence [of edit operations]\",\n      \"working-objective\": \"Given a fixed program (as graph), output a series of graph transformations that result in the graph of a buggy program\",\n      \"working-granularity\": \"graph to sequence [of edit operations]\",\n      \"application\": \"Program repair\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"program-repair\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-052\",\n  \"pdf-id\": \"sb-074\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"Based on graphs in recommendation systems\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"multiple files/project\"\n        }\n      ],\n      \"vertex-type\": \"method declarations/APIs/structural (classes, packages, non-method stuff)\",\n      \"edge-type\": \"method <-> API calls/project structure  (e.g. belongs to)\",\n      \"vertex-features\": \"method/class/package name split up into words\\n\\nunique ID per node\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"embedding layer\",\n        \"GRU on node features (per node); attention-weighted sum of hidden states\",\n        \"GCN-based mechanism (similar to `6.yaml`); Compute aggregated embedding of neighbours, add to own embedding, apply ReLU\",\n        \"readout by concatenating all hidden states in successive GCN layers per node and applying FNN\",\n        \"Similarity through dot product\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"api-recommendation\": {\n      \"training-objective\": \"Maximise similarity of seen method <-> API examples; minimise similarity of unseen combinations\",\n      \"training-granularity\": \"link prediction\",\n      \"working-objective\": \"Find similar method and API nodes for API recommendation\",\n      \"working-granularity\": \"link prediction\",\n      \"application\": \"API recommendation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"api-recommendation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-049\",\n  \"pdf-id\": \"sb-071\",\n  \"graphs\": {\n    \"labelled-pushdown-system\": {\n      \"name\": \"Labelled pushdown system\",\n      \"description\": \"Inter-procedural control flow of a program modelled as a pushdown system,\\nwhere each rule has a label, which are concatenated as the machine makes \\nits transitions.\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"state\",\n      \"edge-type\": \"transition\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"labels (for instruction category, error code,struct type, functions)\",\n      \"connectivity-features\": \"Not specified\",\n      \"graph-features\": \"Perform random walks over the graph, and collect the sequence of labels\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"cbow\": {\n      \"name\": null,\n      \"architecture-attributes\": [\n        \"word2vec model applied on the label sequences\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"cbow\": {\n      \"training-objective\": \"Predict a label, given its context\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"n/a\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Embedding learning\",\n      \"supervision\": \"unsupervised (self-supervised)\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"labelled-pushdown-system\",\n      \"model\": \"cbow\",\n      \"task\": \"cbow\",\n      \"comments\": \"generic embedding learning system. The paper applies it in particular for error handling specification mining\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-051\",\n  \"pdf-id\": \"sb-073\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"based on AST, but with abstracted/less information\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"API call/control unit/variable declaration/assignment\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"not clearly specified, but seems to be node content (type for control unit; tokens for the others)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Generated statements _without variables_ are ranked based on classifier confidence,\\nand a score computed based on a (non ML) data flow analysis of the graph,\\nwhich intuitively measures whether the variables in the statements \\nmake sense, given the graph full training corpus, \\nis used to fill in the names of the variables.\"\n    }\n  },\n  \"models\": {\n    \"statement-model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"embedding layer\",\n        \"child-sum tree-LSTM adapted to handle an arbitrary number of children\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"api-recommendation\": {\n      \"training-objective\": \"Given a piece of code with some API usage, predict the next API usage\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a piece of code with some API usage, recommend the next API usage\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"API Recommendation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"statement-model\",\n      \"task\": \"api-recommendation\",\n      \"comments\": \"The code completion is really simple; only a single API (e.g. no nesting),\\npossibly wrapped in a control structure.\\n\\nThe paper does not mention _how_ the API is recommended; it is totally unclear \\nhow the actual code is generated.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-109\",\n  \"pdf-id\": \"sb-149\",\n  \"graphs\": {\n    \"code-property-graph\": {\n      \"name\": \"Code Property Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"function\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/control flow/control dependence/data dependence\",\n      \"vertex-features\": \"1) node type one hot \\n2) operator type one hot \\n3) used API functions, binary encoding \\n4) float and integer literals are included as their 32 bit representation \\n5) type of variables are included, one-hot encoded\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"gat\",\n        \"SAGPool\",\n        \"MLP\",\n        \"softmax\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable or not\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Classify sample as vulnerable or not\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"vulnerability detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-013\",\n  \"pdf-id\": \"sb-020\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"AST linearised through pre-order traversal. (node types for internal, payload for leafs)\\n\\nTwo matrices are extracted:\\n  1) Shortest path distance matrix where M_{ij} denotes the signed length of the shortest path between node i and j, provided it is less than some threshold p ($\\\\infty$ otherwise)\\n  2) Sibling distance matrix where M_{ij} denotes the signed distance between siblings i and j. $\\\\infty$ if exceeding some threshold\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"transformer encoder/decoder with modified attention mechanism\",\n        \"The attention mechanism incorporates the information from the two matrices (see paper for details)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a code sample, generate a summary\",\n      \"training-granularity\": \"x to sequence\",\n      \"working-objective\": \"Given a code sample, generate a summary\",\n      \"working-granularity\": \"x to sequence\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-122\",\n  \"pdf-id\": \"sb-173\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"method\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/control flow/data dependence\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"weighted sum of adjacency matrices (A)\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"source code is used as feature \\n\\nshortest path length matrix is used as feature (normalised) (M)\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"transformer encoder/decoder setup\",\n        \"encoder with special encoder modules:\\n\\nsource code into mostly traditional transformer encoder layer.\\nHowever, input is transformed according to \\\\sigma(FC(H) + FC(MH)), where M is the normalised shorts path length matrix\\n\\noutput of this first layer is fed into parallel second layer, which is an transformer encoder layer\\nusing graph-connection based attention (AQK^T) (uses the summed _adjacency matrices_)\\n\\noutput of the two is concatenated`\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a method, generate a summary\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a method, generate a summary\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-120\",\n  \"pdf-id\": \"sb-168\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"method\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"code text is used as feature\\n\\nsummary thus far is used as feature\\n\\nast is converted to sequence, where brackets are used \\nto keep structure, node name is used primarily, and lexical\\nelements are added to the node name, like in \\\"SimpleName_String\\\"\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"encoder/decoder with 2 encoders\",\n        \"embedding layer and GRU (separate) for every sequence\",\n        \"the ast and code sequences are combined with the summary sequence (both separately) in attention layer\",\n        \"Concat, FNN\",\n        \"softmax for word prediction\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a method, generate a summary\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a method, generate a summary\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-110\",\n  \"pdf-id\": \"sb-151\",\n  \"graphs\": {\n    \"code-property-graph\": {\n      \"name\": \"Code Property Graph\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": null\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/control flow/control dependence/data dependence\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"Features are represented as a 3D tensor, where the first two dimensions \\nrepresent nodes, and the third dimension represents features describing\\nthe relation between the two nodes.\\n\\nThese features include data type/modifier information,\\noperators between the two nodes, the parent child relationship between the two nodes (i.e. is_parent(i, e), with a one-hot entry for the node type of the child),\\ncontrol flow node information.\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"MLP and flatten to reduce dimensionality and map tensor to a matrix of feature vectors per node\",\n        \"Soft attention (implemented using 1D convolutions)\",\n        \"MLP\",\n        \"softmax\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"vulnerability detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"code-property-graph\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-128\",\n  \"pdf-id\": \"sb-179\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"methods\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"type and value of nodes, encoded using BERT\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"source code tokens used as feature\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"encoder/decoder\",\n        \"GCN w/ residual connections, where each GCN uses a higher power of the adjacency matrix (A, A^2, etc)\",\n        \"weighted sum of GCN outputs\",\n        \"node embedding matrix enriched with positional encoding, inputted into transformer encoder, get AST features\",\n        \"code tokens into transformer encoder\",\n        \"1DConv over ast and code features; combine using attention; add to the original outputs from the GCN module\",\n        \"transformer decoder; 1st attention blocks uses code features, the next one the summed features\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-summarization\": {\n      \"training-objective\": \"Given a function, generate its summary\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a function, generate its summary\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"Code summarization\",\n      \"supervision\": \"Supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-114\",\n  \"pdf-id\": \"sb-160\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"linearised using depth first traversal, \\nyielding a stream of node types and code tokens.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"embedding layer\",\n        \"bidirectional LSTM\",\n        \"max pooling\",\n        \"MLP\",\n        \"sigmoid\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"vulnerability-detection\": {\n      \"training-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Classify sample as vulnerable or not vulnerable\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"vulnerability detection\",\n      \"supervision\": \"n/a\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"vulnerability-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-115\",\n  \"pdf-id\": \"sb-161\",\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"AST Graph\",\n      \"description\": \"generated from the code to be repaired, with a faulty statement located through e.g. a fault localisation model\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"method\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast/direct left sibling\",\n      \"vertex-features\": \"n/a\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"The AST (sub-)structure is traversed (pre-order),\\nand two sequences are created:\\n  1) word2vec encoded sequence of nodes \\n  2) the corresponding tagging sequence, where each tag denotes whether the current statement\\n      belongs to the fault statement, the statement before the faulty statement,\\n      the statement after the faulty statement, or another statement.\"\n    },\n    \"partial-ast\": {\n      \"name\": \"AST (partial)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"n/a\",\n          \"details\": \"generated by model\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": null,\n      \"edge-features\": null,\n      \"connectivity-features\": \"adjacency matrix\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"Sequence of rules used to generate the AST, encoded as real vectors.\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"AST node sequence, enriched with positional encoding, is encoded using multi-head self attention\",\n        \"Gating mechanism (TreeGen) is applied to attention output, based on tagging sequence\",\n        \"GCN based on ast graph is applied to output of gated mechanism\",\n        \"rule sequence into multi-head self-attention\",\n        \"AST Reader with blocks with the following structure; (input is rule sequence) |- 1) Self-attention 2) gating mechanism 3) Attention w/ NL query 4)  GCN based on ast graph is applied to output of gated mechanism\",\n        \"Tree path reader with following structure' |- 1) Attention w/ AST 2) Attention with code 3) FNN\",\n        \"Decoder which computed three different actions based on tree path encoder output; |- 1) Generate next expansion (softmax) 2) Propose tree to be copied (pointer network) 3) Propose modification to existing node (pointer)\\nA decider component (which also takes tree path reader as input) decides which computed action to use\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"automated-code-repair\": {\n      \"training-objective\": \"Given a snippet with a faulty statement, generate an AST with the correct code\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Given a snippet with a faulty statement, generate an AST with the correct code\",\n      \"working-granularity\": \"n/a\",\n      \"application\": \"automated code repair\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph + partial-ast\",\n      \"model\": \"model\",\n      \"task\": \"automated-code-repair\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-103\",\n  \"pdf-id\": \"sb-142\",\n  \"graphs\": {\n    \"class-dependency-network\": {\n      \"name\": \"Class Dependency Network\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"class\",\n      \"edge-type\": \"class/interface relationships\",\n      \"vertex-features\": \"nodes are embedded using node2vec.\\n\\nTraditional software engineering metrics (e.g. CBO) are used as features.\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"random-forest\": {\n      \"name\": \"Random Forest\",\n      \"architecture-attributes\": [\n        \"Random Forest\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"defect-prediction\": {\n      \"training-objective\": \"Classify node as buggy or not\",\n      \"training-granularity\": \"node classification\",\n      \"working-objective\": \"Classify node as buggy or not\",\n      \"working-granularity\": \"node classification\",\n      \"application\": \"defect prediction\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"class-dependency-network\",\n      \"model\": \"random-forest\",\n      \"task\": \"defect-prediction\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-038\",\n  \"pdf-id\": \"sb-057\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"ast\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"Node content (Nonterminal, with payload for leave nodes)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"depth-first traversal of AST, while inserting brackets (<, >) to denote subtrees\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"probably embedding layer\",\n        \"LSTM with stack; hidden states are pushed and popped to a stack based on brackets (<, >)\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-completion\": {\n      \"training-objective\": \"Complete the given code\",\n      \"training-granularity\": \"graph to sequence\",\n      \"working-objective\": \"Complete the given code\",\n      \"working-granularity\": \"graph to sequence\",\n      \"application\": \"code completion\",\n      \"supervision\": \"supervised\"\n    },\n    \"program-classification\": {\n      \"training-objective\": \"classify a program into one of the given classes\",\n      \"training-granularity\": \"graph classification\",\n      \"working-objective\": \"classify a program into one of the given classes\",\n      \"working-granularity\": \"graph classification\",\n      \"application\": \"program classification\",\n      \"supervision\": \"supervised\"\n    },\n    \"code-summarization\": {\n      \"training-objective\": \"generate a summary for the given code\",\n      \"training-granularity\": \"graph to sequence\",\n      \"working-objective\": \"generate a summary for the given code\",\n      \"working-granularity\": \"graph to sequence\",\n      \"application\": \"code summarization\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-completion\",\n      \"comments\": \"the framework (stack based LSTM) is meant to be general; the tasks are merely example evaluation tasks.\"\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"program-classification\",\n      \"comments\": \"the framework (stack based LSTM) is meant to be general; the tasks are merely example evaluation tasks.\"\n    },\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-summarization\",\n      \"comments\": \"the framework (stack based LSTM) is meant to be general; the tasks are merely example evaluation tasks.\"\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-041\",\n  \"pdf-id\": \"sb-062\",\n  \"graphs\": {\n    \"knowledge-graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"project\"\n        }\n      ],\n      \"vertex-type\": \"class/property/method/parameter/variable\",\n      \"edge-type\": \"inheritance/has (class has property, class has method, method has parameter, method has variable)/instance_of/return_type/call\",\n      \"vertex-features\": \"see graph features\",\n      \"edge-features\": \"see graph features\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"knowledge graph is embedded using one of: TransE, TransH, TransR.\\nidea: every (source, edge, tail) triple should have encodings (h, r, t) such that h + r \\\\approx t\",\n      \"other-features\": \"bug report used as feature, encoded using word2vec \\n\\ncode text used as feature, encoded using word2vec\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"rnn w/ max pooling for bug report\",\n        \"cnn w/ max pooling for code text\",\n        \"cross-attention for cnn and rnn output\",\n        \"add two attention vectors with corresponding node embedding from knowledge graph\",\n        \"fnn w/ output\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"bug-localisation\": {\n      \"training-objective\": \"Predict if given bug occurs in the given file\",\n      \"training-granularity\": \"graph classification (kinda not quite)\",\n      \"working-objective\": \"Predict if given bug occurs in the given file\",\n      \"working-granularity\": \"graph classification (kinda not quite)\",\n      \"application\": \"bug localisation\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"knowledge-graph\",\n      \"model\": \"model\",\n      \"task\": \"bug-localisation\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-037\",\n  \"pdf-id\": \"sb-055\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"pairs of source code for training (diff)\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast (bidirectional) / siblings\",\n      \"vertex-features\": \"not specified\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"sequence of edit actions to transform first AST into the other\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"encoder/decoder\",\n        \"Edits encoded using embedding layers; fed into bidirectional LSTM to get representation of the full edit as single vector\",\n        \"encoder - GGNN w/ average pooling; LSTM over pooling outputs to capture edit history of the tree; LSTM also takes as input edit representation\",\n        \"decoder; softmax for action selection, pointer-like network for node selection implemented using FNN, value selector/predictor using FNN for add and copy operations\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-editing\": {\n      \"training-objective\": \"Given a tree and edit sequence, transform the tree into the other\",\n      \"training-granularity\": \"x to tree\",\n      \"working-objective\": \"Given a tree and edit sequence, transform the tree into the other\",\n      \"working-granularity\": \"x to tree\",\n      \"application\": \"program edit representation learning\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-editing\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": null,\n  \"pdf-id\": null,\n  \"graphs\": {\n    \"graph\": {\n      \"name\": \"n/a\",\n      \"description\": \"bipartite network\",\n      \"artefacts\": [\n        {\n          \"name\": \"github repositories\",\n          \"details\": \"n/a\"\n        },\n        {\n          \"name\": \"github user data\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"repositories/users\",\n      \"edge-type\": \"contributes\",\n      \"vertex-features\": \"for users: potential passwords/keys, occurrences of string \\\"password\\\" in a file, sensitive filetypes.\\n\\nfor repos: vulnerability type(s) detected by scanner tool (secret leakage, classical vulnerabilities such as sql, etc.)\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"n/a\",\n      \"graph-features\": \"The bipartite network is projected into two mono-partite networks (user network and repo network)\\n\\nGraphs are encoded using text associated deep walk\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"K-means clustering\",\n      \"architecture-attributes\": [\n        \"k means\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"clustering\": {\n      \"training-objective\": \"n/a\",\n      \"training-granularity\": \"n/a\",\n      \"working-objective\": \"Cluster nodes together\",\n      \"working-granularity\": \"graph clustering\",\n      \"application\": \"identification of groups of vulnerable repositories and users (proactively identify vulnerable communities)\",\n      \"supervision\": \"unsupervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"graph\",\n      \"model\": \"model\",\n      \"task\": \"clustering\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "model$node"
    },
    {
      "action": "refine",
      "old": "{\n  \"paper-id\": \"sb-061\",\n  \"pdf-id\": \"sb-087\",\n  \"graphs\": {\n    \"ast\": {\n      \"name\": \"AST (binarized)\",\n      \"description\": \"n/a\",\n      \"artefacts\": [\n        {\n          \"name\": \"source code\",\n          \"details\": \"n/a\"\n        }\n      ],\n      \"vertex-type\": \"ast\",\n      \"edge-type\": \"ast\",\n      \"vertex-features\": \"tokens word2vec\",\n      \"edge-features\": \"n/a\",\n      \"connectivity-features\": \"not specified\",\n      \"graph-features\": \"n/a\",\n      \"other-features\": \"n/a\"\n    }\n  },\n  \"models\": {\n    \"model\": {\n      \"name\": \"n/a\",\n      \"architecture-attributes\": [\n        \"tree-based LSTM (sums over child nodes)\",\n        \"siamese\"\n      ]\n    }\n  },\n  \"tasks\": {\n    \"code-clone-detection\": {\n      \"training-objective\": \"Given two code samples, determine if they are clones\",\n      \"training-granularity\": \"graph classification (but two graphs)\",\n      \"working-objective\": \"Given two code samples, determine if they are clones\",\n      \"working-granularity\": \"graph classification (but two graphs)\",\n      \"application\": \"Code clone detection\",\n      \"supervision\": \"supervised\"\n    }\n  },\n  \"combinations\": [\n    {\n      \"graph\": \"ast\",\n      \"model\": \"model\",\n      \"task\": \"code-clone-detection\",\n      \"comments\": null\n    }\n  ],\n  \"comments\": null\n}",
      "new": "n/a"
    },
    {
      "action": "n-ary-split",
      "old": "greedy-cluster$node@mc-cluster$node",
      "new": [
        "greedy-cluster$node",
        "mc-cluster$node"
      ]
    },
    {
      "action": "n-ary-split",
      "old": "cluster-1$node@cluster-4$node@cluster-11$node@cluster-9$node@cluster-3$node@cluster-7$node@cluster-8$node@cluster-2$node@cluster-5$node@cluster-6$node@cluster-10$node",
      "new": [
        "cluster-1$node",
        "cluster-4$node",
        "cluster-11$node",
        "cluster-9$node",
        "cluster-3$node",
        "cluster-7$node",
        "cluster-8$node",
        "cluster-2$node",
        "cluster-5$node",
        "cluster-6$node",
        "cluster-10$node"
      ]
    },
    {
      "action": "refine",
      "old": "model$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "cluster-8$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "cluster$graph",
      "new": "graph"
    },
    {
      "action": "refine",
      "old": "mc-cluster$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "cluster-4$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "cluster-3$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "clustering$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "cluster-1$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "cluster-7$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "clustering$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "cluster-10$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "cluster-5$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "cluster-6$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "cluster-9$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "cluster-11$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "cluster-2$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "cluster$node",
      "new": "node"
    },
    {
      "action": "refine",
      "old": "greedy-cluster$node",
      "new": "node"
    }
  ]
}