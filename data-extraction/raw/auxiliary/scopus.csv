Authors,Author full names,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Abstract,References,Sponsors,Conference name,Conference date,Conference location,Conference code,Language of Original Document,Document Type,Publication Stage,Open Access,Source,EID,Paper ID
Mi Q.; Zhan Y.; Weng H.; Bao Q.; Cui L.; Ma W.,"Mi, Qing (57190229579); Zhan, Yi (58592112200); Weng, Han (58285483100); Bao, Qinghang (58285431300); Cui, Longjie (58285222400); Ma, Wei (56591126600)",57190229579; 58592112200; 58285483100; 58285431300; 58285222400; 56591126600,A graph-based code representation method to improve code readability classification,2023,Empirical Software Engineering,28,4,87,,,,1,10.1007/s10664-023-10319-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160003449&doi=10.1007%2fs10664-023-10319-6&partnerID=40&md5=123f5324dfc79038a0d3244e8c791cab,"Context: Code readability is crucial for developers since it is closely related to code maintenance and affects developers’ work efficiency. Code readability classification refers to the source code being classified as pre-defined certain levels according to its readability. So far, many code readability classification models have been proposed in existing studies, including deep learning networks that have achieved relatively high accuracy and good performance. Objective: However, in terms of representation, these methods lack effective preservation of the syntactic and semantic structure of the source code. To extract these features, we propose a graph-based code representation method. Method: Firstly, the source code is parsed into a graph containing its abstract syntax tree (AST) combined with control and data flow edges to reserve the semantic structural information and then we convert the graph nodes’ source code and type information into vectors. Finally, we train our graph neural networks model composing Graph Convolutional Network (GCN), DMoNPooling, and K-dimensional Graph Neural Networks (k-GNNs) layers to extract these features from the program graph. Result: We evaluate our approach to the task of code readability classification using a Java dataset provided by Scalabrino et al. (2016). The results show that our method achieves 72.5% and 88% in three-class and two-class classification accuracy, respectively. Conclusion: We are the first to introduce graph-based representation into code readability classification. Our method outperforms state-of-the-art readability models, which suggests that the graph-based code representation method is effective in extracting syntactic and semantic information from source code, and ultimately improves code readability classification. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Alawad D.M., Panta M., Zibran M.F., An empirical study of the relationships between code readability and software complexity., (2019); Allamanis M., Barr E.T., Sutton C., Learning natural coding conventions, Proceedings of the 22Nd ACM SIGSOFT International Symposium on Foundations of Software Engineering, (2014); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs., (2018); Alon U., Zilberstein M., Levy O., A general path-based representation for predicting program properties., (2018); Brunner E., Munzel U., The nonparametric behrens-fisher problem: Asymptotic theory and a small-sample approximation, Biom J, 42, pp. 17-25, (2000); Buse R., Weimer W., Learning a metric for code readability, Softw Eng IEEE Trans, 36, pp. 546-558, (2010); Cao S., Sun X., Bo L., Et al., Bgnn4vd: Constructing bidirectional graph neural-network for vulnerability detection, Inf Softw Technol, 136, (2021); Devlin J., Chang M.W., Lee K., Bert: Pre-training of deep bidirectional transformers for language understanding., (2018); Dinella E., Dai H., Li Z., Naik M., Song L., Wang K., Hoppity: Learning graph transformations to detect and fix bugs in programs, International Conference on Learning Representations., (2020); Dorn J., A General Software Readability Model, 5, pp. 11-14, (2012); Fakhoury S., Roy D., Hassan S.A., Et al., Improving source code readability: Theory and practice, 2019 IEEE/ACM 27Th International Conference on Program Comprehension (ICPC), pp. 2-12, (2019); Feng Z., Guo D., Tang D., Codebert: A Pre-Trained Model for Programming and Natural Languages. Arxiv Preprint Arxiv, 2002, (2020); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, In: 7Th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. Openreview.Net., (2019); Gilmer J., Schoenholz S.S., Riley P.F., Neural message passing for quantum chemistry., (2017); Hindle A., Barr E.T., Su Z., Et al., On the naturalness of software, 2012 34th International Conference on Software Engineering (ICSE), pp. 837-847, (2012); Hu Z., Dong Y., Wang K., Heterogeneous graph transformer, WWW ’20: The Web Conference 2020, pp. 2704-2710, (2020); Johnson J., Lubo S., Yedla N., Et al., An empirical study assessing source code readability in comprehension, 2019 IEEE International conference on software maintenance and evolution (ICSME), pp. 513-523, (2019); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks. Arxiv Preprint Arxiv, 1609, (2016); Leclair A., Haque S., Wu L.L., Et al., Improved code summarization via a graph neural network, Proceedings of the 28Th International Conference on Program Comprehension, (2020); Lee T., Lee J.B., In H., A study of different coding styles affecting code readability, Int J Softw Eng Appl, 7, pp. 413-422, (2013); Ling C., Huang J., Zhang H., Auc: A statistically consistent and more discriminating measure than accuracy, In: Proc 18Th Int’l Joint Conf Artificial Intelligence (IJCAI), (2003); Li Y., Tarlow D., Brockschmidt M., Gated graph sequence neural networks, 4Th International Conference on Learning Representations, ICLR 2016, (2016); Maddison C.J., Tarlow D., Structured generative models of natural source code, (2014); Mannan U.A., Ahmed I., Sarma A., Towards understanding code readability and its impact on design quality, Proceedings of the 4Th ACM SIGSOFT International Workshop on NLP for Software Engineering, pp. 18-21, (2018); Ma Y., Wang S., Aggarwal C.C., Et al., Graph convolutional networks with eigenpooling, In: Proceedings of the 25Th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining., pp. 723-731, (2019); Mi Q., Keung J., Xiao Y., Et al., Improving code readability classification using convolutional neural networks, Inf Softw Technol, 104, (2018); Mi Q., Hao Y., Ou L., Ma W., Towards using visual, semantic and structural features to improve code readability classification, J Syst Softw, 193, (2022); Mi Q., Hao Y., Wu M., An enhanced data augmentation approach to support multi-class code readability classification, International Conference on Software Engineering and Knowledge Engineering, (2022); Morris C., Ritzert M., Fey M., Et al., Weisfeiler and leman go neural: Higher-order graph neural networks, Proceedings of the AAAI conference on artificial intelligence, pp. 4602-4609, (2019); Pantiuchina J., Lanza M., Bavota G., Improving code: The (mis) perception of quality metrics, 2018 IEEE international conference on software maintenance and evolution (ICSME), pp. 80-91, (2018); Piantadosi V., Fierro F., Scalabrino S., Et al., How does code readability change during software evolution?, Empir Softw Eng, 25, pp. 5374-5412, (2020); Posnett D., Hindle A., Devanbu P., A simpler model of software readability, Proceedings of the 8Th Working Conference on Mining Software Repositories, pp. 73-82, (2011); Raychev V., Bielik P., Vechev M.T., Probabilistic model for code with decision trees, Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2016, Part of SPLASH 2016, Amsterdam, the Netherlands, October 30 - November 4, 2016. ACM, pp. 731-747, (2016); Scalabrino S., Linares-Vasquez M., Oliveto R., A comprehensive model for code readability, J Softw Evol Process, 30, (2018); Scalabrino S., Linares-Vasquez M., Poshyvanyk D., Et al., Improving code readability models with textual features, In: 2016 IEEE 24Th International Conference on Program Comprehension (ICPC), IEEE, pp. 1-10, (2016); Sedano T., Code readability testing, an empirical study, 2016 IEEE 29th International conference on software engineering education and training (CSEET), pp. 111-117, (2016); Tsitsulin A., Palowitch J., Perozzi B., Graph clustering with graph neural networks, Arxiv Preprint Arxiv, 2006, (2020); Vagavolu D., Swarna K.C., Chimalakonda S., A mocktail of source code representations, 2021 36th IEEE/ACM International conference on automated software engineering (ASE), pp. 1296-1300, (2021); Wang X., Ji H., Shi C., Heterogeneous graph attention network, The World Wide Web Conference, pp. 2022-2032, (2019); Wang W., Li G., Ma B., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, 27Th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2020, pp. 261-271, (2020); Wang W., Zhang K., Li G., Learning to represent programs with heterogeneous graphs, Corr Abs, 2012, (2020); Xia X., Bao L., Lo D., Et al., Measuring program comprehension: A large-scale field study with professionals, IEEE Trans Softw Eng, 44, 10, pp. 951-976, (2017); Xu K., Hu W., Leskovec J., How powerful are graph neural networks?, (2018); Xu K., Li C., Tian Y., Representation learning on graphs with jumping knowledge networks, (2018); Yamaguchi F., Golde N., Arp D., Et al., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, SP 2014, Berkeley, CA, USA, May 18-21, 2014, pp. 590-604, (2014); Zhang C., Song D., Huang C., Heterogeneous graph neural network, Proceedings of the 25Th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 793-803, (2019); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Adv Neural Inf Process Syst, 915, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85160003449,1
Ding Z.; Li H.; Shang W.; Chen T.-H.P.,"Ding, Zishuo (57145921100); Li, Heng (57216386064); Shang, Weiyi (35093168200); Chen, Tse-Hsun Peter (55339201600)",57145921100; 57216386064; 35093168200; 55339201600,Towards Learning Generalizable Code Embeddings Using Task-agnostic Graph Convolutional Networks,2023,ACM Transactions on Software Engineering and Methodology,32,2,48,,,,5,10.1145/3542944,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153731394&doi=10.1145%2f3542944&partnerID=40&md5=5579536a2ca56d11845228acae273057,"Code embeddings have seen increasing applications in software engineering (SE) research and practice recently. Despite the advances in embedding techniques applied in SE research, one of the main challenges is their generalizability. A recent study finds that code embeddings may not be readily leveraged for the downstream tasks that the embeddings are not particularly trained for. Therefore, in this article, we propose GraphCodeVec, which represents the source code as graphs and leverages the Graph Convolutional Networks to learn more generalizable code embeddings in a task-agnostic manner. The edges in the graph representation are automatically constructed from the paths in the abstract syntax trees, and the nodes from the tokens in the source code. To evaluate the effectiveness of GraphCodeVec , we consider three downstream benchmark tasks (i.e., code comment generation, code authorship identification, and code clones detection) that are used in a prior benchmarking of code embeddings and add three new downstream tasks (i.e., source code classification, logging statements prediction, and software defect prediction), resulting in a total of six downstream tasks that are considered in our evaluation. For each downstream task, we apply the embeddings learned by GraphCodeVec and the embeddings learned from four baseline approaches and compare their respective performance. We find that GraphCodeVec outperforms all the baselines in five out of the six downstream tasks, and its performance is relatively stable across different tasks and datasets. In addition, we perform ablation experiments to understand the impacts of the training context (i.e., the graph context extracted from the abstract syntax trees) and the training model (i.e., the Graph Convolutional Networks) on the effectiveness of the generated embeddings. The results show that both the graph context and the Graph Convolutional Networks can benefit GraphCodeVec in producing high-quality embeddings for the downstream tasks, while the improvement by Graph Convolutional Networks is more robust across different downstream tasks and datasets. Our findings suggest that future research and practice may consider using graph-based deep learning methods to capture the structural information of the source code for SE tasks.  © 2023 Association for Computing Machinery.","Abuhamad M., AbuHmed T., Mohaisen A., Nyang D., Large-scale and languageoblivious code authorship identification, Proceedings of the ACM SIGSAC Conference on Computer and Communications Security, pp. 101-114, (2018); Allamanis M., Barr E.T., Bird C., Sutton C.A., Suggesting accurate method and class names, Proceedings of the 10th Joint Meeting on Foundations of Software Engineering, pp. 38-49, (2015); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, Proceedings of the 6th International Conference on Learning Representations, (2018); Allamanis M., Peng H., Sutton C.A., A convolutional attention network for extreme summarization of source code, Proceedings of the 33rd International Conference on Machine Learning series, pp. 2091-2100, (2016); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 404-419, (2018); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, PACMPL, 3, pp. 401-4029, (2019); Barbour L., Khomh F., Zou Y., Late propagation in software clones, Proceedings of the IEEE 27th International Conference on Software Maintenance, pp. 273-282, (2011); Bengio Y., Practical recommendations for gradient-based training of deep architectures, Neural Networks: Tricks of the Trade-Second Edition, 7700, pp. 437-478, (2012); Bielik P., Raychev V., Vechev M.T., PHOG: Probabilistic model for code, Proceedings of the 33rd International Conference on Machine Learning, pp. 2933-2942, (2016); Bojanowski P., Grave E., Joulin A., Mikolov T., Enriching word vectors with subword information, Trans. Assoc. Comput. Ling., 5, pp. 135-146, (2017); Buch L., Andrzejak A., Learning-based recursive aggregation of abstract syntax trees for code clone detection, Proceedings of the 26th IEEE International Conference on Software Analysis, Evolution and Reengineering, pp. 95-104, (2019); Cai S., Shu Y., Chen G., Chin Ooi B., Wang W., Zhang M., Effective and efficient dropout for deep convolutional neural networks, (2019); Cao Y., Huang L., Ji H., Chen X., Li J., Bridge text and knowledge by learning multi-prototype entity mention embedding, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pp. 1623-1633, (2017); Chen D., Lin Y., Li W., Li P., Zhou J., Sun X., Measuring and relieving the over-smoothing problem for graph neural networks from the topological view, Proceedings of the 34th AAAI Conference on Artificial Intelligence, the 32nd Innovative Applications of Artificial Intelligence Conference, the 10th AAAI Symposium on Educational Advances in Artificial Intelligence, pp. 3438-3445, (2020); Chen T.-H., Thomas S.W., Hassan A.E., A survey on the use of topic models when mining software repositories, Empir. Softw. Eng., 21, 5, pp. 1843-1919, (2016); Chen Z., Monperrus M., The remarkable role of similarity in redundancy-based program repair, CoRR, (2018); Defferrard M., Bresson X., Vandergheynst P., Convolutional neural networks on graphs with fast localized spectral filtering, Proceedings of the Annual Conference on Neural Information Processing Systems, pp. 3837-3845, (2016); Ding Z., Chen J., Shang W., Towards the use of the readily available tests from the release pipeline as performance tests. Are we there yet?, Proceedings of the 42nd International Conference on Software Engineering, (2020); Dubinsky Y., Rubin J., Berger T., Duszynski S., Becker M., Czarnecki K., An exploratory study of cloning in industrial software product lines, Proceedings of the 17th European Conference on Software Maintenance and Reengineering, pp. 25-34, (2013); Efstathiou V., Spinellis D., Semantic source code models using identifier embeddings, Proceedings of the 16th International Conference on Mining Software Repositories, pp. 29-33, (2019); Fu Q., Zhu J., Hu W., Lou J.-G., Ding R., Lin Q., Zhang D., Xie T., Where do developers log? An empirical study on logging practices in industry, Proceedings of the 36th International Conference on Software Engineering, pp. 24-33, (2014); Garbin C., Zhu X., Marques O., Dropout vs.batch normalization: an empirical study of their impact to deep learning, Multimedia Tools Appl., 79, 19-20, pp. 12777-12815, (2020); Goldberg Y., Hirst G., Neural Network Methods in Natural Language Processing, (2017); Goodfellow I., Bengio Y., Courville A., Deep Learning, (2016); Harer J.A., Kim L.Y., Russell R.L., Ozdemir O., Kosta L.R., Rangamani A., Hamilton L.H., Centeno G.I., Key J.R., Ellingwood P.M., McConley M.W., Opper J.M., Peter Chin S., Lazovich T., Automated software vulnerability detection with machine learning, CoRR, (2018); Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P.T., On the naturalness of software, Proceedings of the 34th International Conference on Software Engineering, pp. 837-847, (2012); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput., 9, 8, pp. 1735-1780, (1997); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation with hybrid lexical and syntactical information, Empirical Software Engineering, 25, 3, pp. 2179-2217, (2020); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proceedings of the 26th Conference on Program Comprehension, pp. 200-210, (2018); Caliskan Islam A., Harang R.E., Liu A., Narayanan A., Voss C.R., Yamaguchi F., Greenstadt R., De-anonymizing programmers via code stylometry, Proceedings of the 24th USENIX Security Symposium, pp. 255-270, (2015); Johnson R., Zhang T., Effective use of word order for text categorization with convolutional neural networks, Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 103-112, (2015); Kallis R., Di Sorbo A., Canfora G., Panichella S., Predicting issue types on GitHub, Science of Computer Programming, 205, (2021); Kamiya T., Kusumoto S., Inoue K., CCFinder: A multilinguistic token-based code clone detection system for large scale source code, IEEE Trans. Softw. Eng., 28, 7, pp. 654-670, (2002); Jin Kang H., Bissyande T.F., Lo D., Assessing the generalizability of code2vec token embeddings, Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering, pp. 1-12, (2019); Kawaguchi S., Garg P.K., Matsushita M., Inoue K., MUDABlue: An automatic categorization system for open source repositories, J. Syst. Softw., 79, 7, pp. 939-953, (2006); Kim Y., Convolutional neural networks for sentence classification, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, pp. 1746-1751, (2014); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, Proceedings of the 5th International Conference on Learning Representations, (2017); Klein G., Kim Y., Deng Y., Senellart J., Rush A.M., OpenNMT: Open-source toolkit for neural machine translation, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pp. 67-72, (2017); Komninos A., Manandhar S., Dependency based embeddings for sentence classification tasks, Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1490-1500, (2016); Le Q.V., Mikolov T., Distributed representations of sentences and documents, Proceedings of the 31st International Conference on Machine Learning, pp. 1188-1196, (2014); Levy O., Goldberg Y., Dependency-basedword embeddings, Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pp. 302-308, (2014); Li C., Li J., Song Y., Lin Z., Training and evaluating improved dependency-based word embeddings, Proceedings of the 32nd AAAI Conference on Artificial Intelligence, the 30th Innovative Applications of Artificial Intelligence, and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence, pp. 5836-5843, (2018); Li G., Muller M., Thabet A.K., Ghanem B., DeepGCNs: Can GCNs go as deep as CNNs?, Proceedings of the International Conference on Computer Vision, pp. 9266-9275, (2019); Li H., Peter Chen T.-H., Shang W., Hassan A.E., Studying software logging using topic models, Empirical Software Engineering, 23, 5, pp. 2655-2694, (2018); Li Q., Han Z., Wu X.-M., Deeper insights into graph convolutional networks for semisupervised learning, Proceedings of the 32nd AAAI Conference on Artificial Intelligence, the 30th innovative Applications of Artificial Intelligence, and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence, pp. 3538-3545, (2018); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, Proceedings of the 4th International Conference on Learning Representations, (2016); Li Z., Li H., Peter Chen T.-H., Shang W., DeepLV: Suggesting log levels using ordinal based neural networks, Proceedings of the 43rd IEEE/ACM International Conference on Software Engineering, pp. 1461-1472, (2021); Lin C.-Y., ROUGE: A package for automatic evaluation of summaries, Text Summarization Branches Out, pp. 74-81, (2004); Liu Z., Lin Y., Sun M., Representation Learning for Natural Language Processing, (2020); Van Der Maaten L., Hinton G., Visualizing data using t-SNE, J. Mach. Learn. Res., 9, pp. 2579-2605, (2008); Marcheggiani D., Titov I., Encoding sentences with graph convolutional networks for semantic role labeling, Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 1506-1515, (2017); Masters D., Luschi C., Revisiting small batch training for deep neural networks, (2018); Mayrand J., Leblanc C., Merlo E., Experiment on the automatic detection of function clones in a software system using metrics, Proceedings of the International Conference on Software Maintenance, (1996); McBurney P.W., McMillan C., Automatic documentation generation via source code summarization of method context, Proceedings of the 22nd International Conference on Program Comprehension, pp. 279-290, (2014); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, Proceedings of the 1st International Conference on Learning Representations, (2013); Mikolov T., Sutskever I., Chen K., Corrado G., Dean J., Distributed representations of words and phrases and their compositionality, Proceedings of the 26th International Conference on Neural Information Processing Systems, pp. 3111-3119, (2013); Mnih A., Hinton G.E., A scalable hierarchical distributed language model, Proceedings of the 22nd Annual Conference on Neural Information Processing Systems, pp. 1081-1088, (2008); Moreno L., Aponte J., Sridhara G., Marcus A., Pollock L.L., Vijay-Shanker K., Automatic generation of natural language summaries for Java classes, Proceedings of the IEEE 21st International Conference on Program Comprehension, pp. 23-32, (2013); Morin F., Bengio Y., Hierarchical probabilistic neural network languagemodel, Proceedings of the 10th InternationalWorkshop on Artificial Intelligence and Statistics; Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Proceedings of the 30th AAAI Conference on Artificial Intelligence, pp. 1287-1293, (2016); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Proceedings of the 30th AAAI Conference on Artificial Intelligence, pp. 1287-1293, (2016); Oliveto R., Gethers M., Poshyvanyk D., De Lucia A., On the equivalence of information retrieval methods for automated traceability link recovery, Proceedings of the 18th IEEE International Conference on Program Comprehension, pp. 68-71; Oliveto R., Gethers M., Poshyvanyk D., De Lucia A., On the equivalence of information retrieval methods for automated traceability link recovery: A ten-year retrospective, Proceedings of the 28th International Conference on Program Comprehension, (2020); Pane J.F., Ann Ratanamahatana C., Myers B.A., Studying the language and structure in non-programmers' solutions to programming problems, Int. J. Hum. Comput. Stud., 54, 2, pp. 237-264, (2001); Panichella S., Di Sorbo A., Guzman E., Aaron Visaggio C., Canfora G., Gall H.C., How can I improve my app? Classifying user reviews for software maintenance and evolution, Proceedings of the IEEE International Conference on Software Maintenance and Evolution, pp. 281-290, (2015); Papineni K., Roukos S., Ward T., Zhu W.-J., Bleu: A method for automatic evaluation of machine translation, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Pedregosa F., Varoquaux G., Gramfort A., Michel V., Thirion B., Grisel O., Blondel M., Prettenhofer P., Weiss R., Dubourg V., Vanderplas J., Passos A., Cournapeau D., Brucher M., Perrot M., Duchesnay E., Scikit-learn: Machine learning in Python, J.Mach. Learn. Res., 12, pp. 2825-2830, (2011); Pennington J., Socher R., Manning C.D., GloVe: Global vectors for word representation, Proceedings of the Conference on EmpiricalMethods in Natural Language Processing, pp. 1532-1543, (2014); Pradel M., Sen K., DeepBugs: A learning approach to name-based bug detection, PACMPL, 2, pp. 1471-14725, (2018); Qiu L., Zhang Y., Lu Y., Syntactic dependencies and distributed word representations for analogy detection and mining, Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 2441-2450, (2015); Raychev V., Vechev M.T., Krause A., Predicting program properties from big code, Proceedings of the 42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pp. 111-124, (2015); Ehek R., Sojka P., Software framework for topicmodelling with large corpora, Proceedings of the LREC Workshop on New Challenges for NLP Frameworks, pp. 45-50, (2010); Rong X., word2vec parameter learning explained, (2014); Rong Y., Huang W., Xu T., Huang J., DropEdge: Towards deep graph convolutional networks on node classification, Proceedings of the 8th International Conference on Learning Representations, (2020); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., SourcererCC: Scaling code clone detection to big-code, Proceedings of the 38th International Conference on Software Engineering, pp. 1157-1168, (2016); Schnabel T., Labutov I., Mimno D.M., Joachims T., Evaluation methods for unsupervised word embeddings, Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 298-307, (2015); Sridhara G., Hill E., Muppaneni D., Pollock L.L., Vijay-Shanker K., Towards automatically generating summary comments for Java methods, Proceedings of the 25th IEEE/ACM International Conference on Automated Software Engineering, pp. 43-52, (2010); Srivastava N., Hinton G., Krizhevsky A., Sutskever I., Salakhutdinov R., Dropout: a simple way to prevent neural networks from overfitting, J.Mach. Learn. Res., 15, 1, pp. 1929-1958, (2014); Svajlenko J., Islam J.F., Keivanloo I., Kumar Roy C., Mia M., Towards a big data curated benchmark of inter-project code clones, Proceedings of the 30th IEEE International Conference on Software Maintenance and Evolution, pp. 476-480, (2014); Theeten B., Vandeputte F., Van Cutsem T., Import2vec learning embeddings for software libraries, Proceedings of the 16th International Conference on Mining Software Repositories, pp. 18-28, (2019); Thummalapenta S., Cerulo L., Aversano L., Di Penta M., An empirical study on the maintenance of source code clones, Empir. Softw. Eng., 15, 1, pp. 1-34, (2010); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, Proceedings of the 15th International Conference on Mining Software Repositories, pp. 542-553, (2018); Vashishth S., Bhandari M., Yadav P., Rai P., Bhattacharyya C., Talukdar P.P., Incorporating syntactic and semantic information in word embeddings using graph convolutional networks, Proceedings of the 57th Conference of the Association for Computational Linguistics, pp. 3308-3318, (2019); Linares Vasquez M., McMillan C., Poshyvanyk D., Grechanik M., On using machine learning to automatically classify software applications into domain categories, Empir. Softw. Eng., 19, 3, pp. 582-618, (2014); Wang K., Singh R., Su Z., Dynamic neural program embeddings for program repair, Proceedings of the 6th International Conference on Learning Representations, (2018); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, Proceedings of the 38th International Conference on Software Engineering, pp. 297-308, (2016); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proceedings of the 26th International Joint Conference on Artificial Intelligence, pp. 3034-3040, (2017); Wendlandt L., Kummerfeld J.K., Mihalcea R., Factors influencing the surprising instability of word embeddings, Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2092-2102, (2018); White M., Tufano M., Martinez M., Monperrus M., Poshyvanyk D., Sorting and transforming program repair ingredients via deep learning code similarities, Proceedings of the 26th IEEE International Conference on Software Analysis, Evolution and Reengineering, pp. 479-490, (2019); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, pp. 87-98, (2016); Yin Y., Wei F., Dong L., Xu K., Zhang M., Zhou M., Unsupervisedword and dependency path embeddings for aspect term extraction, Proceedings of the 25th International Joint Conference on Artificial Intelligence, pp. 2979-2985, (2016); Yu X., Huang Q., Wang Z., Feng Y., Zhao D., Towards context-aware code comment generation, Findings of the Association for Computational Linguistics: EMNLP, pp. 3938-3947, (2020); Zeng L., Xiao Y., Chen H., Linux auditing: Overhead and adaptation, Proceedings of the International Conference on Communications, pp. 7168-7173, (2015); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings of the 41st International Conference on Software Engineering, pp. 783-794, (2019); Zhang X., Zhou Y., Han T., Chen T., Training deep code comment generation models via data augmentation, Proceedings of the 12th Asia-Pacific Symposium on Internetware, pp. 185-188, (2020); Zhou K., Dong Y., Wang K., Sun Lee W., Hooi B., Xu H., Feng J., Understanding and resolving performance degradation in deep graph convolutional networks, Proceedings of the 30th ACM International Conference on Information & Knowledge Management, pp. 2728-2737, (2021)",,,,,,English,Article,Final,,Scopus,2-s2.0-85153731394,3
Pan W.; Ming H.; Kim D.-K.; Yang Z.,"Pan, Weifeng (35230163600); Ming, Hua (25929406700); Kim, Dae-Kyoo (56109731300); Yang, Zijiang (55716575100)",35230163600; 25929406700; 56109731300; 55716575100,Pride: Prioritizing Documentation Effort Based on a PageRank-Like Algorithm and Simple Filtering Rules,2023,IEEE Transactions on Software Engineering,49,3,,1118,1151,33,10,10.1109/TSE.2022.3171469,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129670613&doi=10.1109%2fTSE.2022.3171469&partnerID=40&md5=346cf30e57b601387a769a9b0f781a8d,"Code documentation can be helpful in many software quality assurance tasks. However, due to resource constraints (e.g., time, human resources, and budget), programmers often cannot document their work completely and timely. In the literature, two approaches (one is supervised and the other is unsupervised) have been proposed to prioritize documentation effort to ensure the most important classes to be documented first. However, both of them contain several limitations. The supervised approach overly relies on a difficult-to-obtain labeled data set and has high computation cost. The unsupervised one depends on a graph representation of the software structure, which is inaccurate since it neglects many important couplings between classes. In this paper, we propose an improved approach, named Pride, to prioritize documentation effort. First, Pride uses a weighted directed class coupling network to precisely describe classes and their couplings. Second, we propose a PageRank-like algorithm to quantify the importance of classes in the whole class coupling network. Third, we use a set of software metrics to quantify source code complexity and further propose a simple but easy-to-operate filtering rule. Fourth, we sort all the classes according to their importance in descending order and use the filtering rule to filter out unimportant classes. Finally, a threshold kk is utilized, and the top-kk% ranked classes are the identified important classes to be documented first. Empirical results on a set of nine software systems show that, according to the average ranking of the Friedman test, Pride is superior to the existing approaches in the whole data set.  © 2022 IEEE.","Brooks R.E., Towards a theory of the comprehension of computer programs, Int. J. Man Mach. Stud., 18, 6, pp. 543-554, (1983); Corritore C.L., Wiedenbeck S., An exploratory study of program comprehension strategies of procedural and object-oriented programmers, Int. J. Hum. Comput. Stud., 54, 1, pp. 1-23, (2001); Peters D.K., Parnas D.L., Using test oracles generated from program documentation, IEEE Trans. Softw. Eng., 24, 3, pp. 161-173, (1998); Xie T., Augmenting automatically generated unit-test suites with regression oracle checking, Proc. Object-Oriented Program., 20th Eur. Conf., pp. 380-403, (2006); Huang Q., Xia X., Xing Z., Lo D., Wang X., API method recommendation without worrying about the task-API knowledge gap, Proc. 33rd ACM/IEEE Int. Conf. Automated Softw. Eng., pp. 293-304, (2018); Tan L., Yuan D., Krishna G., Zhou Y., icomment: Bugs or bad comments?, Proc. 21st ACM Symp. Operating Syst. Princ., pp. 145-158, (2007); Tan S.H., Marinov D., Tan L., Leavens G.T., @tcomment: Testing javadoc comments to detect comment-code inconsistencies, Proc. 5th IEEE Int. Conf. Softw. Testing, Verification Validation, pp. 260-269, (2012); Xiong Y., Et al., Precise condition synthesis for program repair, Proc. 39th Int. Conf. Softw. Eng., pp. 416-426, (2017); Lethbridge T., Singer J., Forward A., How software engineers use documentation: The state of the practice, IEEE Softw., 20, 6, pp. 35-39, (2003); Roehm T., Tiarks R., Koschke R., Maalej W., How do professional developers comprehend software?, Proc. 34th Int. Conf. Softw. Eng., pp. 255-265, (2012); Treude C., Robillard M.P., Understanding stack overflow code fragments, Proc. IEEE Int. Conf. Softw. Maintenance Evol., pp. 509-513, (2017); Niu N., Jin X., Niu Z., Cheng J.C., Li L., Kataev M., A clustering-based approach to enriching code foraging environment, IEEE Trans. Cybern., 46, 9, pp. 1962-1973, (2016); McBurney P.W., McMillan C., Automatic source code summarization of context for Java methods, IEEE Trans. Softw. Eng., 42, 2, pp. 103-119, (2016); McBurney P.W., Et al., Towards prioritizing documentation effort, IEEE Trans. Softw. Eng., 44, 9, pp. 897-913, (2018); Liu S., Guo Z., Li Y., Lu H., Chen L., Xu L., Zhou Y., Xu B., Prioritizing code documentation effort: Can we do it simpler but better?, Inf. Softw. Technol., 140, (2021); Hagan M.T., Demuth H.B., Beale M., Neural Network Design, (1997); Chidamber S.R., Kemerer C.F., A metrics suite for object oriented design, IEEE Trans. Softw. Eng., 20, 6, pp. 476-493, (1994); Li Y., McLean D., Bandar Z., O'Shea J., Crockett K.A., Sentence similarity based on semantic nets and corpus statistics, IEEE Trans. Knowl. Data Eng., 18, 8, pp. 1138-1150, (2006); Salton G., Wong A., Yang C., A vector space model for automatic indexing, Commun. ACM, 18, 11, pp. 613-620, (1975); Kumar G., Duhan N., Sharma A.K., Page ranking based on number of visits of links of web page, Proc. 2nd Int. Conf. Comput. Commun. Technol., pp. 11-14, (2011); Wang M.S., Lu H.M., Zhou Y.M., Xu B.W., Identifying key classes using H-index and its variants, J. Front. Comput. Sci. Technol., 5, 10, pp. 891-903, (2011); Meyer P., Siy H.P., Bhowmick S., Identifying important classes of large software systems through k-core decomposition, Adv. Complex Syst., 17, 7-8, (2014); Sora I., Chirila C., Finding key classes in object-oriented software systems by techniques based on static analysis, Inf. Softw. Technol., 116, (2019); Pan W., Song B., Li K., Zhang K., Identifying key classes in object-oriented software using generalized k-core decomposition, Future Gener. Comput. Syst., 81, pp. 188-202, (2018); Pan W., Ming H., Chang C.K., Yang Z., Kim D., ElementRank: Ranking Java software classes and packages using a multilayer complex network-based approach, IEEE Trans. Softw. Eng., 47, 10, pp. 2272-2295, (2021); Briand L.C., Daly J.W., Wust J., A unified framework for coupling measurement in object-oriented systems, IEEE Trans. Softw. Eng., 25, 1, pp. 91-121, (1999); Briand L.C., Devanbu P.T., Melo W.L., An investigation into coupling measures for C++, Proc. 19th Int. Conf. Softw. Eng., pp. 412-421, (1997); Abreu F.B.E., Pereira G., Sousa P.M.A., A coupling-guided cluster analysis approach to reengineer the modularity of objectoriented systems, Proc. 4th Eur. Conf. Softw. Maintenance Reengineering, pp. 13-22, (2000); Abreu F.B.E., Goul Ao M., Coupling and cohesion as modularization drivers: Are we being over-persuaded?, Proc. 5th Conf. Softw. Maintenance Reengineering, pp. 47-57, (2001); Prajapati A., Chhabra J.K., Improving modular structure of software system using structural and lexical dependency, Inf. Softw. Technol., 82, pp. 96-120, (2017); Marcus A., Poshyvanyk D., Ferenc R., Using the conceptual cohesion of classes for fault prediction in object-oriented systems, IEEE Trans. Softw. Eng., 34, 2, pp. 287-300, (2008); Kang D., Xu B., Lu J., Chu W.C., A complexity measure for ontology based on UML, Proc. 10th IEEE Int. Workshop Future Trends Distrib. Comput. Syst. FTDCS, pp. 222-228, (2004); Bruel J., Henderson-Sellers B., Barbier F., Parc A.L., France R.B., Improving the UML metamodel to rigorously specify aggregation and composition, Proc. 7th Int. Conf. Object Oriented Informat. Syst., pp. 5-14, (2001); Brin S., Page L., The anatomy of a large-scale hypertextual web search engine, Comput. Netw., 30, 1-7, pp. 107-117, (1998); Takai Y., Miyauchi A., Ikeda M., Yoshida Y., Hypergraph clustering based on PageRank, Proc. 26th ACM SIGKDD Conf. Knowl. Discov. Data Mining, pp. 1970-1978, (2020); Hashemi A., Dowlatshahi M.B., Nezamabadi-Pour H., MGFS: A multi-label graph-based feature selection algorithm via PageRank centrality, Expert Syst. Appl., 142, (2020); Xiang B., Liu Q., Chen E., Xiong H., Zheng Y., Yang Y., Pagerank with priors: An influence propagation perspective, Proc. 23rd Int. Joint Conf. on Artif. Intell., pp. 2740-2746, (2013); McMillan C., Grechanik M., Poshyvanyk D., Xie Q., Fu C., Portfolio: Finding relevant functions and their usage, Proc. 33rd Int. Conf. Softw. Eng., pp. 111-120, (2011); Linstead E., Bajracharya S., Ngo T., Rigor P., Lopes C., Baldi P., Sourcerer: Mining and searching internet-scale software repositories, Data Mining Knowl. Discov., 18, 2, pp. 300-336, (2009); Zhang M., Et al., An empirical study of boosting spectrum-based fault localization via PageRank, IEEE Trans. Softw. Eng., 47, 6, pp. 1089-1113, (2021); Abbas M., Inayat I., Jan N., Saadatmand M., Enoiu E.P., Sundmark D., MBRP: model-based requirements prioritization using PageRank algorithm, Proc. 26th Asia-Pacific Softw. Eng. Conf., pp. 31-38, (2019); Jin Y., Zhang J., Ma P., Hao W., Luo S., Li Z., Applying PageRank algorithm in requirement concern impact analysis, Proc. 33rd Annu. IEEE Int. Comput. Softw. Appl. Conf., pp. 361-366, (2009); Suzuki S., Aman H., Amasaki S., Yokogawa T., Kawahara M., An application of the PageRank algorithm to commit evaluation on git repository, Proc. 43rd Euromicro Conf. Softw. Eng. Adv. Appl., pp. 380-383, (2017); Pfeiffer R., Identifying critical projects via PageRank and truck factor, Proc. 18th IEEE/ACM Int. Conf. Mining Softw. Repositories, pp. 41-45, (2021); Gori M., Pucci A., Itemrank: A random-walk based scoring algorithm for recommender engines, Proc. 20th Int. Joint Conf. Artif. Intell., pp. 2766-2771, (2007); Langville A.N., Meyer C.D., Survey: Deeper inside PageRank, Internet Math., 1, 3, pp. 335-380, (2003); Gyongyi Z., Garcia-Molina H., Pedersen J.O., Combating web spam with trustrank, Proc. 30th Int. Conf. Very Large Data Bases, pp. 576-587, (2004); Haveliwala T.H., Topic-sensitive PageRank: A context-sensitive ranking algorithm for web search, IEEE Trans. Knowl. Data Eng., 15, 4, pp. 784-796, (2003); Page L., Brin S., Motwani R., Winograd T., The PageRank citation ranking: Bringing order to the web, (1999); Bianchini M., Gori M., Scarselli F., Inside PageRank, ACM Trans. Internet Techn., 5, 1, pp. 92-128, (2005); Haveliwala T., Efficient computation of PageRank, (1999); Wolverton R.W., The cost of developing large-scale software, IEEE Trans. Comput., 23, 6, pp. 615-636, (1974); Tsantalis N., Chatzigeorgiou A., Stephanides G., Predicting the probability of change in object-oriented systems, IEEE Trans. Softw. Eng., 31, 7, pp. 601-614, (2005); Halstead M.H., Elements of Software Science (Operating and Programming Systems Series), (1977); Zaidman A., Demeyer S., Automatic identification of key classes in a software system using webmining techniques, J. Softw. Maintenance Res. Pract., 20, 6, pp. 387-417, (2008); Chandra A.K., Harel D., Horn clause queries and generalizations, J. Log. Program, 2, 1, pp. 1-15, (1985); Abreu F.B.E., The mood metrics set, Proc. Eur. Conf. Object-Oriented Program. Workshop Metrics, (1995); Alqmase M., Alshayeb M., Ghouti L., Threshold extraction framework for software metrics, J. Comput. Sci. Technol., 34, 5, pp. 1063-1078, (2019); Hirsch J.E., An index to quantify an individual's scientific research output, Proc. Natl. Acad. Sci. USA, 102, 46, pp. 16569-16572, (2005); Saaty T.L., The Analytic Hierarchy Process: Planning, Priority Setting, Resources Allocation, (1980); Garcia S., Herrera F., An extension on ""statistical comparisons of classifiers over multiple data sets"" for all pairwise comparisons, J. Mach. Learn. Res., 9, pp. 2677-2694, (2008); Garcia S., Fernandez A., Luengo J., Herrera F., Advanced nonparametric tests for multiple comparisons in the design of experiments in computational intelligence and data mining: Experimental analysis of power, Inf. Sci., 180, 10, pp. 2044-2064, (2010); Ma Y., He K., Li B., Liu J., Zhou X., A hybrid set of complexity metrics for large-scale object-oriented software systems, J. Comput. Sci. Technol., 25, 6, pp. 1184-1201, (2010); Osman M.H., Chaudron M.R.V., Van Der Putten P., An analysis of machine learning algorithms for condensing reverse engineered class diagrams, Proc. IEEE Int. Conf. Softw. Maintenance, pp. 140-149, (2013); Thung F., Lo D., Osman M.H., Chaudron M.R.V., Condensing class diagrams by analyzing design and network metrics using optimistic classification, Proc. 22nd Int. Conf. Prog. Comprehension, pp. 110-121, (2014); Yang X., Lo D., Xia X., Sun J., Condensing class diagrams with minimal manual labeling cost, Proc. 40th IEEE Annu. Comput. Softw. Appl. Conf., pp. 22-31, (2016); Puppin D., Silvestri F., The social network of java classes, Proc. ACM Symp. Appl. Comput., pp. 1409-1413, (2006); Perin F., Renggli L., Ressia J., Ranking software artifacts, Proc. 4th Workshop FAMIX Moose Reengineering, pp. 1-4, (2010); Hammad M., Collard M.L., Maletic J.I., Measuring class importance in the context of design evolution, Proc. 18th IEEE Int. Conf. Prog. Comprehension, pp. 148-151, (2010); Steidl D., Hummel B., Jurgens E., Using network analysis for recommendation of central software classes, Proc. 19th Work. Conf. Reverse Eng., pp. 93-102, (2012)",,,,,,English,Article,Final,,Scopus,2-s2.0-85129670613,230
Cassagne J.; Merlo E.; Branco P.; Jourdan G.-V.; Onut I.-V.,"Cassagne, Julien (58650803200); Merlo, Ettore (57204299654); Branco, Paula (55866459900); Jourdan, Guy-Vincent (56345610700); Onut, Iosif-Viorel (12143708200)",58650803200; 57204299654; 55866459900; 56345610700; 12143708200,Unsupervised Graph Neural Networks for Source Code Similarity Detection,2023,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),14276 LNAI,,,535,549,14,0,10.1007/978-3-031-45275-8_36,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174316921&doi=10.1007%2f978-3-031-45275-8_36&partnerID=40&md5=aee61debb36b07fa4fc6b014d2bd824f,"In this paper, we propose a novel unsupervised approach for code similarity and clone detection that is based on Graph Neural Networks. We propose a hybrid approach to detect similarities within source code, using centroid distances and a Graph Auto-Encoder that uses a raw abstract syntax trees as input. When compared to RTVNN [33], the state-of-the-art unsupervised approach for code similarity and clone detection, our method improves significantly training and inference time efficiency, while preserving or improving precision. In our experiments, our algorithm is on average 77 times faster during training and 21 times faster during inference. This shows that using Graph Auto-Encoders in the domain of source code similarity analysis is the better option in an industrial context or in a production environment. We illustrate this by using our approach to compute source code similarity within a large dataset of phishing kits written in PHP provided by our industry partner. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Baxter I., Yahin A., Moura L., Sant'Anna M., Bier L., Clone detection using abstract syntax trees, Proceedings of the International Conference on Software Maintenance (Cat. No. 98CB36272), pp. 368-377, (1998); Ducasse S., Nierstrasz O., Rieger M., On the effectiveness of clone detection by string matching, Research Articles. J. Softw. Maint. Evol., 18, 1, (2006); Feng S., Duarte M.F., Graph autoencoder-based unsupervised feature selection with broad and local data structure preservation, Neurocomputing, (2018); Fey M., Lenssen J.E., Fast Graph Representation Learning with Pytorch Geometric, (2019); Gilmer J., Schoenholz S.S., Riley P.F., Vinyals O., Dahl G.E., Neural message passing for quantum chemistry, Corr Abs/1704, (2017); Gori M., Monfardini G., Scarselli F., A new model for learning in graph domains, Proceedings of the 2005 IEEE International Joint Conference on Neural Networks, (2005); Jiang S., Hong Y., Fu C., Qian Y., Han L., Function-level obfuscation detection method based on graph convolutional networks, J. Inf. Secur. Appl., 61, (2021); Kingma D.P., Welling M., Auto-Encoding Variational Bayes, (2014); Kipf T.N., Welling M., Variational graph auto-encoders. arXiv:1611.07308 [cs, Stat, (2016); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks, (2017); Li Y., Gu C., Dullien T., Vinyals O., Kohli P., Graph Matching Networks for Learning the Similarity of Graph Structured Objects, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, (2015); Liu C., Lin Z., Lou J.G., Wen L., Zhang D., Can neural clone detection generalize to unseen functionalitiesf, 36Th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 617-629, (2021); Liu S., A unified framework to learn program semantics with graph neural networks, 2020 35Th IEEE/ACM International Conference on Automated Software Engineering (ASE), (2020); Ma G., Ahmed N.K., Willke T.L., Yu P.S., Deep graph similarity learning: A survey, Data Min. Knowl. Disc., 35, 3, pp. 688-725, (2021); McInnes L., Healy J., Melville J., UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction. Arxiv, 1802, (2020); Mehrotra N., Agarwal N., Gupta P., Anand S., Lo D., Purandare R., Modeling Functional Similarity in Source Code with Graph-Based Siamese Networks. Arxiv, 132, cs, (2020); Merlo E., Antoniol G., Di Penta M., Rollo V., Linear complexity object-oriented similarity for clone detection and software evolution analyses, Proceedings of the 20Th IEEE International Conference on Software Maintenance, pp. 412-416, (2004); Nguyen V.A., Nguyen D.Q., Nguyen V., Le T., Tran Q.H., Phung D., ReGVD: Revisiting graph neural networks for vulnerability detection, 2022 IEEE/ACM 44Th International Conference on Software Engineering: Companion Proceedings, (2022); Pan S., Hu R., Long G., Jiang J., Yao L., Zhang C., Adversarially regularized graph autoencoder for graph embedding, Proceedings of the 27Th International Joint Conference on Artificial Intelligence, IJCAI 2018. AAAI Press, (2018); Park J., Lee M., Chang H., Lee K., Choi J., Symmetric graph convolutional autoencoder for unsupervised graph representation learning, 2019 IEEE/CVF International Conference on Computer Vision (ICCV), (2019); Paszke A., Et al., Pytorch: An imperative style, high-performance deep learning library, Advances in Neural Information Processing Systems, 32, (2019); Roy C.K., Cordy J.R., Koschke R., Comparison and evaluation of code clone detection techniques and tools: A qualitative approach, Sci. Comput. Program., 74, 7, pp. 470-495, (2009); Rozi M.F., Ban T., Ozawa S., Kim S., Takahashi T., Inoue D., JStrack: Enriching malicious JavaScript detection based on AST graph analysis and attention mechanism, Neural Information Processing: ICONIP, (2021); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Trans. Neural Netw., 20, 1, pp. 61-80, (2009); Siow J.K., Liu S., Xie X., Meng G., Liu Y., Learning program semantics with code representations: An empirical study, IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 554-565, (2022); Tai K.S., Socher R., Manning C.D., Improved semantic representations from tree-structured long short-term memory networks, Proceedings of the 53Rd Annual Meeting of the Association for Computational Linguistics, Beijing, China, Pp. 1556–1566. Association for Computational Linguistics, (2015); Wang L., Et al., Inductive and unsupervised representation learning on graph structured objects, International Conference on Learning Representations, (2020); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, IEEE 27Th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 261-271, (2020); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proceedings of the 26Th International Joint Conference on Artificial Intelligence, IJCAI 2017, (2017); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, 2016 31St IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 87-98, (2016); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A comprehensive survey on graph neural networks, IEEE Trans. Neural Netw. Learn. Syst., 32, pp. 4-24, (2020); Yahya M.A., Kim D.K., CLCD-I: Cross-language clone detection by using deep learning with infercode, Computers, 12, 1, (2023); Yu H., Lam W., Chen L., Li G., Xie T., Wang Q., Neural detection of semantic code clones via tree-based convolution, IEEE/ACM 27Th International Conference on Program Comprehension (ICPC), pp. 70-80, (2019); Zeng J., Ben K., Li X., Zhang X., Fast code clone detection based on weighted recursive autoencoders, IEEE Access, 7, pp. 125062-125078, (2019); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, IEEE/ACM 41St International Conference on Software Engineering (ICSE), pp. 783-794, (2019); Zhou J., Cui G., Zhang Z., Yang C., Liu Z., Sun M., Graph neural networks: A review of methods and applications, AI Open, 1, pp. 57-81, (2020)",,"26th International Conference on Discovery Science, DS 2023",9 October 2023 through 11 October 2023,Porto,301459,English,Conference paper,Final,,Scopus,2-s2.0-85174316921,5
Liu J.; Zeng J.; Wang X.; Liang Z.,"Liu, Jiahao (57212605025); Zeng, Jun (57220955671); Wang, Xiang (57191904438); Liang, Zhenkai (14034338200)",57212605025; 57220955671; 57191904438; 14034338200,Learning Graph-based Code Representations for Source-level Functional Similarity Detection,2023,Proceedings - International Conference on Software Engineering,,,,345,357,12,5,10.1109/ICSE48619.2023.00040,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171745038&doi=10.1109%2fICSE48619.2023.00040&partnerID=40&md5=53a3e46dcfc8d8ebf0487b07fc1986f7,"Detecting code functional similarity forms the basis of various software engineering tasks. However, the detection is challenging as functionally similar code fragments can be implemented differently, e.g., with irrelevant syntax. Recent studies incorporate program dependencies as semantics to identify syntactically different yet semantically similar programs, but they often focus only on local neighborhoods (e.g., one-hop dependencies), limiting the expressiveness of program semantics in modeling functionalities. In this paper, we present Tailor that explicitly exploits deep graph-structured code features for functional similarity detection. Given source-level programs, Tailor first represents them into code property graphs (CPGs) - which combine abstract syntax trees, control flow graphs, and data flow graphs - to collectively reason about program syntax and semantics. Then, Tailor learns representations of CPGs by applying a CPG-based neural network (CPGNN) to iteratively propagate information on them. It improves over prior work on code representation learning through a new graph neural network (GNN) tailored to CPG structures instead of the off-the-shelf GNNs used previously. We systematically evaluate Tailor on C and Java programs using two public benchmarks. Experimental results show that Tailor outperforms the state-of-the-art approaches, achieving 99.8% and 99.9% F-scores in code clone detection and 98.3% accuracy in source code classification. © 2023 IEEE.","Kamiya T., Kusumoto S., Inoue K., Ccfinder: A multilinguistic token-based code clone detection system for large scale source code, IEEE Transactions on Software Engineering, (2002); Roy C.K., Cordy J.R., Koschke R., Comparison and evaluation of code clone detection techniques and tools: A qualitative approach, Science of computer programming, (2009); Frantzeskou G., MacDonell S., Stamatatos E., Gritzalis S., Examining the significance of high-level programming features in source code author classification, Journal of Systems and Software, (2008); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Thirtieth AAAI Conference on Artificial Intelligence (AAAI), (2016); Jiang L., Su Z., Chiu E., Context-based detection of clone-related bugs, Proceedings of the the 6th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering (ESEC/FSE), (2007); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in neural information processing systems, (2019); Siow J.K., Liu S., Xie X., Meng G., Liu Y., Learning program semantics with code representations: An empirical study, SANER, (2022); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., Sourcerercc: Scaling code clone detection to big-code, Proceedings of the 38th International Conference on Software Engineering (ICSE), (2016); Wang P., Svajlenko J., Wu Y., Xu Y., Roy C.K., Ccaligner: A token based large-gap clone detector, Proceedings of the 40th International Conference on Software Engineering (ICSE), (2018); Nakagawa T., Higo Y., Kusumoto S., Nil: large-scale detection of large-variance clones, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE), (2021); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate tree-based detection of code clones, 29th International Conference on Software Engineering (ICSE). IEEE, (2007); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, 2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, (2016); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, IJCAI, (2017); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, (2019); Bui N.D., Yu Y., Jiang L., Infercode: Self-supervised learning of code representations by predicting subtrees, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, (2021); Liu C., Chen C., Han J., Yu P.S., Gplag: detection of software plagiarism by program dependence graph analysis, Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD), (2006); Wang M., Wang P., Xu Y., Ccsharp: An efficient three-phase code clone detector using modified pdgs, 2017 24th Asia-Pacific Software Engineering Conference (APSEC). IEEE, (2017); Zhao G., Huang J., Deepsim: deep learning code functional similarity, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE), (2018); Fang C., Liu Z., Shi Y., Huang J., Shi Q., Functional code clone detection with syntax and semantics fusion learning, Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA), (2020); Fan W., Ma Y., Li Q., He Y., Zhao E., Tang J., Yin D., Graph neural networks for social recommendation, The World Wide Web Conference (WWW), (2019); Wang X., He X., Cao Y., Liu M., Chua T.-S., Kgat: Knowledge graph attention network for recommendation, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD), (2019); Zeng J., Wang X., Liu J., Chen Y., Liang Z., Chua T.-S., Chua Z.L., Shadewatcher: Recommendation-guided cyber threat analysis using system audit records, IEEE Symposium on Security and Privacy, (2022); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, International Conference on Learning Representations (ICLR), (2018); Li Y., Zemel R., Brockschmidt M., Tarlow D., Gated graph sequence neural networks, International Conference on Learning Representations (ICLR), (2016); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, (2020); Wu Z., Pan S., Chen F., Long G., Zhang C., Philip S.Y., A comprehensive survey on graph neural networks, IEEE transactions on neural networks and learning systems, (2020); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, International Conference on Learning Representations (ICLR), (2017); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy (S&P). IEEE, (2014); Aho A.V., Sethi R., Ullman J.D., Compilers, principles, techniques, (1986); Svajlenko J., Islam J.F., Keivanloo I., Roy C.K., Mia M.M., Towards a big data curated benchmark of inter-project code clones, 2014 IEEE International Conference on Software Maintenance and Evolution (ICSME). IEEE, (2014); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, POPL, (2019); Vagavolu D., Swarna K.C., Chimalakonda S., A mocktail of source code representations, 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 1296-1300, (2021); He X., Deng K., Wang X., Li Y., Zhang Y., Wang M., Lightgcn: Simplifying and powering graph convolution network for recommendation, Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval (SIGIR), (2020); Svajlenko J., Roy C.K., Evaluating clone detection tools with bigclonebench, 2015 IEEE international conference on software maintenance and evolution (ICSME). IEEE, (2015); Eschweiler S., Yakdan K., Gerhards-Padilla E., discovre: Efficient cross-architecture identification of bugs in binary code, Network and Distributed System Security Symposium (NDSS), (2016); Baxter I.D., Yahin A., Moura L., Sant'Anna M., Bier L., Clone detection using abstract syntax trees, Proceedings. International Conference on Software Maintenance. IEEE, (1998); Zhang H., Chen W., Hao Y., Li G., Zhai Y., Zou X., Qian Z., Statically discovering high-order taint style vulnerabilities in os kernels, Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security (CCS), (2021); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in neural information processing systems, 26, (2013); Hamilton W.L., Ying R., Leskovec J., Inductive representation learning on large graphs, Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS), (2017); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); Cho K., Van Merrienboer B., Bahdanau D., Bengio Y., On the properties of neural machine translation: Encoder-decoder approaches, Proceedings of SSST-8, (2014); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, Computer Science, (2013); Abadi M., Barham P., Chen J., Chen Z., Davis A., Dean J., Devin M., Ghemawat S., Irving G., Isard M., Et al., Tensorflow: A system for large-scale machine learning, 12th USENIX symposium on operating systems design and implementation (OSDI), (2016); Kingma D.P., Ba J., Adam: A method for stochastic optimization, International Conference on Learning Representations (ICLR), (2015); Glorot X., Bengio Y., Understanding the difficulty of training deep feedforward neural networks, Proceedings of the thirteenth international conference on artificial intelligence and statistics (AISTATS). JMLR Workshop and Conference Proceedings, (2010); Zeng J., Chua Z.L., Chen Y., Ji K., Liang Z., Mao J., Watson: Abstracting behaviors from audit logs via aggregation of contextual semantics, NDSS, (2021); Arp D., Quiring E., Pendlebury F., Warnecke A., Pierazzi F., Wressnegger C., Cavallaro L., Rieck K., Dos and don'ts of machine learning in computer security, USENIX Security Symposium, (2022); Narayanan A., Chandramohan M., Venkatesan R., Chen L., Liu Y., Jaiswal S., graph2vec: Learning distributed representations of graphs, (2017); Van Der Maaten L., Hinton G., Visualizing data using t-sne, Journal of machine learning research, 9, 11, (2008); Kawrykow D., Robillard M.P., Improving api usage through automatic detection of redundant code, IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, (2009); Poeplau S., Fratantonio Y., Bianchi A., Kruegel C., Vigna G., Execute this! analyzing unsafe and malicious dynamic code loading in android applications, NDSS, (2014); Zhang Y., Luo X., Yin H., Dexhunter: Toward extracting hidden code from packed android applications, European Symposium on Research in Computer Security, (2015); Ahmadi M., Farkhani R.M., Williams R., Lu L., Finding bugs using your own code: detecting functionally-similar yet inconsistent code, 30th USENIX Security Symposium (USENIX Security), (2021); Brumley D., Poosankam P., Song D., Zheng J., Automatic patchbased exploit generation is possible: Techniques and implications, 2008 IEEE Symposium on Security and Privacy (S&P). IEEE, (2008); Zibran M.F., Roy C.K., Towards flexible code clone detection, management, and refactoring in ide, Proceedings of the 5th International Workshop on Software Clones (IWSC), (2011); Tsantalis N., Mazinanian D., Rostami S., Clone refactoring with lambda expressions, 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE). IEEE, (2017); Holmes R., Murphy G.C., Using structural context to recommend source code examples, Proceedings of the 27th International Conference on Software Engineering (ICSE), (2005); Keivanloo I., Rilling J., Zou Y., Spotting working code examples, Proceedings of the 36th International Conference on Software Engineering (ICSE), (2014); Nishi M.A., Damevski K., Scalable code clone detection and search based on adaptive prefix filtering, Journal of Systems and Software, (2018); Su F.-H., Bell J., Harvey K., Sethumadhavan S., Kaiser G., Jebara T., Code relatives: detecting similarly behaving software, Proceedings of the the 24th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering (ESEC/FSE), (2016); Keller P., Kabore A.K., Plein L., Klein J., Le Traon Y., Bissyande T.F., What you see is what it means! semantic representation learning of code based on visualization and transfer learning, (2021); Kargen U., Shahmehri N., Towards robust instruction-level trace alignment of binary code, 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, (2017); Xu Z., Chen B., Chandramohan M., Liu Y., Song F., Spain: security patch analysis for binaries towards understanding the pain and pills, 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE). IEEE, (2017); Ding S.H., Fung B.C., Charland P., Asm2vec: Boosting static representation robustness for binary clone search against code obfuscation and compiler optimization, 2019 IEEE Symposium on Security and Privacy (S&P). IEEE, (2019); Pei K., Xuan Z., Yang J., Jana S., Ray B., Trex: Learning execution semantics from micro-traces for binary similarity, (2020); Duan Y., Li X., Wang J., Yin H., Deepbindiff: Learning programwide code representations for binary diffing, Network and Distributed System Security Symposium (NDSS), (2020); Li X., Qu Y., Yin H., Palmtree: learning an assembly language model for instruction embedding, Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security (CCS), (2021); David Y., Yahav E., Tracelet-based code search in executables, Acm Sigplan Notices, (2014); Huang H., Youssef A.M., Debbabi M., Binsequence: Fast, accurate and scalable binary code reuse detection, Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security (AsiaCCS), (2017); Feng Q., Zhou R., Xu C., Cheng Y., Testa B., Yin H., Scalable graph-based bug search for firmware images, Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security (CCS), (2016); Xu X., Liu C., Feng Q., Yin H., Song L., Song D., Neural networkbased graph embedding for cross-platform binary code similarity detection, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security (CCS), (2017); Caldeira P.M., Sakamoto K., Washizaki H., Fukazawa Y., Shimada T., Improving syntactical clone detection methods through the use of an intermediate representation, 2020 IEEE 14th International Workshop on Software Clones (IWSC). IEEE, (2020); Kononenko O., Zhang C., Godfrey M.W., Compiling clones: What happens?, 2014 IEEE International Conference on Software Maintenance and Evolution (ICSME). IEEE, (2014); Lakhotia A., Preda M.D., Giacobazzi R., Fast location of similar code fragments using semantic'juice, Proceedings of the 2nd ACM SIGPLAN Program Protection and Reverse Engineering Workshop, (2013); Cordy J.R., Roy C.K., The nicad clone detector, 2011 IEEE 19th International Conference on Program Comprehension (ICPC). IEEE, (2011); Li J., Rong Y., Cheng H., Meng H., Huang W., Huang J., Semisupervised graph classification: A hierarchical graph perspective, The World Wide Web Conference (WWW), (2019); Wang X., He X., Wang M., Feng F., Chua T.-S., Neural graph collaborative filtering, Proceedings of the 42nd international ACM SIGIR conference on Research and development in Information Retrieval (SIGIR), (2019); Xu K., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks?, International Conference on Learning Representations (ICLR), (2019); Liu S., A unified framework to learn program semantics with graph neural networks, 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, (2020); Wang Y., Wang K., Gao F., Wang L., Learning semantic program embeddings with graph interval neural network, Proceedings of the ACM on Programming Languages, 4, OOPSLA, (2020); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proceedings of the 28th international conference on program comprehension (ICPC), (2020); Liu S., Chen Y., Xie X., Siow J.K., Liu Y., Retrieval-augmented generation for code summarization via hybrid gnn, International Conference on Learning Representations (ICLR), (2020); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, International Conference on Learning Representations (ICLR), (2019); Dinella E., Dai H., Li Z., Naik M., Song L., Wang K., Hoppity: Learning graph transformations to detect and fix bugs in programs, International Conference on Learning Representations (ICLR), (2020); Liu J., Zeng J., Wang X., Ji K., Liang Z., Tell: Log level suggestions via modeling multi-level code block information, Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA), (2022); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE transactions on neural networks, (2008)",,"45th IEEE/ACM International Conference on Software Engineering, ICSE 2023",15 May 2023 through 16 May 2023,Melbourne,190685,English,Conference paper,Final,,Scopus,2-s2.0-85171745038,6
Nashid N.; Sintaha M.; Mesbah A.,"Nashid, Noor (57321839100); Sintaha, Mifta (57207773539); Mesbah, Ali (17345931800)",57321839100; 57207773539; 17345931800,Embedding Context as Code Dependencies for Neural Program Repair,2023,"Proceedings - 2023 IEEE 16th International Conference on Software Testing, Verification and Validation, ICST 2023",,,,95,106,11,1,10.1109/ICST57152.2023.00018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161949341&doi=10.1109%2fICST57152.2023.00018&partnerID=40&md5=c0ba7521813481c648b352b9f7768f43,"Deep learning-based program repair has received significant attention from the research community lately. Most existing techniques treat source code as a sequence of tokens or abstract syntax trees. Consequently, they cannot incorporate semantic contextual information pertaining to a buggy line of code and its fix. In this work, we propose a program repair technique called GLANCE that combines static program analysis with graph-to-sequence learning for capturing contextual information. To represent contextual information, we introduce a graph representation that can encode information about the buggy code and its repair ingredients by embedding control and data flow information. We employ a fine-grained graphical code representation, which explicitly describes code change context and embeds semantic relationships between code elements. GLANCE leverages a graph neural network and a sequence-based decoder to learn from this semantic code representation. We evaluated our work against six state-of-the-art techniques, and our results show that GLANCE fixes 52% more bugs than the best performing technique.  © 2023 IEEE.","Goues C.L., Pradel M., Roychoudhury A., Automated program repair, Commun. ACM, 62, 12, pp. 56-65, (2019); Monperrus M., Automatic software repair: A bibliography, ACM Comput. Surv., 51, 1, (2018); Chen Z., Kommrusch S.J., Tufano M., Pouchet L., Poshyvanyk D., Monperrus M., SEQUENCER: Sequence-to-sequence learning for endto- end program repair, Transactions on Software Engineering, pp. 1-1, (2019); Mesbah A., Rice A., Johnston E., Glorioso N., Aftandilian E., DeepDelta: Learning to repair compilation errors, Foundations of Software Engineering. ACM, pp. 925-936, (2019); Li Y., Wang S., Nguyen T.N., DLFix: Context-based code transformation learning for automated program repair, International Conference on Software Engineering. ACM, pp. 602-614, (2020); Gupta R., Pal S., Kanade A., Shevade S., DeepFix: Fixing common c language errors by deep learning, AAAI Conference on Artificial Intelligence., pp. 1345-1351, (2017); Dinella E., Dai H., Li Z., Naik M., Song L., Wang K., Hoppity: Learning graph transformations to detect and fix bugs in programs, International Conference on Learning Representations, (2020); Tufano M., Watson C., Bavota G., Penta M.D., White M., Poshyvanyk D., An empirical study on learning bug-fixing patches in the wild via neural machine translation, Trans. Softw. Eng. Methodol., (2019); Lutellier T., Pham H.V., Pang L., Li Y., Wei M., Tan L., CoCoNuT: Combining context-aware neural translation models using ensemble for program repair, International Symposium on Software Testing and Analysis. ACM, pp. 101-114, (2020); Ahmed T., Ledesma N.R., Devanbu P., SYNSHINE: Improved fixing of syntax errors, Transactions on Software Engineering, (2022); Berabi B., He J., Raychev V., Vechev M., TFix: Learning to fix coding errors with a text-to-text transformer, International Conference on Machine Learning. PMLR, pp. 780-791, (2021); Yuan W., Zhang Q., He T., Fang C., Hung N.Q.V., Hao X., Yin H., CIRCLE: Continual repair across programming languages, International Symposium on Software Testing and Analysis. ACM, pp. 678-690, (2022); Mashhadi E., Hemmati H., Applying codebert for automated program repair of java simple bugs, Mining Software Repositories. IEEE, pp. 505-509, (2021); Zhu Q., Sun Z., Xiao Y.-A., Zhang W., Yuan K., Xiong Y., Zhang L., A syntax-guided edit decoder for neural program repair, Foundations of Software Engineering. ACM, pp. 341-353, (2021); Li Y., Wang S., Nguyen T.N., DEAR: A novel deep learning-based approach for automated program repair, International Conference on Software Engineering. ACM, pp. 511-523, (2022); Ye H., Martinez M., Monperrus M., Neural program repair with execution-based backpropagation, International Conference on Software Engineering. ACM, pp. 1506-1518, (2022); Fakhoury S., Ma Y., Arnaoudova V., Adesope O., The effect of poor source code lexicon and readability on developers' cognitive load, Conference on Program Comprehension. ACM, pp. 286-296, (2018); Aljehane S., Sharif B., Maletic J., Determining differences in reading behavior between experts and novices by investigating eye movement on source code constructs during a bug fixing task, ACM Symposium on Eye Tracking Research and Applications. ACM, (2021); Pradel M., Sen K., DeepBugs: A learning approach to name-based bug detection, ACM on Programming Languages, 2, (2018); Hata H., Shihab E., Neubig G., Learning to generate corrective patches using neural machine translation, (2019); Haque S., LeClair A., Wu L., McMillan C., Improved automatic summarization of subroutines via attention to file context, Mining Software Repositories. ACM, pp. 300-310, (2020); Tang B., Li B., Bo L., Wu X., Cao S., Sun X., GrasP: Graphto- sequence learning for automated program repair, International Conference on Software Quality, Reliability and Security. IEEE, pp. 819-828, (2021); Weiser M., Program slicing, Transactions on Software Engineering, 10, 4, pp. 352-357, (1984); Sintaha M., Nashid N., Mesbah A., Katana: Dual slicing-based context for learning bug fixes, (2022); GLANCE, (2023); Spinellis D., Effective debugging: 66 specific ways to debug software and systems, Addison-Wesley Professional, (2016); Hanam Q., Brito F.S.D.M., Mesbah A., Discovering bug patterns in javascript, Foundations of Software Engineering. ACM, pp. 144-156, (2016); Sasirekha N., Robert A.E., Hemalatha D.M., Program slicing techniques and its applications, (2011); Barr E.T., Brun Y., Devanbu P., Harman M., Sarro F., The plastic surgery hypothesis, Foundations of Software Engineering. ACM, pp. 306-317, (2014); Horwitz S., Reps T., The use of program dependence graphs in software engineering, International Conference on Software Engineering. ACM, pp. 392-411, (1992); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Transactions on Neural Networks, 20, 1, pp. 61-80, (2009); Zhou J., Cui G., Hu S., Zhang Z., Yang C., Liu Z., Wang L., Li C., Sun M., Graph neural networks: A review of methods and applications, AI Open, pp. 57-81, (2020); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A comprehensive survey on graph neural networks, Transactions on Neural Networks and Learning Systems, 32, 1, pp. 4-24, (2021); Wu L., Chen Y., Shen K., Guo X., Gao H., Li S., Pei J., Long B., Graph neural networks for natural language processing: A survey, (2021); Wainakh Y., Rauf M., Pradel M., IdBench: Evaluating semantic representations of identifier names in source code, International Conference on Software Engineering. IEEE, pp. 562-573, (2021); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, International Conference on Learning Representations, Workshop Track Proceedings, (2013); Zhang S., Zheng D., Hu X., Yang M., Bidirectional long short-term memory networks for relation classification, Pacific Asia conference on language, information and computation, pp. 73-78, (2015); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, International Conference on Learning Representations, (2017); Bahdanau D., Cho K., Bengio Y., Neural machine translation by jointly learning to align and translate, International Conference on Learning Representations, (2015); See A., Liu P.J., Manning C.D., Get to the point: Summarization with pointer-generator networks, (2017); Tu Z., Lu Z., Liu Y., Liu X., Li H., Modeling coverage for neural machine translation, Association for Computational Linguistics. ACL, pp. 76-85, (2016); Vinyals O., Fortunato M., Jaitly N., Pointer networks, Advances in neural information processing systems, 28, (2015); Xu K., Wu L., Wang Z., Feng Y., Sheinin V., Graph2Seq: Graph to sequence learning with attention-based neural networks, (2018); (2022); Sotomayor L., Avoiding javascript scoping pitfalls, (2022); Allamanis M., The adverse effects of code duplication in machine learning models of code, International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software. ACM, pp. 143-153, (2019); Tufano R., Pascarella L., Tufano M., Poshyvanyk D., Bavota G., Towards automating code review activities, International Conference on Software Engineering. IEEE, pp. 163-174, (2021); Bengio Y., Practical recommendations for gradient-based training of deep architectures, Neural Networks: Tricks of the Trade, ser. LNCS., 7700, pp. 437-478, (2012); Kingma D.P., Ba J., Adam: A method for stochastic optimization, International Conference on Learning Representations, (2015); Wu L., Chen Y., Ji H., Liu B., Deep Learning on Graphs for Natural Language Processing. ACM, pp. 2651-2653, (2021); Chakraborty S., Ray B., On multi-modal learning of editing source code, International Conference on Automated Software Engineering. IEEE, pp. 443-455, (2021); Xiao Y., Ahmed S., Song W., Ge X., Viswanath B., Yao D., Embedding code contexts for cryptographic api suggestion: New methodologies and comparisons, (2021); Ciniselli M., Cooper N., Pascarella L., Poshyvanyk D., Di Penta M., Bavota G., An empirical study on the usage of BERT models for code completion, Mining Software Repositories. IEEE, pp. 108-119, (2021); Papineni K., Roukos S., Ward T., Zhu W.-J., BLEU: A method for automatic evaluation of machine translation, Association for Computational Linguistics. ACL, pp. 311-318, (2002); Ciniselli M., Cooper N., Pascarella L., Mastropaolo A., Aghajani E., Poshyvanyk D., Di Penta M., Bavota G., An empirical study on the usage of transformer models for code completion, Transactions on Software Engineering, pp. 1-1, (2021); Mastropaolo A., Scalabrino S., Cooper N., Palacio D.N., Poshyvanyk D., Oliveto R., Bavota G., Studying the usage of text-totext transfer transformer to support code-related tasks, International Conference on Software Engineering. IEEE, pp. 336-347, (2021); Mastropaolo A., Cooper N., Palacio D., Scalabrino S., Poshyvanyk D., Oliveto R., Bavota G., Using transfer learning for code-related tasks, Transactions on Software Engineering, 1, pp. 1-20, (2022); Gao Z., Xia X., Grundy J., Lo D., Li Y.-F., Generating question titles for stack overflow from mined code snippets, Trans. Softw. Eng. Methodol., 29, 4, pp. 1-37, (2020); Shahbazi R., Sharma R., Fard F.H., API2Com: On the improvement of automatically generated code comments using api documentations, International Conference on Program Comprehension. IEEE, pp. 411-421, (2021); Spadini D., Aniche M., Bacchelli A., PyDriller: Python framework for mining software repositories, Foundations of Software Engineering. ACM, pp. 908-911, (2018); Understand by scitools, (2021); Wen M., Chen J., Wu R., Hao D., Cheung S.-C., Context-aware patch generation for better automated program repair, International Conference on Software Engineering. ACM, pp. 1-11, (2018); Jiang N., Lutellier T., Tan L., CURE: Code-aware neural machine translation for automatic program repair, International Conference on Software Engineering. IEEE, pp. 1161-1173, (2021); Chakraborty S., Ding Y., Allamanis M., Ray B., CODIT: Code editing with tree-based neural models, Transactions on Software Engineering, pp. 1-1, (2020); Ding Y., Ray B., Devanbu P., Hellendoorn V.J., Patching as translation: The data and the metaphor, International Conference on Automated Software Engineering. ACM, pp. 275-286, (2020); Circle github repository, (2022); Chen Z., Hellendoorn V.J., Lamblin P., Maniatis P., Manzagol P.-A., Tarlow D., Moitra S., PLUR: A unifying, graph-based view of program learning, understanding, and repair, Advances in Neural Information Processing Systems, 34, pp. 23089-23101, (2021); Zhong W., Ge H., Ai H., Li C., Liu K., Ge J., Bin L., StandUp4NPR: Standardizing setup for empirically comparing neural program repair systems, International Conference on Automated Software Engineering. IEEE, (2022); Gu J., Chen Z., Monperrus M., Multimodal representation for neural code search, International Conference on Software Maintenance and Evolution. IEEE, pp. 483-494, (2021); Karampatsis R.-M., Sutton C., How often do single-statement bugs occur? the ManySStuBs4J dataset, Mining Software Repositories. ACM, pp. 573-577, (2020); Kamienski A.V., Palechor L., Bezemer C.-P., Hindle A., PySStuBs: Characterizing single-statement bugs in popular open-source python projects, Mining Software Repositories. IEEE, pp. 520-524, (2021); Zhang K., Wang W., Zhang H., Li G., Jin Z., Learning to represent programs with heterogeneous graphs, International Conference on Program Comprehension, pp. 378-389, (2022); Schlichtkrull M., Kipf T.N., Bloem P., Berg R.V.D., Titov I., Welling M., Modeling relational data with graph convolutional networks, European semantic web conference., pp. 593-607, (2018); Tian A., Zhang C., Rang M., Yang X., Zhan Z., RA-GCN: Relational aggregation graph convolutional network for knowledge graph completion, International Conference on Machine Learning and Computing. ACM, pp. 580-586, (2020); (2022); (2022); Gyimesi P., Vancsics B., Stocco A., Mazinanian D., Beszedes A., Ferenc R., Mesbah A., BugsJS: A benchmark of javascript bugs, IEEE Conference on Software Testing, Validation and Verification. IEEE, pp. 90-101, (2019); Le Goues C., Nguyen T., Forrest S., Weimer W., GenProg: A generic method for automatic software repair, Transactions on Software Engineering, 38, pp. 54-72, (2012); Liu K., Koyuncu A., Kim K., Kim D., Bissyande T.F., LSRepair: Live search of fix ingredients for automated program repair, Asia-Pacific Software Engineering Conference, pp. 658-662, (2018); Mehne B., Yoshida H., Prasad M., Sen K., Gopinath D., Khurshid S., Accelerating search-based program repair, International Conference on Software Testing, Verification and Validation, pp. 227-238, (2018); Chen L., Pei Y., Pan M., Zhang T., Wang Q., Furia C.A., Program repair with repeated learning, Transactions on Software Engineering, (2022); Wotawa F., Nica M., Nica I., Automated debugging based on a constraint model of the program and a test case, The Journal of Logic and Algebraic Programming, 81, pp. 390-407, (2012); Malik M.Z., Siddiqui J.H., Khurshid S., Constraint-based program debugging using data structure repair, International Conference on Software Testing, Verification and Validation. IEEE, pp. 190-199, (2011); Schramm L., Improving performance of automatic program repair using learned heuristics, Foundations of Software Engineering. ACM, pp. 1071-1073, (2017); Kim D., Nam J., Song J., Kim S., Automatic patch generation learned from human-written patches, International Conference on Software Engineering. IEEE, pp. 802-811, (2013); Saha R.K., Lyu Y., Yoshida H., Prasad M.R., ELIXIR: Effective object oriented program repair, International Conference on Automated Software Engineering. IEEE, pp. 648-659, (2017); Durieux T., Cornu B., Seinturier L., Monperrus M., Dynamic patch generation for null pointer exceptions using metaprogramming, International Conference on Software Analysis, Evolution and Reengineering. IEEE, pp. 349-358, (2017); Liu X., Zhong H., Mining stackoverflow for program repair, International Conference on Software Analysis, Evolution and Reengineering. IEEE, pp. 118-129, (2018); Liu K., Koyuncu A., Kim D., Bissyande T.F., TBar: Revisiting template-based automated program repair, International Symposium on Software Testing and Analysis. ACM, pp. 31-42, (2019); Tufano M., Pantiuchina J., Watson C., Bavota G., Poshyvanyk D., On learning meaningful code changes via neural machine translation, ICSE. IEEE, pp. 25-36, (2019); Watson C., Tufano M., Moran K., Bavota G., Poshyvanyk D., On learning meaningful assert statements for unit test cases, International Conference on Software Engineering. ACM, pp. 1398-1409, (2020); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, International Conference on Software Engineering. IEEE, pp. 783-794, (2019); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, Mining Software Repositories. ACM, pp. 542-553, (2018); Ding Z., Li H., Shang W., Chen T.-H.P., Towards learning generalizable code embeddings using task-agnostic graph convolutional networks, Trans. Softw. Eng. Methodol., (2022); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proc. ACM Program. Lang., 3, (2019); Bui N.D., Yu Y., Jiang L., Infercode: Self-supervised learning of code representations by predicting subtrees, International Conference on Software Engineering. IEEE, pp. 1186-1197, (2021); Ma W., Zhao M., Soremekun E., Hu Q., Zhang J.M., Papadakis M., Cordy M., Xie X., Le Traon Y., Graphcode2vec: Generic code embedding via lexical and program dependence analyses, Mining Software Repositories. IEEE, pp. 524-536, (2022); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, International Conference on Learning Representations, pp. 520-524, (2018)",Fidelity Investments; Google; IEEE Computer Society; Lero; Meet in Ireland; Meta,"16th IEEE International Conference on Software Testing, Verification and Validation, ICST 2023",16 April 2023 through 20 April 2023,Dublin,189044,English,Conference paper,Final,,Scopus,2-s2.0-85161949341,8
Wang W.; Zhang K.; Li G.; Liu S.; Li A.; Jin Z.; Liu Y.,"Wang, Wenhan (57216463961); Zhang, Kechi (57706554300); Li, Ge (55901136600); Liu, Shangqing (57218717656); Li, Anran (57218704295); Jin, Zhi (8961795500); Liu, Yang (56911879800)",57216463961; 57706554300; 55901136600; 57218717656; 57218704295; 8961795500; 56911879800,Learning Program Representations with a Tree-Structured Transformer,2023,"Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",,,,248,259,11,0,10.1109/SANER56733.2023.00032,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160553032&doi=10.1109%2fSANER56733.2023.00032&partnerID=40&md5=026c96d9f2a353f6e064483c12951584,"Learning vector representations for programs is a critical step in applying deep learning techniques for program understanding tasks. Various neural network models are proposed to learn from tree-structured program representations, e.g., abstract syntax tree (AST) and concrete syntax tree (CST). However, most neural architectures either fail to capture long-range dependencies which are ubiquitous in programs, or cannot learn effective representations for syntax tree nodes, making them incapable of performing the node-level prediction tasks, e.g., bug localization. In this paper, we propose Tree-Transformer, a novel recursive tree-structured neural network to learn the vector representations for source codes. We propose a multi-head attention mechanism to model the dependency between siblings and parent-children node pairs. Moreover, we propose a bi-directional propagation strategy to allow node information passing in two directions, bottom-up and top-down along trees. In this way, Tree-Transformer can learn the information of the node features as well as the global contextual information. The extensive experimental results show that our Tree-Transformer significantly outperforms the existing tree-based and graph-based program representation learning approaches in both the tree-level and node-level prediction tasks. © 2023 IEEE.","Wei H.-H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proceedings of the 26th International Joint Conference on Artificial Intelligence, pp. 3034-3040, (2017); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 261-271, (2020); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems 2019. Neural Information Processing Systems (NIPS), (2019); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Zugner D., Kirschstein T., Catasta M., Leskovec J., Gunnemann S., Language-agnostic representation learning of source code from structure and context, International Conference on Learning Representations, (2021); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Thirtieth AAAI Conference on Artificial Intelligence, (2016); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering, pp. 783-794, (2019); Wang W., Li G., Shen S., Xia X., Jin Z., Modular tree network for source code representation learning, ACM Transactions on Software Engineering and Methodology (TOSEM), 29, 4, pp. 1-23, (2020); Bui N.D., Yu Y., Jiang L., Treecaps: Tree-based capsule networks for source code processing, Proceedings of the AAAI Conference on Artificial Intelligence, 35, 1, pp. 30-38, (2021); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, International Conference on Learning Representations, (2018); Liu S., Chen Y., Xie X., Siow J.K., Liu Y., Retrieval-augmented generation for code summarization via hybrid gnn, International Conference on Learning Representations, (2021); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, International Conference on Learning Representations, (2019); Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, International conference on learning representations, (2020); Liu S., Xie X., Ma L., Siow J., Liu Y., Graphsearchnet: Enhancing gnns via capturing global dependency for semantic code search, (2021); Allamanis M., Barr E.T., Ducousso S., Gao Z., Typilus: Neural type hints, Proceedings of the 41st acm sigplan conference on programming language design and implementation, pp. 91-105, (2020); Tai K.S., Socher R., Manning C.D., Improved semantic representations from tree-structured long short-term memory networks, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 1556-1566, (2015); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, pp. 1-29, (2019); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating sequences from structured representations of code, International Conference on Learning Representations, (2019); Shiv V., Quirk C., Novel positional encodings to enable tree-based transformers, Advances in Neural Information Processing Systems, 32, pp. 12081-12091, (2019); Jiang X., Zheng Z., Lyu C., Li L., Lyu L., Treebert: A tree-based pre-trained model for programming language, UAI 2021: Uncertainty in Artificial Intelligence, (2021); Zhang K., Wang W., Zhang H., Li G., Jin Z., Learning to represent programs with heterogeneous graphs, 2022 IEEE/ACM 30th International Conference on Program Comprehension (ICPC), pp. 378-389, (2022); Gilmer J., Schoenholz S.S., Riley P.F., Vinyals O., Dahl G.E., Neural message passing for quantum chemistry, International conference on machine learning, pp. 1263-1272, (2017); Ahmed M., Samee M.R., Mercer R.E., You only need attention to traverse trees, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 316-322, (2019); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P., Multimodal attention network learning for semantic source code retrieval, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 13-25, (2019); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser S., Polosukhin I., Attention is all you need, Advances in neural information processing systems, pp. 5998-6008, (2017); Goller C., Kuchler A., Learning task-dependent distributed representations by backpropagation through structure, Proceedings of International Conference on Neural Networks (ICNN'96), 1, pp. 347-352, (1996); Ke G., He D., Liu T.-Y., Rethinking positional encoding in language pre-training, International Conference on Learning Representations, (2021); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, International Conference on Learning Representations, (2016); Puri R., Kung D.S., Janssen G., Zhang W., Domeniconi G., Zolotov V., Dolby J., Chen J., Choudhury M., Decker L., Et al., Codenet: A largescale ai for code dataset for learning a diversity of coding tasks, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2), (2021); Parr T., The definitive ANTLR 4 reference, (2013); Kanade A., Maniatis P., Balakrishnan G., Shi K., Learning and evaluating contextual embedding of source code, International Conference on Machine Learning, pp. 5110-5121, (2020); Jesse K., Devanbu P.T., Manytypes4typescript: A comprehensive typescript dataset for sequence-based type inference, 2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR), pp. 294-298, (2022); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, International Conference on Learning Representations, (2017); Xu K., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks?, International Conference on Learning Representations, (2019); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Codebert: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Buratti L., Pujar S., Bornea M., McCarley S., Zheng Y., Rossiello G., Morari A., Laredo J., Thost V., Zhuang Y., Et al., Exploring software naturalness through neural language models, (2020); Wang M.Y., Deep graph library: Towards efficient and scalable deep learning on graphs, ICLR workshop on representation learning on graphs and manifolds, (2019); Vasic M., Kanade A., Maniatis P., Bieber D., Singh R., Neural program repair by jointly learning to localize and repair, International Conference on Learning Representations, (2019); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet challenge: Evaluating the state of semantic code search, (2019); Sontakke A.N., Patwardhan M., Vig L., Medicherla R.K., Naik R., Shroff G., Code summarization: Do transformers really understand code?, Deep Learning for Code Workshop, (2022); Socher R., Lin C.C.-Y., Ng A.Y., Manning C.D., Parsing natural scenes and natural language with recursive neural networks, ICML, (2011); Peng H., Li G., Wang W., Zhao Y., Jin Z., Integrating tree path in transformer for code representation, Thirty-Fifth Conference on Neural Information Processing Systems, (2021); Tang Z., Shen X., Li C., Ge J., Huang L., Zhu Z., Luo B., Ast-trans: Code summarization with efficient tree-structured attention, 2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE), pp. 150-162, (2022); Teng Z., Zhang Y., Head-lexicalized bidirectional tree lstms, Transactions of the Association for Computational Linguistics, 5, pp. 163-177, (2017); Sabour S., Frosst N., Hinton G.E., Dynamic routing between capsules, Proceedings of the 31st International Conference on Neural Information Processing Systems, pp. 3859-3869, (2017); Yao Z., Xu F., Yin P., Sun H., Neubig G., Learning structural edits via incremental tree transformations, International Conference on Learning Representations, (2021); Xue S., Zhang L., Li A., Li X.-Y., Ruan C., Huang W., Appdna: App behavior profiling via graph-based deep learning, IEEE INFOCOM 2018-IEEE Conference on Computer Communications, pp. 1475-1483, (2018); Li A., Xue S., Li X., Zhang L., Qian J., Appdna: Profiling app behavior via deep-learning on function call graphs, IEEE Transactions on Emerging Topics in Computing, (2020); Ma W., Zhao M., Soremekun E., Hu Q., Zhang J.M., Papadakis M., Cordy M., Xie X., Traon Y.L., Graphcode2vec: generic code embedding via lexical and program dependence analyses, Proceedings of the 19th International Conference on Mining Software Repositories, pp. 524-536, (2022); Li Z., Zhou Q., Li C., Xu K., Cao Y., Improving BERT with syntaxaware local attention, Findings of the Association for Computational Linguistics, pp. 645-653, (2021); Guo D., Ren S., Lu S., Feng Z., Tang D., Shujie L., Zhou L., Duan N., Svyatkovskiy A., Fu S., Et al., Graphcodebert: Pre-training code representations with data flow, International Conference on Learning Representations, (2021); Guo D., Lu S., Duan N., Wang Y., Zhou M., Yin J., Unixcoder: Unified cross-modal pre-training for code representation, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 7212-7225, (2022)",IEEE; IEEE Computer Society; Macau University of Science and Technology (MUST),"30th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",21 March 2023 through 24 March 2023,Macao,188717,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85160553032,9
Sukur N.; Milošević N.; Pracner D.; Budimac Z.,"Sukur, Nataša (57191344491); Milošević, Nemanja (57190280120); Pracner, Doni (23092047000); Budimac, Zoran (6505861714)",57191344491; 57190280120; 23092047000; 6505861714,Automated program improvement with reinforcement learning and graph neural networks,2024,Soft Computing,28,3,,2593,2604,11,2,10.1007/s00500-023-08559-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160861647&doi=10.1007%2fs00500-023-08559-1&partnerID=40&md5=8f31b665e0a0762d68a81c3d84e68699,"Automated software transformations and the process of automated program repair and improvement are an important aspect of modern software engineering practices. In this paper, we describe a system which uses a graph-based deep learning model that can be trained to automatically transform and improve computer programs. By operating on language-agnostic, universal graph-like structures easily extractable from source code files (abstract syntax trees), the deep learning agent learns which transformations should be effectively applied to various structures recognized in the source code in order to improve it. By defining a metric which we want to improve and introducing an optimization task—a reinforcement learning setting, an agent learns to automatically apply a chain of transformations to the program, drastically improving it. While similar program improvement processes exist, they exclusively use exhaustive search algorithms to try all the possible code transformations which is a long process susceptible to local optimum issues. Our solution aims to model and embed structural knowledge about the programs being transformed which greatly helps the agent to choose best possible code transformations to apply. Elements of the approach we present in this paper are further applicable not just to automatic software improvement tasks, but also to other code-related tasks. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs. Arxiv Preprint Arxiv, 1711, (2017); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proceedings of the ACM on programming languages, 3, POPL, pp. 1-29, (2019); Arcuri A., Yao X., A novel co-evolutionary approach to automatic software bug fixing, Evolutionary Computation, pp. 162-168, (2008); Balog M., Gaunt A.L., Brockschmidt M., Nowozin S., Tarlow D., Deepcoder: Learning to Write Programs. Arxiv Preprint Arxiv, (2016); Ben-Nun T., Jakobovits A.S., Hoefler T., Neural code comprehension: A learnable representation of code semantics, Adv Neural Inf Process Syst, (2018); Brockman G., Cheung V., Pettersson L., Schneider J., Schulman J., Tang J., Zaremba W., Openai Gym. Arxiv Preprint Arxiv, (2016); Bunel R., Hausknecht M., Devlin J., Singh R., Kohli P., Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis. Arxiv Preprint Arxiv, 1805, (2018); Campbell G.A., SonarSource S., Cognitive complexity, (2020); Cummins C., Fisches Z.V., Ben-Nun T., Hoefler T., Leather H., Programl: Graph-Based Deep Learning for Program Optimization and Analysis. Arxiv Preprint Arxiv, (2020); Dasgupta S.S., Ray S.N., Talukdar P., Hyte: Hyperplane-based temporally aware knowledge graph embedding, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 2001-2011, (2018); Ebert C., Cain J., Antoniol G., Counsell S., Laplante P., Cyclomatic complexity, IEEE softw, 33, 6, pp. 27-29, (2016); Fey M., Lenssen J.E., Fast Graph Representation Learning with Pytorch Geometric. Arxiv Preprint Arxiv, (2019); Forrest S., Nguyen T., Weimer W., Le Goues C., A genetic programming approach to automated software repair, Proceedings of the 11Th Annual Conference on Genetic and Evolutionary Computation, pp. 947-954, (2009); Fu C., Chen H., Liu H., Chen X., Tian Y., Koushanfar F., Zhao J., Coda: An end-to-end neural program decompiler, Adv Neural Inf Process Syst, 32, (2019); Grover A., Leskovec J., pp. 855-864, (2016); Gupta R., Pal S., Kanade A., Shevade S., Deepfix: Fixing common c language errors by deep learning, Thirty-First AAAI Conference on Artificial Intelligence, (2017); Hagberg A., Swart P., S Chult D., Exploring network structure, dynamics, and function using networkx. Technical report, Los Alamos National Lab.(Lanl), (2008); Hamilton W., Ying Z., Leskovec J., Inductive representation learning on large graphs, Adv Neural Inf Process Syst, 30, (2017); Harrand N., Soto-Valero C., Monperrus M., Baudry B., Java decompiler diversity and its application to meta-decompilation, J Syst Softw, 168, (2020); Heo K., Lee W., Pashakhanloo P., Naik M., Effective program debloating via reinforcement learning, Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pp. 380-394, (2018); Huang S., Ontanon S., A closer look at invalid action masking in policy gradient algorithms, Arxiv Preprint Arxiv, 2006, (2020); Katz D.S., Ruchti J., Schulte E., Using recurrent neural networks for decompilation, In: 2018 IEEE 25Th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 346-356, (2018); Kim D., Nam J., Song J., Kim S., Automatic patch generation learned from human-written patches, Proceedings of the 2013 International Conference on Software Engineering. ICSE ’13, pp. 802-811, (2013); Kingma D.P., Ba J., Adam: A method for stochastic optimization, . Arxiv Preprint Arxiv, 1412, (2014); Le Goues C., Nguyen T., Forrest S., Weimer W., Genprog: a generic method for automatic software repair, IEEE Trans Software Eng, 38, 1, (2012); Liang C., Berant J., Le Q., Forbus K.D., Lao N., Neural symbolic machines: Learning semantic parsers on freebase with weak supervision, Arxiv Preprint Arxiv, 1611, (2016); Li Z., Wu Q., Qian K., Adabot: Fault-tolerant java decompiler, Arxiv Preprint Arxiv, 1908, (2019); Malkowski A., Grzechocinski J., Wawrzynski P., Graph autoencoder with constant dimensional latent space, Arxiv Preprint Arxiv, 2201, (2022); Nie M., Chen D., Wang D., Reinforcement learning on graphs: a survey, IEEE Trans Emerg Top Comput Intell, (2023); Parisotto E., Mohamed A.-R., Singh R., Li L., Zhou D., Kohli P., Neuro-symbolic program synthesis, Arxiv Preprint Arxiv, 1611, (2016); Pawlak R., Monperrus M., Petitprez N., Noguera C., Seinturier L., Spoon: a library for implementing analyses and transformations of java source code, Softw Pract Exp, 46, pp. 1155-1179, (2015); Perozzi B., Al-Rfou R., Skiena S., Deepwalk: Online learning of social representations, Proceedings of the 20Th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 701-710, (2014); Pracner D., Budimac Z., Enabling code transformations with fermat on simplified bytecode, J Softw Evol Process, 29, 5, (2017); Raffin A., Hill A., Ernestus M., Gleave A., Kanervisto A., Dormann N., Stable baselines 3, (2019); Russell S.J., Norvig P., Artificial intelligence: a modern approach, (2016); Schulman J., Wolski F., Dhariwal P., Radford A., Klimov O., Proximal policy optimization algorithms, . Arxiv Preprint Arxiv, 1707, (2017); Shin E.C.R., Song D., Moazzezi R., Recognizing functions in binaries with neural networks, In: 24Th USENIX Security Symposium (USENIX Security, 15, pp. 611-626, (2015); Sukur N., Pracner D., Budimac Z., Fitness functions and transformations in an automated process, SQAMIA 2019, 8Th Workshop of Software Quality, Analysis, Monitoring, Improvement, and Applications, pp. 17-011710, (2019); Tang C.-Y., Liu C.-H., Chen W.-K., You S.D., Implementing action mask in proximal policy optimization (ppo) algorithm, ICT Express, 6, 3, pp. 200-203, (2020); Wang X., Lyu D., Li M., Xia Y., Yang Q., Wang X., Wang X., Cui P., Yang Y., Sun B., Et al., Apan: Asynchronous propagation attention network for real-time temporal graph embedding, Proceedings of the 2021 International Conference on Management of Data, pp. 2628-2638, (2021); Wang H., Wang S., Xu D., Zhang X., Liu X., Generating effective software obfuscation sequences with reinforcement learning, IEEE Trans Depend Secure Comput, (2020); Ward M., Assembler restructuring in fermat, In: SCAM, pp. 147-156, (2013); Watson A.H., Wallace D.R., McCabe T.J., Structured testing: A testing methodology using the cyclomatic complexity metric, Special Publication (NIST SP), (1996); Yuan Y., Banzhaf W., Arja: automated repair of java programs via multi-objective genetic programming, IEEE Trans Software Eng, 46, 10, pp. 1040-1067, (2018); Yuan Y., Banzhaf W., Toward better evolutionary program repair: an integrated approach, ACM Trans Softw Eng Methodol, (2019); Zhang L., Rosenblatt G., Fetaya E., Liao R., Byrd W., Might M., Urtasun R., Zemel R., Neural guided constraint logic programming for program synthesis, Adv Neural Inf Process Syst, (2018)",,,,,,English,Article,Final,,Scopus,2-s2.0-85160861647,10
Chen C.; Peng X.; Xing Z.; Sun J.; Wang X.; Zhao Y.; Zhao W.,"Chen, Chi (57210821958); Peng, Xin (53865467700); Xing, Zhenchang (8347413500); Sun, Jun (56153273100); Wang, Xin (55985364400); Zhao, Yifan (57205022706); Zhao, Wenyun (8320355200)",57210821958; 53865467700; 8347413500; 56153273100; 55985364400; 57205022706; 8320355200,Holistic Combination of Structural and Textual Code Information for Context Based API Recommendation,2022,IEEE Transactions on Software Engineering,48,8,,2987,3009,22,23,10.1109/TSE.2021.3074309,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104636235&doi=10.1109%2fTSE.2021.3074309&partnerID=40&md5=673fd9afacf9ce76e19fed9b164bd0b9,"Context based API recommendation is an important way to help developers find the needed APIs effectively and efficiently. For effective API recommendation, we need not only a joint view of both structural and textual code information, but also a holistic view of correlated API usage in control and data flow graph as a whole. Unfortunately, existing API recommendation methods exploit structural or textual code information separately. In this work, we propose a novel API recommendation approach called APIRec-CST (API Recommendation by Combining Structural and Textual code information). APIRec-CST is a deep learning model that combines the API usage with the text information in the source code based on an API Context Graph Network and a Code Token Network that simultaneously learn structural and textual features for API recommendation. We apply APIRec-CST to train a model for JDK library based on 1,914 open-source Java projects and evaluate the accuracy and MRR (Mean Reciprocal Rank) of API recommendation with another 6 open-source projects. The results show that our approach achieves respectively a top-1, top-5, top-10 accuracy and MRR of 60.3, 81.5, 87.7 and 69.4 percent, and significantly outperforms an existing graph-based statistical approach and a tree-based deep learning approach for API recommendation. A further analysis shows that textual code information makes sense and improves the accuracy and MRR. The sensitivity analysis shows that the top-k accuracy and MRR of APIRec-CST are insensitive to the number of APIs to be recommended in a hole. We also conduct a user study in which two groups of students are asked to finish 6 programming tasks with or without our APIRec-CST plugin. The results show that APIRec-CST can help the students to finish the tasks faster and more accurately and the feedback on the usability is overwhelmingly positive. © 1976-2012 IEEE.","Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P.T., On the naturalness of software, Proc. 34th Int. Conf. Softw. Eng., pp. 837-847, (2012); Allamanis M., Sutton C.A., Mining source code repositories at massive scale using language modeling, Proc. 10th Working Conf. Mining Softw. Repositories, pp. 207-216, (2013); Nguyen T.T., Nguyen A.T., Nguyen H.A., Nguyen T.N., A statistical semantic language model for source code, Proc. 9th Joint Meeting Eur. Softw. Eng. Conf. ACM SIGSOFT Symp. Found. Softw. Eng., pp. 532-542, (2013); Tu Z., Su Z., Devanbu P.T., On the localness of software, Proc. 22nd ACM SIGSOFT Int. Symp. Found. Softw. Eng, pp. 269-280, (2014); Raychev V., Vechev M.T., Yahav E., Code completion with statistical language models, Proc. 35th ACM SIGPLAN Conf. Program. Lang. Des. Implementation, pp. 419-428, (2014); Dam H.K., Tran T., Pham T., A deep language model for software code, (2016); Nguyen A.T., Nguyen T.D., Phan H.D., Nguyen T.N., A deep neural network language model with contexts for source code, IEEE Proc. 25th Int. Conf. Softw. Anal., Evol. Reeng., pp. 323-334, (2018); Nguyen A.T., Nguyen T.N., Graph-based statistical language model for code, Proc. 37th IEEE/ACM Int. Conf. Softw. Eng., pp. 858-868, (2015); Liu X., Huang L., Ng V., Effective API recommendation without historical software repositories, Proc. 33rd ACM/IEEE Int. Conf. Automated Softw. Eng., pp. 282-292, (2018); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, (2015); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Trans. Neural Netw., 20, 1, pp. 61-80, (2009); Almeida L.B., A learning rule for asynchronous perceptrons with feedback in a combinatorial environment, Artificial Neural Networks: Concept Learning, pp. 102-111, (1990); Pineda F.J., Generalization of back-propagation to recurrent neural networks, Phys. Rev. Lett., 59, 19, pp. 2229-2232, (1987); Cho K., Et al., Learning phrase representations using RNN encoder-decoder for statistical machine translation, (2014); (2020); (2020); Chen C., Et al., Generative API usage code recommendation with parameter concretization, SCIENCE CHINA Inf. Sci., 62, 9, pp. 1921031-19210322, (2019); (2020); (2020); (2020); gg-nns reference implementation, (2020); Replication package, (2020); Nguyen T.T., Nguyen H.A., Pham N.H., Al-Kofahi J.M., Nguyen T.N., Graph-based mining of multiple object usage patterns, Proc. 7th Joint Meeting Eur. Softw. Eng. Conf. ACM SIGSOFT Int. Symp. Found. Softw. Eng. 2009, pp. 383-392; (2020); (2020); (2020); (2020); (2020); (2020); Nguyen A.T., Et al., API code recommendation using statistical learning from fine-grained changes, Proc. 24th ACM SIGSOFT Int. Symp. Found. Softw. Eng., pp. 511-522, (2016); Hellendoorn V.J., Proksch S., Gall H.C., Bacchelli A., When code completion fails: A case study on real-world completions, Proc. 41st Int. Conf. Softw. Eng., pp. 960-970, (2019); Schwartz B., The Paradox of Choice: Why More is Less, (2004); Reutskaja E., Lindner A., Nagel R., Andersen R.A., Camerer C.F., Choice overload reduces neural signatures of choice set value in dorsal striatum and anterior cingulate cortex, Nat. Hum. Behav., 2, 12, pp. 925-935, (2018); (2020); (2020); (2020); (2020); (2020); (2020); Pletcher D.M., Hou D., BCC: Enhancing code completion for better API usability, Proc. IEEE Int. Conf. Softw. Maintenance, pp. 393-394, (2009); Hou D., Pletcher D.M., Towards a better code completion system by API grouping, filtering, and popularity-based ranking, Proc. 2nd Int. Workshop Recommendation Syst. Softw. Eng., pp. 26-30, (2010); Hou D., Pletcher D.M., An evaluation of the strategies of sorting, filtering, and grouping API methods for code completion, Proc. 27th IEEE Int. Conf. Softw. Maintenance, pp. 233-242, (2011); Heinemann L., Bauer V., Herrmannsdoerfer M., Hummel B., Identifier-based context-dependent API method recommendation, Proc. 16th Eur. Conf. Softw. Maintenance Reeng., pp. 31-40, (2012); Bruch M., Monperrus M., Mezini M., Learning from examples to improve code completion systems, Proc. 7th Joint Meeting Eur. Softw. Eng. Conf. ACM SIGSOFT Int. Symp. Found. Softw. Eng., pp. 213-222, (2009); Asaduzzaman M., Roy C.K., Schneider K.A., Hou D., A simple, efficient, context-sensitive approach for code completion, J. Softw.: Evol. Process, 28, 7, pp. 512-541, (2016); Fowkes J.M., Sutton C.A., Parameter-free probabilistic API mining at github scale, (2015); Wang J., Dang Y., Zhang H., Chen K., Xie T., Zhang D., Mining succinct and high-coverage API usage patterns from source code, Proc. 10th Work. Conf. Mining Softw. Repositories, pp. 319-328, (2013); Zhong H., Xie T., Zhang L., Pei J., Mei H., MAPO: Mining and recommending API usage patterns, Proc. Eur. Conf. Object-Oriented Program., pp. 318-343, (2009); Nguyen T.T., Nguyen H.A., Pham N.H., Al-Kofahi J.M., Nguyen T.N., Graph-based mining of multiple object usage patterns, Proc. 7th Joint Meeting Eur. Softw. Eng. Conf. ACM SIGSOFT Int. Symp. Found. Softw. Eng., pp. 383-392, (2009); Nguyen A.T., Et al., Graph-based pattern-oriented, context-sensitive source code completion, Proc. 34th Int. Conf. Softw. Eng., pp. 69-79, (2012); Xie R., Kong X., Wang L., Zhou Y., Li B., HiRec: API recommendation using hierarchical context, Proc. IEEE 30th Int. Symp. Softw. Rel. Eng., pp. 369-379, (2019); Svyatkovskiy A., Lee S., Hadjitofi A., Riechert M., Franco J., Allamanis M., Fast and memory-efficient neural code completion, (2020); Liu F., Li G., Wei B., Xia X., Fu Z., Jin Z., A self-attentional neural architecture for code completion with multi-task learning, Proc. 28th Int. Conf. Prog. Comprehension, pp. 37-47, (2020); Allamanis M., Peng H., Sutton C.A., A convolutional attention network for extreme summarization of source code, Proc. 33nd Int. Conf. Mach. Learn., pp. 2091-2100, (2016); Yin P., Neubig G., A syntactic neural model for general-purpose code generation, Proc. 55th Annu. Meeting Assoc. Comput. Linguistics, pp. 440-450, (2017); Sun Z., Zhu Q., Mou L., Xiong Y., Li G., Zhang L., A grammar- based structural CNN decoder for code generation, (2018); Ling W., Et al., Latent predictor networks for code generation, Proc. 54thAnnu.MeetingAssoc. Comput. Linguistics, pp. 599-609, (2016); Rabinovich M., Stern M., Klein D., Abstract syntax networks for code generation and semantic parsing, Proc. 55th Annu. Meeting Assoc. Comput. Linguistics, pp. 1139-1149, (2017); Mou L., Men R., Li G., Zhang L., Jin Z., On end-to-end program generation from user intention by deep neural networks, (2015); Gu X., Zhang H., Zhang D., Kim S., Deep API learning, Proc. 24th ACM SIGSOFT Int. Symp. Found. Softw. Eng., pp. 631-642, (2016); Gu X., Zhang H., Kim S., Deep code search, Proc. IEEE/ ACM 40th Int. Conf. Softw. Eng., pp. 933-944, (2018); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proc. 26th Conf. Prog. Comprehension, pp. 200-210, (2018); Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., Summarizing source code with transferred API knowledge, Proc. 27th Int. Joint Conf. Artif. Intell., pp. 2269-2275, (2018); Liang Y., Zhu K.Q., Automatic generation of text descriptive comments for code blocks, Proc. 32nd AAAI Conf. Artif. Intell., pp. 5229-5236, (2018); Wan Y., Et al., Improving automatic source code summarization via deep reinforcement learning, Proc. 33rd ACM/IEEE Int. Conf. Automated Softw. Eng., pp. 397-407, (2018); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proc. 54th Annu. Meeting Assoc. Comput. Linguistics, pp. 2073-2083, (2016); Yang X., Lo D., Xia X., Zhang Y., Sun J., Deep learning for just-in-time defect prediction, Proc. IEEE Int. Conf. Softw. Qual., Rel. Secur., pp. 17-26, (2015); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, Proc. 38th Int. Conf. Softw. Eng., pp. 297-308, (2016); Luan S., Yang D., Barnaby C., Sen K., Chandra S., Aroma: Code recommendation via structural code search, Proc. ACM Program. Lang., 3, (2019); Ai L., Huang Z., Li W., Zhou Y., Yu Y., SENSORY: Leveraging code statement sequence information for code snippets recommendation, Proc. IEEE 43rd Annu. Comput. Softw. Appl. Conf., pp. 27-36, (2019); Kim K., Et al., FaCoy: A code-to-code search engine, Proc. 40th Int. Conf. Softw. Eng., pp. 946-957, (2018); Moreno L., Bavota G., Penta M.D., Oliveto R., Marcus A., How can I use this method?, Proc. 37th IEEE/ACM Int. Conf. Softw. Eng., pp. 880-890, (2015); Gu X., Zhang H., Kim S., CodeKernel: A graph kernel based approach to the selection of API usage examples, Proc. 34th IEEE/ACM Int. Conf. Automated Softw. Eng., 2019, pp. 590-601",,,,,,English,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85104636235,11
Alon Y.; David C.,"Alon, Yoav (57222155634); David, Cristina (23007954000)",57222155634; 23007954000,Using graph neural networks for program termination,2022,ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,,,910,921,11,4,10.1145/3540250.3549095,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143064932&doi=10.1145%2f3540250.3549095&partnerID=40&md5=9156908b690ba90af862a39222ba7ecb,"Termination analyses investigate the termination behavior of programs, intending to detect nontermination, which is known to cause a variety of program bugs (e.g. hanging programs, denial-of-service vulnerabilities). Beyond formal approaches, various attempts have been made to estimate the termination behavior of programs using neural networks. However, the majority of these approaches continue to rely on formal methods to provide strong soundness guarantees and consequently suffer from similar limitations. In this paper, we move away from formal methods and embrace the stochastic nature of machine learning models. Instead of aiming for rigorous guarantees that can be interpreted by solvers, our objective is to provide an estimation of a program's termination behavior and of the likely reason for nontermination (when applicable) that a programmer can use for debugging purposes. Compared to previous approaches using neural networks for program termination, we also take advantage of the graph representation of programs by employing Graph Neural Networks. To further assist programmers in understanding and debugging nontermination bugs, we adapt the notions of attention and semantic segmentation, previously used for other application domains, to programs. Overall, we designed and implemented classifiers for program termination based on Graph Convolutional Networks and Graph Attention Networks, as well as a semantic segmentation Graph Neural Network that localizes AST nodes likely to cause nontermination. We also illustrated how the information provided by semantic segmentation can be combined with program slicing to further aid debugging.  © 2022 Owner/Author.","Competition on Software Verification, (2021); libFuzzer-a library for coverage-guided fuzz testing, (2021); Termination Competition (TermCOMP), (2021); GraphTerm, (2022); Abate A., Giacobbe M., Roy D., Learning Probabilistic Termination Proofs, Computer Aided Verification-33rd International Conference, CAV 2021, pp. 3-26, (2021); Abate A., Giacobbe M., Roy D., Learning Probabilistic Termination Proofs, Computer Aided Verification-33rd International Conference, CAV 2021, pp. 3-26, (2021); Allamanis M., Graph Neural Networks in Program Analysis, pp. 483-497, (2022); Allamanis M., Jackson-Flux H., Brockschmidt M., Self-Supervised Bug Detection and Repair, Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, pp. 27865-27876, (2021); Baudin P., Bobot F., Buhler D., Correnson L., Kirchner F., Kosmatov N., Maroneze A., Perrelle V., Prevosto V., Signoles J., Williams N., The dogged pursuit of bug-free C programs: The Frama-C software analysis platform, Commun. ACM, 64, 8, pp. 56-68, (2021); Ben-Amram A.M., Genaim S., On the linear ranking problem for integer linear-constraint loops, The 40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL '13, pp. 51-62, (2013); Beyer D., Progress on Software Verification: SV-COMP 2022, Proc. TACAS (2) (LNCS 13244)., pp. 375-402, (2022); Calude C.S., Dumitrescu M., A probabilistic anytime algorithm for the halting problem, Comput., 7, 2-3, pp. 259-271, (2018); Caruana R., Lawrence S., Lee Giles C., Overfitting in Neural Nets: Backpropagation, Conjugate Gradient, and Early Stopping, NIPS, pp. 402-408, (2000); Chatterjee K., Kafshdar Goharshady E., Novotny P., Zikelic D., Proving non-termination by program reversal, PLDI '21: 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation, pp. 1033-1048, (2021); Chen H.-Y., David C., Kroening D., Schrammel P., Wachter B., Bit-Precise Procedure-Modular Termination Analysis, ACM Trans. Program. Lang. Syst, 40, 1, pp. 11-138, (2018); Chung J., Gulcehre C., Cho K., Bengio Y., Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling, (2014); Cook B., Podelski A., Rybalchenko A., Termination proofs for systems code, Proceedings of the ACM SIGPLAN 2006 Conference on Programming Language Design and Implementation, pp. 415-426, (2006); Cook B., See A., Zuleger F., Ramsey vs. Lexicographic Termination Proving, Tools and Algorithms for the Construction and Analysis of Systems-19th International Conference, TACAS 2013, 7795, pp. 47-61, (2013); Cousot P., Cousot R., An abstract interpretation framework for termination, Proceedings of the 39th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL 2012, pp. 245-258, (2012); David C., Kroening D., Lewis M., Unrestricted Termination and Non-termination Arguments for Bit-Vector Programs, Programming Languages and Systems-24th European Symposium on Programming, ESOP 2015, 9032, pp. 183-204, (2015); Fedyukovich G., Zhang Y., Gupta A., Syntax-Guided Termination Analysis, Computer Aided Verification-30th International Conference, CAV 2018, pp. 124-143, (2018); Giacobbe M., Kroening D., Parsert J., Neural Termination Analysis, ACMJoint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE), (2022); Gupta A., Henzinger T.A., Majumdar R., Rybalchenko A., Xu R.-G., Proving non-termination, Proceedings of the 35th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL 2008, pp. 147-158, (2008); Hamaguchi T., Oiwa H., Shimbo M., Matsumoto Y., Knowledge transfer for out-of-knowledge-base entities: A graph neural network approach, (2017); Heizmann M., Hoenicke J., Podelski A., Termination Analysis by Learning Terminating Programs, Computer Aided Verification-26th International Conference, CAV 2014, 8559, pp. 797-813, (2014); Hochreiter S., Schmidhuber J., Long Short-term Memory, Neural computation, 9, pp. 1735-1780, (1997); Hossin M., Sulaiman M.N., A Review on Evaluation Metrics for Data Classification Evaluations, International Journal of Data Mining & Knowledge Management Process, 5, pp. 1-11, (2015); Jadon S., A survey of loss functions for semantic segmentation, 2020 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB), (2020); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks, (2016); Kroening D., Sharygina N., Tsitovich A., Wintersteiger C.M., Termination Analysis with Compositional Transition Invariants, Computer Aided Verification, 22nd International Conference, CAV 2010, 6174, pp. 89-103, (2010); Le T.-D.B., Lo D., Le Goues C., Grunske L., A learningto-rank based fault localization approach using likely invariants, Proceedings of the 25th International Symposium on Software Testing and Analysis, ISSTA 2016, pp. 177-188, (2016); Chanh Le T., Xu L., Chen L., Shi W., Proving Conditional Termination for Smart Contracts, Proceedings of the 2nd ACM Workshop on Blockchains, Cryptocurrencies, and Contracts, BCC@AsiaCCS 2018, pp. 57-59, (2018); Lee W., Wang B., Yi K., Termination Analysis with Algorithmic Learning, Computer Aided Verification-24th International Conference, CAV 2012, 7358, pp. 88-104, (2012); Li G., Muller M., Qian G., Delgadillo I.C., Abualshour A., Thabet A.K., Ghanem B., DeepGCNs: Making GCNs Go as Deep as CNNs, (2019); Lin T.-Y., Goyal P., Girshick R., He K., Dollar P., Focal loss for dense object detection, Proceedings of the IEEE international conference on computer vision, pp. 2980-2988, (2017); Neumerkel U., Mesnard F., Localizing and Explaining Reasons for Non-terminating Logic Programs with Failure-Slices, Principles and Practice of Declarative Programming, International Conference PPDP'99, 1702, pp. 328-342, (1999); Paszke A., Gross S., Chintala S., Chanan G., Yang E., DeVito Z., Lin Z., Desmaison A., Antiga L., Lerer A., Automatic Differentiation in PyTorch, NIPS 2017 Workshop on Autodiff, (2017); Sanchez-Gonzalez A., Heess N., Tobias Springenberg J., Merel J., Riedmiller M.A., Hadsell R., Battaglia P.W., Graph Networks as Learnable Physics Engines for Inference and Control, Proceedings of the 35th International Conference on Machine Learning, ICML 2018, 80, pp. 4467-4476, (2018); Sejr Schlichtkrull M., Kipf T.N., Bloem P., Van Den Berg R., Titov I., Welling M., Modeling Relational Data with Graph Convolutional Networks, The Semantic Web-15th International Conference, ESWC 2018, pp. 593-607, (2018); Sherstinsky A., Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) Network, (2018); Turing A., On Computable Numbers, with an Application to the N Tscheidungsproblem, Proceedings of the London Mathematical Society, 42, 1, pp. 230-265, (1936); Velikovi P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph Attention Networks, (2018); Weiser M., Programmers Use Slices When Debugging, Commun. ACM, 25, 7, pp. 446-452, (1982); Wu Y., Lian D., Xu Y., Wu L., Chen E., Graph Convolutional Networks with Markov Random Field Reasoning for Social Spammer Detection, The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, pp. 1054-1061, (2020); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A Comprehensive Survey on Graph Neural Networks, (2019); Xu B., Wang N., Chen T., Li M., Empirical Evaluation of Rectified Activations in Convolutional Network, (2015); Zaheer M., Kottur S., Ravanbakhsh S., Poczos B., Salakhutdinov R., Smola A.J., Deep Sets, (2017); Zhang Y., Rabbat M.G., A Graph-CNN for 3D Point Cloud Classification, 2018 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2018, pp. 6279-6283, (2018); Zhang Z., Cui P., Zhu W., Deep Learning on Graphs: A Survey, IEEE Trans. Knowl. Data Eng, 34, 1, pp. 249-270, (2022); Zhou J., Cui G., Hu S., Zhang Z., Yang C., Liu Z., Wang L., Li C., Sun M., Graph neural networks: A review of methods and applications, AI Open, 1, pp. 57-81, (2020); Zhu S., Kincaid Z., Termination analysis without the tears, PLDI '21: 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation, pp. 1296-1311, (2021)",ACM SIGSOFT; National University of Singapore,"30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2022",14 November 2022 through 18 November 2022,Singapore,184166,English,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85143064932,12
Liu J.; Zeng J.; Wang X.; Ji K.; Liang Z.,"Liu, Jiahao (57212605025); Zeng, Jun (57220955671); Wang, Xiang (57191904438); Ji, Kaihang (57863452800); Liang, Zhenkai (14034338200)",57212605025; 57220955671; 57191904438; 57863452800; 14034338200,TeLL: Log level suggestions via modeling multi-level code block information,2022,ISSTA 2022 - Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis,,,,27,38,11,6,10.1145/3533767.3534379,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136803982&doi=10.1145%2f3533767.3534379&partnerID=40&md5=2e89b0ce740145a39cccfbfc5c613c53,"Developers insert logging statements into source code to monitor system execution, which forms the basis for software debugging and maintenance. For distinguishing diverse runtime information, each software log is assigned with a separate verbosity level (e.g., trace and error). However, choosing an appropriate verbosity level is a challenging and error-prone task due to the lack of specifications for log level usages. Prior solutions aim to suggest log levels based on the code block in which a logging statement resides (i.e., intra-block features). Such suggestions, however, do not consider information from surrounding blocks (i.e., inter-block features), which also plays an important role in revealing logging characteristics. To address this issue, we combine multiple levels of code block information (i.e., intra-block and inter-block features) into a joint graph structure called Flow of Abstract Syntax Tree (FAST). To explicitly exploit multi-level block features, we design a new neural architecture, Hierarchical Block Graph Network (HBGN), on the FAST. In particular, it leverages graph neural networks to encode both the intra-block and inter-block features into code block representations and guide log level suggestions. We implement a prototype system, TeLL, and evaluate its effectiveness on nine large-scale software systems. Experimental results showcase TeLL's advantage in predicting log levels over the state-of-the-art approaches.  © 2022 Owner/Author.","Abadi M., Barham P., Chen J., Chen Z., Davis A., Dean J., Devin M., Ghemawat S., Irving G., Isard M., Et al., Tensorflow: A system for large-scale machine learning, 12th {USENIX} Symposium on Operating Systems Design and Implementation (OSDI). 265-283, (2016); Allamanis M., Brockschmidt M., Khademi M., 2018. Learning to Represent Programs with Graphs, International Conference on Learning Representations (ICLR; Anu H., Chen J., Shi W., Hou J., Liang B., Qin B., An approach to recommendation of verbosity log levels based on logging intention, 2019 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 125-134, (2019); Baxter I.D., Yahin A., Moura L., Santanna M., Bier L., Clone detection using abstract syntax trees, Proceedings. International Conference on Software Maintenance (ICSM). 368-377, (1998); Chen B., Ming Jiang Z., Characterizing and detecting antipatterns in the logging code, 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE). 71-81, (2017); Chen B., Ming Jiang Z., Studying the use of Java logging utilities in the wild, 2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE). 397-408, (2020); Chen B., Ming Z., Jiang J., 2017 Characterizing logging practices in Java-based open source software projects-A replication study in Apache Software Foundation, Empirical Software Engineering, pp. 330-374, (2017); Chen B., Song J., Xu P., Hu X., Ming Jiang Z., An automated approach to estimating code coverage measures via execution logs, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering (ASE). 305-316, (2018); Chen T., Syer M.D., Shang W., Ming Jiang Z., Hassan A.E., Nasser M., Flora P., Analytics-driven load testing: An industrial experience report on load testing of large-scale systems, 2017 IEEE/ACM 39th International Conference on Software Engineering: Software Engineering in Practice Track (ICSE-SEIP), (2017); Fang C., Liu Z., Shi Y., Huang J., Shi Q., Functional code clone detection with syntax and semantics fusion learning, Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA). 516-527, (2020); Fu Q., Zhu J., Hu W., Lou J., Ding R., Lin Q., Zhang D., Xie T., Where do developers log? an empirical study on logging practices in industry, Companion Proceedings of the 36th International Conference on Software Engineering (ICSE). 24-33, (2014); Hamilton W.L., Ying R., Leskovec J., Inductive representation learning on large graphs, Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS). 1025-1035, (2017); He K., Zhang X., Ren S., Sun J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification, Proceedings of the IEEE International Conference on Computer Vision (ICCV). 1026-1034, (2015); He P., Chen Z., He S., Lyu M.R., Characterizing the natural language descriptions in software logging statements, 2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE). 178-189, (2018); He S., Lin Q., Lou J., Zhang H., Lyu M.R., Zhang D., Identifying impactful service system problems via log analysis, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE). 60-70, (2018); He X., Chua T., Neural factorization machines for sparse predictive analytics, Proceedings of the 40th International, (2017); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate tree-based detection of code clones, 29th International Conference on Software Engineering (ICSE). 96-105, (2007); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, International Conference on Learning Representations (ICLR, (2015); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks, International Conference on Learning Representations (ICLR, (2017); Leclair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proceedings of the 28th International Conference on Program Comprehension (ICPC). 184-195, (2020); Li H., Shang W., Adams B., Sayagh M., Hassan A.E., 2020. A qualitative study of the benefits and costs of logging from developers? perspectives, IEEE Transactions on Software Engineering, (2020); Li H., Shang W., Hassan A.E., 2017. Which Log Level Should Developers Choose for A New Logging Statement? Empirical Software Engineering, pp. 1684-1716, (2017); Li J., Rong Y., Cheng H., Meng H., Huang W., Huang J., Semi-supervised graph classification: A hierarchical graph perspective, The World Wide Web Conference, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, International Conference on Learning Representations (ICLR), (2016); Li Z., Chen T., Shang W., Where shall we log? studying and suggesting logging locations in code blocks, 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE). 361-372, (2020); Li Z., Chen T., Yang J., Shang W., DLFinder: Characterizing and detecting duplicate logging code smells, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). 152-163, (2019); Li Z., Li H., Peter Chen T., Shang W., 2021 DeepLV: Suggesting Log Levels Using Ordinal Based Neural Networks, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). 1461-1472; Liu F., Wen Y., Zhang D., Jiang X., Xing X., Meng D., Log2vec: A heterogeneous graph embedding based approach for detecting cyber threats within enterprise, Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security (CCS). 1777-1794, (2019); Liu S., A Unified Framework to Learn Program Semantics with Graph Neural Networks, 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE, (2020); Liu S., Chen Y., Xie X., Siow J., Liu Y., 2021. Retrievalaugmented generation for code summarization via hybrid {gnn}, International Conference on Learning Representations (ICLR; Liu Z., Xia X., Lo D., Xing Z., Hassan A.E., Li S., 2019 Which variables should i log?, IEEE Transactions on Software Engineering, (2019); Lu J., Li F., Li L., Feng X., Cloudraid: Hunting concurrency bugs in the cloud via log-mining, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE). 3-14, (2018); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in Neural Information Processing Systems (NIPS). 3111-3119, (2013); Nagappan M., Wu K., Vouk M.A., Efficiently extracting operational profiles from execution logs using suffix arrays, 2009 20th International Symposium on Software Reliability Engineering (ISSRE). 41-50, (2009); Nagaraj K., Killian C., Neville J., Structured comparative analysis of systems logs to diagnose performance problems, 9th {USENIX} Symposium on Networked Systems Design and Implementation (NSDI, (2012); Nandi A., Mandal A., Atreja S., Dasgupta G.B., Bhattacharya S., Anomaly detection using program control flow graph mining from execution logs, Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD). 215-224, (2016); Barslev Nielsen B., Toldam Torp M., Muller A., 2021. Modular call graph construction for security scanning of Node. js applications, Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis. 29-41; Pecchia A., Cinque M., Carrozza G., Cotroneo D., Industry practices and event logging: Assessment of a critical software development process, 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering (ICSE). 169-178, (2015); Pirzadeh H., Shanian S., Hamou-Lhadj A., Mehrabian A., The concept of stratified sampling of execution traces, 2011 IEEE 19th International Conference on Program Comprehension (ICPC). 225-226, (2011); Van Der Maaten L., Hinton G., 2008. Visualizing Data using t-SNE, Journal of Machine Learning Research, pp. 2579-2605, (2008); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph Attention Networks, International Conference on Learning Representations (ICLR, (2018); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-Augmented abstract syntax tree, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER). 261-271, (2020); Wang X., He X., Wang M., Feng F., Chua T., Neural graph collaborative filtering, Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR). 165-174, (2019); Kewang Y., Gao F., Wang L., 2020 Learning semantic program embeddings with graph interval neural network, Proceedings of the ACM on Programming Languages, pp. 1-27, (2020); Weimer W., Nguyen T., Le Goues C., Forrest S., Automatically finding patches using genetic programming, 2009 IEEE 31st International Conference on Software Engineering (ICSE). 364-374, (2009); Xu K., Hu W., Leskovec J., Jegelka S., How Powerful are Graph Neural Networks?, International Conference on Learning Representations (ICLR, (2018); Xu K., Li C., Tian Y., Sonobe T., Kawarabayashi K., Jegelka S., Representation learning on graphs with jumping knowledge networks, International Conference on Machine Learning (ICML). 5453-5462, (2018); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy (S&P). 590-604, (2014); Yuan D., Mai H., Xiong W., Tan L., Zhou Y., Pasupathy S., Sherlog: Error diagnosis by connecting clues from run-Time logs, Proceedings of the Fifteenth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS). 143-154, (2010); Yuan D., Park S., Zhou Y., Characterizing logging practices in open-source software, 2012 34th International Conference on Software Engineering (ICSE). 102-112, (2012); Yuan D., Zheng J., Park S., Zhou Y., Savage S., Improving software diagnosability via log enhancement, ACM Transactions on Computer Systems (TOCS) 2012, pp. 1-28, (2012); Shaila Zaman T., Han X., Yu T., SCMiner: Localizing system-level concurrency faults from large system call traces, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). 515-526, (2019); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). 783-794, (2019); Zhang X., Xu Y., Lin Q., Qiao B., Zhang H., Dang Y., Xie C., Yang X., Cheng Q., Li Z., Et al., Robust log-based anomaly detection on unstable log data, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE). 807-817, (2019); Zhao X., Rodrigues K., Luo Y., Stumm M., Yuan D., Zhou Y., Log20: Fully automated optimal placement of log printing statements under specified overhead threshold, Proceedings of the 26th Symposium on Operating Systems Principles (SOSP, (2017); Zhao X., Rodrigues K., Luo Y., Yuan D., Stumm M., Nonintrusive performance profiling for entire software stacks based on the flow reconstruction principle, 12th {USENIX} Symposium on Operating Systems Design and Implementation (OSDI). 603-618, (2016); Zhi C., Yin J., Deng S., Ye M., Fu M., Xie T., An exploratory study of logging configuration practice in Java, 2019 IEEE International Conference on Software Maintenance and Evolution (ICSME). 459-469, (2019); Zhu J., He P., Fu Q., Zhang H., Lyu M.R., Zhang D., Learning to log: Helping developers make informed logging decisions, 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering (ICSE). 415-425, (2015)",ACM; ACM SIGSOFT,"31st ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2022",18 July 2022 through 22 July 2022,"Virtual, Online",181816,English,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85136803982,13
Qian Y.; Zhang Y.; Wen Q.; Ye Y.; Zhang C.,"Qian, Yiyue (57219445403); Zhang, Yiming (57194707753); Wen, Qianlong (57271905500); Ye, Yanfang (57323577100); Zhang, Chuxu (55879440900)",57219445403; 57194707753; 57271905500; 57323577100; 55879440900,Rep2Vec: Repository Embedding via Heterogeneous Graph Adversarial Contrastive Learning,2022,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,,,1390,1400,10,10,10.1145/3534678.3539324,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137142998&doi=10.1145%2f3534678.3539324&partnerID=40&md5=c3c7c70d0cdcdb6b01b1b244a0b4d5a9,"Driven by the exponential increase of software and the advent of the pull-based development system Git, a large amount of open-source software has emerged on various social coding platforms. GitHub, as the largest platform, not only attracts developers and researchers to contribute legitimate software and research-related source code but has also become a popular platform for an increasing number of cybercriminals to perform continuous cyberattacks. Hence, some tools have been developed to learn representations of repositories on GitHub for various related applications (e.g., malicious repository detection) recently. However, most of them merely focus on code content while ignoring the rich relational data among repositories. In addition, they usually require a mass of resources to obtain sufficient labeled data for model training while ignoring the usefully handy unlabeled data. To this end, we propose a novel model Rep2Vec which integrates the code content, the structural relations, and the unlabeled data to learn the repository representations. First, to comprehensively model the repository data, we build a repository heterogeneous graph (Rep-HG) which is encoded by a graph neural network. Afterwards, to fully exploit unlabeled data in Rep-HG, we introduce adversarial attacks to generate more challenging contrastive pairs for the contrastive learning module to train the encoder in node view and meta-path view simultaneously. To alleviate the workload of the encoder against attacks, we further design a dual-stream contrastive learning module that integrates contrastive learning on adversarial graph and original graph together. Finally, the pre-trained encoder is fine-tuned to the downstream task, and further enhanced by a knowledge distillation module. Extensive experiments on the collected dataset from GitHub demonstrate the effectiveness of Rep2Vec in comparison with state-of-the-art methods for multiple repository tasks.  © 2022 ACM.","virustotal: R Client for the VirusTotal API, (2017); Chen T., Kornblith S., Norouzi M., Hinton G., A simple framework for contrastive learning of visual representations, ICML, (2020); Devlin J., Chang M.-W., Lee K., Toutanova K., Bert: Pre-training of deep bidirectional transformers for language understanding, (2018); Dong Y., Chawla N.V., Swami A., metapath2vec: Scalable representation learning for heterogeneous networks, KDD, (2017); Grover A., Leskovec J., node2vec: Scalable feature learning for networks, KDD, (2016); Horadam K.J., Hadamard matrices and their applications, (2012); Hou S., Fan Y., Zhang Y., Ye Y., Lei J., Wan W., Wang J., Xiong Q., Shao F., cyber: Enhancing robustness of android malware detection system against adversarial attacks on heterogeneous graph based model, CIKM, (2019); Hou S., Ye Y., Song Y., Abdulhayoglu M., Hindroid: An intelligent android malware detection system based on structured heterogeneous information network, KDD, (2017); Jovanovi N., Meng Z., Faber L., Wattenhofer R., Towards robust graph contrastive learning, (2021); Kingma D.P., Ba J., Adam: A method for stochastic optimization, ICLR, (2015); Kipf T.N., Welling M., Variational graph auto-encoders, (2016); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, ICLR, (2017); Koskela M., Simola I., Stefanidis K., Open source software recommendations using github, TPDL, (2018); Krogh A., Hertz J., A simple weight decay can improve generalization, NeurIPS, (1991); Madry A., Makelov A., Schmidt L., Tsipras D., Vladu A., Towards deep learning models resistant to adversarial attacks, ICLR, (2018); Menard S., Applied logistic regression analysis, Sage, (2002); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, (2013); Perozzi B., Al-Rfou R., Skiena S., Deepwalk: Online learning of social representations, KDD, (2014); Qian Y., Zhang Y., Ye Y., Zhang C., Adapting Meta Knowledge with Heterogeneous Information Network for COVID-19 Themed Malicious Repository Detection, IJCAI, (2021); Qian Y., Zhang Y., Ye Y., Zhang C., Distilling Meta Knowledge on Heterogeneous Graph for Illicit Drug Trafficker Detection on Social Media, NeurIPS, (2021); Qiu J., Chen Q., Dong Y., Zhang J., Yang H., Ding M., Wang K., Tang J., GCC: Graph contrastive coding for graph neural network pre-training, KDD, (2020); Faruk Rokon O., Islam R., Darki A., Papalexakis E.E., Faloutsos M., Sourcefinder Finding malware source-code from publicly available repositories in github, RAID, (2020); Faruk Rokon O., Yan P., Islam R., Faloutsos M., Repo2vec: A comprehensive embedding approach for determining repository similarity, ICSME, (2021); Schlichtkrull M., Kipf T.N., Bloem P., Van Den Berg R., Titov I., Welling M., Modeling relational data with graph convolutional networks, ESWC, (2018); Schmidhuber J., Deep learning in neural networks: An overview, Neural networks, (2015); CodeQL for research, Semmle, (2019); LGTM, Semmle, (2019); Shao H., Sun D., Wu J., Zhang Z., Zhang A., Yao S., Liu S., Wang T., Zhang C., Abdelzaher T., paper2repo: GitHub repository recommendation for academic papers, WWW, (2020); Sun F.-Y., Hoffmann J., Verma V., Tang J., Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization, ICLR, (2020); Sun Y., Han J., Yan X., Yu P.S., Wu T., Pathsim: Meta path-based top-k similarity search in heterogeneous information networks, VLDB, (2011); Velikovi P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph Attention Networks, ICLR, (2018); Velickovic P., Fedus W., Hamilton W.L., Lio P., Bengio Y., Devon Hjelm R., Deep Graph Infomax, ICLR, (2019); Wang H., Wang J., Wang J., Zhao M., Zhang W., Zhang F., Xie X., Guo M., Graphgan: Graph representation learning with generative adversarial nets, AAAI, (2018); Wang X., Ji H., Shi C., Wang B., Ye Y., Cui P., Yu P.S., Heterogeneous graph attention network, WWW, (2019); Wang X., Liu N., Han H., Shi C., Self-supervised Heterogeneous Graph Neural Network with Co-contrastive Learning, KDD, (2021); Wang X., Qi G.-J., Contrastive learning with stronger augmentations, (2021); GitHub Introduction, (2022); Ye Y., Li T., Adjeroh D., Sitharama Iyengar S., A survey on malware detection using data mining techniques, ACM Computing Surveys (CSUR), (2017); You Y., Chen T., Sui Y., Chen T., Wang Z., Shen Y., Graph contrastive learning with augmentations, NeurIPS, (2020); Yu L., Pei S., Ding L., Zhou J., Li L., Zhang C., Zhang X., SAIL: Self-Augmented Graph Contrastive Learning, AAAI, (2022); Zhang C., Song D., Huang C., Swami A., Chawla N.V., Heterogeneous graph neural network, KDD, (2019); Zhang C., Swami A., Chawla N.V., Shne: Representation learning for semantic-associated heterogeneous networks, WSDM, (2019); Zhang M., Chen Y., Link Prediction Based on Graph Neural Networks, NeurIPS, (2018); Zhang X., Zitnik M., Gnnguard: Defending graph neural networks against adversarial attacks, NeurIPS, (2020); Zhang Y., Fan Y., Hou S., Ye Y., Xiao X., Li P., Shi C., Zhao L., Xu S., Cyber-guided Deep Neural Network for Malicious Repository Detection in GitHub, ICKG, (2020); Zhang Y., Lo D., Singh Kochhar P., Xia X., Li Q., Sun J., Detecting similar repositories on GitHub, SANER, (2017); Zhang Y., Qian Y., Fan Y., Ye Y., Li X., Xiong Q., Shao F., dstyle-gan: Generative adversarial network based on writing and photography styles for drug identification in darknet markets, ACSAC, (2020); Zhang Y., Qian Y., Ye Y., Zhang C., Adapting Distilled Knowledge for Few-shot Relation Reasoning over Knowledge Graphs, SDM, (2022); Zhang Y., Xu F.F., Li S., Meng Y., Wang X., Li Q., Han J., Higitclass: Keyword-driven hierarchical classification of github repositories, ICDM, (2019); Zhao J., Wen Q., Sun S., Ye Y., Zhang C., Multi-view Self-supervised Heterogeneous Graph Embedding, ECML/PKDD, (2021); Zugner D., Akbarnejad A., Gunnemann S., Adversarial attacks on neural networks for graph data, KDD, (2018)",ACM SIGKDD; ACM SIGMOD,"28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2022",14 August 2022 through 18 August 2022,Washington,181896,English,Conference paper,Final,,Scopus,2-s2.0-85137142998,14
Ardimento P.; Aversano L.; Bernardi M.L.; Cimitile M.,"Ardimento, Pasquale (12797261100); Aversano, Lerina (6701736448); Bernardi, Mario Luca (57195515766); Cimitile, Marta (23392132800)",12797261100; 6701736448; 57195515766; 23392132800,Design patterns mining using neural sub-graph matching,2022,Proceedings of the ACM Symposium on Applied Computing,,,,1545,1553,8,0,10.1145/3477314.3507073,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130388510&doi=10.1145%2f3477314.3507073&partnerID=40&md5=b0ba92c528295442e80c974754fde807,"Design Patterns detection in Object-Oriented software systems is essential for effectively supporting program comprehension and re-engineering tasks. It helps to recover, from source code, the developers' design decisions and trade-offs that could be not up-to-date or even not documented. Several approaches to mine design patterns from source code have been defined in the last twelve years and they are all based on the analysis of object-oriented systems components, their relationships, and behaviors to identify the roles played in the patterns. Both static and dynamic approaches need to perform matching between data captured from the system with the design patterns specification that encodes the structure and the behavior of the micro-architectural solution. The matching process, in principle, can be formulated as a sub-graph matching problem that is NP-complete. This problem has been addressed in the literature using heuristics designed to produce good solutions in an acceptable time, but the task is still expensive with a significant trade-off between accuracy and performance. This work proposes the adoption of a neural-based approach that exploits graph neural networks to perform detection using a more efficient sub-graph matching step outperforming existing heuristics proposed for this task. The pattern detection approach has been assessed on several open-source systems widely used to perform design pattern detection obtaining very good results for both detection performances and efficiency. © 2022 ACM.","Alnusair A., Zhao T., Yan G., Rule-based detection of design patterns in program code, Int. J. Softw. Tools Technol. Transf., 16, 3, pp. 315-334, (2014); Ardimento P., Bilancia M., Monopoli S., Predicting Bug-Fix Time: Using Standard Versus Topic-Based Text Categorization Techniques, Discovery Science -19th International Conference, Ds 2016, 9956, pp. 167-182, (2016); Ardimento P., Dinapoli A., Knowledge Extraction from On-Line Open Source Bug Tracking Systems to Predict Bug-Fixing Time, Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics (WIMS '17)., (2017); Bafandeh Mayvan B., Rasoolzadegan A., Design Pattern Detection Based on the Graph Theory, Know.-Based Syst., 120, C, pp. 211-225, (2017); Bai Y., Ding H., Bian S., Chen T., Sun Y., Wang W., SimGNN: A Neural Network Approach to Fast Graph Similarity Computation, Proceedings of the Twelfth Acm International Conference OnWeb Search and Data Mining (WSDM '19)., pp. 384-392, (2019); Bai Y., Ding H., Sun Y., Wang W., Convolutional Set Matching for Graph Similarity, (2018); Barbudo R., Ramirez A., Servant F., Raul Romero J., GEML: A grammar-based evolutionary machine learning approach for design-pattern detection, Journal of Systems and Software, 175, (2021); Bennett K.H., Rajlich V.T., Software Maintenance and Evolution: A Roadmap, Proceedings of the Conference on the Future of Software Engineering (ICSE '00)., pp. 73-87, (2000); Luca Bernardi M., Cimitile M., Di Lucca G., Design pattern detection using a DSL-driven graph matching approach, Journal of Software: Evolution and Process 26, 12, pp. 1233-1266, (2014); Luca Bernardi M., Cimitile M., De Ruvo G., Lucca Di G.A., Santone A., Improving Design Patterns Finder Precision Using a Model Checking Approach, Proceedings of the CAiSE 2015 Forum at the 27th International Conference on Advanced Information Systems Engineering Co-located with 27th International Conference on Advanced Information Systems Engineering (CAiSE 2015), 1367, pp. 113-120, (2015); Luca Bernardi M., Cimitile M., De Ruvo G., Lucca Di G.A., Santone A., Model Checking to Improve Precision of Design Pattern Instances Identification in OO Systems, Proceedings of the 10th International Conference on Software Paradigm Trends -Volume 1: ICSOFT-PT, (ICSOFT 2015)., pp. 53-63, (2015); Binun A., Kniesel G., DPJF -Design Pattern Detection with High Accuracy, 2012 16th European Conference on Software Maintenance and Reengineering., pp. 245-254, (2012); Di Martino B., Esposito A., A rule-based procedure for automatic recognition of design patterns in UML diagrams, Software: Practice and Experience, 46, 7, pp. 983-1007, (2016); Gama F., Marques A.G., Leus G., Ribeiro A., Convolutional Graph Neural Networks, 2019 53rd Asilomar Conference on Signals, Systems, and Computers., pp. 452-456, (2019); Gamma E., Helm R., Johnson R., Vlissides J., Design Patterns: Elements of Reusable Object-Oriented Software., (1995); Gravino C., Risi M., Scanniello G., Tortora G., Do Professional Developers Benefit from Design Pattern Documentation? A Replication in the Context of Source Code Comprehension, Proceedings of the 15th International Conference on Model Driven Engineering Languages and Systems (MODELS'12)., pp. 185-201, (2012); Gueheneuc Y., Douence R., Jussien N., No Java without caffeine: A tool for dynamic analysis of Java programs, Proceedings 17th Ieee International Conference on Automated Software Engineering, pp. 117-126, (2002); Gueheneuc Y.G., P-MARt: Pattern-like Micro Architecture Repository, (2007); Gueheneuc Y.G., Antoniol G., DeMIMA: A Multilayered Approach for Design Pattern Identification, Ieee Transactions on Software Engineering, 34, 5, pp. 667-684, (2008); Huang B., Carley K.M., Inductive Graph Representation Learning with Recurrent Graph Neural Networks., (2019); Jeanmart S., Gueheneuc Y., Sahraoui H., Habra N., Impact of the visitor pattern on program comprehension and maintenance, 2009 3rd International Symposium on Empirical Software Engineering and Measurement., pp. 69-78, (2009); Koschke R., Architecture Reconstruction., pp. 140-173, (2009); Li Y., Gu C., Dullien T., Vinyals O., Kohli P., Graph Matching Networks for Learning the Similarity of Graph Structured Objects, Proceedings of the 36th International Conference on Machine Learning, Icml 2019, 9-15 June 2019, Long Beach, California, USA (Proceedings of Machine Learning Research), Kamalika Chaudhuri and Ruslan Salakhutdinov (Eds.), 97, pp. 3835-3845, (2019); De Lucia A., Deufemia V., Gravino C., Risi M., Design Pattern Recovery through Visual Language Parsing and Source Code Analysis, J. Syst. Softw., 82, 7, pp. 1177-1193, (2009); De Lucia A., Deufemia V., Gravino C., Risi M., An Eclipse plug-in for the detection of design pattern instances through static and dynamic analysis, 26th Ieee International Conference on Software Maintenance (ICSM 2010), pp. 1-6, (2010); De Lucia A., Deufemia V., Gravino C., Risi M., Detecting the Behavior of Design Patterns through Model Checking and Dynamic Analysis, Acm Trans. Softw. Eng. Methodol., 26, 4, (2018); McFee B., Lanckriet G., Partial Order Embedding with Multiple Kernels, Proceedings of the 26th Annual International Conference on Machine Learning (ICML '09)., pp. 721-728, (2009); Ka-Yee Ng J., Gueheneuc Y., Antoniol G., Identification of behavioural and creational design motifs through dynamic analysis, Journal of Software Maintenance and Evolution: Research and Practice 22, 8, pp. 597-627, (2010); Park C., Kang Y., Wu C., Yi K., A Static Reference Flow Analysis to Understand Design Pattern Behavior, 11th Working Conference on Reverse Engineering, Wcre 2004, Delft, the Netherlands, November 8-12, 2004., pp. 300-301, (2004); Peng T., Dong J., Zhao Y., Verifying Behavioral Correctness of Design Pattern Implementation, Proceedings of the Twentieth International Conference on Software Engineering & Knowledge Engineering (SEKE'2008), San Francisco, CA, USA, July 1-3, 2008, pp. 454-459, (2008); Pettersson N., Lowe W., Nivre J., Evaluation of Accuracy in Design Pattern Occurrence Detection, Ieee Trans. Softw. Eng., 36, 4, pp. 575-590, (2010); Philippow I., Streitferdt D., Riebisch M., Naumann S., An approach for reverse engineering of design patterns, Software and System Modeling, 4, 1, pp. 55-70, (2005); Prechelt L., Unger-Lamprecht B., Philippsen M., Tichy W.F., Two controlled experiments assessing the usefulness of design pattern documentation in program maintenance, Ieee Transactions on Software Engineering, 28, 6, pp. 595-606, (2002); Rasool G., Philippow I., Mader P., Design pattern recovery based on annotations, Adv. Eng. Softw., 41, 4, pp. 519-526, (2010); Ying R., Lou Z., You J., Wen C., Canedo A., Leskovec J., Neural Subgraph Matching, (2020); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The Graph Neural Network Model, Ieee Transactions on Neural Networks, 20, 1, pp. 61-80, (2009); Tsantalis N., Chatzigeorgiou A., Stephanides G., Halkidis S.T., Design Pattern Detection Using Similarity Scoring, Ieee Transactions on Software Engineering, 32, 11, pp. 896-909, (2006); Vokac M., Tichy W., Sjoberg D.I.K., Arisholm E., Aldrin M., A Controlled Experiment Comparing the Maintainability of Programs Designed with and without Design Patterns-A Replication in a Real Programming Environment, Empirical Softw. Engg., 9, 3, pp. 149-195, (2004); Wendehals L., Orso A., Recognizing Behavioral Patterns Atruntime Using Finite Automata, Proceedings of the 2006 International Workshop on Dynamic Systems Analysis (WODA '06)., pp. 33-40, (2006); Wu D., Hu R., Zheng Y., Jiang J., Sharma N., Blumenstein M., Feature-Dependent Graph Convolutional Autoencoders with Adversarial Training Methods, 2019 International Joint Conference on Neural Networks (IJCNN)., pp. 1-8, (2019); Xu K., Wang L., Yu M., Feng Y., Song Y., Wang Z., Yu D., Cross-lingual Knowledge Graph Alignment Via Graph Matching Neural Network, (2019); You J., Gomes-Selman J., Ying R., Leskovec J., Identity-Aware Graph Neural Networks, (2021); Yu D., Zhang Y., Chen Z., A comprehensive approach to the recovery of design pattern instances based on sub-patterns and method signatures, Journal of Systems and Software, 103, pp. 1-16, (2015); Zanoni M., Arcelli Fontana F., Stella F., On applying machine learning techniques for design pattern detection, Journal of Systems and Software, 103, pp. 102-117, (2015)",ACM Special Interest Group on Applied Computing (SIGAPP),"37th ACM/SIGAPP Symposium on Applied Computing, SAC 2022",25 April 2022 through 29 April 2022,"Virtual, Online",179141,English,Conference paper,Final,,Scopus,2-s2.0-85130388510,15
Xiao D.; Hang D.; Ai L.; Li S.; Liang H.,"Xiao, Da (35189718200); Hang, Dengji (57408360200); Ai, Lu (57216463483); Li, Shengping (57409390900); Liang, Hongliang (16638172700)",35189718200; 57408360200; 57216463483; 57409390900; 16638172700,Path context augmented statement and network for learning programs,2022,Empirical Software Engineering,27,2,37,,,,4,10.1007/s10664-021-10098-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122668648&doi=10.1007%2fs10664-021-10098-y&partnerID=40&md5=50bf30a064322a3cb94a24b84246e28c,"Applying machine learning techniques in program analysis has attracted much attention. Recent research efforts in detecting code clones and classifying code have shown that neural models based on abstract syntax trees (ASTs) can better represent source code than other approaches. However, existing AST-based approaches do not take into account contextual information of a program, like statement context. To address this issue, we propose a novel approach path context to capture the context of statements, and a path context augmented network (PCAN) to learn a program. We evaluate PCAN on code clone detection, source code classification, and method naming. The results show that compared to state-of-the-art approaches, PCAN performs the best on code clone detection and has comparable performance on code classification and method naming. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Ahmadi M., Farkhani R.M., Williams R., Lu L., Finding bugs using your own code: Detecting functionally-similar yet inconsistent code, 30Th USENIX Security Symposium, (2021); Learning to represent programs with graphs, 6Th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings, 1711, (2018); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, SIGPLAN Not, 53, 4, pp. 404-419, (2018); Alon U., Levy O., Brody S., Yahav E., Generating sequences from structured representations of code, 7Th International Conference on Learning Representations, ICLR, 1, pp. 1-22, (2019); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, POPL, pp. 1-29, (2019); Graph Transformer for Graph-To-Sequence Learning, (2020); Cho K., van Merrienboer B., Bahdanau D., Bengio Y., On the Properties of Neural Machine Translation: Encoder-Decoder Approaches, pp. 103-111, (2014); Programl: Graph-Based Deep Learning for Program Optimization and Analysis, (2020); Falke R., Frenzel P., Koschke R., Empirical evaluation of clone detection using syntax suffix trees, Empirical Software Engineering, 13, 6, pp. 601-643, (2008); Fang C., Liu Z., Shi Y., Huang J., Shi Q., Functional code clone detection with syntax and semantics fusion learning, Issta, (2020); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, 7Th International Conference on Learning Representations, pp. 1-18, (2019); Gilmer J., Schoenholz S.S., Riley P.F., Vinyals O., Dahl G.E., Neural message passing for quantum chemistry, 34Th International Conference on Machine Learning, ICML, pp. 2053-2070, (2017); Goffi A., Gorla A., Mattavelli A., Pezze M., Tonella P., Search-Based Synthesis of Equivalent Method Sequences, (2014); Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, International Conference on Learning Representations, (2019); Hindle A., Barr E.T., Gabel M., Su Z., Devanbu P.T., On the naturalness of software, Commun ACM, 59, 5, pp. 122-131, (2016); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation with hybrid lexical and syntactical information, Empirical Software Engineering, 25, 3, pp. 2179-2217, (2020); Jiang L., Misherghi G., Su Z., E Phane Glondu S., Deckard: Scalable and accurate tree-based detection of code clones, pp. 96-105, (2007); Kamiya T., Kusumoto S., Inoue K., Ccfinder: a multilinguistic token-based code clone detection system for large scale source code, IEEE Trans Software Eng, 28, pp. 654-670, (2002); Khandelwal U., He H., Qi P., Jurafsky D., Sharp nearby, fuzzy far away: How neural language models use context, Proceedings of the 56Th Annual Meeting of the Association for Computational Linguistics, 1, pp. 284-294, (2018); Manual of Environmental Microbiology, (2016); Li L., Feng H., Zhuang W., Meng N., Ryder B (2017) CCLearner: A deep learning-based clone detection approach, Proceedings - 2017 IEEE International Conference on Software Maintenance and Evolution, ICSME, pp. 249-260, (2017); Li Y., Zemel R., Brockschmidt M., Tarlow D., Gated graph sequence neural networks, 4Th International Conference on Learning Representations, 1, pp. 1-20, (2016); Li Y., Gu C., Dullien T., Vinyals O., Kohli P., Graph matching networks for learning the similarity of graph structured objects, Proceedings of the 36Th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, PMLR, Proceedings of Machine Learning Research, 97, pp. 3835-3845, (2019); Lin Z., Feng M., Dos Santos C.N., Yu M., Xiang B., Zhou B., Bengio Y., A structured self-attention sentence embedding. 5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings, 1-15, 1703, (2017); Linares-Vasquez M., Mcmillan C., Poshyvanyk D., Grechanik M., On using machine learning to automatically classify software applications into domain categories, Empirical Software Engineering, 19, 3, pp. 582-618, (2014); Luong T., Pham H., Manning C.D., Effective approaches to attention-based neural machine translation, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 1412-1421, (2015); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space. 1st International Conference on Learning Representations, ICLR 2013 - Workshop Track Proceedings, 1301, (2013); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, 30Th AAAI Conference on Artificial Intelligence, AAAI 2016, 1409, (2016); Nafi K.W., Kar T.S., Roy B., Roy C.K., Schneider K.A., Cross language code clone detection using syntactical features and API documentation, Proceedings - 2019 34Th IEEE/ACM International Conference on Automated Software Engineering, pp. 1026-1037, (2019); Narayanan A., Chandramohan M., Venkatesan R., Chen L., Liu Y., Jaiswal S., Graph2vec: Learning Distributed Representations of Graphs, (2017); Ragkhitwetsagul C., Krinke J., Siamese: scalable and incremental code clone search via multiple code representations, Empirical Software Engineering, 24, 4, pp. 2236-2284, (2019); Roy C.K., Cordy J.R., NICAD: Accurate detection of near-miss intentional clones using flexible pretty-printing and code normalization, IEEE International Conference on Program Comprehension, pp. 172-181, (2008); Saini V., Farmahinifarahani F., Lu Y., Baldi P., Lopes C.V., Oreo: Detection of clones in the twilight zone, ESEC/FSE 2018 - Proceedings of the 2018 26Th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 354-365, (2018); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., Sourcerercc: Scaling code clone detection to big-code, 2016 IEEE/ACM 38Th International Conference on Software Engineering (ICSE, pp. 1157-1168, (2016); Socher R., Pennington J., Huang E.H., Ng A.Y., Manning C.D., Semi-supervised recursive autoencoders for predicting sentiment distributions, Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, EMNLP 2011, 27-31 July, 2011, pp. 151-161, (2011); Tai K.S., Socher R., Manning C.D., Improved semantic representations from tree-structured long short-Term memory networks, ACL-IJCNLP 2015 - 53Rd Annual Meeting of the Association for Computational Linguistics and the 7Th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, Proceedings of the Conference, 1, pp. 1556-1566, (2015); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, Proceedings - International Conference on Software Engineering, IEEE Computer Society, 18, pp. 542-553, (2018); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in Neural Information Processing Systems, Vol 2017-Decem, Pp, 5999-6009, 1706, (2017); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting Code Clones with Graph Neural Networkand Flow-Augmented Abstract Syntax Tree, (2020); Wang W., Li G., Shen S., Xia X., Jin Z., Modular Tree Network for Source Code Representation Learning, ACM Transactions on Software Engineering and Methodology, 29, 4, pp. 1-23, (2020); Wang Y., Wang K., Gao F., Wang L., Learning semantic program embeddings with graph interval neural network, Proceedings of the ACM on Programming Languages, 4, OOPSLA, pp. 1-27, (2020); Wei H.H., Li M., Supervised deep features for Software functional clone detection by exploiting lexical and syntactical information in source code, IJCAI International Joint Conference on Artificial Intelligence, pp. 3034-3040, (2017); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, ASE 2016 - Proceedings of the 31St IEEE/ACM International Conference on Automated Software Engineering, pp. 87-98, (2016); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A Novel Neural Source Code Representation Based on Abstract Syntax Tree, Proceedings - International Conference on Software Engineering, IEEE Computer Society, pp. 783-794, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85122668648,16
Zhao Z.; Yang B.; Li G.; Liu H.; Jin Z.,"Zhao, Zhehao (57327947000); Yang, Bo (57721912200); Li, Ge (55901136600); Liu, Huai (19640635500); Jin, Zhi (8961795500)",57327947000; 57721912200; 55901136600; 19640635500; 8961795500,Precise Learning of Source Code Contextual Semantics via Hierarchical Dependence Structure and Graph Attention Networks,2022,Journal of Systems and Software,184,,111108,,,,15,10.1016/j.jss.2021.111108,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118759414&doi=10.1016%2fj.jss.2021.111108&partnerID=40&md5=b2e6deb1d8c0668848a5d5f83bc18516,"Deep learning is being used extensively in a variety of software engineering tasks, e.g., program classification and defect prediction. Although the technique eliminates the required process of feature engineering, the construction of source code model significantly affects the performance on those tasks. Most recent works was mainly focused on complementing AST-based source code models by introducing contextual dependencies extracted from CFG. However, all of them pay little attention to the representation of basic blocks, which are the basis of contextual dependencies. In this paper, we integrated AST and CFG and proposed a novel source code model embedded with hierarchical dependencies. Based on that, we also designed a neural network that depends on the graph attention mechanism. Specifically, we introduced the syntactic structural of the basic block, i.e., its corresponding AST, in source code model to provide sufficient information and fill the gap. We have evaluated this model on three practical software engineering tasks and compared it with other state-of-the-art methods. The results show that our model can significantly improve the performance. For example, compared to the best performing baseline, our model reduces the scale of parameters by 50% and achieves 4% improvement on accuracy on program classification task. © 2021 Elsevier Inc.","Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, (2017); Alon U., Levy O., Yahav E., Code2seq: Generating sequences from structured representations of code, (2018); Alon U., Zilberstein M., Levy O., Yahav E.; Alon U., Zilberstein M., Levy O., Yahav E., Code2Vec:Learning distributed representations of code, Proceedings of the ACM on Programming Languages, Vol. 3, POPL, pp. 1-29, (2019); Breiman L., Random forests, Mach. Learn., 45, 1, pp. 5-32, (2001); Briand L.C., Melo W.L., Wust J., Assessing the applicability of fault-proneness models across object-oriented software projects, IEEE Trans. Softw. Eng., 28, 7, pp. 706-720, (2002); Bruna J., Zaremba W., Szlam A., LeCun Y., Spectral networks and locally connected networks on graphs, 2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14–16, 2014, Conference Track Proceedings, (2014); Chen J., Hu K., Yu Y., Chen Z., Xuan Q., Liu Y., Filkov V., Software Visualization and Deep Transfer Learning for Effective Software Defect Prediction, pp. 578-589, (2020); Cvitkovic M., Singh B., Anandkumar A., Open vocabulary learning on source code with a graph-structured cache, (2018); Dam K.H., Pham T., Ng S.W., Tran T., Grundy J.C., Ghose A.K., Kim T., pp. 46-57, (2019); Fang C., Liu Z., Shi Y., Huang J., Shi Q., Functional code clone detection with syntax and semantics fusion learning, ISSTA 2020 - Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 516-527, (2020); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Trans. Program. Lang. Syst., 9, 3, pp. 319-349, (1987); Fout A., Byrd J., Shariat B., Ben-Hur A., pp. 6530-6539, (2017); Frantzeskou G., MacDonell S., Stamatatos E., Gritzalis S., Examining the significance of high-level programming features in source code author classification, J. Syst. Softw., 81, 3, pp. 447-460, (2008); Hamaguchi T., Oiwa H., Shimbo M., Matsumoto Y., Knowledge transfer for out-of-knowledge-base entities: A graph neural network approach, (2017); Hamilton W., Ying Z., Leskovec J., pp. 1024-1034, (2017); Hu X., Li G., Xia X., Lo D., Jin Z., pp. 200-210, (2018); Jiang L., Liu H., Jiang H., Machine learning based recommendation of method names: How far are we, Proceedings - 2019 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019, pp. 602-614, (2019); Jiang L., Misherghi G., Su Z., Glondu S., DECKARD: scalable and accurate tree-based detection of code clones, 29th International Conference on Software Engineering, ICSE’07, pp. 96-105, (2007); Khoshgoftaar T.M., Lanning D.L., A neural network approach for early detection of program modules having high risk in the maintenance phase, J. Syst. Softw., 29, 1, pp. 85-91, (1995); Khoshgoftaar T.M., Yuan X., Allen E.B., Balancing misclassification rates in classification-tree models of software quality, Empir. Softw. Eng., 5, 4, pp. 313-330, (2000); LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, 2019 IEEE/ACM 41st International Conference on Software Engineering, ICSE, pp. 795-806, (2019); Li J., He P., Zhu J., Lyu M.R., pp. 318-328, (2017); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, (2015); Li Y., Wang S., Nguyen T.N., Nguyen S.V., Improving bug detection via context-based code representation learning and attention-based neural networks, Proc. ACM Program. Lang., 3, pp. 1-30, (2019); Liu Y., Loh H.T., Sun A., Imbalanced text classification: A term weighting approach, Expert Syst. Appl., 36, 1, pp. 690-701, (2009); Maying Y., LuoGuangchun H.T., Zengxue A., ChenAiguo S.V., Transfer learning for cross-company software defect prediction, Inf. Softw. Technol., (2012); Menzies T., Greenwald J., Frank A., Data mining static code attributes to learn defect predictors, IEEE Trans. Softw. Eng., 33, pp. 2-13, (2007); Menzies T., Milton Z., Turhan B., Cukic B., Jiang Y., Bener A.B., Defect prediction from static code features: current results, limitations, new approaches, Autom. Softw. Eng., 17, 4, pp. 375-407, (2010); Mou L., Li G., Zhang L., Wang T., Jin Z., (2016); Munson J.C., Khoshgoftaar T.M., The detection of fault-prone programs, IEEE Trans. Softw. Eng., 26, 5, pp. 423-433, (1992); Nam J., Pan S.J., Kim S., Transfer defect learning, 2013 35th International Conference on Software Engineering, ICSE, pp. 382-391, (2013); Niepert M., Ahmed M., Kutzkov K., pp. 2014-2023, (2016); Ott J., Atchison A., Harnack P., Best N., Anderson H., Firmani C., Linstead E., pp. 336-339, (2018); Phan A., Nguyen L., Nguyen Y., Bui L., DGCNN: A convolutional neural network over large-scale labeled graphs, Neural Netw., 108, (2018); Sutskever I., Vinyals O., Le Q.V., Sequence to sequence learning with neural networks, (2014); Tantithamthavorn C., McIntosh S., Hassan A.E., Matsumoto K., An empirical comparison of model validation techniques for defect prediction models, IEEE Trans. Softw. Eng., 43, 1, pp. 1-18, (2016); Tufano M., Watson C., Bavota G., pp. 542-553, (2018); Ugurel S., Krovetz R., Giles C.L., pp. 632-638, (2002); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); Walden J., Stuckman J., Scandariato R., Predicting vulnerable components: Software metrics vs text mining, 2014 IEEE 25th International Symposium on Software Reliability Engineering, pp. 23-33, (2014); Wang Y., Gao F., Wang L., Wang K., Learning semantic program embeddings with graph interval neural network 1 (January), (2020); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, 2016 IEEE/ACM 38th International Conference on Software Engineering, ICSE, pp. 297-308, (2016); Wang K., Su Z., Learning blended, precise semantic program embeddings, (2019); Wei H.-H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proceedings of the 26th International Joint Conference on Artificial Intelligence, IJCAI’17, pp. 3034-3040, (2017); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, 2016 31st IEEE/ACM International Conference on Automated Software Engineering, ASE, pp. 87-98, (2016); Xia X., Lo D., Wang X., Yang X., Collective personalized change classification with multiobjective search, IEEE Trans. Reliab., 65, 4, pp. 1810-1829, (2016); Xing F., Guo P., Lyu M.R., A novel method for early software quality prediction based on support vector machine, 16th IEEE International Symposium on Software Reliability Engineering, ISSRE’05, (2005); Yang X., Lo D., Xia X., Zhang Y., Sun J., Deep learning for just-in-time defect prediction, 2015 IEEE International Conference on Software Quality, Reliability and Security, pp. 17-26, (2015); Yao Z., Peddamail J.R., Sun H., pp. 2203-2214, (2019); Yu H., Lam W., Chen L., Li G., Xie T., Wang Q., Neural detection of semantic code clones via tree-based convolution, 2019 IEEE/ACM 27th International Conference on Program Comprehension, ICPC, pp. 70-80, (2019); Zanoni M., Fontana F.A., Stella F., On applying machine learning techniques for design pattern detection, J. Syst. Softw., 103, pp. 102-117, (2015); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering, ICSE, pp. 783-794, (2019); Zhao G., Huang J., DeepSim: Deep learning code functional similarity, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2018, pp. 141-151, (2018); Zhong H., Mei H., Learning a graph-based classifier for fault localization, (2019); Zhou J., Cui G., Zhang Z., Yang C., Liu Z., Wang L., Li C., Sun M., Graph neural networks: A review of methods and applications, (2018)",,,,,,English,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85118759414,17
Romanov V.; Ivanov V.,"Romanov, Vitaly (57206352983); Ivanov, Vladimir (57195101229)",57206352983; 57195101229,Prediction of Types in Python with Pre-Trained Graph Neural Networks,2022,"Proceedings - 2022 Ivannikov Memorial Workshop, IVMEM 2022",,,,54,60,6,2,10.1109/IVMEM57067.2022.9983956,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146265787&doi=10.1109%2fIVMEM57067.2022.9983956&partnerID=40&md5=6d2dc784677e91f5f7fdf1c6e5a298f4,"The application of Graph Neural Networks for pre-Training models for source code is not well studied. We experimented with pre-Training a Graph Neural Network model for Python on tasks of Name Prediction and Edge Prediction. Then, we used pre-Trained weights to initialize a model for variable type prediction. Our preliminary results suggest that pre-Training on these tasks brings neither improvements in type prediction performance nor training dynamics. Possible ways to fix this are discussed in the concluding section of the paper. Additionally, we performed an ablation study to see whether type prediction is overreliant on some parts of the graph. Results suggest, that type prediction model does not significantly rely on obvious shortcuts and could be a useful proxy for evaluating pre-Trained graph embeddings.  © 2022 IEEE.","Deng A., Li X., Li Z., Hu D., Xu C., Dou D., Inadequately Pretrained Models Are Better Feature Extractors, (2022); Chirkova N., Troshin S., Empirical study of transformers for source code, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 703-715, (2021); Kanade A., Maniatis P., Balakrishnan G., Shi K., Pretrained Contextual Embedding of Source Code, (2020); Buratti L., Pujar S., Bornea M., McCarley S., Zheng Y., Rossiello G., Morari A., Laredo J., Thost V., Zhuang Y., Et al., Exploring Software Naturalness Through Neural Language Models, (2020); Ahmad W.U., Chakraborty S., Ray B., Chang K.-W., Unified Pretraining for Program Understanding and Generation, (2021); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Et al., Graphcodebert: Pretraining Code Representations with Data Flow, (2020); Liu L., Nguyen H., Karypis G., Sengamedu S., Universal Representation for Code, Pacific-Asia Conference on Knowledge Discovery and Data Mining, pp. 16-28, (2021); Malik R.S., Patra J., Pradel M., NL2Type: Inferring JavaScript Function Types from Natural Language Information, Proceedings-International Conference on Software Engineering, pp. 304-315, (2019); Boone C., De Bruin N., Langerak A., Stelmach F., Dltpy: Deep Learning Type Inference of Python Function Signatures Using Natural Language Context, (2019); Pradel M., Gousios G., Liu J., Chandra S., Typewriter: Neural type prediction with search-based validation, Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 209-220, (2020); Raychev V., Vechev M., Krause A., Predicting program properties from ""big code, ACM SIGPLAN Notices, 50, 1, pp. 111-124, (2015); Allamanis M., Barr E.T., Ducousso S., Gao Z., Typilus: Neural type hints, Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI, pp. 91-105, (2020); Kudo T., Richardson J., Sentencepiece: A Simple and Language Independent Subword Tokenizer and Detokenizer for Neural Text Processing, (2018); Allamaras M., Chanthirasegaran P., Kohli P., Sutton C., Learning continuous semantic representations of symbolic expressions, 34th International Conference on Machine Learning, ICML 2017, 1, pp. 118-131, (2017); Ling X., Wu L., Wang S., Pan G., Ma T., Xu F., Liu A.X., Wu C., Ji S., Deep graph matching and searching for semantic code retrieval, ACM Transactions on Knowledge Discovery from Data (TKDD, 15, 5, pp. 1-21, (2021); Devlin J., Chang M.-W., Lee K., Toutanova K., Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding, (2018); Hamilton W.L., Ying R., Leskovec J., Inductive representation learning on large graphs, Proceedings of the 31st International Conference on Neural Information Processing Systems, pp. 1025-1035, (2017)",,"2022 Ivannikov Memorial Workshop, IVMEM 2022",23 September 2022 through 24 September 2022,Kazan,185405,English,Conference paper,Final,,Scopus,2-s2.0-85146265787,18
Nguyen H.H.; Nguyen N.-M.; Xie C.; Ahmadi Z.; Kudendo D.; Doan T.-N.; Jiang L.,"Nguyen, Hoang H. (57222727288); Nguyen, Nhat-Minh (57821893700); Xie, Chunyao (57873687900); Ahmadi, Zahra (56600274000); Kudendo, Daniel (6603157921); Doan, Thanh-Nam (57822142100); Jiang, Lingxiao (55473381400)",57222727288; 57821893700; 57873687900; 56600274000; 6603157921; 57822142100; 55473381400,MANDO: Multi-Level Heterogeneous Graph Embeddings for Fine-Grained Detection of Smart Contract Vulnerabilities,2022,"Proceedings - 2022 IEEE 9th International Conference on Data Science and Advanced Analytics, DSAA 2022",,,,,,,8,10.1109/DSAA54385.2022.10032337,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143075291&doi=10.1109%2fDSAA54385.2022.10032337&partnerID=40&md5=a50173fabedbf7977331fc2f6d90f0d3,"Learning heterogeneous graphs consisting of different types of nodes and edges enhances the results of homogeneous graph techniques. An interesting example of such graphs is control-flow graphs representing possible software code execution flows. As such graphs represent more semantic information of code, developing techniques and tools for such graphs can be highly beneficial for detecting vulnerabilities in software for its reliability. However, existing heterogeneous graph techniques are still insufficient in handling complex graphs where the number of different types of nodes and edges is large and variable. This paper concentrates on the Ethereum smart contracts as a sample of software codes represented by heterogeneous contract graphs built upon both control-flow graphs and call graphs containing different types of nodes and links. We propose MANDO, a new heterogeneous graph representation to learn such heterogeneous contract graphs' structures. MANDO extracts customized meta-paths, which compose relational connections between different types of nodes and their neighbors. Moreover, it develops a multi-metapath heterogeneous graph attention network to learn multi-level embeddings of different types of nodes and their metapaths in the heterogeneous contract graphs, which can capture the code semantics of smart contracts more accurately and facilitate both fine-grained line-level and coarse-grained contract-level vulnerability detection. Our extensive evaluation of large smart contract datasets shows that MANDO improves the vulnerability detection results of other techniques at the coarse-grained contract level. More importantly, it is the first learning-based approach capable of identifying vulnerabilities at the fine-grained line-level, and significantly improves the traditional code analysis-based vulnerability detection approaches by 11.35% to 70.81% in terms of F1-score. © 2022 IEEE.","Wang X., Ji H., Shi C., Wang B., Ye Y., Cui P., Yu P.S., Heterogeneous graph attention network, The World Wide Web Conference, pp. 2022-2032, (2019); Wood G., Et al., Ethereum: A secure decentralised generalised transaction ledger, Ethereum project yellow paper, 151, 2014, pp. 1-32, (2014); Grover A., Leskovec J., node2vec: Scalable feature learning for networks, the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 855-864, (2016); Tang J., Qu M., Wang M., Zhang M., Yan J., Mei Q., Line: Largescale information network embedding, WWW, (2015); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, (2016); Dong Y., Chawla N.V., Swami A., metapath2vec: Scalable representation learning for heterogeneous networks, the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 135-144, (2017); Tsankov P., Dan A., Cohen D.D., Gervais A., Buenzli F., Vechev M., Securify: Practical security analysis of smart contracts, 25th ACM Conference on Computer and Communications Security, (2018); Mueller B., Smashing smart contracts for fun and real profit, 9th annual HITB Security Conference, pp. 2-51; Feist J., Grieco G., Groce A., Slither: A static analysis framework for smart contracts, IEEE/ACM 2nd International Workshop on Emerging Trends in Software Engineering for Blockchain, pp. 8-15, (2019); Mossberg M., Manzano F., Hennenfent E., Groce A., Grieco G., Feist J., Brunson T., Dinaburg A., Manticore: A user-friendly symbolic execution framework for binaries and smart contracts, the 34th IEEE/ACM International Conference on Automated Software Engineering, pp. 1186-1189, (2019); Tikhomirov S., Voskresenskaya E., Ivanitskiy I., Takhaviev R., Marchenko E., Alexandrov Y., SmartCheck: Static analysis of ethereum smart contracts, the 1st International Workshop on Emerging Trends in Software Engineering for Blockchain, pp. 9-16, (2018); Luu L., Chu D.-H., Olickel H., Saxena P., Hobor A., Making smart contracts smarter, the ACM SIGSAC conference on computer and communications security, pp. 254-269, (2016); Zhuang Y., Liu Z., Qian P., Liu Q., Wang X., He Q., Smart contract vulnerability detection using graph neural network, IJCAI, pp. 3283-3290, (2020); Liu Z., Qian P., Wang X., Zhu L., He Q., Ji S., Smart contract vulnerability detection: From pure neural network to interpretable graph feature and expert pattern fusion, (2021); Chen H., Pendleton M., Njilla L., Xu S., A survey on ethereum systems security: Vulnerabilities, attacks, and defenses, ACM Computing Surveys (CSUR), 53, 3, pp. 1-43, (2020); Sun Y., Han J., Yan X., Yu P.S., Wu T., Pathsim: Meta pathbased top-k similarity search in heterogeneous information networks, the VLDB Endowment, 4, 11, pp. 992-1003, (2011); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in neural information processing systems, pp. 5998-6008, (2017); LeCun Y., Bengio Y., Hinton G., Deep learning, nature, 521, 7553, pp. 436-444, (2015); Liu Z., Qian P., Wang X., Zhuang Y., Qiu L., Wang X., Combining graph neural networks with expert knowledge for smart contract vulnerability detection, IEEE Transactions on Knowledge and Data Engineering, (2021); Durieux T., Ferreira J.F., Abreu R., Cruz P., Empirical review of automated analysis tools on 47, 587 ethereum smart contracts, the ACM/IEEE 42nd International Conference on Software Engineering, pp. 530-541, (2020); Ferreira J.F., Cruz P., Durieux T., Abreu R., Smartbugs: A framework to analyze solidity smart contracts, the 35th IEEE/ACM International Conference on Automated Software Engineering, pp. 1349-1352, (2020); Ghaleb A., Pattabiraman K., How effective are smart contract analysis tools? evaluating smart contract static analysis tools using bug injection, the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, (2020); Schneidewind C., Grishchenko I., Scherer M., Maffei M., ethor: Practical and provably sound static analysis of ethereum smart contracts, the 2020 ACM SIGSAC Conference on Computer and Communications Security, pp. 621-640, (2020); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, International Conference on Learning Representations, (2018); Baldoni R., Coppa E., D'Elia D.C., Demetrescu C., Finocchi I., A survey of symbolic execution techniques, ACM Comput. Surv., 51, 3, (2018); Wu H., Zhang Z., Wang S., Lei Y., Lin B., Qin Y., Zhang H., Mao X., Peculiar: Smart contract vulnerability detection based on crucial data flow graph and pre-training techniques, the 32nd International Symposium on Software Reliability Engineering, (2021); Zhao H., Su P., Wei Y., Gai K., Qiu M., Gan-enabled code embedding for reentrant vulnerabilities detection, Knowledge Science, Engineering and Management, pp. 585-597, (2021); Jeon S., Lee G., Kim H., Woo S.S., Smartcondetect: Highly accurate smart contract code vulnerability detection mechanism using bert, KDD Workshop on Programming Language Processing, (2021); Gao Z., Jiang L., Xia X., Lo D., Grundy J., Checking smart contracts with structural code embedding, IEEE Transactions on Software Engineering, (2020); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., VulDeePecker: A deep learning-based system for vulnerability detection, The Network and Distributed System Security Symposium, (2018); Li Z., Zou D., Xu S., Chen Z., Zhu Y., Jin H., VulDeeLocator: A deep learning-based fine-grained vulnerability detector, IEEE Transactions on Dependable and Secure Computing, (2021); Cao S., Sun X., Bo L., Wei Y., Li B., Bgnn4vd: Constructing bidirectional graph neural-network for vulnerability detection, Information and Software Technology, 136, (2021); Garfatta I., Klai K., Gaaloul W., Graiet M., A survey on formal verification for solidity smart contracts, 2021 Australasian Computer Science Week Multiconference, pp. 1-10, (2021); Wang Y., He J., Zhu N., Yi Y., Zhang Q., Song H., Xue R., Security enhancement technologies for smart contracts in the blockchain: A survey, Transactions on Emerging Telecommunications Technologies, (2021)",ACM SIGKDD; ASA; CCF; IEEE CIS,"9th IEEE International Conference on Data Science and Advanced Analytics, DSAA 2022",13 October 2022 through 16 October 2022,Shenzhen,186596,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85143075291,19
Ma W.; Zhao M.; Soremekun E.; Hu Q.; Zhang J.M.; Papadakis M.; Cordy M.; Xie X.; Le Traon Y.,"Ma, Wei (56302098400); Zhao, Mengjie (57207853884); Soremekun, Ezekiel (57195286600); Hu, Qiang (57216121087); Zhang, Jie M. (57209508429); Papadakis, Mike (57197295611); Cordy, Maxime (55035833600); Xie, Xiaofei (55268560900); Le Traon, Yves (55884641800)",56302098400; 57207853884; 57195286600; 57216121087; 57209508429; 57197295611; 55035833600; 55268560900; 55884641800,GraphCode2Vec: Generic Code Embedding via Lexical and Program Dependence Analyses,2022,"Proceedings - 2022 Mining Software Repositories Conference, MSR 2022",,,,524,536,12,14,10.1145/3524842.3528456,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134018448&doi=10.1145%2f3524842.3528456&partnerID=40&md5=8de7aa869994647081c414a65aa27259,"Code embedding is a keystone in the application of machine learning on several Software Engineering (SE) tasks. To effectively support a plethora of SE tasks, the embedding needs to capture program syntax and semantics in a way that is generic. To this end, we propose the first self-supervised pre-training approach (called Graphcode2vec) which produces task-agnostic embedding of lexical and program dependence features. Graphcode2vec achieves this via a synergistic combination of code analysis and Graph Neural Networks. Graphcode2vec is generic, it allows pre-training, and it is applicable to several SE downstream tasks. We evaluate the effectiveness of Graphcode2vec on four (4) tasks (method name prediction, solution classification, mutation testing and overfitted patch classification), and compare it with four (4) similarly generic code embedding baselines (Code2Seq, Code2Vec, CodeBERT, Graph-CodeBERT) and seven (7) task-specific, learning-based methods. In particular, Graphcode2vec is more effective than both generic and task-specific learning-based baselines. It is also complementary and comparable to GraphCodeBERT (a larger and more complex model). We also demonstrate through a probing and ablation study that Graphcode2vec learns lexical and program dependence features and that self-supervised pre-training improves effectiveness. © 2022 ACM.","Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs., (2017); Alon U., Brody S., Levy O., Yahav E., Code2Seq: Generating Sequences from Structured Representations of Code, (2019); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages 3, POPL, pp. 1-29, (2019); Bellman R.E., Adaptive Control Processes., (2015); Ben-Nun T., Shoshana Jakobovits A., Hoefler T., Neural Code Comprehension: A Learnable Representation of Code Semantics, (2018); Bui N.D.Q., Yu Y., Jiang L., InferCode: Self-Supervised Learning of Code Representations by Predicting Subtrees, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)., pp. 1186-1197, (2021); Buratti L., Pujar S., Bornea M., McCarley S., Zheng Y., Rossiello G., Morari A., Laredo J., Thost V., Zhuang Y., Et al., Exploring Software Naturalness Through Neural Language Models, (2020); Titcheu Chekam T., Papadakis M., Bissyande T.F., Le Traon Y., Sen K., Selecting fault revealing mutants, Empir. Softw. Eng., 25, 1, pp. 434-487, (2020); Conneau A., Kruszewski G., Lample G., Barrault L., Baroni M., What you can cram into a single vector: Probing sentence embeddings for linguistic properties, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (1: Long Papers), pp. 2126-2136, (2018); Cummins C., Leather H., Fisches Z., Ben-Nun T., Hoefler T., O'Boyle M., Deep Data Flow Analysis., (2020); Dean J., Grove D., Chambers C., Optimization of Object- Oriented Programs Using Static Class Hierarchy Analysis, Proceedings of the 9th European Conference on Object-Oriented Programming (ECOOP '95), pp. 77-101, (1995); Devlin J., Chang M., Lee K., Toutanova K., Bert: Pre-training of Deep Bidirectional Transformers for Language Understanding, (2018); Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 1 (Long and Short Papers), pp. 4171-4186, (2019); Do H., Elbaum S., Rothermel G., Supporting controlled experimentation with testing techniques: An infrastructure and its potential impact, Empirical Software Engineering, 10, 4, pp. 405-435, (2005); Einarsson A., Dam Nielsen J., A Survivor's Guide to Java Program Analysis with Soot., (2008); Erhan D., Courville A., Bengio Y., Vincent P., Why does unsupervised pre-training help deep learning?, Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, pp. 201-208, (2010); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Codebert: A Pre-trained Model for Programming and Natural Languages, (2020); Ferrante J., Ottenstein K.J., Warren J.D., The Program Dependence Graph and Its Use in Optimization, ACM Trans. Program. Lang. Syst., 9, 3, pp. 319-349, (1987); Garcia A., Laneve C., JaDA-the Java deadlock analyser, Behavioural Types: From Theories to Tools, pp. 169-192, (2017); Ghannay S., Favre B., Esteve Y., Camelin N., Word embedding evaluation and combination, Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16)., pp. 300-305, (2016); Gilda S., Source code classification using Neural Networks, 2017 14th International Joint Conference on Computer Science and Software Engineering (JCSSE)., pp. 1-6, (2017); Gilmer J., Schoenholz S.S., Riley P.F., Vinyals O., Dahl G.E., Neural Message Passing for Quantum Chemistry, CoRR, (2017); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Et al., Graphcodebert: Pre-training Code Representations with Data Flow, (2020); Hamilton W.L., Ying R., Leskovec J., Inductive representation learning on large graphs, Proceedings of the 31st International Conference on Neural Information Processing Systems., pp. 1025-1035, (2017); Heinzerling B., Strube M., BPEmb: Tokenization-free Pretrained Subword Embeddings in 275 Languages, Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), (2018); Hoang T., Jin Kang H., Lo D., Lawall J., CC2Vec: Distributed Representations of Code Changes, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering (Seoul, South Korea) (ICSE '20), pp. 518-529, (2020); Hu W., Liu B., Gomes J., Zitnik M., Liang P., Pande V., Leskovec J., Strategies for Pre-training Graph Neural Networks, (2019); Huang G., Liu Z., Van Der Maaten L., Weinberger K.Q., Densely connected convolutional networks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition., pp. 4700-4708, (2017); Husain H., Wu H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet Challenge: Evaluating the State of Semantic Code Search, (2019); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate tree-based detection of code clones, 29th International Conference on Software Engineering (ICSE'07)., pp. 96-105, (2007); Jurafsky D., Martin J.H., Speech & Language Processing., (2021); Just R., Jalali D., Ernst M.D., Defects4J: A database of existing faults to enable controlled testing studies for Java programs, Proceedings of the 2014 International Symposium on Software Testing and Analysis., pp. 437-440, (2014); Kanade A., Maniatis P., Balakrishnan G., Shi K., Learning and evaluating contextual embedding of source code, International Conference on Machine Learning, pp. 5110-5121, (2020); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization., (2014); Kipf T.N., Welling M., Semi-supervised Classification with Graph Convolutional Networks., (2016); Kipf T.N., Welling M., Variational Graph Auto-encoders., (2016); Kudo T., Richardson J., SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations., pp. 66-71, (2018); Larsson G., Maire M., Shakhnarovich G., Fractalnet: Ultra-deep Neural Networks Without Residuals., (2016); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks., (2015); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., Roberta: A Robustly Optimized Bert Pretraining Approach, (2019); Long F., Rinard M., Automatic patch generation by learning correct code, Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages., pp. 298-312, (2016); Mikolov T., Chen K., Corrado G., Dean J., Efficient Estimation of Word Representations in Vector Space, 1st International Conference on Learning Representations, ICLR 2013, Scottsdale, Arizona, USA, May 2-4, 2013, (2013); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in Neural Information Processing Systems., pp. 3111-3119, (2013); Nathan Mundhenk T., Ho D., Chen B.Y., Improvements to context based self-supervised learning, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition., pp. 9339-9348, (2018); Ohashi H., Watanobe Y., Convolutional neural network for classification of source codes, 2019 IEEE 13th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC)., pp. 194-200, (2019); Oyedotun O.K., Aouada D., Why do Deep Neural Networks with Skip Connections and Concatenated Hidden Representations Work?, International Conference on Neural Information Processing., pp. 380-392, (2020); Papadakis M., Kintis M., Zhang J., Jia Y., Le Traon Y., Harman M., Mutation testing advances: An analysis and survey, Advances in Computers., 112, pp. 275-378, (2019); Papadakis M., Shin D., Yoo S., Bae D., Are mutation scores correlated with real fault detection?: A large scale empirical study on the relationship between mutants and real faults, Proceedings of the 40th International Conference on Software Engineering, ICSE 2018, Gothenburg, Sweden, May 27 - June 03, 2018, pp. 537-548, (2018); Peng D., Zheng S., Li Y., Ke G., He D., Liu T., How Could Neural Networks Understand Programs?, (2021); Pinter A., Szenasi S., Classification of source code solutions based on the solved programming tasks, 2018 IEEE 18th International Symposium on Computational Intelligence and Informatics (CINTI)., pp. 277-282, (2018); Puri R., Kung D.S., Janssen G., Zhang W., Domeniconi G., Zolotov V., Dolby J., Chen J., Choudhury M., Decker L., Et al., Project CodeNet: A Large-Scale AI for Code Dataset for Learning A Diversity of Coding Tasks., (2021); Raffel C., Shazeer N., Roberts A., Lee K., Narang S., Matena M., Zhou Y., Li W., Liu P.J., Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer, Journal of Machine Learning Research, 21, 140, pp. 1-67, (2020); Rogers A., Kovaleva O., Rumshisky A., A Primer in BERTology: What We Know about How BERT Works, Transactions of the Association for Computational Linguistics, 8, pp. 842-866, (2020); Scarselli F., Gori M., Chung Tsoi A., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Transactions on Neural Networks, 20, 1, pp. 61-80, (2008); Seger C., An Investigation of Categorical Variable Encoding Techniques in Machine Learning: Binary Versus One-hot and Feature Hashing., (2018); Sennrich R., Haddow B., Birch A., Neural Machine Translation of Rare Words with Subword Units, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (1: Long Papers), pp. 1715-1725, (2016); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going deeper with convolutions, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)., pp. 1-9, (2015); Szegedy C., Vanhoucke V., Ioffe S., Shlens J., Wojna Z., Rethinking the inception architecture for computer vision, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition., pp. 2818-2826, (2016); Urolagin S., Prema K.V., Subba Reddy N.V., Generalization capability of artificial neural network incorporated with pruning method, International Conference on Advanced Computing, Networking and Security., pp. 171-178, (2011); Vallee-Rai R., Co P., Gagnon E., Hendren L., Lam P., Sundaresan V., Soot: A Java bytecode optimization framework, CASCON First Decade High Impact Papers., pp. 214-224, (2010); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph Attention Networks., (2017); Venkata Keerthy S., Aggarwal R., Jain S., Sankar Desarkar M., Upadrasta R., Srikant Y.N., Ir2vec: Llvm ir based scalable program embeddings, ACM Transactions on Architecture and Code Optimization (TACO), 17, 4, pp. 1-27, (2020); Wang S., Wen M., Lin B., Wu H., Qin Y., Zou D., Mao X., Jin H., Automated patch correctness assessment: How far are we?, Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering., pp. 968-980, (2020); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)., pp. 261-271, (2020); Wang W., Zhang K., Li G., Jin Z., Learning to Represent Programs with Heterogeneous Graphs., (2020); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, 2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)., pp. 87-98, (2016); Wu Y., Schuster M., Chen Z., Le Q.V., Norouzi M., MacHerey W., Krikun M., Cao Y., Gao Q., MacHerey K., Et al., Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation., (2016); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu Philip S., A comprehensive survey on graph neural networks, IEEE Transactions on Neural Networks and Learning Systems, 32, 1, pp. 4-24, (2020); Xiong Y., Liu X., Zeng M., Zhang L., Huang G., Identifying patch correctness in test-based program repair, Proceedings of the 40th International Conference on Software Engineering., pp. 789-799, (2018); Xu K., Hu W., Leskovec J., Jegelka S., How Powerful Are Graph Neural Networks?, (2018); Yang Z., Dai Z., Yang Y., Carbonell J., Salakhutdinov R.R., Le Q.V., XLNet: Generalized Autoregressive Pretraining for Language Understanding, Advances in Neural Information Processing Systems, 32, (2019); Ye H., Gu J., Martinez M., Durieux T., Monperrus M., Automated classification of overfitting patches with statically extracted code features, IEEE Transactions on Software Engineering, (2021); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)., pp. 783-794, (2019); Zhao G., Huang J., DeepSim: Deep Learning Code Functional Similarity, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (Lake Buena Vista, FL, USA) (ESEC/FSE 2018), pp. 141-151, (2018); Zhao M., Dufter P., Yaghoobzadeh Y., Schutze H., Quantifying the Contextualization of Word Representations with Semantic Class Probing, Findings of the Association for Computational Linguistics: EMNLP 2020., pp. 1219-1234, (2020); Zhao M., Schutze H., A Multilingual BPE Embedding Space for Universal Sentiment Lexicon Induction, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics., pp. 3506-3517, (2019); Zhou J., Cui G., Hu S., Zhang Z., Yang C., Liu Z., Wang L., Li C., Sun M., Graph neural networks: A review of methods and applications, AI Open, 1, pp. 57-81, (2020); Zisserman A., Self-Supervised Learning., (2018)",Association for Computing Machinery (ACM); IEEE Computer Society; JetBrains; Special Interest Group on Software Engineering (ACM SIGSOFT); Technical Council on Software Engineering (IEEE TCSE),"2022 Mining Software Repositories Conference, MSR 2022",23 May 2022 through 24 May 2022,Pittsburgh,180246,English,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85134018448,20
Samoaa H.P.; Longa A.; Mohamad M.; Chehreghani M.H.; Leitner P.,"Samoaa, Hazem Peter (57222122489); Longa, Antonio (57221251335); Mohamad, Mazen (57218826299); Chehreghani, Morteza Haghir (23388320500); Leitner, Philipp (18037605900)",57222122489; 57221251335; 57218826299; 23388320500; 18037605900,TEP-GNN: Accurate Execution Time Prediction of Functional Tests Using Graph Neural Networks,2022,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13709 LNCS,,,464,479,15,3,10.1007/978-3-031-21388-5_32,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142682048&doi=10.1007%2f978-3-031-21388-5_32&partnerID=40&md5=135963edc383a2020c19681c88c0d89f,"Predicting the performance of production code prior to actual execution is known to be highly challenging. In this paper, we propose a predictive model, dubbed TEP-GNN, which demonstrates that high-accuracy performance prediction is possible for the special case of predicting unit test execution times. TEP-GNN uses FA-ASTs, or flow-augmented ASTs, as a graph-based code representation approach, and predicts test execution times using a powerful graph neural network (GNN) deep learning model. We evaluate TEP-GNN using four real-life Java open source programs, based on 922 test files mined from the projects’ public repositories. We find that our approach achieves a high Pearson correlation of 0.789, considerable outperforming a baseline deep learning model. Our work demonstrates that FA-ASTs and GNNs are a feasible approach for predicting absolute performance values, and serves as an important intermediary step towards being able to predict the performance of arbitrary code prior to execution. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, (2017); Baltes S., Ralph P., Sampling in software engineering research: A critical review and guidelines, EMSE, 94, 27, (2022); Brockschmidt M., Allamanis M., Gaunt A.L., Polozov O., Generative Code Modeling with Graphs, (2018); de Oliveira Neto F.G., Ahmad A., Leifler O., Sandahl K., Enoiu E., Improving continuous integration with similarity-based test case selection, Proceedings of the 13Th International Workshop on Automation of Software Test, pp. 39-45, (2018); Fernandes P., Allamanis M., Brockschmidt M., Structured Neural Summarization, (2018); Guo J., Czarnecki K., Apel S., Siegmund N., Wasowski A., Variability-Aware Performance Prediction: A Statistical Learning Approach, pp. 301-311, (2013); Guo J., Et al., Data-efficient performance learning for configurable systems, EMSE, 23, 3, pp. 1826-1867, (2018); Samoaa H.P., Longa A., Mohamed M., Chehreghani M.H., Leitner P., TEP-GNN: Accurate Execution Time Prediction of Functional Tests Using Graph Neural Networks. Zenodo, (2022); Huber W., Carey V.J., Long L., Falcon S., Gentleman R., Graphs in molecular biology, BMC Bioinform, 8, 6, pp. 1-14, (2007); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, (2014); Knauss E., Staron M., Meding W., Soder O., Nilsson A., Castell M., Supporting continuous integration by code-churn based test selection, 2015 IEEE/ACM 2Nd International Workshop on Rapid Continuous Software Engineering, pp. 19-25, (2015); Laaber C., Basmaci M., Salza P., Predicting unstable software benchmarks using static source code features, EMSE, 26, 6, (2021); Laaber C., Scheuner J., Leitner P., Software microbenchmarking in the cloud, How Bad is It Really? EMSE, 24, 4, pp. 2469-2508, (2019); Leitner P., Cito J., Patterns in the Chaos-a study of performance variation and predictability in public IaaS clouds, ACM TOIT, 16, 3, pp. 1-15, (2016); Li Y., Gu C., Dullien T., Vinyals O., Kohli P., Graph matching networks for learning the similarity of graph structured objects, Proceedings of the 36Th International Conference on Machine Learning, 97, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, (2015); Longa A., Cencetti G., Lepri B., Passerini A., An efficient procedure for mining egocentric temporal motifs, Data Min. Knowl. Disc., 36, 1, pp. 355-378, (2022); Marijan D., Gotlieb A., Liaaen M., A learning algorithm for optimizing continuous integration development and testing practice, Softw. Pract. Exp., 49, 2, pp. 192-213, (2019); Meng K., Norris B., Mira: A framework for static performance analysis, CLUS-TER, (2017); Morris C., Et al., Weisfeiler and leman go neural: Higher-order graph neural networks, AAAI, 33, (2019); Narayanan S.H.K., Norris B., Hovland P.D., Generating performance bounds from source code, International Conference on Parallel Processing Workshops, pp. 197-206, (2010); Ramadan T., Islam T.Z., Phelps C., Pinnow N., Thiagarajan J.J., Comparative code structure analysis using deep learning for performance prediction, ISPASS, Los Alamitos, CA, USA. IEEE Computer Society, March, (2021); Samoaa H., Catania B., A pipeline for measuring brand loyalty through social media mining, SOFSEM 2021. LNCS, Vol. 12607, pp. 489-504, (2021); Samoaa H., Leitner P., An exploratory study of the impact of parameterization on JMH measurement results in open-source projects, ICPE. Association for Computing Machinery, (2021); Samoaa H.P., Bayram F., Salza P., Leitner P., A systematic mapping study of source code representation for deep learning in software engineering, IET Softw, (2022); Sandoval Alcocer J.P., Bergel A., Valente M.T., Learning from source code history to identify performance failures, ICPE. Association for Computing Machinery, (2016); Schulz H., Okanovic D., van Hoorn A., Tuma P., Context-tailored workload model generation for continuous representative load testing, ICPE. Association for Computing Machinery, (2021); Spieker H., Gotlieb A., Marijan D., Mossige M., Reinforcement learning for automatic test case prioritization and selection in continuous integration, ISSTA, pp. 12-22, (2017); Viet Phan A., Le Nguyen M., Thu Bui L., Convolutional neural networks over control flow graphs for software defect prediction, ICTAI, (2017); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, SANER, (2020); Zhou M., Chen J., Hu H., Yu J., Li Z., Hu H., DeepTLE: Learning code-level features to predict code performance before it runs, APSEC, (2019)",,"23rd International Conference on Product-Focused Software Process Improvement, PROFES 2022",21 November 2022 through 23 November 2022,Jyväskylä,286329,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85142682048,21
Zhu R.; Yuan L.; Li X.; Gao M.; Cai W.,"Zhu, Renyu (57221475798); Yuan, Lei (57428916600); Li, Xiang (57218466858); Gao, Ming (7201511612); Cai, Wenyuan (22333298900)",57221475798; 57428916600; 57218466858; 7201511612; 22333298900,A Neural Network Architecture for Program Understanding Inspired by Human Behaviors,2022,Proceedings of the Annual Meeting of the Association for Computational Linguistics,1,,,5142,5153,11,9,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140398484&partnerID=40&md5=9020473919331f9676604d8e85374f6c,"Program understanding is a fundamental task in program language processing. Despite the success, existing works fail to take human behaviors as reference in understanding programs. In this paper, we consider human behaviors and propose the PGNN-EK model that consists of two main components. On the one hand, inspired by the “divide-and-conquer” reading behaviors of humans, we present a partitioning-based graph neural network model PGNN on the upgraded AST of codes. On the other hand, to characterize human behaviors of resorting to other resources to help code comprehension, we transform raw codes with external knowledge and apply pre-training techniques for information extraction. Finally, we combine the two embeddings generated from the two components to output code embeddings. We conduct extensive experiments to show the superior performance of PGNN-EK on the code summarization and code clone detection tasks. In particular, to show the generalization ability of our model, we release a new dataset that is more challenging for code clone detection and could advance the development of the community. Our codes and data are publicly available at https://github.com/RecklessRonan/PGNN-EK. © 2022 Association for Computational Linguistics.","Ahmad Wasi Uddin, Chakraborty Saikat, Ray Baishakhi, Chang Kai-Wei, A transformer-based approach for source code summarization, ACL 2020, (2020); Ahmad Wasi Uddin, Chakraborty Saikat, Ray Baishakhi, Chang Kai-Wei, Unified pre-training for program understanding and generation, NAACLHLT 2021, (2021); Allamanis Miltiadis, Barr Earl T., Bird Christian, Sutton Charles, Suggesting accurate method and class names, ESEC/FSE 2015, (2015); Allamanis Miltiadis, Barr Earl T., Devanbu Premkumar T., Sutton Charles, A survey of machine learning for big code and naturalness, ACM Comput. Surv, 51, 4, pp. 81:1-81:37, (2018); Allamanis Miltiadis, Brockschmidt Marc, Khademi Mahmoud, Learning to represent programs with graphs, ICLR 2018, (2018); Alon Uri, Brody Shaked, Levy Omer, Yahav Eran, code2seq: Generating sequences from structured representations of code, ICLR 2019, (2019); Alon Uri, Yahav Eran, On the bottleneck of graph neural networks and its practical implications, ICLR 2021, (2021); Alon Uri, Zilberstein Meital, Levy Omer, Yahav Eran, code2vec: learning distributed representations of code, Proc. ACM Program. Lang, 3, pp. 40:1-40:29, (2019); Bengio Yoshua, LeCun Yann, Hinton Geoffrey E., Deep learning for AI, Commun. ACM, 64, 7, pp. 58-65, (2021); Bui Nghi D. Q., Yu Yijun, Jiang Lingxiao, Infercode: Self-supervised learning of code representations by predicting subtrees, ICSE 2021, (2021); Cummins Chris, Fisches Zacharias V., Ben-Nun Tal, Hoefler Torsten, O'Boyle Michael F. P., Leather Hugh, Programl: A graph-based program representation for data flow analysis and compiler optimizations, ICML 2021, (2021); Cvitkovic Milan, Singh Badal, Anandkumar Animashree, Open vocabulary learning on source code with a graph-structured cache, ICML 2019, (2019); Dam Hoa Khanh, Tran Truyen, Pham Trang, A deep language model for software code, CoRR, (2016); Feng Zhangyin, Guo Daya, Tang Duyu, Duan Nan, Feng Xiaocheng, Gong Ming, Shou Linjun, Qin Bing, Liu Ting, Jiang Daxin, Zhou Ming, Codebert: A pre-trained model for programming and natural languages, EMNLP 2020, (2020); Fey Matthias, Lenssen Jan E., Fast graph representation learning with PyTorch Geometric, ICLR Workshop on Representation Learning on Graphs and Manifolds, (2019); He Kaiming, Zhang Xiangyu, Ren Shaoqing, Sun Jian, Deep residual learning for image recognition, CVPR 2016, (2016); Hellendoorn Vincent J., Sutton Charles, Singh Rishabh, Maniatis Petros, Bieber David, Global relational models of source code, ICLR 2020, (2020); Hindle Abram, Barr Earl T., Gabel Mark, Su Zhendong, Devanbu Premkumar T., On the naturalness of software, Commun. ACM, 59, 5, pp. 122-131, (2016); Hu Xing, Li Ge, Xia Xin, Lo David, Lu Shuai, Jin Zhi, Summarizing source code with transferred API knowledge, IJCAI 2018, (2018); Husain Hamel, Wu Ho-Hsiang, Gazit Tiferet, Allamanis Miltiadis, Brockschmidt Marc, Codesearchnet challenge: Evaluating the state of semantic code search, CoRR, (2019); Iyer Srinivasan, Konstas Ioannis, Cheung Alvin, Zettlemoyer Luke, Summarizing source code using a neural attention model, ACL 2016, (2016); Jean Sebastien, Cho KyungHyun, Memisevic Roland, Bengio Yoshua, On using very large target vocabulary for neural machine translation, ACL 2015, (2015); Karampatsis Rafael-Michael, Babii Hlib, Robbes Romain, Sutton Charles, Janes Andrea, Big code != big vocabulary: open-vocabulary models for source code, ICSE'20, (2020); LeClair Alexander, Jiang Siyuan, McMillan Collin, A neural model for generating natural language summaries of program subroutines, ICSE 2019, (2019); Lewis Mike, Liu Yinhan, Goyal Naman, Ghazvininejad Marjan, Mohamed Abdelrahman, Levy Omer, Stoyanov Veselin, Zettlemoyer Luke, BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, ACL 2020, pp. 7871-7880, (2020); Li Yujia, Tarlow Daniel, Brockschmidt Marc, Zemel Richard S., Gated graph sequence neural networks, ICLR 2016, (2016); Lin Chin-Yew, Och Franz Josef, ORANGE: a method for evaluating automatic evaluation metrics for machine translation, COLING 2004, (2004); Liu Shangqing, Chen Yu, Xie Xiaofei, Siow Jing Kai, Liu Yang, Retrieval-augmented generation for code summarization via hybrid GNN, ICLR 2021, (2021); Liu Yinhan, Ott Myle, Goyal Naman, Du Jingfei, Joshi Mandar, Chen Danqi, Levy Omer, Lewis Mike, Zettlemoyer Luke, Stoyanov Veselin, Roberta: A robustly optimized BERT pretraining approach, CoRR, (2019); Lu Shuai, Guo Daya, Ren Shuo, Huang Junjie, Svyatkovskiy Alexey, Blanco Ambrosio, Clement Colin B., Drain Dawn, Jiang Daxin, Tang Duyu, Li Ge, Zhou Li-dong, Shou Linjun, Zhou Long, Tufano Michele, Gong Ming, Zhou Ming, Duan Nan, Sundaresan Neel, Deng Shao Kun, Fu Shengyu, Liu Shujie, Codexglue: A machine learning benchmark dataset for code understanding and generation, CoRR, (2021); Neculoiu Paul, Versteegh Maarten, Rotaru Mihai, Learning text similarity with siamese recurrent networks, Proceedings of the 1st Workshop on Representation Learning for NLP, Rep4NLP@ACL 2016, (2016); Park Thomas H., Kim Meen Chul, Chhabra Sukrit, Lee Brian, Forte Andrea, Reading hierarchies in code: Assessment of a basic computational skill, ITiCSE 2016, pp. 302-307, (2016); Peng Dinglan, Zheng Shuxin, Li Yatao, Ke Guolin, He Di, Liu Tie-Yan, How could neural networks understand programs?, ICML 2021, (2021); Raychev Veselin, Vechev Martin T., Yahav Eran, Code completion with statistical language models, PLDI'14, (2014); Schulte Carsten, Clear Tony, Taherkhani Ahmad, Busjahn Teresa, Paterson James H., An introduction to program comprehension for computer science educators, Proceedings of the 2010 ITiCSE working group reports, ITiCSE-WGR 2010, pp. 65-86, (2010); Shi Ensheng, Wang Yanlin, Du Lun, Chen Junjie, Han Shi, Zhang Hongyu, Zhang Dongmei, Sun Hongbin, Neural code summarization: How far are we?, CoRR, (2021); Svajlenko Jeffrey, Islam Judith F., Keivanloo Iman, Roy Chanchal Kumar, Mia Mohammad Mamun, Towards a big data curated benchmark of inter-project code clones, ICSME 2014, (2014); Svajlenko Jeffrey, Roy Chanchal K., Evaluating clone detection tools with bigclonebench, ICSME 2015, (2015); Svyatkovskiy Alexey, Deng Shao Kun, Fu Shengyu, Sundaresan Neel, Intellicode compose: code generation using transformer, ESEC/FSE'20, (2020); Vaswani Ashish, Shazeer Noam, Parmar Niki, Uszkoreit Jakob, Jones Llion, Gomez Aidan N., Kaiser Lukasz, Polosukhin Illia, Attention is all you need, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, (2017); Wang Wenhan, Li Ge, Ma Bo, Xia Xin, Jin Zhi, Detecting code clones with graph neural network and flow-augmented abstract syntax tree, SANER 2020, (2020); Wang Yanlin, Li Hui, Code completion by modeling flattened abstract syntax trees as graphs, AAAI 2021, (2021); Wei Huihui, Li Ming, Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, IJCAI 2017, (2017); Wolf Thomas, Debut Lysandre, Sanh Victor, Chaumond Julien, Delangue Clement, Moi Anthony, Cistac Pierric, Rault Tim, Louf Remi, Funtowicz Morgan, Davison Joe, Shleifer Sam, von Platen Patrick, Ma Clara, Jernite Yacine, Plu Julien, Xu Canwen, Le Scao Teven, Gugger Sylvain, Drame Mariama, Lhoest Quentin, Rush Alexander M., Transformers: State-of-the-art natural language processing, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pp. 38-45, (2020); Xu Frank F., Jiang Zhengbao, Yin Pengcheng, Vasilescu Bogdan, Neubig Graham, Incorporating external knowledge through pre-training for natural language to code generation, ACL 2020, (2020); Yamaguchi Fabian, Golde Nico, Arp Daniel, Rieck Konrad, Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, SP 2014, (2014); Yu Hao, Lam Wing, Chen Long, Li Ge, Xie Tao, Wang Qianxiang, Neural detection of semantic code clones via tree-based convolution, ICPC 2019, (2019); Yu Zeping, Zheng Wenxin, Wang Jiaqi, Tang Qiyi, Nie Sen, Wu Shi, Codecmr: Cross-modal retrieval for function-level binary source code matching, NeurIPS 2020, (2020); Zaremba Wojciech, Sutskever Ilya, Learning to execute, CoRR, (2014); Zhang Jian, Wang Xu, Zhang Hongyu, Sun Hailong, Liu Xudong, Retrieval-based neural source code summarization, ICSE, 20, (2020); Zhang Jian, Wang Xu, Zhang Hongyu, Sun Hailong, Wang Kaixuan, Liu Xudong, A novel neural source code representation based on abstract syntax tree, ICSE 2019, (2019); Zugner Daniel, Kirschstein Tobias, Catasta Michele, Leskovec Jure, Gunnemann Stephan, Language-agnostic representation learning of source code from structure and context, ICLR 2021, (2021)",Amazon Science; Bloomberg Engineering; et al.; Google Research; Liveperson; Meta,"60th Annual Meeting of the Association for Computational Linguistics, ACL 2022",22 May 2022 through 27 May 2022,Dublin,181737,English,Conference paper,Final,,Scopus,2-s2.0-85140398484,22
Xue Y.; Guo J.; Zhang L.; Song H.,"Xue, Yang (57225149369); Guo, Junjun (55978093400); Zhang, Li (57752367700); Song, Huiyu (57980084400)",57225149369; 55978093400; 57752367700; 57980084400,Message Passing Graph Neural Networks for Software Security Vulnerability Detection,2022,"Proceedings - 2022 International Conference on Computer Network, Electronic and Automation, ICCNEA 2022",,,,144,148,4,0,10.1109/ICCNEA57056.2022.00041,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142506108&doi=10.1109%2fICCNEA57056.2022.00041&partnerID=40&md5=b9f59e156dd72ddaaacc337da4ce9342,"With the booming development of deep learning and machine learning, the use of neural networks for software source code security vulnerability detection has become a hot pot in the field of software security. As a data structure, graphs can adequately represent the complex syntactic information, semantic information, and dependencies in software source code. In this paper, we propose the MPGVD model based on the idea of text classification in natural language processing. The model uses BERT for source code pre-training, transforms graphs into corresponding feature vectors, uses MPNN (Message Passing Neural Networks) based on graph neural networks in the feature extraction phase, and finally outputs the detection results. Our proposed MPGVD, compared with other existing vulnerability detection models on the same dataset CodeXGLUE, obtain the highest detection accuracy of 64.34%.  © 2022 IEEE.","Gori M., Monfardini G., Scarselli F., A new model for learning in graph domains [C], Proceedings. 2005 IEEE international joint conference on neural networks., 2, pp. 729-734, (2005); Scarselli F., Gori M., Tsoi A.C., Et al., The graph neural network model [J], IEEE transactions on neural networks, 20, 1, pp. 61-80, (2008); Gilmer J., Schoenholz S.S., Riley P.F., Et al., Neural message passing for quantum chemistry [C], International conference on machine learning. PMLR, pp. 1263-1272, (2017); Guo J., Li H., Wang Z., Et al., A Novel Vulnerable Code Clone Detector Based on Context Enhancement and Patch Validation [J], Wireless Communications and Mobile Computing, (2022); Zhou L., Huang M., Li Y., Et al., GraphEye: A Novel Solution for Detecting Vulnerable Functions Based on Graph Attention Network [C], 2021 IEEE Sixth International Conference on Data Science in Cyberspace (DSC). IEEE, pp. 381-388, (2021); Kamiya T., Kusumoto S., Inoue K., CCFinder: A multilinguistic token-based code clone detection system for large scale source code [J], IEEE transactions on software engineering, 28, 7, pp. 654-670, (2002); Pham N.H., Nguyen T.T., Nguyen H.A., Et al., Detection of recurring software vulnerabilities [C], Proceedings of the IEEE/ACM international conference on Automated software engineering., pp. 447-456, (2010); Li J., Ernst M.D., CBCD: Cloned buggy code detector [C], 2012 34th International Conference on Software Engineering (ICSE). IEEE, pp. 310-320, (2012); Kim S., Woo S., Lee H., Et al., Vuddy: A scalable approach for vulnerable code clone discovery [C], 2017 IEEE Symposium on Security and Privacy (SP). IEEE, pp. 595-614, (2017); Xu X., Liu C., Feng Q., Et al., Neural network-based graph embedding for cross-platform binary code similarity detection [C], Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security., pp. 363-376, (2017); Votipka D., Stevens R., Redmiles E., Et al., Hackers vs. testers: A comparison of software vulnerability discovery processes [C], 2018 IEEE Symposium on Security and Privacy (SP). IEEE, pp. 374-391, (2018); Li Z., Zou D., Xu S., Et al., Vuldeepecker: A deep learning-based system for vulnerability detection [J], (2018); Li Z., Zou D., Xu S., Et al., Sysevr: A framework for using deep learning to detect software vulnerabilities [J], IEEE Transactions on Dependable and Secure Computing, (2021); Ziems N., Wu S., Security Vulnerability Detection Using Deep Learning Natural Language Processing [J], (2021); Yun S., Jeong M., Yoo S., Et al., Graph Transformer Networks: Learning Meta-path Graphs to Improve GNNs [J], (2021); Zhang Y., Yu X., Cui Z., Et al., Every document owns its structure: Inductive text classification via graph neural networks [J], (2020); Feng Z., Guo D., Tang D., Et al., Codebert: A pre-trained model for programming and natural languages [J], (2020); Guo J., Wang Z., Li H., Et al., Detecting vulnerability in source code using CNN and LSTM network [J], Soft Computing, pp. 1-11, (2021); Wu Z., Pan S., Chen F., Et al., A comprehensive survey on graph neural networks [J], IEEE transactions on neural networks and learning systems, 32, 1, pp. 4-24, (2020); Lu S., Guo D., Ren S., Et al., Codexglue: A machine learning benchmark dataset for code understanding and generation [J], (2021); Hochreiter S., Schmidhuber J., Et al., Long short-Term memory [J], Neural computation, 9, 8, pp. 1735-1780, (1997); Chen Y., Convolutional neural network for sentence classification [D], (2015); Zhou Y., Liu S., Siow J., Et al., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks [J], Advances in neural information processing systems, 32, (2019); Nguyen V.A., Nguyen D.Q., Nguyen V., Et al., ReGVD: Revisiting Graph Neural Networks for Vulnerability Detection [J], (2021)","State and Provincial Joint Engineering Lab. of Advanced Network, Monitoring and Controls; Xi�an Technological University","5th International Conference on Computer Network, Electronic and Automation, ICCNEA 2022",23 September 2022 through 25 September 2022,Xi�an,183972,English,Conference paper,Final,,Scopus,2-s2.0-85142506108,23
Nguyen H.V.; Zheng J.; Inomata A.; Uehara T.,"Nguyen, Hoang Viet (57352197800); Zheng, Junjun (55496652300); Inomata, Atsuo (8950100000); Uehara, Tetsutaro (8215150700)",57352197800; 55496652300; 8950100000; 8215150700,Code Aggregate Graph: Effective Representation for Graph Neural Networks to Detect Vulnerable Code,2022,IEEE Access,10,,,123786,123800,14,1,10.1109/ACCESS.2022.3216395,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140708573&doi=10.1109%2fACCESS.2022.3216395&partnerID=40&md5=1a5ef9149269d7bcb295558d4263f64a,"Deep learning, especially graph neural networks (GNNs), provides efficient, fast, and automated methods to detect vulnerable code. However, the accuracy could be improved as previous studies were limited by existing code representations. Additionally, the diversity of embedding techniques and GNN models can make selecting the appropriate method challenging. Herein we propose Code Aggregate Graph (CAG) to improve vulnerability detection efficiency. CAG combines the principles of different code analyses such as abstract syntax tree, control flow graph, and program dependence graph with dominator and post-dominator trees. This extensive representation empowers deep graph networks for enhanced classification. We also implement different data encoding methods and neural networks to provide a multidimensional view of the system performance. Specifically, three word embedding approaches and three deep GNNs are utilized to build classifiers. Then CAG is evaluated using two datasets: a real-world open-source dataset and the software assurance reference dataset. CAG is also compared with seven state-of-the-art methods and six classic representations. CAG shows the best performance. Compared to previous studies, CAG has an increased accuracy (5.4%) and F1-score (5.1%). Additionally, experiments confirm that encoding has a positive impact on accuracy (4-6%) but the network type does not. The study should contribute to a meaningful benchmark for future research on code representations, data encoding, and GNNs.  © 2013 IEEE.","All about Whitesource's 2021 Open Source Security Vulnerabilities Report, (2021); Raveendran S., Explained: How Big Is the Damage Caused by Open Source Software Log4J Vulnerability?, (2021); Kim S., Kim R.Y.C., Park Y.B., Software vulnerability detection methodology combined with static and dynamic analysis, Wireless Pers. Commun., 89, 3, pp. 777-793, (2016); McGraw G., Software security, IEEE Secur. Privacy, 2, 2, pp. 80-83, (2004); Li Z., Zou D., Tang J., Zhang Z., Sun M., Jin H., A comparative study of deep learning-based vulnerability detection system, IEEE Access, 7, pp. 103184-103197, (2019); Lin G., Xiao W., Zhang J., Xiang Y., Deep learning-based vulnerable function detection: A benchmark, Proc. 21st Int. Conf. Inf. Commun. Secur. (ICICS), pp. 219-232, (2019); Nguyen N.H., Nguyen V.H., Uehara T., An extended benchmark system of word embedding methods for vulnerability detection, Proc. 4th Int. Conf. Future Netw. Distrib. Syst. (ICFNDS), pp. 1-8, (2020); Cao S., Sun X., Bo L., Wei Y., Li B., BGNN4VD: Constructing bidirectional graph neural-network for vulnerability detection, Inf. Softw. Technol., 136, (2021); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., VulDeePecker: A Deep Learning-based System for Vulnerability Detection, (2018); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., SySeVR: A framework for using deep learning to detect software vulnerabilities, IEEE Trans. Depend. Sec. Comput., 19, 4, pp. 2244-2258, (2022); Schafer A., Amme W., Heinze T.S., Detection of similar functions through the use of dominator information, Proc. IEEE Int. Conf. Auto-Nomic Comput. Self-Organizing Syst. Companion (ACSOS-C), pp. 206-211, (2020); Sun H., Cui L., Li L., Ding Z., Hao Z., Cui J., Liu P., VDSimilar: Vulnerability detection based on code similarity of vulnerabilities and patches, Comput. Secur., 110, (2021); Kim S., Woo S., Lee H., Oh H., VUDDY: A scalable approach for vulnerable code clone discovery, Proc. IEEE Symp. Secur. Privacy (SP), pp. 595-614, (2017); Bromley J., Guyon I., LeCun Y., Sackinger E., Shah R., Signature verification using a 'Siamese' time delay neural network, Proc. Adv. Neural Inf. Process. Syst., 6, pp. 1-8, (1993); Rough Audit Tool for Security, (2014); Flawfinder, (2018); Younan Y., Joosen W., Piessens F., Code Injection in C and CCC: A Survey of Vulnerabilities and Countermeasures, (2004); Yu Z., Theisen C., Williams L., Menzies T., Improving vulnerability inspection efficiency using active learning, IEEE Trans. Softw. Eng., 47, 11, pp. 2401-2420, (2021); Sultana K.Z., Towards a software vulnerability prediction model using traceable code patterns and software metrics, Proc. 32nd IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 1022-1025, (2017); Chernis B., Verma R., Machine learning methods for software vulnerability detection, Proc. 4th ACM Int. Workshop Secur. Privacy Anal., pp. 31-39, (2018); Welty C.A., Augmenting abstract syntax trees for program understanding, Proc. 12th IEEE Int. Conf. Automated Softw. Eng., pp. 126-133, (1997); Grosch J., Emmelmann H., A tool box for compiler construction, Proc. 3rd Int. Workshop Compiler Compil. (CC), pp. 106-116, (1991); Orailoglu A., Gajski D.D., Flow graph representation, Proc. 23rd ACM/IEEE Design Autom. Conf., pp. 503-509, (1986); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Trans. Program. Lang. Syst., 9, 3, pp. 319-349, (1987); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, Proc. IEEE Symp. Secur. Privacy, pp. 590-604, (2014); Ramalingam G., Reps T., An incremental algorithm for maintaining the dominator tree of a reducible flowgraph, Proc. 21st ACM SIGPLAN-SIGACT Symp. Princ. Program. Lang., pp. 287-296, (1994); Nguyen H.N., Teerakanok S., Inomata A., Uehara T., The comparison of word embedding techniques in RNNs for vulnerability detection, Proc. ICISSP, pp. 109-120, (2021); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Proc. Adv. Neural Inf. Process. Syst., 32, pp. 1-11, (2019); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Proc. Adv. Neural Inf. Process. Syst., 26, pp. 1-9, (2013); Mikolov T., Chen K., Corrado G., Dean J., Efficient Estimation of Word Representations in Vector Space, (2013); Bojanowski P., Grave E., Joulin A., Mikolov T., Enriching word vectors with subword information, Trans. Assoc. Comput. Linguistics, 5, pp. 135-146, (2017); Pennington J., Socher R., Manning C.D., Glove: Global vectors for word representation, Proc. Conf. Empirical Methods Natural Lang. Process. (EMNLP), pp. 1532-1543, (2014); Wu Y., Lu J., Zhang Y., Jin S., Vulnerability detection in C/CCC source code with graph representation learning, Proc. IEEE 11th Annu. Comput. Commun. Workshop Conf. (CCWC), pp. 1519-1524, (2021); Kipf T.N., Welling M., Semi-supervised Classification with Graph Convolutional Networks, (2016); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, (2015); Xu K., Hu W., Leskovec J., Jegelka S., Howpowerful Are Graph Neural Networks?, (2018); Hamilton W.L., Graph representation learning, Synth. Lect. Artif. Intell. Mach. Learn., 14, 3, pp. 1-159, (2020); Black P., A software assurance reference dataset: Thousands of programs with known bugs, J. Res. Nat. Inst. Standards Technol., 123, pp. 1-3, (2018); Fan J., Li Y., Wang S., Nguyen T.N., AC/CCC code vulnerability dataset with code changes and CVE summaries, Proc. 17th Int. Conf. Mining Softw. Repositories, pp. 508-512, (2020); Ozkan S., CVE Details: The Ultimate Security Vulnerability Data-Source, (2011); The National Vulnerability Database (NVD); McKight P.E., Najab J., Kruskal-Wallis test, The Corsini Ency-Clopedia of Psychology., (2010)",,,,,,English,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85140708573,24
Petukhov M.; Gudauskayte E.; Kaliyev A.; Oskin M.; Ivanov D.; Wang Q.,"Petukhov, Maxim (57685974200); Gudauskayte, Evelina (57687006100); Kaliyev, Arman (55701609000); Oskin, Mikhail (57685974300); Ivanov, Dmitry (57226306481); Wang, Qianxiang (57208587889)",57685974200; 57687006100; 55701609000; 57685974300; 57226306481; 57208587889,Method Name Prediction for Automatically Generated Unit Tests,2022,ICCQ 2022 - Proceedings of the 2nd International Conference on Code Quality,,,,29,38,9,1,10.1109/ICCQ53703.2022.9763112,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130020877&doi=10.1109%2fICCQ53703.2022.9763112&partnerID=40&md5=ed0fff791e84806977f36e384166f1e4,"Writing intuitively understandable method names is an important aspect of good programming practice. The method names have to summarize the codes' behavior such that software engineers would easily understand their purpose. Modern automatic testing tools are able to generate potentially unlimited number of unit tests for a project under test. However, these tests suffers from unintelligible unit test names as it is quite difficult to understand what each test triggers and checks. This inspired us to adapt the state-of-the-art method name prediction approaches for automatically generated unit tests. We have developed a graph extraction pipeline with prediction models based on Graph Neural Networks (GNNs). Extracted graphs contain information about the structure of unit tests and their called functions. The experiment results have shown that the proposed work outperforms other models with precision = 0.48, recall = 0.42 and F1 = 0.45 results. The dataset and source codes are released for wide public access.  © 2022 IEEE.","Allamanis M., Barr E.T., Bird C., Sutton C., Suggesting Accurate Method and Class Names, Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering (Bergamo, Italy), pp. 38-49, (2015); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, CoRR, (2018); Almasi M.M., Hemmati H., Fraser G., Arcuri A., Benefelds J., An Industrial Evaluation of Unit Test Generation: Finding Real Faults in a Financial Application, 2017 IEEE/ACM 39th International Conference on Software Engineering: Software Engineering in Practice Track (ICSE-SEIP), pp. 263-272, (2017); Alon U., Levy O., Yahav E., Code2seq: Generating Sequences from Structured Representations of Code, CoRR, (2018); Cadar C., Dunbar D., Engler D., KLEE: Unassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs, Proceedings of the 8th USENIX Conference on Operating Systems Design and Implementation (San Diego, California) (OSDI'08), pp. 209-224, (2008); Cvitkovic M., Singh B., Anandkumar A., Open Vocabulary Learning on Source Code with a Graph-Structured Cache, CoRR, (2018); Fernandes P., Allamanis M., Brockschmidt M., Structured Neural Summarization, CoRR, (2018); Fey M., Lenssen J.E., Fast Graph Representation Learning with PyTorch Geometric, CoRR, (2019); Fraser G., Arcuri A., 1600 Faults in 100 Projects: Automatically Finding Faults While Achieving High Coverage with EvoSuite, Empirical Softw. Engg., 20, 3, pp. 611-639, (2015); Glorot X., Bengio Y., Understanding the difficulty of training deep feedforward neural networks, AISTATS, 9, pp. 249-256, (2010); Hamilton W.L., Ying R., Leskovec J., Sosic R., Representation Learning on Networks, (2018); Hosseini R., Brusilovsky P., JavaParser: A fine-grain concept indexing tool for java problems, CEUR Workshop Proceedings, 1009, pp. 60-63, (2013); Ivanov D., Bukharev N., Menshutin A., Nagdalian A., Stromov G., Ustinov A., UtBot at the SBST2021 Tool Competition, Proceedings of the ACM/IEEE 43th International Conference on Software Engineering: Companion Proceedings (ICSE '21), (2021); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing Source Code using a Neural Attention Model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, 1, pp. 2073-2083, (2016); Kalliamvakou E., Gousios G., Blincoe K., Singer L., German D.M., Damian D., The Promises and Perils of Mining GitHub, Proceedings of the 11th Working Conference on Mining Software Repositories (Hyderabad, India), pp. 92-101, (2014); Korf R.E., Depth-first iterative-deepening: An optimal admissible tree search, Artificial Intelligence, 27, 1, pp. 97-109, (1985); Lam P., Bodden E., Lhotak O., Hendren L., The Soot framework for Java program analysis: a retrospective, (2011); Le-Clair A., Haque S., Wu L., McMillan C., Improved Code Summarization via a Graph Neural Network, (2020); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, CoRR, (2016); Liang H., Sun L., Wang M., Yang Y., Deep Learning With Customized Abstract Syntax Tree for Bug Localization, IEEE Access, 7, pp. 116309-116320, (2019); Luong M.-T., Pham H., Manning C.D., Effective Approaches to Attention-based Neural Machine Translation, CoRR, (2015); Nazar N., Hu Y., Jiang H., Summarizing Software Artifacts: A Literature Review, J. Comput. Sci. Technol., 31, 5, pp. 883-909, (2016); Nguyen S., Phan H., Le T., Nguyen T.N., Suggesting Natural Method Names to Check Name Consistencies, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering (Seoul, South Korea) (ICSE '20), pp. 1372-1384, (2020); Paszke A., Gross S., Massa F., Lerer A., Bradbury J., Chanan G., Killeen T., Lin Z., Gimelshein N., Antiga L., Desmaison A., Kopf A., Yang E., De-Vito Z., Raison M., Tejani A., Chilamkurthy S., Steiner B., Fang L., Bai J., Chintala S., PyTorch: An Imperative Style, High-Performance Deep Learning Library, CoRR, (2019); Serra D., Grano G., Palomba F., Ferrucci F., Gall H.C., Bacchelli A., On the Effectiveness of Manual and Automatic Unit Test Generation: Ten Years Later, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), pp. 121-125, (2019); Shamshiri S., Just R., Rojas J.M., Fraser G., McMinn P., Arcuri A., Do Automatically Generated Unit Tests Find Real Faults? An Empirical Study of Effectiveness and Challenges (T), 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 201-211, (2015); Song X., Sun H., Wang X., Yan J., A Survey of Automatic Generation of Source Code Comments: Algorithms and Techniques, CoRR, (2019); Wang Y., Gao F., Wang L., Wang K., Learning Semantic Program Embeddings with Graph Interval Neural Network, (2020); Wang Y., Li H., Code Completion by Modeling Flattened Abstract Syntax Trees as Graphs, (2021); Zheng M., Pan X., Lillis D., CodEX: Source Code Plagiarism Detection Based on Abstract Syntax Tree, Proceedings for the 26th AIAI Irish Conference on Artificial Intelligence and Cognitive Science Trinity College Dublin, Dublin, Ireland, 2259, pp. 362-373, (2018)",,"2nd International Conference on Code Quality, ICCQ 2022",23 April 2022,Innopolis,179041,English,Conference paper,Final,,Scopus,2-s2.0-85130020877,25
Chen Z.; Zhang T.; Peng X.,"Chen, Zijie (58062870800); Zhang, Tao (55547105895); Peng, Xiao (58429170900)",58062870800; 55547105895; 58429170900,A Novel API Recommendation Approach By Using Graph Attention Network,2021,"IEEE International Conference on Software Quality, Reliability and Security, QRS",2021-December,,,726,737,11,2,10.1109/QRS54544.2021.00082,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146199902&doi=10.1109%2fQRS54544.2021.00082&partnerID=40&md5=cef4668a79de071a6550072240aef8be,"Although the use of APIs (Application Programming Interfaces) in software program development can effectively improve development efficiency, developers still need to spend more time in finding suitable APIs. To improve the overall development efficiency, many API recommendation approaches have been proposed. However, they could not make good use of the information in the source code, especially for the structural information. The PDG (Program Dependence Graph) of source code can contain both syntactic and structural information, which can be great representations of the source code. Based on the PDG, we propose a new approach, called JARST (Java API Recommendation combining Structural with Textual code information), which recommends the appropriate APIs by analyzing the structure information and text information of the source code. The JARST approach uses a graph neural network to learn source code structure information of PDG and uses a multi-modal approach to learn the text information in the source code. Finally, we combine the structural and textual information of the source code to implement API recommendations. We collect 625 open source Java projects from Github as our experimental objects. The experimental results show that JARST can provide accurate APIs to help software developers facilitate development activities. Moreover, it performs better than the cutting-edge studies including APIRes-CST and APIREC with higher top-k accuracy values. In detail, the improvement achieves up to 35.3%. © 2021 IEEE.","Rahman M. M., Roy C. K., Lo D., Rack: Automatic api recommendation using crowdsourced knowledge, Proceedings of the 2016 23rd IEEE International Conference on Software Analysis, Evolution, and Reengineering, 1, pp. 349-359, (2016); Huang Q., Xia X., Xing Z., Lo D., Wang X., Api method recommendation without worrying about the task-api knowledge gap, Proceedings of the 2018 33rd IEEE/ACM International Conference on Automated Software Engineering, pp. 293-304, (2018); Cai L., Wang H., Huang Q., Xia X., Xing Z., Lo D., Biker: a tool for bi-information source based api method recommendation, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 1075-1079, (2019); Robillard M. P., What makes apis hard to learn answers from developers, IEEE Software, 26, 6, pp. 27-34, (2009); Nasehi S. M., Sillito J., Maurer F., Burns C., What makes a good code example: A study of programming q&a in stackoverflow, Proceedings of the 2012 28th IEEE International Conference on Software Maintenance, pp. 25-34, (2012); Nguyen A. T., Hilton M., Codoban M., Nguyen H. A., Mast L., Rademacher E., Nguyen T. N., Dig D., Api code recommendation using statistical learning from fine-grained changes, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 511-522, (2016); Ling C., Zou Y., Xie B., Graph neural network based collaborative filtering for api usage recommendation, Proceedings of the 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering, pp. 36-47, (2021); Scarselli F., Gori M., Tsoi A. C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Transactions on Neural Networks, 20, 1, pp. 61-80, (2008); Xu K., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks, (2018); Chen C., Peng X., Xing Z., Sun J., Wang X., Zhao Y., Zhao W., Holistic combination of structural and textual code information for context based api recommendation, IEEE Transactions on Software Engineering, (2021); Ottenstein K. J., Ottenstein L. M., The program dependence graph in a software development environment, ACM Sigplan Notices, 19, 5, pp. 177-184, (1984); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); Hochreiter S., Schmidhuber J., Long short-term memory, Neural computation, 9, 8, pp. 1735-1780, (1997); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, Proceedings of the 2020 27th IEEE International Conference on Software Analysis, Evolution and Reengineering, pp. 261-271, (2020); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P. S., Multimodal attention network learning for semantic source code retrieval, (2019); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, (2018); Lau J., Perelman E., Calder B., Selecting software phase markers with code structure analysis, Proceedings of the 2006 International Symposium on Code Generation and Optimization, pp. 135-146, (2006); Zou Y., Ban B., Xue Y., Xu Y., Ccgraph: a pdg-based code clone detector with approximate graph matching, Proceedings of the 2020 35th IEEE/ACM International Conference on Automated Software Engineering, pp. 931-942, (2020); Higo Y., Yasushi U., Nishino M., Kusumoto S., Incremental code clone detection: A pdg-based approach, Proceedings of the 2011 18th Working Conference on Reverse Engineering, pp. 3-12, (2011); Li Y., Wang S., Nguyen T. N., Van Nguyen S., Improving bug detection via context-based code representation learning and attentionbased neural networks, Proceedings of the ACM on Programming Languages, 3, 162, pp. 1-30, (2019); Bian P., Liang B., Zhang Y., Yang C., Shi W., Cai Y., Detecting bugs by discovering expectations and their violations, IEEE Transactions on Software Engineering, 45, 10, pp. 984-1001, (2018); Brown P. F., Della Pietra V. J., Desouza P. V., Lai J. C., Mercer R. L., Class-based n-gram models of natural language, Computational Linguistics, 18, 4, pp. 467-480, (1992); Wu Z., Pan S., Chen F., Long G., Zhang C., Philip S. Y., A comprehensive survey on graph neural networks, IEEE Transactions on Neural Networks and Learning Systems, 32, 1, pp. 4-24, (2020); LeCun Y., Bengio Y., Convolutional Networks for Images, Speech, and Time Series, pp. 255-258, (1998); Kipf T. N., Welling M., Semi-supervised classification with graph convolutional networks, (2016); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, (2015); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proceedings of the 2020 28th International Conference on Program Comprehension, pp. 184-195, (2020); Zhou H., Ren D., Xia H., Fan M., Yang X., Huang H., Astgnn: An attention-based spatio-temporal graph neural network for interaction-aware pedestrian trajectory prediction, Neurocomputing, 445, pp. 298-308, (2021); Zaremba W., Sutskever I., Vinyals O., Recurrent neural network regularization, (2014); Jones J., Abstract syntax tree implementation idioms, Proceedings of the 2003 10th Conference on Pattern Languages of Programs, pp. 1-10, (2003); Javaparser, (2021); Github, (2021); JDK8, (2021); Marin V. J., Rivero C. R., Towards a framework for generating program dependence graphs from source code, Proceedings of the 2018 4th ACM SIGSOFT International Workshop on Software Analytics, pp. 30-36, (2018); Galaxy, (2021); Log4j, (2021); Froyo-email, (2021); Grid-sphere, (2021); Itext, (2021); Bellon S., Koschke R., Antoniol G., Krinke J., Merlo E., Comparison and evaluation of clone detection tools, IEEE Transactions on Software Engineering, 33, 9, pp. 577-591, (2007); Saini V., Farmahinifarahani F., Lu Y., Baldi P., Lopes C. V., Oreo: Detection of clones in the twilight zone, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 354-365, (2018); Liu C., Chen C., Han J., Yu P. S., Gplag: detection of software plagiarism by program dependence graph analysis, Proceedings of the 2006 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 872-881, (2006); Nguyen A. T., Nguyen T. N., Graph-based statistical language model for code, Proceedings of the 2015 37th IEEE International Conference on Software Engineering, 1, pp. 858-868, (2015); Xie R., Kong X., Wang L., Zhou Y., Li B., Hirec: Api recommendation using hierarchical context, Proceedings of the 2019 30th IEEE International Symposium on Software Reliability Engineering, pp. 369-379, (2019); Grove D., DeFouw G., Dean J., Chambers C., Call graph construction in object-oriented languages, Proceedings of the 1997 12th ACM SIGPLAN Conference on Object-oriented Programming, Systems, Languages, and Applications, pp. 108-124, (1997); Zhao Y., Li L., Sun X., Liu P., Grundy J., Icon2code: Recommending code implementations for android gui components, Information and Software Technology, 138, pp. 1-12, (2021); Nguyen P. T., Di Rocco J., Di Ruscio D., Ochoa L., Degueule T., Di Penta M., Focus: A recommender system for mining api function calls and usage patterns, Proceedings of the 2019 41st IEEE/ACM International Conference on Software Engineering, pp. 1050-1060, (2019); Allamanis M., Sutton C., Mining source code repositories at massive scale using language modeling, Proceedings of the 2013 10th Working Conference on Mining Software Repositories, pp. 207-216, (2013); Raychev V., Vechev M., Yahav E., Code completion with statistical language models, Proceedings of the 2014 35th ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 419-428, (2014); Ren X., Ye X., Xing Z., Xia X., Xu X., Zhu L., Sun J., Apimisuse detection driven by fine-grained api-constraint knowledge graph, Proceedings of the 2020 35th IEEE/ACM International Conference on Automated Software Engineering, pp. 461-472, (2020); Sven A., Nguyen H. A., Nadi S., Nguyen T. N., Mezini M., Investigating next steps in static api-misuse detection, Proceedings of the 2019 16th IEEE/ACM International Conference on Mining Software Repositories, pp. 265-275, (2019); Kang H. J., Lo D., Active learning of discriminative subgraph patterns for api misuse detection, IEEE Transactions on Software Engineering, (2021); Chen C., Xing Z., Liu Y., Ong K. L. X., Mining likely analogical apis across third-party libraries via large-scale unsupervised api semantics embedding, IEEE Transactions on Software Engineering, (2019); Xu S., Dong Z., Meng N., Meditor: inference and application of api migration edits, Proceedings of the 2019 27th IEEE/ACM International Conference on Program Comprehension, pp. 335-346, (2019); Alrubaye H., Mkaouer M. W., Khokhlov I., Reznik L., Ouni A., Mcgoff J., Learning to recommend third-party library migration opportunities at the api level, Applied Soft Computing, 90, pp. 1-12, (2020)",,"21st International Conference on Software Quality, Reliability and Security, QRS 2021",6 December 2021 through 10 December 2021,Hainan,177710,English,Conference paper,Final,,Scopus,2-s2.0-85146199902,26
Paaßen B.; McBroom J.; Jeffries B.; Yacef K.; Koprinska I.,"Paaßen, Benjamin (56140047200); McBroom, Jessica (57202792326); Jeffries, Bryn (57188721296); Yacef, Kalina (6505989104); Koprinska, Irena (6506616260)",56140047200; 57202792326; 57188721296; 6505989104; 6506616260,Mapping Python Programs to Vectors using Recursive Neural Encodings,2021,Journal of Educational Data Mining,13,3,,1,35,34,6,10.5281/zenodo.5634224,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132630551&doi=10.5281%2fzenodo.5634224&partnerID=40&md5=7aa89301e2e8d1ae526fd13f58e9cd3f,"Educational data mining involves the application of data mining techniques to student activity. However, in the context of computer programming, many data mining techniques can not be applied because they require vector-shaped input, whereas computer programs have the form of syntax trees. In this paper, we present ast2vec, a neural network that maps Python syntax trees to vectors and back, thereby enabling about a hundred data mining techniques that were previously not applicable. Ast2vec has been trained on almost half a million programs of novice programmers and is designed to be applied across learning tasks without re-training, meaning that users can apply it without any need for deep learning. We demonstrate the generality of ast2vec in three settings. First, we provide example analyses using ast2vec on a classroom-sized dataset, involving two novel techniques, namely progress-variance projection for visualization and a dynamical systems analysis for prediction. In these examples, we also explain how ast2vec can be utilized for educational decisions. Second, we consider the ability of ast2vec to recover the original syntax tree from its vector representation on the training data and two other large-scale programming datasets. Finally, we evaluate the predictive capability of a linear dynamical system on top of ast2vec, obtaining similar results to techniques that work directly on syntax trees while being much faster (constant- instead of linear-time processing). We hope ast2vec can augment the educational data mining toolkit by making analyses of computer programs easier, richer, and more efficient. © 2021. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","AGGARWAL C. C., HINNEBURG A., KEIM D. A., On the surprising behavior of distance metrics in high dimensional space, Proceedings of the International Conference on Database Theory (ICDT 2001), pp. 420-434, (2001); AHO A., LAM M., SETHI R., ULLMAN J., Compilers: Principles, Techniques, and Tools, (2006); ALON U., ZILBERSTEIN M., LEVY O., YAHAV E., Code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, (2019); BAKER R. S., YACEF K., The state of educational data mining in 2009: A review and future visions, Journal of Educational Data Mining, 1, 1, pp. 3-17, (2009); BARNES T., MOSTAFAVI B., EAGLE M. J., Data-driven domain models for problem solving, Design Recommendations for Intelligent Tutoring Systems, 4, pp. 137-145, (2016); BRODER A. Z., GLASSMAN S. C., MANASSE M. S., ZWEIG G., Syntactic clustering of the web, Computer Networks and ISDN Systems, 29, 8, pp. 1157-1166, (1997); CAMPI M., KUMAR P., Learning dynamical systems in a stationary environment, Systems & Control Letters, 34, 3, pp. 125-132, (1998); CHEN X., LIU C., SONG D., Tree-to-tree neural networks for program translation, Proceedings of the 31st International Conference on Advances in Neural Information Processing Systems, pp. 2552-2562, (2018); CHO K., VAN MERRIENBOER B., GULCEHRE C., BOUGARES F., SCHWENK H., BENGIO Y., Learning phrase representations using RNN encoder-decoder for statistical machine translation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pp. 1724-1734, (2014); CHOUDHURY R. R., YIN H., MOGHADAM J., FOX A., Autostyle: Toward coding style feedback at scale, Proceedings of the 19th ACM Conference on Computer Supported Cooperative Work and Social Computing Companion, pp. 21-24, (2016); DAI H., TIAN Y., DAI B., SKIENA S., SONG L., Syntax-directed variational autoencoder for structured data, Proceedings of the 6th International Conference on Learning Representations, (2018); DEMPSTER A. P., LAIRD N. M., RUBIN D. B., Maximum likelihood from incomplete data via the EM algorithm, Journal of the Royal Statistical Society. Series B (Methodological), 39, 1, pp. 1-38, (1977); DENNING P. J., Remaining trouble spots with computational thinking, Communications of the ACM, 60, 6, pp. 33-39, (2017); GISBRECHT A., SCHLEIF F.-M., Metric and non-metric proximity transformations at linear costs, Neurocomputing, 167, pp. 643-657, (2015); GLASSMAN E. L., SCOTT J., SINGH R., GUO P. J., MILLER R. C., Overcode: Visualizing variation in student solutions to programming problems at scale, ACM Transactions on Computer-Human Interaction, 22, 2, (2015); GROSS S., MOKBEL B., PAASSEN B., HAMMER B., PINKWART N., Example-based feedback provision using structured solution spaces, International Journal of Learning Technology, 9, 3, pp. 248-280, (2014); GROSS S., PINKWART N., How do learners behave in help-seeking when given a choice?, Proceedings of the 17th International Conference on Artificial Intelligence in Education, pp. 600-603, (2015); GULWANI S., RADICEK I., ZULEGER F., Automated clustering and program repair for introductory programming assignments, ACM SIGPLAN Notices, 53, 4, pp. 465-480, (2018); HAMMER B., HASENFUSS A., Topographic mapping of large dissimilarity data sets, Neural Computation, 22, 9, pp. 2229-2284, (2010); HAZAN E., SINGH K., ZHANG C., Learning linear dynamical systems via spectral filtering, Proceedings of the 30th Conference on Advances Neural Information Processing Systems, pp. 6702-6712, (2017); HYNDMAN R. J., KOEHLER A. B., Another look at measures of forecast accuracy, International Journal of Forecasting, 22, 4, pp. 679-688, (2006); IHANTOLA P., AHONIEMI T., KARAVIRTA V., SEPPALA O., Review of recent systems for automatic assessment of programming assignments, Proceedings of the 10th Koli Calling International Conference on Computing Education Research, pp. 86-93, (2010); KINGMA D., BA J., Adam: A method for stochastic optimization, Proceedings of the 3rd International Conference on Learning Representations, (2015); KINGMA D., WELLING M., Auto-encoding variational Bayes, Proceedings of the 1st International Conference on Learning Representations, (2013); KIPF T. N., WELLING M., Semi-supervised classification with graph convolutional networks, Proceedings of the 4th International Conference on Learning Representations, (2016); KOPRINSKA I., STRETTON J., YACEF K., Predicting student performance from multiple data sources, Proceedings of the International Conference on Artificial Intelligence in Education, pp. 678-681, (2015); KUSNER M. J., PAIGE B., HERNANDEZ-LOBATO J. M., Grammar variational autoencoder, Proceedings of the 34th International Conference on Machine Learning, pp. 1945-1954, (2017); LAHTINEN E., ALA-MUTKA K., JARVINEN H.-M., A study of the difficulties of novice programmers, SIGCSE Bulletin, 37, 3, pp. 14-18, (2005); LAN A. S., STUDER C., BARANIUK R. G., Time-varying learning and content analytics via sparse factor analysis, Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 452-461, (2014); MCBROOM J., KOPRINSKA I., YACEF K., How does student behaviour change approaching dropout? A study of gender and school year differences, Proceedings of the 13th International Conference on Educational Data Mining, pp. 643-647, (2020); MCBROOM J., KOPRINSKA I., YACEF K., A survey of automated programming hint generation: The hints framework, ACM Computing Surveys, 54, 8, (2021); MCBROOM J., PAASSEN B., JEFFRIES B., KOPRINSKA I., YACEF K., Progress networks as a tool for analysing student programming difficulties, Proceedings of the Twenty-Third Australasian Conference on Computing Education, pp. 158-167, (2021); MCBROOM J., YACEF K., KOPRINSKA I., CURRAN J. R., A data-driven method for helping teachers improve feedback in computer programming automated tutors, Artificial Intelligence in Education, pp. 324-337, (2018); MCCRACKEN M., ALMSTRUM V., DIAZ D., GUZDIAL M., HAGAN D., KOLIKANT Y. B.-D., LAXER C., THOMAS L., UTTING I., WILUSZ T., A multi-national, multi-institutional study of assessment of programming skills of first-year CS students, Working Group Reports from ITiCSE on Innovation and Technology in Computer Science Education, pp. 125-180, (2001); MIKOLOV T., SUTSKEVER I., CHEN K., CORRADO G. S., DEAN J., Distributed representations of words and phrases and their compositionality, Proceedings of the 26th International Conference on Advances in Neural Information Processing Systems, pp. 3111-3119, (2013); MOKBEL B., GROSS S., PAASSEN B., PINKWART N., HAMMER B., Domain-independent proximity measures in intelligent tutoring systems, Proceedings of the 6th International Conference on Educational Data Mining, pp. 334-335, (2013); NGUYEN A., PIECH C., HUANG J., GUIBAS L., Codewebs: Scalable homework search for massive open online programming courses, Proceedings of the 23rd International Conference on World Wide Web, pp. 491-502, (2014); PAASSEN B., GOPFERT C., HAMMER B., Time series prediction for graphs in kernel and dissimilarity spaces, Neural Processing Letters, 48, 2, pp. 669-689, (2018); PAASSEN B., HAMMER B., PRICE T., BARNES T., GROSS S., PINKWART N., The continuous hint factory - providing hints in vast and sparsely populated edit distance spaces, Journal of Educational Data Mining, 10, 1, pp. 1-35, (2018); PAASSEN B., JENSEN J., HAMMER B., Execution traces as a powerful data representation for intelligent tutoring systems for programming, Proceedings of the 9th International Conference on Educational Data Mining, pp. 183-190, (2016); PAASSEN B., KOPRINSKA I., YACEF K., Recursive tree grammar autoencoders, (2021); PASZKE A., GROSS S., MASSA F., LERER A., BRADBURY J., CHANAN G., KILLEEN T., LIN Z., GIMELSHEIN N., ANTIGA L., DESMAISON A., KOPF A., YANG E., DEVITO Z., RAI-SON M., TEJANI A., CHILAMKURTHY S., STEINER B., FANG L., BAI J., CHINTALA S., PyTorch: An imperative style, high-performance deep learning library, Proceedings of the 32nd International Conference on Advances in Neural Information Processing Systems, pp. 8026-8037, (2019); PEARSON K., On lines and planes of closest fit to systems of points in space, The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2, 11, pp. 559-572, (1901); PEDDYCORD B., HICKS A., BARNES T., Generating hints for programming problems using intermediate output, Proceedings of the 7th International Conference on Educational Data Mining, pp. 92-98, (2014); PEKALSKA E., DUIN R., The Dissimilarity Representation for Pattern Recognition: Foundations And Applications (Machine Perception and Artificial Intelligence), (2005); PENNINGTON J., SOCHER R., MANNING C. D., GloVe: Global vectors for word representation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pp. 1532-1543, (2014); PIECH C., HUANG J., NGUYEN A., PHULSUKSOMBATI M., SAHAMI M., GUIBAS L., Learning program embeddings to propagate feedback on student code, Proceedings of the 37th International Conference on Machine Learning, pp. 1093-1102, (2015); PIECH C., SAHAMI M., HUANG J., GUIBAS L., Autonomously generating hints by inferring problem solving policies, Proceedings of the Second ACM Conference on Learning @ Scale, pp. 195-204, (2015); POLITI A., Lyapunov exponent, Scholarpedia, 8, 3, (2013); PRICE T., ZHI R., BARNES T., Evaluation of a data-driven feedback algorithm for open-ended programming, Proceedings of the 10th International Conference on Educational Data Mining, pp. 192-197, (2017); PRICE T. W., DONG Y., ZHI R., PAASSEN B., LYTLE N., CATETE V., BARNES T., A comparison of the quality of data-driven programming hint generation algorithms, International Journal of Artificial Intelligence in Education, 29, 3, pp. 368-395, (2019); QIAN Y., LEHMAN J., Students’ misconceptions and other difficulties in introductory programming: A literature review, ACM Transactions on Computing Education, 18, 1, pp. 1-25, (2017); REDDY S., LABUTOV I., JOACHIMS T., Latent skill embedding for personalized lesson sequence recommendation, (2016); RIVERS K., KOEDINGER K. R., A canonicalizing model for building programming tutors, Proceedings of the 11th International Conference on Intelligent Tutoring Systems, (ITS 2012), pp. 591-593, (2012); RIVERS K., KOEDINGER K. R., Data-driven hint generation in vast solution spaces: a self-improving python programming tutor, International Journal of Artificial Intelligence in Education, 27, 1, pp. 37-64, (2017); ROBINS A., ROUNTREE J., ROUNTREE N., Learning and teaching programming: A review and discussion, Computer Science Education, 13, 2, pp. 137-172, (2003); SCARSELLI F., GORI M., TSOI A. C., HAGENBUCHNER M., MONFARDINI G., The graph neural network model, IEEE Transactions on Neural Networks, 20, 1, pp. 61-80, (2009); TAI K. S., SOCHER R., MANNING C. D., Improved semantic representations from tree-structured long short-term memory networks, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistic, pp. 1556-1566, (2015); TRUONG N., ROE P., BANCROFT P., Static analysis of students’ Java programs, Proceedings of the Sixth Australasian Conference on Computing Education, pp. 317-325, (2004); WILES R., DURRANT G., BROE S. D., POWELL J., Methodological approaches at PhD and skills sought for research posts in academia: A mismatch?, International Journal of Social Research Methodology, 12, 3, pp. 257-269, (2009); ZHANG K., SHASHA D., Simple fast algorithms for the editing distance between trees and related problems, SIAM Journal on Computing, 18, 6, pp. 1245-1262, (1989); ZHI R., PRICE T. W., LYTLE N., DONG Y., BARNES T., Reducing the state space of programming problems through data-driven feature detection, Proceedings of the second Educational Data Mining in Computer Science Education Workshop, (2018); ZIMMERMAN K., RUPAKHETI C. R., An automated framework for recommending program elements to novices (N), Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering (ASE 2015), pp. 283-288, (2015)",,,,,,English,Article,Final,,Scopus,2-s2.0-85132630551,28
Ivanov V.; Romanov V.; Succi G.,"Ivanov, Vladimir (57195101229); Romanov, Vitaly (57206352983); Succi, Giancarlo (7004757466)",57195101229; 57206352983; 7004757466,Predicting Type Annotations for Python using Embeddings from Graph Neural Networks,2021,"International Conference on Enterprise Information Systems, ICEIS - Proceedings",1,,,548,556,8,3,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137946240&partnerID=40&md5=ab98f6d51366117e312176dbdc39bd0f,"An intelligent tool for type annotations in Python would increase the productivity of developers. Python is a dynamic programming language, and predicting types using static analysis is difficult. Existing techniques for type prediction use deep learning models originated in the area of Natural Language Processing. These models depend on the quality of embeddings for source code tokens. We compared approaches for pre-training embeddings for source code. Specifically, we compared FastText embeddings to embeddings trained with Graph Neural Networks (GNN). Our experiments showed that GNN embeddings outperformed FastText embeddings on the task of type prediction. Moreover, they seem to encode complementary information since the prediction quality increases when both types of embeddings are used. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.","Allamanis M., Barr E. T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Computing Surveys (CSUR), 51, 4, pp. 1-37, (2018); Allamanis M., Barr E. T., Ducousso S., Gao Z., Typilus: neural type hints, Proceedings of the 41st acm sigplan conference on programming language design and implementation, pp. 91-105, (2020); Boone C., de Bruin N., Langerak A., Stelmach F., Dltpy: Deep learning type inference of python function signatures using natural language context, (2019); Busbridge D., Sherburn D., Cavallo P., Hammerla N. Y., Relational graph attention networks, (2019); Collobert R., Weston J., Bottou L., Karlen M., Kavukcuoglu K., Kuksa P., Natural language processing (almost) from scratch, Journal of machine learning research, 12, ARTICLE, pp. 2493-2537, (2011); Efstathiou V., Spinellis D., Semantic source code models using identifier embeddings, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), pp. 29-33, (2019); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Codebert: A pre-trained model for programming and natural languages, (2020); Hellendoorn V. J., Bird C., Barr E. T., Allamanis M., Deep learning type inference, Proceedings of the 2018 26th acm joint meeting on european software engineering conference and symposium on the foundations of software engineering, pp. 152-162, (2018); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet challenge: Evaluating the state of semantic code search, (2019); Kanade A., Maniatis P., Balakrishnan G., Shi K., Learning and evaluating contextual embedding of source code, International Conference on Machine Learning, pp. 5110-5121, (2020); Malik R. S., Patra J., Pradel M., Nl2type: inferring javascript function types from natural language information, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 304-315, (2019); Pradel M., Gousios G., Liu J., Chandra S., Typewriter: Neural type prediction with search-based validation, (2019); Raychev V., Bielik P., Vechev M., Probabilistic model for code with decision trees, ACM SIGPLAN Notices, 51, 10, pp. 731-747, (2016); Raychev V., Vechev M., Krause A., Predicting program properties from” big code”, ACM SIGPLAN Notices, 50, 1, pp. 111-124, (2015); Rehurek R., Sojka P., Software Framework for Topic Modelling with Large Corpora, Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks, pp. 45-50, (2010); Romanov V., Evaluating importance of edge types when using graph neural network for predicting return types of python functions, Companion Proceedings of the 2020 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity, pp. 25-27, (2020); Romanov V., Ivanov V., Succi G., Representing programs with dependency and function call graphs for learning hierarchical embeddings, ICEIS, 2, pp. 360-366, (2020); Schlichtkrull M., Kipf T. N., Bloem P., Van Den Berg R., Titov I., Welling M., Modeling relational data with graph convolutional networks, European Semantic Web Conference, pp. 593-607, (2018); Wei J., Goyal M., Durrett G., Dillig I., Lambdanet: Probabilistic type inference using graph neural networks, (2020); Wu Z., Pan S., Chen F., Long G., Zhang C., Philip S. Y., A comprehensive survey on graph neural networks, IEEE transactions on neural networks and learning systems, (2020)","Institute for Systems and Technologies of Information, Control and Communication (INSTICC)","23rd International Conference on Enterprise Information Systems, ICEIS 2021",26 April 2021 through 28 April 2021,"Virtual, Online",180136,English,Conference paper,Final,,Scopus,2-s2.0-85137946240,29
Ramadan T.; Islam T.Z.; Phelps C.; Pinnow N.; Thiagarajan J.J.,"Ramadan, Tarek (57222276871); Islam, Tanzima Z. (57197324531); Phelps, Chase (57222268985); Pinnow, Nathan (57222270156); Thiagarajan, Jayaraman J. (25929725600)",57222276871; 57197324531; 57222268985; 57222270156; 25929725600,Comparative Code Structure Analysis using Deep Learning for Performance Prediction,2021,"Proceedings - 2021 IEEE International Symposium on Performance Analysis of Systems and Software, ISPASS 2021",,,9408199,151,161,10,9,10.1109/ISPASS51385.2021.00032,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105381706&doi=10.1109%2fISPASS51385.2021.00032&partnerID=40&md5=63fe68357a1b32bc8ca94c6f9bdb3311,"Performance analysis has always been an afterthought during the application development process, focusing on application correctness first. The learning curve of the existing static and dynamic analysis tools are steep, which requires understanding low-level details to interpret the findings for actionable optimizations. Additionally, application performance is a function of a number of unknowns stemming from the application-, runtime-, and interactions between the OS and underlying hardware, making it difficult to model using any deep learning technique, especially without a large labeled dataset. In this paper, we address both of these problems by presenting a large corpus of a labeled dataset for the community and take a comparative analysis approach to mitigate all unknowns except their source code differences between different correct implementations of the same problem. We put the power of deep learning to the test for automatically extracting information from the hierarchical structure of abstract syntax trees to represent source code. This paper aims to assess the feasibility of using purely static information (e.g., abstract syntax tree or AST) of applications to predict performance change based on the change in code structure. This research will enable performance-aware application development since every version of the application will continue to contribute to the corpora, which will enhance the performance of the model. We evaluate several deep learning-based representation learning techniques for source code. Our results show that tree-based Long Short-Term Memory (LSTM) models can leverage source code's hierarchical structure to discover latent representations. Specifically, LSTM-based predictive models built using a single problem and a combination of multiple problems can correctly predict if a source code will perform better or worse up to 84% and 73% of the time, respectively.  © 2021 IEEE.","Codeforces: Online Programming Competition; Contest 1027C-Military Problem; Contest 1027C-Minimum Value Rectangle; Contest 914D-Bash and a Tough Math Puzzle; Contest 4C-Registration; Contest 230B-TPrime; Akiba T., Sano S., Yanase T., Ohta T., Koyama M., Optuna: A next-generation hyperparameter optimization framework, Proceedings of the 25th Acm Sigkdd International Conference on Knowledge Discovery & Data Mining, pp. 2623-2631, (2019); Alsulami B., Dauber E., Harang R., Mancoridis S., Greenstadt R., Source code authorship attribution using long short-term memory based networks, European Symposium on Research in Computer Security, pp. 65-82, (2017); Canavera K.R., Esfahani N., Malek S., Mining the execution history of a software system to infer the best time for its adaptation, Proceedings of the Acm Sigsoft 20th International Symposium on the Foundations of Software Engineering, (2012); Cummins C., Petoumenos P., Wang Z., Leather H., End-to-end deep learning of optimization heuristics, 2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT), pp. 219-232, (2017); Dam H.K., Pham T., Ng S.W., Tran T., Grundy J., Ghose A., Kim T., Kim C.-J., A Deep Tree-based Model for Software Defect Prediction, (2018); Eriguchi A., Hashimoto K., Tsuruoka Y., Tree-to-sequence Attentional Neural Machine Translation, (2016); Graves A., Schmidhuber J., Framewise phoneme classification with bidirectional lstm and other neural network architectures, Neural Networks, 18, 5-6, pp. 602-610, (2005); Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P., On the naturalness of software, 2012 34th International Conference on Software Engineering (ICSE), pp. 837-847, (2012); Kalchbrenner N., Grefenstette E., Blunsom P., A Convolutional Neural Network for Modelling Sentences, (2014); Kipf T.N., Welling M., Semi-supervised Classification with Graph Convolutional Networks, (2016); Lu H., Cukic B., Culp M., Software defect prediction using semi-supervised learning with dimension reduction, Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering, pp. 314-317, (2012); Maaten L.V.D., Hinton G., Visualizing data using t-sne, Journal of Machine Learning Research, 9, pp. 2579-2605, (2008); Meng K., Norris B., Mira: A Framework for Static Performance Analysis, (2017); Meng K., Norris B., Mira: A framework for static performance analysis, 2017 Ieee International Conference on Cluster Computing (CLUSTER), pp. 103-113, (2017); Mikolov T., Chen K., Corrado G., Dean J., Efficient Estimation of Word Representations in Vector Space, (2013); Mou L., Li G., Jin Z., Zhang L., Wang T., TBCNN: A Tree-based Convolutional Neural Network for Programming Language Processing, (2014); Mou L., Li G., Liu Y., Peng H., Jin Z., Xu Y., Zhang L., Building Program Vector Representations for Deep Learning, (2014); Narayanan S.H.K., Norris B., Hovland P.D., Generating performance bounds from source code, 2010 39th International Conference on Parallel Processing Workshops, pp. 197-206, (2010); Neamtiu I., Foster J.S., Hicks M., Understanding source code evolution using abstract syntax tree matching, Acm Sigsoft Software Engineering Notes, 30, 4, pp. 1-5, (2005); Pascanu R., Mikolov T., Bengio Y., On the difficulty of training recurrent neural networks, International Conference on Machine Learning, pp. 1310-1318, (2013); Pennington J., Socher R., Manning C.D., Glove: Global vectors for word representation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1532-1543, (2014); Perozzi B., Al-Rfou R., Skiena S., Deepwalk: Online learning of social representations, Kdd, (2014); Qin H., Sun X., Classifying bug reports into bugs and non-bugs using lstm, Proceedings of the Tenth Asia-Pacific Symposium on Internetware, Internetware '18, (2018); Quinlan D., Liao C., The rose sourceto-source compiler infrastructure, Cetus Users and Compiler Infrastructure Workshop, (2011); Schlichtkrull M., Kipf T.N., Bloem P., Berg R.V.D., Titov I., Welling M., Modeling relational data with graph convolutional networks, European Semantic Web Conference, pp. 593-607, (2018); Shido Y., Kobayashi Y., Yamamoto A., Miyamoto A., Matsumura T., Automatic Source Code Summarization with Extended Treelstm, (2019); Sundermeyer M., Schluter R., Ney H., Lstm neural networks for language modeling, Thirteenth Annual Conference of the International Speech Communication Association, (2012); Tai K.S., Socher R., Manning C.D., Improved semantic representations from treestructured long short-term memory networks, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, 1, pp. 1556-1566, (2015); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P.S., Multi-modal Attention Network Learning for Semantic Source Code Retrieval, (2019); Wang X., Ji H., Shi C., Wang B., Ye Y., Cui P., Yu P.S., Heterogeneous graph attention network, The World Wide Web Conference, pp. 2022-2032, (2019); Williams R.J., Zipser D., A learning algorithm for continually running fully recurrent neural networks, Neural Computation, 1, 2, pp. 270-280, (1989)",et al.; FutureWei; IEEE Computer Society; IMO Ventures; Intel; Qualcomm,"2021 IEEE International Symposium on Performance Analysis of Systems and Software, ISPASS 2021",28 March 2021 through 30 March 2021,"Virtual, Stony Brook",168654,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85105381706,30
Wang W.; Li G.; Shen S.; Xia X.; Jin Z.,"Wang, Wenhan (57216463961); Li, Ge (55901136600); Shen, Sijie (57218547707); Xia, Xin (54586248800); Jin, Zhi (8961795500)",57216463961; 55901136600; 57218547707; 54586248800; 8961795500,Modular Tree Network for Source Code Representation Learning,2020,ACM Transactions on Software Engineering and Methodology,29,4,3409331,,,,30,10.1145/3409331,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092714268&doi=10.1145%2f3409331&partnerID=40&md5=d905cdf7f3fff0be2096f74ffa0ca9ba,"Learning representation for source code is a foundation of many program analysis tasks. In recent years, neural networks have already shown success in this area, but most existing models did not make full use of the unique structural information of programs. Although abstract syntax tree (AST)-based neural models can handle the tree structure in the source code, they cannot capture the richness of different types of substructure in programs. In this article, we propose a modular tree network that dynamically composes different neural network units into tree structures based on the input AST. Different from previous tree-structural neural network models, a modular tree network can capture the semantic differences between types of AST substructures. We evaluate our model on two tasks: program classification and code clone detection. Our model achieves the best performance compared with state-of-the-art approaches in both tasks, showing the advantage of leveraging more elaborate structure information of the source code.  © 2020 ACM.","Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, Acm Computing Surveys, 51, 4, (2018); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, Proceedings of the International Conference on Learning Representations (ICLR'18), (2018); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, Proceedings of the International Conference on Machine Learning., pp. 2091-2100, (2016); Alon U., Levy O., Yahav E., Code2seq: Generating Sequences from Structured Representations of Code, (2018); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proceedings of the Acm on Programming Languages, 3, (2019); Arabshahi F., Singh S., Anandkumar A., Combining symbolic expressions and blackbox function evaluations in neural programs, Proceedings of the International Conference on Learning Representations (ICLR'18), (2018); Ben-Nun T., Shoshana Jakobovits A., Hoefler T., Neural Code Comprehension: A Learnable Representation of Code Semantics, (2018); Bhoopchand A., Rocktaschel T., Barr E., Riedel S., Learning Python Code Suggestion with a Sparse Pointer Network, (2016); Brockschmidt M., Allamanis M., Gaunt A.L., Polozov O., Generative code modeling with graphs, Proceedings of the 7th International Conference on Learning Representations (ICLR'19), (2019); Dong L., Wei F., Tan C., Tang D., Zhou M., Xu K., Adaptive recursive neural network for target-dependent twitter sentiment classification, Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)., pp. 49-54, (2014); Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P., On the naturalness of software, Proceedings of the 2012 34th International Conference on Software Engineering (ICSE'12), pp. 837-847, (2012); Hinton G.E., Osindero S., Teh Y., A fast learning algorithm for deep belief nets, Neural Computation, 18, 7, pp. 1527-1554, (2006); Hochreiter S., Schmidhuber J., Long short-Termmemory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Huo X., Li M., Enhancing the unified features to locate buggy files by exploiting the sequential nature of source code, Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI'17)., pp. 1909-1915, (2017); Huo X., Li M., Zhou Z., Learning unified features from natural and programming languages for locating buggy source code, Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI'16)., pp. 1606-1612, (2016); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)., pp. 2073-2083, (2016); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate treebased detection of code clones, Proceedings of the 29th International Conference on Software Engineering, pp. 96-105, (2007); Kim Y., Convolutional neural networks for sentence classification, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP'14)., pp. 1746-1751, (2014); Kingma D.P., Lei Ba J., Adam: A method for stochastic optimization, Proceedings of the International Conference on Learning Representations (ICLR'15), 5, (2015); Li J., Wang Y., King I., Lyu M.R., Code completion with neural attention and pointer networks, Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI'18)., pp. 4159-4165, (2018); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, Proceedings of the International Conference on Learning Representations (ICLR'16), (2016); Liang Y., Zhu K., Automatic generation of text descriptive comments for code blocks, Proceedings of the Aaai Conference on Artificial Intelligence, (2018); Liu P., Qiu X., Huang X., Dynamic compositional neural networks over tree structure, Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI'17)., pp. 4054-4060, (2017); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Proceedings of the 30th Aaai Conference on Artificial Intelligence, 2, (2016); Neubig G., Goldberg Y., Dyer C., On-The-fly operation batching in dynamic computation graphs, Advances in Neural Information Processing Systems., pp. 3971-3981, (2017); Roy C.K., Cordy J.R., A survey on software clone detection research, Queen's School of Computing Tr, 541, 115, pp. 64-68, (2007); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., Sourcerercc: Scaling code clone detection to big-code, Proceedings of the 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE'16), pp. 1157-1168, (2016); Socher R., Bauer J., Manning C.D., Ng A.Y., Parsing with compositional vector grammars, Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)., pp. 455-465, (2013); Socher R., Lin C.C., Manning C., Ng A.Y., Parsing natural scenes and natural language with recursive neural networks, Proceedings of the 28th International Conference on Machine Learning (ICML'11)., pp. 129-136, (2011); Svajlenko J., Islam J.F., Keivanloo I., Roy C.K., Mamun Mia M., Towards a big data curated benchmark of inter-project code clones, Proceedings of the 2014 Ieee International Conference on Software Maintenance and Evolution, pp. 476-480, (2014); Sheng Tai K., Socher R., Manning C.D., Improved semantic representations from treestructured long short-Term memory networks, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)., pp. 1556-1566, (2015); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, Proceedings of the 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE'16), pp. 297-308, (2016); Wei H., Li M., Positive and unlabeled learning for detecting software functional clones with adversarial training, Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI'18)., pp. 2840-2846, (2018); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI'17)., pp. 3034-3040, (2017); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, pp. 87-98, (2016); Wilcoxon F., Wilcox R.A., Some Rapid Approximate Statistical Procedures, (1964); Yang X., Lo D., Xia X., Zhang Y., Sun J., Deep learning for just-in-Time defect prediction, Proceedings of the 2015 Ieee International Conference on Software Quality, Reliability, and Security (QRS'64)., pp. 17-26, (2015); Yuan Z., Lu Y., Wang Z., Xue Y., Droid-sec: Deep learning in android malware detection, Acm Sigcomm Computer Communication Review, 44, pp. 371-372, (2014)",,,,,,English,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85092714268,32
Ye G.; Tang Z.; Wang H.; Fang D.; Fang J.; Huang S.; Wang Z.,"Ye, Guixin (57193613039); Tang, Zhanyong (15822992800); Wang, Huanting (57213424982); Fang, Dingyi (8975043000); Fang, Jianbin (53984066400); Huang, Songfang (56349908000); Wang, Zheng (35111811300)",57193613039; 15822992800; 57213424982; 8975043000; 53984066400; 56349908000; 35111811300,Deep program structure modeling through multi-relational graph-based learning,2020,"Parallel Architectures and Compilation Techniques - Conference Proceedings, PACT",,,,111,123,12,22,10.1145/3410463.3414670,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094208858&doi=10.1145%2f3410463.3414670&partnerID=40&md5=7e53d7f68569e46dadc23171ed2dae04,"Deep learning is emerging as a promising technique for buildingpredictive models to support code-related tasks like performanceoptimization and code vulnerability detection. One of the criticalaspects of building a successful predictive model is having theright representation to characterize the model input for the giventask. Existing approaches in the area typically treat the programstructure as a sequential sequence but fail to capitalize on the richsemantics of data and control flow information, for which graphsare a proven representation structure.We present Poem1, a novel framework that automatically learnsuseful code representations from graph-based program structures.At the core of Poem is a graph neural network (GNN) that is specially designed for capturing the syntax and semantic informationfrom the program abstract syntax tree and the control and dataflow graph. As a departure from existing GNN-based code modeling techniques, our network simultaneously learns over multiplerelations of a program graph. This capability enables the learningframework to distinguish and reason about the diverse code relationships, be it a data or a control flow or any other relationshipsthat may be important for the downstream processing task.We apply Poem to four representative tasks that require a strongability to reason about the program structure: heterogeneous devicemapping, parallel thread coarsening, loop vectorization and codevulnerability detection. We evaluate Poem on programs written inOpenCL, C, Java and Swift, and compare it against nine learningbased methods. Experimental results show that Poem consistentlyoutperforms all competing methods across evaluation settings.  © 2020 Association for Computing Machinery.","ANTLR (ANother Tool for Language Recognition; Clang: A Language Front-end and Tooling Infrastructure; LLVM: A Collection of Modular and Reusable Compiler and Toolchain Technologies; Neural Network Intelligence; Soot: A Framework for Analyzing and Transforming Java Applications; Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Computing Surveys (CSUR), 51, 4, pp. 1-37, (2018); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, ICLR, (2018); Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating sequences from structured representations of code, ICLR, (2019); Ansel J., Chan C., Lok Wong Y., Olszewski M., Zhao Q., Edelman A., Amarasinghe S., Petabricks: A language and compiler for algorithmic choice, ACM Sigplan Notices, 44, 6, pp. 38-49, (2009); Ashouri A.H., Killian W., Cavazos J., Palermo G., Silvano C., A survey on compiler autotuning using machine learning, ACM Computing Surveys (CSUR), 51, 5, pp. 1-42, (2018); Barchi F., Urgese G., Macii E., Acquaviva A., Code mapping in heterogeneous platforms using deep learning and llvm-ir, 2019 56th ACM/IEEE Design Automation Conference (DAC), pp. 1-6, (2019); Ben-Nun T., Shoshana Jakobovits A., Hoefler T., Neural code comprehension: A learnable representation of code semantics, Advances in Neural Information Processing Systems, pp. 3585-3597, (2018); Brauckmann A., Goens A., Ertel S., Castrillon J., Compiler-based graph representations for deep learning models of code, Proceedings of the 29th International Conference on Compiler Construction (CC 2020), (2020); Chen T., Moreau T., Jiang Z., Zheng L., Yan E., Shen H., Cowan M., Wang L., Hu Y., Ceze L., Et al., {tvm}: An automated end-to-end optimizing compiler for deep learning, 13th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 18), pp. 578-594, (2018); Chen T., Zheng L., Yan E., Jiang Z., Moreau T., Ceze L., Guestrin C., Krishnamurthy A., Learning to optimize tensor programs, Advances in Neural Information Processing Systems, pp. 3389-3400, (2018); Chen X., Liu C., Song D., Tree-to-tree neural networks for program translation, Advances in Neural Information Processing Systems, pp. 2547-2557, (2018); Chung J., Gulcehre C., Cho K., Bengio Y., Empirical evaluation of gated recurrent neural networks on sequence modeling, NIPS 2014 Workshop on Deep Learning, (2014); Cummins C., Fisches Z.V., Ben-Nun T., Hoefler T., Leather H., ProGraML: Graph-based Deep Learning for Program Optimization and Analysis, (2020); Cummins C., Petoumenos P., Murray A., Leather H., Compiler fuzzing through deep learning, Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 95-105, (2018); Cummins C., Petoumenos P., Wang Z., Leather H., Endto-end deep learning of optimization heuristics, 26th International Conference on Parallel Architectures and Compilation Techniques (PACT), (2017); Cummins C., Petoumenos P., Wang Z., Leather H., Synthesizing benchmarks for predictive modeling, 2017 IEEE/ACMInternational Symposium on Code Generation and Optimization (CGO), pp. 86-99, (2017); Defferrard M., Bresson X., Vandergheynst P., Convolutional neural networks on graphs with fast localized spectral filtering, Advances in Neural Information Processing Systems., pp. 3844-3852, (2016); Delimitrou C., Kozyrakis C., Quasar: Resource-efficient and qos-aware cluster management, ACM SIGPLAN Notices, 49, 4, pp. 127-144, (2014); Ding Y., Ansel J., Veeramachaneni K., Shen X., O'Reilly U., Amarasinghe S., Autotuning algorithmic choice for input sensitivity, Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 379-390, (2015); Krishna Emani M., Wang Z., O'Boyle M.F.P., Smart, adaptive mapping of parallelism in the presence of external workload, Proceedings of the 2013 IEEE/ACM International Symposium on Code Generation and Optimization (CGO), pp. 1-10, (2013); 2019 CWE Top 25 Most Dangerous Software Errors, (2019); Ertel W., On the definition of speedup, Proceedings of the International Conference on Parallel Architectures and Languages Europe, pp. 289-300, (1994); Girshick R., Donahue J., Darrell T., Malik J., Rich feature hierarchies for accurate object detection and semantic segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 580-587, (2014); Grauer-Gray S., Xu L., Searles R., Ayalasomayajula S., Cavazos J., Auto-tuning A High-Level Language Targeted to GPU Codes, (2012); Grewe D., Wang Z., O'Boyle M.F.P., Portable mapping of data parallel programs to opencl for heterogeneous systems, Proceedings of the 2013 IEEE/ACM International Symposium on Code Generation and Optimization (CGO), pp. 1-10, (2013); Grosser T., Et al., Polly-performing polyhedral optimizations on a low-level intermediate representation, Parallel Processing Letters, (2012); Guthaus M.R., Ringenberg J.S., Ernst D., Austin T.M., Mudge T., Brown R.B., Mibench: A free, commercially representative embedded benchmark suite, Proceedings of the Fourth Annual IEEE International Workshop on Workload Characterization. WWC-4 (Cat. No. 01EX538). IEEE, pp. 3-14, (2001); Haj-Ali A., Ahmed N.K., Willke T., Sophia Shao Y., Asanovic K., Stoica I., Neurovectorizer: End-to-end vectorization with deep reinforcement learning, Proceedings of the 18th ACM/IEEE International Symposium on Code Generation and Optimization, pp. 242-255, (2020); Hamilton W., Ying Z., Leskovec J., Inductive representation learning on large graphs, Advances in Neural Information Processing Systems, pp. 1024-1034, (2017); Hochreiter S., Schmidhuber J., Long short-term memory, Proceedings of the Neural Computation, 9, 8, pp. 1735-1780, (1997); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proceedings of the 26th Conference on Program Comprehension, pp. 200-210, (2018); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, (2014); Leather H., Bonilla E., O'Boyle M., Automatic feature generation for machine learning based optimizing compilation, 2009 International Symposium on Code Generation and Optimization, pp. 81-91, (2009); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, (2015); Lin G., Zhang J., Luo W., Pan L., De Vel O., Montague P., Xiang Y., Software vulnerability discovery via learning multi-domain knowledge bases, IEEE Transactions on Dependable and Secure Computing, (2019); Van Der Maaten L., Hinton G., Visualizing data using t-sne, Journal of Machine Learning Research, 9, pp. 2579-2605, (2008); Magni A., Dubach C., O'Boyle M., Automatic optimization of thread-coarsening for graphics processors, Proceedings of the 23rd International Conference on Parallel Architectures and Compilation Techniques, pp. 455-466, (2014); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in Neural Information Processing Systems, pp. 3111-3119, (2013); Namolaru M., Cohen A., Fursin G., Zaks A., Freund A., Practical aggregation of semantical program properties for machine learning based optimization, Proceedings of the 2010 International Conference on Compilers, Architectures and Synthesis for Embedded Systems, pp. 197-206, (2010); Nuzman D., Rosen I., Zaks A., Auto-vectorization of interleaved data for simd, ACM SIGPLAN Notices, 41, 6, pp. 132-143, (2006); Ogilvie W.F., Petoumenos P., Wang Z., Leather H., Minimizing the cost of iterative compilation with active learning, 2017 IEEE/ACM International Symposium on Code Generation and Optimization (CGO), pp. 245-256, (2017); Park E., Cavazos J., Alvarez M.A., Using graph-based program characterization for predictive modeling, Proceedings of the Tenth International Symposium on Code Generation and Optimization, pp. 196-206, (2012); Ren J., Gao L., Wang H., Wang Z., Optimise web browsing on heterogeneous mobile platforms: A machine learning based approach, IEEE INFOCOM 2017-IEEE Conference on Computer Communications. IEEE, pp. 1-9, (2017); Tulio Ribeiro M., Singh S., Guestrin C., Why should i trust you? Explaining the predictions of any classifier, Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1135-1144, (2016); Schlichtkrull M., Kipf T.N., Bloem P., Van Den Berg R., Titov I., Welling M., Modeling relational data with graph convolutional networks, European Semantic Web Conference, (2018); Tournavitis G., Wang Z., Franke B., O'Boyle M.F.P., Towards a holistic approach to auto-parallelization: Integrating profile-driven parallelism detection and machine-learning based mapping, Proceedings of the 30th ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 177-187, (2009); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph Attention Networks, (2017); Wang Z., Grewe D., O'Boyle M.F.P., Automatic and portable mapping of data parallel programs to opencl for GPU-based heterogeneous systems, ACM Transactions on Architecture and Code Optimization (TACO), 11, 4, pp. 1-26, (2014); Wang Z., O'Boyle M., Machine learning in compiler optimization, Proc. IEEE, 106, 11, pp. 1879-1901, (2018); Wang Z., O'Boyle M.F.P., Mapping parallelism to multi-cores: A machine learning based approach, Proceedings of the 14th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, pp. 75-84, (2009); Wang Z., O'Boyle M.F.P., Partitioning streaming parallelism for multi-cores: A machine learning based approach, Proceedings of the 19th International Conference on Parallel Architectures and Compilation Techniques, pp. 307-318, (2010); Wu Y., Liu X., Feng Y., Wang Z., Yan R., Zhao D., Relation-aware entity alignment for heterogeneous knowledge graphs, Proceedings of the 28th International Joint Conference on Artificial Intelligence, pp. 5278-5284, (2019); Xu K., Hu W., Leskovec J., Jegelka S., How Powerful Are Graph Neural Networks?, (2018); Xu X., Liu C., Feng Q., Yin H., Song L., Song D., Neural network-based graph embedding for cross-platform binary code similarity detection, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 363-376, (2017); Yosinski J., Clune J., Bengio Y., Lipson H., How transferable are features in deep neural networks?, Advances in Neural Information Processing Systems, pp. 3320-3328, (2014); Yu Y., Chen J., Gao T., Yu M., Dag-gnn: Dag structure learning with graph neural networks, Proceedings of the 36th International Conference on Machine Learning, (2019); Zhang P., Fang J., Tang T., Yang C., Wang Z., Auto-tuning streamed applications on intel xeon phi, 2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS), pp. 515-525, (2018); Zhang P., Fang J., Yang C., Huang C., Tang T., Wang Z., Optimizing streaming parallelism on heterogeneous many-core architectures, IEEE Transactions on Parallel and Distributed Systems, 31, 8, pp. 1878-1896, (2020); Zhang Z., Sabuncu M., Generalized cross entropy loss for training deep neural networks with noisy labels, Proceedings of the Advances in Neural Information Processing Systems, pp. 8778-8788, (2018); Zhao Y., Li J., Liao C., Shen X., Bridging the gap between deep learning and sparse matrix format selection, Proceedings of the 23rd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, pp. 94-108, (2018); Zou D., Wang S., Xu S., Li Z., Jin H., Vuldeepecker: A deep learning-based system for multiclass vulnerability detection, IEEE Transactions on Dependable and Secure Computing, (2019)",ACM SIGARCH; IEEE Computer Society; ifip,"2020 ACM International Conference on Parallel Architectures and Compilation Techniques, PACT 2020",3 October 2020 through 7 October 2020,"Virtual, Online",163544,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85094208858,33
Richter C.; Hüllermeier E.; Jakobs M.-C.; Wehrheim H.,"Richter, Cedric (57208495733); Hüllermeier, Eyke (6701552637); Jakobs, Marie-Christine (56352518800); Wehrheim, Heike (6603094619)",57208495733; 6701552637; 56352518800; 6603094619,Algorithm selection for software validation based on graph kernels,2020,Automated Software Engineering,27,1-2,,153,186,33,25,10.1007/s10515-020-00270-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083878337&doi=10.1007%2fs10515-020-00270-x&partnerID=40&md5=cf9df51fce68c365deb53d95201ca5b3,"Algorithm selection is the task of choosing an algorithm from a given set of candidate algorithms when faced with a particular problem instance. Algorithm selection via machine learning (ML) has recently been successfully applied for various problem classes, including computationally hard problems such as SAT. In this paper, we study algorithm selection for software validation, i.e., the task of choosing a software validation tool for a given validation instance. A validation instance consists of a program plus properties to be checked on it. The application of machine learning techniques to this task first of all requires an appropriate representation of software. To this end,we propose a dedicated kernel function, which compares two programs in terms of their similarity, thus making the algorithm selection task amenable to kernel-based machine learning methods. Our kernel operates on a graph representation of source code mixing elements of control-flow and program-dependence graphs with abstract syntax trees.Thus, given two such representations as input, the kernel function yields a real-valued score that can be interpreted as a degree of similarity. We experimentally evaluate our kernel in two learning scenarios, namely a classification and a ranking problem: (1) selecting between a verification and a testing tool for bug finding (i.e., property violation), and (2) ranking several verification tools,from presumably best to worst, for property proving. The evaluation, which is based on data sets from the annual software verification competition SV-COMP, demonstrates our kernel to generalize well and to achieve rather high prediction accuracy, both for the classification and the ranking task. © 2020, The Author(s).","Albarghouthi A., Li Y., Gurfinkel A., Chechik M., Ufo: A framework for abstraction- and interpolation-based software verification, CAV, LNCS, 7358, pp. 672-678, (2012); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, Corr, (2017); Allamanis M., Barr E.T., Devanbu P.T., Sutton C.A., A survey of machine learning for big code and naturalness, ACM Comput. Surv., 51, 4, pp. 81:1-81:37, (2018); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, Proc. PLDI, pp. 404-419, (2018); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: learning distributed representations of code, PACMPL, 3, POPL, pp. 40:1-40:29, (2019); Amerise I.L., Tarsitano A., Correction methods for ties in rank correlations, J. Appl. Stat., 42, 12, pp. 2584-2596, (2015); Apel S., Beyer D., Friedberger K., Raimondi F., von Rhein A., Domain types: Abstract-domain selection based on variable usage, HVC, LNCS, 8244, pp. 262-278, (2013); Beyer D., Dangl M., Strategy selection for software verification based on boolean features—a simple but effective approach, Isola, LNCS, 11245, pp. 144-159, (2018); Beyer D., Keremogluachecker M.E.C.P., : A Tool for Configurable Software Verification, CAV, LNCS, 6806, pp. 184-190, (2011); Beyer D., Lemberger T., Software verification: Testing versus model checking—a comparative evaluation of the state of the art, HVC, LNCS, 10629, pp. 99-114, (2017); Beyer D., Lowe S., Wendler P., Refinement selection, SPIN, LNCS, 9232, pp. 20-38, (2015); Beyer D., Lowe S., Wendler P., Reliable benchmarking: Requirements and solutions, Int. J. Softw Tools Technol. Transf., pp. 1-29, (2017); Beyer D., Software verification with validation of results—(Report on SV-COMP 2017, TACAS, LNCS, 10206, pp. 331-349, (2017); Bischl B., Kerschke P., Kotthoff L., Lindauer M.T., Malitsky Y., Frechette A., Hoos H.H., Hutter F., Leyton-Brown K., Tierney K., Vanschoren J., ASlib: a benchmark library for algorithm selection, Artif. Intell., 237, pp. 41-58, (2016); Borgwardt K., Kriegel H., Shortest-path kernels on graphs, ICDM, pp. 74-81, (2005); Boser B.E., Guyon I., Vapnik V., A training algorithm for optimal margin classifiers, COLT, pp. 144-152, (1992); Cadar C., Dunbar D., Engler D.R., KLEE: Unassisted and automatic generation of high-coverage tests for complex systems programs, USENIX, pp. 209-224, (2008); Chalupa M., Vitovska M., Jonas M., Slaby J., Strejcek J., Symbiotic 4: Beyond reachability—(competition contribution), TACAS, LNCS, 10206, pp. 385-389, (2017); Chen Y., Hsieh C., Lengal O., Lii T., Tsai M., Wang B., Wang F., PAC learning-based verification and model synthesis, ICSE, pp. 714-724, (2016); Czech M., Hullermeier E., Jakobs M.-C., Wehrheim H., Predicting rankings of software verification tools, SWAN@ESEC/SIGSOFT FSE, pp. 23-26, (2017); de Borda J.C., Mémoire sur les élections au scrutin, Mémoire de l’Académie Royale, Histoire De lÁcademie Royale Des Sciences, pp. 657-665, (1781); Demyanova Y., Pani T., Veith H., Zuleger F., Empirical software metrics for benchmarking of verification tools, CAV, LNCS, Vol. 9206, pp. 561-579, (2015); Demyanova Y., Pani T., Veith H., Zuleger F., Empirical software metrics for benchmarking of verification tools, Formal Methods Syst. Des., 50, 2-3, pp. 289-316, (2017); Furnkranz J., Round robin classification, J. Mach. Learn. Res., 2, pp. 721-747, (2002); Gadelha M.Y.R., Monteiro F.R., Morse J., Cordeiro L.C., Fischer B., Nicole D.A., ESBMC 5.0: An industrial-strength C model checker. In, ASE, pp. 888-891, (2018); Gamma E., Helm R., Johnson R., Vlissides J., Design patterns: elements of reusable object-oriented software, (1995); Gartner T., Flach P.A., Wrobel S., On graph kernels: Hardness results and efficient alternatives, Colt/Kernel, LNCS, 2777, pp. 129-143, (2003); Gartner T., Kernels for structured data, (2008); Greitschus M., Dietsch D., Heizmann M., Nutz A., Schatzle C., Schilling C., Schussele F., Podelski A., Ultimate Taipan: Trace abstraction and abstract interpretation, TACAS, LNCS, 10206, pp. 399-403, (2017); Gunther H., Weissenbacher G., Incremental bounded software model checking, SPIN, pp. 40-47, (2014); Gurfinkel A., Kahsai T., Komuravelli A., Navas J.A., The SeaHorn verification framework, CAV, LNCS, 9206, pp. 343-361, (2015); Habib A., Pradel M., Is this class thread-safe? Inferring documentation using graph-based learning, ASE, pp. 41-52, (2018); Hamilton W., Ying Z., Leskovec J., Inductive representation learning on large graphs, NIPS, pp. 1024-1034, (2017); Heizmann M., Hoenicke J., Podelski A., Software model checking for people who love automata, CAV, LNCS, 8044, pp. 36-52, (2013); Helmert M., Roger G., Seipp J., Karpas E., Hoffmann J., Keyder E., Nissim R., Richter S., Westphal M., Fast Downward Stone Soup, pp. 28-35, (2011); Horwitz S., Reps T.W., The use of program dependence graphs in software engineering, ICSE, pp. 392-411, (1992); Hullermeier E., Furnkranz J., On predictive accuracy and risk minimization in pairwise label ranking, J. Comput. Syst. Sci., 76, 1, pp. 49-62, (2010); Hullermeier E., Furnkranz J., Cheng W., Brinker K., Label ranking by learning pairwise preferences, Artif. Intell., 172, pp. 1897-1917, (2008); Kashima H., Tsuda K., Inokuchi A., Marginalized kernels between labeled graphs, ICML, pp. 321-328, (2003); Kondor R., Lafferty J.D., Diffusion kernels on graphs and other discrete structures, ICML, pp. 315-322, (2002); Kotthoff L., Gent I.P., Miguel I., An evaluation of machine learning in algorithm selection for search problems, AI Commun., 25, 3, pp. 257-270, (2012); Kroening D., Tautschnig M., CBMC–C bounded model checker, TACAS, LNCS, 8413, pp. 389-391, (2014); Lau T., Programming by Demonstration: A Machine Learning Approach, (2001); Le T.B., Lo D., Le Goues C., Grunske L., A learning-to-rank based fault localization approach using likely invariants, ISSTA, pp. 177-188, (2016); Li W., Saidi H., Sanchez H., Schaf M., Schweitzer P., Detecting similar programs via the Weisfeiler-Leman graph kernel, ICSR, LNCS, 9679, pp. 315-330, (2016); McTear M., Callejas Z., Griol D., The conversational interface, 694, (2016); Nutz A., Dietsch D., Mohamed M.M., Podelski A., ULTIMATE KOJAK with memory safety checks, TACAS, LNCS, 9035, pp. 458-460, (2015); Pielou E.C., The interpretation of ecological data: a primer on classification and ordination, (1984); Platt J., Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods, Advances in Large Margin Classifiers, pp. 6-74, (1999); Pradel M., Sen K., DeepBugs: a learning approach to name-based bug detection, Proc. ACM Program. Lang., 2, OOPSLA, pp. 147:1-147:25, (2018); Rakamaric Z., Emmi M., SMACK: Decoupling source language details from verifier implementations, CAV, LNCS, 8559, pp. 106-113, (2014); Ralaivola L., Swamidass S.J., Saigo H., Baldi P., Graph kernels for chemical informatics, Neural Netw., 18, 8, pp. 1093-1110, (2005); Raychev V., Bielik P., Vechev M.T., Krause A., Learning programs from noisy data, POPL, pp. 761-774, (2016); Raychev V., Vechev M.T., Krause A., Predicting program properties from big code, In: POPL, pp. 111-124, (2015); Rice J., The algorithm selection problem, Adv. Comput., 15, pp. 65-118, (1976); Richter C., Wehrheim H., PeSCo: Predicting sequential combinations of verifiers (competition contribution), TACAS, LNCS, 11429, pp. 229-233, (2019); Rocha W., Rocha H., Ismail H., Cordeiro L., Fischer B., DepthK: A k-induction verifier based on invariant inference for C programs, TACAS, LNCS, 10206, pp. 360-364, (2017); Sahs J., Khan L., A machine learning approach to android malware detection, EISIC, pp. 141-147, (2012); Scholkopf B., Smola A., Learning with Kernels: support vector machines, regularization, optimization, and beyond, (2001); Schrammel P., Kroening, D.: 2LS for program analysis, TACAS, LNCS, 9636, pp. 905-907, (2016); Shawe-Taylor J., Cristianini N., Kernel methods for pattern analysis, (2004); Shervashidze N., Schweitzer P., van Leeuwen E.J., Mehlhorn K., Borgwardt K.M., Weisfeiler–Lehman graph kernels, J. Mach. Learn. Res., 12, pp. 2539-2561, (2011); Spearman C., The proof and measurement of association between two things, Am. J. Psychol., 15, pp. 72-101, (1904); Tulsian V., Kanade A., Kumar R., Lal A., Nori A.V., MUX: Algorithm selection for software model checkers, MSR, pp. 132-141, (2014); Vembu S., Gartner T., Label ranking algorithms: A survey, Preference Learning, pp. 45-64, (2010); Wagner C., Wagener G., State R., Engel T., Malware analysis with graph kernels and support vector machines, MALWARE, pp. 63-68, (2009); Weisfeiler B., Lehman A., A reduction of a graph to a canonical form and an algebra arising during this reduction, Nauchno Technicheskaya Informatsia, 2, 9, pp. 12-19, (1968); Wendler P., CPAchecker with sequential combination of explicit-state analysis and predicate analysis—(Competition Contribution), TACAS, LNCS, 7795, pp. 613-615, (2013); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A comprehensive survey on graph neural networks, Corr, (2019); Xu K., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks?, ICLR 2019. Openreview.Net, (2019); Xu L., Hutter F., Hoos H.H., Leyton-Brown K., Satzilla: Portfolio-based algorithm selection for SAT, J. Artif. Intell. Res., 32, pp. 565-606, (2008); Yefet N., Alon U., Yahav E., Adversarial examples for models of code, Corr, (2019)",,,,,,English,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85083878337,34
Rodrigues G.E.D.P.; Braga A.M.; Dahab R.,"Rodrigues, Gustavo Eloi De P. (57205624942); Braga, Alexandre M. (55492898000); Dahab, Ricardo (16232535600)",57205624942; 55492898000; 16232535600,Using Graph Embeddings and Machine Learning to Detect Cryptography Misuse in Source Code,2020,"Proceedings - 19th IEEE International Conference on Machine Learning and Applications, ICMLA 2020",,,9356194,1059,1066,7,4,10.1109/ICMLA51294.2020.00171,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102530771&doi=10.1109%2fICMLA51294.2020.00171&partnerID=40&md5=25e315d337ac391c396b4291e7741021,"Cryptography is an essential aspect of software development. Nevertheless, software developers have limited knowledge of cryptography primitives, and support tools are limited. In this work, we present a comparison between graph embedding techniques, node2vec and Bag of Graphs, as embedding generators of source code graph representations. We combined these techniques with machine learning models in order to detect cryptography misuses in source codes. We show that Bag of Graphs outperforms node2vec in this task; also, both techniques outperform previously evaluated tools. © 2020 IEEE.","Lazar D., Chen H., Wang X., Zeldovich N., Why does cryptographic software fail?: A case study and open problems, Proceedings of 5th Asia-Pacific Workshop on Systems., (2014); Egele M., Brumley D., Fratantonio Y., Kruegel C., An empirical study of cryptographic misuse in android applications, Proceedings of the 2013 Acm Sigsac Conference on Computer & Communications Security. Acm, pp. 73-84, (2013); Diaz G., Bermejo J.R., Static analysis of source code security: Assessment of tools against samate tests, Information and Software Technology, 55, 8, pp. 1462-1476, (2013); Antunes N., Vieira M., Assessing and comparing vulnerability detection tools for web services: Benchmarking approach and examples, Ieee Transactions on Services Computing, 8, 2, pp. 269-283, (2014); Goseva-Popstojanova K., Perhinschi A., On the capability of static code analysis to detect security vulnerabilities, Information and Software Technology, 68, pp. 18-33, (2015); Braga A., Dahab R., Antunes N., Laranjeiro N., Vieira M., Understanding how to use static analysis tools for detecting cryptography misuse in software, Ieee Transactions on Reliability, 68, 4, pp. 1384-1403, (2019); Braga A., Dahab R., Antunes N., Laranjeiro N., Vieira M., Practical evaluation of static analysis tools for cryptography: Benchmarking method and case study, 2017 Ieee 28th International Symposium on Software Reliability Engineering (ISSRE). Ieee, pp. 170-181, (2017); Braga A., Dahab R., Mining cryptography misuse in online forums, 2016 Ieee International Conference on Software Quality, Reliability and Security Companion (QRS-C). Ieee, pp. 143-150, (2016); Nadi S., Kruger S., Mezini M., Bodden E., Jumping through hoops: Why do Java developers struggle with cryptography apis?, Proceedings of the 38th International Conference on Software Engineering., pp. 935-946, (2016); Braga A., Dahab R., A longitudinal and retrospective study on how developers misuse cryptography in online communities, Xvii Simpósio Brasileiro em Segurança da Informação e de Sistemas Computacionais (SBSeg'17), (2017); Silva F.B., Et al., Bag of Graphs=definition, Implementation, and Validation in Classification Tasks, (2014); Navarro L.C., Navarro A.K., Gregio A., Rocha A., Dahab R., Leveraging ontologies and machine-learning techniques for malware analysis into android permissions ecosystems, Computers & Security, 78, pp. 429-453, (2018); Silva F.B., Werneck R.D.O., Goldenstein S., Tabbone S., Torres R.D.S., Graph-based bag-of-words for classification, Pattern Recognition, 74, pp. 266-285, (2018); Grover A., Leskovec J., Node2vec: Scalable feature learning for networks, Proceedings of the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining, pp. 855-864, (2016); Mogensen T.A., Introduction to Compiler Design., (2017); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proc. Acm Program. Lang., 3, pp. 401-4029, (2019); Long F., Rinard M., Automatic patch generation by learning correct code, Acm Sigplan Notices, 51, 1, pp. 298-312, (2016); Shippey T., Bowes D., Hall T., Automatically identifying code features for software defect prediction: Using ast n-grams, Information and Software Technology, 106, pp. 142-160, (2019); Fischer F., Xiao H., Kao C.-Y., Stachelscheid Y., Johnson B., Razar D., Fawkesley P., Buckley N., Bottinger K., Muntean P., Et al., Stack overflow considered helpful! deep learning security nudges towards stronger cryptography, 28th {USENIX} Security Symposium ({USENIX} Security 19), pp. 339-356, (2019); Java Cryptography Architecture (Jca) Reference Guide, (2020); Parr T., The Definitive Antlr 4 Reference., (2013)",,"19th IEEE International Conference on Machine Learning and Applications, ICMLA 2020",14 December 2020 through 17 December 2020,"Virtual, Miami",167387,English,Conference paper,Final,,Scopus,2-s2.0-85102530771,35
Wang Y.; Wang K.; Gao F.; Wang L.,"Wang, Yu (57200052559); Wang, Ke (57001542000); Gao, Fengjuan (57191360803); Wang, Linzhang (56379755500)",57200052559; 57001542000; 57191360803; 56379755500,Learning semantic program embeddings with graph interval neural network,2020,Proceedings of the ACM on Programming Languages,4,OOPSLA,137,,,,42,10.1145/3428205,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097576154&doi=10.1145%2f3428205&partnerID=40&md5=e25d55bad2a851b1147a5f865acc5153,"Learning distributed representations of source code has been a challenging task for machine learning models. Earlier works treated programs as text so that natural language methods can be readily applied. Unfortunately, such approaches do not capitalize on the rich structural information possessed by source code. Of late, Graph Neural Network (GNN) was proposed to learn embeddings of programs from their graph representations. Due to the homogeneous (i.e. do not take advantage of the program-specific graph characteristics) and expensive (i.e. require heavy information exchange among nodes in the graph) message-passing procedure, GNN can suffer from precision issues, especially when dealing with programs rendered into large graphs. In this paper, we present a new graph neural architecture, called Graph Interval Neural Network (GINN), to tackle the weaknesses of the existing GNN. Unlike the standard GNN, GINN generalizes from a curated graph representation obtained through an abstraction method designed to aid models to learn. In particular, GINN focuses exclusively on intervals (generally manifested in looping construct) for mining the feature representation of a program, furthermore, GINN operates on a hierarchy of intervals for scaling the learning to large graphs. We evaluate GINN for two popular downstream applications: variable misuse prediction and method name prediction. Results show in both cases GINN outperforms the state-of-the-art models by a comfortable margin. We have also created a neural bug detector based on GINN to catch null pointer deference bugs in Java code. While learning from the same 9,000 methods extracted from 64 projects, GINN-based bug detector significantly outperforms GNN-based bug detector on 13 unseen test projects. Next, we deploy our trained GINN-based bug detector and Facebook Infer, arguably the state-of-the-art static analysis tool, to scan the codebase of 20 highly starred projects on GitHub. Through our manual inspection, we confirm 38 bugs out of 102 warnings raised by GINN-based bug detector compared to 34 bugs out of 129 warnings for Facebook Infer. We have reported 38 bugs GINN caught to developers, among which 11 have been fixed and 12 have been confirmed (fix pending). GINN has shown to be a general, powerful deep neural network for learning precise, semantic program embeddings. © 2020 Owner/Author.","Allamanis M., The adverse effects of code duplication in machine learning models of code, Proceedings of the 2019 Acm Sigplan International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software (Onward! 2019), (2019); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, International Conference on Learning Representations, (2018); Allen F.E., Control flow analysis, Proceedings of a Symposium on Compiler Optimization, (1970); Alon U., Levy O., Yahav E., Code2seq: Generating sequences from structured representations of code, International Conference on Learning Representations, (2019); Alon U., Zilberstein M., Levy O., Yahav E., Code2Vec: Learning distributed representations of code, Proc. Acm Program. Lang. Popl, (2019); Bahdanau D., Cho K., Bengio Y., Neural machine translation by jointly learning to align and translate, International Conference on Learning Representations, (2015); Berdine J., Calcagno C., O'Hearn P.W., Smallfoot: Modular automatic assertion checking with separation logic, Proceedings of the 4th International Conference on Formal Methods for Components and Objects (FMCO'05), (2006); Calcagno C., Distefano D., Dubreil J., Gabi D., Hooimeijer P., Luca M., O'Hearn P., Papakonstantinou I., Purbrick J., Rodriguez D., Moving fast with software verification, Nasa Formal Methods, (2015); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using rnn encoder-decoder for statistical machine translation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), (2014); Cousot P., Cousot R., Abstract interpretation: A unified lattice model for static analysis of programs by construction or approximation of fixpoints, Conference Record of the Fourth Annual Acm SIGPLAN-SIGACT Symposium on Principles of Programming Languages, (1977); Devlin J., Zbib R., Huang Z., Lamar T., Schwartz R., Makhoul J., Fast and robust neural network joint models for statistical machine translation, Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), (2014); Dinella E., Dai H., Li Z., Naik M., Song L., Wang K., Hoppity: Learning graph transformations to detect and fix bugs in programs, International Conference on Learning Representations, (2020); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, International Conference on Learning Representations, (2019); Gilmer J., Schoenholz S.S., Riley P.F., Vinyals O., Dahl G.E., Neural message passing for quantum chemistry, Proceedings of the 34th International Conference on Machine Learning - Volume 70 (ICML'17), (2017); Gori M., Monfardini G., Scarselli F., A new model for learning in graph domains, Proceedings. 2005 Ieee International Joint Conference on Neural Networks, (2005); Gupta R., Pal S., Kanade A., Shevade S., DeepFix: Fixing common C language errors by deep learning, Thirty-First Aaai Conference on Artificial Intelligence, (2017); Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, International Conference on Learning Representations, (2020); Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P., On the naturalness of software, Proceedings of the 34th International Conference on Software Engineering (ICSE '12), (2012); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Computation, (1997); Jiang L., Misherghi G., Su Z., Glondu S., DECKARD: Scalable and accurate tree-based detection of code clones, 29th International Conference on Software Engineering (ICSE'07), (2007); Just R., Jalali D., Ernst M.D., Defects4J: A database of existing faults to enable controlled testing studies for Java programs, Proceedings of the 2014 International Symposium on Software Testing and Analysis., pp. 437-440, (2014); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, International Conference on Learning Representations, (2016); Maddison C., Tarlow D., Structured generative models of natural source code, International Conference on Machine Learning, (2014); Mikolov T., Sutskever I., Chen K., Corrado G., Dean J., Distributed representations of words and phrases and their compositionality, Neural Information Processing Systems (NIPS), (2013); Nguyen T.T., Nguyen A.T., Nguyen H.A., Nguyen T.N., A statistical semantic language model for source code, Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering (ESEC/FSE 2013), (2013); Pawlak R., Monperrus M., Petitprez N., Noguera C., Seinturier L., Spoon: A library for implementing analyses and transformations of Java source code, Software: Practice and Experience, (2015); Pradel M., Sen K., Deepbugs: A learning approach to name-based bug detection, Proceedings of the Acm on Programming Languages Oopsla, (2018); Pu Y., Narasimhan K., Solar-Lezama A., Barzilay R., Sk-P: A neural program corrector for MOOCs, Companion Proceedings of the 2016 Acm Sigplan International Conference on Systems, Programming, Languages and Applications: Software for Humanity (SPLASH), (2016); Raychev V., Bielik P., Vechev M., Probabilistic model for code with decision trees, Proceedings of the 2016 Acm Sigplan International Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA 2016), (2016); Saha R., Lyu Y., Lam W., Yoshida H., Prasad M., Bugs. jar: A large-scale, diverse dataset of real-world Java bugs, 2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)., pp. 10-13, (2018); Si X., Dai H., Raghothaman M., Naik M., Song L., Learning loop invariants for program verification, Proceedings of the 32nd International Conference on Neural Information Processing Systems (NIPS'18), (2018); Svozil D., Kvasnicka V., Pospichal J., Introduction to multi-layer feed-forward neural networks, Chemometrics and Intelligent Laboratory Systems, (1997); Tomassi D.A., Dmeiri N., Wang Y., Bhowmick A., Liu Y.-C., Devanbu P.T., Vasilescu B., Rubio-Gonzalez C., Bugswarm: Mining and continuously growing a dataset of reproducible failures and fixes, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)., pp. 339-349, (2019); Vasic M., Kanade A., Maniatis P., Bieber D., Singh R., Neural program repair by jointly learning to localize and repair, International Conference on Learning Representations, (2019); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in Neural Information Processing Systems, (2017); Vinyals O., Fortunato M., Jaitly N., Pointer networks, Advances in Neural Information Processing Systems, (2015); Wang K., Learning Scalable and Precise Representation of Program Semantics, (2019); Wang K., Christodorescu M., COSET: A Benchmark for Evaluating Neural Program Embeddings, (2019); Wang K., Singh R., Su Z., Dynamic neural program embedding for program repair, International Conference on Learning Representations, (2018); Wang K., Su Z., Blended, precise semantic program embeddings, Proceedings of the 41st Acm Sigplan International Conference on Programming Language Design and Implementation (PLDI '20), (2020); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)., (2016); Wei J., Goyal M., Durrett G., Dillig I., LambdaNet: Probabilistic type inference using graph neural networks, International Conference on Learning Representations, (2020); Weiser M., Program slicing, Proceedings of the 5th International Conference on Software Engineering (ICSE '81), (1981); Ye X., Bunescu R., Liu C., Learning to rank relevant files for bug reports using domain knowledge, Proceedings of the 22nd Acm Sigsoft International Symposium on Foundations of Software Engineering., pp. 689-699, (2014)",,,,,,English,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85097576154,36
Wang D.; Dong W.; Li S.,"Wang, Deze (57212529423); Dong, Wei (57190581192); Li, Shanshan (55741045700)",57212529423; 57190581192; 55741045700,A multi-Task representation learning approach for source code,2020,"RL+SE and PL 2020 - Proceedings of the 1st ACM SIGSOFT International Workshop on Representation Learning for Software Engineering and Program Languages, Co-located with ESEC/FSE 2020",,,,1,2,1,3,10.1145/3416506.3423575,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096999195&doi=10.1145%2f3416506.3423575&partnerID=40&md5=90838a9e9cff8ebedea3fa270f9fc249,"Representation learning has shown impressive results for a multitude of tasks in software engineering. However, most researches still focus on a single problem. As a result, the learned representations cannot be applied to other problems and lack generalizability and interpretability. In this paper, we propose a Multi-Task learning approach for representation learning across multiple downstream tasks of software engineering. From the perspective of generalization, we build a shared sequence encoder with a pretrained BERT for the token sequence and a structure encoder with a Tree-LSTM for the abstract syntax tree of code. From the perspective of interpretability, we integrate attention mechanism to focus on different representations and set learnable parameters to adjust the relationship between tasks. We also present the early results of our model. The learning process analysis shows our model has a significant improvement over strong baselines.  © 2020 Owner/Author.","Compton R., Frank E., Patros P., Koay A., 2020. Embedding Java classes with code2vec: Improvements from variable obfuscation [Accepted], Msr, 2020; Corazza A., Maggio V., Scanniello G., 2018. Coherence of comments and method implementations: A dataset and an empirical investigation, Software Quality Journal, 26, 2, pp. 751-777, (2018); Jin Kang H., Bissyande T.F., Lo D., 2019. Assessing the generalizability of code2vec token embeddings, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). Ieee, pp. 1-12; Kendall A., Gal Y., Cipolla R., 2018. Multi-Task learning using uncertainty to weigh losses for scene geometry and semantics, Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition, pp. 7482-7491; Duplicates Dataset Vmarkovtsev, (2018)",ACM SIGSOFT,"1st ACM SIGSOFT International Workshop on Representation Learning for Software Engineering and Program Languages, RL+SE and PL 2020, co-located with ESEC/FSE 2020",13 November 2020,"Virtual, Online",164841,English,Conference paper,Final,,Scopus,2-s2.0-85096999195,37
Wei J.; Goyal M.; Durrett G.; Dillig I.,"Wei, Jiayi (57205020772); Goyal, Maruth (57219758637); Durrett, Greg (6504004627); Dillig, Isil (22936636100)",57205020772; 57219758637; 6504004627; 22936636100,LAMBDANET: PROBABILISTIC TYPE INFERENCE USING GRAPH NEURAL NETWORKS,2020,"8th International Conference on Learning Representations, ICLR 2020",,,,,,,64,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136028933&partnerID=40&md5=def38a1ee95a887c65c0df9dc70d4a25,"As gradual typing becomes increasingly popular in languages like Python and TypeScript, there is a growing need to infer type annotations automatically. While type annotations help with tasks like code completion and static error catching, these annotations cannot be fully determined by compilers and are tedious to annotate by hand. This paper proposes a probabilistic type inference scheme for TypeScript based on a graph neural network. Our approach first uses lightweight source code analysis to generate a program abstraction called a type dependency graph, which links type variables with logical constraints as well as name and usage information. Given this program abstraction, we then use a graph neural network to propagate information between related type variables and eventually make type predictions. Our neural architecture can predict both standard types, like number or string, as well as user-defined types that have not been encountered during training. Our experimental results show that our approach outperforms prior work in this space by 14% (absolute) on library types, while having the ability to make type predictions that are out of scope for existing techniques. © 2020 8th International Conference on Learning Representations, ICLR 2020. All rights reserved.","Deeplearning4j; Allamanis Miltiadis, Brockschmidt Marc, Khademi Mahmoud, Learning to represent programs with graphs, ICLR, (2017); Ancona Davide, Zucca Elena, Principal typings for java-like languages, ACM SIGPLAN Notices, 39, pp. 306-317, (2004); Bierman Gavin, Abadi Martin, Torgersen Mads, Understanding typescript, ECOOP 2014 - Object-Oriented Programming, pp. 257-281, (2014); Chung Benjamin, Li Paley, Nardelli Francesco Zappa, Vitek Jan, Kafka: Gradual typing for objects, ECOOP 2018-2018 European Conference on Object-Oriented Programming, (2018); Dauphin Yann, Tur Gokhan, Hakkani-Tur Dilek Z., Heck Larry P., Zero-shot learning for semantic utterance classification, ICLR, (2013); Eshel Yotam, Cohen Noam, Radinsky Kira, Markovitch Shaul, Yamada Ikuya, Levy Omer, Named entity disambiguation for noisy text, CoNLL, (2017); Farhadi Ali, Endres Ian, Hoiem Derek, Forsyth David, Describing objects by their attributes, CVPR, (2017); Gao Zheng, Bird Christian, Barr Earl T., To type or not to type: Quantifying detectable bugs in javascript, Proceedings of the 39th International Conference on Software Engineering, ICSE'17, pp. 758-769, (2017); Gulcehre Caglar, Ahn Sungjin, Nallapati Ramesh, Zhou Bowen, Bengio Yoshua, Pointing the unknown words, Proceedings of the ACL, (2016); Hanenberg Stefan, Kleinschmager Sebastian, Robbes Romain, Tanter Eric, Stefik Andreas, An empirical study on the impact of static typing on software maintainability, Empirical Software Engineering, 19, pp. 1335-1382, (2013); Hellendoorn Vincent J., Bird Christian, Barr Earl T., Allamanis Miltiadis, Deep learning type inference, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2018, pp. 152-162, (2018); Jangda Abhinav, Anand Gaurav, Predicting variable types in dynamically typed programming languages, (2019); Kingma Diederik P., Ba Jimmy, Adam: A method for stochastic optimization, ICLR, (2014); Li Yujia, Tarlow Daniel, Brockschmidt Marc, Zemel Richard S., Gated graph sequence neural networks, ICLR, (2016); Malik Rabee Sohail, Patra Jibesh, Pradel Michael, Nl2type: inferring javascript function types from natural language information, Proceedings of the 41st International Conference on Software Engineering, pp. 304-315, (2019); Mou Lili, Li Ge, Zhang Lu, Wang Tao, Jin Zhi, Convolutional neural networks over tree structures for programming language processing, AAAI, 2, (2016); Pierce Benjamin C, Turner David N, Local type inference, ACM Transactions on Programming Languages and Systems (TOPLAS), 22, 1, pp. 1-44, (2000); Raychev Veselin, Vechev Martin, Krause Andreas, Predicting program properties from”big code, Proceedings of the 42Nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL'15, pp. 111-124, (2015); Ren Xiang, He Wenqi, Qu Meng, Voss Clare R, Ji Heng, Han Jiawei, Label noise reduction in entity typing by heterogeneous partial-label embedding, Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1825-1834, (2016); Siek Jeremy G., Taha Walid, Gradual typing for objects, ECOOP, (2007); Traytel Dmitriy, Berghofer Stefan, Nipkow Tobias, Extending hindley-milner type inference with coercive structural subtyping, Asian Symposium on Programming Languages and Systems, pp. 89-104, (2011); Velickovic Petar, Cucurull Guillem, Casanova Arantxa, Romero Adriana, Lio Pietro, Bengio Yoshua, Graph Attention Networks, International Conference on Learning Representations, (2018); Vinyals Oriol, Fortunato Meire, Jaitly Navdeep, Pointer networks, NeurIPS, (2015); Vitousek Michael M, Kent Andrew M, Siek Jeremy G, Baker Jim, Design and evaluation of gradual typing for python, ACM SIGPLAN Notices, 50, pp. 45-56, (2014); Wang Mingzhe, Tang Yihe, Wang Jian, Deng Jia, Premise selection for theorem proving by deep graph embedding, Advances in Neural Information Processing Systems, pp. 2786-2796, (2017); Wang Xiaolong, Ye Yufei, Gupta Abhinav, Zero-shot recognition via semantic embeddings and knowledge graphs, CVPR, (2018); Xu Zhaogui, Zhang Xiangyu, Chen Lin, Pei Kexin, Xu Baowen, Python probabilistic type inference with natural language support, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 607-618, (2016)",,"8th International Conference on Learning Representations, ICLR 2020",30 April 2020,Addis Ababa,186995,English,Conference paper,Final,,Scopus,2-s2.0-85136028933,38
Brauckmann A.; Goens A.; Ertel S.; Castrillon J.,"Brauckmann, Alexander (57210584782); Goens, Andrés (56252187300); Ertel, Sebastian (55447928700); Castrillon, Jeronimo (24779298800)",57210584782; 56252187300; 55447928700; 24779298800,Compiler-based graph representations for deep learning models of code,2020,CC 2020 - Proceedings of the 29th International Conference on Compiler Construction,,,,201,211,10,48,10.1145/3377555.3377894,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082029510&doi=10.1145%2f3377555.3377894&partnerID=40&md5=2b6ac90a73bc967e9ed2e3c34a9e86df,"In natural language processing, novel methods in deep learning, like recurrent neural networks (RNNs) on sequences of words, have been very successful. In contrast to natural languages, programming languages usually have a well-defined structure. With this structure compilers can reason about programs, using graphs such as abstract syntax trees (ASTs) or control-data flow graphs (CDFGs). In this paper, we argue that we should use these graph structures instead of sequences for learning compiler optimization tasks. To this end, we use graph neural networks (GNNs) for learning predictive compiler tasks on two representations based on ASTs and CDFGs. Experiments show that this improves upon the state-of-the-art in the task of heterogeneous OpenCL mapping, while providing orders of magnitude faster inference times, crucial for compiler optimizations. When testing on benchmark suites not included for training, our AST-based model significantly outperforms the state-of-the-art by over 12 percentage points in terms of accuracy. It is the only one to perform clearly better than a random mapping. On the task of predicting thread coarsening factors, we show that all of the methods fail to produce an overall speedup. © 2020 Association for Computing Machinery.","Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Computing Surveys (CSUR), 51, 4, (2018); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, (2017); Ben-Nun T., Jakobovits A.S., Hoefler T., Neural code comprehension: A learnable representation of code semantics, Advances in Neural Information Processing Systems, pp. 3585-3597, (2018); Chung J., Gulcehre C., Cho K., Bengio Y., Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling, (2014); Cummins C., Petoumenos P., Wang Z., Leather H., End-to-end deep learning of optimization heuristics, Proceedings of the International Conference on Parallel Architectures and Compilation Techniques (PACT 2017), (2017); Fursin G., Kashnikov Y., Memon A.W., Chamski Z., Temam O., Namolaru M., Yom-Tov E., Mendelson B., Zaks A., Courtois E., Et al., Milepost GCC: Machine learning enabled self-tuning compiler, International Journal of Parallel Programming, 39, 3, pp. 296-327, (2011); Goens A., Brauckmann A., Ertel S., Cummins C., Leather H., Castrillon J., A case study on machine learning for synthesizing benchmarks, Proceedings of the 3rd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages (MAPL), MAPL 2019, pp. 38-46, (2019); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Johnson D.D., Learning graphical state transitions, ICLR, (2017); Kipf T.N., Welling M., Semi-supervised Classification with Graph Convolutional Networks, (2016); Leather H., Bonilla E., O'Boyle M., Automatic feature generation for machine learning-based optimising compilation, ACM Transactions on Architecture and Code Optimization (TACO), 11, 1, (2014); LeCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, 7553, (2015); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, (2015); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A Deep Learning-based System for Vulnerability Detection, (2018); Magni A., Dubach C., O'Boyle M., Automatic optimization of thread-coarsening for graphics processors, Proceedings of the 23rd International Conference on Parallel Architectures and Compilation, pp. 455-466, (2014); Mikolov T., Chen K., Corrado G., Dean J., Efficient Estimation of Word Representations in Vector Space, (2013); O'Boyle M.F., Wang Z., Grewe D., Portable mapping of data parallel programs to opencl for heterogeneous systems, Proceedings of the 2013 IEEE/ACM International Symposium on Code Generation and Optimization (CGO), pp. 1-10, (2013); Raychev V., Vechev M., Krause A., Predicting program properties from big code, ACM SIGPLAN Notices, 50, pp. 111-124, (2015); Raychev V., Vechev M., Yahav E., Code completion with statistical language models, Acm Sigplan Notices, 49, pp. 419-428, (2014); Vasilache N., Bastoul C., Cohen A., Polyhedral code generation in the real world, Compiler Construction, pp. 185-201, (2006); Wang Z., Oaazboyle M., Machine learning in compiler optimization, Proceedings of the IEEE, 106, 11, pp. 1879-1901, (2018); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A Comprehensive Survey on Graph Neural Networks, (2019)",ACM SIGPLAN; Google; Huawei; Raincode Labs; Reservoir Labs,"29th ACM SIGPLAN International Conference on Compiler Construction, CC 2020",22 February 2020 through 23 February 2020,San Diego,158012,English,Conference paper,Final,,Scopus,2-s2.0-85082029510,39
Chen L.; Ye W.; Zhang S.,"Chen, Long (57770625800); Ye, Wei (57202350940); Zhang, Shikun (7409376421)",57770625800; 57202350940; 7409376421,Capturing Source Code Semantics via Tree-based Convolution over API-enhanced AST,2019,"ACM International Conference on Computing Frontiers 2019, CF 2019 - Proceedings",,,,174,182,8,20,10.1145/3310273.3321560,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066012156&doi=10.1145%2f3310273.3321560&partnerID=40&md5=f82f46e1227a2748179f7d71d5072443,"When deep learning meets big code, a key question is how to efficiently learn a distributed representation for source code that can capture its semantics effectively. We propose to use tree-based convolution over API-enhanced AST. To demonstrate the effectiveness of our approach, we apply it to detect semantic clones-code fragments with similar semantics but dissimilar syntax. Experiment results show that our approach outperforms an existing state-of-the-art approach that uses tree-based LSTM, with an increase of 0.39 and 0.12 in F1-score on OJClone and BigCloneBench respectively. We further propose architectures that incorporate our approach for code search and code summarization. © 2019 Association for Computing Machinery.","Allamanis M., Barr E.T., Bird C., Sutton C.A., Learning natural coding conventions, Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 281-293, (2014); Allamanis M., Barr E.T., Devanbu P.T., Sutton C.A., A Survey of Machine Learning for Big Code and Naturalness, (2017); Alon U., Levy O., Yahav E., Code2seq: Generating Sequences from Structured Representations of Code, (2018); Bellon S., Koschke R., Antoniol G., Krinke J., Merlo E., Comparison and evaluation of clone detection tools, IEEE Trans. Software Eng, 33, 9, pp. 577-591, (2007); Bengio Y., Simard P.Y., Frasconi P., Learning long-term dependencies with gradient descent is difficult, IEEE Trans. Neural Networks, 5, 2, pp. 157-166, (1994); Chaturvedi A., Arun Pandit O., Garain U., CNN for text-based multiple choice question answering, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, 2, pp. 272-277, (2018); Floyd B., Santander T., Weimer W., Decoding the representation of code in the brain: An fMRI study of code review and expertise, Proceedings of the 39th International Conference on Software Engineering, ICSE 2017, pp. 175-186, (2017); Gabel M., Su Z., A study of the uniqueness of source code, Proceedings of the 18th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 147-156, (2010); Gehring J., Auli M., Grangier D., Yarats D., Dauphin Y.N., Convolutional sequence to sequence learning, Proceedings of the 34th International Conference on Machine Learning, pp. 1243-1252, (2017); Gu X., Zhang H., Zhang D., Kim S., Deep API learning, Proceedings of the 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, 2016, pp. 631-642, (2016); Abram H., Barr E.T., Su Z., Gabel M., Devanbu P.T., On the naturalness of software, 34th International Conference on Software Engineering, pp. 837-847, (2012); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proceedings of the 26th Conference on Program Comprehension, pp. 200-210, (2018); Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., Summarizing source code with transferred api knowledge, Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, pp. 2269-2275, (2018); Jiang L., Misherghi G., Su Z., Glondu S., DECKARD: Scalable and accurate tree-based detection of code clones, Proceedings of the 29th International Conference on Software Engineering, pp. 96-105, (2007); Jiang S., Armaly A., McMillan C., Automatically generating commit messages from diffs using neural machine translation, Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering, ASE 2017, Urbana, IL, USA, October 30-November 03, pp. 135-146, (2017); Nal K., Grefenstette E., Blunsom P., A convolutional neural network for modelling sentences, Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pp. 655-665, (2014); Yoon K., Convolutional neural networks for sentence classification, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pp. 1746-1751, (2014); Koch G., Zemel R., Salakhutdinov R., Siamese neural networks for one-shot image recognition, ICML Deep Learning Workshop, 2, (2015); Koschke R., Falke R., Frenzel P., Clone detection using abstract syntax suffix trees, Proceedings of the 13th Working Conference on Reverse Engineering, pp. 253-262, (2006); Le P., Zuidema W.H., Quantifying the vanishing gradient and long distance dependency problem in recursive neural networks and recursive LSTMs, Proceedings of the 1st Workshop on Representation Learning for NLP, Rep4NLP@ACL 2016, pp. 87-93, (2016); Lopes C.V., Maj P., Martins P., Saini V., Yang Jakub Zitny D., Sajnani H., Vitek J., DéjàVu: A map of code duplicates on GitHub, PACMPL 1, OOPSLA (2017), pp. 841-8428, (2017); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Proceedings of the 30th AAAI Conference on Artificial Intelligence, pp. 1287-1293, (2016); Peng H., Mou L., Li G., Liu Y., Zhang L., Jin Z., Building program vector representations for deep learning, Proceedings of the 8th International Conference on Knowledge Science, Engineering and Management, pp. 547-553, (2015); Rattan D., Kumar Bhatia R., Singh M., Software clone detection: A systematic review, Information & Software Technology, 55, 7, pp. 1165-1199, (2013); Roy C.K., Cordy J.R., A Survey on Software Clone Detection Research, (2007); Roy C.K., Cordy J.R., A mutation/injection-based automatic framework for evaluating code clone detection tools, Proceedings of the 2nd International Conference on Software Testing Verification and Validation, pp. 157-166, (2009); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., Sourcerer CC: Scaling code clone detection to big-code, Proceedings of the 38th International Conference on Software Engineering, pp. 1157-1168, (2016); Jeffrey S., Islam J.F., Keivanloo I., Kumar Roy C., Mamun Mia M., Towards a big data curated benchmark of interproject code clones, Proceedings of the 30th IEEE International Conference on Software Maintenance and Evolution, pp. 476-480, (2014); Svajlenko J., Roy C.K., Evaluating clone detection tools with BigCloneBench, Proceedings of the 2015 IEEE International Conference on Software Maintenance and Evolution, pp. 131-140, (2015); Sheng Tai K., Socher R., Manning C.D., Improved semantic representations from tree-structured long short-term memory networks, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, pp. 1556-1566, (2015); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proceedings of the 26th International Joint Conference on Artificial Intelligence, pp. 3034-3040, (2017); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, pp. 87-98, (2016); Yu H., Lam W., Chen L., Li G., Xie T., Wang Q., Neural detection of semantic code clones via tree-based convolution, Proceedings of the 27th IEEE/ACM Conference on Program Comprehension, ICPC 2019, Montreal, QC, Canada, May, pp. 25-26, (2019)",ACM Special Interest Group on Microarchitectural Research and Processing (SIGMICRO); ALOHA; ARM; IBM; pluX,"16th ACM International Conference on Computing Frontiers, CF 2019",30 April 2019 through 2 May 2019,"Alghero, Sardinia",147897,English,Conference paper,Final,,Scopus,2-s2.0-85066012156,41
Azcona D.; Hsiao I.-H.; Arora P.; Smeaton A.,"Azcona, David (57193264092); Hsiao, I-Han (22834963700); Arora, Piyush (57044215000); Smeaton, Alan (7003631244)",57193264092; 22834963700; 57044215000; 7003631244,User2Code2vec: Embeddings for profiling students based on distributional representations of source code,2019,ACM International Conference Proceeding Series,,,,86,95,9,31,10.1145/3303772.3303813,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062775545&doi=10.1145%2f3303772.3303813&partnerID=40&md5=57afdeb344c75f39f57c3e0cf6dd2c24,"In this work, we propose a new methodology to profile individual students of computer science based on their programming design using a technique called embeddings. We investigate different approaches to analyze user source code submissions in the Python language. We compare the performances of different source code vectorization techniques to predict the correctness of a code submission. In addition, we propose a new mechanism to represent students based on their code submissions for a given set of laboratory tasks on a particular course. This way, we can make deeper recommendations for programming solutions and pathways to support student learning and progression in computer programming modules effectively at a Higher Education Institution. Recent work using Deep Learning tends to work better when more and more data is provided. However, in Learning Analytics, the number of students in a course is an unavoidable limit. Thus we cannot simply generate more data as is done in other domains such as FinTech or Social Network Analysis. Our findings indicate there is a need to learn and develop better mechanisms to extract and learn effective data features from students so as to analyze the students' progression and performance effectively. © 2019 Association for Computing Machinery.","Allamanis M., Barr E.T., Bird C., Sutton C., Learning natural coding conventions, Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 281-293, (2014); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, International Conference on Machine Learning, pp. 2091-2100, (2016); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning Distributed Representations of Code, (2018); Alon U., Zilberstein M., Levy O., Yahav E., A General Path-Based Representation for Predicting Program Properties, (2018); Azcona D., Corrigan O., Scanlon P., Smeaton A., Innovative learning analytics research at a data-driven HEI, Proceedings of the 3rd International Conference on Higher Education Advances, pp. 435-443, (2017); Azcona D., Hsiao I.-H., Smeaton A.F., Detecting students-in-need in programming classes with multimodal learning analytics, International Journal of Artificial Intelligence in Education (ijAIED), (2018); Azcona D., Hsiao I.-H., Smeaton A.F., An exploratory study on student engagement with adaptive notifications in programming courses, European Conference on Technology Enhanced Learning, pp. 644-647, (2018); Azcona D., Hsiao I.-H., Smeaton A.F., PredicTCS: Personalizing programming learning by leveraging learning analytics, Companion Proceedings 8th International Conference on Learning Analytics & Knowledge (LAK18), (2018); Azcona D., Smeaton A.F., Targeting at-risk students using engagement and effort predictors in an introductory computer programming course, European Conference on Technology Enhanced Learning (EC-TEL'17), pp. 361-366, (2017); Baroni M., Dinu G., Kruszewski G., Don't count, predict! A systematic comparison of context-counting vs. Context-predicting semantic vectors, Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers, 1, pp. 238-247, (2014); Bengio Y., Ducharme R., Vincent P., Jauvin C., A neural probabilistic language model, Journal of Machine Learning Research, 3, pp. 1137-1155, (2003); Gross S., Mokbel B., Paassen B., Hammer B., Pinkwart N., Example-based feedback provision using structured solution spaces, International Journal of Learning Technology, 10, 9, pp. 248-280, (2014); Manning C.D., Raghavan P., Schutze H., Text classification and naive bayes, Introduction to Information Retrieval, 1, (2008); Mikolov T., Chen K., Corrado G., Dean J., Efficient Estimation of Word Representations in Vector Space, (2013); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in Neural Information Processing Systems, pp. 3111-3119, (2013); Mou L., Li G., Liu Y., Peng H., Jin Z., Xu Y., Zhang L., Building Program Vector Representations for Deep Learning, (2014); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, AAAI, 2, 4, (2016); Neamtiu I., Foster J.S., Hicks M., Understanding source code evolution using abstract syntax tree matching, ACM SIGSOFT Software Engineering Notes, 30, 4, pp. 1-5, (2005); Paassen B., Hammer B., Price T.W., Barnes T., Gross S., Pinkwart N., The Continuous Hint Factory-Providing Hints in Vast and Sparsely Populated Edit Distance Spaces, (2017); Piech C., Huang J., Nguyen A., Phulsuksombati M., Sahami M., Guibas L., Learning program embeddings to propagate feedback on student code, Proceedings of the 32nd International Conference on International Conference on Machine Learning-, 37, pp. 1093-1102, (2015); Proksch S., Amann S., Nadi S., Enriched event streams: A general dataset for empirical studies on in-IDE activities of software developers, Proceedings of the International Conference on Mining Software Repositories, (2018); Proksch S., Amann S., Nadi S., Mezini M., A dataset of simplified syntax trees for C, Proceedings of the 13th International Conference on Mining Software Repositories, pp. 476-479, (2016); Rabinovich M., Stern M., Klein D., Abstract Syntax Networks for Code Generation and Semantic Parsing, (2017); Raychev V., Vechev M., Yahav E., Code completion with statistical language models, Acm Sigplan Notices, 49, pp. 419-428, (2014); Sahebi S., Lin Y.-R., Brusilovsky P., Tensor factorization for student modeling and performance prediction in unstructured domain, Proceedings of the 9th International Conference on Educational Data Mining. IEDMS, pp. 502-506, (2016); Salton G., Wong A., Yang C.-S., A vector space model for automatic indexing, Commun. ACM, 18, 11, pp. 613-620, (1975); Theodoridis S., Koutroumbas K., Et al., Pattern recognition, IEEE Transactions on Neural Networks, 19, 2, (2008); Tipping M.E., Bishop C.M., Probabilistic principal component analysis, Journal of the Royal Statistical Society: Series B (Statistical Methodology), 61, 3, pp. 611-622, (1999)","ACM Special Interest Group on Computer-Human Interaction (SIGCHI); ACM Special Interest Group on Hypertext, Hypermedia, and Web (SIGWEB); The Society for Learning Analytics Research (SoLAR)","9th International Conference on Learning Analytics and Knowledge, LAK 2019",4 March 2019 through 8 March 2019,Tempe,145666,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85062775545,42
Jin Y.; Bai Y.; Zhu Y.; Sun Y.; Wang W.,"Jin, Yiqiao (57402350500); Bai, Yunsheng (57206481016); Zhu, Yanqiao (57218708975); Sun, Yizhou (25823970300); Wang, Wei (55157954300)",57402350500; 57206481016; 57218708975; 25823970300; 55157954300,Code Recommendation for Open Source Software Developers,2023,"ACM Web Conference 2023 - Proceedings of the World Wide Web Conference, WWW 2023",,,,1324,1333,9,4,10.1145/3543507.3583503,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159264141&doi=10.1145%2f3543507.3583503&partnerID=40&md5=32b2da1f0f6ea3e64ea2d6f6b9e24913,"Open Source Software (OSS) is forming the spines of technology infrastructures, attracting millions of talents to contribute. Notably, it is challenging and critical to consider both the developers' interests and the semantic features of the project code to recommend appropriate development tasks to OSS developers. In this paper, we formulate the novel problem of code recommendation, whose purpose is to predict the future contribution behaviors of developers given their interaction history, the semantic features of source code, and the hierarchical file structures of projects. We introduce CODER, a novel graph-based CODE Recommendation framework for open source software developers, which accounts for the complex interactions among multiple parties within the system. CODER jointly models microscopic user-code interactions and macroscopic user-project interactions via a heterogeneous graph and further bridges the two levels of information through aggregation on file-structure graphs that reflect the project hierarchy. Moreover, to overcome the lack of reliable benchmarks, we construct three large-scale datasets to facilitate future research in this direction. Extensive experiments show that our CODER framework achieves superior performance under various experimental settings, including intra-project, cross-project, and cold-start recommendation. © 2023 Owner/Author.","Willem David Alderliesten J., Zaidman A., An Initial Exploration of the ""Good First Issue"" Label for Newcomer Developers, CHASE, pp. 117-118, (2021); Borges H., Hora A., Tulio Valente M., Understanding the factors that impact the popularity of GitHub repositories, ICSME, pp. 334-344, (2016); Chen J., Lian D., Jin B., Zheng K., Chen E., Learning Recommenders for Implicit Feedback with Importance Resampling, WWW, pp. 1997-2005, (2022); Coelho J., Tulio Valente M., Milen L., Silva L.L., Is this GitHub project maintained? Measuring the level of maintenance activity of open-source projects, Information and Software Technology, 122, (2020); Di Cosmo R., Zacchiroli S., Software Heritage: Why and How to Preserve Software Source Code, iPRES, pp. 1-10, (2017); Fan W., Ma Y., Li Q., He Y., Zhao E., Tang J., Yin D., Graph neural networks for social recommendation, WWW, pp. 417-426, (2019); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., CodeBERT: A Pre-Trained Model for Programming and Natural Languages, Findings of EMNLP 2020, pp. 1536-1547, (2020); Fey M., Lenssen J.E., Fast Graph Representation Learning with PyTorch Geometric, RLGM@ICLR, (2019); Freitas S., Yang D., Kumar S., Tong H., Horng Chau D., Graph vulnerability and robustness: A survey, TKDE, (2022); Gerosa M., Wiese I., Trinkenreich B., Link G., Robles G., Treude C., Steinmacher I., Sarma A., The shifting sands of motivation: Revisiting what drives contributors in open source, ICSE, pp. 1046-1058, (2021); The State of the Octoverse, (2016); Collection: Programming Languages, (2022); Github Number of Repositories, (2022); Glorot X., Bengio Y., Understanding the difficulty of training deep feedforward neural networks, AISTATS, pp. 249-256, (2010); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Et al., GraphCodeBERT: Pre-training Code Representations with Data Flow, ICLR, (2021); Hamilton W., Ying Z., Leskovec J., Inductive representation learning on large graphs, NIPS, (2017); Hao J., Zhao T., Li J., Luna Dong X., Faloutsos C., Sun Y., Wang W., P-companion: A principled framework for diversified complementary product recommendation, CIKM, pp. 2517-2524, (2020); He X., Deng K., Wang X., Li Y., Zhang Y., Wang M., Lightgcn: Simplifying and powering graph convolution network for recommendation, SIGIR, pp. 639-648, (2020); He X., Liao L., Zhang H., Nie L., Hu X., Chua T.-S., Neural collaborative filtering, WWW, pp. 173-182, (2017); He X., Xu L., Zhang X., Hao R., Feng Y., Xu B., Pyart: Python api recommendation in real-time, ICSE, pp. 1634-1645, (2021); Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., Summarizing source code with transferred API knowledge, IJCAI, pp. 2269-2275, (2018); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet challenge: Evaluating the state of semantic code search, (2019); Jiang J.-Y., Cheng P.-J., Wang W., Open source repository recommendation in social coding, SIGIR, pp. 1173-1176, (2017); Jin Y., Wang X., Hao Y., Sun Y., Xie X., Prototypical Fine-tuning: Towards Robust Performance Under Varying Data Sizes, AAAI, (2023); Jin Y., Wang X., Yang R., Sun Y., Wang W., Liao H., Xie X., Towards fine-grained reasoning for fake news detection, AAAI, 36, pp. 5746-5754, (2022); Devlin J., Chang Kenton M.-W., Kristina Toutanova L., BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, NAACL, (2019); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, ICLR, (2015); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, ICLR, (2016); Li A., Yang B., Huo H., Hussain F., Hypercomplex Graph Collaborative Filtering, WWW, pp. 1914-1922, (2022); Lin Z., Tian C., Hou Y., Xin Zhao W., Improving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning, WWW, pp. 2320-2329, (2022); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., Roberta: A robustly optimized bert pretraining approach, (2019); Lu J., Yang J., Batra D., Parikh D., Hierarchical question-image co-attention for visual question answering, NIPS, (2016); Luan S., Yang D., Barnaby C., Sen K., Chandra S., Aroma: Code recommendation via structural code search, OOPSLA, (2019); Mao H., Du L., Zheng Y., Fu Q., Li Z., Chen X., Shi H., Zhang D., Source free unsupervised graph domain adaptation, (2021); McDonald N., Goggins S., Performance and participation in open source software on github, CHI, pp. 139-144, (2013); Mei X., Cai X., Xu S., Li W., Pan S., Yang L., Mutually reinforced network embedding: An integrated approach to research paper recommendation, Expert Systems with Applications, (2022); Valerio Miceli-Barone A., Sennrich R., A Parallel Corpus of Python Functions and Documentation Strings for Automated Code Documentation and Code Generation, IJCNLP, pp. 314-319, (2017); Nahar N., Zhou S., Lewis G., Kastner C., Collaboration Challenges in Building ML-Enabled Systems: Communication, Documentation, Engineering, and Process, Organization, 1, 2, (2022); Tuan Nguyen A., Hilton M., Codoban M., Anh Nguyen H., Mast L., Rademacher E., Nguyen T.N., Dig D., API code recommendation using statistical learning from fine-grained changes, SIGSOFT, pp. 511-522, (2016); Nguyen P.T., Di Rocco J., Di Ruscio D., Ochoa L., Degueule T., Di Penta M., Focus: A recommender system for mining api function calls and usage patterns, ICSE, pp. 1050-1060, (2019); Oh S., Bhardwaj A., Han J., Kim S., Rossi R.A., Kumar S., Implicit Session Contexts for Next-Item Recommendations, CIKM, pp. 4364-4368, (2022); Paszke A., Gross S., Massa F., Lerer A., Bradbury J., Chanan G., Killeen T., Lin Z., Gimelshein N., Antiga L., Et al., Pytorch: An imperative style, high-performance deep learning library, NIPS, (2019); Rendle S., Freudenthaler C., Gantner Z., Schmidt-Thieme L., BPR: Bayesian personalized ranking from implicit feedback, UAI, pp. 452-461, (2009); Shalaby W., Oh S., Afsharinejad A., Kumar S., Cui X., M2TRec: Metadata-aware Multi-task Transformer for Large-scale and Cold-start free Session-based Recommendations, RecSys, pp. 573-578, (2022); Shao H., Sun D., Wu J., Zhang Z., Zhang A., Yao S., Liu S., Wang T., Zhang C., Abdelzaher T., paper2repo: GitHub repository recommendation for academic papers, WWW, pp. 629-639, (2020); Sharma K., Lee Y.-C., Nambi S., Salian A., Shah S., Kim S.-W., Kumar S., A Survey of Graph Neural Networks for Social Recommender Systems, (2022); Srivastava N., Salakhutdinov R.R., Multimodal learning with deep boltzmann machines, NIPS, (2012); Steinmacher I., Paula Chaves A., Uchoa Conte T., Aurelio Gerosa M., Preliminary empirical identification of barriers faced by newcomers to Open Source Software projects, SBES, pp. 51-60, (2014); Velikovi P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph Attention Networks, ICLR, (2018); Venkataramani R., Gupta A., Asadullah A., Muddu B., Bhat V., Discovery of technical expertise from open source code repositories, WWW, pp. 97-98, (2013); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, ASE, pp. 397-407, (2018); Wang H., Zhang J., Zhu Q., Huang W., Augmentation-free graph contrastive learning, (2022); Wang X., He X., Wang M., Feng F., Chua T.-S., Neural graph collaborative filtering, SIGIR, pp. 165-174, (2019); Wang X., Huang T., Wang D., Yuan Y., Liu Z., He X., Chua T.-S., Learning intents behind interactions with knowledge graph for recommendation, WWW, pp. 878-887, (2021); Wang X., Liu K., Wang D., Wu L., Fu Y., Xie X., Multi-level recommendation reasoning over knowledge graphs with reinforcement learning, WWW, pp. 2098-2108, (2022); Wolf T., Debut L., Sanh V., Chaumond J., Delangue C., Moi A., Cistac P., Rault T., Louf R., Funtowicz M., Et al., Transformers: State-of-the-art natural language processing, EMNLP, pp. 38-45, (2020); Wu J., Xu W., Liu Q., Wu S., Wang L., Adversarial Contrastive Learning for Evidence-aware Fake News Detection with Graph Neural Networks, (2022); Wu L., Sun P., Fu Y., Hong R., Wang X., Wang M., A neural influence diffusion model for social recommendation, SIGIR, pp. 235-244, (2019); Wu S., Tang Y., Zhu Y., Wang L., Xie X., Tan T., Session-based recommendation with graph neural networks, AAAI, 33, pp. 346-353, (2019); Xiao W., He H., Xu W., Tan X., Dong J., Zhou M., Recommending good first issues in GitHub OSS projects, ICSE, pp. 1830-1842, (2022); Xu K., Hu W., Leskovec J., Jegelka S., How Powerful are Graph Neural Networks?, ICLR, (2018); Xu W., Sun X., Xia X., Chen X., Scalable relevant project recommendation on GitHub, Internetware, pp. 1-10, (2017); Xu W., Wu J., Liu Q., Wu S., Wang L., Mining Finegrained Semantics via Graph Neural Networks for Evidence-based Fake News Detection, (2022); Xu Y., Zhu Y., A Survey on Pretrained Language Models for Neural Code Intelligence, (2022); Yan C., He Y., Auto-suggest: Learning-to-recommend data preparation steps using data science notebooks, SIGMOD, pp. 1539-1554, (2020); Yang R., Wang X., Jin Y., Li C., Lian J., Xie X., Reinforcement Subgraph Reasoning for Fake News Detection, KDD, pp. 2253-2262, (2022); Ye Y., Kishida K., Toward an understanding of the motivation of open source software developers, ICSE, pp. 419-429, (2003); Ying R., He R., Chen K., Eksombatchai P., Hamilton W.L., Leskovec J., Graph convolutional neural networks for web-scale recommender systems, KDD, pp. 974-983, (2018); Yu X., Xu W., Cui Z., Wu S., Wang L., Graph-based Hierarchical Relevance Matching Signals for Ad-hoc Retrieval, WWW, pp. 778-787, (2021); Yu Y., Wang H., Yin G., Wang T., Reviewer recommendation for pull-requests in GitHub: What can we learn from code review and bug assignment?, Information and Software Technology, 74, pp. 204-218, (2016); Yu Z., Yu J., Cui Y., Tao D., Tian Q., Deep modular co-attention networks for visual question answering, CVPR, pp. 6281-6290, (2019); Yuan F., He X., Jiang H., Guo G., Xiong J., Xu Z., Xiong Y., Future data helps training: Modeling future contexts for session-based recommendation, WWW, pp. 303-313, (2020); Zhang J., Zhu Y., Liu Q., Wu S., Wang S., Wang L., Mining Latent Structures for Multimedia Recommendation, ACM MM, pp. 3872-3880, (2021); Zhang Y., Xu F.F., Li S., Meng Y., Wang X., Li Q., Han J., Higitclass: Keyword-driven hierarchical classification of github repositories, ICDM, pp. 876-885, (2019); Zhao J., Wang X., Shi C., Hu B., Song G., Ye Y., Heterogeneous graph structure learning for graph neural networks, AAAI, 35, pp. 4697-4705, (2021); Zhao J., Wen Q., Sun S., Ye Y., Zhang C., Multi-view Self-supervised Heterogeneous Graph Embedding, ECML-PKDD, pp. 319-334, (2021); Zheng Y., Gao C., Chen L., Jin D., Li Y., DGCN: Diversified Recommendation with Graph Convolutional Networks, WWW, pp. 401-412, (2021); Zheng Y., Gao C., Li X., He X., Li Y., Jin D., Disentangling user interest and conformity for recommendation with causal embedding, WWW, pp. 2980-2991, (2021); Zhu J., Zhou M., Mockus A., Patterns of folder use and project popularity: A case study of GitHub repositories, ESEM, pp. 1-4, (2014); Zhu Y., Xu W., Zhang J., Liu Q., Wu S., Wang L., Deep graph structure learning for robust representations: A survey, (2021); Zhu Y., Xu Y., Yu F., Liu Q., Wu S., Wang L., Graph contrastive learning with adaptive augmentation, WWW, pp. 2069-2080, (2021)",ACM SIGWEB; Amazon Science; Baidu; et al.; Megagon Labs; Zhipu AI,"2023 World Wide Web Conference, WWW 2023",30 April 2023 through 4 May 2023,Austin,188213,English,Conference paper,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85159264141,47
Ye Z.; Feng Z.; Xiao J.; Gao Y.; Fan G.; Zhang H.; Chen S.,"Ye, Zhixiong (57914854700); Feng, Zhiyong (56984876600); Xiao, Jianmao (57208469280); Gao, Yuqing (58137879400); Fan, Guodong (57205028891); Zhang, Huwei (57914854600); Chen, Shizhan (59157692000)",57914854700; 56984876600; 57208469280; 58137879400; 57205028891; 57914854600; 59157692000,Heterogeneous Graph Neural Network-Based Software Developer Recommendation,2022,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",460 LNICST,,,433,452,19,0,10.1007/978-3-031-24383-7_24,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149873121&doi=10.1007%2f978-3-031-24383-7_24&partnerID=40&md5=ecf48c7bba6e98f18bb9a9e0c0705a55,"In software maintenance, it is critical for project managers to assign software issues to the appropriate developers. However, finding suitable developers is challenging due to the general sparsity and the long-tail of developer-issue interactions. In this paper, we propose a novel Heterogeneous Graph Neural Network-based method for Developer Recommendation (called HGDR), in which text information embedding and self-supervised learning (SSL) are incorporated. Specifically, to alleviate the sparsity of developer-issue interactions, we unify developer-issue interactions, developer-source code file interactions and issue-source code file relations into a heterogeneous graph, and we embed text descriptions to graph nodes as information supplements. In addition, to mitigate the long-tail influence, e.g., recommendation bias, the proficiency weight suppression link supplementation is proposed to complement the tail developers by adjusting proficiency weights. Finally, to fully utilize rich structural information of heterogeneous graph, we use the joint learning of metapath-guided heterogeneous graph neural network and SSL to learn the embedding representation. Extensive comparison experiments on three real-world datasets show that HGDR outperforms the state-of-the-art methods by 6.02% to 44.27% on recommended metric. The experimental results also demonstrate the efficacy of HGDR in the sparse and long-tail scenario. Our code is available at https://github.com/1qweasdzxc/HGDR. © 2022, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Chen T., Kornblith S., Norouzi M., Hinton G., A simple framework for contrastive learning of visual representations, International Conference on Machine Learning, pp. 1597-1607, (2020); Danielsson P.E., Euclidean distance mapping, Comput. Graphics Image Process., 14, 3, pp. 227-248, (1980); Devlin J., Chang M.W., Lee K., Toutanova K., BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding. Arxiv Preprint Arxiv, 1810, (2018); Gousios G., Zaidman A., Storey M.A., van Deursen A., Work practices and challenges in pull-based development: The integrator’s perspective, 2015 IEEE/ACM 37Th IEEE International Conference on Software Engineering, 1, pp. 358-368, (2015); Han Z., Et al., Metapath-and entity-aware graph neural network for recommendation. arXiv e-prints, Arxiv-2010, (2020); Hassani K., Khasahmadi A.H., Contrastive multi-view representation learning on graphs, International Conference on Machine Learning, pp. 4116-4126, (2020); He X., Deng K., Wang X., Li Y., Zhang Y., Wang M., LightGCN: Simplifying and powering graph convolution network for recommendation, Proceedings of the 43Rd International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 639-648, (2020); He X., Liao L., Zhang H., Nie L., Hu X., Chua T.S., Neural collaborative filtering, Proceedings of the 26Th International Conference on World Wide Web, pp. 173-182, (2017); Jarvelin K., Kekalainen J., Cumulated gain-based evaluation of IR techniques, ACM Trans. Inf. Syst. (TOIS), 20, 4, pp. 422-446, (2002); Kearns M., Ron D., Algorithmic stability and sanity-check bounds for leave-one-out cross-validation, Neural Comput, 11, 6, pp. 1427-1453, (1999); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks. Arxiv Preprint Arxiv, 1609, (2016); Koren Y., Bell R., Volinsky C., Matrix factorization techniques for recommender systems, Computer, 42, 8, pp. 30-37, (2009); Mikolov T., Chen K., Corrado G., Dean J., Efficient Estimation of Word Representations in Vector Space. Arxiv Preprint Arxiv, 1301, (2013); Rajlich V., Software evolution and maintenance, Future of Software Engineering Proceedings, pp. 133-144, (2014); Rendle S., Freudenthaler C., Gantner Z., Schmidt-Thieme L., BPR: Bayesian Personalized Ranking from Implicit Feedback. Arxiv Preprint Arxiv, 1205, (2012); Servant F., Jones J.A., WhoseFault: Automatic developer-to-fault assignment through fault localization, 2012 34Th International Conference on Software Engineering (ICSE), Pp. 36–46. IEEE, (2012); Shi C., Li Y., Zhang J., Sun Y., Philip S.Y., A survey of heterogeneous information network analysis, IEEE Trans. Knowl. Data Eng., 29, 1, pp. 17-37, (2016); Steven B., NLTK: The Natural Language Toolkit in Proceedings of The ACL 2004 on Interactive Poster and Demonstration Sessions, (2004); Sun X., Yang H., Leung H., Li B., Li H.J., Liao L., Effectiveness of exploring historical commits for developer recommendation: An empirical study, Front. Comp. Sci., 12, 3, pp. 528-544, (2018); Sun X., Yang H., Xia X., Li B., Enhancing developer recommendation with supplementary information via mining historical commits, J. Syst. Softw., 134, pp. 355-368, (2017); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph Attention Networks. Arxiv Preprint Arxiv, 1710, (2017); Wang X., He X., Cao Y., Liu M., Chua T.S., KGAT: Knowledge graph attention network for recommendation, Proceedings of the 25Th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 950-958, (2019); Wang X., He X., Wang M., Feng F., Chua T.S., Neural graph collaborative filtering, Proceedings of the 42Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 165-174, (2019); Wang X., Et al., Heterogeneous graph attention network, The World Wide Web Conference, pp. 2022-2032, (2019); Wang X., Liu N., Han H., Shi C., Self-Supervised Heterogeneous Graph Neural Network with Co-Contrastive Learning. Arxiv Preprint Arxiv, 2105, (2021); Wu Z., Pan S., Chen F., Long G., Zhang C., Philip S.Y., A comprehensive survey on graph neural networks, IEEE Trans. Neural Netw. Learn. Syst., 32, 1, pp. 4-24, (2020); Xia X., Lo D., Wang X., Yang X., Who should review this change?: Putting text and file location analyses together for more accurate recommendations, 2015 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 261-270, (2015); Xia X., Lo D., Wang X., Zhou B., Dual analysis for recommending developers to resolve bugs, J. Softw. Evol. Process, 27, 3, pp. 195-220, (2015); Xia Z., Sun H., Jiang J., Wang X., Liu X., A hybrid approach to code reviewer recommendation with collaborative filtering, 2017 6Th International Workshop on Software Mining (Softwaremining), pp. 24-31, (2017); Xie X., Wang B., Yang X., SoftRec: Multi-relationship fused software developer recommendation, Appl. Sci., 10, 12, (2020); Xin X., He X., Zhang Y., Zhang Y., Jose J., Relational collaborative filtering: Modeling multiple item relations for recommendation, Proceedings of the 42Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 125-134, (2019); Ye L., Sun H., Wang X., Wang J., Personalized teammate recommendation for crowdsourced software developers, Proceedings of the 33Rd ACM/IEEE International Conference on Automated Software Engineering, pp. 808-813, (2018)",,"18th EAI International Conference on Collaborative Computing: Networking, Applications and Worksharing, CollaborateCom 2022",15 October 2022 through 16 October 2022,Hangzhou,290789,English,Conference paper,Final,,Scopus,2-s2.0-85149873121,48
Yerramreddy S.; Mordahl A.; Koc U.; Wei S.; Foster J.S.; Carpuat M.; Porter A.A.,"Yerramreddy, Sai (57202285348); Mordahl, Austin (57210920990); Koc, Ugur (56113196400); Wei, Shiyi (55497866400); Foster, Jeffrey S. (7403380901); Carpuat, Marine (8915594500); Porter, Adam A. (7202005069)",57202285348; 57210920990; 56113196400; 55497866400; 7403380901; 8915594500; 7202005069,An empirical assessment of machine learning approaches for triaging reports of static analysis tools,2023,Empirical Software Engineering,28,2,28,,,,2,10.1007/s10664-022-10253-z,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146111753&doi=10.1007%2fs10664-022-10253-z&partnerID=40&md5=aca50e2d5282663af0b1c5a20fba98c0,"Despite their ability to detect critical bugs in software, static analysis tools’ high false positive rates are a key barrier to their adoption in real-world settings. To improve the usability of these tools, researchers have recently begun to apply machine learning techniques to classify and filter incorrect analysis reports. Although initial results have been promising, the long-term potential and best practices for this line of research are unclear due to the lack of detailed, large-scale empirical evaluation. To partially address this knowledge gap, we present a comparative empirical study of three machine learning techniques—traditional models, recurrent neural networks (RNNs), and graph neural networks (GNNs)—for classifying correct and incorrect results in three static analysis tools—FindSecBugs, CBMC, and JBMC—using multiple datasets. These tools represent different techniques of static analysis, namely taint analysis and model-checking. We also introduce and evaluate new data preparation routines for RNNs and node representations for GNNs. We find that overall classification accuracy reaches a high of 80%–99% for different datasets and application scenarios. We observe that data preparation routines have a positive impact on classification accuracy, with an improvement of up to 5% for RNNs and 16% for GNNs. Overall, our results suggest that neural networks (RNNs or GNNs) that learn over a program’s source code outperform traditional models, although interesting tradeoffs are present among all techniques. Our observations provide insight into the future research needed to speed the adoption of machine learning approaches for static analysis tools in practice. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Abadi M., Agarwal A., Barham P., Brevdo E., Chen Z., Citro C., Corrado G.S., Davis A., Dean J., Devin M., Ghemawat S., Goodfellow I., Harp A., Irving G., Isard M., Jia Y., Jozefowicz R., Kaiser Lkudlur M., Levenberg J., Mane D., Monga R., Moore S., Murray D., Olah C., Schuster M., Shlens J., Steiner B., Sutskever I., Talwar K., Tucker P., Vanhoucke V., Vasudevan V., Viegas F., Vinyals O., Warden P., Wattenberg M., Wicke M., Yu Y., Zheng X., Tensorflow: Large-Scale Machine Learning on Heterogeneous Systems, (2015); Allamanis M., Barr E.T., Bird C., Sutton C., Suggesting accurate method and class names, : Proceedings of the 2015 10Th Joint Meeting on Foundations of Software Engineering (ESEC/FSE 2015, pp. 38-49, (2015); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, . Arxiv, 1711, (2017); Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Comput Surv, 51, 4, (2018); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: learning distributed representations of code, Proceedings of the ACM on programming languages, 3, POPL, pp. 1-29, (2019); Andres M., Free Chat-Server: A Chatserver Written in Java, (2013); Apollo: A Distributed Configuration Center, (2018); Arteau Ph F.D., Polesovsky T., Find Security Bugs, Version 1.4.6., (2018); Automl., (2022); Beyer D., Results of the Competition, (2018); Beyer D., Results of the Competition, (2019); Biere A., Cimatti A., Clarke E., Zhu Y., Symbolic model checking without BDDs, Tools and Algorithms for the Construction and Analysis of Systems, pp. 193-207, (1999); The DaCapo benchmarks: Java benchmarking development and analysis, Proceedings of the 21St Annual ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA ’06)., pp. 169-190, (2006); Okhttp: An HTTP & HTTP/2 Client for Android and Java Applications., (2022); Bravenboer M., Yannis S., Strictly declarative specification of sophisticated points-to analyses, SIGPLAN Not, 44, 10, pp. 243-262, (2009); Burato E., Ferrara P., Spoto F., Security analysis of the OWASP benchmark with julia, In: Proceedings of ITASEC17, the Rst Italian Conference on Security, (2017); Carrier P.-L., Cho K., LSTM Networks for Sentiment Analysis: Deeplearning 0.1 Documentation, (2018); Chen Z., Monperrus M., A literature study of embeddings on source code, Arxiv, 1904, (2019); Cho K., van Merrienboer B., Bahdanau D., Bengio Y., On the Properties of Neural Machine Translation: Encoder-Decoder Approaches, (2014); Clarke E., Kroening D.F., A tool for checking ANSIC programs, Tools and Algorithms for the Construction and Analysis of Systems (TACAS 2004), pp. 168-176, (2004); Cordeiro L., Kesseli P., Kroening D., Schrammel P., Marek T., JBMC: A bounded model checking tool for verifying java bytecode, Computer Aided Verification (CAV) (LNCS), 10981, pp. 183-190, (2018); Dam H.K., Tran T., Pham T.T.M., A deep language model for software code, FSE 2016: Proceedings of the Foundations Software Engineering International Symposium, pp. 1-4, (2016); Diamantopoulos T., Astextractor, v0, (2020); Eclipse Java Integrated Development Environment., (2022); Foundation E., Jetty: Lightweight Highly Scalable Java Based Web Server and Servlet Engine, (2022); Eibe F., Hall M.A., Witten I.H., The WEKA Workbench, (2016); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., Code- BERT: A pre-trained model for programming and natural languages, Arxiv: Cs.Cl/2002.08155, (2020); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Trans Program Lang Syst, 9, 3, pp. 319-349, (1987); Fowkes J., Sutton C., Parameter-free probabilistic API mining across GitHub, . In: Proceedings of the 2016 24Th ACM SIGSOFT International Symposium on Foundations of Software Engineering (FSE 2016)., pp. 254-265, (2016); Gers F.A., Schmidhuber J., Fred C., Learning to forget: continual prediction with LSTM, Neural Comput, 12, 10, pp. 2451-2471, (2000); Giraph: Large-Scale Graph Processing on Hadoop, (2020); Goldberg Y., Neural network methods for natural language processing, Synth Lect Hum Lang Technol, 10, 1, pp. 1-309, (2017); Goldberg Y., Levy O., Word2vec Explained: Deriving Mikolov et al.’s negative-sampling word-embedding method, Arxiv, 1402, (2014); Gori M., Monfardini G., Scarselli F., A new model for learning in graph domains, : 2005 IEEE International Joint Conference on Neural Networks, 2, pp. 729-734, (2005); Gros D., Sezhiyan H., Devanbu P., Yu Z., Code to comment “translation”: Data, metrics, baselining & evaluation, Arxiv: Cs.Se/2010.01410, (2020); Gu X., Zhang H., Zhang D., Kim S., Deep API learning, Proceedings of the 2016 24Th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 631-642, (2016); H2 Database Engine, (2022); Haque S., Leclair A., Wu L., McMillan C., Improved automatic summarization of subroutines via attention to file context, Proceedings of the 17Th International Conference on Mining Software Repositories, (2020); Heckman S.S., Adaptive probabilistic model for ranking code-based static analysis alerts, 29Th International Conference on Software engineering—companion. ICSE 2007 Companion, pp. 89-90, (2007); Heckman S.S., A Systematic Model Building Process for Predicting Actionable Static Analysis Alerts, (2009); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput, 9, 8, (1997); T. J. Watson Libraries for Analysis (WALA, (2006); Joda-Time a Quality Replacement for the Java Date and Time Classes, (2021); Johnson A., Waye L., Moore S., Chong S., Exploring and enforcing security guarantees via program dependence graphs, Proceedings of the 36Th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI ’15, pp. 291-302, (2015); Johnson B., Song Y., Murphy-Hill E., Bowdidge R (2013) Why don’t software developers use static analysis tools to find bugs?, Proceedings of the 2013 International Conference on Software Engineering (ICSE ’13), pp. 672-681; Jozefowicz R., Zaremba W., Sutskever I., An empirical exploration of recurrent network architectures, . In: Proceedings of the 32Nd International Conference on International Conference on Machine learning—volume 37 (ICML’15)., pp. 2342-2350, (2015); Kang H.J.K.L.D., Detecting false alarms from automatic static analysis tools: How far are we?, Proceedings of the 44Th International Conference on Software Engineering (ICSE ’22)., pp. 698-709, (2022); Kharkar A., Moghaddam R.Z., Jin M., Liu X., Shi X., Clement C., Sundaresan N., Learning to reduce false positives in analytic bug detectors, Proceedings of the 44Th International Conference on Software Engineering, (2022); Kingma D.P., Adam J.B., A Method for Stochastic Optimization, (2014); Koc U., Saadatpanah P., Foster J.S., Porter A.A., Learning a classifier for false positive error reports emitted by static code analysis tools, Proceedings of the 1St ACM SIGPLAN International Workshop on Machine Learning and Programming Languages, pp. 35-42, (2017); Koc U., Wei S., Foster J.S., Carpuat M., Porter A.A., An empirical assessment of machine learning approaches for triaging reports of a java static analysis tool, 2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST), pp. 288-299, (2019); Koc U., Mordahl A., Wei S., Foster J.S., Porter A., SATune: Study-driven auto-tuning approach for configurable software verification tools, Proceedings of the 36Th IEEE/ACM International Conference on Automated Software Engineering (ASE 2021, (2021); Kroening D., Tautschnig M., CBMC—C bounded model checker, Tools and Algorithms for the Construction and Analysis of Systems, pp. 389-391, (2014); Kushman N., Barzilay R., Using semantic unification to generate regular expressions from natural language, Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 826-836, (2013); Li H., Kim S., Chandra S., Neural code search evaluation dataset, Arxiv: Cs.Se/1908.09804, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, (2015); Li Y., Tarlow D., Brockschmidt M., Zemel R., 2015b) Gated graph sequence neural networks, Arxiv, 1511; Ling W., Blunsom P., Grefenstette E., Hermann K.M., Kocisky T., Wang F., Senior A., Latent predictor networks for code generation, Proceedings of the 54Th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 1, pp. 599-609, (2016); The LLVM Compiler Infrastructure, (2020); Lukins S.K., Kraft N.A., Letha H.E., Bug Localization using latent Dirichlet allocation, Inf Softw Technol, 52, 9, pp. 972-990, (2010); Mandic D.P., Chambers J., Recurrent neural networks for prediction: learning algorithms architectures and stability, (2001); Microsoft Gated Graph Neural Networks, (2019); Mikolov T., Chen K., Corrado G., Dean J., Sutskever L., Zweig G., Word2vec, (2013); Mohr M., Hecker M., Bischof S., Bechberger J., JOANA (Java Object-Sensitive ANALysis)—information Flow Control Framework for Java, (2021); Mybatis: SQL Mapper Framework for Java, (2021); Naik M., Petablox: Large-Scale Software Analysis and Analytics Using Datalog, (2020); Java Pathfinder., (2022); Nguyen T.T., Nguyen A.T., Nguyen H.A., Nguyen T.N., A statistical semantic language model for source code, Proceedings of the 2013 9Th Joint Meeting on Foundations of Software Engineering (ESEC/FSE 2013, pp. 532-542, (2013); Nie C., Hareton L., A survey of combinatorial testing, ACM Comput Surv, 43, 2, (2011); The OWASP Benchmark for Security Automation, Version, 1, (2014); Panthaplackel S., Nie P., Gligoric M., Li J.J., Mooney R.J., Learning to update natural language comments based on code changes, Arxiv: Cs.Cl/2004.12169, (2020); Prlic A., Yates A., Bliven S.E., Rose P.W., Jacobsen J., Troshin P.V., Chapman M., Gao J., Koh C.H., Foisy S., Et al., Biojava: an open-source framework for bioinformatics in 2012, Bioinformatics, 28, 20, pp. 2693-2695, (2012); Quinlan J.R., C4.5: Programs for Machine Learning, (2014); Raghothaman M., Kulkarni S., Heo K., Naik M., User-guided program reasoning using bayesian inference, : Proceedings of the 39Th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI 2018)., pp. 722-735, (2018); Raychev V., Vechev M., Yahav E., Code completion with statistical language models, Proceedings of the 35Th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI ’14, pp. 419-428, (2014); Raychev V., Vechev M., Krause A., Predicting program properties from “Big code”, Proceedings of the 42Nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL ’15, pp. 111-124, (2015); Rish I., Et al., An empirical study of the naive Bayes classifier, IJCAI 2001 Workshop on Empirical Methods in Artificial Intelligence, 3, pp. 41-46, (2001); Rosen B.K., Wegman M.N., Zadeck F.K., Global value numbers and redundant computations, Proceedings of the 15Th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL ’88, pp. 12-27, (1988); Rosenblatt F., The perceptron: a probabilistic model for information storage and organization in the brain, Psychol Rev, 65, 6, (1958); Russell S.J., Norvig P., Artificial intelligence: a modern approach, (2016); Safavian S.R., Landgrebe D., A survey of decision tree classifier methodology, IEEE Trans Syst Man Cybern, 21, 3, pp. 660-674, (1991); Sak H., Senior A., Beaufays F., Long short-term memory recurrent neural network architectures for large scale acoustic modeling, Fifteenth Annual Conference of the International Speech Communication Association, (2014); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Trans Neural Netw, 20, 1, pp. 61-80, (2009); Smith A., Universal Password Manager., (2019); Sureka A., Jalote P., Detecting duplicate bug report using character N-Gram-Based features, In: 2010 Asia Pacific Software Engineering Conference, pp. 366-374, (2010); api.susi.ai—software and Rules for Personal Assistants, (2018); Tanwar A., Sundaresan K., Ashwath P., Ganesan P., Chandrasekaran S.K., Ravi S., Predicting Vulnerability in Large Codebases with Deep Code Representation, (2020); Apache Jackrabbit is a Fully Conforming Implementation of the Content Repository for Java Technology API, (2022); ) Clang 12 Documentation, (2021); Hypersql Database, (2021); Theano: A python framework for fast computation of mathematical expressions, Arxiv, 1605, (2016); Javalang: Pure Python Java Parser and Tools, (2020); Tripp O., Guarnieri S., Pistoia M., Aleksandr A., ALETHEIA: Improving the usability of static security analysis, Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security (CCS ’14, pp. 762-774, (2014); Tu Z., Su Z., Devanbu P., On the localness of software, : Proceedings of the 22Nd ACM SIGSOFT International Symposium on Foundations of Software Engineering (FSE 2014)., pp. 269-280, (2014); Utture A., Liu S., Kalhauge C.G., Palsberg J., Striking a balance: pruning false-positives from static call graphs, Proceedings of the 44Th International Conference on Software Engineering (ICSE ’22), pp. 2043-2055, (2022); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P.S., Multi-modal attention network learning for semantic source code retrieval, Arxiv: Cs.Se/1909.13516, (2019); Wang J., Wang S., Wang Q., ) Is there a “golden” feature set for static warning identification?: An experimental evaluation, In: Proceedings of the 12Th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM ’18)., (2018); Wang W., Zhang Y., Zeng Z., Xu G., Trans3̂: A transformer-based framework for unifying code summarization and code search, Arxiv: Cs.Se/2003.03238, (2020); Weiser M., Program slicing, Proceedings of the 5Th International Conference on Software Engineering, pp. 439-449, (1981); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proceedings of the 31St IEEE/ACM International Conference on Automated Software Engineering (ASE 2016)., pp. 87-98, (2016); Xypolytos A., Xu H., Vieira B., Ali-Eldin A.M.T., A framework for combining and ranking static analysis tool findings based on tool performance statistics, In: 2017 IEEE International Conference on Software Quality, Reliability and Security Companion (Qrs-C). IEEE, Pp, pp. 595-596, (2017); Ye X., Shen H., Ma X., Bunescu R., Liu C., From word embeddings to document similarities for improved information retrieval in software engineering, Proceedings of the 38Th International Conference on Software Engineering (ICSE ’16, pp. 404-415, (2016); Yuksel U., Sozer H., Automated classification of static code analysis alerts: A case study, 2013 IEEE International Conference on Software Maintenance, pp. 532-535, (2013); Zeiler M.D., ADADELTA: An adaptive learning rate method, . Arxiv, 1212, (2012); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85146111753,49
Tommasel A.; Diaz-Pace J.A.,"Tommasel, Antonela (56341290400); Diaz-Pace, J. Andres (14017872900)",56341290400; 14017872900,Identifying emerging smells in software designs based on predicting package dependencies,2022,Engineering Applications of Artificial Intelligence,115,,105209,,,,0,10.1016/j.engappai.2022.105209,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135130833&doi=10.1016%2fj.engappai.2022.105209&partnerID=40&md5=dfeac6767cd0654f1ee0925e2fe7c8ef,"Software systems naturally evolve, and this evolution often brings design problems that contribute to system degradation. Architectural smells are typical symptoms of such problems, and several of these smells are related to undesired dependencies among packages. The early detection of smells is essential for software engineers to plan ahead for maintenance or refactoring efforts. Although tools for identifying smells exist, they detect the smells once they already exist in the source code when their undesired dependencies are already created. In this work, we explore a forward-looking approach for identifying smells that can emerge in the next system version based on inferring package dependencies that are likely to appear in the system. Our approach takes the current design structure of the system as a network, along with information from previous versions, and applies link prediction techniques from the field of social network analysis. In particular, we consider a group of smells known as instability smells (cyclic dependency, hub-like dependency, and unstable dependency), which fit well with the link prediction model. The approach includes a feedback mechanism to progressively reduce false positives in predictions. An evaluation based on six open-source projects showed that, under certain considerations, the proposed approach can satisfactorily predict missing dependencies and smell configurations thereof. The feedback mechanism led to improvements of up to three times the initial precision values. Furthermore, we have developed a tool for practitioners to apply the approach in their projects. © 2022 Elsevier Ltd","Arcelli Fontana F., Mantyla M.V., Zanoni M., Marino A., Comparing and experimenting machine learning techniques for code smell detection, Empir. Soft. Eng., 21, 3, pp. 1143-1191, (2016); Arvanitou E.M., Ampatzoglou A., Tzouvalidis K., Chatzigeorgiou A., Avgeriou P., Deligiannis I., pp. 98-105, (2017); Behnamghader P., Le D.M., Garcia J., Link D., Shahbazian A., Medvidovic N., A large-scale study of architectural evolution in open-source software systems, Empir. Soft. Eng., 22, 3, pp. 1146-1193, (2017); de Bruin G., Veenman C., van den Herik H., Takes F., Experimental evaluation of train and test split strategies in link prediction, Complex Networks & their Applications IX - Volume 2, Proceedings of the Ninth International Conference on Complex Networks and their Applications, COMPLEX NETWORKS 2020, 1-3 December 2020, Madrid, Spain, Studies in Computational Intelligence, 944, pp. 79-91, (2020); Deza E., Deza M.-M., Chapter 17 - distances and similarities in data analysis, Dictionary of Distances, pp. 217-229, (2006); Diaz-Pace J.A., Tommasel A., Godoy D., pp. 62-71, (2018); Fontana F.A., Pigazzini I., Roveda R., Tamburri D., Zanoni M., Nitto E.D., pp. 282-285, (2017); Fontana F.A., Pigazzini I., Roveda R., Zanoni M., Automatic detection of instability architectural smells, ICSME, pp. 433-437, (2016); Garcia J., Popescu D., Edwards G., Medvidovic N., Toward a catalogue of architectural bad smells., QoSA, LNCS, 5581, pp. 146-162, (2009); Hochstein L., Lindvall M., Combating architectural degeneration: A survey, Inf. Softw. Technol., 47, 10, pp. 643-656, (2005); Le D.M., Link D., Shahbazian A., Medvidovic N., An empirical study of architectural decay in open-source software, IEEE International Conference on Software Architecture, ICSA 2018, Seattle, WA, USA, April 30 - May 4, 2018, pp. 176-185, (2018); Liben-Nowell D., Kleinberg J., The link-prediction problem for social networks, J. Am. Soc. Inf. Sci. Technol., 58, 7, pp. 1019-1031, (2007); Lu L., Zhou T., Link prediction in complex networks: A survey, Physica A, 390, 6, (2011); Manteli C., pp. 124-133, (2012); Marinescu R., Assessing technical debt by identifying design flaws in software systems, IBM J. Res. Dev., 56, 5, (2012); Marinescu R., Assessing technical debt by identifying design flaws in software systems, IBM J. Res. Dev., 56, 5, (2012); Melton H., Tempero E., An empirical study of cycles among classes in Java, Empir. Soft. Eng., 12, 4, pp. 389-415, (2007); Mo R., Cai Y., Kazman R., Xiao L., Hotspot patterns: The formal definition and automatic detection of architecture smells, Proceedings of the 2015 12th Working IEEE/IFIP Conference on Software Architecture, WICSA ’15, pp. 51-60, (2015); Moradabadi B., Meybodi M.R., A novel time series link prediction method: Learning automata approach, Physica A, 482, pp. 422-432, (2017); Nguyen V.H., Tran L.M.S., Predicting vulnerable software components with dependency graphs, Proceedings of the 6th International Workshop on Security Measurements and Metrics, MetriSec ’10, pp. 31-38, (2010); Nucci D.D., Palomba F., Tamburri D.A., Serebrenik A., Lucia A.D., pp. 612-621, (2018); Palomba F., Lucia A.D., Bavota G., Oliveto R., Chapter four - anti-pattern detection: Methods, challenges, and open issues, Advances in Computers, Advances in Computers, 95, pp. 201-238, (2014); Peker S., Kocyigit A., An adjusted recommendation list size approach for users’ multiple item preferences, Artificial Intelligence: Methodology, Systems, and Applications, pp. 310-319, (2016); Ramasubbu N., Kemerer C.F., Managing technical debt in enterprise software packages, IEEE Trans. Softw. Eng., 40, 8, pp. 758-772, (2014); Salton G., McGill M.J., Introduction to Modern Information Retrieval, (1986); Sas D., Avgeriou P., Fontana F.A., Investigating instability architectural smells evolution: an exploratory case study, 2019 IEEE International Conference on software maintenance and evolution (ICSME), pp. 557-567, (2019); Scholkopf B., Platt J.C., Shawe-Taylor J.C., Smola A.J., Williamson R.C., Estimating the support of a high-dimensional distribution, Neural Comput., 13, 7, pp. 1443-1471, (2001); de Silva L., Balasubramaniam D., Controlling software architecture erosion: A survey, J. Syst. Softw., 85, 1, pp. 132-151, (2012); Terra R., Brunet J., Miranda L., Valente M.T., Serey D., Castilho D., Bigonha R., pp. 753-758, (2013); Tracz W., Refactoring for software design smells: Managing technical debt by girish suryanarayana, ganesh samarthyam, and tushar sharma, ACM SIGSOFT Softw. Eng. Notes, 40, 6, (2015); Yang Y., Lichtenwalter R.N., Chawla N.V., Evaluating link prediction methods, Knowl. Inf. Syst., 45, 3, pp. 751-782, (2015); Zhou B., Xia X., Lo D., Wang X., Build predictor: More accurate missed dependency prediction in build configuration files, Proceedings of the 2014 IEEE 38th Annual Computer Software and Applications Conference, COMPSAC ’14, pp. 53-58, (2014); Zimmermann T., Nagappan N., Predicting defects using network analysis on dependency graphs, Proceedings of the 30th International Conference on Software Engineering, ICSE ’08, pp. 531-540, (2008)",,,,,,English,Article,Final,,Scopus,2-s2.0-85135130833,50
Li Y.; Wang S.; Nguyen T.N.; Van Nguyen S.,"Li, Yi (57214684298); Wang, Shaohua (55935247000); Nguyen, Tien N. (55386311200); Van Nguyen, Son (57205025014)",57214684298; 55935247000; 55386311200; 57205025014,Improving bug detection via context-based code representation learning and attention-based neural networks,2019,Proceedings of the ACM on Programming Languages,3,OOPSLA,A162,,,,111,10.1145/3360588,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120130347&doi=10.1145%2f3360588&partnerID=40&md5=c59c9874585380c66a93a3079e51cc7d,"Bug detection has been shown to be an effective way to help developers in detecting bugs early, thus, saving much effort and time in software development process. Recently, deep learning-based bug detection approaches have gained successes over the traditional machine learning-based approaches, the rule-based program analysis approaches, and mining-based approaches. However, they are still limited in detecting bugs that involve multiple methods and suffer high rate of false positives. In this paper, we propose a combination approach with the use of contexts and attention neural network to overcome those limitations. We propose to use as the global context the Program Dependence Graph (PDG) and Data Flow Graph (DFG) to connect the method under investigation with the other relevant methods that might contribute to the buggy code. The global context is complemented by the local context extracted from the path on the AST built from the method's body. The use of PDG and DFG enables our model to reduce the false positive rate, while to complement for the potential reduction in recall, we make use of the attention neural network mechanism to put more weights on the buggy paths in the source code. That is, the paths that are similar to the buggy paths will be ranked higher, thus, improving the recall of our model. We have conducted several experiments to evaluate our approach on a very large dataset with +4.973M methods in 92 different project versions. The results show that our tool can have a relative improvement up to 160% on F-score when comparing with the state-of-the-art bug detection approaches. Our tool can detect 48 true bugs in the list of top 100 reported bugs, which is 24 more true bugs when comparing with the baseline approaches. We also reported that our representation is better suitable for bug detection and relatively improves over the other representations up to 206% in accuracy. © 2019 Association for Computing Machinery. All rights reserved.","The GitHub Repository for This Study, (2019); Allamanis M., Peng H., Sutton C.A., A convolutional attention network for extreme summarization of source code, CoRR, (2016); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, CoRR, (2018); Amodio M., Chaudhuri S., Reps T.W., Neural attribute machines for program generation, CoRR, (2017); Ayewah N., Pugh W., David Morgenthaler J., Penix J., Zhou Y., Evaluating static analysis defect warnings on production software, Proceedings of the 7th ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for Software Tools and Engineering, pp. 1-8, (2007); Bhatia S., Singh R., Automated correction for syntax errors in programming assignments using recurrent neural networks, CoRR, (2016); Bian P., Liang B., Shi W., Huang J., Cai Y., Nar-miner: Discovering negative association rules from code for bug detection, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2018), pp. 411-422, (2018); Bielik P., Raychev V., Vechev M., Phog: Probabilistic model for code, Proceedings of the 33rd International Conference on Machine Learning (Proceedings of Machine Learning Research), 48, pp. 2933-2942, (2016); Cho K., Van Merrienboer B., Gulcehre C., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using rnn encoder-decoder for statistical machine translation, CoRR, (2014); Cole B., Hakim D., Hovemeyer D., Lazarus R., Pugh W., Stephens K., Improving your software using static analysis to find bugs, Companion to the 21st ACM SIGPLAN Symposium on Objectoriented Programming Systems, Languages, and Applications (OOPSLA '06), pp. 673-674, (2006); Le Cun Y., Galland C.C., Hinton G.E., Advances in Neural Information Processing Systems 1, (1989); Le Cun Y., Galland C.C., Hinton G.E., Advances in Neural Information Processing Systems 1, (1989); Engler D., Yu Chen D., Hallem S., Chou A., Chelf B., Bugs as deviant behavior: A general approach to inferring errors in systems code, SIGOPS Oper. Syst. Rev., 35, 5, pp. 57-72, (2001); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Trans. Program. Lang. Syst., 9, 3, pp. 319-349, (1987); Grover A., Leskovec J., Node2vec: Scalable feature learning for networks, CoRR, (2016); Gruska N., Wasylkowski A., Zeller A., Learning from 6, 000 projects: Lightweight cross-project anomaly detection, Proceedings of the 19th International Symposium on Software Testing and Analysis (ISSTA '10), pp. 119-130, (2010); Henkel J., Lahiri S., Liblit B., Reps T.W., Code vectors: Understanding programs through embedded abstracted symbolic traces, CoRR, (2018); Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P., On the naturalness of software, Proceedings of the 34th International Conference on Software Engineering (ICSE '12), pp. 837-847, (2012); Hovemeyer D., Pugh W., Finding more null pointer bugs, but not too many, Proceedings of the 7th ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for Software Tools and Engineering (PASTE '07), pp. 9-14, (2007); Jin G., Song L., Shi X., Scherpelz J., Lu S., Understanding and detecting real-world performance bugs, SIGPLAN Not., 47, 6, pp. 77-88, (2012); Kildall G.A., A unified approach to global program optimization, Proceedings of the 1st Annual ACM SIGACTSIGPLAN Symposium on Principles of Programming Languages, pp. 194-206, (1973); Kim H., Jiang Y., Kannan S., Oh S., Viswanath P., Deepcode: Feedback codes via deep learning, CoRR, (2018); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems, pp. 1097-1105, (2012); Li L., Feng H., Zhuang W., Meng N., Ryder B., Cclearner: A deep learning-based clone detection approach, 2017 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 249-260, (2017); Li Z., Zhou Y., Pr-miner: Automatically extracting implicit programming rules and detecting violations in large software code, SIGSOFT Softw. Eng. Notes, 30, 5, pp. 306-315, (2005); Liang B., Bian P., Zhang Y., Shi W., You W., Cai Y., Antminer: Mining more bugs by reducing noise interference, 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE), pp. 333-344, (2016); Livshits B., Zimmermann T., Dynamine: Finding common error patterns by mining software revision histories, SIGSOFT Softw. Eng. Notes, 30, 5, pp. 296-305, (2005); Mikolov T., Sutskever I., Chen K., Corrado G., Dean J., Distributed representations of words and phrases and their compositionality, CoRR, (2013); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, 27th Annual Conference on Neural Information Processing Systems 2013 (NIPS'13), pp. 3111-3119, (2013); Mockus A., Votta L.G., Identifying reasons for software changes using historic databases., Icsm, pp. 120-130, (2000); Mou L., Li G., Jin Z., Zhang L., Wang T., Tbcnn: A tree-based convolutional neural network for programming language processing, CoRR, (2014); Nam J., Kim S., Heterogeneous defect prediction, Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering (ESEC/FSE 2015), pp. 508-519, (2015); Anh Nguyen H., Thanh Nguyen T., Pham N.H., Al-Kofahi J.M., Nguyen T.N., Accurate and efficient structural characteristic feature extraction for clone detection, Proceedings of the 12th International Conference on Fundamental Approaches to Software Engineering: Held As Part of the Joint European Conferences on Theory and Practice of Software, ETAPS 2009 (FASE'09), pp. 440-455, (2009); Thanh Nguyen T., Anh Nguyen H., Pham N.H., Al-Kofahi J.M., Nguyen T.N., Graph-based mining of multiple object usage patterns, Proceedings of the the 7th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering (ESEC/FSE '09), pp. 383-392, (2009); Olivo O., Dillig I., Lin C., Static detection of asymptotic performance bugs in collection traversals, SIGPLAN Not., 50, 6, pp. 369-378, (2015); Patra J., Pradel M., Learning to Fuzz: Application-Independent Fuzz Testing with Probabilistic, Generative Models of Input Data, (2016); Pradel M., Sen K., Deepbugs: A learning approach to name-based bug detection, CoRR, (2018); Ray B., Hellendoorn V., Godhane S., Tu Z., Bacchelli A., Devanbu P., On the"" naturalness"" of buggy code, 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE), pp. 428-439, (2016); Ray B., Posnett D., Filkov V., Devanbu P., A large scale study of programming languages and code quality in github, Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 155-165, (2014); Smith R., Horwitz S., Detecting and Measuring Similarity in Code Clones, (2009); Sheng Tai K., Socher R., Manning C.D., Improved semantic representations from tree-structured long short-term memory networks, CoRR, (2015); Toman J., Grossman D., Taming the static analysis beast, 2nd Summit on Advances in Programming Languages (SNAPL 2017) (Leibniz International Proceedings in Informatics (LIPIcs)), 71, pp. 181-1814, (2017); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, Proceedings of the 15th International Conference on Mining Software Repositories (MSR '18), pp. 542-553, (2018); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, CoRR, (2017); WALA Documentation; Wang S., Chollak D., Movshovitz-Attias D., Tan L., Bugram: Bug detection with n-gram language models, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering (ASE 2016), pp. 708-719, (2016); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, Proceedings of the 38th International Conference on Software Engineering (ICSE '16), pp. 297-308, (2016); Wasylkowski A., Zeller A., Lindig C., Detecting object usage anomalies, Proceedings of the the 6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering (ESEC-FSE '07), pp. 35-44, (2007); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering (ASE 2016), pp. 87-98, (2016); Yin W., Schutze H., Xiang B., Zhou B., Abcnn: Attention-based convolutional neural network for modeling sentence pairs, CoRR, (2015); Yourdon E., Structured programming and structured design as art forms, Proceedings of the May 19-22, 1975, National Computer Conference and Exposition (AFIPS '75), pp. 277-277, (1975); Zhao G., Huang J., Deepsim: Deep learning code functional similarity, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2018), pp. 141-151, (2018)",,,,,,English,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85120130347,53
Hadj-Kacem M.; Bouassida N.,"Hadj-Kacem, Mouna (57211276825); Bouassida, Nadia (6506761943)",57211276825; 6506761943,Deep Representation Learning for Code Smells Detection using Variational Auto-Encoder,2019,Proceedings of the International Joint Conference on Neural Networks,2019-July,,8851854,,,,26,10.1109/IJCNN.2019.8851854,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073195905&doi=10.1109%2fIJCNN.2019.8851854&partnerID=40&md5=2eaf6624f11a6ef208211dabcb36df5f,"Detecting code smells is an important research problem in the software maintenance. It assists the subsequent steps of the refactoring process so as to improve the quality of the software system. However, most of existing approaches have been limited to the use of structural information. There have been few researches to detect code smells using semantic information although its proven effectiveness in many software engineering problems. In addition, they do not capture entirely the semantic embedded in the source code. This paper attempts to fill this gap by proposing a semantic-based approach that detects bad smells which are scattered at different levels of granularity in the source code. To this end, we use an Abstract Syntax Tree with a Variational Auto-Encoder in the detection of three code smells. The code smells are Blob, Feature Envy and Long Method. We have performed our experimental evaluation on nine open-source projects and the results have achieved a considerable overall accuracy. To further evaluate the performance of our approach, we compare our results with a state-of-the-art method on the same publicly available dataset. © 2019 IEEE.","Fowler M., Beck K., Brant J., Opdyke W., Roberts D., Refactoring: Improving the Design of Existing Code, (1999); Khomh F., Penta M.D., Gueheneuc Y.-G., Antoniol G., An exploratory study of the impact of antipatterns on class change- And fault-proneness, Empirical Software Engineering, 17, 3, pp. 243-275, (2012); Soh Z., Yamashita A., Khomh F., Guhneuc Y.G., Do code smells impact the effort of different maintenance programming activities?, IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering, 1, pp. 393-402, (2016); Tufano M., Palomba F., Bavota G., Oliveto R., Di Penta M., De Lucia A., Poshyvanyk D., When and why your code starts to smell bad, Proceedings of the 37th International Conference on Software Engineering, 1, pp. 403-414, (2015); Palomba F., Bavota G., Di Penta M., Fasano F., Oliveto R., De Lucia A., On the diffuseness and the impact on maintainability of code smells: A large scale empirical investigation, Empirical Software Engineering, 23, 3, pp. 1188-1221, (2018); Mens T., Tourwe T., A survey of software refactoring, IEEE Transactions on Software Engineering, 30, 2, pp. 126-139, (2004); Sahin D., Kessentini M., Bechikh S., Deb K., Codesmell detection as a bilevel problem, ACM Trans. Softw. Eng. Methodol, 24, 1, pp. 61-644, (2014); Khomh F., Vaucher S., Yann-Gael G., Sahraoui H., Bdtex: A gqm-based Bayesian approach for the detection of antipatterns, Journal of Systems and Software, 84, 4, pp. 559-572, (2011); Fontana F.A., Zanoni M., Code smell severity classification using machine learning techniques, Knowledge-Based Systems, 128, pp. 43-58, (2017); Saranya G., Nehemiah H.K., Kannan A., Nithya V., Model Level Code Smell Detection Using Egapso Based on Similarity Measures, 57, 3, pp. 1631-1642, (2018); Ghannem A., El Boussaidi G., Kessentini M., On the use of design defect examples to detect model refactoring opportunities, Software Quality Journal, 24, 4, pp. 947-965, (2016); Moha N., Gueheneuc Y.G., Duchien L., Meur A.F.L., Decor: A method for the specification and detection of code and design smells, IEEE Transactions on Software Engineering, 36, 1, pp. 20-36, (2010); Fontana F.A., Mantyla M.V., Zanoni M., Marino A., Comparing and experimenting machine learning techniques for code smell detection, Empirical Software Engineering, 21, 3, pp. 1143-1191, (2016); Hadj-Kacem M., Bouassida N., A hybrid approach to detect code smells using deep learning, Proceedings of the 13th International Conference on Eval- Uation of Novel Approaches to Software Engineering. SciTePress, pp. 137-146, (2018); Sharma T., Spinellis D., A survey on software smells, Journal of Systems and Software, 138, pp. 158-173, (2018); Palomba F., Panichella A., Lucia A.D., Oliveto R., Zaidman A., A textual-based technique for smell detection, IEEE 24th International Conference on Program Comprehension (ICPC). IEEE, pp. 1-10, (2016); Liu H., Xu Z., Zou Y., Deep learning based feature envy detection, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 385-396, (2018); Hadj-Kacem M., Bouassida N., Towards a taxonomy of bad smells detection approaches, Proceedings of the 13th International Conference on Software Technologies. SciTePress, pp. 164-175, (2018); White M., Vendome C., Linares-Vasquez M., Poshyvanyk D., Toward deep learning software repositories, Proceedings of the 12th Working Conference on Mining Software Repositories, pp. 334-345, (2015); LeCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, 7553, pp. 436-444, (2015); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE), pp. 297-308, (2016); Maddison C., Tarlow D., Structured generative models of natural source code, International Conference on Machine Learning, pp. 649-657, (2014); Hellendoorn V.J., Devanbu P., Are deep neural networks the best choice for modeling source code?, Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, pp. 763-773, (2017); Kingma D.P., Welling M., Auto-encoding Variational Bayes, (2013); Peng H., Mou L., Li G., Liu Y., Zhang L., Jin Z., Building program vector representations for deep learning, Knowledge Science, Engineering and Management. Springer International Publishing, pp. 547-553, (2015); Palomba F., Nucci D.D., Tufano M., Bavota G., Oliveto R., Poshyvanyk D., De Lucia A., Landfill: An open dataset of code smells with public evaluation, Proceedings of the 12th Working Conference on Mining Software Repositories, pp. 482-485, (2015); Palomba F., Bavota G., Penta M.D., Oliveto R., Poshyvanyk D., Lucia A.D., Mining version histories for detecting code smells, IEEE Transactions on Software Engineering, 41, 5, pp. 462-489, (2015); McCabe T.J., A complexity measure, IEEE Transactions on Software Engineering, 4, pp. 308-320, (1976); Chidamber S.R., Kemerer C.F., A metrics suite for object oriented design, IEEE Transactions on Software Engineering, 20, 6, pp. 476-493, (1994); Marinescu R., Detection strategies: Metrics-based rules for detecting design flaws, 20th IEEE International Conference on Software Maintenance, pp. 350-359, (2004); Kessentini W., Kessentini M., Sahraoui H., Bechikh S., Ouni A., A cooperative parallel search-based software engineering approach for code-smells detection, IEEE Transactions on Software Engineering, 40, 9, pp. 841-861, (2014); Palomba F., Bavota G., Di Penta M., Oliveto R., De Lucia A., Poshyvanyk D., Detecting bad smells in source code using change history information, Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering. IEEE Press, pp. 268-278, (2013); Fu S., Shen B., Code bad smell detection through evolutionary data mining, 2015 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM), Oct 2015, pp. 1-9; Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P., On the naturalness of software, 34th International Conference on Software Engineering (ICSE, pp. 837-847, (2012); Bengio Y., Et al., Learning deep architectures for ai, Foundations and Trends in Machine Learning, 2, 1, pp. 1-127, (2009); Witten I.H., Frank E., Hall M.A., Data Mining: Practical Machine Learning Tools and Techniques, 3rd Ed, (2011)",,"2019 International Joint Conference on Neural Networks, IJCNN 2019",14 July 2019 through 19 July 2019,Budapest,152291,English,Conference paper,Final,,Scopus,2-s2.0-85073195905,55
Wu B.; Liu S.; Xiao Y.; Li Z.; Sun J.; Lin S.-W.,"Wu, Bozhi (57207695744); Liu, Shangqing (57218717656); Xiao, Yang (57208225953); Li, Zhiming (57226344159); Sun, Jun (56153273100); Lin, Shang-Wei (55813047300)",57207695744; 57218717656; 57208225953; 57226344159; 56153273100; 55813047300,Learning Program Semantics for Vulnerability Detection via Vulnerability-Specific Inter-procedural Slicing,2023,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,,,1371,1383,12,0,10.1145/3611643.3616351,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180555589&doi=10.1145%2f3611643.3616351&partnerID=40&md5=692aaffa5f587038352bbcc822a1a86b,"Learning-based approaches that learn code representations for software vulnerability detection have been proven to produce inspiring results. However, they still fail to capture complete and precise vulnerability semantics for code representations. To address the limitations, in this work, we propose a learning-based approach namely SnapVuln, which first utilizes multiple vulnerability-specific inter-procedural slicing algorithms to capture vulnerability semantics of various types and then employs a Gated Graph Neural Network (GGNN) with an attention mechanism to learn vulnerability semantics. We compare SnapVuln with state-of-the-art learning-based approaches on two public datasets, and confirm that SnapVuln outperforms them. We further perform an ablation study and demonstrate that the completeness and precision of vulnerability semantics captured by SnapVuln contribute to the performance improvement. © 2023 Owner/Author.","(2022); (2022); Allamanis M., Barr E.T., Ducousso S., Gao Z., Typilus: Neural type hints, Proceedings of the 41st acm sigplan conference on program-ming language design and implementation, pp. 91-105, (2020); Allamanis M., Jackson-Flux H., Brockschmidt M., Selfsupervised bug detection and repair, Advances in Neural Information Processing Systems, 34, pp. 27865-27876, (2021); Allen F.E., Cocke J., A program data-ow analysis procedure, Commun. ACM, 19, 3, (1976); Learning Precise Program Semantics for Vulnerability Detection via Type-speci-c Inter-procedural Slicing, (2023); Babic D., Martignoni L., McCamant S., Song D., Statically-directed dynamic automated test generation, Proceedings of the 2011 International Symposium on Software Testing and Analysis, pp. 12-22, (2011); Bieber D., Sutton C., Larochelle H., Tarlow D., Learning to execute programs with instruction pointer attention graph neural networks, Advances in Neural Information Processing Systems, 33, pp. 8626-8637, (2020); Bieman J.M., Kang B., Measuring design-level cohesion, IEEE Transactions on software engineering, 24, 2, pp. 111-124, (1998); Bieman J.M., Ott L.M., Measuring functional cohesion, IEEE transactions on Software Engineering, 20, 8, pp. 644-657, (1994); Binkley D., Precise executable interprocedural slices, ACM Letters on Programming Languages and Systems (LOPLAS), 2, 1-4, pp. 31-45, (1993); Binkley D., Slicing in the presence of parameter aliasing, Software Engineering Research Forum, pp. 261-268, (1993); Boyer R.S., Elspas B., Levitt K.N., SELECT-a formal system for testing and debugging programs by symbolic execution, ACM SigPlan Notices, 10, 6, pp. 234-245, (1975); Cha S.K., Woo M., Brumley D., Program-adaptive mutational fuzzing, 2015 IEEE Symposium on Security and Privacy. IEEE, pp. 725-741, (2015); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet, IEEE Transactions on Software Engineering, (2021); Chang W., Strei- B., Lin C., E-cient and extensible security enforcement using dynamic data-ow analysis, Proceedings of the 15th ACM conference on Computer and communications security, pp. 39-50, (2008); Cheng X., Wang H., Hua J., Xu G., Sui Y., Deepwukong: Statically detecting software vulnerabilities using deep graph neural network, ACM Transactions on Software Engineering and Methodology (TOSEM), 30, 3, pp. 1-33, (2021); Cheng X., Zhang G., Wang H., Sui Y., Path-sensitive code embedding via contrastive learning for software vulnerability detection, Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 519-531, (2022); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using RNN encoder-decoder for statistical machine translation, (2014); Fan J., Li Y., Wang S., Nguyen T.N., AC/C++ code vulnerability dataset with code changes and CVE summaries, Proceedings of the 17th International Conference on Mining Software Repositories, pp. 508-512, (2020); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Codebert: A pre-trained model for programming and natural languages, (2020); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, (2018); Fosdick L.D., Osterweil L.J., Data-ow analysis in software reliability, ACM Computing Surveys (CSUR), 8, 3, pp. 305-330, (1976); Fritzson P., Shahmehri N., Kamkar M., Gyimothy T., Generalized algorithmic debugging and testing, ACM Letters on Programming Languages and Systems (LOPLAS), 1, 4, pp. 303-322, (1992); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Et al., Graphcodebert: Pre-training code representations with data-ow, (2020); Hisley D., Bridges M., Pollock L., Static interprocedural slicing of shared memory parallel programs, (2002); Horwitz S., Reps T., Binkley D., Interprocedural slicing using dependence graphs, ACM Transactions on Programming Languages and Systems (TOPLAS), 12, 1, pp. 26-60, (1990); Jackson D., Rollins E.J., Chopping: A generalization of slic-ing, (1994); Jeong D.R., Kim K., Shivakumar B., Lee B., Shin I., Razzer: Finding kernel race bugs through fuzzing, 2019 IEEE Symposium on Security and Privacy (SP). IEEE, pp. 754-768, (2019); Kang B., Bieman J.M., Design-level cohesion measures: Derivation, comparison, and applications, Proceedings of 20th International Computer Software and Applications Conference: COMPSAC'96. IEEE, pp. 92-97, (1996); Kim T., Song Y., Chung L., Huynh D.T., Software architecture analysis using dynamic slicing, AoM/IAoM 17th International Conference on Computer Science, pp. 242-247, (1999); Kim T., Song Y., Chung L., Huynh D.T., Software architecture analysis: A dynamic slicing approach, International Journal of Computer & Information Science, 1, 2, pp. 91-103, (2000); Kim T., Song Y., Chung L., Hyunh D.T., Dynamic software architecture slicing, Proceedings. Twenty-Third Annual International Computer Software and Applications Conference (Cat. No. 99CB37032). IEEE, pp. 61-66, (1999); Kiss A., Jasz J., Lehotai G., Gyimothy T., Interprocedural static slicing of binary executables, Proceedings Third IEEE International Workshop on Source Code Analysis and Manipulation. IEEE, pp. 118-127, (2003); Lakhotia A., Improved interprocedural slicing algorithm, (1992); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proceedings of the 28th international conference on program comprehension, pp. 184-195, (2020); Li Y., Wang S., Nguyen T.N., Van Nguyen S., Improving bug detection via context-based code representation learning and attention-based neural networks, Proceedings of the ACM on Programming Languages, 3, pp. 1-30, (2019); Li Z., Zou D., Xu S., Chen Z., Zhu Y., Jin H., Vuldeelocator: A deep learning-based-ne-grained vulnerability detector, IEEE Transactions on Dependable and Secure Computing, (2021); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: A framework for using deep learning to detect software vulnerabilities, IEEE Transactions on Dependable and Secure Computing, (2021); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, (2018); Liu S., Chen Y., Xie X., Siow J.K., Liu Y., Retrieval-Augmented Generation for Code Summarization via Hybrid GNN, International Conference on Learning Representations, (2020); Liu S., Grau B., Horrocks I., Kostylev E., Indigo: Gnn-based inductive knowledge graph completion using pair-wise encoding, Advances in Neural Information Processing Systems, 34, pp. 2034-2045, (2021); Liu S., Xie X., Ma L., Siow J., Liu Y., Graphsearchnet: Enhancing gnns via capturing global dependency for semantic code search, (2021); Livadas P.E., Croll S., System dependence graph construction for recursive programs, Proceedings of 1993 IEEE 17th International Computer Software and Applications Conference COMPSAC'93. IEEE, pp. 414-420, (1993); Livadas P.E., Croll S., A new algorithm for the calculation of transitive dependences, Journal of Software Maintenance: Research and Practice, 7, 3, pp. 151-176, (1995); Lo W.W., Layeghy S., Sarhan M., Gallagher M., Portmann M., GNN-based Android Malware Detection with Jumping Knowledge, (2022); Lyle R., Automatic program bug location by program slicing, Proceedings 2nd international conference on computers and applications, pp. 877-883, (1987); Mashhadi E., Hemmati H., Applying codebert for automated program repair of Java simple bugs, 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR). IEEE, pp. 505-509, (2021); Pak B.S., Hybrid fuzz testing: Discovering software bugs via fuzzing and symbolic execution, School of Computer Science Carnegie Mellon University, (2012); Reps T., Rosay G., Precise interprocedural chopping, Proceedings of the 3rd ACM SIGSOFT Symposium on Foundations of Software Engineering, pp. 41-52, (1995); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE international conference on machine learning and applications (ICMLA). IEEE, pp. 757-762, (2018); Shapiro E.Y., Algorithmic program debugging, (1982); Stephens N., Grosen J., Salls C., Dutcher A., Wang R., Corbetta J., Shoshitaishvili Y., Kruegel C., Vigna G., Driller: Augmenting Fuzzing Through Selective Symbolic Execution, NDSS, 16, pp. 1-16, (2016); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser U., Polosukhin I., Attention is all you need, Advances in neural information processing systems, 30, (2017); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph Attention Networks, International Con-ference on Learning Representations, (2018); Wang H., Ye G., Tang Z., Tan S.H., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Transactions on Information Forensics and Security, 16, pp. 1943-1958, (2020); Wang J., Chen B., Wei L., Liu Y., Superion: Grammaraware greybox fuzzing, 2019 IEEE/ACM 41st International Conference on Soft-ware Engineering (ICSE). IEEE, pp. 724-735, (2019); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and-ow-augmented abstract syntax tree, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, pp. 261-271, (2020); Wang Y., Wang K., Gao F., Wang L., Learning semantic program embeddings with graph interval neural network, Proceedings of the ACM on Programming Languages 4, pp. 1-27, (2020); Wei J., Goyal M., Durrett G., Dillig I., Lambdanet: Probabilistic type inference using graph neural networks, (2020); Weiser M.D., Program slices: Formal, psychological, and practical in-vestigations of an automatic program abstraction method, (1979); Wu B., Liu S., Feng R., Xie X., Siow J., Lin S., Enhancing Security Patch Identi-cation by Capturing Structures in Commits, IEEE Transactions on Dependable and Secure Computing, (2022); Xu B., Qian J., Zhang X., Wu Z., Chen L., A brief survey of program slicing, ACM SIGSOFT Software Engineering Notes, 30, 2, pp. 1-36, (2005); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy. IEEE, pp. 590-604, (2014); Zhao J., Applying slicing technique to software architectures, Proceedings. Fourth IEEE International Conference on Engineering of Complex Computer Systems (Cat. No. 98EX193). IEEE, pp. 87-98, (1998); Zheng Y., Pujar S., Lewis B., Buratti L., Epstein E., Yang B., Laredo J., Morari A., Su Z., D2A: A dataset built for AI-based vulnerability detection methods using di-erential analysis, 2021 IEEE/ACM 43rd International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP). IEEE, pp. 111-120, (2021); Zhou J., Pacheco M., Wan Z., Xia X., Lo D., Wang Y., Hassan A.E., Finding A Needle in a Haystack: Automated Mining of Silent Vulnerability Fixes, 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 705-716, (2021); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: E-ective vulnerability identi-cation by learning comprehensive program semantics via graph neural networks, Advances in neural information processing systems, 32, (2019); Zhou Y., Siow J.K., Wang C., Liu S., Liu Y., Spi: Automated identi-cation of security patches via commits, ACM Transactions on Software Engineering and Methodology (TOSEM), 31, 1, pp. 1-27, (2021); Zou D., Wang S., Xu S., Li Z., Jin H., VulDeePecker: A Deep Learning-Based System for Multiclass Vulnerability Detection, IEEE Transactions on Dependable and Secure Computing, 18, 5, pp. 2224-2236, (2019)",ACM SIGSOFT; Ant Group; et al.; Google; JetBrains; Meta,"31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2023",3 December 2023 through 9 December 2023,San Francisco,195093,English,Conference paper,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85180555589,56
Hao J.; Luo S.; Pan L.,"Hao, Jingwei (56367599300); Luo, Senlin (7401986059); Pan, Limin (36141326500)",56367599300; 7401986059; 36141326500,A novel vulnerability severity assessment method for source code based on a graph neural network,2023,Information and Software Technology,161,,107247,,,,3,10.1016/j.infsof.2023.107247,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159789401&doi=10.1016%2fj.infsof.2023.107247&partnerID=40&md5=595dd25f95f5a584f70f056f531a35a0,"Context: Vulnerability severity assessment is an important part of vulnerability management that can help security personnel determine the priority of vulnerability repair work. Objective: Aiming at the problems of low evaluation efficiency and poor timeliness in the existing method, a vulnerability severity evaluation method combining a function call graph and vulnerability attribute graph is proposed. Method: This method constructs a function call graph centered on vulnerable functions and uses the call relationship between vulnerable functions and sensitive API functions to reflect the severity of the damage of the vulnerable functions. The graph attention neural network algorithm is used to mine the key vulnerability characteristics in the function call graph and the vulnerability attribute graph to realize the assessment of vulnerability severity. Results: The ablation experiment results showed that the combined vulnerability attribute graph and function call graph had higher evaluation accuracy than the vulnerability attribute graph or function call graph alone, which increased by 6.85% and 32.90%, respectively. Compared with other existing methods, our method has achieved a better evaluation effect, and the evaluation accuracy has increased by 10%. Conclusion: The vulnerability severity assessment method incorporating function call graphs and vulnerability property graphs demonstrates an enhancement in the ability to represent the severity of vulnerabilities and increases the efficiency of vulnerability severity evaluation through elimination of the requirement for manual analysis. © 2023","Toloudis D., Spanos G., Angelis L., Associating the severity of vulnerabilities with their description, International Conference on Advanced Information Systems Engineering (CAiSE)[C], New York, pp. 231-242, (2016); Spanos G., Angelis L., Toloudis D., Assessment of vulnerability severity using text mining, Proceedings of the 21st Pan-Hellenic Conference on Informatics[C], New York, NY, pp. 1-6, (2017); Ognawala S., Amato R.N., Pretschner A., Et al., Automatically assessing vulnerabilities discovered by compositional analysis, Proceedings of the 1st International Workshop on Machine Learning and Software Engineering in Symbiosis[C], New York, NY, pp. 16-25, (2018); Zhou Y., Et al., Devign: effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Adv. Neural Inf. Process. Syst., 32, (2019); Cheng X., Et al., DeepWukong: statically detecting software vulnerabilities using deep graph neural network, ACM Trans. Softw. Eng. Methodol. (TOSEM), 30, 3, pp. 1-33, (2021); Wang H., Et al., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans. Inform. Forensics Security, 16, pp. 1943-1958, (2020); Yamamoto Y., Miyamoto D., Nakayama M., Text-mining approach for estimating vulnerability score, 2015 4th International Workshop on Building Analysis Datasets and Gathering Experience Returns for Security (BADGERS)[C], Piscataway, NJ, pp. 67-73, (2015); Kumari M., Sharma M., Singh V.B., Severity assessment of a reported bug by considering its uncertainty and irregular state[J], International J. Open Source Softw. Process., 9, 4, pp. 20-46, (2018); Han Z., Li X., Xing Z., Et al., Learning to predict severity of software vulnerability using only vulnerability description, 2017 IEEE International Conference on Software Maintenance and Evolution (ICSME)[C], Piscataway, NJ, pp. 125-136, (2017); NAKAGAWA S., NAGAI T., KANEHARA H., Et al., Character-level convolutional neural network for predicting severity of software vulnerability from vulnerability description[J], IEICE Trans. Inf. Syst., E102-D, 9, pp. 1679-1682, (2019); Jindal R., Malhotra R., Jain A., Prediction of defect severity by mining software project reports[J], Int. J. Syst. Assur. Eng. Manage., 8, 2, pp. 334-351, (2017); Kukkar A., Mohana R., Nayyar A., Et al., A novel deep-learning-based bug severity classification technique using convolutional neural networks and random forest with boosting[J], Sensors, 19, 13, (2019); Fang S., Tan Y., Zhang T., Et al., Effective prediction of bug-fixing priority via weighted graph convolutional networks[J], IEEE Trans. Reliab., 70, 2, pp. 563-574, (2021); Umer Q., Liu H., Illahi I., CNN-based automatic prioritization of bug reports[J], IEEE Trans. Reliab., 69, 4, pp. 1341-1354, (2019); Jacobs J., Romanosky S., Adjerid I., Baker W., Improving vulnerability remediation through better exploit prediction[J], J. Cybersecur., 6, 1, (2020); Tan Y., Et al., Bug severity prediction using question-and-answer pairs from Stack Overflow[J], J. Syst. Softw., 165, (2020); Kumari M., Singh V.B., An improved classifier based on entropy and deep learning for bug priority prediction, International Conference on Intelligent Systems Design and Applications[C], Cham, (2018); Pourasghar B., Izadkhah H., Isazadeh A., Et al., A graph-based clustering algorithm for software systems modularization[J], Inf. Softw. Technol., 133, (2021); Sahin S., Tosun A., A conceptual replication on predicting the severity of software vulnerabilities, Proceedings of the Evaluation and Assessment on Software Engineering[C], New York, NY, pp. 244-250, (2019); Bani-Salameh H., Sallam M., A deep-learning-based bug priority prediction using RNN-LSTM neural networks, e-Informatica Softw. Eng. J., 15, 1, (2021); Kumari M., Singh V.B., An improved classifier based on entropy and deep learning for bug priority prediction, International Conference on Intelligent Systems Design and Applications, Cham, (2018); Chen H., Liu J., Liu R., Et al., VEST: a system for vulnerability exploit scoring & timing, Proceedings of the 28th International Joint Conference on Artificial Intelligence [C], Palo Alto, CA, pp. 6503-6505, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85159789401,57
Tang G.; Yang L.; Zhang L.; Cao W.; Meng L.; He H.; Kuang H.; Yang F.; Wang H.,"Tang, Gaigai (57215544716); Yang, Lin (57945734100); Zhang, Long (55181963100); Cao, Weipeng (57195309486); Meng, Lianxiao (57215545789); He, Hongbin (57822354400); Kuang, Hongyu (58803542100); Yang, Feng (57223897708); Wang, Huiqiang (54790335900)",57215544716; 57945734100; 55181963100; 57195309486; 57215545789; 57822354400; 58803542100; 57223897708; 54790335900,An attention-based automatic vulnerability detection approach with GGNN,2023,International Journal of Machine Learning and Cybernetics,14,9,,3113,3127,14,2,10.1007/s13042-023-01824-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152895909&doi=10.1007%2fs13042-023-01824-7&partnerID=40&md5=addd333bf03eebcb80f6b62c16ad9400,"Vulnerability detection has long been an important issue in software security. The existing methods mainly define the rules and features of vulnerabilities through experts, which are time-consuming and laborious, and usually with poor accuracy. Thus automatic vulnerability detection methods based on code representation graph and Graph Neural Network (GNN) have been proposed with the advantage of effectively capture both the semantics and structure information of the source code, showing a better performance. However, these methods ignore the redundant information in the graph and the GNN model, leading to a still unsatisfactory performance. To alleviate this problem, we propose a attention-based automatic vulnerability detection approach with Gated Graph Sequence Neural Network (GGNN). Firstly, we introduce two preprocessing methods namely pruning and symbolization representation to reduce the redundant information of the input code representation graph, and then put the graph into the GGNN layer to update the node features. Next, the key subgraph extraction and global feature aggregation are realized through the attention-based Pooling layers. Finally, the classification result is obtained through a linear classifier. The experimental results show the effectiveness of our proposed preprocessing methods and attention-based Pooling layers, especially the higher Accuracy and F1-score gains compared with the state-of-the-art automatic vulnerability detection approaches. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Flawfinder.; Viega J., Bloch J.T., McGraw G., ITS4: A static vulnerability scanner for C and C++ code, 16Th Annual Computer Security Applications Conference (ACSAC), 11–15 December 2000, New Orleans, Louisiana, USA, P, (2000); Rough-Auditing-Tool-For-Security.; Checkmarx; Hp Fortify; Kim S., Woo S., Lee H., Oh H., VUDDY: A scalable approach for vulnerable code clone discovery, In: 2017 IEEE Symposium on Security and Privacy, SP 2017, San Jose, CA, USA, May, 22-26, pp. 595-614, (2017); Li Z., Zou D., Xu S., Et al., Vulpecker: An automated vulnerability detection system based on code similarity analysis, In: Proceedings of the 32Nd Annual Conference on Computer Security Applications, ACSAC, Los Angeles, CA, USA, December, 5-9, pp. 201-213, (2016); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, SP 2014, Berkeley, CA, USA, May 18–21, pp. 590-604, (2014); Perl H., Dechand S., Et al., Vccfinder: Finding potential vulnerabilities in open-source projects to assist code audits, In: Proceedings of the 22Nd ACM SIGSAC Conference on Computer and Communications Security, Denver, CO, USA, October, 12-16, 2015, pp. 426-437, (2015); Grieco G., Grinblat G.L., Et al., Toward large-scale vulnerability discovery using machine learning, Proceedings of the Sixth ACM on Conference on Data and Application Security and Privacy, CODASPY, New Orleans, LA, USA, March 9–11, pp. 85-96, (2016); Wu F., Wang J., Liu J., Wang W., Vulnerability detection with deep learning, In: 2017 3Rd IEEE International Conference on Computer and Communications (ICCC), Pp, pp. 1298-1302, (2017); Li Z., Zou D., Sysevr: A Framework for Using Deep Learning to Detect Software Vulnerabilities, (2018); Li Z., Zou D., Et al., Vuldeepecker: A deep learning-based system for vulnerability detection, In: 25Th Annual Network and Distributed System Security Symposium, NDSS, San Diego, pp. 18-21, (2018); Srikant S., Lesimple N., O'Reilly U., Dependency-Based Neural Representations for Classifying Lines of Programs, (2020); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, 4Th International Conference on Learning Representations, ICLR, San Juan, pp. 2-4, (2016); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5Th International Conference on Learning Representations, ICLR, Toulon, pp. 24-26, (2017); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, IEEE Conference on Computer Vision and Pattern Recognition, CVPR, Boston, MA, USA, June, 7-12, pp. 3431-3440, (2015); Zheng W., Gao J., Et al., The impact factors on the performance of machine learning-based vulnerability detection: a comparative study, J Syst Softw, (2020); Cho K., van Merrienboer B., Et al., Learning phrase representations using RNN encoder-decoder for statistical machine translation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25–29, 2014, pp. 1724-1734, (2014); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, In: 6Th International Conference on Learning Representations, ICLR, Vancouver, BC, Canada, April 30–May 3, (2018); Zhou Y., Liu S., Et al., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, In: Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems, Neurips 2019, December 8–14, 2019, pp. 10197-10207, (2019); Rabheru R., Hanif H., Maffeis S., A Hybrid Graph Neural Network Approach for Detecting PHP Vulnerabilities, (2020); Wang H., Ye G., Et al., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans Inf Forensics Secur, 16, pp. 1943-1958, (2021); Cheng X., Wang H., Et al., Static detection of control-flow-related vulnerabilities using graph embedding, 24Th International Conference on Engineering of Complex Computer Systems. ICECCS 2019, Guangzhou, China, November 10–13, pp. 41-50, (2019); Cao S., Sun X., Bo L., Wei Y., Li B., Bgnn4vd: constructing bidirectional graph neural-network for vulnerability detection, Inf Softw Technol, 136, (2021); Wu Y., Lu J., Zhang Y., Jin S., Vulnerability detection in C/C++ source code with graph representation learning, 11Th IEEE Annual Computing and Communication Workshop and Conference, CCWC, Las Vegas, NV, USA, January, 27-30, pp. 1519-1524, (2021); Lee J., Lee I., Kang J., Self-attention graph pooling, Proceedings of the 36Th International Conference on Machine Learning, ICML, 9–15 June 2019, Long Beach, California, USA, 97, pp. 3734-3743, (2019); Yamaguchi F., Joern; Russell L.K.R., Common Vulnerabilities and Exposures; Russell R.L., Kim L.Y., Hamilton L.H., Lazovich T., Harer J., Ozdemir O., Ellingwood P.M., McConley M.W., Automated vulnerability detection in source code using deep representation learning, 17Th IEEE International Conference on Machine Learning and Applications. ICMLA 2018, Orlando, FL, USA, December 17–20, pp. 757-762, (2018); Yang Z., Yang D., Et al., Hierarchical attention networks for document classification, NAACL HLT, the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, San Diego California, USA, June, 12-17, pp. 1480-1489, (2016); Lin G., Zhang J., Luo W., Pan L., de Vel O.Y., Montague P., Xiang Y., Software vulnerability discovery via learning multi-domain knowledge bases, IEEE Trans Depend Secur Comput, 18, 5, pp. 2469-2485, (2021)",,,,,,English,Article,Final,,Scopus,2-s2.0-85152895909,58
Zhang C.; Yu T.; Liu B.; Xin Y.,"Zhang, Chunyong (57776483000); Yu, Tianxiang (57698956000); Liu, Bin (57858931200); Xin, Yang (23479035200)",57776483000; 57698956000; 57858931200; 23479035200,Vulnerability detection based on federated learning,2024,Information and Software Technology,167,,107371,,,,0,10.1016/j.infsof.2023.107371,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178012067&doi=10.1016%2fj.infsof.2023.107371&partnerID=40&md5=a4a4d156a7de399955acc40c2eb449b6,"Context: Detecting potential vulnerabilities is a key step in defending against network attacks. However, manual detection is time-consuming and requires expertise. Therefore, vulnerability detection must require automated techniques. Objective: Vulnerability detection methods based on deep learning need to rely on sufficient vulnerable code samples. However, the problem of code islands has not been extensively researched. For example, in the case of multi-party vulnerability data, how to securely combine multi-party data to improve vulnerability detection performance. From the perspectives of data augmentation and data security, we propose a vulnerability detection framework based on federated learning (VDBFL). VDBFL is a new model for vulnerability code detection that combines multi-party data. Method: Firstly, VDBFL utilizes the code property graph as a code representation. The code property graph contains various semantic dependencies of the code. Secondly, VDBFL utilizes graph neural networks and convolutional neural networks as the code feature extractor. VDBFL utilizes the jump-structured graph attention network to aggregate node information of important neighbors. Finally, VDBFL utilizes horizontal federated learning to train a local vulnerability detection model for the client. Result: In the real world, VDBFL improves F1-Score by 37.4% compared to the vulnerability detection method Reveal. Among the 5401 vulnerability samples, VDBFL detected 11.8 times more vulnerabilities than Reveal. Conclusion: Under different datasets, VDBFL has shown better performance than advanced vulnerability detection methods in multiple metrics. In addition, the federated learning stage of VDBFL can be expanded on top of the feature extraction stage of any vulnerable detection method. © 2023","Jang-Jaccard J., Nepal S., A survey of emerging threats in cybersecurity, J. Comput. System Sci., 80, 5, pp. 973-993, (2014); Ghaffarian S.M., Shahriari H.R., Software vulnerability analysis and discovery using machine-learning and data-mining techniques: A survey, ACM Comput. Surv., 50, 4, pp. 1-36, (2017); Liu B., Shi L., Cai Z., Li M., Software vulnerability discovery techniques: A survey, 2012 Fourth International Conference on Multimedia Information Networking and Security, pp. 152-156, (2012); Lin G., Wen S., Han Q.-L., Zhang J., Xiang Y., Software vulnerability detection using deep neural networks: a survey, Proc. IEEE, 108, 10, pp. 1825-1848, (2020); Le T.H.M., Chen H., Babar M.A., A survey on data-driven software vulnerability assessment and prioritization, ACM Comput. Surv., 55, 5, pp. 1-39, (2022); Chess B., Gerschefske M., Rough auditing tool for security. Google code, (2013); David A., Ramos, Dawson Engler, {Under-Constrained} Symbolic Execution: Correctness Checking for Real Code, pp. 49-64, (2015); Xie T., Tillmann N., De Halleux J., Schulte W., Fitness-guided path exploration in dynamic symbolic execution, 2009 IEEE/IFIP International Conference on Dependable Systems & Networks, pp. 359-368, (2009); Humphries A., Cating-Subramanian K., Reiter M.K., TASE: Reducing latency of symbolic execution with transactional memory, (2019); Sutton M., Greene A., Amini P., Fuzzing: Brute Force Vulnerability Discovery, (2007); Gan S., Zhang C., Qin X., Tu X., Li K., Pei Z., Chen Z., Collafl: Path sensitive fuzzing, 2018 IEEE Symposium on Security and Privacy, SP, pp. 679-696, (2018); Aloraini B., Nagappan M., German D.M., Hayashi S., Higo Y., An empirical study of security warnings from static application security testing tools, J. Syst. Softw., 158, (2019); Cheng X., Wang H., Hua J., Xu G., Sui Y., Deepwukong: Statically detecting software vulnerabilities using deep graph neural network, ACM Trans. Softw. Eng. Methodol., 30, 3, pp. 1-33, (2021); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, (2018); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: A framework for using deep learning to detect software vulnerabilities, IEEE Trans. Dependable Secure Comput., (2021); Zou D., Wang S., Xu S., Li Z., Jin H., μ VulDeePecker: A deep learning-based system for multiclass vulnerability detection, IEEE Trans. Dependable Secure Comput., 18, 5, pp. 2224-2236, (2019); Zou D., Hu Y., Li W., Wu Y., Zhao H., Jin H., MVulPreter: A multi-granularity vulnerability detection system with interpretations, IEEE Trans. Dependable Secure Comput., (2022); Lin G., Zhang J., Luo W., Pan L., Xiang Y., De Vel O., Montague P., Cross-project transfer representation learning for vulnerable function discovery, IEEE Trans. Ind. Inform., 14, 7, pp. 3289-3297, (2018); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, pp. 590-604, (2014); Cao S., Sun X., Bo L., Wei Y., Li B., Bgnn4vd: constructing bidirectional graph neural-network for vulnerability detection, Inf. Softw. Technol., 136, (2021); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Adv. Neural Inf. Process. Syst., 32, (2019); Wang H., Ye G., Tang Z., Tan S.H., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans. Inf. Forensics Secur., 16, pp. 1943-1958, (2020); pp. 111-123, (2020); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet, IEEE Trans. Softw. Eng., (2021); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, (2015); pp. 4665-4671, (2019); Zheng W., Jiang Y., Su X., VulSPG: Vulnerability detection based on slice property graph representation learning, (2021); Li M., Li C., Li S., Wu Y., Zhang B., Wen Y., ACGVD: Vulnerability detection based on comprehensive graph via graph neural network with attention, International Conference on Information and Communications Security, pp. 243-259, (2021); An W., Chen L., Wang J., Du G., Shi G., Meng D., AVDHRAM: Automated vulnerability detection based on hierarchical representation and attention mechanism, 2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking, ISPA/BDCloud/SocialCom/SustainCom, pp. 337-344, (2020); Hin D., Kan A., Chen H., Babar M.A., LineVD: Statement-level vulnerability detection using graph neural networks, (2022); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); Zhang C., Xie Y., Bai H., Yu B., Li W., Gao Y., A survey on federated learning, Knowl.-Based Syst., 216, (2021); AbdulRahman S., Tout H., Ould-Slimane H., Mourad A., Talhi C., Guizani M., A survey on federated learning: The journey from centralized to distributed on-site learning and beyond, IEEE Internet Things J., 8, 7, pp. 5476-5497, (2020); Yang Q., Liu Y., Chen T., Tong Y., Federated machine learning: Concept and applications, ACM Trans. Intell. Syst. Technol., 10, 2, pp. 1-19, (2019); (2016); Zheng Y., Pujar S., Lewis B., Buratti L., Epstein E., Yang B., Laredo J., Morari A., Su Z., D2a: A dataset built for ai-based vulnerability detection methods using differential analysis, 2021 IEEE/ACM 43rd International Conference on Software Engineering: Software Engineering in Practice, ICSE-SEIP, pp. 111-120, (2021); Hanzely F., Richtarik P., Federated learning of a mixture of global and local models, (2020); Mitra S., Avra L.J., McCluskey E.J., Scan synthesis for one-hot signals, Proceedings International Test Conference 1997, pp. 714-722, (1997); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, (2013); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE International Conference on Machine Learning and Applications, ICMLA, pp. 757-762, (2018); Chawla N.V., Bowyer K.W., Hall L.O., Kegelmeyer W.P., SMOTE: synthetic minority over-sampling technique, J. Artificial Intelligence Res., 16, pp. 321-357, (2002); Barua S., Islam M.M., Yao X., Murase K., MWMOTE–majority weighted minority oversampling technique for imbalanced data set learning, IEEE Trans. Knowl. Data Eng., 26, 2, pp. 405-425, (2012); pp. 225-228, (2016); Jiang Y., Konecny J., Rush K., Kannan S., Improving federated learning personalization via model agnostic meta learning, (2019); Van Hove P.L., Silhouette-Slice Theorems: Technical Report, (1986); pp. 178-182, (2022); Van der Maaten L., Hinton G., Visualizing data using t-sne, J. Mach. Learn. Res., 9, 11, (2008); Mao C., Zhong Z., Yang J., Vondrick C., Ray B., Metric learning for adversarial robustness, Adv. Neural Inf. Process. Syst., 32, (2019); Cheng X., Nie X., Li N., Wang H., Zheng Z., Sui Y., How about bug-triggering paths?-understanding and characterizing learning-based vulnerability detectors, IEEE Trans. Dependable Secure Comput., (2022); pp. 519-531, (2022); pp. 2365-2376, (2022); Le Q., Mikolov T., Distributed representations of sentences and documents, International Conference on Machine Learning, pp. 1188-1196, (2014); Moghadasi M.N., Zhuang Y., Sent2vec: A new sentence embedding representation with sentimental semantic, 2020 IEEE International Conference on Big Data, Big Data, pp. 4672-4680, (2020); Ben-Nun T., Jakobovits A.S., Hoefler T., Neural code comprehension: A learnable representation of code semantics, Adv. Neural Inf. Process. Syst., 31, pp. 3588-3600, (2018); Li Y., Wang S., Nguyen T.N., Vulnerability detection with fine-grained interpretations, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 292-303, (2021); Arivazhagan M.G., Aggarwal V., Singh A.K., Choudhary S., Federated learning with personalization layers, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85178012067,59
Tang M.; Tang W.; Gui Q.; Hu J.; Zhao M.,"Tang, Mingwei (36163501500); Tang, Wei (57712377000); Gui, Qingchi (58660143700); Hu, Jie (57194794887); Zhao, Mingfeng (55477805500)",36163501500; 57712377000; 58660143700; 57194794887; 55477805500,A vulnerability detection algorithm based on residual graph attention networks for source code imbalance (RGAN),2024,Expert Systems with Applications,238,,122216,,,,1,10.1016/j.eswa.2023.122216,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174739465&doi=10.1016%2fj.eswa.2023.122216&partnerID=40&md5=94e2526ac216a9a47dc35d30db8111a8,"It is essential to detect potential vulnerabilities in software to ensure its safety. As software systems become more complex, traditional static vulnerability detection methods perform poorly. Currently, deep learning-based vulnerability detection models only extract source code vulnerability features using sequences or graphs. Sequential neural networks ignore structural information in the code, such as control flow diagrams and data flow diagrams. Additionally, graph neural networks cannot accurately extract features due to the lack of effective methods for extracting nodes’ features and aggregating global information. To address the above issue, we propose a vulnerability detection algorithm based on residual graph attention networks for source code imbalance (RGAN). Firstly, a local feature extraction module (PE-BL-A module) is designed. Using the sequence neural network, the module extracts various useful features, including node features in a control flow diagram based on local semantic features. Secondly, we present the Residual Graph Attention Network module (RGAT). To learn and update node features along the control flow direction, the module uses a graph attention network with residual connections. In this module, a mean biaffine attention pooling mechanism is proposed that can extract total graph vulnerability features more effectively. Thirdly, a dynamic cross-entropy loss function is designed. Using this function, it can handle sample imbalances during training. Finally, experiments conducted on several benchmark datasets demonstrate that the proposed model achieves state-of-the-art results. © 2023","Ahmad W.U., Chakraborty S., Ray B., Chang K., (2021); American Information Technology Laboratory W.U., National Vulnerability Database[EB/OL], (2023); Brown T., Mann B., Ryder N., Subbiah M., Kaplan J.D., Dhariwal P., Et al., Language models are few-shot learners, Advances in Neural Information Processing Systems, 33, pp. 1877-1901, (2020); Buratti L., Pujar S., Bornea M., McCarley S., Zheng Y., Rossiello G., Et al., Exploring software naturalness through neural language models, (2020); Cao S., Sun X., Bo L., Wu R., Li B., Tao C., MVD: Memory-related vulnerability detection based on flow-sensitive graph neural networks, Proceedings - International conference on software engineering, vol. 2022-May, pp. 1456-1468, (2022); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet?, IEEE Transactions on Software Engineering, 48, 9, pp. 3280-3296, (2022); Chawla N.V., Bowyer K.W., Hall L.O., Kegelmeyer W.P., SMOTE: synthetic minority over-sampling technique, Journal of Artificial Intelligence Research, 16, pp. 321-357, (2002); Chen M., Tworek J., Jun H., Yuan Q., Pinto H.P.D.O., Kaplan J., Et al., Evaluating large language models trained on code, (2021); Cheng X., Wang H., Hua J., Xu G., Sui Y., DeepWukong: Statically detecting software vulnerabilities using deep graph neural network, ACM Transactions on Software Engineering and Methodology, 30, 3, (2021); Cui J., Zong L., Xie J., Tang M., A novel multi-module integrated intrusion detection system for high-dimensional imbalanced data, Applied Intelligence, 53, 1, pp. 272-288, (2023); Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-training of deep bidirectional transformers for language understanding, Proceedings of the 2019 conference of the North American chapter of the Association for Computational Linguistics: Human language technologies, pp. 4171-4186, (2019); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Et al., CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, Findings of ACL, EMNLP 2020, pp. 1536-1547, (2020); FreeBuf Network Security Industry Portal Z., Zero to One takes you deeper into the log4j2 Jndi RCE CVE-2021-44228 vulnerability, (2023); Fu C., Chen H., Liu H., Chen X., Tian Y., Koushanfar F., Et al., Coda: An end-to-end neural program decompiler, Advances in Neural Information Processing Systems, 32, (2019); Fu M., Tantithamthavorn C., LineVul: A transformer-based line-level vulnerability prediction, Proceedings - 2022 mining software repositories conference, pp. 608-620, (2022); Guo D., Lu S., Duan N., Wang Y., Zhou M., Yin J., UniXcoder: Unified cross-modal pre-training for code representation, Proceedings of the annual meeting of the Association for Computational Linguistics, pp. 7212-7225, (2022); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Et al., Graphcodebert: Pre-training code representations with data flow, (2020); Hanif H., Maffeis S., VulBERTa: Simplified source code pre-training for vulnerability detection, Proceedings of the International Joint Conference on Neural Networks, vol. 2022-July, (2022); Hin D., Kan A., Chen H., Babar M., (2022); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Khoshnam F., Baraani-Dastjerdi A., A dual framework for implicit and explicit emotion recognition: An ensemble of language models and computational linguistics, Expert Systems with Applications, 198, (2022); Lacomis J., Yin P., Schwartz E., Allamanis M., Le Goues C., Neubig G., Et al., Dire: A neural approach to decompiled identifier naming, 2019 34th IEEE/ACM international conference on automated software engineering, pp. 628-639, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, 4th international conference on learning representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, conference track proceedings, (2016); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Et al., Vuldeepecker: A deep learning-based system for vulnerability detection, (2018); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Et al., RoBERTa: A robustly optimized BERT pretraining approach, (2019); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in Neural Information Processing Systems, 26, (2013); Nguyen V.-A., Nguyen D.Q., Nguyen V., Le T., Tran Q.H., Phung D., (2022); Phan L., Tran H., Le D., Nguyen H., Annibal J., Peltekian A., Et al., CoTexT: Multi-task learning with code-text transformer, Proceedings of the 1st workshop on natural language processing for programming, pp. 40-47, (2021); Roziere B., Lachaux M.-A., Szafraniec M., Lample G., Dobf: A deobfuscation pre-training objective for programming languages, (2021); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Et al., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE international conference on machine learning and applications, pp. 757-762, (2018); Security Guest R., Compilation of domestic and international information leakage cases in 2018[EB/OL], (2023); Uddin Ahmad W., Chakraborty S., Ray B., Chang K.-W., Unified pre-training for program understanding and generation, (2021); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); Wang Y., Wang W., Joty S., Hoi S.C., CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, Proceedings of the 2021 conference on empirical methods in natural language processing, pp. 8696-8708, (2021); Wang X., Wang Y., Mi F., Zhou P., Wan Y., Liu X., Et al., SynCoBERT: Syntax-guided multi-modal contrastive pre-training for code representation, (2021); Yamaguchi F., Schmidt N., Effendi D.B., Joern–the bug hunter's workbench, (2014); Yu J., Bohnet B., Poesio M., (2020); Yu Z., Zheng W., Wang J., Tang Q., Nie S., Wu S., Codecmr: Cross-modal retrieval for function-level binary source code matching, Advances in Neural Information Processing Systems, 33, pp. 3872-3883, (2020); Zhao S., Wen J., Tuan L.A., Zhao J., Fu J., Prompt as triggers for backdoor attack: Examining the vulnerability in language models, (2023); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, 32, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85174739465,60
Fan Y.; Wan C.; Fu C.; Han L.; Xu H.,"Fan, Yuanhai (58184732100); Wan, Chuanhao (58184695600); Fu, Cai (57199741768); Han, Lansheng (12802563500); Xu, Hao (57712794700)",58184732100; 58184695600; 57199741768; 12802563500; 57712794700,VDoTR: Vulnerability detection based on tensor representation of comprehensive code graphs,2023,Computers and Security,130,,103247,,,,6,10.1016/j.cose.2023.103247,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152599286&doi=10.1016%2fj.cose.2023.103247&partnerID=40&md5=b08c018dcb6c1cbaa89c8808b2af2a6c,"Code vulnerability detection has long been a critical issue due to its potential threat to computer systems. It is imperative to detect source code vulnerabilities in software and remediate them to avoid cyber attacks. To automate detection and reduce labor costs, many deep learning-based methods have been proposed. However, these approaches have been found to be either ineffective in detecting multiple classes of vulnerabilities or limited by treating original source code as a natural language sequence without exploiting the structural information of code. In this paper, we propose VDoTR, a model that leverages a new tensor representation of comprehensive code graphs, including AST, CFG, DFG, and NCS, to detect multiple types of vulnerabilities. Firstly, a tensor structure is introduced to represent the structured information of code, which deeply captures code features. Secondly, a new Circle Gated Graph Neural Network (CircleGGNN) is designed based on tensor for hidden state embedding of nodes. CircleGGNN can perform heterogeneous graph information fusion more directly and effectively. Lastly, a 1-D convolution-based output layer is applied to hidden embedding features for classification. The experimental results demonstrate that the detection performance of VDoTR is superior to other approaches with higher accuracy, precision, recall, and F1-measure on multiple datasets for vulnerability detection. Moreover, we illustrate which code graph contributes the most to the performance of VDoTR and which code graph is more sensitive to represent vulnerability features for different types of vulnerabilities through ablation experiments. © 2023","Brito T., Lopes P., Santos N., Santos J.F., Wasmati: an efficient static vulnerability scanner for WebAssembly, Comput. Secur., 118, (2022); Deng F., Fu C., Qian Y., Yang J., He S., Xu H., Federated learning based multi-task feature fusion framework for code expressive semantic extraction, Softw Pract Exper, 52, 8, pp. 1849-1866, (2022); Elleuch H., Dafaoui E., Elmhamedi A., Chabchoub H., Resilience and vulnerability in supply chain: literature review, IFAC-PapersOnLine, 49, 12, pp. 1448-1453, (2016); Fidalgo A., Medeiros I., Antunes P., Neves N., Towards a deep learning model for vulnerability detection on web application variants, 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW), pp. 465-476, (2020); Grieco G., Dinaburg A., Toward smarter vulnerability discovery using machine learning, Proceedings of the 11th ACM Workshop on Artificial Intelligence and Security, pp. 48-56, (2018); Guo N., Li X., Yin H., Gao Y., Vulhunter: an automated vulnerability detection system based on deep learning and bytecode, International Conference on Information and Communications Security, pp. 199-218, (2019); Han Z., Li X., Xing Z., Liu H., Feng Z., Learning to predict severity of software vulnerability using only vulnerability description, 2017 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 125-136, (2017); Hanif H., Nasir M.H.N.M., Ab Razak M.F., Firdaus A., Anuar N.B., The rise of software vulnerability: taxonomy of software vulnerabilities detection and machine learning approaches, J. Netw. Comput. Appl., 179, (2021); Hariyanti E., Djunaidy A., Siahaan D., Information security vulnerability prediction based on business process model using machine learning approach, Comput. Secur., 110, (2021); Jeon S., Kim H.K., Autovas: an automated vulnerability analysis system with a deep learning approach, Comput. Secur., 106, (2021); Jurn J., Kim T., Kim H., An automated vulnerability detection and remediation method for software security, Sustainability, 10, 5, (2018); Kilmer M.E., Martin C.D., Factorization strategies for third-order tensors, Linear Algebra Appl., 435, 3, pp. 641-658, (2011); Kim S., Kim R., Park Y.B., Software vulnerability detection methodology combined with static and dynamic analysis, Wirel. Personal Commun., 89, 3, pp. 777-793, (2016); Kim S., Woo S., Lee H., Oh H., VUDDY: a scalable approach for vulnerable code clone discovery, 2017 IEEE Symposium on Security and Privacy (SP), pp. 595-614, (2017); Kronjee J., Hommersom A., Vranken H., Discovering software vulnerabilities using data-flow analysis and machine learning, Proceedings of the 13th International Conference on Availability, Reliability and Security, pp. 1-10, (2018); Lekies S., Stock B., Johns M., 25 million flows later: large-scale detection of DOM-based XSS, Proceedings of the 2013 ACM SIGSAC Conference on Computer & Communications Security, pp. 1193-1204, (2013); Li X., Wang L., Xin Y., Yang Y., Chen Y., Automated vulnerability detection in source code using minimum intermediate representation learning, Appl. Sci., 10, 5, (2020); Li Y., Tarlow D., Brockschmidt M., Zemel R., (2015); Li Z., Zhou Y., Pr-miner: automatically extracting implicit programming rules and detecting violations in large software code, ACM SIGSOFT Softw. Eng. Notes, 30, 5, pp. 306-315, (2005); Li Z., Zou D., Xu S., Chen Z., Zhu Y., Jin H., Vuldeelocator: a deep learning-based fine-grained vulnerability detector, IEEE Trans. Dependable Secure Comput., (2021); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: a framework for using deep learning to detect software vulnerabilities, IEEE Trans. Dependable Secure Comput., (2021); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., (2018); Liang H., Yang Y., Sun L., Jiang L., JSAC: a novel framework to detect malicious javascript via CNNs over AST and CFG, 2019 International Joint Conference on Neural Networks (IJCNN), pp. 1-8, (2019); Lin G., Xiao W., Zhang J., Xiang Y., Deep learning-based vulnerable function detection: abenchmark, International Conference on Information and Communications Security, pp. 219-232, (2019); Lin G., Zhang J., Luo W., Pan L., De Vel O., Montague P., Xiang Y., Software vulnerability discovery via learning multi-domain knowledge bases, IEEE Trans. Dependable Secure Comput., 18, 5, pp. 2469-2485, (2019); Lin G., Zhang J., Luo W., Pan L., Xiang Y., De Vel O., Montague P., Cross-project transfer representation learning for vulnerable function discovery, IEEE Trans. Ind. Inf., 14, 7, pp. 3289-3297, (2018); Liu D., Wang J., Rong Z., Mi X., Gai F., Tang Y., Wang B., Pangr: a behavior-based automatic vulnerability detection and exploitation framework, 2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE), pp. 705-712, (2018); Liu X., You X., Zhang X., Wu J., Lv P., Tensor graph convolutional networks for text classification, Proceedings of the AAAI Conference on Artificial Intelligence, 34, pp. 8409-8416, (2020); Ma S., Thung F., Lo D., Sun C., Deng R.H., VuRLE: automatic vulnerability detection and repair by learning from examples, European Symposium on Research in Computer Security, pp. 229-246, (2017); Medeiros I., Neves N., Correia M., Dekant: a static analysis tool that learns to detect web application vulnerabilities, Proceedings of the 25th International Symposium on Software Testing and Analysis, pp. 1-11, (2016); Mikolov T., Chen K., Corrado G., Dean J., (2013); Raiyn J., Et al., A survey of cyber attack detection strategies, Int. J. Secur. Appl., 8, 1, pp. 247-256, (2014); Ren J., Zheng Z., Liu Q., Wei Z., Yan H., A buffer overflow prediction approach based on software metrics and machine learning, Secur. Commun. Netw., (2019); Roy C.K., Cordy J.R., Koschke R., Comparison and evaluation of code clone detection techniques and tools: a qualitative approach, Sci. Comput. Program., 74, 7, pp. 470-495, (2009); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 757-762, (2018); Shar L.K., Briand L.C., Tan H.B.K., Web application vulnerability prediction using hybrid program analysis and machine learning, IEEE Trans. Dependable Secure Comput., 12, 6, pp. 688-707, (2014); Shuai B., Li H., Zhang L., Zhang Q., Tang C., Software vulnerability detection based on code coverage and test cost, 2015 11th International Conference on Computational Intelligence and Security (CIS), pp. 317-321, (2015); Sultana K.Z., Williams B.J., Evaluating micro patterns and software metrics in vulnerability prediction, 2017 6th International Workshop on Software Mining (SoftwareMining), pp. 40-47, (2017); Sun H., Cui L., Li L., Ding Z., Hao Z., Cui J., Liu P., Vdsimilar: vulnerability detection based on code similarity of vulnerabilities and patches, Comput. Secur., 110, (2021); Tian J., Xing W., Li Z., Bvdetector: a program slice-based binary code vulnerability intelligent detection system, Inf. Softw. Technol., 123, (2020); Wang X., Wu R., Ma J., Long G., Han J., Research on vulnerability detection technology for web mail system, Procedia Comput. Sci., 131, pp. 124-130, (2018); Wu Z., Pan S., Chen F., Long G., Zhang C., Philip S.Y., A comprehensive survey on graph neural networks, IEEE Trans. Neural Netw. Learn. Syst., 32, 1, pp. 4-24, (2020); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, pp. 590-604, (2014); Yamaguchi F., Maier A., Gascon H., Rieck K., Automatic inference of search patterns for taint-style vulnerabilities, 2015 IEEE Symposium on Security and Privacy, pp. 797-812, (2015); Yan H., Luo S., Pan L., Zhang Y., HAN-BSVD: a hierarchical attention network for binary software vulnerability detection, Comput. Secur., 108, (2021); Yu Z., Theisen C., Williams L., Menzies T., Improving vulnerability inspection efficiency using active learning, IEEE Trans. Softw. Eng., (2019); Zagane M., Abdi M.K., Alenezi M., Deep learning for software vulnerabilities detection using code metrics, IEEE Access, 8, pp. 74562-74570, (2020); Zhao J., Gong R., A new framework of security vulnerabilities detection in PHP web application, 2015 9th International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing, pp. 271-276, (2015); Zhao J., Guo S., Mu D., DouBiGRU-A: software defect detection algorithm based on attention mechanism and double BiGRU, Comput. Secur., 111, (2021); Zheng Z., Zhang B., Liu Y., Ren J., Zhao X., Wang Q., An approach for predicting multiple-type overflow vulnerabilities based on combination features and a time series neural network algorithm, Comput. Secur., 114, (2022); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Adv. Neural Inf. Process. Syst., 32, (2019); Zou D., Wang S., Xu S., Li Z., Jin H., μvuldeepecker: a deep learning-based system for multiclass vulnerability detection, IEEE Trans. Dependable Secure Comput., 18, 5, pp. 2224-2236, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85152599286,61
Sachdeva A.; Lazarine B.; Zhu H.; Samtani S.,"Sachdeva, Agrim (57863264600); Lazarine, Ben (57205675529); Zhu, Hongyi (56304013300); Samtani, Sagar (57188838077)",57863264600; 57205675529; 56304013300; 57188838077,User Profiling and Vulnerability Introduction Prediction in Social Coding Repositories: A Dynamic Graph Embedding Approach: Vulnerability Introduction Prediction in Social Coding Repositories,2023,ACM International Conference Proceeding Series,,,,19,25,6,1,10.1145/3607505.3607512,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171448656&doi=10.1145%2f3607505.3607512&partnerID=40&md5=5e5eed1da91608cfff8e39fbf2bbaef2,"Social Coding Repositories (SCRs) such as GitHub host open-source code that is significant to the global economy. However, open-source code is especially vulnerable, with most vulnerabilities being introduced due to human error. An important mitigation strategy is preventing the introduction of vulnerabilities. One of the ways this can be achieved is through targeted developer security training, which necessitates the identification of high-risk actors and predicting the introduction of vulnerabilities. In this study, we propose a novel framework for predicting the introduction of vulnerabilities in SCRs by users, with a novel dynamic graph representation learning model, security continuous propagation, and evolution (seCoPE). The proposed seCoPE framework addresses the limitations of existing methods by incorporating the relative influence of nodes on the propagation of information to generate high-quality nodal embeddings. We systematically evaluate seCoPE against prevailing Recurrent Neural Network (RNN) based and Attention-based models on a vulnerability introduction dataset. The proposed framework has important implications for cybersecurity providers, firms, and software developers.  © 2023 ACM.","Forsgren N., Ceccarelli G., Jedamski D., Kelly S., Sullivan C., State of the Octoverse: Finding Balance Between Work and Play (2021, (2020); Wen S.-F., Kianpour M., Kowalski S., An Empirical Study Of Security Culture In Open Source Software Communities, 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), pp. 863-870, (2019); Lazarine B., Samtani S., Patton M., Zhu H., Ullman S., Ampel B., Chen H., Identifying Vulnerable Github Repositories And Users In Scientific Cyberinfrastructure: An Unsupervised Graph Embedding Approach, 2020 IEEE International Conference on Intelligence and Security Informatics (ISI), pp. 1-6, (2020); Martinez-Torres M.R., Diaz-Fernandez M.C., Current Issues And Research Trends On Open-Source Software Communities, Technology Analysis & Strategic Management, 26, 1, pp. 55-68, (2014); GitGuardian State of the Secrets Sprawl, (2021); Nord R.L., Ozkaya I., Schwartz E.J., Shull F., Kazman R., Can Knowledge of Technical Debt Help Identify Software Vulnerabilities?, 9th Workshop on Cyber Security Experimentation and Test (CSET 16), (2016); Householder A.D., Chrabaszcz J., Novelly T., Warren D., Spring J.M., Historical analysis of exploit availability timelines, 13th USENIX Workshop on Cyber Security Experimentation and Test (CSET 20), (2020); Stanton B., Theofanos M.F., Prettyman S.S., Furman S., Security Fatigue, IT Professional, 18, 5, pp. 26-32, (2016); Cram W.A., Proudfoot J.G., D'Arcy J., When Enough Is Enough: Investigating The Antecedents And Consequences Of Information Security Fatigue, Information Systems Journal, 31, 4, pp. 521-549, (2021); Vance A., Eargle D., Jenkins J.L., Kirwan C.B., Anderson B.B., The Fog Of Warnings: How Non-Essential Notifications Blur With Security Warnings Fifteenth Symposium on Usable Privacy and Security (SOUPS 2019), pp. 407-420, (2019); Alfadel M., Costa D.E., Shihab E., Mkhallalati M., On the Use of Dependabot Security Pull Requests, IEEE/ACM 18th International Conference on Mining Software Repositories (MSR), pp. 254-265, (2021); Zhou Y., Sharma A., Automated Identification Of Security Issues From Commit Messages And Bug Reports, Proceedings Of The 2017 11th Joint Meeting On Foundations Of Software Engineering, pp. 914-919, (2017); Dahmane M., Foucher S., Combating Insider Threats By User Profiling From Activity Logging Data, 2018 1st International Conference on Data Intelligence and Security (ICDIS), pp. 194-199, (2018); Shahid W.B., Aslam B., Abbas H., Khalid S.B., Afzal H., An Enhanced Deep Learning Based Framework For Web Attacks Detection, Mitigation And Attacker Profiling, Journal of Network and Computer Applications, 198, 2022; Zhang Y., Fan Y., Hou S., Ye Y., Xiao X., Li P., Shi C., Zhao L., Xu S., Cyber-Guided Deep Neural Network For Malicious Repository Detection In Github, 2020 IEEE International Conference on Knowledge Graph (ICKG), pp. 458-465, (2020); Meli M., McNiece M.R., Reaves B., How Bad Can It Git? Characterizing Secret Leakage in Public GitHub Repositories, NDSS, (2019); Yan J., Sun H., Wang X., Liu X., Song X., Profiling Developer Expertise Across Software Communities With Heterogeneous Information Network Analysis, Proceedings of the Tenth Asia-Pacific Symposium on Internetware, pp. 1-9, (2018); Saxena R., Pedanekar N., I Know What You Coded Last Summer: Mining Candidate Expertise From Github Repositories, Companion of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing, pp. 299-302, (2017); Bidoki N.H., Schiappa M., Sukthankar G., Garibay I., Modeling Social Coding Dynamics With Sampled Historical Data, Online Social Networks and Media, 16, 2020; Guo Z., Tang L., Guo T., Yu K., Alazab M., Shalaginov A., Deep Graph Neural Network-Based Spammer Detection Under The Perspective Of Heterogeneous Cyberspace, Future Generation Computer Systems, 117, 2021, pp. 205-218; Sarkar P., Moore A., Dynamic Social Network Analysis Using Latent Space Models, Advances in Neural Information Processing Systems, 18, (2005); Zhang Z., Cui P., Pei J., Wang X., Zhu W., TIMERS: Error-Bounded SVD Restart On Dynamic Networks, Thirty-second AAAI Conference on Artificial Intelligence, (2018); Nguyen G.H., Lee J.B., Rossi R.A., Ahmed N.K., Koh E., Kim S., Continuous-Time Dynamic Network Embeddings Companion, Proceedings of the The Web Conference 2018, pp. 969-976, (2018); Du L., Wang Y., Song G., Lu Z., Wang J., Dynamic Network Embedding: An Extended Approach for Skip-gram based Network Embedding, IJCAI, pp. 2086-2092, (2018); Zhou L., Yang Y., Ren X., Wu F., Zhuang Y., Dynamic Network Embedding By Modeling Triadic Closure Process, Proceedings of the AAAI Conference on Artificial Intelligence, 32, (2018); Trivedi R., Farajtabar M., Biswal P., Zha H., Dyrep: Learning Representations over Dynamic Graphs, International Conference on Learning Representations, (2019); Kumar S., Zhang X., Leskovec J., Predicting Dynamic Embedding Trajectory In Temporal Interaction Networks, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 1269-1278, (2019); Xhonneux L.-P., Qu M., Tang J., Continuous Graph Neural Networks, International Conference on Machine Learning, pp. 10432-10441, (2020); Zhang Y., Xiong Y., Li D., Shan C., Ren K., Zhu Y., CoPE: Modeling Continuous Propagation and Evolution on Interaction Graph, Proceedings of the 30th ACM International Conference on Information & Knowledge Management, 2021, pp. 2627-2636; Ray B., Posnett D., Filkov V., Devanbu P., A Large Scale Study Of Programming Languages And Code Quality In Github, Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 155-165, (2014)",,"16th Cyber Security Experimentation and Test Workshop, CSET 2023",7 August 2023,"Hybrid, Marina Del Rey",191972,English,Conference paper,Final,,Scopus,2-s2.0-85171448656,62
Wang S.; Huang C.; Yu D.; Chen X.,"Wang, Sixuan (58182333800); Huang, Chen (58182057900); Yu, Dongjin (35176839900); Chen, Xin (57102336800)",58182333800; 58182057900; 35176839900; 57102336800,VulGraB: Graph-embedding-based code vulnerability detection with bi-directional gated graph neural network,2023,Software - Practice and Experience,53,8,,1631,1658,27,1,10.1002/spe.3205,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152473653&doi=10.1002%2fspe.3205&partnerID=40&md5=d2796319b2e3f7249116999d618965af,"Code vulnerabilities can have serious consequences such as system attacks and data leakage, making it crucial to perform code vulnerability detection during the software development phase. Deep learning is an emerging approach for vulnerability detection tasks. Existing deep learning-based code vulnerability detection methods are usually based on word2vec embedding of linear sequences of source code, followed by code vulnerability detection through RNNs network. However, such methods can only capture the superficial structural or syntactic information of the source code text, which is not suitable for modeling the complex control flow and data flow and miss edge information in the graph structure constructed by the source code, with limited effect of neural network model. To solve the above problems, this article proposes a code vulnerability detection method, named VulGraB, which is based on graph embedding and bidirectional gated graph neural networks. VulGraB uses node2vec to convert the program-dependent graphs into graph embeddings of the code, which contain rich structure information of the source code, improving the ability of features to express nonlinear information to a certain extent. Then the BiGGNN is used for training, and finally the accuracy of the detection results is evaluated using target program. The bi-directional gated neural network utilizes a bi-directional recurrent structure, which is beneficial to global information aggregation. The experimental results show that the accuracy of VulGraB is significantly improved over the baseline models on two datasets, with F1 scores of 85.89% and 97.24% being the highest, demonstrating that VulGraB consistently outperforms other effective vulnerability detection models. © 2023 John Wiley & Sons Ltd.","Kim S., Woo S., Lee H., Oh H., VUDDY: a scalable approach for vulnerable code clone discovery. Proceedings of the 2017 IEEE Symposium on Security and Privacy; 2017:595-614; Zhang M., de Carnavalet X.D.C., Wang L., Ragab A., Large-scale empirical study of important features indicative of discovered vulnerabilities to assess application security, IEEE Trans Inf Forensic Secur, 14, 9, pp. 2315-2330, (2019); National vulnerability database; 2011; Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., SySeVR: a framework for using deep learning to detect software vulnerabilities, IEEE Trans Dependable Secure Comput, 19, pp. 2244-2258, (2021); Bowman B., Huang H.H., VGRAPH: a robust vulnerable code clone detection system using code property triplets. Proceedings of the 2020 IEEE European Symposium on Security and Privacy; 2020:53-69; Ghaffarian S.M., Shahriari H.R., Neural software vulnerability analysis using rich intermediate graph representations of programs, Inf Sci, 553, pp. 189-207, (2021); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: are we there yet?, IEEE Trans Softw Eng, 48, pp. 3280-3296, (2021); Tian J., Xing W., Li Z., BVDetector: a program slice-based binary code vulnerability intelligent detection system, Inf Softw Technol, 123, (2020); Grover A., Leskovec J., node2vec: scalable feature learning for networks. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; 2016:855-864; Chen Y., Wu L., Zaki M.J., Reinforcement learning based graph-to-sequence model for natural question generation. Proceedings of the 8th International Conference on Learning Representations; 2020; Shen Z., Chen S., A survey of automatic software vulnerability detection, program repair, and defect prediction techniques, Secur Commun Netw, 2020, pp. 1-16, (2020); Letychevskyi O., Hryniuk Y., Machine learning methods for improving vulnerability detection in low-level code. Proceedings of the 2020 IEEE International Conference on Big Data; 2020:5750-5752; Li Y., Wang S., Nguyen T.N., Vulnerability detection with fine-grained interpretations. Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering; 2021:292-303; Wang Z., Zheng Q., Sun Y., GVD-net: graph embedding-based machine learning model for smart contract vulnerability detection. Proceedings of the 2022 International Conference on Algorithms, Data Mining, and Information Technology; 2022:99-103; Cheng X., Wang H., Hua J., Xu G., Sui Y., Deepwukong: statically detecting software vulnerabilities using deep graph neural network, ACM Trans Softw Eng Methodol, 30, 3, pp. 1-33, (2021); Russell R., Kim L., Hamilton L., Et al., Automated vulnerability detection in source code using deep representation learning. Proceedings of the 2018 17th IEEE International Conference on Machine Learning and Applications; 2018:757-762; Maiorca D., Biggio B., Digital investigation of pdf files: unveiling traces of embedded malware, IEEE Secur Priv, 17, 1, pp. 63-71, (2019); (2020); Liu S., Lin G., Qu L., Et al., CD-VulD: cross-domain vulnerability discovery based on deep domain adaptation, IEEE Trans Dependable Secure Comput, 19, pp. 438-451, (2020); Li Z., Zou D., Xu S., Et al., Vuldeepecker: a deep learning-based system for vulnerability detection. Proceedings of the Network and Distributed Systems Security (NDSS) Symposium 2018; 2018; Wang H., Ye G., Tang Z., Et al., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans Inf Forensic Secur, 16, pp. 1943-1958, (2020); Cheng X., Nie X., Li N., Wang H., Zheng Z., Sui Y., How about bug-triggering paths? Understanding and characterizing learning-based vulnerability detectors, IEEE Trans Dependable Secure Comput, 14, 8, pp. 1-18, (2022); Gao H., Wu L., Hu P., Wei Z., Xu F., Long B., Graph-augmented learning to rank for querying large-scale knowledge graph. Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing; 2022:82-92; Wu F., Wang J., Liu J., Wang W., Vulnerability detection with deep learning. Proceedings of the 3rd IEEE International Conference on Computer and Communications; 2017:1298-1302; Zhuang Y., Suneja S., Thost V., Domeniconi G., Morari A., Laredo J., Software vulnerability detection via deep learning over disaggregated code graph representation. CoRR abs/2109.03341; 2021; Grieco G., Grinblat G.L., Uzal L., Rawat S., Feist J., Mounier L., Toward large-scale vulnerability discovery using machine learning. Proceedings of the Sixth ACM Conference on Data and Application Security and Privacy; 2016:85-96; Lin G., Zhang J., Luo W., Et al., Software vulnerability discovery via learning multi-domain knowledge bases, IEEE Trans Dependable Secure Comput, 18, 5, pp. 2469-2485, (2019); Gong X., Xing Z., Li X., Feng Z., Han Z., Joint prediction of multiple vulnerability characteristics through multi-task learning. Proceedings of the 2019 24th International Conference on Engineering of Complex Computer Systems; 2019:31-40; Buch L., Andrzejak A., Learning-based recursive aggregation of abstract syntax trees for code clone detection. Proceedings of the 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering; 2019:95-104; Cheng X., Wang H., Hua J., Et al., Static detection of control-flow-related vulnerabilities using graph embedding. Proceedings of the 2019 24th International Conference on Engineering of Complex Computer Systems (ICECCS); November 2019:41–50; Cheng X., Zhang G., Wang H., Sui Y., Path-sensitive code embedding via contrastive learning for software vulnerability detection. Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis; 2023; Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space. ICLR Workshop Track Proceedings; 2013; Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality. Proceedings of the 26th International Conference on Neural Information Processing Systems, vol. 26; 2013; Yang W., Li L., Zhang Z., Ren X., Sun X., He B., Be careful about poisoned word embeddings: exploring the vulnerability of the embedding layers in NLP models. CoRR abs/2103.15543; 2021; Sui Y., Xue J., Value-flow-based demand-driven pointer analysis for C and C++, IEEE Trans Softw Eng, 46, 8, pp. 812-835, (2020); Sui Y., Cheng X., Zhang G., Wang H., Flow2Vec: value-flow-based precise code embedding, Proc ACM Program Lang, 4, pp. 1-27, (2020); Guo J., Wang Z., Li H., Xue Y., Detecting vulnerability in source code using CNN and LSTM network, Soft Comput, 27, pp. 1131-1141, (2021); Lee Y.J., Choi S.H., Kim C., Lim S., Park K., Learning binary code with deep learning to detect software weakness. Proceedings of the 9th International Conference on Internet (ICONI) 2017 Symposium; 2017; Feng Q., Feng C., Hong W., Graph neural network-based vulnerability predication. Proceedings of the 2020 IEEE International Conference on Software Maintenance and Evolution; 2020:800-801; Wu J., Literature review on vulnerability detection using NLP technology. CoRR abs/2104.11230, 2021; Bilgin Z., Ersoy M.A., Soykan E.U., Tomur E., Comak P., Karacay L., Vulnerability prediction from source code using machine learning, IEEE Access, 8, pp. 150672-150684, (2020); Duan X., Wu J., Ji S., Et al., VulSniper: focus your attention to shoot fine-grained vulnerabilities. Proceedings of the 28th International Joint Conference on Artificial Intelligence; 2019:4665-4671; Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks. Proceedings of the 33rd International Conference on Neural Information Processing Systems, vol. 32; 2019; Shar L.K., Tan H.B.K., Predicting common web application vulnerabilities from input validation and sanitization code patterns. Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering; 2012:310-313; Choi M., Jeong S., Oh H., Choo J., End-to-end prediction of buffer overruns from raw source code via neural memory networks. Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI-17); 2017:1546-1553; Liu S., Xie X., Ma L., Siow J., Liu Y., GraphSearchNet: Enhancing GNNs via capturing global dependency for semantic code search. CoRR abs/2111.02671, 2021; Alexander L., Neural Models of Automated Documentation Generation for Source Code. Dissertation. University of Notre Dame; 2022; Wu B., Liu S., Feng R., Xie X., Siow J., Lin S.W., Enhancing security patch identification by capturing structures in commits, IEEE Trans Dependable Secure Comput, 14, 8, (2022); Yin X., Huang Z., Kan S., Et al., SafeOSL: ensuring memory safety of C via ownership-based intermediate language, Softw Pract Exp, 52, 5, pp. 1114-1142, (2022); Xiao Y., Chen B., Yu C., Et al., MVP: detecting vulnerabilities using patch-enhanced vulnerability signatures. Proceedings of the 29th USENIX Security Symposium; August 12–14, 2020; Woo S., Hong H., Choi E., Lee H., MOVERY: a precise approach for modified vulnerable code clone discovery from modified open-source software components. Proceedings of the 31st USENIX Security Symposium; August 10–12, 2022; Akram J., Luo P., SQVDT: a scalable quantitative vulnerability detection technique for source code security assessment, Softw Pract Exp, 51, pp. 294-318, (2021)",,,,,,English,Article,Final,,Scopus,2-s2.0-85152473653,63
Wang M.; Tao C.; Guo H.,"Wang, Mingke (57788089200); Tao, Chuanqi (36086787600); Guo, Hongjing (57215096241)",57788089200; 36086787600; 57215096241,LCVD: Loop-oriented code vulnerability detection via graph neural network,2023,Journal of Systems and Software,202,,111706,,,,2,10.1016/j.jss.2023.111706,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85157985357&doi=10.1016%2fj.jss.2023.111706&partnerID=40&md5=9d08c9e5a66deffd43cab0392ed9ed3c,"Due to the unique mechanism and complex structure, loops in programs can easily lead to various vulnerabilities such as dead loops, memory leaks, resource depletion, etc. Traditional approaches to loop-oriented program analysis (e.g. loop summarization) are costly with a high rate of false positives in complex software systems. To address the issues above, recent works have applied deep learning (DL) techniques to vulnerability detection. However, existing DL-based approaches mainly focused on the general characteristics of most vulnerabilities without considering the semantic information of specific vulnerabilities. As a typical structure in programs, loops are highly iterative with multi-paths. Currently, there is a lack of available approaches to represent loops, as well as useful methods to extract the implicit vulnerability patterns. Therefore, this paper introduces LCVD, an automated loop-oriented code vulnerability detection approach. LCVD represents the source code as the Loop-flow Abstract Syntax Tree (LFAST), which focuses on interleaving multi-paths around loop structures. Then a novel Loop-flow Graph Neural Network (LFGNN) is proposed to learn both the local and overall structure of loop-oriented vulnerabilities. The experimental results demonstrate that LCVD outperforms the three static analysis-based and four state-of-the-art DL-based vulnerability detection approaches across evaluation settings. © 2023 Elsevier Inc.","Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings, (2018); Anon M., Common weakness enumeration, (2022); Anon M., Cppchecker, (2022); Anon M., Flawfinder, (2022); Anon M., Joern, (2022); Anon M., National Institute of Standards and Technology, (2022); Anon M., National vulnerability database, (2022); Anon M., NIST Software Assurance Reference Dataset, (2022); Anon M., PyTorch, (2022); Anon M., Rough audit tool for security, (2022); Biere A., Cimatti A., Clarke E.M., Strichman O., Zhu Y., Bounded model checking, Handbook of Satisfiability, Vol. 185, No. 99, pp. 457-481, (2009); Cao S., Sun X., Bo L., Wei Y., Li B., BGNN4VD: Constructing bidirectional graph neural-network for vulnerability detection, Inf. Softw. Technol., 136, (2021); Cao S., Sun X., Bo L., Wu R., Li B., Tao C., MVD: memory-related vulnerability detection based on flow-sensitive graph neural networks, 44th IEEE/ACM 44th International Conference on Software Engineering, ICSE 2022, Pittsburgh, PA, USA, May 25-27, 2022, pp. 1456-1468, (2022); Cho K., van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using RNN encoder-decoder for statistical machine translation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pp. 1724-1734, (2014); Cousot P., Cousot R., pp. 238-252, (1977); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, Findings of ACL, pp. 1536-1547, (2020); Fey M., Lenssen J.E., (2019); Godefroid P., Luchaup D., Automatic partial loop summarization in dynamic test generation, Proceedings of the 20th International Symposium on Software Testing and Analysis, pp. 23-33, (2011); Hamilton W.L., Ying Z., Leskovec J., Inductive Representation Learning on Large Graphs, pp. 1024-1034, (2017); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30, 2016, pp. 770-778, (2016); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, (2015); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings, (2017); Kroening D., Sharygina N., Tonetta S., Tsitovich A., Wintersteiger C.M., Loop summarization using state and transition invariants, Form. Methods Syst. Des., 42, 3, pp. 221-261, (2013); Li J., Wang Y., Lyu M.R., King I., Code completion with neural attention and pointer networks, Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, pp. 4159-4165, (2018); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., SySeVR: A framework for using deep learning to detect software vulnerabilities, IEEE Trans. Dependable Secur. Comput., 19, 4, pp. 2244-2258, (2022); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., VulDeePecker: A deep learning-based system for vulnerability detection, 25th Annual Network and Distributed System Security Symposium, NDSS 2018, San Diego, California, USA, February 18-21, 2018, (2018); Lu S., Guo D., Ren S., Huang J., Svyatkovskiy A., Blanco A., Clement C.B., Drain D., Jiang D., Tang D., Li G., Zhou L., Shou L., Zhou L., Tufano M., Gong M., Zhou M., Duan N., Sundaresan N., Deng S.K., Fu S., Liu S., (2021); Lu M., Tan D., Xiong N., Chen Z., Li H., Program classification using gated graph attention neural network for online programming service, CoRR abs/1903.03804, (2019); Mehrotra N., Agarwal N., Gupta P., Anand S., Lo D., Purandare R., Modeling functional similarity in source code with graph-based siamese networks, IEEE Trans. Softw. Eng., 48, 10, pp. 3771-3789, (2022); Mikolov T., Chen K., Corrado G., Dean J., Efficient Estimation of Word Representations in Vector Space, (2013); Mou L., Li G., Jin Z., Zhang L., Wang T., TBCNN: A tree-based convolutional neural network for programming language processing, CoRR abs/1409.5718, (2014); Nguyen V., Nguyen D.Q., Nguyen V., Le T., Tran Q.H., Phung D., ReGVD: Revisiting graph neural networks for vulnerability detection, 44th IEEE/ACM International Conference on Software Engineering: Companion Proceedings, ICSE Companion 2022, Pittsburgh, PA, USA, May 22-24, 2022, pp. 178-182, (2022); Russell R.L., Kim L.Y., Hamilton L.H., Lazovich T., Harer J., Ozdemir O., Ellingwood P.M., McConley M.W., Automated vulnerability detection in source code using deep representation learning, 17th IEEE International Conference on Machine Learning and Applications, pp. 757-762, (2018); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Trans. Neural Netw., 20, 1, pp. 61-80, (2009); Sharma R., Dillig I., Dillig T., Aiken A., Simplifying loop invariant generation using splitter predicates, Computer Aided Verification - 23rd International Conference, CAV 2011, Snowbird, UT, USA, July 14-20, 2011. Proceedings, Lecture Notes in Computer Science, 6806, pp. 703-719, (2011); Siow J.K., Liu S., Xie X., Meng G., Liu Y., Learning program semantics with code representations: An empirical study, IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022, Honolulu, HI, USA, March 15-18, 2022, pp. 554-565, (2022); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Adv. Neural Inf. Process. Syst., 30, (2017); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30–May 3, 2018, Conference Track Proceedings, (2018); Wang Y., Li H., Code completion by modeling flattened abstract syntax trees as graphs, Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, the Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021, pp. 14015-14023, (2021); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, 27th IEEE International Conference on Software Analysis, Evolution and Reengineering, pp. 261-271, (2020); Xiao X., Li S., Xie T., Tillmann N., Characteristic studies of loop problems for structural test generation via symbolic execution, 2013 28th IEEE/ACM International Conference on Automated Software Engineering, ASE, pp. 246-256, (2013); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, SP 2014, Berkeley, CA, USA, May 18-21, 2014, pp. 590-604, (2014); Yu H., Lam W., Chen L., Li G., Xie T., Wang Q., Neural detection of semantic code clones via tree-based convolution, Proceedings of the 27th International Conference on Program Comprehension, pp. 70-80, (2019); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings of the 41st International Conference on Software Engineering, pp. 783-794, (2019); Zhou Y., Liu S., Siow J.K., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, pp. 10197-10207, (2019); Zou D., Wang S., Xu S., Li Z., Jin H., $\mu$μVulDeePecker: A deep learning-based system for multiclass vulnerability detection, IEEE Trans. Dependable Secur. Comput., 18, 5, pp. 2224-2236, (2021)",,,,,,English,Article,Final,,Scopus,2-s2.0-85157985357,66
Tang W.; Tang M.; Ban M.; Zhao Z.; Feng M.,"Tang, Wei (57712377000); Tang, Mingwei (36163501500); Ban, Minchao (58040198600); Zhao, Ziguo (57705046500); Feng, Mingjun (57551937500)",57712377000; 36163501500; 58040198600; 57705046500; 57551937500,CSGVD: A deep learning approach combining sequence and graph embedding for source code vulnerability detection,2023,Journal of Systems and Software,199,,111623,,,,9,10.1016/j.jss.2023.111623,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147191808&doi=10.1016%2fj.jss.2023.111623&partnerID=40&md5=35cd17dd043c1d9487c1e1b02c7a2420,"In order to secure software, it is critical to detect potential vulnerabilities. The performance of traditional static vulnerability detection methods is limited by predefined rules, which rely heavily on the expertise of developers. Existing deep learning-based vulnerability detection models usually use only a single sequence or graph embedding approach to extract vulnerability features. Sequence embedding-based models ignore the structured information inherent in the code, and graph embedding-based models lack effective node and graph embedding methods. As a result, we propose a novel deep learning-based approach, CSGVD (Combining Sequence and Graph embedding for Vulnerability Detection), which considers function-level vulnerability detection as a graph binary classification task. Firstly, we propose a PE-BL module, which inherits and enhances the knowledge from the pre-trained language model. It extracts the code's local semantic features as node embedding in the control flow graph by using sequence embedding. Secondly, CSGVD uses graph neural networks to extract the structured information of the graph. Finally, we propose a mean biaffine attention pooling, M-BFA, to better aggregate node information as a graph's feature representation. The experimental results show that CSGVD outperforms the existing state-of-the-art models and obtains 64.46% accuracy on the real-world benchmark dataset from CodeXGLUE for vulnerability detection. © 2023 Elsevier Inc.","Ahmad W., Chakraborty S., Ray B., Chang K.-W., Unified pre-training for program understanding and generation, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2655-2668, (2021); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proc. ACM Program. Lang. (PACMPL), 3, (2019); Anon U., National Vulnerability Database, (2022); Anon U., Clang static analyzer, (2022); Anon U., Checkmarx, (2022); Anon U., Coverity, (2022); Anon U., FFmpeg, (2022); Anon U., Flawfinder, (2022); Anon U., Joern - The bug Hunter's workbench, (2022); Anon U., QEMU, (2022); Anon U., RATS, (2022); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet, IEEE Trans. Softw. Eng., (2021); Chawla N.V., Bowyer K.W., Hall L.O., Kegelmeyer W.P., SMOTE: synthetic minority over-sampling technique, J. Artificial Intelligence Res., 16, pp. 321-357, (2002); Cheng X., Wang H.Y., Hua J.Y., Xu G.A., Sui Y.L., DeepWukong: Statically detecting software vulnerabilities using deep graph neural network, ACM Trans. Softw. Eng. Methodol., 30, 3, (2021); Cheng X., Wang H., Hua J., Zhang M., Xu G., Yi L., Sui Y., Static detection of control-flow-related vulnerabilities using graph embedding, 2019 24th International Conference on Engineering of Complex Computer Systems, ICECCS, pp. 41-50, (2019); Clark K., Luong M.-T., Le Q.V., Manning C.D., ELECTRA: Pre-training text encoders as discriminators rather than generators, 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26–30, 2020, (2020); Coimbra D., Reis S., Abreu R., Pasareanu C., Erdogmus H., On using distributed representations of source code for the detection of C security vulnerabilities, (2021); Dam H.K., Tran T., Pham T., Ng S.W., Grundy J., Ghose A., Automatic feature learning for vulnerability prediction, (2017); Devlin J., Chang M.-W., Lee K., Toutanova K., BERT: Pre-training of deep bidirectional transformers for language understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Vol. 1 (Long and Short Papers), pp. 4171-4186, (2019); Du X., Chen B., Li Y., Guo J., Zhou Y., Liu Y., Jiang Y., LEOPARD: Identifying vulnerable code for vulnerability assessment through program metrics, 2019 IEEE/ACM 41st International Conference on Software Engineering, ICSE, (2019); Fan J., Li Y., Wang S., Nguyen T.N., A C/C++ code vulnerability dataset with code changes and CVE summaries, Proceedings of the 17th International Conference on Mining Software Repositories, pp. 508-512, (2020); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics, Findings of ACL, vol. EMNLP 2020, pp. 1536-1547, (2020); Fu C., Chen H., Liu H., Chen X., Tian Y., Koushanfar F., Zhao J., Coda: An end-to-end neural program decompiler, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, pp. 3703-3714, (2019); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Deng S.K., Clement C.B., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., GraphCodeBERT: Pre-training code representations with data flow, 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3–7, 2021, (2021); Hin D., Kan A., Chen H., Babar M.A., LineVD: Statement-level vulnerability detection using graph neural networks, 2022 IEEE/ACM 19th International Conference on Mining Software Repositories, MSR, pp. 596-607, (2022); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput., 9, 8, pp. 1735-1780, (1997); Jaffe A., Lacomis J., Schwartz E.J., Goues C.L., Vasilescu B., pp. 20-30, (2018); Jain P., Jain A., Zhang T., Abbeel P., Gonzalez J., Stoica I., Contrastive code representation learning, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 5954-5971, (2021); Kanade A., Maniatis P., Balakrishnan G., Shi K., Learning and Evaluating Contextual Embedding of Source Code, pp. 5110-5121, (2020); Kim Y., Convolutional neural networks for sentence classification, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25–29, 2014, Doha, Qatar, a Meeting of SIGDAT, a Special Interest Group of the ACL, pp. 1746-1751, (2014); Lachaux M.-A., Roziere B., Szafraniec M., Lample G., DOBF: A deobfuscation pre-training objective for programming languages, Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, pp. 14967-14979, (2021); Lacomis J., Yin P., Schwartz E., Allamanis M., Le Goues C., Neubig G., Vasilescu B., Dire: A Neural Approach to Decompiled Identifier Naming, pp. 628-639, (2019); Le Q., Mikolov T., Distributed representations of sentences and documents, Proceedings of the 31st International Conference on Machine Learning, pp. 1188-1196, (2014); Lewis M., Liu Y., Goyal N., Ghazvininejad M., Mohamed A., Levy O., Stoyanov V., Zettlemoyer L., BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 7871-7880, (2020); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, 4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2–4, 2016, Conference Track Proceedings, (2016); Li Y., Wang S., Nguyen T.N., Vulnerability detection with fine-grained interpretations, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 292-303, (2021); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., VulDeePecker: A Deep Learning-Based System for Vulnerability Detection, (2018); Lin G., Wen S., Han Q.-L., Zhang J., Xiang Y., Software vulnerability detection using deep neural networks: A survey, Proc. IEEE, 108, 10, pp. 1825-1848, (2020); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., RoBERTa: A robustly optimized BERT pretraining approach, (2019); Lu S., Guo D., Ren S., Huang J., Svyatkovskiy A., Blanco A., Clement C.B., Drain D., Jiang D., Tang D., Li G., Zhou L., Shou L., Zhou L., Tufano M., Gong M., Zhou M., Duan N., Sundaresan N., Deng S.K., Fu S., Liu S., CodeXGLUE: A machine learning benchmark dataset for code understanding and generation, Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, (2021); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in Neural Information Processing Systems, Vol. 26, (2013); Nguyen V.-A., Nguyen D.Q., Nguyen V., Le T., Tran Q.H., Phung D., ReGVD: Revisiting graph neural networks for vulnerability detection, 2022 IEEE/ACM 44th International Conference on Software Engineering: Companion Proceedings, ICSE-Companion, pp. 178-182, (2022); Phan L., Tran H., Le D., Nguyen H., Annibal J., Peltekian A., Ye Y., CoTexT: Multi-task learning with code-text transformer, Proceedings of the 1st Workshop on Natural Language Processing for Programming, NLP4Prog 2021, pp. 40-47, (2021); Raffel C., Shazeer N., Roberts A., Lee K., Narang S., Matena M., Zhou Y., Li W., Liu P.J., Exploring the limits of transfer learning with a unified text-to-text transformer, J. Mach. Learn. Res., 21, 140, pp. 1-67, (2020); Raychev V., Vechev M.T., Krause A., Predicting program properties from ‘Big Code’, Commun. ACM, 62, 3, pp. 99-107, (2019); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE International Conference on Machine Learning and Applications, ICMLA, pp. 757-762, (2018); Sennrich R., Haddow B., Birch A., Neural machine translation of rare words with subword units, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, Vol. 1: Long Papers, ACL 2016, August 7–12, 2016, Berlin, Germany, (2016); Sui Y., Cheng X., Zhang G., Wang H., Flow2Vec: Value-flow-based precise code embedding, Proc. ACM Program. Lang. (PACMPL), 4, (2020); Svyatkovskiy A., Deng S.K., Fu S., Sundaresan N., pp. 1433-1443, (2020); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings, (2018); Wang Y., Wang W., Joty S., Hoi S.C., CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 8696-8708, (2021); Wang H., Ye G., Tang Z., Tan S.H., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans. Inf. Forensics Secur., 16, pp. 1943-1958, (2021); Xu Z., pp. 1397-1399, (2020); Yu J., Bohnet B., Poesio M., Named entity recognition as dependency parsing, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 6470-6476, (2020); Yu Z., Zheng W., Wang J., Tang Q., Nie S., Wu S., CodeCMR cross-modal retrieval for function-level binary source code matching, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, (2020); Zeng Z., Tan H., Zhang H., Li J., Zhang Y., Zhang L., An extensive study on pre-trained models for program understanding and generation, Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2022, pp. 39-51, (2022); Zheng W., Abdallah Semasaba A.O., Wu X., Agyemang S.A., Liu T., Ge Y., Representation vs. model: What matters most for source code vulnerability detection, 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER, (2021); Zheng Y., Pujar S., Lewis B., Buratti L., Epstein E., Yang B., Laredo J., Morari A., Su Z., D2A: A dataset built for AI-based vulnerability detection methods using differential analysis, 2021 IEEE/ACM 43rd International Conference on Software Engineering: Software Engineering in Practice, ICSE-SEIP, pp. 111-120, (2021); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, Vol. 32, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85147191808,67
Nguyen S.; Vu T.T.; Vo H.D.,"Nguyen, Son (57205025014); Vu, Thanh Trong (58608910700); Vo, Hieu Dinh (55446198800)",57205025014; 58608910700; 55446198800,VFFINDER: A Graph-Based Approach for Automated Silent Vulnerability-Fix Identification,2023,"Proceedings - International Conference on Knowledge and Systems Engineering, KSE",,,,,,,1,10.1109/KSE59128.2023.10299438,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173098270&doi=10.1109%2fKSE59128.2023.10299438&partnerID=40&md5=32132664d3df53b29a7ef7891aaaeca6,"The increasing reliance of software projects on third-party libraries has raised concerns about the security of these libraries due to hidden vulnerabilities. Managing these vul-nerabilities is challenging due to the time gap between fixes and public disclosures. Moreover, a significant portion of open-source projects silently fix vulnerabilities without disclosure, impacting vulnerability management. Existing tools like OWASP heavily rely on public disclosures, hindering their effectiveness in detecting unknown vulnerabilities. To tackle this problem, automated identification of vulnerability-fixing commits has emerged. However, identifying silent vulnerability fixes remains challenging. This paper presents VFFINDER, a novel graph-based approach for automated silent vulnerability fix identification. VFFINDER captures structural changes using Abstract Syntax Trees (ASTs) and represents them in annotated ASTs. VFFINDER distinguishes vulnerability-fixing commits from non-fixing ones using attention-based graph neural network models to extract structural features. We conducted experiments to evaluate VFFINDER on a dataset of 36K+ fixing and non-fixing commits in 507 real-world C/C++ projects. Our results show that VFFINDER significantly improves the state-of-the-art methods by 39-83% in Precision, 19-148% in Recall, and 30%-109% in F1. Especially, VFFINDER speeds up the silent fix identification process by up to 47% with the same review effort of 5% compared to the existing approaches.  © 2023 IEEE.","ISO/IEC 29147, (2018); Householder A.D., Wassermann G., Manion A., King C., The cert guide to coordinated vulnerability disclosure, (2017); Sawadogo A.D., Bissyande T.F., Moha N., Allix K., Klein J., Li L., Le Traon Y., Sspcatcher: Learning to catch security patches, Empirical Software Engineering, 27, 6, (2022); Tal L., The state of open source security report, Snyk, (2019); Ponta S.E., Plate H., Sabetta A., Bezzi M., Dangremont C., A manually-curated dataset of fixes to vulnerabilities of open-source software, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR). IEEE, pp. 383-387, (2019); Zhou J., Pacheco M., Wan Z., Xia X., Lo D., Wang Y., Hassan A.E., Finding a needle in a haystack: Automated mining of silent vulnerability fixes, 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 705-716, (2021); Zhou J., Pacheco M., Chen J., Hu X., Xia X., Lo D., Hassan A.E., Colefunda: Explainable silent vulnerability fix identification, (2023); Nguyen T.G., Le-Cong T., Kang H.J., Widyasari R., Yang C., Zhao Z., Xu B., Zhou J., Xia X., Hassan A.E., Et al., Multi-granularity detector for vulnerability fixes, IEEE Transactions on Software Engineering, (2023); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Dong J., Lou Y., Zhu Q., Sun Z., Li Z., Zhang W., Hao D., Fira: fine-grained graph-based code change representation for automated commit message generation, Proceedings of the 44th International Conference on Software Engineering, pp. 970-981, (2022); Casanova P.V.G.C.A., Lio A.R.P., Bengio Y., Graph attention networks, ICLR. Petar Velickovic Guillem Cucurull Arantxa Casanova Adriana Romero Pietro Lio and Yoshua Bengio, (2018); Ni C., Wang W., Yang K., Xia X., Liu K., Lo D., The best of both worlds: integrating semantic features with expert features for defect prediction and localization, Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 672-683, (2022); Pornprasit C., Tantithamthavorn C.K., Jitline: A simpler, better, faster, finer-grained just-in-time defect prediction, 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR). IEEE, pp. 369-379, (2021); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, 1st International Conference on Learning Representations, ICLR 2013, (2013); Ding Z., Li H., Shang W., Chen T.-H.P., Can pre-trained code embeddings improve model performance? revisiting the use of code embeddings in software engineering tasks, Empirical Software Engineering, 27, 3, pp. 1-38, (2022); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, International Conference on Learning Representations, (2016); Chen J., Ma T., Xiao C., Fastgcn: fast learning with graph convolutional networks via importance sampling, (2018); Bhandari G., Naseer A., Moonen L., Cvefixes: Automated collection of vulnerabilities and their fixes from open-source software, Proceedings of the 17th International Conference on Predictive Models and Data Analytics in Software Engineering, pp. 30-39, (2021); Fan J., Li Y., Wang S., Nguyen T.N., A c/c++code vulnerability dataset with code changes and cve summaries, Proceedings of the 17th International Conference on Mining Software Repositories, pp. 508-512, (2020); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in neural information processing systems, 32, (2019); Zeng Z., Zhang Y., Zhang H., Zhang L., Deep just-in-time defect prediction: how far are we?, Proceedings of the 30th International Symposium on Software Testing and Analysis, pp. 427-438, (2021); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy. IEEE, pp. 590-604, (2014); Hoang T., Dam H.K., Kamei Y., Lo D., Ubayashi N., Deepjit: An end-to-end deep learning framework for just-in-time defect prediction, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR). IEEE, pp. 34-45, (2019); Nguyen S., Phan H., Le T., Nguyen T.N., Suggesting natural method names to check name consistencies, 2020 42nd International Conference on Software Engineering. IEEE, pp. 1372-1384, (2020); Nguyen S., Nguyen T., Li Y., Wang S., Combining program analysis and statistical language model for code statement completion, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 710-721, (2019); Nguyen S., Manh C.T., Tran K.T., Nguyen T.M., Nguyen T.-T., Ngo K.-T., Vo H.D., Arist: An effective api argument recommendation approach, Journal of Systems and Software, (2023); Gvero T., Kuncak V., Synthesizing java expressions from freeform queries, Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications, pp. 416-432, (2015); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, 2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC). IEEE, pp. 200-20010, (2018); Liu Z., Xia X., Treude C., Lo D., Li S., Automatic generation of pull request descriptions, 34th IEEE/ACM International Conference on Automated Software Engineering. IEEE, pp. 176-188, (2019); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2073-2083, (2016); Mastropaolo A., Scalabrino S., Cooper N., Palacio D.N., Poshyvanyk D., Oliveto R., Bavota G., Studying the usage of text-to-text transfer transformer to support code-related tasks, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, pp. 336-347, (2021); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Li L., Feng H., Zhuang W., Meng N., Ryder B., Cclearner: A deep learning-based clone detection approach, International Conference on Software Maintenance and Evolution. IEEE, pp. 249-260, (2017); Godefroid P., Peleg H., Singh R., Learn&fuzz: Machine learning for input fuzzing, 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 50-59, (2017); Nguyen H.A., Phan H.D., Khairunnesa S.S., Nguyen S., Yadavally A., Wang S., Rajan H., Nguyen T., A hybrid approach for inference between behavioral exception api documentation and implementations, and its applications, 37th IEEE/ACM International Conference on Automated Software Engineering, pp. 1-13, (2022); Li Y., Wang S., Nguyen T.N., Van Nguyen S., Improving bug detection via context-based code representation learning and attentionbased neural networks, Proceedings of the ACM on Programming Languages, 3, OOPSLA, pp. 1-30, (2019); Nguyen S., Nguyen T.-T., Vu T.T., Do T.-D., Ngo K.-T., Vo H.D., Code-centric learning-based just-in-time vulnerability detection, (2023); Vo H.D., Nguyen S., Can an old fashioned feature extraction and a light-weight model improve vulnerability type identification performance?, Information and Software Technology, 164, (2023); Jiang N., Lutellier T., Tan L., Cure: Code-aware neural machine translation for automatic program repair, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, pp. 1161-1173, (2021); Ding Y., Ray B., Devanbu P., Hellendoorn V.J., Patching as translation: The data and the metaphor, 2020 35th IEEE/ACM International Conference on Automated Software Engineering. IEEE, pp. 275-286, (2020)",Intelligent Integration (INT2); Secure Metric Technology and Partner Key Factor; Vietnam National Cyber Security Technology Corporation (NCS); Vingroup Innovation Foundation (VINIF),"15th International Conference on Knowledge and Systems Engineering, KSE 2023",18 October 2023 through 20 October 2023,"Virtual, Online",194303,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85173098270,68
Yang J.; Ruan O.; Zhang J.,"Yang, Jia (57188768184); Ruan, Ou (55174014200); Zhang, JiXin (57023309200)",57188768184; 55174014200; 57023309200,Tensor-based gated graph neural network for automatic vulnerability detection in source code,2024,Software Testing Verification and Reliability,34,2,e1867,,,,0,10.1002/stvr.1867,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177856805&doi=10.1002%2fstvr.1867&partnerID=40&md5=1a569590b2491578fb19b6dbb6a325d8,"The rapid expansion of smart devices leads to the increasing demand for vulnerability detection in the cyber security field. Writing secure source codes is crucial to protect applications and software. Recent vulnerability detection methods are mainly using machine learning and deep learning. However, there are still some challenges, how to learn accurate source code semantic embedding at the function level, how to effectively perform vulnerability detection using the learned semantic embedding of source code and how to solve the overfitting problem of learning-based models. In this paper, we consider codes as various graphs with node features and propose a tensor-based gated graph neural network called TensorGNN to produce code embedding for function-level vulnerability detection. First, we propose a high-dimensional tensor for combining different code graph representations. Second, inspired by the work of tensor technology, we propose the TensorGNN model to produce accurate code representations using the graph tensor. We evaluate our model on 7 C and C++ large open-source code corpus (e.g. SARD&NVD, Debian, SATE IV, FFmpeg, libpng&LibTiff, Wireshark and Github datasets), which contains 13 types of vulnerabilities. Our TensorGNN model improves on existing state-of-the-art works by 10%–30% on average in terms of vulnerability detection accuracy and F1, while our TensorGNN model needs less training time and model parameters. Specifically, compared with other existing works, our model reduces 25–47 times of the number of parameters and decreases 3–10 times of training time. Results of evaluations show that TensorGNN has better performance while using fewer training parameters and less training time. © 2023 John Wiley & Sons, Ltd.","Wang H., Ye G., Tang Z., Tan S.H., Huang S., Fang D., Et al., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans Inf Forensics Secur, 16, pp. 1943-1958, (2021); Zou D., Wang S., Xu S., Ou X., Jin H., Wang S., $μvuldeepecker: a deep learning-based system for multiclass vulnerability detection, IEEE Trans Dependable Secur Comput, 18, 5, pp. 2224-2236, (2021); Sonnekalb T., Machine-learning supported vulnerability detection in source code, Proceedings of the ACM joint meeting on european software engineering conference and symposium on the foundations of software engineering, ESEC/SIGSOFT FSE 2019, tallinn, estonia, august 26-30, 2019, pp. 1180-1183, (2019); Wang W., Song J., Xu G., Li Y., Wang H., Su C., Contractward: automated vulnerability detection models for ethereum smart contracts, IEEE Trans Netw Sci Eng, 8, 2, pp. 1133-1144, (2021); Hin D., Kan A., Chen H., Babar M.A., LineVD: statement-level vulnerability detection using graph neural networks, (2022); Russell R.L., Kim L.Y., Hamilton L.H., Lazovich T., Harer J., Ozdemir O., Et al., Automated vulnerability detection in source code using deep representation learning, pp. 757-762, (2018); Karampatsis R.-M., Babii H., Robbes R., Sutton C., Janes A., Big code!= big vocabulary, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, (2020); Li J., Wang Y., Lyu M.R., King I., Code completion with neural attention and pointer networks, Proceedings of the twenty-seventh international joint conference on artificial intelligence, IJCAI, pp. 4159-4165, (2018); Liu F., Li G., Zhao Y., Jin Z., Multi-task learning based pre-trained language model for code completion, pp. 473-485, (2020); Tjandra A., Sakti S., Manurung R., Gated recurrent neural tensor network, pp. 448-455, (2016); Zhou Y., Liu S., Siow J.K., Du X., Liu Y., Devign: effective vulnerability identification by learning comprehensive program semantics via graph neural networks, pp. 10197-10207, (2019); Kilmer M.E., Martin C.D., Factorization strategies for third-order tensors, Linear Algebra Appl, 435, 3, pp. 641-658, (2011); Kolda T.G., Bader B.W., Tensor decompositions and applications, SIAM Rev., 51, 3, pp. 455-500, (2009); Cichocki A., Mandic D.P., Tensor decompositions for signal processing applications: from two-way to multiway component analysis, IEEE Signal Process Mag, 32, 2, pp. 145-163, (2015); Ruiz L., Gama F., Ribeiro A., Gated graph recurrent neural networks, IEEE Trans Signal Process, 68, pp. 6303-6318, (2020); Nguyen A.T., Nguyen T.T., Nguyen H.A., Graph-based pattern-oriented, context-sensitive source code completion, 34th international conference on software engineering, ICSE 2012, June 2-9, 2012, Zurich, Switzerland, pp. 69-79, (2012); Grohe M., word2vec, node2vec, graph2vec, X2vec: towards a theory of vector embeddings of structured data, Proceedings of the 39th ACM symposium on principles of database systems, PODS, pp. 1-16, (2020); Cheng L., Shi Q., Towards overfitting avoidance: tuning-free tensor-aided multi-user channel estimation for 3d massive MIMO communications, IEEE J Sel Top Signal Process, 15, 3, pp. 832-846, (2021); Li-mei Z., Li-shan Q., Song-can C., A survey of feature extraction and classifier design based on tensor pattern, J Shandong University (Eng Sci), 39, 1, pp. 6-14, (2009); Jukic A., Filipovic M., Supervised feature extraction for tensor objects based on maximization of mutual information, Pattern Recognit Lett, 34, 13, pp. 1476-1484, (2013); Wu Y., Lu J., Zhang Y., Jin S., Vulnerability detection in C/C++ source code with graph representation learning, pp. 1519-1524, (2021); Lin G., Zhang J., Luo W., Pan L., Xiang Y., POSTER: vulnerability discovery with function representation learning from unlabeled projects, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, CCS 2017, Dallas, TX, USA, October 30 - November 03, 2017, pp. 2539-2541, (2017); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Et al., Vuldeepecker: a deep learning-based system for vulnerability detection, (2018); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, pp. 590-604, (2014); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, (2018); Guo D., Ren S., Lu S., GraphCodeBERT: pre-training code representations with data flow, (2021); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Et al., CodeBERT: a pre-trained model for programming and natural languages, EMNLP, pp. 1536-1547, (2020); Kim S., Woo S., Lee H., Oh H., VUDDY: a scalable approach for vulnerable code clone discovery, pp. 595-614, (2017); Khaire U.M., Dhanalakshmi R., High-dimensional microarray dataset classification using an improved adam optimizer (iadam), J Ambient Intell Humaniz Comput, 11, 11, pp. 5187-5204, (2020); Quoc D.L., Gregor F., Arnautov S., Kunkel R., Bhatotia P., Fetzer C., secureTF: a secure tensorflow framework, (2021); Ratre A., Pankajakshan V., Tucker tensor decomposition-based tracking and gaussian mixture model for anomaly localisation and detection in surveillance videos, IET Comput Vision, 12, 6, pp. 933-940, (2018); Liu X., You X., Zhang X., Tensor graph convolutional networks for text classification, pp. 8409-8416, (2020); Waner S., Introduction to differential geometry and general relativity, (1986); Guo X., Yao Q., Kwok J.T.-Y., Efficient sparse low-rank tensor completion using the Frank-Wolfe algorithm, Proceedings of the thirty-first AAAI conference on artificial intelligence, pp. 1948-1954, (2017); Jaggi M., Revisiting Frank-Wolfe: projection-free sparse convex optimization, Proceedings of the 30th international conference on machine learning, pp. 427-435, (2013); Gidel G., Jebara T., Lacoste-Julien S., Frank-Wolfe algorithms for saddle point problems, Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, 54, pp. 362-371, (2017); Peldszus S., Burger J., Kehrer T., Jurjens J., Ontology-driven evolution of software security, Data Knowl Eng, 134, (2021); Medeiros I., Neves N.F., Correia M., DEKANT: a static analysis tool that learns to detect web application vulnerabilities, Proceedings of the 25th international symposium on software testing and analysis, ISSTA 2016, Saarbrücken, pp. 1-11, (2016); Agosta G., Barenghi A., Parata A., Pelosi G., Automated security analysis of dynamic web applications through symbolic code execution, pp. 189-194, (2012); Lin G., Zhang J., Luo W., Pan L., Xiang Y., De Vel O., Montague P., Cross-project transfer representation learning for vulnerable function discovery, IEEE Trans Ind Inform, 14, 7, pp. 3289-3297, (2018); Zhang Y., Jin D., Xing Y., Gong Y., Automated defect identification via path analysis-based features with transfer learning, J Syst Softw, 166, (2020); Jemal I., Haddar M.A., Cheikhrouhou O., Mahfoudhi A., Malicious http request detection using code-level convolutional neural network, Risks and Security of internet and systems - 15th International Conference, CRiSIS 2020, Paris, France, November 4-6, 2020, Revised Selected Papers, pp. 317-324, (2020); Rong W., Zhang B., Lv X., Malicious web request detection using character-level CNN, Machine learning for cyber security - second international conference, ML4CS 2019, Xi'An, China, september 19-21, 2019, Proceedings, pp. 6-16, (2019); Li Y., Xue Y., Chen H., Wu X., Zhang C., Xie X., Et al., Cerebro: context-aware adaptive fuzzing for effective vulnerability detection, Proceedings of the ACM joint meeting on european software engineering conference and symposium on the foundations of software engineering, ESEC/SIGSOFT FSE 2019, tallinn, estonia, august 26-30, 2019, pp. 533-544, (2019); Chinthanet B., Ponta S.E., Plate H., Sabetta A., Kula R.G., Ishio T., Matsumoto K., Code-based vulnerability detection in node.js applications: how far are we?, pp. 1199-1203, (2020); Duan X., Wu J., Ji S., Rui Z., Luo T., Yang M., Et al., VulSniper: focus your attention to shoot fine-grained vulnerabilities, Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI Macao, China, pp. 4665-4671, (2019); Ye G., Tang Z., Wang H., Fang D., Fang J., Huang S., Wang Z., Deep program structure modeling through multi-relational graph-based learning, pp. 111-123, (2020)",,,,,,English,Article,Final,,Scopus,2-s2.0-85177856805,69
Li W.; Li X.; Feng W.; Jin G.; Liu Z.; Jia J.,"Li, Wei (57225012996); Li, Xiang (56052690000); Feng, Wanzheng (58617158400); Jin, Guanglu (58617430800); Liu, Zhihan (57930885900); Jia, Jing (57221996082)",57225012996; 56052690000; 58617158400; 58617430800; 57930885900; 57221996082,Vulnerability Detection Based on Unified Code Property Graph,2023,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),14094 LNCS,,,359,370,11,0,10.1007/978-981-99-6222-8_30,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172249628&doi=10.1007%2f978-981-99-6222-8_30&partnerID=40&md5=33ae0e4b5456900bb0974d21eb318e95,"As the number of source codes grows rapidly, detecting source code vulnerabilities in current software has become an important study. Most current deep learning-based vulnerability detection technologies treat source code as a sequence, which loses the source code’s structural information, leading to many false positives in the detection results. We propose a novel source code vulnerability detection model, named UCPGVul, based on the Unified Code Property Graph (UCPG). A new graph representation, UCPG, is proposed to extract semantic features from the source code. By extracting features from UCPG, our proposed UCPGVul model can capture more vulnerability features. Experimental results on a publicly available dataset show that UCPGVul can achieve more accurate and stable detection results compared to five state-of-the-art methods. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Feng Z., Guo D., Tang D., Et al., Codebert: A Pre-Trained Model for Programming and Natural Languages. Arxiv Preprint Arxiv, 2002, (2020); Zhou X., Han D.G., Lo D., Assessing generalizability of codebert, 2021 IEEE International Conference on Software Maintenance and Evolution (ICSME), Pp. 425–436. IEEE, (2021); Ahmad W.U., Chakraborty S., Ray B., Et al., Unified Pre-Training for Program Understanding and Generation. Arxiv Preprint Arxiv, 2103, (2021); Zhou W., Junhua W., Code comments generation with data flow-guided transformer, Web Information Systems and Applications: 19Th International Conference, WISA 2022, Dalian, China, September 16–18, 2022, Proceedings, pp. 168-180, (2022); Yamaguchi F., Golde N., Arp D., Et al., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, Pp. 590–604. IEEE, (2014); Ghaffarian S.M., Shahriari H.R., Neural software vulnerability analysis using rich intermediate graph representations of programs, Inf. Sci., 553, pp. 189-207, (2021); Manning C.D., An Introduction to Information Retrieval, Cambridge University Press, (2009); Sahin C.B., Semantic-based vulnerability detection by functional connectivity of gated graph sequence neural networks, Soft Comput, pp. 1-17, (2023); Wi S., Woo S., Whang J.J., Et al., HiddenCPG: Large-scale vulnerable clone detection using subgraph isomorphism of code property graphs. Proc, ACM Web Conf, 2022, pp. 755-766, (2022); Wang H., Ye G., Tang Z., Et al., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans. Inf. Forensics Secur, 16, pp. 1943-1958, (2020); Kim S., Woo S., Lee H., Et al., Vuddy: A scalable approach for vulnerable code clone discovery, IEEE Symposium on Security and Privacy (SP), pp. 595-614, (2017); Li Z., Zou D., Xu S., Et al., Vuldeepecker: A Deep Learning-Based System for Vulnerability Detection. Arxiv Preprint Arxiv, 1801, (2018); Zhou Y., Liu S., Siow J., Et al., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, Vol. 32, (2019); Xu K., Li C., Tian Y., Et al., Representation learning on graphs with jumping knowledge networks, International Conference on Machine Learning. PMLR, Pp. 5453–5462, (2018)",,"Proceedings of the 20th Web Information Systems and Applications Conference, WISA 2023",15 September 2023 through 17 September 2023,Chengdu,300559,English,Conference paper,Final,,Scopus,2-s2.0-85172249628,71
Li X.; Xin Y.; Zhu H.; Yang Y.; Chen Y.,"Li, Xin (57215823563); Xin, Yang (23479035200); Zhu, Hongliang (55717927100); Yang, Yixian (56969151000); Chen, Yuling (37095433600)",57215823563; 23479035200; 55717927100; 56969151000; 37095433600,Cross-domain vulnerability detection using graph embedding and domain adaptation,2023,Computers and Security,125,,103017,,,,5,10.1016/j.cose.2022.103017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145617321&doi=10.1016%2fj.cose.2022.103017&partnerID=40&md5=15b2ba79fa4afd2aa82af96a915df12e,"Vulnerability detection is an effective means to maintain cyberspace security. Machine learning methods have risen much attention in software security due to their advantage of accuracy and automation. However, current researches mainly focus on in-domain vulnerability detection where the training data and test data belong to the same domain. Due to application scenarios, coding habits, and other factors, vulnerabilities in different software projects may obey different probability distributions. This discrepancy compromises the performance of machine learning methods when they are applied to a brand-new project. To address this cold start problem, we propose a cross-domain vulnerability detection framework using graph embedding and deep domain adaption (VulGDA). It works in a variety of cross-domain fashions, including the Zero-Shot fashion that no labeled data in the target domain is available for training. VulGDA is decomposed to graph embedding and domain adaptation. At the graph embedding stage, we transform the samples in source code into graph representations where elements are directly concatenated according to their syntactic and semantic relationships. Then, we aggregate information from neighbors and edges defined in the graph into real-valued vectors. By graph embedding, VulGDA extracts comprehensive vulnerability features and compromises the challenge of long-term dependency. Aiming at the discrepancy between training data and test data, domain adaption is used to train a feature generator. This feature generator maps the graph embedding to a “deep” feature that is discriminative for vulnerability detection, and invariant to the shift between domains. We perform a systematic experiment to validate the effectiveness of VulGDA. The results show that combining graph embedding and deep domain adaptation promotes VulGDA's performance in cross-domain vulnerability detection. Compared with the state-of-the-art methods, our method has better performance under the cold start condition. © 2022","Bissell K., Lasalle R.M., (2022); Chakraborty S., Krishna R., Ding Y., Et al., Deep learning based vulnerability detection: are we there yet, IEEE Trans. Softw. Eng., 48, 9, pp. 3280-3296, (2021); Eriguchi A., Hashimoto K., Tsuruoka Y., Tree-to-sequence attentional neural machine translation, Proceedings of the ACL, Berlin, Germany, pp. 823-833, (2016); Fenton N., Bieman J., Software Metrics: A Rigorous and Practical Approach, (2014); Hanif H., Nasir M.H.N.M., Ab Razak M.F., Firdaus A., Anuar N.B., The rise of software vulnerability: taxonomy of software vulnerabilities detection and machine learning approaches, J. Netw. Comput. Appl., 179, 1, (2021); Hellendoorn V.J., Sutton C., Singh R., Et al., Global relational models of source code, Proceedings of the ICLR, New Orleans, LA, USA, (2019); Hellendoorn V.J., Sutton C., Singh R., Et al., Global relational models of source code, Proceedings of the ICLR, New Orleans, LA, USA, (2020); Hovsepyan A., Scandariato R., Joosen W., Is newer always better?: The case of vulnerability prediction models, Proceedings of the ESEM, Ciudad Real, Spain, pp. 1-26, (2016); (2022); Kalouptsoglou I., Siavvas M., Tsoukalas D., Et al., Cross-project vulnerability prediction based on software metrics and deep learning, Proceedings of the ICCSA, Cagliari, Italy, pp. 877-893, (2020); Lemos R., (2022); Li R., Feng C., Zhang X., Et al., A lightweight assisted vulnerability discovery method using deep neural networks, IEEE Access, 7, pp. 80079-80092, (2019); Li Y., Wang S., Nguyen T.N., Vulnerability Detection with Fine-grained Interpretations, Proceedings of the ESEC/FSE, Tallinn, Estonia, pp. 23-28, (2021); Li Z., Jing X.Y., Wu F., Et al., Cost-sensitive transfer kernel canonical correlation analysis for heterogeneous defect prediction, Autom. Softw. Eng., 25, 2, pp. 201-245, (2018); Li Z., Zou D., Xu S., Et al., Vuldeepecker: a deep learning-based system for vulnerability detection, Proceedings of the NDSS, San Diego, CAN, (2018); Li Z., Zou D., Xu S., Et al., SySeVR: A framework for using deep learning to detect software vulnerabilities, IEEE Trans. Dependable Secure Comput., 19, 4, pp. 2244-2258, (2022); Lin G., Wen S., Han Q.L., Et al., Software vulnerability detection using deep neural networks: a survey, Proc. IEEE, 108, 10, pp. 1825-1848, (2020); Lin G., Zhang J., Luo W., Et al., POSTER: vulnerability discovery with function representation learning from unlabeled projects, Proceedings of the CCS, Dallas, TX, USA, pp. 2539-2541, (2017); Lin G., Zhang J., Luo W., Et al., Software vulnerability discovery via learning multi-domain knowledge bases, IEEE Trans. Dependable Secure Comput., 18, 5, pp. 2469-2485, (2021); Lin G., Zhang J., Luo W., Pan L., Et al., Cross-project transfer representation learning for vulnerable function discovery, IEEE Trans. Ind. Inf., 14, 7, pp. 3289-3297, (2018); Liu S., Lin G., Han Q., Et al., DeepBalance: deep-learning and fuzzy oversampling for vulnerability detection, IEEE Trans. Fuzzy Syst., 28, 7, pp. 1329-1343, (2019); Liu S., Lin G., Qu L., Et al., CD-VulD: cross-domain vulnerability discovery based on deep domain adaptation, IEEE Trans. Dependable Secure Comput., (2020); Morrison P., Herzig K., Murphy B., Williams L., Challenges with applying vulnerability prediction models, Proceedings of the HotSoS, Urbana, IL, USA, pp. 1-4, (2015); Moshtari S., Sami A., Evaluating and comparing complexity, coupling and a new proposed set of coupling metrics in cross-project vulnerability prediction, Proceedings of the SAC, Pisa, Italy, pp. 1415-1421, (2016); Mou L., Li G., Zhang L., Et al., Convolutional neural networks over tree structures for programming language processing, Proceedings of the AAAI, Phoenix, AZ, USA, (2016); Nam J., Pan S.J., Kim S., Transfer defect learning, Proceedings of the ICSE, San Francisco, CA, USA, pp. 382-391, (2013); Narayanan A., Chandramohan M., Venkatesan R., Et al., graph2vec: learning distributed representations of graphs, Proceedings of the MLG, Halifax, Nova Scotia, CAN, (2017); Nguyen V., Le T., Le T., Et al., Deep domain adaptation for vulnerable code function identification, Proceedings of the IJCNN, Budapest, Hungary, pp. 1-8, (2019); Perl H., Dechand S., Smith M., Arp D., Yamaguchi F., VCCFinder: finding potential vulnerabilities in opensource projects to assist code audits, Proceedings of the CCS, Denver, CO, USA, (2015); Phan A.V., Nguyen L.M., Bui L.T., Convolutional neural networks over control flow graphs for software defect prediction, Proceedings of the ICTAI, Boston, MA, USA, pp. 45-52, (2017); (2022); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Et al., Automated vulnerability detection in source code using deep representation learning, Proceedings of the ICMLA, Orlando, FL, USA, (2018); (2022); Shin Y., Williams L., An initial study on the use of execution complexity metrics as indicators of software vulnerabilities, Proceedings of the SESS, Honolulu, HI, USA, pp. 1-7, (2011); Turton W., Mehrotra K., (2021); Vytovtov P., Chuvilin K., Unsupervised classifying of software source code using graph neural networks, Proceedings of the FRUCT, Moscow, Moskovskaya oblast’, Russia, pp. 518-524, (2019); Wang H., Ye G., Tang Z., Et al., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans. Inf. Forensics Secur., 16, pp. 1943-1958, (2021); Wang S., Chollak D., Movshovitz-Attias D., Et al., Bugram: bug detection with n-gram language models, Proceedings of the ASE, Singapore, Singapore, pp. 708-719, (2016); Wang X., Guan Z., Xin W., Et al., Multi-type source code defect detection based on TextCNN, Proceedings of the FCS, Singapore, Singapore, pp. 95-103, (2020); Xu Y., Pan S.J., Xiong H., Et al., A unified framework for metric transfer learning, IEEE Trans. Knowl. Data Eng., 29, 6, pp. 1158-1171, (2017); Zagane M., Abdi M.K., Alenezi M., Deep learning for software vulnerabilities detection using code metrics, IEEE Access, 8, pp. 74562-74570, (2020); Zhang J., Wang X., Zhang H., Et al., A novel neural source code representation based on abstract syntax tree, Proceedings of the ICSE, Montréal, QC, CAN, pp. 783-794, (2019); Zhao D., Wang L., Wang Z., Et al., Virus propagation and patch distribution in multiplex networks: modeling, analysis, and optimal allocation, IEEE Trans. Inf. Forensics Secur., 14, 7, pp. 1755-1767, (2018); Zhao D., Xiao G., Wang Z., Et al., Minimum dominating set of multiplex networks: definition, application, and identification, IEEE Trans. Syst. Man Cybern. Syst., 51, pp. 7823-7837, (2020); Zheng Z., Zhang B., Liu Y., Et al., An approach for predicting multiple-type overflow vulnerabilities based on combination features and a time series neural network algorithm, Comput. Secur., 114, (2022); Zhou Y., Liu S., Siow J.K., Et al., Devign: effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Proceedings of the NeurIPS, Vancouver, BC, CAN, pp. 10197-10207, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85145617321,72
Ni C.; Guo X.; Zhu Y.; Xu X.; Yang X.,"Ni, Chao (57189892547); Guo, Xinrong (58833767100); Zhu, Yan (58839361400); Xu, Xiaodan (58514278700); Yang, Xiaohu (8258116000)",57189892547; 58833767100; 58839361400; 58514278700; 8258116000,Function-Level Vulnerability Detection Through Fusing Multi-Modal Knowledge,2023,"Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023",,,,1911,1918,7,0,10.1109/ASE56229.2023.00084,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179002505&doi=10.1109%2fASE56229.2023.00084&partnerID=40&md5=c4ca6b4d197b1c4cef905dbb95bbf33d,"Software vulnerabilities damage the functionality of software systems. Recently, many deep learning-based approaches have been proposed to detect vulnerabilities at the function level by using one or a few different modalities (e.g., text representation, graph-based representation) of the function and have achieved promising performance. However, some of these existing studies have not completely leveraged these diverse modalities, particularly the underutilized image modality, and the others using images to represent functions for vulnerability detection have not made adequate use of the significant graph structure underlying the images. In this paper, we propose MVulD, a multi-modal-based function-level vulnerability detection approach, which utilizes multi-modal features of the function (i.e., text representation, graph representation, and image representation) to detect vulnerabilities. Specifically, MVulD utilizes a pre-trained model (i.e., UniXcoder) to learn the semantic information of the textual source code, employs the graph neural network to distill graph-based representation, and makes use of computer vision techniques to obtain the image representation while retaining the graph structure of the function. We conducted a large-scale experiment on 25,816 functions. The experimental results show that MVulD improves four state-of-the-art baselines by 30.8%-81.3%, 12.8%-27.4%, 48.8%-115%, and 22.9%-141% in terms of F1-score, Accuracy, Precision, and PR-AUC respectively.  © 2023 IEEE.","(2022); (2022); Backes M., Kopf B., Rybalchenko A., Automatic discovery and quantification of information leaks, 2009 30th IEEE Symposium on Security and Privacy. IEEE, pp. 141-153, (2009); Shankar U., Talwar K., Foster J.S., Wagner D., Detecting format string vulnerabilities with type qualifiers, 10th USENIX Security Symposium (USENIX Security 01), (2001); Shar L.K., Briand L.C., Tan H.B.K., Web application vulnerability prediction using hybrid program analysis and machine learning, IEEE Transactions on dependable and secure computing, 12, 6, pp. 688-707, (2014); Li Y., Wang S., Nguyen T.N., Vulnerability detection with finegrained interpretations, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 292-303, (2021); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, (2018); Lin G., Zhang J., Luo W., Pan L., Xiang Y., Poster: Vulnerability discovery with function representation learning from unlabeled projects, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 2539-2541, (2017); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet, IEEE Transactions on Software Engineering, (2021); Steenhoek B., Rahman M.M., Jiles R., Le W., An empirical study of deep learning models for vulnerability detection, 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE). IEEE, pp. 2237-2248, (2023); Cao S., Sun X., Bo L., Wu R., Li B., Tao C., Mvd: Memory-related vulnerability detection based on flow-sensitive graph neural networks, (2022); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE international conference on machine learning and applications (ICMLA). IEEE, pp. 757-762, (2018); Mou L., Li G., Jin Z., Zhang L., Wang T., Tbcnn: A tree-based convolutional neural network for programming language processing, (2014); Duan X., Wu J., Ji S., Rui Z., Luo T., Yang M., Wu Y., Vulsniper: Focus your attention to shoot fine-grained vulnerabilities., IJCAI, pp. 4665-4671, (2019); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy. IEEE, pp. 590-604, (2014); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in neural information processing systems, 32, (2019); Chen J., Hu K., Yu Y., Chen Z., Xuan Q., Liu Y., Filkov V., Software visualization and deep transfer learning for effective software defect prediction, Proceedings of the ACM/IEEE 42nd international conference on software engineering, pp. 578-589, (2020); Wu Y., Zou D., Dou S., Yang W., Xu D., Jin H., Vulcnn: An image-inspired scalable vulnerability detection system, (2022); Siow J.K., Liu S., Xie X., Meng G., Liu Y., Learning program semantics with code representations: An empirical study, (2022); Guo D., Lu S., Duan N., Wang Y., Zhou M., Yin J., Unixcoder: Unified cross-modal pre-training for code representation, (2022); Liu Z., Hu H., Lin Y., Yao Z., Xie Z., Wei Y., Ning J., Cao Y., Zhang Z., Dong L., Et al., Swin transformer v2: Scaling up capacity and resolution, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 12009-12019, (2022); Rough auditing tool for security (rats), (2022); Yamaguchi F., Maier A., Gascon H., Rieck K., Automatic inference of search patterns for taint-style vulnerabilities, 2015 IEEE Symposium on Security and Privacy. IEEE, pp. 797-812, (2015); Yamaguchi F., Lottmann M., Rieck K., Generalized vulnerability extrapolation using abstract syntax trees, Proceedings of the 28th Annual Computer Security Applications Conference, pp. 359-368, (2012); Neuhaus S., Zimmermann T., Holler C., Zeller A., Predicting vulnerable software components, Proceedings of the 14th ACM conference on Computer and communications security, pp. 529-540, (2007); Dam H.K., Tran T., Pham T., Ng S.W., Grundy J., Ghose A., Automatic feature learning for vulnerability prediction, (2017); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: A framework for using deep learning to detect software vulnerabilities, IEEE Transactions on Dependable and Secure Computing, (2021); Shi B., Bai X., Yao C., An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition, IEEE transactions on pattern analysis and machine intelligence, 39, 11, pp. 2298-2304, (2016); Zhou X., Yao C., Wen H., Wang Y., Zhou S., He W., Liang J., East: An efficient and accurate scene text detector, Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pp. 5551-5560, (2017); Wang W., Xie E., Li X., Hou W., Lu T., Yu G., Shao S., Shape robust text detection with progressive scale expansion network, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9336-9345, (2019); Liao M., Wan Z., Yao C., Chen K., Bai X., Real-time scene text detection with differentiable binarization, Proceedings of the AAAI conference on artificial intelligence, 34, 7, pp. 11474-11481, (2020); Quan T.M., Hildebrand D.G.C., Jeong W.-K., Fusionnet: A deep fully residual convolutional neural network for image segmentation in connectomics, Frontiers in Computer Science, (2021); Badrinarayanan V., Kendall A., Cipolla R., Segnet: A deep convolutional encoder-decoder architecture for image segmentation, IEEE transactions on pattern analysis and machine intelligence, 39, 12, pp. 2481-2495, (2017); Chen L.-C., Zhu Y., Papandreou G., Schroff F., Adam H., Encoderdecoder with atrous separable convolution for semantic image segmentation, Proceedings of the European conference on computer vision (ECCV), pp. 801-818, (2018); Peng C., Zhang X., Yu G., Luo G., Sun J., Large kernel matters-improve semantic segmentation by global convolutional network, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4353-4361, (2017); Pouyanfar S., Sadiq S., Yan Y., Tian H., Tao Y., Reyes M.P., Shyu M.-L., Chen S.-C., Iyengar S.S., A survey on deep learning: Algorithms, techniques, and applications, ACM Computing Surveys (CSUR), 51, 5, pp. 1-36, (2018); (2022); Deng J., Dong W., Socher R., Li L.-J., Li K., Fei-Fei L., Imagenet: A large-scale hierarchical image database, 2009 IEEE conference on computer vision and pattern recognition. Ieee, pp. 248-255, (2009); Smirnov E.A., Timoshenko D.M., Andrianov S.N., Comparison of regularization methods for imagenet classification with deep convolutional neural networks, Aasri Procedia, 6, pp. 89-94, (2014); Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, (2014); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, (2016); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3431-3440, (2015); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical image computing and computer-assisted intervention, pp. 234-241, (2015); Luc P., Couprie C., Chintala S., Verbeek J., Semantic segmentation using adversarial networks, (2016); Lewis M., Liu Y., Goyal N., Ghazvininejad M., Mohamed A., Levy O., Stoyanov V., Zettlemoyer L., Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, (2019); Karampatsis R.-M., Sutton C., Scelmo: Source code embeddings from language models, (2020); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A pre-trained model for programming and natural languages, Proceedings of the Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547; Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, stat, 1050, (2017); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, (2016); Li X., Jiang S., Know more say less: Image captioning based on scene graphs, IEEE Transactions on Multimedia, 21, 8, pp. 2117-2130, (2019); Yang X., Tang K., Zhang H., Cai J., Auto-encoding scene graphs for image captioning, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 10685-10694, (2019); Li K., Zhang Y., Li K., Li Y., Fu Y., Visual semantic reasoning for image-text matching, Proceedings of the IEEE/CVF international conference on computer vision, pp. 4654-4662, (2019); Liu C., Mao Z., Zhang T., Xie H., Wang B., Zhang Y., Graph structured network for image-text matching, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 10921-10930, (2020); Fan J., Li Y., Wang S., Nguyen T.N., Ac/c++ code vulnerability dataset with code changes and cve summaries, Proceedings of the 17th International Conference on Mining Software Repositories, pp. 508-512, (2020)",,"38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023",11 September 2023 through 15 September 2023,Echternach,194295,English,Conference paper,Final,,Scopus,2-s2.0-85179002505,73
Xue J.; Yu Z.; Song Y.; Qin Z.; Sun X.; Wang W.,"Xue, Jintao (57408213600); Yu, Zihan (57209472226); Song, Yubo (23393708100); Qin, Zhongyuan (7202822604); Sun, Xin (57226549021); Wang, Wen (58172111800)",57408213600; 57209472226; 23393708100; 7202822604; 57226549021; 58172111800,VulSAT: Source Code Vulnerability Detection Scheme Based on SAT Structure,2023,"2023 8th International Conference on Signal and Image Processing, ICSIP 2023",,,,639,644,5,0,10.1109/ICSIP57908.2023.10271020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174681667&doi=10.1109%2fICSIP57908.2023.10271020&partnerID=40&md5=6303903a0553b7309b1e4efac7d12f2d,"The number of software vulnerabilities have increased rapidly, and their forms have shown the characteristics of complexity and diversity, which has brought severe challenges to software systems. Deep learning can automatically learn the features of code and is widely used in source code vulnerability detection. Some studies treat codes as text sequences, ignoring the structural relationship between lines of code. Other studies extract the code as a graph structure, but ignore the order relationship of code lines and do not make full use of the dependencies between code lines. This paper proposes a C/C++ source code vulnerability detection scheme based on SAT (Structure-Aware Transformer) structure. It first standardizes the source code, then extracts the PDG (program dependency graph) representation of source code, next convert each node into a vector representation using sentence embedding, which retains the dependencies between nodes. Finally input it into the SAT architecture model for training, and judge whether the input program contains vulnerabilities according to the output results. We compared VulSAT with a variety of vulnerability detection methods (i.e., Devign, SySeVR, VulCNN, Checkmarx, VulDeePecker), and selected C/C++ functions in the SARD vulnerability dataset as experimental objects. The performance of accuracy rate and false positive rate has been improved to a certain extent.  © 2023 IEEE.","Li Z., Zou D.Q., Xu S.H., Et al., VulPecker: An automated vulnerability detection system based on code similarity analysis[C], Proc of the 32nd Annual on Computer Security Applications Conf(ACSAC), pp. 201-213, (2016); Vaswani A., Shazeer N., Parmar N., Et al., Attention is all you need, Advances in Neural Information Processing Systems (NeurIPS); Chen D., Bray L.O., Borgwardt K., Structure-Aware Transformer for Graph Representation Learning, Proceedings of the 39th International Conference on Machine Learning, Proceedings of Machine Learning Research, 2022[C]. PMLR; Zhou Y.Q., Liu S.Q., Siow J.K., Et al., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Proceedings ofthe 2019Advances in Neural Information Processing Systems (NlPS'I9), pp. 10197-10207; Li Z., Zou D.Q., Xu S.H., Et al., SySeVR: A framework for using deep learning to detect software vulnerabilities, IEEE Transactions on Dependable and Secure Computing, pp. 1-15, (2021); Wu Y., Zou D., Dou S., Yang W., Xu D., Jin H., VulCNN: An Image-inspired Scalable Vulnerability Detection System, 2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE), pp. 2365-2376, (2022); (2023); Li Z., Zou D.Q., Xu S.H., Et al., VulDeePecker: A deep learning-based system for vulnerability detection, Proceedings of the 2018 Network and Distributed System Security Symposium (NDSS'I8), pp. 1-15; Software Assurance Reference Dataset, (2023); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, Proc. 38th Int. Conf. Softw. Eng. (ICSE), pp. 297-308, (2016); Lin G., Et al., Cross-project transfer representation learning for vulnerable function discovery, IEEE Trans. Ind. Informat, 14, 7, pp. 3289-3297, (2018); Dam H.K., Tran T., Pham T., Et al., Automatic feature learning for vulnerability prediction, (2017); Yamaguchi F., Golde N., Arp D., Et al., Modeling and Discovering Vulnerabilities with Code Property Graphs[C], IEEE Symposium on Security and Privacy. IEEE, (2014); Yamaguchi F., Golde N., Arp D., Et al., Modeling and discovering vulnerabilities with code property graphs, Proceddings ofthe 20I4fEEE Symposium on Security alld Privacy (S&P'I4), pp. 590-604; Pagliardini M., Gupta P., Jaggi M., Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features, (2017); Dwivedi V.P., Luu A.T., Laurent T., Et al., Graph neural networks with learnable structural and positional representations, International Conference on Learning Representations, (2022); Corso G., Cavalleri L., Beaini D., Et al., Principal Neighbourhood Aggregation for Graph Nets[J], (2020); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks[J], (2016); Xu K., Hu W., Leskovec J., Et al., How powerful are graph neural networks[J], (2018)",Southeast University,"8th International Conference on Signal and Image Processing, ICSIP 2023",8 July 2023 through 10 July 2023,Wuxi,193314,English,Conference paper,Final,,Scopus,2-s2.0-85174681667,74
Ganz T.; Imgrund E.; Härterich M.; Rieck K.,"Ganz, Tom (57368584800); Imgrund, Erik (58554227900); Härterich, Martin (55814005200); Rieck, Konrad (14016551700)",57368584800; 58554227900; 55814005200; 14016551700,CodeGraphSMOTE - Data Augmentation for Vulnerability Discovery,2023,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13942 LNCS,,,282,301,19,1,10.1007/978-3-031-37586-6_17,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169070482&doi=10.1007%2f978-3-031-37586-6_17&partnerID=40&md5=c330a7e55e690a560e961818f726fea0,"The automated discovery of vulnerabilities at scale is a crucial area of research in software security. While numerous machine learning models for detecting vulnerabilities are known, recent studies show that their generalizability and transferability heavily depend on the quality of the training data. Due to the scarcity of real vulnerabilities, available datasets are highly imbalanced, making it difficult for deep learning models to learn and generalize effectively. Based on the fact that programs can inherently be represented by graphs and to leverage recent advances in graph neural networks, we propose a novel method to generate synthetic code graphs for data augmentation to enhance vulnerability discovery. Our method includes two significant contributions: a novel approach for generating synthetic code graphs and a graph-to-code transformer to convert code graphs into their code representation. Applying our augmentation strategy to vulnerability discovery models achieves the same originally reported F1-score with less than 20 % of the original dataset and we outperform the F1-score of prior work on augmentation strategies by up to 25.6 % in detection performance. © 2023, IFIP International Federation for Information Processing.","Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, Arxiv Abs/1711, (2017); Bronstein M.M., Bruna J., Cohen T., Velivckovi'C P., Geometric deep learning: Grids, groups, graphs, geodesics, And Gauges, (2021); Cai T., Luo S., Xu K., He D., Yan Liu T., Wang L., Graphnorm: A Principled Approach to Accelerating Graph Neural Network Training, (2020); Cao S., Sun X., Bo L., Wei Y., Li B., Bgnn4vd: Constructing bidirectional graph neural-network for vulnerability detection, Inf. Softw. Technol., 136, (2021); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet?, IEEE Trans. Softw. Eng. TBD, (2020); Chen D., Lin Y., Li W., Li P., Zhou J., Sun X., Measuring and Relieving the Over-Smoothing Problem for Graph Neural Networks from the Topological View, (2019); Cheng X., Wang H., Hua J., Xu G., Sui Y., DeepWukong: Statically detecting software vulnerabilities using deep graph neural network, ACM Trans. Softw. Eng. Methodol., 30, 3, (2021); Dablain D., Krawczyk B., Chawla N., DeepSMOTE: Fusing deep learning and smote for imbalanced data, IEEE Trans. Neural Netw. Learn. Syst., pp. 1-15, (2022); Dinella E., Dai H., Li Z., Naik M., Song L., Wang K., Hoppity: Learning graph transformations to detect and fix bugs in programs, International Conference on Learning Representations, (2020); Do T.H., Nguyen D.M., Bekoulis G., Munteanu A., Deligiannis N., Graph convolutional neural networks with node transition probability-based message passing and DropNode regularization, Expert Syst. Appl., 174, (2021); Fey M., Lenssen J.E., Fast graph representation learning with PyTorch Geometric, ICLR Workshop on Representation Learning on Graphs and Manifolds, (2019); Ganz T., Harterich M., Warnecke A., Rieck K., Explaining graph neural networks for vulnerability discovery, Proceedings of the 14Th ACM Workshop on Artificial Intelligence and Security, Pp. 145–156, Aisec ’21, New York, NY, USA, (2021); Gao Z., Bhattacharya S., Zhang L., Blum R.S., Ribeiro A., Sadler B.M., Training Robust Graph Neural Networks with Topology Adaptive Edge Dropping, (2021); Gaunt R.E., Products of normal, beta and gamma random variables: Stein operators and distributional theory, Brazilian J. Probab. Stat., 32, 2, pp. 437-466, (2018); Grieco G., Grinblat G.L., Uzal L., Rawat S., Feist J., Mounier L., Toward large-scale vulnerability discovery using machine learning, Proceedings of the Sixth ACM Conference on Data and Application Security and Privacy, Pp. 85–96, CODASPY ’16, New York, NY, USA, (2016); Hagberg A., Swart P., S Chult D., Exploring network structure, dynamics, And Function Using Networkx (1, (2008); Hamilton W.L., Ying R., Leskovec J., Inductive representation learning on large graphs, NIPS, (2017); Han X., Jiang Z., Liu N., Hu X., G-mixup: Graph data augmentation for graph classification, Chaudhuri, K., Jegelka, S., Song, L., Szepesvari, C., Niu, G., Sabato, S. (Eds.) Proceedings of the 39Th International Conference on Machine Learning, Proceedings of Machine Learning Research, Vol. 162, Pp. 8230–8248, PMLR (17–23, (2022); Johnson J.M., Khoshgoftaar T.M., Survey on deep learning with class imbalance, J. Big Data, 6, 1, (2019); Kingma D.P., Welling M., Auto-encoding variational Bayes, Corr Abs/1312, (2014); Kipf T.N., Welling M., Variational graph auto-encoders, NIPS Workshop on Bayesian Deep Learning, (2016); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, International Conference on Learning Representations (ICLR, (2017); Kong K., Et al., Robust optimization as data augmentation for large-scale graphs, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 60-69, (2022); Lewis M., Et al., BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, Proceedings of the 58Th Annual Meeting of the Association for Computational Linguistics, pp. 7871-7880, (2020); Li J., Li J., Liu Y., Yu J., Li Y., Cheng H., Deconvolutional networks on graph data, Advances in Neural Information Processing Systems, (2021); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, Bengio, Y., Lecun, Y., (Eds.) 4Th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2–4, 2016, Conference Track Proceedings, (2016); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: A framework for using deep learning to detect software vulnerabilities, IEEE Trans. Depend. Secure Comput., 19, 4, pp. 2244-2258, (2022); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, 25Th Annual Network and Distributed System Security Symposium, NDSS 2018, San Diego, California, USA, February 18–21, 2018, the Internet Society, (2018); Luo Y., McThrow M., Au W.Y., Komikado T., Uchino K., Maruhashi K., Ji S., Automated Data Augmentations for Graph Classification, (2022); Nijkamp E., Et al., Codegen: An open large language model for code with multi-turn program synthesis, The Eleventh International Conference on Learning Representations, (2023); Nong Y., Ou Y., Pradel M., Chen F., Cai H., Generating realistic vulnerabilities via neural code editing: An empirical study, ESEC/FSE 2022, pp. 1097-1109, (2022); Nt H., Maehara T., Revisiting Graph Neural Networks: All We have is Low-Pass Filters, (2019); Pewny J., Holz T., Evilcoder: Automated bug insertion, Proceedings of the 32Nd Annual Conference on Computer Security Applications, Pp. 214–225, ACSAC ’16, New York, NY, USA, (2016); Rong Y., Huang W., Xu T., Huang J., Dropedge: Towards Deep Graph Convolutional Networks on Node Classification, (2020); Russell R., Et al., Automated Vulnerability Detection in Source Code Using Deep Representation Learning, pp. 757-762, (2018); Sennrich R., Haddow B., Birch A., Improving neural machine translation models with monolingual data, Corr Abs/1511, (2015); Spinelli I., Scardapane S., Hussain A., Uncini A., Biased Edge Dropout for Enhancing Fairness in Graph Representation Learning, (2021); Vaswani A., Et al., Attention is all you need, Advances in Neural Information Processing Systems, 30, (2017); Wang X., Wang S., Feng P., Sun K., Jajodia S., Patchdb: A large-scale security patch dataset, 51St Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pp. 149-160, (2021); Wang Y., Wang W., Liang Y., Cai Y., Hooi B., Graphcrop: Subgraph cropping for graph classification, Corr Abs/2009, (2020); Weiss K., Banse C., A Language-Independent Analysis Platform for Source Code, (2022); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A comprehensive survey on graph neural networks, IEEE Trans. Neural Netw. Learn. Syst., 32, 1, pp. 4-24, (2021); Xu K., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks?, International Conference on Learning Representations, (2019); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, pp. 590-604, (2014); Yao Z., Xu F.F., Yin P., Sun H., Neubig G., Learning structural edits via incremental tree transformations, 9Th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3–7, 2021, Openreview.Net, (2021); Zhao T., Liu G., Gunnemann S., Jiang M., Graph Data Augmentation for Graph Machine Learning: A Survey, (2022); Zhao T., Liu G., Wang D., Yu W., Jiang M., Counterfactual graph learning for link prediction, Corr Abs/2106, (2021); Zhao T., Liu Y., Neves L., Woodford O.J., Jiang M., Shah N., Data augmentation for graph neural networks, AAAI, (2021); Zhao T., Zhang X., Wang S., GraphSMOTE: Imbalanced node classification on graphs with graph neural networks, Proceedings of the 14Th ACM International Conference on Web Search and Data Mining, (2021); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, 32, (2019); Zhu Y., Xu Y., Yu F., Liu Q., Wu S., Wang L., Graph contrastive learning with adaptive augmentation, Proceedings of the Web Conference, 2021, (2021)",,"37th Annual IFIP WG 11.3 Conference on Data and Applications Security and Privacy, DBSec 2023",19 July 2023 through 21 July 2023,Sophia Antipolis,298129,English,Conference paper,Final,,Scopus,2-s2.0-85169070482,76
Wang S.; Wang X.; Sun K.; Jajodia S.; Wang H.; Li Q.,"Wang, Shu (57218712811); Wang, Xinda (57215327301); Sun, Kun (55268467200); Jajodia, Sushil (57190678016); Wang, Haining (56463251600); Li, Qi (58733277600)",57218712811; 57215327301; 55268467200; 57190678016; 56463251600; 58733277600,GraphSPD: Graph-Based Security Patch Detection with Enriched Code Semantics,2023,Proceedings - IEEE Symposium on Security and Privacy,2023-May,,,2409,2426,17,5,10.1109/SP46215.2023.10179479,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166049487&doi=10.1109%2fSP46215.2023.10179479&partnerID=40&md5=7406fabfa206c6c0509c0e2a440c0d44,"With the increasing popularity of open-source software, embedded vulnerabilities have been widely propagating to downstream software. Due to different maintenance policies, software vendors may silently release security patches without providing sufficient advisories (e.g., CVE). This leaves users unaware of security patches and provides attackers good chances to exploit unpatched vulnerabilities. Thus, detecting those silent security patches becomes imperative for secure software maintenance. In this paper, we propose a graph neural network based security patch detection system named GraphSPD, which represents patches as graphs with richer semantics and utilizes a patch-tailored graph model for detection. We first develop a novel graph structure called PatchCPG to represent software patches by merging two code property graphs (CPGs) for the pre-patch and post-patch source code as well as retaining the context, deleted, and added components for the patch. By applying a slicing technique, we retain the most relevant context and reduce the size of PatchCPG. Then, we develop the first end-to-end deep learning model called PatchGNN to determine if a patch is security-related directly from its graph-structured PatchCPG. PatchGNN includes a new embedding process to convert PatchCPG into a numeric format and a new multi-attributed graph convolution mechanism to adapt diverse relationships in PatchCPG. The experimental results show GraphSPD can significantly outperform the state-of-the-art approaches on security patch detection.  © 2023 IEEE.","Open Source Security and Risk Analysis Report, (2021); National Vulnerability Database; CVE-2021-22205 Detail; Vaniea K., Rashidi Y., Tales of software updates: The process of updating software, Proceedings of the 2016 Chi Conference on Human Factors in Computing Systems, Chi '16, pp. 3215-3226, (2016); Wang X., Sun K., Batcheller A., Jajodia S., Detecting ""0-day"" vulnerability: An empirical study of secret security patch in oss, 2019 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pp. 485-492, (2019); Tian Y., Lawall J., Lo D., Identifying linux bug fixing patches, 2012 34th International Conference on Software Engineering (ICSE), pp. 386-396, (2012); Wang X., Wang S., Sun K., Batcheller A., Jajodia S., A machine learning approach to classify security patches into vulnerability types, 2020 Ieee Conference on Communications and Network Security (CNS), pp. 1-9, (2020); Wang X., Wang S., Feng P., Sun K., Jajodia S., Benchaaboun S., Geck F., PatchRNN: A deep learning-based system for security patch identification, CoRR, (2021); Zhou Y., Kai Siow J., Wang C., Liu S., Liu Y., SPI: Automated identification of security patches via commits, Acm Trans. Softw. Eng. Methodol, 31, 1, (2021); Wang X., Wang S., Feng P., Sun K., Jajodia S., PatchDB: A large-scale security patch dataset, 2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pp. 149-160, (2021); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 Ieee Symposium on Security and Privacy, pp. 590-604, (2014); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, International Conference on Learning Representations, (2018); Wang W., Zhang K., Li G., Jin Z., Learning to represent programs with heterogeneous graphs, CoRR, (2020); Xiaomeng W., Tao Z., Runpu W., Wei X., Changyu H., CPGVA: Code property graph based vulnerability analysis by deep learning, 2018 10th International Conference on Advanced Infocomm Technology (ICAIT), pp. 184-188, (2018); Guan Z., Wang X., Xin W., Wang J., Code property graph-based vulnerability dataset generation for source code detection. in Guangquan Xu, Kaitai Liang, and Chunhua Su, editors, Frontiers in Cyber Security, pp. 584-591, (2020); Bai Y., Ding H., Bian S., Chen T., Sun Y., Wang W., SimGNN: A neural network approach to fast graph similarity computation, Proceedings of the Twelfth Acm International Conference on Web Search and Data Mining, Wsdm '19, pp. 384-392, (2019); Li Y., Gu C., Dullien T., Vinyals O., Kohli P., Graph matching networks for learning the similarity of graph structured objects, Proceedings of the 36th International Conference on Machine Learning, Icml 2019, 97, pp. 3835-3845, (2019); Ji Y., Cui L., Howie Huang H., BugGraph: Differentiating source-binary code similarity with graph triplet-loss network, Proceedings of the 2021 Acm Asia Conference on Computer and Communications Security, Asia Ccs '21, pp. 702-715, (2021); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics Via Graph Neural Networks, (2019); Cppcheck; Wheeler D.A., Flawfinder; Jang J., Agrawal A., Brumley D., Redebug: Finding unpatched code clones in entire os distributions, 2012 Ieee Symposium on Security and Privacy, pp. 48-62, (2012); Kim S., Woo S., Lee H., Oh H., VUDDY: A scalable approach for vulnerable code clone discovery, 2017 Ieee Symposium on Security and Privacy (SP), pp. 595-614, (2017); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., VulDeePecker: A deep learningbased system for vulnerability detection, 25th Annual Network and Distributed System Security Symposium, Ndss 2018, (2018); Golden D., A Survey of Git Best Practices; 5 Best Git Practices for Git Commit; Nvd Cwe Slice; Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, Acm Trans. Program. Lang. Syst, 9, 3, pp. 319-349, (1987); Bowman B., Howie Huang H., VGRAPH: A robust vulnerable code clone detection system using code property triplets, 2020 Ieee European Symposium on Security and Privacy (EuroS&P), pp. 53-69, (2020); Code Property Graph-Joern Documentation, (2021); The State of Open Source Vulnerabilities, (2021); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, Proc. of Ieee Symposium on Security and Privacy (S&P), (2014); Weiser M., Program slicing, Ieee Transactions on Software Engineering, 10, 4, pp. 352-357, (1984); Khan W., Daud A., Abdul Nasir J., Amjad T., A survey on the state-of-the-art machine learning models in the context of nlp, Kuwait Journal of Science, 43, (2016); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., SySeVR: A framework for using deep learning to detect software vulnerabilities, Ieee Transactions on Dependable and Secure Computing, (2021); Fey M., Lenssen J.E., Fast graph representation learning with PyTorch Geometric, Iclr Workshop on Representation Learning on Graphs and Manifolds, (2019); Xiao Y., Chen B., Yu C., Xu Z., Yuan Z., Li F., Liu B., Liu Y., Huo W., Zou W., Shi W., MVP: Detecting vulnerabilities using patch-enhanced vulnerability signatures, 29th Usenix Security Symposium (USENIX Security 20), pp. 1165-1182, (2020); 2021 Cwe Top 25 Most Dangerous Software Weaknesses, (2021); Vulnerabilities by Type; Tomek I., Two modifications of CNN, Ieee Transactions on Systems, Man, and Cybernetics, 6, 11, pp. 769-772, (1976); Fernandez A., Garcia S., Herrera F., Chawla N.V., SMOTE for learning from imbalanced data: Progress and challenges, marking the 15-year anniversary, J. Artif. Int. Res, 61, 1, pp. 863-905, (2018); Li F., Paxson V., A large-scale empirical study of security patches, Proceedings of the 2017 Acm Sigsac Conference on Computer and Communications Security, Ccs '17, pp. 2201-2215, (2017); Soto M., Thung F., Wong C., Le Goues C., Lo D., A deeper look into bug fixes: Patterns, replacements, deletions, and additions, Proceedings of the 13th International Conference on Mining Software Repositories, Msr '16, pp. 512-515, (2016); Perl H., Dechand S., Smith M., Arp D., Yamaguchi F., Rieck K., Fahl S., Acar Y., VCCFinder: Finding potential vulnerabilities in open-source projects to assist code audits, Proceedings of the 22nd Acm Sigsac Conference on Computer and Communications Security, Ccs '15, pp. 426-437, (2015); MacHiry A., Redini N., Camellini E., Kruegel C., Vigna G., SPIDER: Enabling fast patch propagation in related software repositories, 2020 Ieee Symposium on Security and Privacy (SP), pp. 1562-1579, (2020); Wu Q., He Y., McCamant S., Lu K., Precisely characterizing security impact in a flood of patches via symbolic rule comparison, 27th Annual Network and Distributed System Security Symposium, Ndss 2020, (2020); Huang Z., Lie D., Tan G., Jaeger T., Using safety properties to generate vulnerability patches, 2019 Ieee Symposium on Security and Privacy (SP), pp. 539-554, (2019); Xu Z., Zhang Y., Zheng L., Xia L., Bao C., Wang Z., Liu Y., Automatic hot patch generation for android kernels, 29th Usenix Security Symposium (USENIX Security 20), pp. 2397-2414, (2020); Hoang T., Lawall J., Oentaryo R.J., Tian Y., Lo D., PatchNet: A tool for deep patch classification, 2019 IEEE/ACM 41st International Conference on Software Engineering: Companion Proceedings (ICSE-Companion), pp. 83-86, (2019); Hoang T., Lawall J., Tian Y., Jayadi Oentaryo R., Lo D., PatchNet: Hierarchical deep learning-based stable patch identification for the linux kernel, CoRR, (2019); Tian H., Liu K., Kader Kabore A., Koyuncu A., Li L., Klein J., Tegawende F., Bissyandé. Evaluating representation learning of code changes for predicting patch correctness in program repair, Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering, Ase '20, pp. 981-992, (2020); Ming J., Xu D., Jiang Y., Wu D., BinSim: Trace-based semantic binary diffing via system call sliced segment equivalence checking, 26th Usenix Security Symposium (USENIX Security 17), pp. 253-270, (2017); Duan Y., Li X., Wang J., Yin H., DeepBinDiff: Learning program-wide code representations for binary diffing, Network and Distributed System Security Symposium, (2020); Zhao L., Zhu Y., Ming J., Zhang Y., Zhang H., Yin H., PatchScope: Memory object centric patch diffing, Proceedings of the 2020 Acm Sigsac Conference on Computer and Communications Security, Ccs '20, pp. 149-165, (2020); Dai J., Zhang Y., Jiang Z., Zhou Y., Chen J., Xing X., Zhang X., Tan X., Yang M., Yang Z., BScout: Direct whole patch presence test for java executables, 29th Usenix Security Symposium (USENIX Security 20), pp. 1147-1164, (2020); Zhang Z., Zhang H., Qian Z., Lau B., An investigation of the android kernel patch ecosystem, 30th Usenix Security Symposium (USENIX Security 21), pp. 3649-3666, (2021); Zhang H., Qian Z., Precise and accurate patch presence test for binaries, 27th Usenix Security Symposium (USENIX Security 18), pp. 887-902, (2018); Jiang Z., Zhang Y., Xu J., Wen Q., Wang Z., Zhang X., Xing X., Yang M., Yang Z., PDiff: Semanticbased patch presence testing for downstream kernels, Proceedings of the 2020 Acm Sigsac Conference on Computer and Communications Security, Ccs '20, pp. 1149-1163, (2020); Xu Z., Chen B., Chandramohan M., Liu Y., Song F., SPAIN: Security patch analysis for binaries towards understanding the pain and pills, 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE), pp. 462-472, (2017); Duan R., Bijlani A., Ji Y., Alrawi O., Xiong Y., Ike M., Saltaformaggio B., Lee W., Automating patching of vulnerable open-source software versions in application binaries, 26th Annual Network and Distributed System Security Symposium, Ndss 2019, (2019); Niesler C., Surminski S., Davi L., HERA: Hotpatching of embedded real-time applications, Network and Distributed System Security Symposium, (2021); Chen J., Diao W., Zhao Q., Zuo C., Lin Z., Wang X., Cheong Lau W., Sun M., Yang R., Zhang K., IoTFuzzer: Discovering memory corruptions in iot through app-based fuzzing, 25th Annual Network and Distributed System Security Symposium, Ndss 2018, (2018); Hu Y., Wang W., Hunger C., Wood R., Khurshid S., Tiwari M., ACHyb: A hybrid analysis approach to detect kernel access control vulnerabilities, Proceedings of the 29th Acm Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2021, pp. 316-327, (2021); You W., Zong P., Chen K., Wang X., Liao X., Bian P., Liang B., Semfuzz: Semantics-based automatic generation of proof-of-concept exploits, Proceedings of the 2017 Acm Sigsac Conference on Computer and Communications Security, Ccs '17, pp. 2139-2154, (2017); Pan J., Yan G., Fan X., Digtool: A virtualizationbased framework for detecting kernel vulnerabilities, 26th Usenix Security Symposium (USENIX Security 17), pp. 149-165, (2017); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th Ieee International Conference on Machine Learning and Applications (ICMLA), pp. 757-762, (2018); Zhou Y., Sharma A., Automated identification of security issues from commit messages and bug reports, Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2017, pp. 914-919, (2017); Chandra Das D., Rayhanur Rahman Md., Security and performance bug reports identification with class-imbalance sampling and feature selection, 2018 Joint 7th International Conference on Informatics, Electronics Vision (ICIEV) and 2018 2nd International Conference on Imaging, Vision Pattern Recognition (IcIVPR), pp. 316-321, (2018); Goseva-Popstojanova K., Tyo J., Identification of security related bug reports via text mining using supervised and unsupervised classification, 2018 Ieee International Conference on Software Quality, Reliability and Security (QRS), pp. 344-355, (2018); Bohme M., Pham V., Nguyen M., Roychoudhury A., Directed greybox fuzzing, Proceedings of the 2017 Acm Sigsac Conference on Computer and Communications Security, Ccs '17, pp. 2329-2344, (2017); Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, International Conference on Learning Representations, (2020); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proceedings of the 28th International Conference on Program Comprehension, Icpc '20, pp. 184-195, (2020); Wang Y., Wang K., Gao F., Wang L., Learning semantic program embeddings with graph interval neural network, Proc. Acm Program. Lang, 4, (2020); Brauckmann A., Goens A., Ertel S., Castrillon J., Compiler-based graph representations for deep learning models of code, Proceedings of the 29th International Conference on Compiler Construction, Cc 2020, pp. 201-211, (2020); Ye F., Zhou S., Venkat A., Marcus R., Tatbul N., Jahan Tithi J., Petersen P., Mattson T.G., Kraska T., Dubey P., Sarkar V., Gottschlich J., MISIM: An end-to-end neural code similarity system, CoRR, (2020); Wang H., Ye G., Tang Z., Hwei Tan S., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining graph-based learning with automated data collection for code vulnerability detection, Ieee Transactions on Information Forensics and Security, 16, pp. 1943-1958, (2021); Liu Z., Qian P., Wang X., Zhuang Y., Qiu L., Wang X., Combining graph neural networks with expert knowledge for smart contract vulnerability detection, Ieee Transactions on Knowledge & Data Engineering, 1; Arakelyan S., Hauser C., Kline E., Galstyan A., Bin2vec: Learning representations of binary executable programs for security tasks, CoRR, (2020); Yang S., Cheng L., Zeng Y., Lang Z., Zhu H., Shi Z., Asteria: Deep learning-based ast-encoding for crossplatform binary code similarity detection, CoRR, (2021); Zhu X., Jiang L., Chen Z., Cross-platform binary code similarity detection based on nmt and graph embedding, Mathematical Biosciences and Engineering, 18, 5, pp. 4528-4551, (2021)",,"44th IEEE Symposium on Security and Privacy, SP 2023",22 May 2023 through 25 May 2023,"Hybrid, San Francisco",190916,English,Conference paper,Final,,Scopus,2-s2.0-85166049487,77
Zhou X.; Pang J.; Zhang C.; Yue F.; Wang J.; Liu G.,"Zhou, Xin (57201549428); Pang, Jianmin (24344798200); Zhang, Chunyan (57197763121); Yue, Feng (55836200400); Wang, Junchao (55321539000); Liu, Guangming (57827415300)",57201549428; 24344798200; 57197763121; 55836200400; 55321539000; 57827415300,TS-GGNN: Combining Graph and Sequence Features for Vulnerability Detection in Source Code,2023,"2023 5th International Conference on Communications, Information System and Computer Engineering, CISCE 2023",,,,196,200,4,0,10.1109/CISCE58541.2023.10142859,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163405645&doi=10.1109%2fCISCE58541.2023.10142859&partnerID=40&md5=858b0ff35c1046eeefb38744e97cc35f,"Software vulnerability detection is crucial for maintaining the security and stability of software systems. In this paper, we propose a novel neural network model called TS-GGNN to address the problem of vulnerability detection in source code slices. The TS-GGNN model effectively captures both local and global features of vulnerable code by fusing sequence features with graph features. To achieve this, we utilize graph structure and sequence structure learning approaches to comprehensively extract valuable information from the source code slices. Our experiments are conducted on the SARD dataset, which consists of 61,638 code samples annotated for the presence or absence of vulnerabilities. The results demonstrate that TS-GGNN has the best vulnerability detection performance, with an accuracy of 99.4%, a precision of 98.81%, and an F1 score as high as 99.4% thereby validating the effectiveness of the TS-GGNN model in capturing features relevant to software vulnerabilities.  © 2023 IEEE.","Thome J., Shar L.K., Bianculli D., Et al., Search-driven string constraint solving for vulnerability detection[C], 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE). IEEE, pp. 198-208, (2017); Qiang W., Liao Y., Sun G., Et al., Patch-related vulnerability detection based on symbolic execution[J], IEEE Access, 5, pp. 20777-20784, (2017); Zhou Y., Sharma A., Automated identification of security issues from commit messages and bug reports[C], Proceedings of the 2017 11th joint meeting on foundations of software engineering., pp. 914-919, (2017); Cao X., Zhang J., Wu X., Et al., A survey on security in consensus and smart contracts[J], Peer-to-Peer Networking and Applications, pp. 1-21, (2022); Lee Y., Kwon H., Choi S.H., Et al., Instruction2vec: Efficient preprocessor of assembly code to detect software weakness with CNN[J], Applied Sciences, 9, 19, (2019); Le T., Nguyen T., Le T., Et al., Maximal divergence sequential autoencoder for binary software vulnerability detection[C], International Conference on Learning Representations., (2019); Li Z., Zou D., Xu S., Et al., Vuldeepecker: A deep learning-based system for vulnerability detection[J], (2018); Zou D., Wang S., Xu S., Et al., μvuldeepecker: A deep learning-based system for multiclass vulnerability detection[j], IEEE Transactions on Dependable and Secure Computing, 18, 5, pp. 2224-2236, (2019); Li Z., Zou D., Xu S., Et al., Sysevr: A framework for using deep learning to detect software vulnerabilities[J], IEEE Transactions on Dependable and Secure Computing, 19, 4, pp. 2244-2258, (2021); Beck D., Haffari G., Cohn T., Graph-to-sequence learning using gated graph neural networks[J], (2018); Ohsawa Y., Benson N.E., Yachida M., KeyGraph: Automatic indexing by co-occurrence graph based on building construction metaphor[C], Proceedings IEEE International Forum on Research and Technology Advances in Digital Libraries-ADL'98. IEEE, pp. 12-18, (1998); Bouma G., Normalized (pointwise) mutual information in collocation extraction[J], Proceedings of GSCL, 30, pp. 31-40, (2009); Gong L., Ji R., What does a TextCNN learn?[J], (2018); Zhou Y., Liu S., Siow J., Et al., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks[J], Advances in neural information processing systems, (2019)",IEEE,"5th International Conference on Communications, Information System and Computer Engineering, CISCE 2023",14 April 2023 through 16 April 2023,Guangzhou,189405,English,Conference paper,Final,,Scopus,2-s2.0-85163405645,78
Wang J.; Huang M.; Nie Y.; Kuang X.; Li X.; Zhong W.,"Wang, Jingjing (57237621400); Huang, Minhuan (14631981500); Nie, Yuanpin (59038668200); Kuang, Xiaohui (7006865075); Li, Xiang (58650547900); Zhong, Wenjing (57439704800)",57237621400; 14631981500; 59038668200; 7006865075; 58650547900; 57439704800,Fine-Grained Source Code Vulnerability Detection via Graph Neural Networks,2023,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",2023-July,,,222,227,5,0,10.18293/SEKE2023-115,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170065533&doi=10.18293%2fSEKE2023-115&partnerID=40&md5=0394a3677f82786986e04fcdec1fee65,"Although the number of exploitable vulnerabilities in software continues to increase, the speed of bug fixes and software updates have not increased accordingly. It is therefore crucial to analyze the source code and identify vulnerabilities in the early phase of software development. However, vulnerability location in most of the current machine learning-based methods tends to concentrate at the function level. It undoubtedly imposes a burden on further manual code audits when faced with large-scale source code projects. In this paper, a fine-grained source code vulnerability detection model based on Graph Neural Networks (GNNs) is proposed with the aim of locating vulnerabilities at the function level and line level. Our empirical evaluation on different C/C++ datasets demonstrated that our proposed model outperforms the state-of-the-art methods and achieves significant improvements even when faced with more complex, real-project source code. © 2023 Knowledge Systems Institute Graduate School. All rights reserved.","NVD Analysis 2022: A Call to Action on Software Supply Chain Security, (2022); Malhotra R., A systematic review of machine learning techniques for software fault prediction, Applied Soft Computing, 27, pp. 504-518, (2015); Singh S. K., Chaturvedi A., Applying deep learning for discovery and analysis of software vulnerabilities: A brief survey, Soft Computing: Theories and Applications, pp. 649-658, (2020); Chen Y., Convolutional neural network for sentence classification, (2015); Lin G., Zhang J., Luo W., Pan L., Xiang Y., Poster: Vulnerability discovery with function representation learning from unlabeled projects, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 2539-2541, (2017); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE international conference on machine learning and applications (ICMLA), pp. 757-762, (2018); Wu F., Wang J., Liu J., Wang W., Vulnerability detection with deep learning, 2017 3rd IEEE international conference on computer and communications (ICCC), pp. 1298-1302, (2017); Bruna J., Zaremba W., Szlam A., LeCun Y., Spectral networks and locally connected networks on graphs, (2013); Cao S., Sun X., Bo L., Wei Y., Li B., Bgnn4vd: constructing bidirectional graph neural-network for vulnerability detection, Information and Software Technology, 136, (2021); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet, IEEE Transactions on Software Engineering, pp. 1-1, (2021); Zheng W., Jiang Y., Su X., Vu1spg: Vulnerability detection based on slice property graph representation learning, 2021 IEEE 32nd International Symposium on Software Reliability Engineering (ISSRE), pp. 457-467, (2021); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in neural information processing systems, 32, (2019); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: A framework for using deep learning to detect software vulnerabilities, IEEE Transactions on Dependable and Secure Computing, (2021); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, (2018); Hin D., Kan A., Chen H., Babar M. A., Linevd: Statement-level vulnerability detection using graph neural networks, (2022); Zou D., Wang S., Xu S., Li Z., Jin H., µvuldeepecker: A deep learning-based system for multiclass vulnerability detection, IEEE Transactions on Dependable and Secure Computing, 18, 5, pp. 2224-2236, (2021); Li Z., Zou D., Xu S., Chen Z., Zhu Y., Jin H., Vuldeelocator: a deep learning-based fine-grained vulnerability detector, IEEE Transactions on Dependable and Secure Computing, (2021); Fan G., Diao X., Yu H., Yang K., Chen L., Software defect prediction via attention-based recurrent neural network, Scientific Programming, 2019, (2019); Lin G., Zhang J., Luo W., Pan L., Xiang Y., De Vel O., Montague P., Cross-project transfer representation learning for vulnerable function discovery, IEEE Transactions on Industrial Informatics, 14, 7, pp. 3289-3297, (2018); Liu S., Lin G., Han Q.-L., Wen S., Zhang J., Xiang Y., Deepbalance: Deep-learning and fuzzy oversampling for vulnerability detection, IEEE Transactions on Fuzzy Systems, 28, 7, pp. 1329-1343, (2019); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, pp. 590-604, (2014); Duan X., Wu J., Ji S., Rui Z., Luo T., Yang M., Wu Y., Vulsniper: Focus your attention to shoot fine-grained vulnerabilities, IJCAI, pp. 4665-4671, (2019); Lee J., Lee I., Kang J., Self-attention graph pooling, International conference on machine learning. PMLR, pp. 3734-3743, (2019); Yamaguchi F., Pattern-based vulnerability discovery, (2015); Kipf T. N., Welling M., Semi-supervised classification with graph convolutional networks, (2016); Nair V., Hinton G. E., Rectified linear units improve restricted boltzmann machines, Icml, (2010); Li Q., Han Z., Wu X.-M., Deeper insights into graph convolutional networks for semi-supervised learning, Thirty-Second AAAI conference on artificial intelligence, (2018); Xu K., Li C., Tian Y., Sonobe T., Kawarabayashi K.-i., Jegelka S., Representation learning on graphs with jumping knowledge networks, International conference on machine learning. PMLR, pp. 5453-5462, (2018); Ba J. L., Kiros J. R., Hinton G. E., Layer normalization, (2016); Cangea C., Velickovic P., Jovanovic N., Kipf T., Lio P., Towards sparse hierarchical graph classifiers, (2018); Atwood J., Towsley D., Diffusion-convolutional neural networks, Advances in neural information processing systems, 29, (2016); Simonovsky M., Komodakis N., Dynamic edge-conditioned filters in convolutional neural networks on graphs, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3693-3702, (2017); Gao H., Ji S., Graph u-nets, international conference on machine learning. PMLR, pp. 2083-2092, (2019); Zhang M., Cui Z., Neumann M., Chen Y., An end-to-end deep learning architecture for graph classification, Proceedings of the AAAI conference on artificial intelligence, 32, 1, (2018); Cppcheck: A tool for static C/C++ code analysis; FlawFinder; Rough Audit Tool for Security; FlintPlusPlus; Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017)",Knowledge Systems Institute; KSI Research Inc.,"35th International Conference on Software Engineering and Knowledge Engineering, SEKE 2023",1 July 2023 through 10 July 2023,"Hybrid, San Francisco",191784,English,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85170065533,80
Zhang H.; Kishi T.,"Zhang, Hanyu (57223096162); Kishi, Tomoji (7201965912)",57223096162; 7201965912,Long Method Detection Using Graph Convolutional Networks,2023,Journal of Information Processing,31,,,469,477,8,0,10.2197/ipsjjip.31.469,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169480537&doi=10.2197%2fipsjjip.31.469&partnerID=40&md5=64c615bceca1579d612103656725e595,"Long Method is a code smell that frequently happens in software development, which refers to the com-plex method with multiple functions. Detecting and refactoring such problems has been a popular topic in software refactoring, and many detection approaches have been proposed. In past years, the approaches based on metrics or rules have been the leading way in long method detection. However, the approach based on deep learning has also attracted extensive attention in recent studies. In this paper, we propose a graph-based deep learning approach to de-tect Long Method. The key point of our approach is that we extended the PDG (Program Dependency Graph) into a Directed-Heterogeneous Graph as the input graph and used the GCN (Graph Convolutional Network) to build a graph neural network for Long Method detection. Moreover, to get substantial data samples for the deep learning task, we propose a novel semi-automatic approach to generate a large number of data samples. Finally, to prove the validity of our approach, we compared our approach with the existing approaches based on five groups of datasets manually reviewed. The evaluation result shows that our approach achieved a good performance in Long Method detection. © 2023, Information Processing Society of Japan. All rights reserved.","Fowler M., Beck K., Brant J., Opdyke W., Refactoring: Improving the Design of Existing Code, (1999); Sharma T., Spinellis D., A survey on software smells, Journal of Systems and Software, 138, pp. 158-173, (2018); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Trans. Programming Languages and Systems, 9, pp. 319-349, (1987); Liu H., Jin J., Xu Z., Et al., Deep Learning Based Code Smell De-tection, IEEE Trans. Software Engineering, 47, (2021); Tsantalis N., Chatzigeorgiou A., Identification of extract method refactoring opportunities for the decomposition of methods, Journal of Systems and Software, 84, pp. 1757-1782, (2011); Tsantalis N., Chatzigeorgiou A., Identification of Extract Method Refactoring Opportunities, Proc. European Conference on Software Maintenance and Reengineering (CSMR 2009), pp. 119-128, (2009); JDeodorant; Madeyskia L., Lewowski T., MLCQ: Industry-Relevant Code Smell Data Set, Proc. Evaluation and Assessment in Software Engi-neering, pp. 342-347, (2020); Gori M., Monfardini G., Scarselli F., A new model for learning in graph domains, Proc. IEEE International Joint Conference on Neural Networks, (2005); Scarselli F., Gori M., Tsoi A.C., Et al., The graph neural network model, IEEE Trans. Neural Networks, 20, pp. 61-80, (2009); Zhoua J., Cuia G., Hu S., Et al., Graph neural networks: A review of methods and applications, AI Open, 1, pp. 57-81, (2020); Wu Z., Pan S., Chen F., Et al., A Comprehensive Survey on Graph Neural Networks, IEEE Trans. Neural Networks and Learning Sys-tems, 32, pp. 4-24, (2021); AbuHassan A., Alshayeb M., Ghouti L., Software smell detection techniques: A systematic literature review, Journal of Software: Evolution and Process, 33, (2021); Fitzpatrick J., Applying the ABC metric to C, C++, and Java, Proc. More C++ Gems, pp. 245-264, (2000); Allen F.E., Control flow analysis, Proc. Symposium on Compiler Op-timization, pp. 1-19, (1970); Aho A.V., Lam M.S., Sethi R., Compilers: Principles, Tech-niques, and Tools, (1986); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks, Proc. ICLR 2017, 2017; Leetcode; Netty; Puri R., Kung D.S., Janssen G., Et al., CodeNet: A Large-Scale AI for Code Dataset for Learning a Diversity of Coding Tasks; Prem D., Dwyer M., Elbaum S., Et al., Deep Learning & Software Engineering: State of Research and Future Directions, Proc. 2019 NSF Workshop on Deep Learning and Software Engineering, (2019); Watson C., Cooper N., Palacio D.N., Et al., A Systematic Literature Review on the Use of Deep Learning in Software Engineering Re-search; Pereira dos Reis J., Brito e Abreu F., de Figueiredo Carneiro G., Et al., Code Smells Detection and Visualization: A Systematic Literature Review, Archives of Computational Methods in Engineering, 29, pp. 47-94, (2022); Fontana F.A., Mantyla M.V., Zanoni M., Et al., Comparing and experimenting machine learning techniques for code smell detection, Empirical Software Engineering, 21, pp. 1143-1191, (2016); Newman M., Networks: An Introduction, (2010); Shahidi M., Ashtiani M., Zakeri-Nasrabadi M., An automated extract method refactoring approach to correct the long method code smell, Journal of Systems and Software, 187, (2022); OpenRefine; Jgrapht; RxJava; Mybatis; JUnit; PyTorch; JEdit; Open Hospital; Steidl D., Eder S., Prioritizing maintainability defects based on refactoring recommendations, 22nd International Conference on Program Comprehension, pp. 168-176, (2014); Lippert M., Roock S., Refactoring in large software projects: Per-forming complex restructurings successfully, (2006); PMD; Gephi; Libgdx; Charalampidou S., Ampatzoglou A., Avgeriou P., Size and cohe-sion metrics as indicators of the long method bad smell: An empirical study, ICPC 2014: Proc. 22nd International Conference on Program Comprehension, pp. 168-176, (2014); Jsprit",,,,,,English,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85169480537,81
Guo W.; Fang Y.; Huang C.; Ou H.; Lin C.; Guo Y.,"Guo, Wenbo (57267203800); Fang, Yong (57026722800); Huang, Cheng (55511401300); Ou, Haoran (57207735169); Lin, Chun (57818819300); Guo, Yongyan (57221283841)",57267203800; 57026722800; 55511401300; 57207735169; 57818819300; 57221283841,HyVulDect: A hybrid semantic vulnerability mining system based on graph neural network,2022,Computers and Security,121,,102823,,,,8,10.1016/j.cose.2022.102823,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134880709&doi=10.1016%2fj.cose.2022.102823&partnerID=40&md5=7c0d39840ad714fb2d4762a2437aa558,"In recent years, software programs tend to be large and complex, software has become the infrastructure of modern society, but software security issues can not be ignored. software vulnerabilities have become one of the main threats to computer security. There are countless cases of exploiting source code vulnerabilities to launch attacks. At the same time, the development of open source software has made source code vulnerability detection more and more critical. Traditional vulnerability mining methods have been unable to meet the security analysis needs of complex software because of the high false-positive rate and false-negative rate. To resolve the existing problems, we propose a graph neural network vulnerability mining system named HyVulDect based on hybrid semantics, which constructs a composite semantic code property graph for code representation based on the causes of vulnerabilities. A gated graph neural network is used to extract deep semantic information. Since most of the vulnerabilities are data flow associated, we use taint analysis to extract the taint propagation chain, use the BiLSTM model to extract the token-level features of the context, and finally use the classifier to classify the fusion features. We introduce a dual-attention mechanism that allows the model to focus on vulnerability-related code, making it more suitable for vulnerability mining tasks. The experimental results show that HyVulDect outperforms existing state-of-the-art methods and can achieve an accuracy rate of 92% on the benchmark dataset. Compared with the rule-based static mining tools Flawfinder, RATS, and Cppcheck, it has better performance and can effectively detect the actual CVE source code vulnerabilities. © 2022 Elsevier Ltd","Ben-Nun T., Jakobovits A.S., Hoefler T., Neural code comprehension: a learnable representation of code semantics, Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 3589-3601, (2018); Cao S., Sun X., Bo L., Wei Y., Li B., BGNN4VD: constructing bidirectional graph neural-network for vulnerability detection, Inf Softw Technol, 136, (2021); Chen T., Xu R., He Y., Wang X., Improving sentiment analysis via sentence type classification using BiLSTM-CRF and CNN, Expert Syst Appl, 72, pp. 221-230, (2017); Church K.W., Word2vec, Nat Lang Eng, 23, 1, pp. 155-162, (2017); (2021); Dey R., Salem F.M., Gate-variants of gated recurrent unit (gru) neural networks, 2017 IEEE 60th International Midwest Symposium on Circuits and Systems (MWSCAS), pp. 1597-1600, (2017); Duan X., Wu J., Ji S., Rui Z., Luo T., Yang M., Wu Y., VulSniper: Focus your attention to shoot fine-grained vulnerabilities, IJCAI, pp. 4665-4671, (2019); Fang Y., Han S., Huang C., Wu R., Tap: a static analysis model for PHP vulnerabilities based on token and deep learning technology, PLoS ONE, 14, 11, (2019); Ferschke O., Gurevych I., Rittberger M., Flawfinder: A modular system for predicting quality flaws in wikipedia, CLEF (Online Working Notes/Labs/Workshop), pp. 1-10, (2012); Guo W., Huang C., Niu W., Fang Y., Intelligent mining vulnerabilities in python code snippets, Journal of Intelligent & Fuzzy Systems, 41, 2, pp. 3615-3628, (2021); Ji Y., Cui L., Huang H.H., Buggraph: Differentiating source-binary code similarity with graph triplet-loss network, Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security, pp. 702-715, (2021); (2019); Ke G., Xu Z., Zhang J., Bian J., Liu T.-Y., Deepgbm: A deep learning framework distilled by GBDT for online prediction tasks, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 384-394, (2019); Kim S., Woo S., Lee H., Oh H., VUDDY: a scalable approach for vulnerable code clone discovery, 2017 IEEE Symposium on Security and Privacy (SP), pp. 595-614, (2017); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, arXiv preprint arXiv:1511.05493, (2015); Li Y., Wang S., Nguyen T.N., Van Nguyen S., Improving bug detection via context-based code representation learning and attention-based neural networks, Proceedings of the ACM on Programming Languages, 3, OOPSLA, pp. 1-30, (2019); Li Z., Zou D., Xu S., Jin H., Qi H., Hu J., Vulpecker: an automated vulnerability detection system based on code similarity analysis, Proceedings of the 32nd Annual Conference on Computer Security Applications, pp. 201-213, (2016); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: a framework for using deep learning to detect software vulnerabilities, IEEE Trans Dependable Secure Comput, (2021); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: a deep learning-based system for vulnerability detection, arXiv preprint arXiv:1801.01681, (2018); Lin G., Wen S., Han Q.-L., Zhang J., Xiang Y., Software vulnerability detection using deep neural networks: a survey, Proc. IEEE, 108, 10, pp. 1825-1848, (2020); Lopez M.M., Kalita J., Deep learning applied to nlp, arXiv preprint arXiv:1703.03091, (2017); Minaee S., Boykov Y.Y., Porikli F., Plaza A.J., Kehtarnavaz N., Terzopoulos D., Image segmentation using deep learning: a survey, IEEE Trans Pattern Anal Mach Intell, (2021); Nasirloo H., Azimzadeh F., Semantic code clone detection using abstract memory states and program dependency graphs, 2018 4th International Conference on Web Research (ICWR), pp. 19-27, (2018); Neamtiu I., Foster J.S., Hicks M., Understanding source code evolution using abstract syntax tree matching, Proceedings of the 2005 International Workshop on Mining Software Repositories, pp. 1-5, (2005); (1901); Ponta S.E., Plate H., Sabetta A., Beyond metadata: Code-centric and usage-based analysis of known vulnerabilities in open-source software, 2018 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 449-460, (2018); Rabheru R., Hanif H., Maffeis S., A hybrid graph neural network approach for detecting php vulnerabilities, arXiv preprint arXiv:2012.08835, (2020); (2014); (2017); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Trans. Neural Networks, 20, 1, pp. 61-80, (2008); Sun H., Cui L., Li L., Ding Z., Hao Z., Cui J., Liu P., Vdsimilar: vulnerability detection based on code similarity of vulnerabilities and patches, Computers & Security, 110, (2021); Sundermeyer M., Schluter R., Ney H., Lstm neural networks for language modeling, Thirteenth Annual Conference of the International Speech Communication Association, (2012); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, arXiv preprint arXiv:1710.10903, (2017); Wang D., Chen J., Supervised speech separation based on deep learning: an overview, IEEE/ACM Trans Audio Speech Lang Process, 26, 10, pp. 1702-1726, (2018); Wang H., Ye G., Tang Z., Tan S.H., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans. Inf. Forensics Secur., 16, pp. 1943-1958, (2020); Wang M., Zheng D., Ye Z., Gan Q., Li M., Song X., Zhou J., Ma C., Yu L., Gai Y., Xiao T., He T., Karypis G., Li J., Zhang Z., Deep graph library: a graph-centric, highly-performant package for graph neural networks, arXiv preprint arXiv:1909.01315, (2019); Xiaomeng W., Tao Z., Runpu W., Wei X., Changyu H., Cpgva: Code property graph based vulnerability analysis by deep learning, 2018 10th International Conference on Advanced Infocomm Technology (ICAIT), pp. 184-188, (2018); Zhang H., Wang S., Li H., Chen T.-H.P., Hassan A.E., A study of C/C++ code weaknesses on stack overflow, IEEE Trans. Software Eng., (2021); Zheng L., Yuan H., Peng X., Zhu G., Guo Y., Deng G., Research and implementation of web application system vulnerability location technology, The International Conference on Cyber Security Intelligence and Analytics, pp. 937-944, (2019); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems 2019, (2019)",,,,,,English,Review,Final,,Scopus,2-s2.0-85134880709,82
Luo Y.; Xu W.; Xu D.,"Luo, Yu (57437318900); Xu, Weifeng (35073269500); Xu, Dianxiang (7404073618)",57437318900; 35073269500; 7404073618,Compact Abstract Graphs for Detecting Code Vulnerability with GNN Models,2022,ACM International Conference Proceeding Series,,,,497,507,10,4,10.1145/3564625.3564655,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144086642&doi=10.1145%2f3564625.3564655&partnerID=40&md5=a8df527c9c6a10e7f895ff4800eb4fc9,"Source code representation is critical to the machine-learning-based approach to detecting code vulnerability. This paper proposes Compact Abstract Graphs (CAGs) of source code in different programming languages for predicting a broad range of code vulnerabilities with Graph Neural Network (GNN) models. CAGs make the source code representation aligned with the task of vulnerability classification and reduce the graph size to accelerate model training with minimum impact on the prediction performance. We have applied CAGs to six GNN models and large Java/C datasets with 114 vulnerability types in Java programs and 106 vulnerability types in C programs. The experiment results show that the GNN models have performed well, with accuracy ranging from 94.7% to 96.3% on the Java dataset and from 91.6% to 93.2% on the C dataset. The resultant GNN models have achieved promising performance when applied to more than 2,500 vulnerabilities collected from real-world software projects. The results also show that using CAGs for GNN models is significantly better than ASTs, CFGs (Control Flow Graphs), and PDGs (Program Dependence Graphs). A comparative study has demonstrated that the CAG-based GNN models can outperform the existing methods for machine learning-based vulnerability detection.  © 2022 ACM.","Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs With Graphs""; Bianchi F.M., Grattarola D., Livi L., Alippi C., Graph neural networks with convolutional arma flters, IEEE transactions on pattern analysis and machine intelligence, (2021); Bresson X., Laurent T., Residual Gated Graph Convnets; Checkmarx. Checkmarx, (2006); Chen P., Wang Y., Xin Z., Mao B., Xie L., Brick: A binary tool for run time detecting and locating integer-based vulnerability, 2009 International Conference on Availability, Reliability and Security, pp. 208-215, (2009); Chinchani R., Iyer A., Jayaraman B., Upadhyaya S., ARCHERR: Runtime Environment Driven Program Safety"", pp. 385-406; Choi M., Jeong S., Oh H., Choo J., End-to-end prediction of bufer over runs from raw source code via neural memory networks""; Common Vulnerabilities and Exposures; Dam H.K., Tran T., Pham T., Ng S.W., Grundy J., Ghose A., Automatic feature learning for vulnerability prediction""; Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, (2018); Dong F., Wang J., Li Q., Xu G., Zhang S., Defect prediction in android binary executables using deep neural network, Wireless Personal Communications, 102, 3, pp. 2261-2285, (2018); Eclipse CDT; Eclipse JDT; Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Codebert: A Pre-Trained Model For Programming And Natural Languages, (2020); Flawfnder. Flawfnder; Gao J., Yang X., Fu Y., Jiang Y., Sun J., VulSeeker: A semantic learning based vulnerability seeker for cross-platform binary, 2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 896-899, (2018); Godefroid P., Levin M., Molnar D., Automated whitebox fuzz testing, Network and Distributed System Security Symposium, (2008); Holmes G., Donkin A., Witten I.H., Weka: A machine learning workbench, Proceedings of ANZIIS'94-Australian New Zealnd Intelligent Information Systems Conference, pp. 357-361, (1994); Hovsepyan A., Scandariato R., Joosen W., Walden J., Software vulnerability prediction using text analysis techniques, Proceedings of the 4th international workshop on Security measurements and metrics, pp. 7-10, (2012); Kipf T.N., Welling M., Semi-Supervised Classifcation with Graph Convolutional Networks, International Conference on Learning Representations, (2017); Kravets D., Sorry Ma'am You Didn't Win $43M-There Was A Slot Machine 'malfunction', (2017); Le T., Nguyen T., Le T., Phung D., Montague P., De Vel O., Qu L., Maximal divergence sequential autoencoder for binary software vulnerability detection, International Conference on Learning Representations, (2018); Lee Y., Choi S., Kim C., Lim S., Park K., Learning binary code with deep learning to detect software weakness, KSII the 9th international conference on internet (ICONI) 2017 symposium, (2017); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks"", (2015); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: A framework for using deep learning to detect software vulnerabilities, IEEE Transactions on Dependable and Secure Computing, (2021); Li Z., Zou D., Xu S., Ou X., Zhong Y., VulDeePecker: A Deep Learning Based System for Vulnerability Detection, Network and Distributed System Security Symposium, (2018); Lin G., Zhang J., Luo W., Pan L., Xiang Y., POSTER: Vulnerability discovery with function representation learning from unlabeled projects, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 2539-2541, (2017); Lin G., Zhang J., Luo W., Pan L., Xiang Y., De Vel O., Montague P., Cross project transfer representation learning for vulnerable function discovery, IEEE Transactions on Industrial Informatics 14.7, pp. 3289-3297, (2018); Liu Z., Qian P., Wang X., Zhuang Y., Qiu L., Wang X., Combining graph neural networks with expert knowledge for smart contract vulnerability detection, IEEE Transactions on Knowledge and Data Engineering, (2021); Luo Y., Xu W., Xu D., Detecting Integer Overfow Errors in Java Source Code via Machine Learning, 2021 IEEE 33rd International Conference on Tools with Artifcial Intelligence (ICTAI), pp. 724-728, (2021); Microsoft. PREfast Analysis Tool, (2012); Mokhov S.A., Paquet J., Debbabi M., MARFCAT: Fast code analysis for defects and vulnerabilities, 2015 IEEE 1st International Workshop on Software Analytics, pp. 35-38, (2015); National Vulnerability Database; Pang Y., Xue X., Namin A., Predicting vulnerable software components through n-gram analysis and statistical feature selection, 2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA), pp. 543-548, (2015); Peng H., Mou L., Li G., Liu Y., Zhang L., Jin Z., Building program vector representations for deep learning, International conference on knowledge science, engineering and management, pp. 547-553, (2015); PyG; Pytorch; Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 757-762, (2018); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., Sourcerercc: Scaling code clone detection to big-code, Proceedings of the 38th International Conference on Software Engineering, pp. 1157-1168, (2016); NIST Software Assurance Reference Dataset Project, (2019); Scandariato R., Walden J., Hovsepyan A., Joosen W., Predicting vulnerable software components via text mining, IEEE Transactions on Software Engineering, 40, 10, pp. 993-1006, (2014); Sestili C.D., Snavely W.S., VanHoudnos N.M., Towards Security Defect Prediction With AI""; Shabtai A., Moskovitch R., Elovici Y., Glezer C., Detection of malicious code by applying machine learning classifers on static features: A state-of the-art survey, Information Security Technical Report, 14, 1, pp. 16-29, (2009); Shi Y., Huang Z., Feng S., Zhong H., Wang W., Sun Y., Masked Label Prediction: Unifed Message Passing Model For Semi Supervised Classifcation, (2020); Song K., Tan X., Qin T., Lu J., Liu T., Mpnet: Masked and permuted pre-training for language understanding, Advances in Neural Information Processing Systems, 33, pp. 16857-16867, (2020); Petar V., Guillem C., Arantxa C., Adriana R., Pietro L., Yoshua B., Graph Attention Networks, International Conference on Learning Representations, (2018); Verma N., Boyer E., Verbeek J., Feastnet: Feature-steered graph convolutions for 3d shape analysis, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2598-2606, (2018); Wang H., Ye G., Tang Z., Tan S.H., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining Graph-based Learning with Automated Data Collection for Code Vulnerability Detection, IEEE TIFS, 16, pp. 1943-1958, (2020); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE), pp. 297-308, (2016); Wang T., Wei T., Lin Z., Zou W., IntScope: Automatically Detecting Integer Overfow Vulnerability In X86 Binary Using Symbolic Execution, Network & Distributed System Security Symposium (NDSS2009), (2009); Wilcoxon F., Individual comparisons by ranking methods, Breakthroughs in Statistics, pp. 196-202, (1992); Wojtczuk R., UQBTng: a tool capable of automatically nding integer overows in Win32 binaries, Proceedings of Chaos Communication Congress, (2005); Yamaguchi F., Lindner F., Rieck K., Vulnerability extrapolation: Assisted discovery of vulnerabilities using machine learning, Proceedings of the 5th USENIX conference on Ofensive technologies, pp. 13-13, (2011); Zhao G., Huang J., Deepsim: deep learning code functional similarity, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 141-151, (2018); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Efective vulnerability identif-cation by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, 32, (2019); Zou D., Wang S., Xu S., Li Z., Jin H., VulDeePecker: A Deep Learning Based System for Multiclass Vulnerability Detection, IEEE Transactions on Dependable and Secure Computing, (2019)",Applied Computer Security Associates (ACSA,"38th Annual Computer Security Applications Conference, ACSAC 2022",5 December 2022 through 9 December 2022,Austin,184900,English,Conference paper,Final,,Scopus,2-s2.0-85144086642,83
Liu Z.; Fang Y.; Huang C.; Xu Y.,"Liu, Zhonglin (57218578040); Fang, Yong (57026722800); Huang, Cheng (55511401300); Xu, Yijia (57210602136)",57218578040; 57026722800; 55511401300; 57210602136,MFXSS: An effective XSS vulnerability detection method in JavaScript based on multi-feature model,2023,Computers and Security,124,,103015,,,,10,10.1016/j.cose.2022.103015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142136187&doi=10.1016%2fj.cose.2022.103015&partnerID=40&md5=eb1a928fab60b2f8770f3043b3edb47f,"The widespread use of web applications has also made them more vulnerable to hackers, resulting in the leakage of large amounts of application and personal privacy data. Cross-site scripting (XSS) attacks are one of the most significant threats to web applications. Attackers can inject scripts to control the victim's browser to send data or execute commands, leading to the theft of privacy or the hijacking of login tokens. Therefore, we proposed a multi-feature fusion-based neural network vulnerability detection model for detecting XSS vulnerabilities in the JavaScript source code of websites (We termed our implementation of this approach MFXSS). We combine abstract syntax tree (AST) and code control flow graph (CFG) to convert the generalized sample data into graph structure and code string structure. Then, through the graph convolutional neural network, weighted aggregation, and the bidirectional recurrent neural network, the logical call features and the context execution relationship features of the source code are extracted and fused respectively. Finally, the fused feature vectors are used to detect and predict XSS vulnerabilities in JavaScript. In the experiment, we designed multiple control experiments to verify that the model construction is optimal, and the accuracy rates in the standard and variant datasets are 0.997 and 0.986. Moreover, in comparing similar detection schemes, MFXSS also performs better. Applying the model to an actual web environment, we successfully detected the presence of XSS vulnerabilities in websites. © 2022 Elsevier Ltd","Allen F.E., Control flow analysis, ACM Sigplan Notices, 5, 7, pp. 1-19, (1970); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proc ACM Program Lang, 3, pp. 1-29, (2019); Bensalim S., Klein D., Barber T., Johns M., Talking about my generation: Targeted DOM-based XSS exploit generation using dynamic data flow analysis, In Proceedings of the 14th European Workshop on Systems Security (27-33), (2021); Chen H., Huang B., Chen W., Liu F., Machine Learning Principles and Applications, (2017); Chen X., Li M., Jiang Y., Sun Y., A comparison of machine learning algorithms for detecting XSS attacks, In Proceedings of the International Conference on Artificial Intelligence and Security, New York, NY, USA, pp. 214-224, (2019); Dahse J., Schwenk J., RIPS-A static source code analyser for vulnerabilities in PHP scripts, (2010); Edward L., Steven B., NLTK: The natural language toolkit, In Proceedings of the ACL Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics, pp. 62-69, (2002); Fang Y., Han S., Huang C., Wu R., TAP: A static analysis model for PHP vulnerabilities based on token and deep learning technology, PLoS ONE, 14, (2019); Fang Y., Huang C., Zeng M., Zhao Z., Huang C., JStrong: Malicious javascript detection based on code semantic representation and graph neural network, Computers & Security, 118, (2022); Fang Y., Xu Y., Jia P., Huang C., Providing email privacy by preventing webmail from loading malicious XSS payloads, Applied Sciences, 10, 13, (2020); Fass A., Backes M., Stock B.J., A static pre-filter for malicious javascript detection, Proceedings of the 35th Annual Computer Security Applications Conference, pp. 257-269, (2019); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization[j], ACM Transactions on Programming Languages and Systems (TOPLAS), 9, 3, pp. 319-349, (1987); Graves A., Schmidhuber J., Framewise phoneme classification with bidirectional LSTM and other neural network architectures, Neural networks, 18, 5-6, pp. 602-610, (2005); Guo N., Li X., Yin H., Gao Y., Vulhunter: An automated vulnerability detection system based on deep learning and bytecode, In Proceedings of the International Conference on Information and Communications Security, Beijing, China, 15-17 December 2019, pp. 199-218, (2019); Gupta M.K., Govil M.C., Singh G., Static analysis approaches to detect SQL injection and cross site scripting vulnerabilities in web applications: a survey, pp. 1-5, (2014); Gupta S., Gupta B.B., Cross-site scripting (XSS) attacks and defense mechanisms: classification and state-of-the-art, International Journal of System Assurance Engineering and Management, 8, 1, pp. 512-530, (2017); Jingchi Z., Yu-Tsern J., Xiangyang L., Cross-site scripting (XSS) detection integrating evidences in multiple stages, In Proceedings of the 52nd Hawaii International Conference on System Sciences–HICSS, Grand Wailea, Maui, pp. 7166-7175, (2019); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, arXiv preprint arXiv:, (2016); Lekies S., Stock B., Johns M., 25 million flows later: Large-scale detection of DOM-based XSS, In Proc. ACM SIGSAC Conference on Computer and Communications Security, pp. 1193-1204, (2013); Li C., Wang Y., Miao C., Huang C., Cross-site scripting guardian: A static XSS detector based on data stream input-output association mining, Applied Sciences, 10, 14, (2020); Li J., Zhao B., Zhang C., Fuzzing: A survey, Cybersecurity, 1, (2018); Li X., Zhang W., Ding Q., Understanding and improving deep learning-based rolling bearing fault diagnosis with attention mechanism, Signal processing, 161, pp. 136-154, (2019); Liu G., Cui X., Wang Z., Wang X., Fang Y., Li X., Malicescript: A novel browser-based intranet threat, In Proceedings of the 2018 IEEE 3rd International Conference on Data Science in Cyberspace–DSC, Guangzhou, China, 18-21 June, pp. 219-226, (2018); Liu S., Lin G., Qu L., Zhang J., De Vel O., Montague P., Xiang Y., CD-vuld: Cross-domain vulnerability discovery based on deep domain adaptation, IEEE Trans Dependable Secur Comput, (2020); Liu Z., Fang Y., Huang C., Han J., GraphXSS: an efficient XSS payload detection approach based on graph convolutional network, Computers & Security, 114, (2022); Liu Z., Fang Y., Huang C., Xu Y., GAXSS: Effective payload generation method to detect XSS vulnerabilities based on genetic algorithm, Security and Communication Networks, 2022, (2022); Marcheggiani D., Titov I., Encoding sentences with graph convolutional networks for semantic role labeling, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 1506-1515, (2017); Melicher W., Fung C., Bauer L., Towards a lightweight, hybrid approach for detecting dom xss vulnerabilities with machine learning, pp. 2684-2695, (2021); Mikolov T., Chen K., Corrado G., Efficient estimation of word representations in vector space, arXiv preprint arXiv:, (2013); Navarin N., Van T.D., Sperduti A., Universal readout for graph convolutional neural networks, 2019 International Joint Conference on Neural Networks (IJCNN), pp. 1-7, (2019); Neamtiu I., Foster J.S., Hicks M., Understanding source code evolution using abstract syntax tree matching, Proceedings of the 2005 international workshop on Mining software repositories, pp. 1-5, (2005); Nirmal K., Janet B., Kumar R., It's more than stealing cookies-exploitability of XSS, In Proceedings of the 2018 Second International Conference on Intelligent Computing and Control Systems (ICICCS), Madurai, India, pp. 490-493, (2018); Nithya V., Pandian S.L., Malarvizhi C., A survey on detection and prevention of cross-site scripting attack, International Journal of Security and Its Applications, 9, 3, pp. 139-152, (2015); Pinkus A., Approximation theory of the MLP model in neural networks, Acta numerica, 8, pp. 143-195, (1999); Rodriguez G., Torres J., Flores P., Benavides E., Nunez Agurto D., XSStudent: Proposal to Avoid Cross-Site Scripting (XSS) Attacks in Universities. In Proceedings of the 2019 3rd Cyber Security in Networking Conference (CSNet), Quito, pp. 142-149, (2019); She D., Chen Y., Shah A., Ray B., Jana S., Neutaint: Efficient dynamic taint analysis with neural networks, In Proc. IEEE Symposium on Security and Privacy, (2020); Stock B., Lekies S., Mueller T., Spiegel P., Johns M., Precise client-side protection against DOM-based cross-site scripting, pp. 655-670, (2014); Yamaguchi F., Lindner F., Rieck K., Vulnerability extrapolation: Assisted discovery of vulnerabilities using machine learning, In Proceedings of the 5th USENIX Conference on Offensive Technologies, (2011); Zhou Y., Evans D., Understanding and monitoring embedded web scripts, In 2015 IEEE Symposium on Security and Privacy, pp. 850-865, (2015)",,,,,,English,Article,Final,,Scopus,2-s2.0-85142136187,84
Cheng X.; Zhang G.; Wang H.; Sui Y.,"Cheng, Xiao (57211627500); Zhang, Guanqin (57202953646); Wang, Haoyu (55808022700); Sui, Yulei (54788439800)",57211627500; 57202953646; 55808022700; 54788439800,Path-sensitive code embedding via contrastive learning for software vulnerability detection,2022,ISSTA 2022 - Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis,,,,519,531,12,43,10.1145/3533767.3534371,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136799873&doi=10.1145%2f3533767.3534371&partnerID=40&md5=e74c09d0c019b5dec610654bd695b380,"Machine learning and its promising branch deep learning have shown success in a wide range of application domains. Recently, much effort has been expended on applying deep learning techniques (e.g., graph neural networks) to static vulnerability detection as an alternative to conventional bug detection methods. To obtain the structural information of code, current learning approaches typically abstract a program in the form of graphs (e.g., data-flow graphs, abstract syntax trees), and then train an underlying classification model based on the (sub)graphs of safe and vulnerable code fragments for vulnerability prediction. However, these models are still insufficient for precise bug detection, because the objective of these models is to produce classification results rather than comprehending the semantics of vulnerabilities, e.g., pinpoint bug triggering paths, which are essential for static bug detection. This paper presents ContraFlow, a selective yet precise contrastive value-flow embedding approach to statically detect software vulnerabilities. The novelty of ContraFlow lies in selecting and preserving feasible value-flow (aka program dependence) paths through a pretrained path embedding model using self-supervised contrastive learning, thus significantly reducing the amount of labeled data required for training expensive downstream models for path-based vulnerability detection. We evaluated ContraFlow using 288 real-world projects by comparing eight recent learning-based approaches. ContraFlow outperforms these eight baselines by up to 334.1%, 317.9%, 58.3% for informedness, markedness and F1 Score, and achieves up to 450.0%, 192.3%, 450.0% improvement for mean statement recall, mean statement precision and mean IoU respectively in terms of locating buggy statements.  © 2022 ACM.","Alon U., Zilberstein M., Levy O., Yahav E., 2019. Code2vec: Learning Distributed Representations of Code, 3, (2019); Arora S., Khandeparkar H., Khodak M., Plevrakis O., Saunshi N., 2019. A Theoretical Analysis of Contrastive Unsupervised Representation Learning; Backes M., Kopf B., Rybalchenko A., Automatic Discovery and Quantification of Information Leaks, 2009 30th IEEE Symposium on Security and Privacy. IEEE, pp. 141-153, (2009); Bromley J., Guyon I., Lecun Y., Sackinger E., Shah R., Signature Verification Using a Siamese"" Time Delay Neural Network, Proceedings of the 6th International Conference on Neural Information Processing Systems (NIPS ?93) ACM, pp. 737-744, (1993); Bui N.D.Q., Yu Y., Jiang L., 2021 Self-Supervised Contrastive Learning for Code Retrieval and Summarization via Semantic-Preserving Transformations, Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ?21). ACM, pp. 511-521; Chakraborty S., Krishna R., Ding Y., Ray B., 2020. Deep Learning Based Vulnerability Detection: Are We There Yet?; Chawla N.V., Bowyer K.W., Hall L.O., Philip Kegelmeyer W., 2002 smote: Synthetic minority over-sampling technique, Journal of Artificial Intelligence Research, pp. 321-357, (2002); Chen T., Kornblith S., Norouzi M., Hinton G.E., 2020 A Simple Framework for Contrastive Learning of Visual Representations, CoRR abs/2002 05709, (2020); Cheng X., Jiayi Hua H., Xu G., Sui Y., 2021. DeepWukong: Statically Detecting Software Vulnerabilities Using Deep Graph Neural Network; Cheng X., Wang H., Hua J., Zhang M., Xu G., Yi L., Sui Y., Static Detection of Control-Flow-Related Vulnerabilities Using Graph Embedding, ICECCS, pp. 41-50, (2019); Cherem S., Princehouse L., Rugina R., Practical Memory Leak Detection Using Guarded Value-Flow Analysis, Proceedings of the 28th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI ?07). ACM, pp. 480-491, (2007); Cho K., Van Merrienboer B., Bahdanau D., Bengio Y., On the Properties of Neural Machine Translation: Encoder-Decoder Approaches, Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation. Association for Computational Linguistics, Doha, Qatar, pp. 103-111, (2014); Das M., Lerner S., Seigle M., ESP: Path-Sensitive Program Verification in Polynomial Time, Proceedings of the ACM SIGPLAN 2002 Conference on Programming Language Design and Implementation (PLDI ?02). Association for Computing Machinery, pp. 57-68, (2002); De Moura L., Bjorner N., Z3: An Efficient SMT Solver, Proceedings of the Theory and Practice of Software, 14th International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS?08/ETAPS?08, pp. 337-340, (2008); Erhan D., Bengio Y., Courville A., Manzagol P., Vincent P., Bengio S., Why Does Unsupervised Pre-Training Help Deep Learning?, J. Mach. Learn. Res 2010, pp. 625-660, (2010); Facebook 2021. Infer; (2021); Fan J., Li Y., Wang S., Nguyen T.N., 2020. A C/C++ Code Vulnerability Dataset with Code Changes and CVE Summaries, Proceedings of the 17th International Conference on Mining Software Repositories (MSR, pp. 508-512; Fang H., Xie P., 2020 CERT: Contrastive Self-supervised Learning for Language Understanding; Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A Pre-Trained Model for Programming and Natural Languages, Findings of the Association for Computational Linguistics: EMNLP 2020. ACL, pp. 1536-1547, (2020); Fernando B., Bilen H., Gavves E., Gould S., Self-Supervised Video Representation Learning with Odd-One-Out Networks, (2016); Fey M., Eric Lenssen J., Fast Graph Representation Learning with PyTorch Geometric, (2019); Gao Q., Ma S., Shao S., Sui Y., Zhao G., Ma L., Ma X., Duan F., Deng X., Zhang S., Chen X., CoBOT: Static C/C++ Bug Detection in the Presence of Incomplete Code. in, IEEE/ACM 26th International Conference on Program Comprehension (ICPC ?18). IEEE, pp. 385-3853, (2018); Gao T., Yao X., Chen D., 2021. SimCSE: Simple Contrastive Learning of Sentence Embeddings, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Online and Punta Cana, Dominican Republic, pp. 6894-6910; Gao T., Yao X., Chen D., SimCSE: Simple Contrastive Learning of Sentence Embeddings, CoRR abs/2104.08821 2021, (2021); Gidaris S., Singh P., Komodakis N., Unsupervised Representation Learning by Predicting Image Rotations, CoRR abs/1803 07728 2018, (2018); Graves A., Schmidhuber J., 2005 Framewise phoneme classification with bidirectional LSTM and other neural network architectures, Neural Networks, 18, 5, pp. 602-610, (2005); Guyon I., Sun-Hosoya L., Boulle M., Jair Escalante H., Escalera S., Liu Z., Jajetic D., Ray B., Saeed M., Sebag M., Statnikov A., Tu W., Viegas E., Analysis of the AutoML Challenge series 2015-2018, AutoML, (2019); Gönter Obiltschnig, 2021; He J., Lee C., Raychev V., Vechev M., 2021. Learning to Find Naming Issues with Big Code and Small Supervision, pp. 296-311; Hecht-Nielsen Theory of the backpropagation neural network, International 1989 Joint Conference on Neural Networks, 1, pp. 593-605, (1989); Israel 2021. Checkmarx; Jaccard 2021. Jaccard Index; Jain P., Jain A., Zhang T., Abbeel P., Gonzalez J., Stoica I., 2021 Contrastive Code Representation Learning, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Online and Punta Cana, Dominican Republic, pp. 5954-5971; Jaiswal A., Ramesh Babu A., Zaki Zadeh M., Banerjee D., Makedon F., 2020. A Survey on Contrastive Self-supervised Learning; Kanungo T., Mount D.M., Netanyahu N.S., Piatko C.D., Silverman R., Wu A.Y., An efficient k-means clustering algorithm: Analysis and implementation, IEEE Trans. Pattern Anal. Mach. Intell 2002, pp. 881-892, (2002); Kiefer J., Wolfowitz J., 1952 Stochastic Estimation of the Maximum of a Regression Function, The Annals of Mathematical Statistics, 23, 3, pp. 462-466, (1952); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks, (2016); Klein T., Nabi M., 2020. Contrastive Self-Supervised Learning for Commonsense Reasoning; Korbar B., Tran D., Torresani L., Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization, Proceedings of the 32nd International Conference on Neural Information Processing Systems (NIPS ?18) ACM, pp. 7774-7785, (2018); Kroening D., Tautschnig M., CBMC-C Bounded Model Checker, Tools and Algorithms for the Construction and Analysis of Systems, Erika Abraham and Klaus Havelund (Eds, pp. 389-391, (2014); Li C., Ma H., Kang Z., Yuan Y., Zhang X., Wang G., On Deep Unsupervised Active Learning, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, Christian Bessiere (Ed.). International Joint Conferences on Artificial Intelligence Organization, pp. 2626-2632, (2020); Li T., Bai J., Sui Y., Hu S., 2022. Path-Sensitive and Alias-Aware Typestate Analysis for Detecting OS Bugs, Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (Lausanne, Switzerland) (ASPLOS 2022). Association for Computing Machinery, New York, NY, USA, pp. 859-872; Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, 4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings, Yoshua Bengio and Yann LeCun (Eds, (2016); Li Y., Wang S., Nguyen T.N., 2021 Vulnerability Detection with Fine-Grained Interpretations (FSE ?21, pp. 292-303; Li Z., Zou D., Xu S., Chen Z., Zhu Y., Jin H., 2021 VulDeeLocator: A Deep Learning-based Fine-grained Vulnerability Detector IEEE Transactions on Dependable and Secure Computing, 1, 2021, pp. 1-1; Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., 2021. SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities, 2021, pp. 1-1; Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., VulDeePecker: A Deep Learning-Based System for Vulnerability Detection. NDSS 2018, (2018); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., 2019 RoBERTa: A Robustly Optimized BERT Pretraining Approach, CoRR abs/1907 11692, (2019); Livshits B., Sridharan M., Smaragdakis Y., Lhotak O., Nelson Amaral J., Evan Chang B., Guyer S.Z., Khedker U.P., Moller A., Vardoulakis D., 2015 Defense of Soundiness:AManifesto. Commun ACM, 58, 2, pp. 44-46, (2015); Mikolov T., Sutskever I., Chen K., Corrado G., Dean J., Distributed Representations ofWords and Phrases and Their Compositionality, Proceedings of the 26th International Conference on Neural Information Processing Systems-, 2, pp. 3111-3119, (2013); MITRE 2021. CWE840; Russell R.L., Kim L.Y., Hamilton L.H., Lazovich T., Harer J.A., Ozdemir O., Ellingwood P.M., McConley M.W., 2018 Automated Vulnerability Detection in Source Code Using Deep Representation Learning, ICMLA, pp. 757-762, (2018); Shi Q., Xiao X., Jinguo Zhou R., Fan G., Zhang C., Pinpoint: Fast and Precise Sparse Value Flow Analysis for Million Lines of Code, Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI ?18). ACM, pp. 693-706, (2018); Shi Q., Yao P., Wu R., Zhang C., 2021 path-sensitive sparse analysis without path conditions, Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation (PLDI ?21). ACM, pp. 930-943; Shi T., Li L., Wang P., Reddy C.K., 2020 A Simple and Effective Self-Supervised Contrastive Learning Framework for Aspect Detection, CoRR abs/2009 09107, (2020); Inc Secure Software, (2014); Srivastava N., Hinton G., Krizhevsky A., Sutskever I., Salakhutdinov R., Dropout: A Simple Way to Prevent Neural Networks fromOverfitting, J. Mach. Learn. Res, 15, pp. 1929-1958, (2014); Sui Y., Cheng X., Zhang G., Wang H., 2020 Flow2Vec: Value-Flow-Based Precise Code Embedding. Proc, ACM Program. Lang 4, (2020); Sui Y., Xue J., SVF: Interprocedural Static Value-Flow Analysis in LLVM, Proceedings of the 25th International Conference on Compiler Construction (Barcelona, Spain) (CC, pp. 265-266, (2016); Sui Y., Ye D., Xue J., Static memory leak detection using full-sparse value-flow analysis, Proceedings of the 2012 International Symposium on Software Testing and Analysis (ISSTA ?12, pp. 254-264, (2012); Sui Y., Ye D., Xue J., Detecting Memory Leaks Statically with Full-Sparse Value-Flow Analysis, pp. 107-122, (2014); Synopsys 2021. Coverity; Tao Xuetingwang L., Yamasaki T., Self-supervised video representation learning using inter-intra contrastive framework, Proceedings of the 28th ACM International Conference on Multimedia (MM ?20). ACM, pp. 2193-2201, (2020); The Tcpdump Group 2021. TCPDUMP; Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., 2017 Attention is All you Need, Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS ?17). Curran Associates, Inc, pp. 6000-6010; Viega J., Bloch J.T., Kohno Y., McGraw G., ITS4: A static vulnerability scanner for C and C++ code, Proceedings 16th Annual Computer Security Applications Conference (ACSAC?00, pp. 257-267, (2000); White M., Vendome C., Linares-Vasquez M., Poshyvanyk D., Toward Deep Learning Software Repositories, Proceedings of the 12th Working Conference on Mining Software Repositories (MSR, pp. 334-345, (2015); Wikipedia 2021. Norm; Xu K., Li C., Tian Y., Sonobe T., Kawarabayashi K., Jegelka S., 2018. Representation Learning on Graphs with Jumping Knowledge Networks. CoRR abs/1806 03536, (2018); Yamaguchi F., Maier A., Gascon H., Rieck K., Automatic Inference of Search Patterns for Taint-Style Vulnerabilities, 2015 IEEE Symposium on Security and Privacy, pp. 797-812, (2015); Yamaguchi F., Hugo Gascon C., Rieck K., Chucky: Exposing missing checks in source code for vulnerability discovery, Proceedings of the 2013 ACM SIGSAC Conference on Computer  Communications Security (CCS ?13). ACM, pp. 499-510, (2013); Yan H., Sui Y., Chen S., Xue J., Spatio-Temporal Context Reduction: A Pointer-Analysis-Based Static Approach for Detecting Useafter-Free Vulnerabilities, Proceedings of the 40th International Conference on Software Engineering (ICSE ?18, (2018); Yang Z., Cheng Y., Liu Y., Sun M., Reducing word omission errors in neural machine translation: A contrastive learning approach, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL ?19). ACM, pp. 6191-6196, (2019); Ying Z., Bourgeois D., You J., Zitnik M., Leskovec J., GNNExplainer: Generating Explanations for Graph Neural Networks, Advances in Neural Information Processing Systems, H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alche-Buc, E. Fox, and R. Garnett (Eds.). Curran Associates, Inc, (2019); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., 2019. A Novel Neural Source Code Representation Based on Abstract Syntax Tree (ICSE, pp. 783-794; Zheng Y., Pujar S., Lewis B., Buratti L., Epstein E., Yang B., Laredo J., Morari A., Su Z., 2021 d2a: A dataset built for aibased vulnerability detection methods using differential analysis, Proceedings of the ACM/IEEE 43rd International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Proceedings of the 33rd International Conference on Neural Information Processing Systems (NIPS ?19). Curran Associates Inc, (2019); Zou D., Wang S., Xu S., Li Z., Jin H., VulDeePecker: A Deep Learning-Based System for Multiclass Vulnerability Detection, TDSC 2019, pp. 1-1, (2019)",ACM; ACM SIGSOFT,"31st ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2022",18 July 2022 through 22 July 2022,"Virtual, Online",181816,English,Conference paper,Final,,Scopus,2-s2.0-85136799873,85
Lin C.; Xu Y.; Fang Y.; Liu Z.,"Lin, Chun (57818819300); Xu, Yijia (57210602136); Fang, Yong (57026722800); Liu, Zhonglin (57218578040)",57818819300; 57210602136; 57026722800; 57218578040,VulEye: A Novel Graph Neural Network Vulnerability Detection Approach for PHP Application,2023,Applied Sciences (Switzerland),13,2,825,,,,9,10.3390/app13020825,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146468835&doi=10.3390%2fapp13020825&partnerID=40&md5=18e5279034f59365a34fda512d5d2da2,"Following advances in machine learning and deep learning processing, cyber security experts are committed to creating deep intelligent approaches for automatically detecting software vulnerabilities. Nowadays, many practices are for C and C++ programs, and methods rarely target PHP application. Moreover, many of these methods use LSTM (Long Short-Term Memory) but not GNN (Graph Neural Networks) to learn the token dependencies within the source code through different transformations. That may lose a lot of semantic information in terms of code representation. This article presents a novel Graph Neural Network vulnerability detection approach, VulEye, for PHP applications. VulEye can assist security researchers in finding vulnerabilities in PHP projects quickly. VulEye first constructs the PDG (Program Dependence Graph) of the PHP source code, slices PDG with sensitive functions contained in the source code into sub-graphs called SDG (Sub-Dependence Graph), and then makes SDG the model input to train with a Graph Neural Network model which contains three stack units with a GCN layer, Top-k pooling layer, and attention layer, and finally uses MLP (Multi-Layer Perceptron) and softmax as a classifier to predict if the SDG is vulnerable. We evaluated VulEye on the PHP vulnerability test suite in Software Assurance Reference Dataset. The experiment reports show that the best macro-average F1 score of the VulEye reached 99% in the binary classification task and 95% in the multi-classes classification task. VulEye achieved the best result compared with the existing open-source vulnerability detection implements and other state-of-art deep learning models. Moreover, VulEye can also locate the precise area of the flaw, since our SDG contains code slices closely related to vulnerabilities with a key triggering sensitive/sink function. © 2023 by the authors.","Sun H., Cui L., Li L., Ding Z., Hao Z., Cui J., Liu P., VDSimilar: Vulnerability detection based on code similarity of vulnerabilities and patches, Comput. Secur, 110, (2021); Zhang H., Wang S., Li H., Chen T.H., Hassan A.E., A Study of C/C++ Code Weaknesses on Stack Overflow, IEEE Trans. Softw. Eng, 48, pp. 2359-2375, (2022); Fang Y., Han S., Huang C., Wu R., TAP: A static analysis model for PHP vulnerabilities based on token and deep learning technology, PLoS ONE, 14, pp. 1-19, (2019); Guo W., Fang Y., Huang C., Ou H., Lin C., Guo Y., HyVulDect: A hybrid semantic vulnerability mining system based on Graph Neural Network, Comput. Secur, 121, (2022); Jovanovic N., Kruegel C., Kirda E., Pixy: A static analysis tool for detecting Web application vulnerabilities, Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06), pp. 6-263; Dahse J., Schwenk J., RIPS-A static source code analyser for vulnerabilities in PHP scripts, Seminar Work (Seminer Çalismasi), (2010); Dahse J., Holz T., Simulation of Built-in PHP Features for Precise Static Code Analysis, Proceedings of the NDSS, 14, pp. 23-26; Son S., Shmatikov V., SAFERPHP: Finding semantic vulnerabilities in PHP applications, Proceedings of the ACM SIGPLAN 6th Workshop on Programming Languages and Analysis for Security, pp. 1-13; Nunes P.J.C., Fonseca J., Vieira M., phpSAFE: A security analysis tool for OOP web application plugins, Proceedings of the 2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks, pp. 299-306; Medeiros I., Neves N., Correia M., Equipping wap with weapons to detect vulnerabilities: Practical experience report, Proceedings of the 2016 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pp. 630-637; Huang J., Li Y., Zhang J., Dai R., UChecker: Automatically detecting php-based unrestricted file upload vulnerabilities, Proceedings of the 2019 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pp. 581-592; Fidalgo A., Medeiros I., Antunes P., Neves N., Towards a deep learning model for vulnerability detection on web application variants, Proceedings of the 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW), pp. 465-476; Guo N., Li X., Yin H., Gao Y., Vulhunter: An automated vulnerability detection system based on deep learning and bytecode, Proceedings of the International Conference on Information and Communications Security, pp. 199-218; Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The Graph Neural Network model, IEEE Trans. Neural Netw, 20, pp. 61-80, (2008); Backes M., Rieck K., Skoruppa M., Stock B., Yamaguchi F., Efficient and flexible discovery of php application vulnerabilities, Proceedings of the 2017 IEEE European Symposium on Security and Privacy (EuroS&P), pp. 334-349; Rabheru R., Hanif H., Maffeis S., A Hybrid Graph Neural Network Approach for Detecting PHP Vulnerabilities, Proceedings of the 2022 IEEE Conference on Dependable and Secure Computing (DSC), pp. 1-9; Le Q., Mikolov T., Distributed Representations of Sentences and Documents, Proceedings of the 31st International Conference on International Conference on Machine Learning (ICML’14), 32; Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, arXiv, (2016); Weiser M., Program slicing, IEEE Trans. Softw. Eng, 4, pp. 352-357, (1984); Stivalet B., PHP Vulnerability Test Suite; Medeiros I., Neves N., Correia M., Detecting and removing web application vulnerabilities with static analysis and data mining, IEEE Trans. Reliab, 65, pp. 54-69, (2015); Medeiros I., Neves N., Correia M., DEKANT: A static analysis tool that learns to detect web application vulnerabilities, Proceedings of the 25th International Symposium on Software Testing and Analysis, pp. 1-11; Rabiner L.R., A tutorial on hidden Markov models and selected applications in speech recognition, Proc. IEEE, 77, pp. 257-286, (1989); Kronjee J., Hommersom A., Vranken H., Discovering software vulnerabilities using data-flow analysis and machine learning, Proceedings of the Proceedings of the 13th International Conference on Availability, Reliability and Security, pp. 1-10; Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, arXiv, (2018); Lin G., Wen S., Han Q.L., Zhang J., Xiang Y., Software Vulnerability Detection Using Deep Neural Networks: A Survey, Proc. IEEE, 108, pp. 1825-1848, (2020); Corporation M., 2022 CWE Top 25 Most Dangerous Software Weaknesses; Li Y., Wang S., Nguyen T.N., Van Nguyen S., Improving bug detection via context-based code representation learning and attention-based neural networks, Proc. ACM Program. Lang, 3, pp. 1-30, (2019); Fan W., Ma Y., Li Q., He Y., Zhao E., Tang J., Yin D., Graph Neural Networks for social recommendation, Proceedings of the World Wide Web Conference, pp. 417-426; Shang C., Tang Y., Huang J., Bi J., He X., Zhou B., End-to-end structure-aware convolutional networks for knowledge base completion, Proceedings of the AAAI Conference on Artificial Intelligence, 33, pp. 3060-3067; Zheng C., Fan X., Wang C., Qi J., Gman: A graph multi-attention network for traffic prediction, Proceedings of the AAAI Conference on Artificial Intelligence, 34, pp. 1234-1241; Khamsi M.A., Kirk W.A., An Introduction to Metric Spaces and Fixed Point Theory, (2011); Fey M., Pytorch Geometric Documentation",,,,,,English,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85146468835,86
Şahin S.E.; Özyedierler E.M.; Tosun A.,"Şahin, Sefa Eren (57208426892); Özyedierler, Ecem Mine (57416296900); Tosun, Ayse (26649652100)",57208426892; 57416296900; 26649652100,Predicting vulnerability inducing function versions using node embeddings and graph neural networks,2022,Information and Software Technology,145,,106822,,,,5,10.1016/j.infsof.2022.106822,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123002701&doi=10.1016%2fj.infsof.2022.106822&partnerID=40&md5=faca0fa5b8ecb873804f1428477ad855,"Context: Predicting software vulnerabilities over code changes is a difficult task due to obtaining real vulnerability data and their associated code fixes from software projects as software organizations are often reluctant to report those. Objective: We aim to propose a vulnerability prediction model that runs after every code change, and identifies vulnerability inducing functions in that version. We also would like to assess the success of node and token based source code representations over abstract syntax trees (ASTs) on predicting vulnerability inducing functions. Method: We train neural networks to represent node embeddings and token embeddings over ASTs in order to obtain feature representations. Then, we build two Graph Neural Networks (GNNs) with node embeddings, and compare them against Convolutional Neural Network (CNN) and Support Vector Machine (SVM) with token representations. Results: We report our empirical analysis over the change history of vulnerability inducing functions of Wireshark project. GraphSAGE model using source code representation via ASTs achieves the highest AUC rate, while CNN models using token representations achieves the highest recall, precision and F1 measure. Conclusion: Representing functions with their structural information extracted from ASTs, either in token form or in complete graph form, is great at predicting vulnerability inducing function versions. Transforming source code into token frequencies as a natural language text fails to build successful models for vulnerability prediction in a real software project. © 2022 Elsevier B.V.","(2011); Meneely A., Chapter 8 - analyzing security data, The Art And Science Of Analyzing Software Data, pp. 215-229, (2015); Piessens F., A taxonomy of causes of software vulnerabilities in Internet software, (2002); Camilo F., Meneely A., Nagappan M., Do bugs foreshadow vulnerabilities? A study of the chromium project, 2015 IEEE/ACM 12th Working Conference On Mining Software Repositories, pp. 269-279, (2015); Walden J., Stuckman J., Scandariato R., Predicting vulnerable components: Software metrics vs text mining, 2014 IEEE 25th International Symposium On Software Reliability Engineering, pp. 23-33, (2014); Yamaguchi F., Lottmann M., Rieck K., Generalized vulnerability extrapolation using abstract syntax trees, Proceedings Of The 28th Annual Computer Security Applications Conference On - ACSAC ’12, (2012); Hovsepyan A., Scandariato R., Joosen W., Walden J., Software vulnerability prediction using text analysis techniques, Proceedings Of The 4th International Workshop On Security Measurements And Metrics, MetriSec ’12, pp. 7-10, (2012); Suneja S., Zheng Y., Zhuang Y., Laredo J., Morari A., Learning to map source code to software vulnerability using code-as-a-graph, (2020); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated Graph Sequence Neural Networks, (2016); Zhang Y., Lo D., Xia X., Xu B., Sun J., Li S., Combining software metrics and text features for vulnerable file prediction, 2015 20th International Conference On Engineering Of Complex Computer Systems, ICECCS, pp. 40-49, (2015); Cao D., Huang J., Zhang X., Liu X., FTCLNet: Convolutional LSTM with Fourier transform for vulnerability detetion, IEEE 19th International Conference On Trust, Security And Privacy In Computing And Communications, TrustCom, pp. 539-546, (2020); Neuhaus S., Zimmermann T., Holler C., Zeller A., Predicting vulnerable software components, Proceedings Of the 14th ACM Conference on Computer and Communications Security, CCS ’07, pp. 529-540, (2007); Zimmermann T., Nagappan N., Williams L., Searching for a Needle in a Haystack: Predicting Security Vulnerabilities for Windows Vista, pp. 421-428, (2010); Shin Y., Meneely A., Williams L., Osborne J.A., Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities, IEEE Trans. Softw. Eng., 37, 6, pp. 772-787, (2011); Shin Y., Williams L., Can traditional fault prediction models be used for vulnerability prediction?, Empir. Softw. Eng., 18, 1, pp. 25-59, (2013); Morrison P., Herzig K., Murphy B., Williams L., Challenges with applying vulnerability prediction models, Proceedings of the 2015 Symposium and Bootcamp on the Science Of Security, HotSoS ’15, pp. 1-9, (2015); Scandariato R., Walden J., Hovsepyan A., Joosen W., Predicting vulnerable software components via text mining, IEEE Trans. Softw. Eng., 40, 10, pp. 993-1006, (2014); Kamei Y., Shihab E., Adams B., Hassan A., Mockus A., Sinha A., Ubayashi N., A large-scale empirical study of just-in-time quality assurance, IEEE Trans. Softw. Eng., 39, 6, pp. 757-773, (2013); Ghaffarian S.M., Shahriari H.R., Neural software vulnerability analysis using rich intermediate graph representations of programs, Inform. Sci., 553, pp. 189-207, (2021); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, (2019); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet?, (2020); Menzies T., Greenwald J., Frank A., Data mining static code attributes to learn defect predictors, IEEE Trans. Softw. Eng., 33, 1, pp. 2-13, (2007); McIntosh S., Kamei Y., [Journal first] are fix-inducing changes a moving target?: A longitudinal case study of just-in-time defect prediction, 2018 IEEE/ACM 40th International Conference On Software Engineering, ICSE, (2018); Pornprasit C., Tantithamthavorn C., JITLine: A Simpler, Better, Faster, Finer-grained Just-In-Time Defect Prediction, pp. 369-379, (2021); Eken B., Tufan S., Tunaboylu A., Guler T., Atar R., Tosun A., Deployment of a change-level software defect prediction solution into an industrial setting, J. Softw.: Evol. Process, (2021); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5th International Conference On Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings, (2017); Hamilton W.L., Ying Z., Leskovec J., Inductive Representation Learning on Large Graphs, pp. 1024-1034, (2017); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, (2018); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating Sequences from Structured Representations of Code, (2019); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Proceedings Of The Thirtieth AAAI Conference On Artificial Intelligence, pp. 1287-1293, (2016); Schrouff J.V., Wohlfahrt K., Marnette B., Atkinson L., Inferring Javascript types using Graph Neural Networks, (2019); Liang H., Sun L., Wang M., Yang Y., Deep learning with customized abstract syntax tree for bug localization, IEEE Access, 7, pp. 116309-116320, (2019); Garg A., Degiovanni R., Jimenez M., Cordy M., Papadakis M., Traon Y.L., Learning to predict vulnerabilities from vulnerability-fixes: a machine translation approach, (2020); Zheng W., Gao J., Wu X., Xun Y., Liu G., Chen X., An Empirical Study of High-Impact Factors for Machine Learning-Based Vulnerability Detection, pp. 26-34, (2020); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Trans. Neural Netw., 20, 1, pp. 61-80, (2009); Schlichtkrull M., Kipf T.N., Bloem P., van den Berg R., Titov I., Welling M., Modeling relational data with graph convolutional networks, The Semantic Web, Lecture Notes in Computer Science, pp. 593-607, (2018); Xu K., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks?, 7th International Conference On Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019, (2019); Zhou J., Cui G., Hu S., Zhang Z., Yang C., Liu Z., Wang L., Li C., Sun M., Graph neural networks: A review of methods and applications, AI Open, 1, pp. 57-81, (2020); Bruna J., Zaremba W., Szlam A., LeCun Y., Spectral Networks and Locally Connected Networks on Graphs, (2014); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: learning distributed representations of code, Proc. ACM Programm. Lang., 3, POPL, pp. 1-29, (2019); Sliwerski J., Zimmermann T., Zeller A., When do changes induce fixes?, Proceedings Of The 2005 International Workshop On Mining Software Repositories, St. Louis, Missouri, MSR ’05, pp. 1-5, (2005); Sahin S.E., Ozyedierler E.M., Tosun A., (2022); Goodfellow I., Bengio Y., Courville A., Deep Learning, (2016); Mikolov T., Chen K., Corrado G., Dean J., Efficient Estimation of Word Representations in Vector Space, (2013); Maaten L.V.D., Hinton G.E., Visualizing data using t-SNE, J. FMach. Learn. Res., (2008); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A comprehensive survey on graph neural networks, IEEE Trans. Neural Netw. Learn. Syst., pp. 1-21, (2020); Lin G., Wen S., Han Q.L., Zhang J., Xiang Y., Software vulnerability detection using deep neural networks: A survey, Proc. IEEE, 108, 10, pp. 1825-1848, (2020); Spanos G., Angelis L., Toloudis D., Assessment of vulnerability severity using text mining, Proceedings Of The 21st Pan-Hellenic Conference On Informatics, (2017); Shein K.P.P., Nyunt T.T.S., Sentiment classification based on ontology and SVM classifier, 2010 Second International Conference On Communication Software And Networks, pp. 169-172, (2010); Colas F., Brazdil P., Comparison of SVM and some older classification algorithms in text classification tasks, Artificial Intelligence In Theory And Practice, Vol. 217, pp. 169-178, (2006); Sahin S.E., Ozyedierler E.M., Tosun A.; Perozzi B., Al-Rfou R., Skiena S., DeepWalk: online learning of social representations, Proceedings Of The 20th ACM SIGKDD International Conference On Knowledge Discovery And Data Mining, KDD ’14, pp. 701-710, (2014); Grover A., Leskovec J., Node2vec: Scalable feature learning for networks, Proceedings Of The 22nd ACM SIGKDD International Conference On Knowledge Discovery And Data Mining, pp. 855-864, (2016); Maloof A., Learning when data sets are imbalanced and when costs are unequal and unknown, (2003)",,,,,,English,Article,Final,,Scopus,2-s2.0-85123002701,87
Hin D.; Kan A.; Chen H.; Babar M.A.,"Hin, David (57213001510); Kan, Andrey (57217611527); Chen, Huaming (56021883400); Babar, M. Ali (6602842620)",57213001510; 57217611527; 56021883400; 6602842620,LineVD: Statement-level Vulnerability Detection using Graph Neural Networks,2022,"Proceedings - 2022 Mining Software Repositories Conference, MSR 2022",,,,596,607,11,68,10.1145/3524842.3527949,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134019413&doi=10.1145%2f3524842.3527949&partnerID=40&md5=5148d83b0082ec460c9f6f5ef06cd8e1,"Current machine-learning based software vulnerability detection methods are primarily conducted at the function-level. However, a key limitation of these methods is that they do not indicate the specific lines of code contributing to vulnerabilities. This limits the ability of developers to efficiently inspect and interpret the predictions from a learnt model, which is crucial for integrating machine-learning based tools into the software development work-flow. Graph-based models have shown promising performance in function-level vulnerability detection, but their capability for statement-level vulnerability detection has not been extensively explored. While interpreting function-level predictions through explainable AI is one promising direction, we herein consider the statement-level software vulnerability detection task from a fully supervised learning perspective. We propose a novel deep learning framework, LineVD, which formulates statement-level vulnerability detection as a node classification task. LineVD leverages control and data dependencies between statements using graph neural networks, and a transformer-based model to encode the raw source code tokens. In particular, by addressing the conflicting outputs between function-level and statement-level information, LineVD significantly improve the prediction performance without vulnerability status for function code. We have conducted extensive experi-ments against a large-scale collection of real-world C/C++ vulnerabilities obtained from multiple real-world projects, and demonstrate an increase of 105% in F1-score over the current state-of-the-art. © 2022 ACM.","NIST: National Vulnerability Database., (2021); Uddin Ahmad W., Chakraborty S., Ray B., Chang K., Unified Pre-training for Program Understanding and Generation, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies., pp. 2655-2668, (2021); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, International Conference on Learning Representations., pp. 1-17, (2018); Alon U., Yahav E., On the bottleneck of graph neural networks and its practical implications, International Conference on Learning Representations (ICLR)., pp. 1-16, (2020); Aloraini B., Nagappan M., German D.M., Hayashi S., Higo Y., An empirical study of security warnings from static application security testing tools, Journal of Systems and Software, 158, (2019); Reproduction Package for MSR Double-blind Review., (2022); Bian R., Sing Koh Y., Dobbie G., Divoli A., Network embedding and change modeling in dynamic heterogeneous networks, Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval., pp. 861-864, (2019); Buratti L., Pujar S., Bornea M., McCarley S., Zheng Y., Rossiello G., Morari A., Laredo J., Thost V., Zhuang Y., Et al., Exploring Software Naturalness Through Neural Language Models, (2020); Cao S., Sun X., Bo L., Wei Y., Li B., BGNN4VD: Constructing Bidirectional Graph Neural-Network for Vulnerability Detection, Information and Software Technology, 136, (2021); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet, IEEE Transactions on Software Engineering, (2021); Chen C., Li K., Teo S.G., Zou X., Wang K., Wang J., Zeng Z., Gated residual recurrent graph neural networks for traffic prediction, Proceedings of the AAAI Conference on Artificial Intelligence, 33, pp. 485-492, (2019); Cheng X., Wang H., Hua J., Xu G., Sui Y., DeepWukong: Statically detecting software vulnerabilities using deep graph neural network, ACM Transactions on Software Engineering and Methodology (TOSEM), 30, 3, pp. 1-33, (2021); Croft R., Newlands D., Chen Z., Ali Babar M., An Empirical Study of Rule-Based and Learning-Based Approaches for Static Application Security Testing, Proceedings of the 15th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)., pp. 1-12, (2021); Cui L., Hao Z., Jiao Y., Fei H., Yun X., VulDetector: Detecting Vulnerabilities Using Weighted Feature Graph Comparison, IEEE Transactions on Information Forensics and Security, 16, pp. 2004-2017, (2020); Ding Y., Suneja S., Zheng Y., Laredo J., Morari A., Kaiser G., Ray B., VELVET: A noVel Ensemble Learning approach to automatically locate VulnErable sTatements, 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)., pp. 1-12, (2022); Du X., Chen B., Li Y., Guo J., Zhou Y., Liu Y., Jiang Y., Leopard: Identifying vulnerable code for vulnerability assessment through program metrics, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)., pp. 60-71, (2019); Duan X., Wu J., Ji S., Rui Z., Luo T., Yang M., Wu Y., VulSniper: Focus Your Attention to Shoot Fine-Grained Vulnerabilities, Proceedings of the 27th International Conference on International Joint Conferences on Artificial Intelligence., pp. 4665-4671, (2019); Falessi D., Huang J., Narayana L., Fong Thai J., Turhan B., On the need of preserving order of data when validating withinproject defect classifiers, Empirical Software Engineering, 25, 6, pp. 4805-4830, (2020); Fan J., Li Y., Wang S., Nguyen T.N., AC/C++ Code Vulnerability Dataset with Code Changes and CVE Summaries, Proceedings of the 17th International Conference on Mining Software Repositories., pp. 508-512, (2020); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., CodeBERT: A Pre- Trained Model for Programming and Natural Languages, Findings of the Association for Computational Linguistics: EMNLP 2020., pp. 1536-1547, (2020); Mohammad Ghaffarian S., Reza Shahriari H., Software vulnerability analysis and discovery using machine-learning and data-mining techniques: A survey, ACM Computing Surveys (CSUR), 50, 4, pp. 1-36, (2017); Hanif H., Md Nasir M.H.N., Ab Razak M.F., Firdaus A., Badrul Anuar N., The rise of software vulnerability: Taxonomy of software vulnerabilities detection and machine learning approaches, Journal of Network and Computer Applications, (2021); Hoang T., Jin Kang H., Lo D., Lawall J., Cc2vec: Distributed representations of code changes, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering., pp. 518-529, (2020); Hovsepyan A., Scandariato R., Joosen W., Is Newer Always Better? the Case of Vulnerability Prediction Models, Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement., pp. 1-6, (2016); Jang-Jaccard J., Nepal S., A survey of emerging threats in cybersecurity, J. Comput. System Sci., 80, 5, pp. 973-993, (2014); Johnson A., Waye L., Moore S., Chong S., Exploring and enforcing security guarantees via program dependence graphs, ACM SIGPLAN Notices, 50, 6, pp. 291-302, (2015); Kim S., Woo S., Lee H., Oh H., Vuddy: A scalable approach for vulnerable code clone discovery, 2017 IEEE Symposium on Security and Privacy (SP)., pp. 595-614, (2017); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks, Proceedings of the 5th International Conference on Learning Representations (Palais des Congres Neptune, Toulon, France) (ICLR '17)., (2017); Le Q., Mikolov T., Distributed representations of sentences and documents, International Conference on Machine Learning. PMLR, pp. 1188-1196, (2014); Le T.H.M., Chen H., Ali Babar M., Deep learning for source code modeling and generation: Models, applications, and challenges, ACM Computing Surveys (CSUR), 53, 3, pp. 1-38, (2020); Lessmann S., Baesens B., Mues C., Pietsch S., Benchmarking classification models for software defect prediction: A proposed framework and novel findings, IEEE Transactions on Software Engineering, 34, 4, pp. 485-496, (2008); Li Y., Wang S., Nguyen T.N., Vulnerability Detection with Finegrained Interpretations, The 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, (2021); Li Z., Zou D., Xu S., Chen Z., Zhu Y., Jin H., Vuldeelocator: A deep learning-based fine-grained vulnerability detector, IEEE Transactions on Dependable and Secure Computing, pp. 1-17, (2021); Li Z., Zou D., Xu S., Jin H., Qi H., Hu J., Vulpecker: An automated vulnerability detection system based on code similarity analysis, Proceedings of the 32nd Annual Conference on Computer Security Applications., pp. 201-213, (2016); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., SySeVR: A framework for using deep learning to detect software vulnerabilities, IEEE Transactions on Dependable and Secure Computing, (2021); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., VulDeePecker: A Deep Learning-Based System for Vulnerability Detection, Network and Distributed Systems Security (NDSS) Symposium, 2018, pp. 1-12, (2018); Liaw R., Liang E., Nishihara R., Moritz P., Gonzalez J.E., Stoica I., Tune: A Research Platform for Distributed Model Selection and Training, (2018); Lin G., Xiao W., Yu Zhang L., Gao S., Tai Y., Zhang J., Deep neural-based vulnerability discovery demystified: Data, model and performance, Neural Computing and Applications, pp. 1-14, (2021); Liu B., Shi L., Cai Z., Li M., Software vulnerability discovery techniques: A survey, 2012 Fourth International Conference on Multimedia Information Networking and Security., pp. 152-156, (2012); Liu C., Chen C., Han J., Yu P.S., GPLAG: Detection of software plagiarism by program dependence graph analysis, Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining., pp. 872-881, (2006); Liu F., Li G., Zhao Y., Jin Z., Multi-task learning based pretrained language model for code completion, Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering., pp. 473-485, (2020); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., Roberta: A Robustly Optimized Bert Pretraining Approach, (2019); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in Neural Information Processing Systems., pp. 3111-3119, (2013); Naeem H., Alalfi M.H., Identifying Vulnerable IoT Applications using Deep Learning, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)., pp. 582-586, (2020); Nair V., Hinton G.E., Rectified linear units improve restricted boltzmann machines, Proceedings of the 27th International Conference on International Conference on Machine Learning., pp. 807-814, (2010); Ngoc Nguyen H., Teerakanok S., Inomata A., Uehara T., The Comparison ofWord Embedding Techniques in RNNs for Vulnerability Detection, ICISSP, pp. 109-120, (2021); Pennington J., Socher R., Manning C.D., Glove: Global vectors for word representation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)., pp. 1532-1543, (2014); Pham N.H., Thanh Nguyen T., Anh Nguyen H., Nguyen T.N., Detection of recurring software vulnerabilities, Proceedings of the IEEE/ACM International Conference on Automated Software Engineering., pp. 447-456, (2010); Pornprasit C., Tantithamthavorn C., JITLine: A Simpler, Better, Faster, Finer-grained Just-In-Time Defect Prediction, 2021 International Conference on Mining Software Repositories (MSR'21)., pp. 1-11, (2021); Pornprasit C., Tantithamthavorn C., DeepLineDP: Towards a Deep Learning Approach for Line-Level Defect Prediction, IEEE Transactions on Software Engineering, 1, (2022); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., Sourcerercc: Scaling code clone detection to big-code, Proceedings of the 38th International Conference on Software Engineering., pp. 1157-1168, (2016); Scandariato R., Walden J., Hovsepyan A., Joosen W., Predicting vulnerable software components via text mining, IEEE Transactions on Software Engineering, 40, 10, pp. 993-1006, (2014); Scarselli F., Gori M., Chung Tsoi A., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Transactions on Neural Networks, 20, 1, pp. 61-80, (2008); Sennrich R., Haddow B., Birch A., Neural Machine Translation of Rare Words with Subword Units., pp. 1715-1725, (2016); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph Attention Networks, Proceedings of the 6th International Conference on Learning Representations., pp. 1-12, (2018); Wang D., Yu Y., Li S., Dong W., Wang J., Qing L., Mul- Code: A Multi-task Learning Approach for Source Code Understanding, 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)., pp. 48-59, (2021); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)., pp. 261-271, (2020); Wattanakriengkrai S., Thongtanunam P., Tantithamthavorn C., Hata H., Matsumoto K., Predicting Defective Lines Using a Model-Agnostic Technique, IEEE Transactions on Software Engineering, 1, (2020); Wilcoxon F., Individual comparisons by ranking methods, Breakthroughs in Statistics., pp. 196-202, (1992); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy., pp. 590-604, (2014); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, 32, pp. 8026-8037, (2019); Zou D., Zhu Y., Xu S., Li Z., Jin H., Ye H., Interpreting deep learning-based vulnerability detector predictions based on heuristic searching, ACM Transactions on Software Engineering and Methodology (TOSEM), 30, 2, pp. 1-31, (2021)",Association for Computing Machinery (ACM); IEEE Computer Society; JetBrains; Special Interest Group on Software Engineering (ACM SIGSOFT); Technical Council on Software Engineering (IEEE TCSE),"2022 Mining Software Repositories Conference, MSR 2022",23 May 2022 through 24 May 2022,Pittsburgh,180246,English,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85134019413,88
Li R.; Chen B.; Zhang F.; Sun C.; Peng X.,"Li, Rongfan (59099724400); Chen, Bihuan (35224542900); Zhang, Fengyi (57205029279); Sun, Chao (57188711126); Peng, Xin (53865467700)",59099724400; 35224542900; 57205029279; 57188711126; 53865467700,Detecting Runtime Exceptions by Deep Code Representation Learning with Attention-Based Graph Neural Networks,2022,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",,,,373,384,11,1,10.1109/SANER53432.2022.00053,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134875978&doi=10.1109%2fSANER53432.2022.00053&partnerID=40&md5=8cd8ed205b17dc752c7516483d7b729d,"Uncaught runtime exceptions have been recognized as one of the commonest root causes of real-life exception bugs in Java applications. However, existing runtime exception detection techniques rely on symbolic execution or random testing, which may suffer the scalability or coverage problem. Rule-based bug detectors (e.g., SpotBugs) provide limited rule support for runtime exceptions. Inspired by the recent successes in applying deep learning to bug detection, we propose a deep learning-based technique, named Drex, to identify not only the types of runtime exceptions that a method might signal but also the statement scopes that might signal the detected runtime exceptions. It is realized by graph-based code representation learning with (i) a lightweight analysis to construct a joint graph of CFG, DFG and AST for each method without requiring a build environment so as to comprehensively characterize statement syntax and semantics and (ii) an attention-based graph neural network to learn statement embeddings in order to distinguish different types of potentially signaled runtime exceptions with interpretability. Our evaluation on 54,255 methods with caught runtime exceptions and 54,255 methods without caught runtime exceptions from 5,996 GitHub Java projects has indicated that Drex improves baseline approaches by up to 18.2% in exact accuracy and 41.6% in F1-score. Drex detects 20 new uncaught runtime exceptions in 13 real-life pro-jects, 7 of them have been fixed, while none of them is detected by rule-based bug detectors (i.e., SpotBugs and PMD).  © 2022 IEEE.","Abrantes J., Coelho R., Specifying and dynamically monitoring the exception handling policy, SEKE, pp. 370-374, (2015); Aftandilian E., Sauciuc R., Priya S., Krishnan S., Building useful program analysis tools using an extensible Java compiler, SCAM, pp. 14-23, (2012); Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACAf Computing Surveys, 51, 4, (2018); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, OOPSLA, (2019); Baldoni R., Coppa E., D'Elia D.C., Demetrescu C., Finocchi I., A survey of symbolic execution techniques, ACM Computing Survey, 51, 3, pp. 501-5039, (2018); Barbosa E.A., Garcia A., Barbosa S.D.J., Categorizing faults in exception handling: A study of open source projects, SBES, pp. 11-20, (2014); Barbosa E.A., Garcia A., Robillard M.P., Jakobus B., Enforcing exception handling policies with a domain-specific language, IEEE Transactions on Software Engineering, 42, 6, pp. 559-584, (2016); Ben-Nun T., Jakobovits A.S., Hoefler T., Neural code comprehension: A learnable representation of code semantics, NIPS, pp. 3585-3597, (2018); Bian P., Liang B., Shi W., Huang J., Cai Y., Nar-miner: Discovering negative association rules from code for bug detection, ESEC/FSE, pp. 411-422, (2018); Bielik P., Raychev V., Vechev M., Trogramrning with ""big code"" Lessons, techniques and applications, SNAPL, pp. 1-10, (2015); Bloch J., Effective Java, (2016); Chen C., Su T., Meng G., Xing Z., Liu Y., From ui design image to gui skeleton: A neural machine translator to bootstrap mobile gui implementation, ICSE, pp. 665-676, (2018); Chen H., Dou W., Jiang Y., Qin F., Understanding exception-related bugs in large-scale cloud systems, ASE, pp. 339-351, (2019); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using run encoder-decoder for statistical machine translation, EMNLP, pp. 1724-1734, (2014); Choi M.-J., Jeong S., Oh H., Choo J., End-to-end prediction of buffer overruns from raw source code via neural memory networks, IJCAI, pp. 1546-1553, (2017); Coelho R., Almeida L., Gousios G., Van Deursen A., Unveiling exception handling bug hazards in android based on github and google code issues, MSR, pp. 134-145, (2015); Coelho R., Rashid A., Garcia A., Ferrari F., Cacho N., Kulesza U., Von Staa A., Lucena C., Assessing the impact of aspects on exception flows: An exploratory study, ECOOP, pp. 207-234, (2008); Coelho R., Rashid A., Von Staa A., Noble J., Kulesza U., Lucena C., A catalogue of bug patterns for exception handling in aspect-oriented programs, PLoP, pp. 1-13, (2008); Copeland T., PMD Applied, (2005); Cortes-Coy L.F., Linares-Vasquez M., Aponte J., Poshyvanyk D., On automatically generating commit messages via summarization of source code changes, SCAM, pp. 275-284, (2014); Cristian F., Exception handling and software fault tolerance, IEEE Transactions on Computers, 31, 6, pp. 531-540, (1982); Csallner C., Smaragdakis Y., Jcrasher: An automatic robustness tester for Java, Software: Practice and Experience, 34, 11, pp. 1025-1050, (2004); DeFreez D., Thakur A.V., Rubio-Gonzalez C., Path-based function embedding and its application to error-handling specification mining, ESEC/FSE, pp. 423-433, (2018); Ebert F., Castor F., A study on developers' perceptions about exception handling bugs, ICSM, pp. 448-451, (2013); Ebert F., Castor F., Serebrenik A., An exploratory study on exception handling bugs in Java programs, Journal of Systems and Software, 106, pp. 82-101, (2015); Engler D., Chen D.Y., Hallem S., Chou A., Chelf B., Bugs as deviant behavior: A general approach to inferring errors in systems code, SOSP, pp. 57-72, (2001); Ernst M.D., Natural language is a programming language: Applying natural language processing to software development, SNAPL, pp. 1-14, (2017); Fan L., Su T., Chen S., Meng G., Liu Y., Xu L., Pu G., Su Z., Large-scale analysis of framework-specific exceptions in android apps, ICSE, pp. 408-419, (2018); Filho F.C., Cacho N., Figueiredo E., Maranhao R., Garcia A., Rubira C.M.F., Exceptions and aspects: The devil is in the details, FSE, pp. 152-162, (2006); Filho J.L.M., Rocha L., Andrade R., Britto R., Preventing erosion in exception handling design using static-architecture conformance checking, ECSA, pp. 67-83, (2017); Garcia A.F., Rubira C.M., Romanovsky A., Xu J., A comparative study of exception handling mechanisms for building dependable object-oriented software, Journal of Systems and Software, 59, 2, pp. 197-222, (2001); Goodenough J.B., Exception handling: Issues and a proposed notation, Communications of the ACM, 18, 12, pp. 683-696, (1975); Gu X., Zhang H., Kim S., Deep code search, ICSE, pp. 933-944, (2018); Gu X., Zhang H., Zhang D., Kim S., Deep api learning, FSE, pp. 631-642, (2016); Gu X., Zhang H., Zhang D., Kim S., Deepam: Migrate apis with multi-modal sequence to sequence learning, AAAI, pp. 3675-3681, (2017); Gupta R., Kanade A., Shevade S., Deep reinforcement learning for syntactic error repair in student programs, AAAI, pp. 930-937, (2019); Habib A., Pradel M., How many of all bugs do we find? a study of static bug detectors, ASE, pp. 317-328, (2018); Habib A., Pradel M., Neural bug finding: A study of opportunities and challenges, (2019); Henkel J., Lahiri S.K., Liblit B., Reps T., Code vectors: Understanding programs through embedded abstracted symbolic traces, ESEC/FSE, pp. 163-174, (2018); Hooimeijer P., Luca M., O'Hearn P., Papakonstantinou I., Purbrick J., Rodriguez D., Moving fast with software verification, NFM, pp. 3-11, (2015); Hovemeyer D., Pugh W., Finding bugs is easy, OOPSLA, pp. 92-106, (2004); Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., Summarizing source code with transferred API knowledge, AAA?, pp. 2269-2275, (2018); Jakobus B., Barbosa E.A., Garcia A., De Lucena C.J.P., Contrasting exception handling code across languages: An experience report involving 50 open source projects, ISSRE, pp. 183-193, (2015); Jiang S., Zhang H., Wang Q., Zhang Y., A debugging approach for Java runtime exceptions based on program slicing and stack traces, QSIC, pp. 393-398, (2010); Jo J.-W., Chang B.-M., Yi K., Choe K.-M., An uncaught exception analysis for Java, Journal of Systems and Software, 72, 1, pp. 59-69, (2004); Kadar I., Hegedus P., Ferenc R., Runtime exception detection in Java programs using symbolic execution, Acta Cybernetica, 21, 3, pp. 331-352, (2014); Kechagia M., Spinellis D., Undocumented and unchecked: Exceptions that spell trouble, MSR, pp. 312-315, (2014); Kery M.B., Le Goues C., Myers B.A., Examining programmer practices for locally handling exceptions, MSR, pp. 484-487, (2016); Le Q., Mikolov T., Distributed representations of sentences and documents, ICML, pp. 1188-1196, (2014); LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, ICSE, pp. 795-806, (2019); Li X., Li W., Zhang Y., Zhang L., Deepfl: integrating multiple fault diagnosis dimensions for deep fault localization, ISSTA, pp. 169-180, (2019); Li X., Jiang H., Kamei Y., Chen X., Bridging semantic gaps between natural languages and apis with word embedding, IEEE Transactions on Software Engineering, (2018); Li Y., Wang S., Nguyen T.N., Van Nguyen S., Improving bug detection via context-based code representation learning and attention-based neural networks, OOPSLA, pp. 1621-16230, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, ICLR, (2016); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, NDSS, (2018); Li Z., Zhou Y., Pr-miner: Automatically extracting implicit programming rules and detecting violations in large software code, ESEC/FSE, pp. 306-315, (2005); Liang B., Bian P., Zhang Y., Shi W., You W., Cai Y., Antminer: Mining more bugs by reducing noise interference, ICSE, pp. 333-344, (2016); Lippert M., Lopes C.V., A study on exception detection and handling using aspect-oriented programming, ICSE, pp. 418-427, (2000); Loyola P., Marrese-Taylor E., Matsuo Y., A neural architecture for generating natural language descriptions from source code changes, ACL, pp. 287-292, (2017); Miller R., Tripathi A., Issues with exception handling in object-oriented systems, ECOOP, pp. 85-103, (1997); Monperrus M., Bruch M., Mezini M., Detecting missing method calls in object-oriented software, ECOOP, pp. 2-25, (2010); Montenegro T., Melo H., Coelho R., Barbosa E., Improving developers awareness of the exception handling policy, SANER, pp. 413-422, (2018); Murali V., Chaudhuri S., Jermaine C., Bayesian specification learning for finding api usage errors, ESEC/FSE, pp. 151-162, (2017); Nakshatri S., Hegde M., Thandra S., Analysis of exception handling patterns in Java projects: An empirical study, MSR, pp. 500-503, (2016); Nguyen A.T., Nguyen T.D., Phan H.D., Nguyen T.N., A deep neural network language model with contexts for source code, SANER, pp. 323-334, (2018); Nguyen T.T., Nguyen H.A., Pham N.H., Al-Kofahi J.M., Nguyen T.N., Graph-based mining of multiple object usage patterns, ESEC/FSE, pp. 383-392, (2009); Oliveira J., Borges D., Silva T., Cacho N., Castor F., Do android developers neglect error handling? a maintenance-centric study on the relationship between android abstractions and uncaught exceptions, Journal of Systems and Software, 136, pp. 1-18, (2018); Pradel M., Jaspan C., Aldrich J., Gross T.R., Statically checking api protocol conformance with mined multi-object specifications, ICSE, pp. 925-935, (2012); Pradel M., Sen K., Deepbugs: A learning approach to name-based bug detection, OOPSLA, pp. 1471-14725, (2018); Raychev V., Vechev M., Yahav E., Code completion with statistical language models, PLDI, pp. 419-428, (2014); Seidel E.L., Sibghat H., Chaudhuri K., Weimer W., Jhala R., Learning to blame: Localizing novice type errors with data-driven diagnosis, OOPSLA, pp. 601-6027, (2017); Sena D., Coelho R., Kulesza U., Bonifacio R., Understanding the exception handling strategies of java libraries: An empirical study, MSR, pp. 212-222, (2016); Shah H., Gorg C., Harrold M.J., Understanding exception handling: Viewpoints of novices and experts, IEEE Transactions on Software Engineering, 36, 2, pp. 150-161, (2010); Shamshiri S., Just R., Rojas J.M., Fraser G., McMinn P., Arcuri A., Do automatically generated unit tests find real faults? an empirical study of effectiveness and challenges, ASE, pp. 201-211, (2015); Sinha S., Shah H., Gorg C., Jiang S., Kim M., Harrold M.J., Fault localization and repair for Java runtime exceptions, ISSTA, pp. 153-164, (2009); Smith N., Van Bruggen D., Tomassetti F., Javaparser: Visited, Leanpub, (2017); Sun Z., Zhu Q., Xiong Y., Sun Y., Mou L., Zhang L., Treegen: A tree-based transformer architecture for code generation, (2020); Thummalapenta S., Xie T., Mining exception-handling rules as; Thummalapenta S., Xie T., An empirical investigation into learning bug-fixing patches in sequence association rales, ICSE, pp. 496-506, (2009); Tufano M., Watson C., Bavota G., Di Penta M., Whits M., Poshy-Vanyk D., Deep learning similarities from different representations of source code, MSR, pp. 542-553, (2018); Vallee-Rai R., Co P., Gagnon E., Hendren L., Lam P., Sundaresan V., Soot: A Java bytecode optimization framework, CASCON, (1999); Van Dooren M., Steegmans E., Combining the robustness of checked exceptions with the flexibility of unchecked exceptions using anchored exception declarations, OOPSLA, pp. 455-471, (2005); Velickovid P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, ICLR, (2018); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P., Multi-modal attention network learning for semantic source code retrieval, ASE, pp. 13-25, (2019); Wang K., Learning scalable and precise representation of program semantics, (2019); Wang K., Singh R., Su Z., Dynamic neural program embeddings for program repair, ICLR, (2018); Wang S., Chollak D., Movshovitz-Attias D., Tan L., Bugram: Bug detection with n-gram language models, ASE, pp. 708-719, (2016); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, ICSE, pp. 297-308, (2016); Wasylkowski A., Zeller A., Mining temporal specifications from object usage, ASE, pp. 295-306, (2009); Wasylkowski A., Zeller A., Lindig C., Detecting object usage anomalies, ESEC/FSE, pp. 35-44, (2007); Weimer W., Necula G.C., Finding and preventing run-time error handling mistakes, OOPSLA, pp. 419-431, (2004); Weimer W., Necula G.C., Mining temporal specifications for error detection, TACAS, pp. 461-476, (2005); Weimer W., Necula G.C., Exceptional situations and program reliability, ACM Transactions on Programming Languages and Systems, 30, 2, pp. 1-51, (2008); White M., Vendome C., Linares-Vasquez M., Poshyvanyk D., Toward deep learning software repositories, MSR, (2015); Wirfs-Brock R.J., Toward exception-handling best practices and patterns, IEEE Software, 23, 5, pp. 11-13, (2006); Wu J., Liu S., Ji S., Yang M., Luo T., Wu Y., Wang Y., Exception beyond exception: Crashing android system by trapping in""uncaughtexception, ICSE-SEIP, pp. 283-292, (2017); Wu Z., Pan S., Chen F., Long G., Zhang C., Philip S.Y., A comprehensive survey on graph neural networks, IEEE Transactions on Neural Networks and Learning Systems, (2020); Yahav E., Programming with ""big code, APLAS, pp. 3-8, (2015); Yuan D., Luo Y., Zhuang X., Rodrigues G.R., Zhao X., Zhang Y., Jain P.U., Stumm M., Simple testing can prevent most critical failures: An analysis of production failures in distributed data-intensive systems, OSDI, pp. 249-265, (2014); Zhang F., Chen B., Li R., Peng X., A hybrid code representation learning approach for predicting method names, Journal of Systems and Software, 180, (2021); Zhang J., Wang X., Zhang H., Sun H., Pu Y., Liu X., Learning to handle exceptions, ASE, pp. 29-41, (2020); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, ICSE, pp. 783-794, (2019); Zhang P., Elbaum S., Amplifying tests to validate exception handling code, ICSE, pp. 595-605, (2012); Zhao G., Huang J., Deepsim: deep learning code functional similarity, ESEC/FSE, pp. 141-151, (2018); Zhou J., Cui G., Zhang Z., Yang C., Liu Z., Wang L., Li C., Sun M., Graph neural networks: A review of methods and applications, (2018); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, NIPS, pp. 10197-10207, (2019)",IEEE Computer Society,"29th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",15 March 2022 through 18 March 2022,"Virtual, Online",181173,English,Conference paper,Final,,Scopus,2-s2.0-85134875978,89
Zou D.; Hu Y.; Li W.; Wu Y.; Zhao H.; Jin H.,"Zou, Deqing (8935128200); Hu, Yutao (57880867900); Li, Wenke (57205355807); Wu, Yueming (57202109788); Zhao, Haojun (57880281400); Jin, Hai (56434989100)",8935128200; 57880867900; 57205355807; 57202109788; 57880281400; 56434989100,mVulPreter: A Multi-Granularity Vulnerability Detection System With Interpretations,2022,IEEE Transactions on Dependable and Secure Computing,,,,1,12,11,10,10.1109/TDSC.2022.3199769,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137554035&doi=10.1109%2fTDSC.2022.3199769&partnerID=40&md5=d4831c43be79246dab220be2e289fcae,"Due to the powerful automatic feature extraction, deep learning-based vulnerability detection methods have evolved significantly in recent years. However, almost all current work focuses on detecting vulnerabilities at a single granularity (<italic>i.e</italic>., slice-level or function-level). In practice, slice-level vulnerability detection is fine-grained but may contain incomplete vulnerability details. Function-level vulnerability detection includes full vulnerability semantics but may contain vulnerability-unrelated statements. Meanwhile, they pay more attention to predicting whether the source code is vulnerable and cannot pinpoint which statements are more likely to be vulnerable. In this paper, we design <italic>mVulPreter</italic>, a multi-granularity vulnerability detector that can provide interpretations of detection results. Specifically, we propose a novel technique to effectively blend the advantages of function-level and slice-level vulnerability detection models and output the detection results&#x0027; interpretation only by the model itself. We evaluate <italic>mVulPreter</italic> on a dataset containing 5,310 vulnerable functions and 7,601 non-vulnerable functions. The experimental results indicate that <italic>mVulPreter</italic> outperforms existing state-of-the-art vulnerability detection approaches (<italic>i.e</italic>., <italic>Checkmarx</italic>, <italic>FlawFinder</italic>, <italic>RATS</italic>, <italic>TokenCNN</italic>, <italic>StatementLSTM</italic>, <italic>SySeVR</italic>, and <italic>Devign</italic>). IEEE",,,,,,,English,Article,Article in press,,Scopus,2-s2.0-85137554035,90
Yan G.; Chen S.; Bail Y.; Li X.,"Yan, Guoqing (57867025600); Chen, Sen (57190395316); Bail, Yude (57215362079); Li, Xiaohong (57022407900)",57867025600; 57190395316; 57215362079; 57022407900,Can Deep Learning Models Learn the Vulnerable Patterns for Vulnerability Detection?,2022,"Proceedings - 2022 IEEE 46th Annual Computers, Software, and Applications Conference, COMPSAC 2022",,,,904,913,9,3,10.1109/COMPSAC54236.2022.00142,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136989786&doi=10.1109%2fCOMPSAC54236.2022.00142&partnerID=40&md5=7dae859cbf5309de1a4c77fa15eb9138,"Deep learning has been widely used for the security issue of vulnerability prediction. However, it is confusing to explain how a deep learning model makes decisions on the prediction, although such a model achieves a good performance. Meanwhile, it is also difficult to discover which part of the source code is concentrated on by this black-box model. To this end, we present an empirical evaluation to explore how the deep learning model works on predicting vulnerability and whether it precisely captures the critical code segments to represent the vulnerable patterns. First of all, we build a new vulnerability dataset, called Juliet+, in which vulnerability-related code lines of both positive (bad) and negative (good) samples are labeled manually with substantial efforts, based on the Juliet Test Suite. After that, four deep learning models by leveraging attention mechanisms are empirically implemented to detect vulnerability through mining vulnerable patterns from the source code. We conduct extensive experiments to evaluate the effectiveness of such four models and to analyze the interpretability with evaluation metrics such as Hit@k. The empirical experiment results reveal that the deep learning models with attention, to some extent, can focus on the vulnerability-related code segments that are profitable to interpret the result of vulnerability detection, especially when we adopt the graph neural network model. We further investigate what factors affect the interpretability of models including the class distribution, the number of samples, and the differences of sample features. We find the graph neural network model performs better on part of the dataset which contains balanced and sufficient samples with obvious differences between vulnerable and non-vulnerable patterns. © 2022 IEEE.","Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, (2018); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: A framework for using deep learning to detect software vulnerabilities, IEEE Transactions on Dependable and Secure Computing (TDSC), (2021); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, (2019); Wang H., Ye G., Tang Z., Hwei Tan S., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Transactions on Information Forensics and Security (TIFS), 16, pp. 1943-1958, (2020); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet, IEEE Transactions on Software Engineering (TSE), (2021); Zheng W., Jiang Y., Su X., Vulspg: Vulnerability detection based on slice property graph representation learning, (2021); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE), pp. 297-308, (2016); Hinton G.E., Osindero S., Teh Y.-W., A fast learning algorithm for deep belief nets, Neural computation, 18, 7, pp. 1527-1554, (2006); Lin G., Wen S., Han Q.-L., Zhang J., Xiang Y., Software vulnerability detection using deep neural networks: A survey, Proceedings of the IEEE (Proc.IEEE), 108, 10, pp. 1825-1848, (2020); Bahdanau D., Cho K., Bengio Y., Neural machine translation by jointly learning to align and translate, (2014); Zhou P., Shi W., Tian J., Qi Z., Li B., Hao H., Xu B., Attention-based bidirectional long short-term memory networks for relation classification, Proceedings of the 54th annual meeting of the association for computational linguistics (volume 2: Short papers), pp. 207-212, (2016); Yang Z., Yang D., Dyer C., He X., Smola A., Hovy E., Hierarchical attention networks for document classification, Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies, pp. 1480-1489, (2016); Zenkel T., Wuebker J., DeNero J., Adding interpretable attention to neural translation models improves word alignment, (2019); Fan G., Diao X., Yu H., Yang K., Chen L., Software defect prediction via attention-based recurrent neural network, Scientific Programming (SP), 2019, (2019); Lin G., Xiao W., Zhang J., Xiang Y., Deep learningbased vulnerable function detection: A benchmark, International Conference on Information and Communications Security (ICICS), pp. 219-232, (2019); Just R., Jalali D., Ernst M.D., Defects4j: A database of existing faults to enable controlled testing studies for java programs, Proceedings of the 2014 International Symposium on Software Testing and Analysis, pp. 437-440, (2014); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE international conference on machine learning and applications (ICMLA), pp. 757-762, (2018); Black P.E., Et al., Samate's contribution to information assurance, NIST Special Publication, 500, 264, (2006); Juliet test suite v1.2 for java user guide, (2012); Smith N., Van Bruggen D., Tomassetti F., Javaparser: visited. Leanpub, (2017); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Transactions on Programming Languages and Systems (TOPLAS), 9, 3, pp. 319-349, (1987); Karampatsis R.-M., Babii H., Robbes R., Sutton C., Janes A., Big code!= big vocabulary: Open-vocabulary models for source code, 2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE), pp. 1073-1085, (2020); (2021); Schlichtkrull M., Kipf T.N., Bloem P., Van Den Berg R., Titov I., Welling M., Modeling relational data with graph convolutional networks, European semantic web conference, pp. 593-607, (2018); Lee J., Lee I., Kang J., Self-attention graph pooling, International Conference on Machine Learning (ICML), pp. 3734-3743, (2019); Common weakness enumeration, (2021); Wang M., Yu L., Zheng D., Gan Q., Gai Y., Ye Z., Li M., Zhou J., Huang Q., Ma C., Et al., Deep graph library: Towards efficient and scalable deep learning on graphs, (2019); Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2014); Pendleton M., Richard G.-L., Cho J.-H., Xu S., A survey on systems security metrics, ACM Computing Surveys (CSUR), 49, 4, pp. 1-35, (2016); Zhang Y., Yao Q., Shao Y., Chen L., Nscaching: Simple and efficient negative sampling for knowledge graph embedding, 2019 IEEE 35th International Conference on Data Engineering (ICDE), pp. 614-625, (2019); Hua J., Wang H., On the effectiveness of deep vulnerability detectors to simple stupid bug detection, 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR), pp. 530-534, (2021); Jain S., Wallace B.C., Attention is not explanation, (2019); Serrano S., Smith N.A., Is attention interpretable?, (2019); Bastings J., Filippova K., The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?, (2020); Wiegreffe S., Pinter Y., Attention is not not explanation, (2019); Wu B., Chen S., Gao C., Fan L., Liu Y., Wen W., Lyu M., Why an android app is classified as malware? towards malware classification interpretation, (2020); Engler D., Chen D.Y., Hallem S., Chou A., Chelf B., Bugs as deviant behavior: A general approach to inferring errors in systems code, ACM SIGOPS Operating Systems Review, 35, 5, pp. 57-72, (2001); (2013); Shin Y., Williams L., An empirical model to predict security vulnerabilities using code complexity metrics, Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement, pp. 315-317, (2008); Hochreiter S., Schmidhuber J., Long short-term memory, Neural computation, 9, 8, pp. 1735-1780, (1997); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using rnn encoder-decoder for statistical machine translation, (2014); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, (2015); Fan M., Wei W., Xie X., Liu Y., Guan X., Liu T., Can we trust your explanations? sanity checks for interpreters in android malware analysis, IEEE Transactions on Information Forensics and Security (TIFS), 16, pp. 838-853, (2020); Tulio Ribeiro M., Singh S., Guestrin C., Why should i trust you? explaining the predictions of any classifier, Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pp. 1135-1144, (2016); Guo W., Mu D., Xu J., Su P., Wang G., Xing X., Lemna: Explaining deep learning based security applications, proceedings of the 2018 ACM SIGSAC conference on computer and communications security, pp. 364-379, (2018); Zou D., Zhu Y., Xu S., Li Z., Jin H., Ye H., Interpreting deep learning-based vulnerability detector predictions based on heuristic searching, ACM Transactions on Software Engineering and Methodology (TOSEM), 30, 2, pp. 1-31, (2021); Ganz T., Harterich M., Warnecke A., Rieck K., Explaining graph neural networks for vulnerability discovery, Proceedings of the 14th ACM Workshop on Artificial Intelligence and Security, pp. 145-156, (2021); Li Z., Zou D., Xu S., Chen Z., Zhu Y., Jin H., Vuldeelocator: A deep learning-based fine-grained vulnerability detector, IEEE Transactions on Dependable and Secure Computing (TDSC), (2021)",IEEE Future Directions,"46th IEEE Annual Computers, Software, and Applications Conference, COMPSAC 2022",27 June 2022 through 1 July 2022,"Virtual, Online",181776,English,Conference paper,Final,,Scopus,2-s2.0-85136989786,91
Wu B.; Liu S.; Feng R.; Xie X.; Siow J.; Lin S.,"Wu, Bozhi (57207695744); Liu, Shangqing (57218717656); Feng, Ruitao (56104268000); Xie, Xiaofei (55268560900); Siow, Jingkai (57216460449); Lin, Shang-Wei (55813047300)",57207695744; 57218717656; 56104268000; 55268560900; 57216460449; 55813047300,Enhancing Security Patch Identification by Capturing Structures in Commits,2022,IEEE Transactions on Dependable and Secure Computing,,,,1,15,14,12,10.1109/TDSC.2022.3192631,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135750651&doi=10.1109%2fTDSC.2022.3192631&partnerID=40&md5=03faa8fe5f35a1bdcf6a280e89552e9d,"With the rapid increasing number of open source software (OSS), the majority of the software vulnerabilities in the open source components are fixed silently, which leads to the deployed software that integrated them being unable to get a timely update. Hence, it is critical to design a security patch identification system to ensure the security of the utilized software. However, most of the existing works for security patch identification just consider the changed code and the commit message of a commit as a flat sequence of tokens with simple neural networks to learn its semantics, while the structure information is ignored. To address these limitations, in this paper, we propose our well-designed approach E-SPI, which extracts the structure information hidden in a commit for effective identification. Specifically, it consists of the code change encoder to extract the syntactic of the changed code with the BiLSTM to learn the code representation and the message encoder to construct the dependency graph for the commit message with the graph neural network (GNN) to learn the message representation. We further enhance the code change encoder by embedding contextual information related to the changed code. To demonstrate the effectiveness of our approach, we conduct the extensive experiments against six state-of-the-art approaches on the existing dataset and from the real deployment environment. The experimental results confirm that our approach can significantly outperform current state-of-the-art baselines. IEEE",,,,,,,English,Article,Article in press,All Open Access; Green Open Access,Scopus,2-s2.0-85135750651,92
Yang H.; Yang H.; Zhang L.,"Yang, Hongyu (7406556789); Yang, Haiyun (57939212200); Zhang, Liang (56105968400)",7406556789; 57939212200; 56105968400,VDHGT: A Source Code Vulnerability Detection Method Based on Heterogeneous Graph Transformer,2022,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13547 LNCS,,,217,224,7,0,10.1007/978-3-031-18067-5_16,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140476757&doi=10.1007%2f978-3-031-18067-5_16&partnerID=40&md5=f7aa123f037071d1b10aa98db66facd0,"Vulnerability detection is still a challenging problem. The source code representation method used by the existing vulnerability detection methods cannot fully contain the context information of the vulnerability occurrence statement, and the vulnerability detection model does not fully consider the importance of the context statement to the vulnerability occurrence statement. Aiming at the problems raised above, this paper proposes a source code vulnerability detection method based on the heterogeneous graph transformer. The method proposed in this paper adopts a novel source code representation method—the vulnerability dependence representation graph, which includes the control dependence of the vulnerability occurrence statement and the data dependence of the variables involved in the statement. At the same time, this paper builds a graph learning network for vulnerability dependence representation graph based on the heterogeneous graph transformer, which can automatically learn the importance of contextual sentences for vulnerable sentences. To prove the effectiveness of the method in this paper, experiments were carried out on the SARD data set, and the average accuracy rate was 95.4% and the recall rate was 92.4%. The average performance is improved by 4.1%–62.7%. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Lin G.J.F., Wen S.S., Han Q.L.T., Software vulnerability detection using deep neural networks: A survey, Proc. IEEE, 108, 10, pp. 1825-1848, (2020); Li Z.F., Zou D.Q.S., Xu S.H.T., SySeVR: A framework for using deep learning to detect software vulnerabilities, IEEE Trans. Depend. Secure Comput., pp. 1-15, (2021); Wang H.T.F., Ye G.X.S., Tang Z.Y.T., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans. Inform. Foren. Secur., 16, pp. 1943-1958, (2021); Li Z.F., Zou D.Q.S., Xu S.H.T., Vuldeepecker: A Deep Learning-Based System for Vulnerability Detection. Arxiv Preprint Arxiv, 1801, pp. 1681-1695, (2018); Allamanis M.F., Brockschmidt M.S., Khademi M.T., Learning to Represent Programs with Graphs. Arxiv Preprint Arxiv 1711, pp. 740-756, (2017); Li Y.J.F., Tarlow D.S., Brockschmidt M.T., Gated Graph Sequence Neural Networks. Arxiv Preprint Arxiv 1511, pp. 5493-5512, (2015); Zhou Y.Q.F., Liu S.Q.S., Siow J.K.T., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Adv. Neural Inf. Process. Syst., 32, pp. 1-11, (2019); Hu Z.N.F., Dong Y.X.S., Wang K.S.T., Heterogeneous graph transformer, Proceedings of the Web Conference 2020, WWW, Vol. 04202020, pp. 2704-2710, (2020)",,"14th International Symposium on Cyberspace Safety and Security, CSS 2022",16 October 2022 through 18 October 2022,Xi’an,284359,English,Conference paper,Final,,Scopus,2-s2.0-85140476757,93
Rabheru R.; Hanif H.; Maffeis S.,"Rabheru, Rishi (57221862877); Hanif, Hazim (57221869399); Maffeis, Sergio (8724118800)",57221862877; 57221869399; 8724118800,A Hybrid Graph Neural Network Approach for Detecting PHP Vulnerabilities,2022,"5th IEEE Conference on Dependable and Secure Computing, DSC 2022 and SECSOC 2022 Workshop, PASS4IoT 2022 Workshop SICSA International Paper/Poster Competition in Cybersecurity",,,,,,,4,10.1109/DSC54232.2022.9888816,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141069074&doi=10.1109%2fDSC54232.2022.9888816&partnerID=40&md5=cfd7e321bea4879cb5fcb78b57af4ac6,"We validate our approach in the wild by discovering 4 novel vulnerabilities in established WordPress plugins. This paper presents DeepTective, a deep learning-based approach to detect vulnerabilities in PHP source code. Our approach implements a novel hybrid technique that combines Gated Recurrent Units and Graph Convolutional Networks to detect SQLi, XSS and OSCI vulnerabilities leveraging both syntactic and semantic information. We evaluate DeepTective and compare it to the state of the art on an established synthetic dataset and on a novel real-world dataset collected from GitHub. Experimental results show that DeepTective outperformed other solutions, including recent machine learning-based vulnerability detection approaches, on both datasets. The gap is noticeable on the synthetic dataset, where our approach achieves very high classification performance, but grows even wider on the realistic dataset, where most existing tools fail to transfer their detection ability, whereas DeepTective achieves an F1 score of 88.12%.  © 2022 IEEE.","Rabheru R., Hanif H., Maffeis S., Deeptective: Detection of php vulnerabilities using hybrid graph neural networks, Proceedings of The 36th Annual ACM Symposium on Applied Computing, Ser. SAC’21, pp. 1687-1690, (2021); Browse Cve Vulnerabilities by Date; Jovanovic N., Kruegel C., Kirda E., Pixy: A static analysis tool for detecting web application vulnerabilities, 2006 IEEE Symposium on Security and Privacy (S P’06), (2006); Dahse J., Schwenk J., Rips-a static source code analyser for vulnerabilities in php scripts, Seminar Work (Seminer Çalismasi), (2010); Dahse J., Holz T., Simulation of built-in PHP features for precise static code analysis, 21st Annual Network and Distributed System Security Symposium, NDSS 2014, (2014); Son S., Shmatikov V., SaferPhP: Finding semantic vulnerabilities in php applications, Proceedings of The ACM SIGPLAN 6th Workshop on Programming Languages and Analysis for Security, Ser. PLAS’11, (2011); Medeiros I., Neves N.F., Correia M., Automatic detection and correction of web application vulnerabilities using data mining to predict false positives, Proceedings of The 23rd International Conference on World Wide Web, Ser. WWW’14, pp. 63-74, (2014); Medeiros I., Neves N., Correia M., Equipping WAP with weapons to detect vulnerabilities: Practical experience report, 2016 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pp. 630-637, (2016); Nunes P.J.C., Fonseca J., Vieira M., PhPsafe: A security analysis tool for oop web application plugins, 2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pp. 299-306, (2015); Huang J., Li Y., Zhang J., Dai R., Uchecker: Automatically detecting PHP-based unrestricted file upload vulnerabilities, 2019 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pp. 581-592, (2019); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, 32, (2019); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 757-762, (2018); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A Deep Learning-Based System for Vulnerability Detection, (2018); Fang Y., Han S., Huang C., Wu R., TAP: A static analysis model for php vulnerabilities based on token and deep learning technology, PLOS ONE, 14, 11, pp. 1-19, (2019); Fidalgo A., Medeiros I., Antunes P., Neves N., Towards a deep learning model for vulnerability detection on web application variants, 2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW), 2020, pp. 465-476; Guo N., Li X., Yin H., Gao Y., Vulhunter: An automated vulnerability detection system based on deep learning and bytecode, Information and Communications Security, pp. 199-218, (2020); Medeiros I., Neves N., Correia M., DeKant: A static analysis tool that learns to detect web application vulnerabilities, Proceedings of The 25th International Symposium on Software Testing and Analysis, Ser. ISSTA 2016, pp. 1-11, (2016); Rabiner L.R., A tutorial on hidden markov models and selected applications in speech recognition, Proceedings of The IEEE, 77, 2, pp. 257-286, (1989); Kronjee J., Hommersom A., Vranken H., Discovering software vulnerabilities using data-flow analysis and machine learning, Proceedings of The 13th International Conference on Availability, Reliability and Security, Ser. ARES 2018, (2018); Wang H., Ye G., Tang Z., Tan S.H., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Transactions on Information Forensics and Security, 16, pp. 1943-1958, (2021); Zou D., Wang S., Xu S., Li Z., Jin H., ΜVuldeepecker: A deep learning-based system for multiclass vulnerability detection, IEEE Transactions on Dependable and Secure Computing, (2019); Filaretti D., Maffeis S., An executable formal semantics of PHP, ECOOP 2014 - Object-Oriented Programming - 28th European Conference, Ser. LNCS, 8586, pp. 567-592, (2014); Pitucha S., Phply, (2016); Beazley D., Ply, (2017); LabelEncoder, (2011); Backes M., Rieck K., Skoruppa M., Stock B., Yamaguchi F., Efficient and flexible discovery of php application vulnerabilities, 2017 IEEE European Symposium on Security and Privacy (EuroS P), pp. 334-349, (2017); Cho K., van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning Phrase Representations Using Rnn Encoder-Decoder for Statistical Machine Translation, (2014); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks, (2016); Fey M., Pytorch Geometric Documentation; SARD; Stivalet B.C., PHP Vulnerability Test Suite, (2015); PHP Vulnerability Test Suite Generator, (2015); National Vulnerability Database; Progpilot, (2017); Khliupko V., Composer, pp. 43-50, (2017)",,"5th IEEE Conference on Dependable and Secure Computing, DSC 2022",22 June 2022 through 24 June 2022,Edinburgh,183263,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85141069074,94
Cao S.; Sun X.; Bo L.; Wu R.; Li B.; Tao C.,"Cao, Sicong (57222584216); Sun, Xiaobing (24829988300); Bo, Lili (57204660270); Wu, Rongxin (55469414900); Li, Bin (56342840400); Tao, Chuanqi (36086787600)",57222584216; 24829988300; 57204660270; 55469414900; 56342840400; 36086787600,MVD: Memory-Related Vulnerability Detection Based on Flow-Sensitive Graph Neural Networks,2022,Proceedings - International Conference on Software Engineering,2022-May,,,1456,1468,12,46,10.1145/3510003.3510219,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133519100&doi=10.1145%2f3510003.3510219&partnerID=40&md5=1f1c9a8b53c4e5850c9714d51db35d49,"Memory-related vulnerabilities constitute severe threats to the security of modern software. Despite the success of deep learning-based approaches to generic vulnerability detection, they are still limited by the underutilization of flow information when applied for detecting memory-related vulnerabilities, leading to high false positives. In this paper, we propose MVD, a statement-level Memory-related Vulnerability Detection approach based on flow-sensitive graph neural networks (FS-GNN). FS-GNN is employed to jointly embed both unstructured information (i.e., source code) and structured information (i.e., control- and data-flow) to capture implicit memory-related vulnerability patterns. We evaluate MVD on the dataset which contains 4,353 real-world memory-related vulnerabilities, and compare our approach with three state-of-the-art deep learning-based approaches as well as five popular static analysis-based memory detectors. The experiment results show that MVD achieves better detection accuracy, outperforming both state-of-the-art DL-based and static analysis-based approaches. Furthermore, MVD makes a great trade-off between accuracy and efficiency. © 2022 ACM.","Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, 6th International Conference on Learning Representations, ICLR 2018, (2018); Common Vulnerabilities and Exposures, (2021); CommonWeakness Enumeration, (2021); CVE-2016-10200, (2021); CVE-2019-15920, (2021); CVE-2019-19083, (2021); CVE-2019-19448, (2021); Flawfinder, (2021); Infer, (2021); Linux Kernel, (2021); PyTorch, (2021); Rough Audit Tool for Security, (2021); Software Assurance Reference Dataset, (2021); Bordes A., Usunier N., Garcia-Duran A., Weston J., Yakhnenko O., Translating embeddings for modeling multi-relational data, Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013, pp. 2787-2795, (2013); Bruening D., Zhao Q., Practical memory checking with dr. memory, Proceedings of the CGO 2011, the 9th International Symposium on Code Generation and Optimization, pp. 213-223, (2011); Cao S., Sun X., Bo L., Wei Y., Li B., Bgnn4vd: Constructing bidirectional graph neural-network for vulnerability detection, Inf. Softw. Technol., 136, (2021); Chakraborty S., Krishna R., Ding Y., Ray B., Deep Learning Based Vulnerability Detection: Are We There Yet?, (2020); Chawla N.V., Bowyer K.W., Hall L.O., Philip Kegelmeyer W., Smote: Synthetic minority over-sampling technique, J. Artif. Intell. Res., 16, pp. 321-357, (2002); Chen Z., Wang C., Yan J., Sui Y., Xue J., Runtime detection of memory errors with smart status, ISSTA '21: 30th ACM SIGSOFT International Symposium on Software Testing and Analysis, Virtual Event, pp. 296-308, (2021); Cheng X., Wang H., Hua J., Xu G., Sui Y., Deepwukong: Statically detecting software vulnerabilities using deep graph neural network, ACM Trans. Softw. Eng. Methodol., 30, 3, pp. 381-3833, (2021); Cherem S., Princehouse L., Rugina R., Practical memory leak detection using guarded value-flow analysis, Proceedings of the ACM SIGPLAN 2007 Conference on Programming Language Design and Implementation, pp. 480-491, (2007); Clause J.A., Orso A., Leakpoint: Pinpointing the causes of memory leaks, Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering-Volume 1, ICSE 2010, pp. 515-524, (2010); Khanh Dam H., Tran T., Pham T., Wee Ng S., Grundy J., Ghose A., Automatic feature learning for predicting vulnerable software components, IEEE Trans. Software Eng., 47, 1, pp. 67-85, (2021); Fan G., Wu R., Shi Q., Xiao X., Zhou J., Zhang C., Smoke: Scalable path-sensitive memory leak detection for millions of lines of code, Proceedings of the 41st International Conference on Software Engineering, ICSE 2019, pp. 72-82, (2019); Fan J., Li Y., Wang S., Nguyen T.N., A c/c++ code vulnerability dataset with code changes and cve summaries, MSR '20: 17th International Conference on Mining Software Repositories, pp. 508-512, (2020); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Trans. Program. Lang. Syst., 9, 3, pp. 319-349, (1987); Garg A., Degiovanni R., Jimenez M., Cordy M., Papadakis M., Le Traon Y., Learning to Predict Vulnerabilities from Vulnerability-Fixes: A Machine Translation Approach, (2020); Mohammad Ghaffarian S., Reza Shahriari H., Neural software vulnerability analysis using rich intermediate graph representations of programs, Inf. Sci., 553, pp. 189-207, (2021); Gkortzis A., Mitropoulos D., Spinellis D., Vulinoss: A dataset of security vulnerabilities in open-source systems, Proceedings of the 15th International Conference on Mining Software Repositories, MSR 2018, pp. 18-21, (2018); Gong X., Xing Z., Li X., Feng Z., Han Z., Joint prediction of multiple vulnerability characteristics through multi-task learning, 24th International Conference on Engineering of Complex Computer Systems, ICECCS 2019, pp. 31-40, (2019); Heine D.L., Lam M.S., Static detection of leaks in polymorphic containers, 28th International Conference on Software Engineering (ICSE 2006), pp. 252-261, (2006); John L.H., Spec cpu2000: Measuring cpu performance in the new millennium, Computer, 33, 7, pp. 28-35, (2000); Imtiaz N., Williams L.A., Memory Error Detection in Security Testing, (2021); Ji X., Yang J., Xu J., Feng L., Li X., Interprocedural path-sensitive resource leaks detection for c programs, Proceedings of the Fourth Asia-Pacific Symposium on Internetware, Internetware 2012, pp. 191-199, (2012); Jung C., Lee S., Raman E., Pande S., Automated memory leak detection for production use, 36th International Conference on Software Engineering, ICSE '14, pp. 825-836, (2014); Kingma D.P., Ba J., Adam: A method for stochastic optimization, 3rd International Conference on Learning Representations, ICLR 2015, (2015); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5th International Conference on Learning Representations, ICLR 2017, (2017); Kroening D., Tautschnig M., Cbmc-c bounded model checker-(competition contribution), Tools and Algorithms for the Construction and Analysis of Systems-20th International Conference, TACAS 2014, Held As Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2014, 8413, pp. 389-391, (2014); Le Q.V., Mikolov T., Distributed representations of sentences and documents, Proceedings of the 31th International Conference on Machine Learning, ICML 2014, 32, pp. 1188-1196, (2014); Li W., Cai H., Sui Y., Manz D., PCA: Memory leak detection using partial call-path analysis, ESEC/FSE '20: 28th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 1621-1625, (2020); Li Y., Tan T., Moller A., Smaragdakis Y., Precision-guided context sensitivity for pointer analysis, Proc. ACM Program. Lang., 2, OOPSLA, pp. 1411-14129, (2018); Li Y., Tan T., Moller A., Smaragdakis Y., A principled approach to selective context sensitivity for pointer analysis, ACM Trans. Program. Lang. Syst., 42, 2, pp. 101-1040, (2020); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, 4th International Conference on Learning Representations, ICLR 2016, (2016); Li Y., Wang S., Nguyen T.N., Vulnerability detection with fine-grained interpretations, ESEC/FSE '21: 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 292-303, (2021); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Wang S., Wang J., SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities, (2018); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, 25th Annual Network and Distributed System Security Symposium, NDSS 2018, (2018); Liu T., Curtsinger C., Berger E.D., Doubletake: Fast and precise error detection via evidence-based dynamic analysis, Proceedings of the 38th International Conference on Software Engineering, ICSE 2016, pp. 911-922, (2016); Lou Y., Zhu Q., Dong J., Li X., Sun Z., Hao D., Zhang L., Zhang L., Boosting coverage-based fault localization via graphbased representation learning, ESEC/FSE '21: 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 664-676, (2021); Lu K., Pakki A., Wu Q., Detecting missing-check bugs via semantic-and context-aware criticalness and constraints inferences, 28th USENIX Security Symposium, USENIX Security 2019, pp. 1769-1786, (2019); Nethercote N., Seward J., Valgrind: A framework for heavyweight dynamic binary instrumentation, Proceedings of the ACM SIGPLAN 2007 Conference on Programming Language Design and Implementation, pp. 89-100, (2007); Nong Y., Cai H., Ye P., Li L., Chen F., Evaluating and comparing memory error vulnerability detectors, Inf. Softw. Technol., 137, (2021); Orlovich M., Rugina R., Memory leak analysis by contradiction, Static Analysis, 13th International Symposium, SAS 2006, 4134, pp. 405-424, (2006); Barbara G.R., Constructing the call graph of a program, IEEE Trans. Software Eng., 5, 3, pp. 216-226, (1979); Sejr Schlichtkrull M., Kipf T.N., Bloem P., Van Den Berg R., Titov I., Welling M., Modeling relational data with graph convolutional networks, The Semantic Web-15th International Conference, ESWC 2018, pp. 593-607, (2018); Serebryany K., Bruening D., Potapenko A., Vyukov D., Addresssanitizer: A fast address sanity checker, 2012 USENIX Annual Technical Conference, pp. 309-318, (2012); Shi Q., Xiao X., Wu R., Zhou J., Fan G., Zhang C., Pinpoint: Fast and precise sparse value flow analysis for million lines of code, Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2018, pp. 693-706, (2018); Sinha N.K., Griscik M.P., A stochastic approximation method, IEEE Trans. Syst. Man Cybern., 1, 4, pp. 338-344, (1971); Smith J., Johnson B., Murphy-Hill E.R., Chu B., Richter Lipford H., How developers diagnose potential security vulnerabilities with a static analysis tool, IEEE Trans. Software Eng., 45, 9, pp. 877-897, (2019); Soremekun E.O., Kirschner L., Bohme M., Zeller A., Locating faults with program slicing: An empirical analysis, Empir. Softw. Eng., 26, 3, (2021); Sui Y., Ye D., Xue J., Static memory leak detection using full-sparse value-flow analysis, International Symposium on Software Testing and Analysis, ISSTA 2012, pp. 254-264, (2012); Sui Y., Ye D., Xue J., Detecting memory leaks statically with full-sparse value-flow analysis, IEEE Trans. Software Eng., 40, 2, pp. 107-122, (2014); Sun X., Peng X., Zhang K., Liu Y., Cai Y., How security bugs are fixed and what can be improved: An empirical study with mozilla, Sci. China Inf. Sci., 62, 1, pp. 191021-191023, (2019); Szekeres L., Payer M., Wei T., Song D., Sok: Eternalwar in memory, 2013 IEEE Symposium on Security and Privacy, SP 2013, pp. 48-62, (2013); Wang H., Ye G., Tang Z., Hwei Tan S., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans. Inf. Forensics Secur., 16, pp. 1943-1958, (2021); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, 27th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2020, pp. 261-271, (2020); Wei Y., Sun X., Bo L., Cao S., Xia X., Li B., A comprehensive study on security bug characteristics, J. Softw. Evol. Process., 33, 10, (2021); Weiser M., Program slicing, IEEE Trans. Software Eng., 10, 4, pp. 352-357, (1984); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, SP 2014, pp. 590-604, (2014); Zhao T., Zhang X., Wang S., Graphsmote: Imbalanced node classification on graphs with graph neural networks, WSDM '21, the Fourteenth ACM International Conference on Web Search and Data Mining, pp. 833-841, (2021); Zhou T., Sun X., Xia X., Li B., Chen X., Improving defect prediction with deep forest, Inf. Softw. Technol., 114, pp. 204-216, (2019); Zhou Y., Liu S., Kai Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, pp. 10197-10207, (2019); Zou D., Wang S., Xu S., Li Z., Jin H., Miuvuldeepecker: A deep learning-based system for multiclass vulnerability detection, IEEE Trans. Dependable Secur. Comput., 18, 5, pp. 2224-2236, (2021)",Association for Computing Machinery (ACM); IEEE Computer Society; IEEE Technical Council on Software Engineering (TCSE); Special Interest Group on Software Engineering (SIGSOFT),"44th ACM/IEEE International Conference on Software Engineering, ICSE 2022",22 May 2022 through 27 May 2022,Pittsburgh,180255,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85133519100,95
Cao S.; Sun X.; Bo L.; Wei Y.; Li B.,"Cao, Sicong (57222584216); Sun, Xiaobing (24829988300); Bo, Lili (57204660270); Wei, Ying (57204919030); Li, Bin (56342840400)",57222584216; 24829988300; 57204660270; 57204919030; 56342840400,BGNN4VD: Constructing Bidirectional Graph Neural-Network for Vulnerability Detection,2021,Information and Software Technology,136,,106576,,,,113,10.1016/j.infsof.2021.106576,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103334174&doi=10.1016%2fj.infsof.2021.106576&partnerID=40&md5=649f46166db76c21002626593f04ce4b,"Context: Previous studies have shown that existing deep learning-based approaches can significantly improve the performance of vulnerability detection. They represent code in various forms and mine vulnerability features with deep learning models. However, the differences of code representation forms and deep learning models make various approaches still have some limitations. In practice, their false-positive rate (FPR) and false-negative rate (FNR) are still high. Objective: To address the limitations of existing deep learning-based vulnerability detection approaches, we propose BGNN4VD (Bidirectional Graph Neural Network for Vulnerability Detection), a vulnerability detection approach by constructing a Bidirectional Graph Neural-Network (BGNN). Method: In Phase 1, we extract the syntax and semantic information of source code through abstract syntax tree (AST), control flow graph (CFG), and data flow graph (DFG). Then in Phase 2, we use vectorized source code as input to Bidirectional Graph Neural-Network (BGNN). In Phase 3, we learn the different features between vulnerable code and non-vulnerable code by introducing backward edges on the basis of traditional Graph Neural-Network (GNN). Finally in Phase 4, a Convolutional Neural-Network (CNN) is used to further extract features and detect vulnerabilities through a classifier. Results: We evaluate BGNN4VD on four popular C/C++ projects from NVD and GitHub, and compare it with four state-of-the-art (Flawfinder, RATS, SySeVR, and VUDDY) vulnerab ility detection approaches. Experiment results show that, when compared these baselines, BGNN4VD achieves 4.9%, 11.0%, and 8.4% improvement in F1-measure, accuracy and precision, respectively. Conclusion: The proposed BGNN4VD achieves a higher precision and accuracy than the state-of-the-art methods. In addition, when applied on the latest vulnerabilities reported by CVE, BGNN4VD can still achieve a precision at 45.1%, which demonstrates the feasibility of BGNN4VD in practical application. © 2021","Sun X., Peng X., Zhang K., Liu Y., Cai Y., How security bugs are fixed and what can be improved: an empirical study with mozilla, Sci. China Inf. Sci., 62, 1, pp. 191021-191023, (2019); Zhuang Y., Liu Z., Qian P., Liu Q., Wang X., He Q., Smart contract vulnerability detection using graph neural network, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020, pp. 3283-3290, (2020); Munaiah N., Camilo F., Wigham W., Meneely A., Nagappan M., Do bugs foreshadow vulnerabilities? An in-depth study of the chromium project, Empir. Softw. Eng., 22, 3, pp. 1305-1347, (2017); Du X., Chen B., Li Y., Guo J., Zhou Y., Liu Y., Jiang Y., Leopard: identifying vulnerable code for vulnerability assessment through program metrics, Proceedings of the 41st International Conference on Software Engineering, ICSE 2019, Montreal, QC, Canada, May 25-31, 2019, pp. 60-71, (2019); Kim S., Woo S., Lee H., Oh H., VUDDY: a scalable approach for vulnerable code clone discovery, 2017 IEEE Symposium on Security and Privacy, SP 2017, San Jose, CA, USA, May 22-26, 2017, pp. 595-614, (2017); Shin Y., Meneely A., Williams L., Osborne J.A., Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities, IEEE Trans. Softw. Eng., 37, 6, pp. 772-787, (2011); Yamaguchi F., Lottmann M., Rieck K., Generalized vulnerability extrapolation using abstract syntax trees, 28th Annual Computer Security Applications Conference, ACSAC 2012, Orlando, FL, USA, 3-7 December 2012, pp. 359-368, (2012); Ni Z., Li B., Sun X., Chen T., Tang B., Shi X., Analyzing bug fix for automatic bug cause classification, J. Syst. Softw., 163, (2020); Jiang L., Liu H., Jiang H., Zhang L., Mei H., Heuristic and neural network based prediction of project-specific api member access, IEEE Trans. Softw. Eng., (2020); Drozd W., Wagner M.D., Fuzzergym: A competitive framework for fuzzing and learning, (2018); Boudjema E.H., Verlan S., Mokdad L., Faure C., VYPER: Vulnerability detection in binary code, Secur. Priv., 3, 2, (2020); Yi Q., Yang Z., Guo S., Wang C., Liu J., Zhao C., Eliminating path redundancy via postconditioned symbolic execution, IEEE Trans. Softw. Eng., 44, 1, pp. 25-43, (2018); Guo N., Li X., Yin H., Gao Y., Vulhunter: An automated vulnerability detection system based on deep learning and bytecode, Information and Communications Security - 21st International Conference, ICICS 2019, Beijing, China, December 15-17, 2019, Revised Selected Papers, Lecture Notes in Computer Science, 11999, pp. 199-218, (2019); Xu K., Li Y., Deng R.H., Chen K., Deeprefiner: Multi-layer android malware detection system applying deep neural networks, 2018 IEEE European Symposium on Security and Privacy, EuroS&P 2018, London, United Kingdom, April 24-26, 2018, pp. 473-487, (2018); Yuan Z., Lu Y., Wang Z., Xue Y., Droid-sec: deep learning in android malware detection, ACM SIGCOMM 2014 Conference, SIGCOMM’14, Chicago, IL, USA, August 17-22, 2014, pp. 371-372, (2014); Liu H., Shen M., Zhu J., Niu N., Li G., Zhang L., Deep learning based program generation from requirements text: Are we there yet?, IEEE Trans. Softw. Eng., (2020); Xu Y., Xu Z., Chen B., Song F., Liu Y., Liu T., Patch based vulnerability matching for binary programs, ISSTA ’20: 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, Virtual Event, USA, July 18-22, 2020, pp. 376-387, (2020); Liu H., Jin J., Xu Z., Bu Y., Zou Y., Zhang L., Deep learning based code smell detection, IEEE Trans. Softw. Eng., (2019); Xu Z., Chen B., Chandramohan M., Liu Y., Song F., SPAIN: security patch analysis for binaries towards understanding the pain and pills, Proceedings of the 39th International Conference on Software Engineering, ICSE 2017, Buenos Aires, Argentina, May 20-28, 2017, pp. 462-472, (2017); Nam J., Kim S., CLAMI: Defect prediction on unlabeled datasets (T), 30th IEEE/ACM International Conference on Automated Software Engineering, ASE 2015, Lincoln, NE, USA, November 9-13, 2015, pp. 452-463, (2015); Zhou T., Sun X., Xia X., Li B., Chen X., Improving defect prediction with deep forest, Inf. Softw. Technol., 114, pp. 204-216, (2019); Gyimothy T., Ferenc R., Siket I., Empirical validation of object-oriented metrics on open source software for fault prediction, IEEE Trans. Softw. Eng., 31, 10, pp. 897-910, (2005); Hall T., Beecham S., Bowes D., Gray D., Counsell S., A systematic literature review on fault prediction performance in software engineering, IEEE Trans. Softw. Eng., 38, 6, pp. 1276-1304, (2012); Radjenovic D., Hericko M., Torkar R., Zivkovic A., Software fault prediction metrics: A systematic literature review, Inf. Softw. Technol., 55, 8, pp. 1397-1418, (2013); Zhang F., Zheng Q., Zou Y., Hassan A.E., Cross-project defect prediction using a connectivity-based unsupervised classifier, Proceedings of the 38th International Conference on Software Engineering, ICSE 2016, Austin, TX, USA, May 14-22, 2016, pp. 309-320, (2016); Huang Q., Xia X., Lo D., Revisiting supervised and unsupervised models for effort-aware just-in-time defect prediction, Empir. Softw. Eng., 24, 5, pp. 2823-2862, (2019); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, 25th Annual Network and Distributed System Security Symposium, NDSS 2018, San Diego, California, USA, February 18-21, 2018, (2018); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Wang S., Wang J., Sysevr: A framework for using deep learning to detect software vulnerabilities, (2018); Wu F., Wang J., Liu J., Wang W., Vulnerability detection with deep learning, 2017 3rd IEEE International Conference on Computer and Communications (ICCC), pp. 1298-1302, (2017); Russell R.L., Kim L.Y., Hamilton L.H., Lazovich T., Harer J., Ozdemir O., Ellingwood P.M., McConley M.W., Automated vulnerability detection in source code using deep representation learning, 17th IEEE International Conference on Machine Learning and Applications, ICMLA 2018, Orlando, FL, USA, December 17-20, 2018, pp. 757-762, (2018); Dam H.K., Tran T., Pham T., Ng S.W., Grundy J., Ghose A., Automatic feature learning for vulnerability prediction, (2017); Zhou Y., Liu S., Siow J.K., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14 December 2019, Vancouver, BC, Canada, pp. 10197-10207, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, 4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings, (2016); Baxter I.D., Yahin A., de Moura L.M., Sant'Anna M., Bier L., Clone detection using abstract syntax trees, 1998 International Conference on Software Maintenance, ICSM 1998, Bethesda, Maryland, USA, November 16-19, 1998, pp. 368-377, (1998); Sparks S., Embleton S., Cunningham R., Zou C.C., Automated vulnerability analysis: Leveraging control flow for evolutionary input crafting, 23rd Annual Computer Security Applications Conference (ACSAC 2007), December 10-14, 2007, Miami Beach, Florida, USA, pp. 477-486, (2007); Gascon H., Yamaguchi F., Arp D., Rieck K., Structural detection of android malware using embedded call graphs, AISec’13, Proceedings of the 2013 ACM Workshop on Artificial Intelligence and Security, Co-Located with CCS 2013, Berlin, Germany, November 4, 2013, pp. 45-54, (2013); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings, (2017); Abadi M., Barham P., Chen J., Chen Z., Davis A., Dean J., Devin M., Ghemawat S., Irving G., Isard M., Kudlur M., Levenberg J., Monga R., Moore S., Murray D.G., Steiner B., Tucker P.A., Vasudevan V., Warden P., Wicke M., Yu Y., Zheng X., Tensorflow: A system for large-scale machine learning, 12th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2016, Savannah, GA, USA, November 2-4, 2016, pp. 265-283, (2016); Kingma D.P., Ba J., Adam: A method for stochastic optimization, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, (2015); Zheng W., Gao J., Wu X., Liu F., Xun Y., Liu G., Chen X., The impact factors on the performance of machine learning-based vulnerability detection: A comparative study, J. Syst. Softw., 168, (2020); Zhang M., Cui Z., Neumann M., Chen Y., An end-to-end deep learning architecture for graph classification, Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th Innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018, pp. 4438-4445, (2018); Pradel M., Sen K., Deepbugs: a learning approach to name-based bug detection, Proc. ACM Program. Lang., 2, OOPSLA, pp. 1471-147:25, (2018); Younis A.A., Malaiya Y.K., Anderson C., Ray I., To fear or not to fear that is the question: Code characteristics of a vulnerable functionwith an existing exploit, Proceedings of the Sixth ACM on Conference on Data and Application Security and Privacy, CODASPY 2016, New Orleans, la, USA, March 9-11, 2016, pp. 97-104, (2016)",,,,,,English,Article,Final,,Scopus,2-s2.0-85103334174,96
Song Z.; Wang J.; Liu S.; Fang Z.; Yang K.,"Song, Zihua (57219892503); Wang, Junfeng (57205765387); Liu, Shengli (36010722100); Fang, Zhiyang (49663272000); Yang, Kaiyuan (57419950600)",57219892503; 57205765387; 36010722100; 49663272000; 57419950600,HGVul: A Code Vulnerability Detection Method Based on Heterogeneous Source-Level Intermediate Representation,2022,Security and Communication Networks,2022,,1919907,,,,7,10.1155/2022/1919907,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129314783&doi=10.1155%2f2022%2f1919907&partnerID=40&md5=acfe9a476db18fb89687d385fa8fdd90,"Vulnerability detection on source code can prevent the risk of cyber-attacks as early as possible. However, lacking fine-grained analysis of the code has rendered the existing solutions still suffering from low performance; besides, the explosive growth of open-source projects has dramatically increased the complexity and diversity of the source code. This paper presents HGVul, a code vulnerability detection method based on heterogeneous intermediate representation of source code. The key of the proposed method is the fine-grained handling on heterogeneous source-level intermediate representation (SIR) without expert knowledge. It first extracts graph SIR of code with multiple syntactic-semantic information. Then, HGVul splits the SIR into different subgraphs according to various semantic relations, which are used to obtain semantic information conveyed by different types of edges. Next, a graph neural network with attention operations is deployed on each subgraph to learn representation, which captures the subtle effects from node neighbors on their representation. Finally, the learned code feature representations are utilized to perform vulnerability detection. Experiments are conducted on multiple datasets. The F1 of HGVul reaches 96.1% on the sample-balanced Big-Vul-VP dataset and 88.3% on the unbalanced Big-Vul dataset. Further experiments on actual open-source project datasets prove the better performance of HGVul.  © 2022 Zihua Song et al.","The 2020 State of the Octoverse, (2021); State of the Software Supply Chain, (2021); Yamaguchi F., Wressnegger C., Gascon H., Rieck K., Chucky: Exposing Missing Checks in Source Code for Vulnerability Discovery, pp. 499-510; Du X., Chen B., Li Y., Guo J., Zhou Y., Liu Y., Jiang Y., Leopard: Identifying Vulnerable Code for Vulnerability Assessment Through Program Metrics, pp. 60-71; Xu Z., Chen B., Chandramohan M., Liu Y., Fu S., Spain: Security Patch Analysis for Binaries Towards Understanding the Pain and Pills, pp. 462-472; Cha S.K., Woo M., Brumley D., Program-adaptive Mutational Fuzzing, pp. 725-741; Stephens N., Grosen J., Salls C., Dutcher A., Wang R., Corbetta J., Yan S., Kruegel C., Vigna G., Driller: Augmenting fuzzing through selective symbolic execution, NDSS, 16, pp. 1-16, (2016); Ramos D.A., Engler D., Under-constrained Symbolic Execution: Correctness Checking for Real Code, pp. 49-64; Chen H., Xue Y., Li Y., Chen B., Xie X., Wu X., Liu Y., Hawkeye: Towards A Desired Directed Grey-box Fuzzer, pp. 2095-2108; Li Y., Xue Y., Chen H., Wu X., Zhang C., Xie X., Wang H., Liu Y., Cerebro: Context-aware Adaptive Fuzzing for Effective Vulnerability Detection, pp. 533-544; Wang H., Xie X., Li Y., Cheng W., Li Y., Liu Y., Qin S., Chen H., Sui Y., Typestate-guided Fuzzer for Discovering Use-after-free Vulnerabilities, pp. 999-1010; Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and Discovering Vulnerabilities with Code Property Graphs, pp. 590-604; Yamaguchi F., Maier A., Gascon H., Rieck K., Automatic Inference of Search Patterns for Taint-style Vulnerabilities, pp. 797-812; Seyed M.G., Reza Shahriari H., Software vulnerability analysis and discovery using machine-learning and data-mining techniques: A survey, ACM Computing Surveys, 50, 4, pp. 1-36, (2017); Pang Y., Xue X., Namin A.S., Predicting Vulnerable Software Components Through N-gram Analysis and Statistical Feature Selection, pp. 543-548; Yamaguchi F., Lindner F., Rieck K., Vulnerability Extrapolation: Assisted Discovery of Vulnerabilities Using Machine Learning; Dam H.K., Tran T., Pham T., Ng S.W., Grundy J., Ghose A., Automatic feature learning for predicting vulnerable software components, IEEE Transactions on Software Engineering, 47, 1, pp. 67-85, (2021); Lin G., Zhang J., Luo W., Pan L., Xiang Y., De Vel O., Montague P., Cross-project transfer representation learning for vulnerable function discovery, IEEE Transactions on Industrial Informatics, 14, 7, pp. 3289-3297, (2018); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics Via Graph Neural Networks, (2019); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A Deep Learning-Based System for Vulnerability Detection; Lin G., Wen S., Han Q.-L., Zhang J., Xiang Y., Software vulnerability detection using deep neural networks: A survey, Proceedings of the IEEE, 108, 10, pp. 1825-1848, (2020); Wu F., Wang J., Liu J., Wang W., Vulnerability Detection with Deep Learning, pp. 1298-1302; Grieco G., Grinblat G.L., Uzal L., Rawat S., Feist J., Mounier L., Toward Large-scale Vulnerability Discovery Using Machine Learning, pp. 85-96; Russell R., Kim L., Hamilton L., Lazovich T., Jacob H., Ozdemir O., Paul E., McConley M., Automated Vulnerability Detection in Source Code Using Deep Representation Learning, pp. 757-762; Lin G., Zhang J., Luo W., Pan L., De Vel O., Paul M., Yang X., Software vulnerability discovery via learning multi-domain knowledge bases, IEEE Transactions on Dependable and Secure Computing, 18, 5, pp. 2469-2485, (2019); Zou D., Wang S., Xu S., Li Z., Jin H., Vuldeepecker: A deep learning-based system for multiclass vulnerability detection, IEEE Transactions on Dependable and Secure Computing, 18, 5, pp. 2224-2236, (2021); Cao S., Sun X., Bo L., Wei Y., Li B., Bgnn4vd: Constructing bidirectional graph neural-network for vulnerability detection, Information and Software Technology, 136, (2021); Wang H., Ye G., Tang Z., Tan S.H., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Transactions on Information Forensics and Security, 16, pp. 1943-1958, (2020); Cui L., Zhiyu H., Yang J., Fei H., Yun X., Vuldetector: Detecting vulnerabilities using weighted feature graph comparison, IEEE Transactions on Information Forensics and Security, 16, pp. 2004-2017, (2020); Software S., Rough Audit Tool for Security, (2021); Wheeler D.A., Flawfinder, (2021); Checkmarx, Checkmarx, (2021); Jang J., Agrawal A., Brumley D., Redebug: Finding Unpatched Code Clones in Entire Os Distributions, pp. 48-62; Kim S., Woo S., Lee H., Oh H., Vuddy: A Scalable Approach for Vulnerable Code Clone Discovery, pp. 595-614; Fu W., Menzies T., Revisiting Unsupervised Learning for Defect Prediction, pp. 72-83; Liu J., Zhou Y., Yang Y., Lu H., Xu B., Code Churn: A Neglected Metric in Effort-aware Just-in-time Defect Prediction, pp. 11-19; Shin Y., Williams L., Can traditional fault prediction models be used for vulnerability prediction?, Empirical Software Engineering, 18, 1, pp. 25-59, (2013); Wen S., Sayad Haghighi M., Chen C., Yang X., Zhou W., Jia W., A sword with two edges: Propagation studies on both positive and negative information in online social networks, IEEE Transactions on Computers, 64, 3, pp. 640-653, (2014); Neuhaus S., Zimmermann T., Holler C., Zeller A., Predicting Vulnerable Software Components, pp. 529-540; Guo Z., Shen Y., Bashir A.K., Imran M., Kumar N., Zhang D., Yu K., Robust spammer detection using collaborative neural network in internet-of-things applications, IEEE Internet of Things Journal, 8, 12, pp. 9549-9558, (2021); Cui Z., Jing X., Zhao P., Zhang W., Chen J., A new subspace clustering strategy for ai-based data analysis in iot system, IEEE Internet of Things Journal, 8, 16, pp. 12540-12549, (2021); Yu K., Lin L., Alazab M., Tan L., Gu B., Deep learning-based traffic safety solution for a mixture of autonomous and manual vehicles in a 5g-enabled intelligent transportation system, IEEE Transactions on Intelligent Transportation Systems, 22, 7, pp. 4337-4347, (2021); Guo Z., Tang L., Guo T., Yu K., Alazab M., Shalaginov A., Deep graph neural network-based spammer detection under the perspective of heterogeneous cyberspace, Future Generation Computer Systems, 117, pp. 205-218, (2021); Wu Y., Lu J., Zhang Y., Jin S., Vulnerability Detection in C/c++ Source Code with Graph Representation Learning, pp. 1519-1524; Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Transactions on Programming Languages and Systems, 9, 3, pp. 319-349, (1987); Fan J., Li Y., Wang S., Nguyen T.N., Ac/c++ Code Vulnerability Dataset with Code Changes and Cve Summaries, pp. 508-512; Joern, Joern, (2021); Zheng Y., Pujar S., Lewis B., Buratti L., Epstein E., Yang B., Laredo J., Morari A., Su Z., D2a: A Dataset Built for Ai-based Vulnerability Detection Methods Using Differential Analysis, pp. 111-120; Mitre, Cve Details, (2021); Lee D.G., Deep Graph Library, (2021); Pytorch, Pytorch, (2021); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks; Kipf T.N., Welling M., Semi-supervised Classification with Graph Convolutional Networks; Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph Attention Networks",,,,,,English,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85129314783,97
Ding Y.; Suneja S.; Zheng Y.; Laredo J.; Morari A.; Kaiser G.; Ray B.,"Ding, Yangruibo (57221142654); Suneja, Sahil (55813198500); Zheng, Yunhui (55901243300); Laredo, Jim (57197580620); Morari, Alessandro (51665633100); Kaiser, Gail (7202982863); Ray, Baishakhi (24492560400)",57221142654; 55813198500; 55901243300; 57197580620; 51665633100; 7202982863; 24492560400,VELVET: A noVel Ensemble Learning approach to automatically locate VulnErable sTatements,2022,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",,,,959,970,11,18,10.1109/SANER53432.2022.00114,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127031754&doi=10.1109%2fSANER53432.2022.00114&partnerID=40&md5=52f8fa0cd17e6cd221bc2a6f6b90c2e5,"Automatically locating vulnerable statements in source code is crucial to assure software security and alleviate developers' debugging efforts. This becomes even more important in today's software ecosystem, where vulnerable code can flow easily and unwittingly within and across software repositories like GitHub. Across such millions of lines of code, traditional static and dynamic approaches struggle to scale. Although existing machine-learning-based approaches look promising in such a setting, most work detects vulnerable code at a higher granularity - at the method or file level. Thus, developers still need to inspect a significant amount of code to locate the vulnerable statement(s) that need to be fixed. This paper presents Velvet, a novel ensemble learning approach to locate vulnerable statements. Our model combines graph-based and sequence-based neural networks to successfully capture the local and global context of a program graph and effectively understand code semantics and vulnerable patterns. To study Velvet's effectiveness, we use an off-the-shelf synthetic dataset and a recently published real-world dataset. In the static analysis setting, where vulnerable functions are not detected in advance, Velvet achieves 4.5× better performance than the baseline static analyzers on the real-world data. For the isolated vulnerability localization task, where we assume the vulnerability of a function is known while the specific vulnerable statement is unknown, we compare Velvet with several neural networks that also attend to local and global context of code. Velvet achieves 99.6% and 43.6% top-1 accuracy over synthetic data and real-world data, respectively, outperforming the baseline deep learning models by 5.3-29.0%.  © 2022 IEEE.","Johnson B., Song Y., Murphy-Hill E., Bowdidge R., Why don't software developers use static analysis tools to find bugs?, Proceed-ings of the 2013 International Conference on Software Engineering, pp. 672-681, (2013); Smith J., Johnson B., Murphy-Hill E., Chu B., Lipford H.R., Questions developers ask while diagnosing potential security vulnerabilities with static analysis, Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering, pp. 248-259, (2015); Liu B., Shi L., Cai Z., Li M., Software vulnerability discovery techniques: A survey, 2012 fourth international conference on multimedia information networking and security, pp. 152-156, (2012); Suneja S., Zheng Y., Zhuang Y., Laredo J., Morari A., Learning to map source code to software vulnerability using code-as-a-graph, (2020); Buratti L., Pujar S., Bornea M., McCarley S., Zheng Y., Rossiello G., Morari A., Laredo J., Thost V., Zhuang Y., Domeniconi G., Exploring software naturalness through neural language models, (2020); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 757-762, (2018); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, Proceedings of the 25th Annual Network and Distributed System Security Symposium (NDSS'2018), (2018); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: A framework for using deep learning to detect software vulnerabilities, (2018); Li B., Roundy K., Gates C., Vorobeychik Y., Large-scale identification of malicious singleton files, Proceedings of the Seventh ACM on Conference on Data and Application Security and Privacy, pp. 227-238, (2017); Maiorca D., Biggio B., Digital investigation of pdf files: Unveiling traces of embedded malware, IEEE Security & Privacy, 17, 1, pp. 63-71, (2019); Suarez-Tangil G., Dash S.K., Ahmadi M., Kinder J., Giacinto G., Cavallaro L., Droidsieve: Fast and accurate classification of obfuscated android malware, Proceedings of the Seventh ACM on Conference on Data and Application Security and Privacy, pp. 309-320, (2017); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, pp. 10197-10207, (2019); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet?, (2020); Cheng X., Wang H., Hua J., Xu G., Sui Y., Deepwukong: Statically detecting software vulnerabilities using deep graph neural network, ACM Trans. Softw. Eng. Methodol., 30, (2021); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, International Conference on Learning Representations, (2018); Yin P., Neubig G., Allamanis M., Brockschmidt M., Gaunt A.L., Learning to represent edits, International Conference on Learning Representations, (2019); Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, International Conference on Learning Representations, (2020); Dinella E., Dai H., Li Z., Naik M., Song L., Wang K., Hoppity: Learning graph transformations to detect and fix bugs in programs, International Conference on Learning Representations, (2020); Dash S.K., Allamanis M., Barr E.T., Refinym: Using names to refine types, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2018, pp. 107-117, (2018); Wang Y., Wang K., Gao F., Wang L., Learning semantic program embeddings with graph interval neural network, Proc. ACM Program. Lang., 4, (2020); Gao J., Jiang Y., Liu Z., Yang X., Wang C., Jiao X., Yang Z., Sun J., Semantic learning and emulation based cross-platform binary vulnerability seeker, IEEE Transactions on Software Engineering, pp. 1-1, (2019); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, pp. 590-604, (2014); Zheng Y., Pujar S., Lewis B., Buratti L., Epstein E., Yang B., Laredo J., Morari A., Su Z., D2A: A Dataset Built for AI-Based Vulnerability Detection Methods Using Differential Analysis, Proceedings of the ACM/IEEE 43rd International Conference on Software Engineering: Software Engineering in Practice, ICSE-SEIP '21, (2021); Juliet test suite v1. 3, (2017); Common Weakness Enumeration, (2020); Github Repository for This Paper's data and Code, (2021); Li Y., Wang S., Nguyen T.N., Vulnerability detection with finegrained interpretations, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2021, pp. 292-303, (2021); Tarlow D., Moitra S., Rice A., Chen Z., Manzagol P.-A., Sutton C., Aftandilian E., Learning to fix build errors with graph2diff neural networks, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, (2017); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS'17, pp. 6000-6010, (2017); Ahmad W.U., Chakraborty S., Ray B., Chang K.-W., A transformer-based approach for source code summarization, ACL, pp. 4998-5007, (2020); Ahmad W.U., Chakraborty S., Ray B., Chang K.-W., Unified pretraining for program understanding and generation, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics, (2021); Lutellier T., Pham V.H., Pang L., Li Y., Wei M., Tan L., Coconut: Combining context-aware neural translation models using ensemble for program repair, (2020); Ding Y., Ray B., Premkumar D., Hellendoorn V.J., Patching as translation: the data and the metaphor, 35th IEEE/ACM International Conference on Automated Software Engineering, ASE '20, (2020); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, (Online), pp. 1536-1547, (2020); Kovalenko V., Palomba F., Bacchelli A., Mining file histories: Should we consider branches?, 2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 202-213, (2018); Juergens E., Deissenboeck F., Hummel B., Wagner S., Do code clones matter?, Proceedings of the 31st International Conference on Software Engineering, ICSE '09, pp. 485-495, (2009); (2021); Fernandes P., Allamanis M., Brockschmidt M., Structured Neural Summarization, International Conference on Learning Representa-tions (ICLR), (2019); National Vulnerability Database (NVD), (2020); Li Z., Zou D., Xu S., Chen Z., Zhu Y., Jin H., Vuldeelocator: A deep learning-based fine-grained vulnerability detector, (2020); Du X., Chen B., Li Y., Guo J., Zhou Y., Liu Y., Jiang Y., Leopard: Identifying vulnerable code for vulnerability assessment through program metrics, Proceedings of the 41st International Conference on Software Engineering, ICSE '19, pp. 60-71, (2019); Jimenez M., Rwemalika R., Papadakis M., Sarro F., Le Traon Y., Harman M., The importance of accounting for real-world labelling when predicting software vulnerabilities, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2019, pp. 695-705, (2019); Calcagno C., Distefano D., Infer: An automatic program verifier for memory safety of c programs, Proceedings of the Third International Conference on NASA Formal Methods, NFM'11, pp. 459-465, (2011); Wheeler D.A.; Rough Audit Tool for Security, (2013); Calcagno C., Distefano D., Dubreil J., Gabi D., Hooimeijer P., Luca M., O'Hearn P., Papakonstantinou I., Purbrick J., Rodriguez D., Moving fast with software verification, NASA Formal Methods, pp. 3-11, (2015); GitHub Code Security, (2021); Codacy Security Scan, (2021); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., Roberta: A robustly optimized bert pretraining approach, (2019); Abreu R., Zoeteweij P., Van Gemund A.J.C., An evaluation of similarity coefficients for software fault localization, 2006 12th Pacific Rim International Symposium on Dependable Computing (PRDC'06), pp. 39-46, (2006); Abreu R., Zoeteweij P., Van Gemund A.J.C., On the accuracy of spectrum-based fault localization, Testing: Academic and Industrial Conference Practice and Research Techniques-MUTATION (TAICPART-MUTATION 2007), pp. 89-98, (2007); Naish L., Lee H.J., Ramamohanarao K., A model for spectra-based software diagnosis, ACM Trans. Softw. Eng. Methodol., 20, (2011); Jones J.A., Harrold M.J., Empirical evaluation of the tarantula automatic fault-localization technique, Proceedings of the 20th IEEE/ACM International Conference on Automated Software Engineer-ing, ASE '05, pp. 273-282, (2005); Moon S., Kim Y., Kim M., Yoo S., Ask the mutants: Mutating faulty programs for fault localization, 2014 IEEE Seventh Inter-national Conference on Software Testing, Verification and Validation, pp. 153-162, (2014); Papadakis M., Le Traon Y., Using mutants to locate ""unknown"" faults, 2012 IEEE Fifth International Conference on Software Test-ing, Verification and Validation, pp. 691-700, (2012); Zhang L., Zhang L., Khurshid S., Injecting mechanical faults to localize developer faults for evolving software, Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages & Applications, OOPSLA '13, pp. 765-784, (2013); Li X., Li W., Zhang Y., Zhang L., Deepfl: Integrating multiple fault diagnosis dimensions for deep fault localization, ISSTA 2019, pp. 169-180, (2019); Zhang Z., Lei Y., Mao X., Li P., Cnn-fl: An effective approach for localizing faults using convolutional neural networks, 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 445-455, (2019); Lou Y., Ghanbari A., Li X., Zhang L., Zhang H., Hao D., Zhang L., Can automated program repair refine fault localization? a unified debugging approach, Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2020, pp. 75-87, (2020)",IEEE Computer Society,"29th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",15 March 2022 through 18 March 2022,"Virtual, Online",181173,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85127031754,98
Nguyen V.-A.; Nguyen D.Q.; Nguyen V.; Le T.; Tran Q.H.; Phung D.,"Nguyen, Van-Anh (57220158645); Nguyen, Dai Quoc (56283158300); Nguyen, Van (57202983154); Le, Trung (57202557822); Tran, Quan Hung (57191843710); Phung, Dinh (7003397144)",57220158645; 56283158300; 57202983154; 57202557822; 57191843710; 7003397144,ReGVD: Revisiting Graph Neural Networks for Vulnerability Detection,2022,Proceedings - International Conference on Software Engineering,,,,178,182,4,42,10.1109/ICSE-Companion55297.2022.9793807,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128155921&doi=10.1109%2fICSE-Companion55297.2022.9793807&partnerID=40&md5=ead1f06fa683209f9301b928840b5491,"Identifying vulnerabilities in the source code is essential to protect the software systems from cyber security attacks. It, however, is also a challenging step that requires specialized expertise in security and code representation. To this end, we aim to develop a general, practical, and programming language-independent model capable of running on various source codes and libraries without difficulty. Therefore, we consider vulnerability detection as an inductive text classification problem and propose ReGVD, a simple yet effective graph neural network-based model for the problem. In particular, ReGVD views each raw source code as a flat sequence of tokens to build a graph, wherein node features are initialized by only the token embedding layer of a pre-trained programming language (PL) model. ReGVD then leverages residual connection among GNN layers and examines a mixture of graph-level sum and max poolings to return a graph embedding for the source code. ReGVD outperforms the existing state-of-the-art models and obtains the highest accuracy on the real-world benchmark dataset from CodeXGLUE for vulnerability detection. Our code is available at: https://github.com/daiquocnguyen/GNN-ReGVD. © 2022 IEEE.","Bresson X., Laurent T., Residual gated graph convnets, (2017); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation, EMNLP, pp. 1724-1734, (2014); Clark K., Luong M., Le Q.V., Manning C.D., Electra: Pre-training text encoders as discriminators rather than generators, (2020); Devlin J., Chang M., Lee K., Toutanova K., Bert: Pre-training of deep bidirectional transformers for language understanding, (2018); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A Pre-Trained Model for Programming and Natural Languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Kun Deng S., Clement C.B., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., GraphCodeBERT: Pre-training Code Representations with Data Flow, ICLR, (2021); Hamilton W.L., Ying R., Leskovec J., Representation learning on graphs: Methods and applications, (2017); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, CVPR, pp. 770-778, (2016); Hochreiter S., Schmidhuber J., Long Short-Term Memory, Neural Computation, 9, pp. 1735-1780, (1997); Huang L., Ma D., Li S., Zhang X., Wang H., Text Level Graph Neural Network for Text Classification, EMNLP-IJCNLP, (2019); Kim Y., Convolutional Neural Networks for Sentence Classification, EMNLP, pp. 1746-1751, (2014); Kingma D., Ba J., Adam: A Method for Stochastic Optimization, (2014); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks, ICLR, (2017); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, ICLR, (2016); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, (2018); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., Roberta: A robustly optimized bert pretraining approach, (2019); Lu S., Guo D., Ren S., Huang J., Svyatkovskiy A., Blanco A., Clement C.B., Drain D., Jiang D., Tang D., Li G., Zhou L., Shou L., Zhou L., Tufano M., Gong M., Zhou M., Duan N., Sundaresan N., Kun Deng S., Fu S., Liu S., CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation, (2021); Neuhaus S., Zimmermann T., Holler C., Zeller A., Predicting vulnerable software components, ACM CCS, pp. 529-540, (2007); Quoc Nguyen D., Representation Learning for Graph-Structured Data, (2021); Quoc Nguyen D., Dinh Nguyen T., Phung D., Universal Graph Transformer Self-Attention Networks, (2019); Quoc Nguyen D., Dinh Nguyen T., Phung D., Quaternion Graph Neural Networks, Asian Conference on Machine Learning, (2021); Hung Nguyen V., Minh Sang Tran L., Predicting vulnerable software components with dependency graphs, MetriSec, pp. 1-8, (2010); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, ICMLA, (2018); Scarselli F., Gori M., Chung Tsoi A., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Transactions on Neural Networks, 20, pp. 61-80, (2009); Shin Y., Meneely A., Williams L., Osborne J.A., Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities, IEEE transactions on software engineering, 37, (2010); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A comprehensive survey on graph neural networks, (2019); Xu K., Hu W., Leskovec J., Jegelka S., How Powerful Are Graph Neural Networks?, ICLR, (2019); Yao L., Mao C., Luo Y., Graph convolutional networks for text classification, AAAI, pp. 7370-7377, (2019); Zhang Y., Yu X., Cui Z., Wu S., Wen Z., Wang L., Every Document Owns Its Structure: Inductive Text Classification via Graph Neural Networks, ACL, pp. 334-339, (2020); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks, NeurIPS, (2019)",ACM and its Special Interest Group on Software Engineering (SIGSOFT); IEEE CS and its Technical Committee on Software Engineering (TCSE),"44th ACM/IEEE International Conference on Software Engineering: Companion, ICSE-Companion 2022",22 May 2022 through 27 May 2022,Pittsburgh,180124,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85128155921,99
Wu T.; Chen L.; Du G.; Zhu C.; Cui N.; Shi G.,"Wu, Tongshuai (57442603200); Chen, Liwei (57192609456); Du, Gewangzi (57222072569); Zhu, Chenguang (57701614500); Cui, Ningning (57713446800); Shi, Gang (57189342099)",57442603200; 57192609456; 57222072569; 57701614500; 57713446800; 57189342099,Inductive Vulnerability Detection via Gated Graph Neural Network,2022,"2022 IEEE 25th International Conference on Computer Supported Cooperative Work in Design, CSCWD 2022",,,,519,524,5,2,10.1109/CSCWD54268.2022.9776051,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130846469&doi=10.1109%2fCSCWD54268.2022.9776051&partnerID=40&md5=6896f26785fbfbf10fba33ae7844bd52,"Vulnerability detection is an essential means to ensure the normal operation of various software tools and system security. The Recurrent Neural Networks (RNNs) have achieved remarkable results in vulnerability detection, but the sequence-based code representation has great limitations in feature expression and propagation. In this paper, we propose a fine-grained code vulnerability detection framework based on Gated Graph Neural Network (GGNN). Firstly, we process the source code into fine-grained slices. Secondly, graph embedding of code slices is constructed by clustering neighborhood information. Finally, GGNN is used to learn the syntax and semantic information of vulnerability codes for graph-level classification. Furthermore, we theoretically analyze that GGNN has a strong inductive learning ability. This means that the model requires only a small amount of training data to obtain sufficient advanced features, which is significant for vulnerability detection tasks that are difficult to collect data sets. We carry out conventional experiments and inductive experiments with manually collected data sets, and the results show that the framework is superior to RNNs in vulnerability detection performance. Moreover, our framework performs better than RNNs under inductive conditions. © 2022 IEEE.","Dam H.K., Tran T., Pham T., Ng S.W., Grundy J., Ghose A., Automatic feature learning for vulnerability prediction, (2017); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE international conference on machine learning and applications (ICMLA). IEEE, pp. 757-762, (2018); Hochreiter S., Schmidhuber J., Long short-term memory, Neural computation, 9, 8, pp. 1735-1780, (1997); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, (2018); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, (2015); Li J., He P., Zhu J., Lyu M.R., Software defect prediction via convolutional neural network, 2017 IEEE International Conference on Software Quality, Reliability and Security (QRS). IEEE, pp. 318-328, (2017); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Thirtieth AAAI Conference on Artificial Intelligence, (2016); Xu X., Liu C., Feng Q., Yin H., Song L., Song D., Neural networkbased graph embedding for cross-platform binary code similarity detection, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 363-376, (2017); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, (2017); Dai H., Dai B., Song L., Discriminative embeddings of latent variable models for structured data, International conference on machine learning. PMLR, pp. 2702-2711, (2016); Schlichtkrull M., Kipf T.N., Bloem P., Van Den Berg R., Titov I., Welling M., Modeling relational data with graph convolutional networks, European semantic web conference, pp. 593-607, (2018); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); Zhang Y., Yu X., Cui Z., Wu S., Wen Z., Wang L., Every document owns its structure: Inductive text classification via graph neural networks, (2020); Li Y., Xue Y., Chen H., Wu X., Zhang C., Xie X., Wang H., Liu Y., Cerebro: context-aware adaptive fuzzing for effective vulnerability detection, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 533-544, (2019); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using rnn encoder-decoder for statistical machine translation, (2014); Wu T., Chen L., Du G., Zhu C., Shi G., Self-attention based automated vulnerability detection with effective data representation, 2021 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom). IEEE, pp. 892-899, (2021); Pendleton M., Garcia-Lebron R., Cho J.-H., Xu S., A survey on systems security metrics, ACM Computing Surveys (CSUR), 49, 4, pp. 1-35, (2016); Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2014)",,"25th IEEE International Conference on Computer Supported Cooperative Work in Design, CSCWD 2022",4 May 2022 through 6 May 2022,Hangzhou,179401,English,Conference paper,Final,,Scopus,2-s2.0-85130846469,100
Qian J.; Ju X.; Chen X.; Shen H.; Shen Y.,"Qian, Jie (57220544299); Ju, Xiaolin (55883850700); Chen, Xiang (57189091783); Shen, Hao (58356694100); Shen, Yiheng (57947198100)",57220544299; 55883850700; 57189091783; 58356694100; 57947198100,AGFL: A Graph Convolutional Neural Network-Based Method for Fault Localization,2021,"IEEE International Conference on Software Quality, Reliability and Security, QRS",2021-December,,,672,680,8,3,10.1109/QRS54544.2021.00077,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138900023&doi=10.1109%2fQRS54544.2021.00077&partnerID=40&md5=4d8c8936839e1d46ec0184447d0afc82,"Fault localization techniques have been developed for decades. Spectrum Based Fault Localization (SBFL) is a popular strategy in this research topic. However, SBFL is well known for low accuracy, mainly due to simply using a coverage matrix of program executions. In this paper, we propose a method based on graph neural network (AGFL), characterized by the adjacent matrix of the abstract syntax tree and the word vector of each program token. Referring to the Dstar, we calculate the suspiciousness of the statements and rank these statements. The experiment carried on Defects4J, a widely used benchmark, reveals that AGFL can locate 178 of the 262 studied bugs within Top-1, while state-of-the-art techniques at most locate 148 within Top-1. We also investigate the impacts of hyper-parameters (e.g., epoch and learning rate). The results show that AGFL has the best effect when the epoch is 100 and the learning rate is 0.0001. This value of epoch and learning rate increases by 66% compared to the worst on Top-1. © 2021 IEEE.","Wong W. E., Debroy V., Surampudi A., Kim H., Siok M. F., Recent catastrophic accidents: Investigating how software was responsible, 2010 Fourth International Conference on Secure Software Integration and Reliability Improvement. IEEE, pp. 14-22, (2010); Wong W. E., Li X., Laplante P. A., Be more familiar with our enemies and pave the way forward: A review of the roles bugs played in software failures, Journal of Systems and Software, 133, pp. 68-94, (2017); Wong W. E., Gao R., Li Y., Abreu R., Wotawa F., A survey on software fault localization, IEEE Transactions on Software Engineering, 42, 8, pp. 707-740, (2016); Debroy V., Wong W. E., Xu X., Choi B., A grouping-based strategy to improve the effectiveness of fault localization techniques, 2010 10th International Conference on Quality Software. IEEE, pp. 13-22, (2010); Jones J. A., Harrold M. J., Empirical evaluation of the tarantula automatic fault-localization technique, Proceedings of the 20th IEEE/ACM international Conference on Automated software engineering, pp. 273-282, (2005); Abreu R., Zoeteweij P., Van Gemund A. J., An evaluation of similarity coefficients for software fault localization, 2006 12th Pacific Rim International Symposium on Dependable Computing (PRDC'06). IEEE, pp. 39-46, (2006); Wong W. E., Debroy V., Li Y., Gao R., Software fault localization using dstar (d), 2012 IEEE Sixth International Conference on Software Security and Reliability. IEEE, pp. 21-30, (2012); Abreu R., Zoeteweij P., Van Gemund A. J., On the accuracy of spectrum-based fault localization, Testing: Academic and industrial conference practice and research techniques-MUTATION (TAICPARTMUTATION 2007), pp. 89-98, (2007); Naish L., Lee H. J., Ramamohanarao K., A model for spectrabased software diagnosis, ACM Transactions on software engineering and methodology (TOSEM), 20, 3, pp. 1-32, (2011); Zhang L., Zhang L., Khurshid S., Injecting mechanical faults to localize developer faults for evolving software, ACM SIGPLAN Notices, 48, 10, pp. 765-784, (2013); Papadakis M., Le Traon Y., Metallaxis-fl: mutation-based fault localization, Software Testing, Verification and Reliability, 25, 5-7, pp. 605-628, (2015); Moon S., Kim Y., Kim M., Yoo S., Ask the mutants: Mutating faulty programs for fault localization, 2014 IEEE Seventh International Conference on Software Testing, Verification and Validation. IEEE, pp. 153-162, (2014); Li D., Wong W. E., Wang W., Yao Y., Chau M., Detection and mitigation of label-flipping attacks in federated learning systems with kpca and k-means, 2021 8th International Conference on Dependable Systems and Their Applications (DSA). IEEE, pp. 551-559, (2021); Liu C., Yan X., Yu H., Han J., Yu P. S., Mining behavior graphs for ""backtrace"" of noncrashing bugs, Proceedings of the 2005 SIAM international conference on data mining. SIAM, pp. 286-297, (2005); Wong W. E., Shi Y., Qi Y., Golden R., Using an rbf neural network to locate program bugs, 2008 19th International Symposium on Software Reliability Engineering (ISSRE). IEEE, pp. 27-36, (2008); Krizhevsky A., Sutskever I., Hinton G. E., Imagenet classification with deep convolutional neural networks, Advances in neural information processing systems, 25, pp. 1097-1105, (2012); Li Y., Wang S., Nguyen T. N., Fault localization with code coverage representation learning, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, pp. 661-673, (2021); Mikolov T., Sutskever I., Chen K., Corrado G. S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in neural information processing systems, pp. 3111-3119, (2013); Baxter I. D., Yahin A., Moura L., Sant'Anna M., Bier L., Clone detection using abstract syntax trees, Proceedings. International Conference on Software Maintenance (Cat. No. 98CB36272). IEEE, pp. 368-377, (1998); Weimer W., Nguyen T., Le Goues C., Forrest S., Automatically finding patches using genetic programming, 2009 IEEE 31st International Conference on Software Engineering. IEEE, pp. 364-374, (2009); Paul S., Prakash A., A framework for source code search using program patterns, IEEE Transactions on Software Engineering, 20, 6, pp. 463-475, (1994); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, pp. 783-794, (2019); Kipf T. N., Welling M., Semi-supervised classification with graph convolutional networks, (2016); Bruna J., Zaremba W., Szlam A., LeCun Y., Spectral networks and locally connected networks on graphs, (2013); Bahdanau D., Cho K., Bengio Y., Neural machine translation by jointly learning to align and translate, (2014); Luong M.-T., Pham H., Manning C. D., Effective approaches to attention-based neural machine translation, (2015); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A. N., Kaiser, Polosukhin I., Attention is all you need, Advances in neural information processing systems, pp. 5998-6008, (2017); Chawla N. V., Japkowicz N., Kotcz A., Special issue on learning from imbalanced data sets, ACM SIGKDD explorations newsletter, 6, 1, pp. 1-6, (2004); Mohammed R., Rawashdeh J., Abdullah M., Machine learning with oversampling and undersampling techniques: overview study and experimental results, 2020 11th International Conference on Information and Communication Systems (ICICS). IEEE, pp. 243-248, (2020); Chawla N. V., Bowyer K. W., Hall L. O., Kegelmeyer W. P., Smote: synthetic minority over-sampling technique, Journal of artificial intelligence research, 16, pp. 321-357, (2002); Zhao T., Zhang X., Wang S., Graphsmote: Imbalanced node classification on graphs with graph neural networks, Proceedings of the 14th ACM International Conference on Web Search and Data Mining, pp. 833-841, (2021); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proceedings of the 28th International Conference on Program Comprehension, pp. 184-195, (2020); Kochhar P. S., Xia X., Lo D., Li S., Practitioners' expectations on automated fault localization, Proceedings of the 25th International Symposium on Software Testing and Analysis, pp. 165-176, (2016); Li X., Li W., Zhang Y., Zhang L., Deepfl: Integrating multiple fault diagnosis dimensions for deep fault localization, Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 169-180, (2019); Sohn J., Yoo S., Fluccs: Using code and change metrics to improve fault localization, Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 273-283, (2017); Li X., Zhang L., Transforming programs and tests in tandem for fault localization, Proceedings of the ACM on Programming Languages, 1, pp. 1-30, (2017); Wohlin C., Runeson P., Host M., Ohlsson M. C., Regnell B., Wesslen A., Experimentation in software engineering, (2012); Xie X., Wong W. E., Chen T. Y., Xu B., Spectrum-based fault localization: Testing oracles are no longer mandatory, 2011 11th International Conference on Quality Software. IEEE, pp. 1-10, (2011); de Souza H. A., Chaim M. L., Kon F., Spectrum-based software fault localization: A survey of techniques, advances, and challenges, (2016); Gong P., Zhao R., Li Z., Faster mutation-based fault localization with a novel mutation execution strategy, 2015 IEEE Eighth International Conference on Software Testing, Verification and Validation Workshops (ICSTW). IEEE, pp. 1-10, (2015); Papadakis M., Le Traon Y., Effective fault localization via mutation analysis: A selective mutation approach, Proceedings of the 29th annual ACM symposium on applied computing, pp. 1293-1300, (2014); Wong W. E., Qi Y., Bp neural network-based effective fault localization, International Journal of Software Engineering and Knowledge Engineering, 19, pp. 573-597, (2009); Zheng W., Hu D., Wang J., Fault localization analysis based on deep neural network, Mathematical Problems in Engineering, 2016, (2016)",,"21st International Conference on Software Quality, Reliability and Security, QRS 2021",6 December 2021 through 10 December 2021,Hainan,177710,English,Conference paper,Final,,Scopus,2-s2.0-85138900023,101
Wu Y.; Lu J.; Zhang Y.; Jin S.,"Wu, Yuelong (57219287857); Lu, Jintian (57204261261); Zhang, Yunyi (57219289757); Jin, Shuyuan (59035738800)",57219287857; 57204261261; 57219289757; 59035738800,Vulnerability Detection in C/C++ Source Code with Graph Representation Learning,2021,"2021 IEEE 11th Annual Computing and Communication Workshop and Conference, CCWC 2021",,,9376145,1519,1524,5,18,10.1109/CCWC51732.2021.9376145,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103439913&doi=10.1109%2fCCWC51732.2021.9376145&partnerID=40&md5=a7e6b3ad521d4c8c52f4acfa3f048dbd,"An open challenge in software vulnerability detection is how to identify potential vulnerabilities of source code at a fine-grained level automatically. This paper proposes an approach to automate vulnerability detection in source code at the software function level based on graph representation learning without the efforts of security experts. The proposed approach firstly represents software functions as Simplified Code Property Graphs (SCPG), which can conserve syntactic and semantic information of source code while keeping itself small enough for computing. It then utilizes graph neural network and multi layer perceptrons to learn graph representations and extract features automatically, saving efforts of feature engineering. The comparison experiments demonstrate the effectiveness of the proposed approach. © 2021 IEEE.","Lewis J., Economic Impact of Cybercrime-No Slowing down Report, (2018); Wassermann G., Su Z., Static detection of cross-site scripting vulnerabilities, Proceedings-International Conference on Software Engineering, pp. 171-180, (2008); Dahse J., Holz T., Simulation of built-in php features for precise static code analysis, Proceedings 2014 Network and Distributed System Security Symposium, 14, 2, pp. 23-26, (2014); Schwartz E.J., Avgerinos T., Brumley D., All you ever wanted to know about dynamic taint analysis and forward symbolic execution (but might have been afraid to ask), Proceedings-IEEE Symposium on Security and Privacy, pp. 317-331, (2010); Brooks T.N., Survey of automated vulnerability detection and exploit generation techniques in cyber reasoning systems, Intelligent Computing, (2019); Neuhaus S., Zimmermann T., Holler C., Zeller A., Predicting vulnerable software components, Proceedings of the ACM Conference on Computer and Communications Security, pp. 529-540, (2007); Shin Y., Meneely A., Williams L., Osborne J.A., Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities, IEEE Transactions on Software Engineering, 37, 6, pp. 772-787, (2011); Scandariato R., Walden J., Hovsepyan A., Joosen W., Predicting vulnerable software components via text mining, IEEE Transactions on Software Engineering, 40, 10, pp. 993-1006, (2014); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, Proceedings-IEEE Symposium on Security and Privacy, pp. 590-604, (2014); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Transactions on Neural Networks, 20, 1, pp. 61-80, (2009); Chernis B., Verma R., Machine learning methods for software vulnerability detection, IWSPA 2018-Proceedings of the 4th ACM International Workshop on Security and Privacy Analytics, Co-located with CODASPY 2018 2018-Janua, pp. 31-39, (2018); Dam H.K., Tran T., Pham T.T.M., Ng S.W., Grundy J., Ghose A., Automatic feature learning for predicting vulnerable software components, IEEE Transactions on Software Engineering, (2018); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, Proceedings-17th IEEE International Conference on Machine Learning and Applications, ICMLA, 2018, (2018); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, 1st International Conference on Learning Representations, ICLR 2013-Workshop Track Proceedings, pp. 1-12, (2013); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, pp. 1-29, (2019); Lin G., Zhang J., Luo W., Pan L., Xiang Y., De Vel O., Montague P., Cross-project transfer representation learning for vulnerable function discovery, IEEE Transactions on Industrial Informatics, 14, 7, pp. 3289-3297, (2018); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, Proceedings 2018 Network and Distributed System Security Symposium, pp. 1-1, (2018); Zou D., Wang S., Xu S., Li Z., Jin H., Vuldeepecker: A deep learning-based system for multiclass vulnerability detection, IEEE Transactions on Dependable and Secure Computing, PP, C, pp. 1-1, (2019); Poshyvanyk D., White M., Tufano M., Bavota G., Watson C., Di Penta M., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, Proceedings of the 15th International Conference on Mining Software Repositories-MSR '18, pp. 542-553, (2018); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, pp. 10197-10207, (2019); Duan X., Wu J., Ji S., Rui Z., Luo T., Yang M., Wu Y., Vulsniper: Focus your attention to shoot fine-grained vulnerabilities, IJCAI International Joint Conference on Artificial Intelligence, 2019, pp. 4665-4671, (2019); Cheng X., Wang H., Hua J., Zhang M., Xu G., Yi L., Sui Y., Static detection of control-flow-related vulnerabilities using graph embedding, 2019 24th International Conference on Engineering of Complex Computer Systems (ICECCS), 2019, pp. 41-50, (2019); ShiftLeftSecurity/joern: Open-source Code Analysis Platform for C/C++ Based on Code Property Graphs; Velickovic P., Casanova A., Lio P., Cucurull G., Romero A., Bengio Y., Graph attention networks, 6th International Conference on Learning Representations, ICLR 2018-Conference Track Proceedings, (2018); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5th International Conference on Learning Representations, ICLR 2017-Conference Track Proceedings, (2017); Li Y., Zemel R., Brockschmidt M., Tarlow D., Brockschmidt M., Zemel R., Brockschmidt M., Tarlow D., Gated graph sequence neural networks, 4th International Conference on Learning Representations, ICLR 2016-Conference Track Proceedings, 1, pp. 1-20, (2016); Xu K., Jegelka S., Hu W., Leskovec J., How powerful are graph neural networks, 7th International Conference on Learning Representations, ICLR, 2019, pp. 1-17, (2019); Software Assurance Reference Dataset; Zhang Y., Jin D., Xing Y., Gong Y., Automated defect identification via path analysis-based features with transfer learning, The Journal of Systems & Software, 166, (2020); Fey M., Lenssen J.E., Fast graph representation learning with pytorch geometric, ICLR Workshop on Representation Learning on Graphs and Manifolds, 1, pp. 1-19, (2019)",IEEE Region 1; IEEE Region 6; IEEE USA; Institute of Engineering and Management (IEM); SMART; University of Engineering and Management (UEM),"11th IEEE Annual Computing and Communication Workshop and Conference, CCWC 2021",27 January 2021 through 30 January 2021,"Virtual, Las Vegas",167930,English,Conference paper,Final,,Scopus,2-s2.0-85103439913,102
Zheng W.; Jiang Y.; Su X.,"Zheng, Weining (57267400800); Jiang, Yuan (57216415290); Su, Xiaohong (7402181881)",57267400800; 57216415290; 7402181881,Vu1SPG: Vulnerability detection based on slice property graph representation learning,2021,"Proceedings - International Symposium on Software Reliability Engineering, ISSRE",2021-October,,,457,467,10,18,10.1109/ISSRE52982.2021.00054,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126394310&doi=10.1109%2fISSRE52982.2021.00054&partnerID=40&md5=43007b746f7d6abcaf08fab52274f36d,"Vulnerability detection is an important issue in software security. Although various data-driven vulnerability detection methods have been proposed, the task remains challenging since the diversity and complexity of real-world vulnerable code in syntax and semantics make it difficult to extract vulnerable features with regular deep learning models, especially in analyzing a large program. Moreover, the fact that real-world vulnerable codes contain a lot of redundant information unrelated to vulnerabilities will further aggravate the above problem. To mitigate such challenges, we define a novel code representation named Slice Property Graph (SPG), and then propose VulSPG, a new vulnerability detection approach using the improved R-GCN model with triple attention mechanism to identify potential vulnerabilities in SPG. Our approach has at least two advantages over other methods. First, our proposed SPG can reflect the rich semantics and explicit structural information that may be relevance to vulnerabilities, while eliminating as much irrelevant information as possible to reduce the complexity of graph. Second, VulSPG incorporates triple attention mechanism in R-GCNs to achieve more effective learning of vulnerability patterns from SPG. We have extensively evaluated VulSPG on two large-scale datasets with programs from SARD and real-world projects. Experimental results prove the effectiveness and efficiency of VulSPG.  © 2021 IEEE.","Lin G., Wen S., Han Q.-L., Zhang J., Xiang Y., Software vulnerability detection using deep neural networks: A survey, Proceedings of the IEEE, 108, 10, pp. 1825-1848, (2020); Votipka D., Stevens R., Redmiles E., Hu J., Mazurek M., Hackers vs. testers: A comparison of software vulnerability discovery processes, 2018 IEEE Symposium on Security and Privacy (SP). IEEE, pp. 374-391, (2018); Engler D., Chen D.Y., Hallem S., Chou A., Chelf B., Bugs as deviant behavior: A general approach to inferring errors in systems code, ACM SIGOPS Operating Systems Review, 35, 5, pp. 57-72, (2001); Chess B., Gerschefske M., Rough Auditing Tool for Security, (2019); Zhou Y., Sharma A., Automated identification of security issues from commit messages and bug reports, Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, pp. 914-919, (2017); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: A framework for using deep learning to detect software vulnerabilities, IEEE Transactions on Dependable and Secure Computing, (2021); Kilpatrick P., Crookes D., Owens M., Program slicing: A computer aided programming technique, Second IEF/BCS Conference: Software Engineering, 1988 Software Engineering 88. IET, pp. 60-64, (1988); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics Via Graph Neural Networks, (2019); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy. IEEE, pp. 590-604, (2014); Noonan R.E., An algorithm for generating abstract syntax trees, Computer Languages, 10, 3-4, pp. 225-236, (1985); Ferrante J., Ottenstein K.J., Warren J.D., Toe program dependence graph and its use in optimization, ACM Transactions on Programming Languages and Systems (TOPIAS), 9, 3, pp. 319-349, (1987); Schlichtkrull M., Kipf T.N., Bloem P., Van Den Berg R., Titov I., Welling M., Modeling relational data with graph convolutional networks, European Semantic Web Conference. Springer, pp. 593-607, (2018); Wang H., Ye G., Tang Z., Tan S.H., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Transactions on Information Forensics and Security, (2020); Lee Y.J., Choi S.-H., Kim C., Lim S.-H., Park K.-W., Learning binary code with deep learning to detect software weakness, KSII the 9th International Conference on Internet (ICON!) 2017 Symposium, (2017); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir, Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE International Conference on Machine Learning and Applications (ICMIA). IEEE, pp. 757-762, (2018); Choi M.-J., Jeong S., Oh H., Choo J., End-to-end Prediction of Buffer Overruns from Raw Source Code Via Neural Memory Networks, (2017); Duvenaud D., Maclaurin D., Aguilera-Iparraguirre J., Bombarelli R.G., Hirzel T., Aspuru-Guzik A., Adams R.P., Convolutional Networks on Graphs for Learning Molecular Fingerprints, (2015); Hamilton W.L., Ymg R., Leskovec J., Inductive Representation Learning on Large Graphs, (2017); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, 4th International Conference on Leaming Representations, ICI.R 2016, Conference Track Proceedings, (2016); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention Is All You Need, (2017); Lee J., Lee I., Kang J., Self-attention graph pooling, International Conference on Machine Leaming. PMLR, pp. 3734-3743, (2019); Bishop C.M., Pattern Recognition and Machine Learning, (2006); (2021); Sard: A Software Assurance Reference Dataset, (2021); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A Deep Learning-based System for Vulnerability Detection, (2018); Maxim L., Hua G., Geeta C., Gisle D., Pytorch Profiler, (2021); Wang M., Zheng D., Gan G., Li M., Ye Z., Et al., Dgl: Deep Graph Library, (2021); (2021); (2021); Rats: Rough Audit Tool for Security, (2021); Pistoia M., Chandra S., Fink S.J., Yahav E., A survey of static analysis methods for identifying security vulnerabilities in software systems, IBM Systems Journal, 46, 2, pp. 265-288, (2007); Godefroid P., Levin M.Y., Molnar D.A., Et al., Automated whitebox fuzz testing, NDSS, 8, pp. 151-166, (2008); Shar L.K., Briand L.C., Tan H.B.K., Web application vulnerability prediction using hybrid program analysis and machine learning, IEEE Transactions on Dependable and Secure Computing, 12, 6, pp. 688-707, (2014); Mahmood R., Mahmoud Q.H., Evaluation of Static Analysis Tools for Finding Vulnerabilities in Java and C/c++ Source Code, (2018); Cadar C., Dunbar D., Engler D.R., Et al., Klee: Unassisted and automatic generation of high-coverage tests for complex systems programs, OSDI, 8, pp. 209-224, (2008); Cadar C., Sen K., Symbolic execution for software testing: Three decades later, Communications of the ACM, 56, 2, pp. 82-90, (2013); Neuhaus S., Zimmermann T., Holler C., Zeller A., Predicting vulnerable software components, Proceedings of the 14th ACM Conference on Computer and Communications Security, pp. 529-540, (2007); Chowdhury I., Zulkernine M., Using complexity, coupling, and cohesion metrics as early indicators of vulnerabilities, Journal of Systems Architecture, 57, 3, pp. 294-313, (2011); Shin Y., Williams L., An empirical model to predict security vulnerabilities using code complexity metrics, Proceedings of the Second ACM-IEEE International Symposium on Empirical Software Engineering and Measurement, pp. 315-317, (2008); Zimmermann T., Nagappan N., Williams L., Searching for a needle in a haystack: Predicting security vulnerabilities for windows vista, 2010 Third International Conference on Software Testing, Verification and Validation. IEEE, pp. 421-428, (2010); Shin Y., Meneely A., Wtlliams L., Osborne J.A., Evaluating complexity, code chum, and developer activity metrics as indicators of software vulnerabilities, IEEE Transactions on Software Engineering, 37, 6, pp. 772-787, (2010); Ghaffarian S.M., Shahriari H.R., Software vulnerability analysis and discovery using machine-learning and data-mining techniques: A survey, ACM Computing Surveys (CSUR), 50, 4, pp. 1-36, (2017); Shen Z., Chen S., A survey of automatic software vulnerability detection, Security and Communication Networks, 2020, (2020); Singh S.K., Chaturvedi A., Applying deep learning for discovery and analysis of software vulnerabilities: A brief survey, Soft Computing: Theories and Applications, pp. 649-658, (2020)",IEEE Computer Society; IEEE Reliability Society,"32nd IEEE International Symposium on Software Reliability Engineering, ISSRE 2021",25 October 2021 through 28 October 2021,Wuhan,177191,English,Conference paper,Final,,Scopus,2-s2.0-85126394310,103
Xia X.; Wang Y.; Yang Y.,"Xia, Xiaoling (14632644000); Wang, Yu (57606321100); Yang, Ye (57608455100)",14632644000; 57606321100; 57608455100,Source Code Vulnerability Detection Based on SAR-GIN,2021,"Proceedings - 2021 2nd International Conference on Electronics, Communications and Information Technology, CECIT 2021",,,,1144,1149,5,0,10.1109/CECIT53797.2021.00202,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128636129&doi=10.1109%2fCECIT53797.2021.00202&partnerID=40&md5=a8ed7158323cb10544edad6bc36b66ec,"With the development of the Internet era, software technology is being used more and more commonly, and the detection of vulnerabilities in the corresponding software must be efficient and accurate. However, software vulnerabilities are diverse, and mining vulnerabilities through source code requires a high level of professional experience for developers. Previous vulnerability detection solutions either relied on expert-defined features or used recursive neural networks only for code sequences, making it difficult to extract complex features of vulnerabilities in the traditional code space. In recent years, with the booming development of artificial intelligence technology, some scholars have started to try to combine graph neural networks to extract graph structure information of source code for software vulnerability detection. In this paper, by introducing a method based on Graph Isomorphism Network (GIN) combined with a self-attention aggregation mechanism for vulnerability detection, we achieve superior detection results. By assigning different attention weights to each layer, the self-attention mechanism helps to solve the problem of too smooth node representation and poor comprehensive performance of graph-level output. In this paper, we propose Self Attention Readout Graph Isomorphism Network (SAR-GIN), which efficiently extracts and utilizes global information at all depths by combining GIN with a self-attention mechanism in generating global graph-level features. Meanwhile, the experimental results on CWE-400, CWE-190 datasets, combined with the discrete Fourier transform, show that the modeling approach in this paper achieves superior results compared to other models.  © 2021 IEEE.","Chess B., McGraw G., Static analysis for security[J], IEEE security & privacy, 2, 6, pp. 76-79, (2004); Bayer U., Moser A., Kruegel C., Et al., Dynamic analysis of malicious code[J], Journal in Computer Virology, 2, 1, pp. 67-77, (2006); King J.C., Symbolic execution and program testing[J], Communications of the ACM, 19, 7, pp. 385-394, (1976); Li Z., Zou D., Xu S., Et al., Vuldeepecker: A deep learning-based system for vulnerability detection[J], (2018); Russell R., Et al., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE international conference on machine learning and applications (ICMLA). IEEE, (2018); Li Z., Zou D., Xu S., Et al., SySeVR: A framework for using deep learning to detect software vulnerabilities[J], IEEE Transactions on Dependable and Secure Computing, (2021); Zhou Y., Liu S., Siow J., Et al., Devign: effective vulnerability identification by learning comprehensive program semantics via graph neural networks[C], Advances in Neural Information Processing Systems 2019. Neural Information Processing Systems (NIPS), (2019); Wang H., Ye G., Tang Z., Et al., Combining graph-based learning with automated data collection for code vulnerability detection[J], IEEE Transactions on Information Forensics and Security, 16, pp. 1943-1958, (2020); Cao S., Sun X., Bo L., Et al., BGNN4VD: Constructing Bidirectional Graph Neural-Network for Vulnerability Detection[J], Information and Software Technology, 136, (2021); Neamtiu I., Foster J.S., Hicks M., Understanding source code evolution using abstract syntax tree matching[C], Proceedings of the 2005 international workshop on Mining software repositories, pp. 1-5, (2005); Minaee S., Boykov Y.Y., Porikli F., Et al., Image segmentation using deep learning: A survey[J], IEEE Transactions on Pattern Analysis and Machine Intelligence, (2021); Gao J., Li P., Chen Z., Et al., A survey on deep learning for multimodal data fusion[J], Neural Computation, 32, 5, pp. 829-864, (2020); Kuutti S., Bowden R., Jin Y., Et al., A survey of deep learning applications to autonomous vehicle control[J], IEEE Transactions on Intelligent Transportation Systems, 22, 2, pp. 712-733, (2020); Mou L., Li G., Zhang L., Et al., Convolutional neural networks over tree structures for programming language processing[C], Thirtieth AAAI Conference on Artificial Intelligence, (2016); Goldberg Y., Levy O., word2vec Explained: deriving Mikolov et al 's negative-sampling word-embedding method[J], (2014); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs[C], International Conference on Learning Representations, (2018); Xu K., Hu W., Leskovec J., Et al., How Powerful are Graph Neural Networks [C], International Conference on Learning Representations, (2018); Lafta R., Zhang J., Tao X., Et al., A fast Fourier transform-coupled machine learning-based ensemble model for disease risk prediction using a real-life dataset[C], Pacific-Asia Conference on Knowledge Discovery and Data Mining, pp. 654-670, (2017); Radojii D., Kredatus S., The impact of stock market price Fourier transform analysis on the Gated Recurrent Unit classifier model[J], Expert Systems with Applications, 159, (2020)",The International Society for Applied Computing (ISAC); The Technical Institute for Engineers (T.I.E.),"2nd International Conference on Electronics, Communications and Information Technology, CECIT 2021",27 December 2021 through 29 December 2021,"Virtual, Sanya",178297,English,Conference paper,Final,,Scopus,2-s2.0-85128636129,104
Cheng X.; Wang H.; Hua J.; Xu G.; Sui Y.,"Cheng, Xiao (57211627500); Wang, Haoyu (55808022700); Hua, Jiayi (57211621471); Xu, Guoai (25630048500); Sui, Yulei (54788439800)",57211627500; 55808022700; 57211621471; 25630048500; 54788439800,DeepWukong: Statically Detecting Software Vulnerabilities Using Deep Graph Neural Network,2021,ACM Transactions on Software Engineering and Methodology,30,3,38,,,,134,10.1145/3436877,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105713814&doi=10.1145%2f3436877&partnerID=40&md5=f2f88288533288e48de75486035787b6,"Static bug detection has shown its effectiveness in detecting well-defined memory errors, e.g., memory leaks, buffer overflows, and null dereference. However, modern software systems have a wide variety of vulnerabilities. These vulnerabilities are extremely complicated with sophisticated programming logic, and these bugs are often caused by different bad programming practices, challenging existing bug detection solutions. It is hard and labor-intensive to develop precise and efficient static analysis solutions for different types of vulnerabilities, particularly for those that may not have a clear specification as the traditional well-defined vulnerabilities. This article presents DeepWukong, a new deep-learning-based embedding approach to static detection of software vulnerabilities for C/C++ programs. Our approach makes a new attempt by leveraging advanced recent graph neural networks to embed code fragments in a compact and low-dimensional representation, producing a new code representation that preserves high-level programming logic (in the form of control-and data-flows) together with the natural language information of a program. Our evaluation studies the top 10 most common C/C++ vulnerabilities during the past 3 years. We have conducted our experiments using 105,428 real-world programs by comparing our approach with four well-known traditional static vulnerability detectors and three state-of-the-art deep-learning-based approaches. The experimental results demonstrate the effectiveness of our research and have shed light on the promising direction of combining program analysis with deep learning techniques to address the general static code analysis challenges.  © 2021 ACM.","National Vulnerability Database, (2020); Clang Static Analyzer, (2020); Coverity, (2020); HP Fortify, (2020); Wheeler D.A., Flawfinder, (2020); Infer, (2020); Viega J., Bloch J.T., Kohno Y., McGraw G., ITS4: A static vulnerability scanner for C and C++ code, Proceedings 16th Annual Computer Security Applications Conference (ACSAC’00), pp. 257-267, (2000); RATS, (2014); Checkmarx, (2020); Sui Y., Xue J., SVF: Interprocedural static value-flow analysis in LLVM, Proceedings of the 25th International Conference on Compiler Construction (CC’16), pp. 265-266, (2016); Grieco G., Grinblat G.L., Uzal L., Rawat S., Feist J., Mounier L., Toward large-scale vulnerability discovery using machine learning, Proceedings of the 6th ACM Conference on Data and Application Security and Privacy (CODASPY’16), pp. 85-96, (2016); Neuhaus S., Zimmermann T., The beauty and the beast: Vulnerabilities in red hat’s packages, Proceedings of the 2009 USENIX Annual Technical Conference (USENIX ATC’09), (2009); Neuhaus S., Zimmermann T., Holler C., Zeller A., Predicting vulnerable software components, Proceedings of the 14th ACM Conference on Computer and Communications Security (CCS’07), pp. 529-540, (2007); Shin Y., Meneely A., Williams L., Osborne J.A., Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities, IEEE Trans. Software Eng., 37, pp. 772-787, (2011); Cheng X., Wang H., Hua J., Zhang M., Xu G., Yi L., Sui Y., Static detection of control-flow-related vulnerabilities using graph embedding, 2019 24th International Conference on Engineering of Complex Computer Systems (ICECCS’19), pp. 41-50, (2019); White M., Vendome C., Linares-Vasquez M., Poshyvanyk D., Toward deep learning software repositories, Proceedings of the 12th Working Conference on Mining Software Repositories (MSR’15), pp. 334-345, (2015); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019 (NeurIPS’19), (2019); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, The Network and Distributed System Security Symposium (NDSS’18), (2018); Mikolov T., Sutskever I., Chen K., Corrado G., Dean J., Distributed representations of words and phrases and their compositionality, Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2 (NIPS’13), pp. 3111-3119, (2013); Le Q.V., Mikolov T., Distributed representations of sentences and documents, Proceedings of the 31th International Conference on Machine Learning (ICML’14), 32, pp. 1188-1196, (2014); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, CoRR, (2017); Software Assurance Reference Dataset, (2017); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, CoRR, (2016); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, International Conference on Learning Representations, (2018); Morris C., Ritzert M., Fey M., Hamilton W.L., Lenssen J.E., Rattan G., Grohe M., Weisfeiler and Leman go neural: Higher-order graph neural networks, CoRR, (2018); Pingali K., Bilardi G., APT: A data structure for optimal control dependence computation, Proceedings of the ACM SIGPLAN 1995 Conference on Programming Language Design and Implementation (PLDI’95), pp. 32-46, (1995); Hardekopf B., Lin C., Flow-sensitive pointer analysis for millions of lines of code, Proceedings of the 9th Annual IEEE/ACM International Symposium on Code Generation and Optimization (CGO’11), pp. 289-298, (2011); Cowan C., Pu C., Maier D., Hintony H., Walpole J., Bakke P., Beattie S., Grier A., Wagle P., Zhang Q., StackGuard: Automatic adaptive detection and prevention of buffer-overflow attacks, Proceedings of the 7th Conference on USENIX Security Symposium - Volume 7 (SSYM’98), (1998); Cowan C., Wagle F., Pu C., Beattie S., Walpole J., Buffer overflows: Attacks and defenses for the vulnerability of the decade, Proceedings DARPA Information Survivability Conference and Exposition (DISCEX’00), 2, pp. 119-129, (2000); Antlr, (2014); Weiser M., Program slicing, Proceedings of the 5th International Conference on Software Engineering (ICSE’81), pp. 439-449, (1981); Gupta R., Pal S., Kanade A., Shevade S.K., DeepFix: Fixing common C language errors by deep learning, Proceedings of the 31st AAAI Conference on Artificial Intelligence (AAAI’17), pp. 1345-1351, (2017); Robbins H., A stochastic approximation method, Annals of Mathematical Statistics, 22, pp. 400-407, (2007); Cangea C., Velickovic P., Jovanovic N., Kipf T., Lio P., Towards Sparse Hierarchical Graph Classifiers, (2018); Xu K., Li C., Tian Y., Sonobe T., Kawarabayashi K.-I., Jegelka S., Representation learning on graphs with jumping knowledge networks, CoRR, (2018); Xu K., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks?, CoRR, (2018); Ramchoun H., Janati Idrissi M.A., Ghanou Y., Ettaouil M., Multilayer perceptron: Architecture optimization and training with mixed activation functions, Proceedings of the 2nd International Conference on Big Data, Cloud and Applications (BDCA’17), (2017); Aljawarneh S.A., Alawneh A., Jaradat R., Cloud security engineering: Early stages of SDLC, Future Generation Computer Systems, 74, pp. 385-392, (2017); AlBreiki H.H., Mahmoud Q.H., Evaluation of static analysis tools for software security, 2014 10th International Conference on Innovations in Information Technology (IIT’14), pp. 93-98, (2014); Zhou Y., Sharma A., Automated identification of security issues from commit messages and bug reports, Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering (ESEC/FSE’17), pp. 914-919, (2017); Fey M., Lenssen J.E., Fast graph representation learning with PyTorch geometric, ICLR Workshop on Representation Learning on Graphs and Manifolds, (2019); Kingma D.P., Ba J., ADaM: A method for stochastic optimization, 3rd International Conference on Learning Representations (ICLR’15), Conference Track Proceedings, (2015); Pendleton M., Garcia-Lebron R., Cho J.-H., Xu S., A survey on systems security metrics, ACM Computing Surveys, 49, 4, (2016); Powers D.M.W., Evaluation: From precision, recall and F-measure to ROC, informedness, markedness & correlation, Journal of Machine Learning Technologies, 2, 1, pp. 37-63, (2011); Mutzel P., Algorithmic data science (invited talk), 36th International Symposium on Theoretical Aspects of Computer Science (STACS’19) (, 126, (2019); Younan Y., Joosen W., Piessens F., Code Injection in C and C++: A Survey of Vulnerabilities and Countermeasures, (2004); The UC Davis Reducing Software Security Risk through An Integrated Approach Project, (2000); Berdine J., Calcagno C., O'Hearn P.W., Smallfoot: Modular automatic assertion checking with separation logic, Formal Methods for Components and Objects, pp. 115-137, (2006); Calcagno C., Distefano D., O'Hearn P., Yang H., Compositional shape analysis by means of bi-abduction, Proceedings of the 36th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL’09), pp. 289-300, (2009); Yamaguchi F., Wressnegger C., Gascon H., Rieck K., Chucky: Exposing missing checks in source code for vulnerability discovery, Proceedings of the 2013 ACM SIGSAC Conference on Computer & Communications Security (CCS’13), pp. 499-510, (2013); Yamaguchi F., Maier A., Gascon H., Rieck K., Automatic inference of search patterns for taint-style vulnerabilities, 2015 IEEE Symposium on Security and Privacy (SP’15), pp. 797-812, (2015); Backes M., Kopf B., Rybalchenko A., Automatic discovery and quantification of information leaks, 2009 IEEE Symposium on Security and Privacy (SP’09), pp. 141-153, (2009); Jang J., Agrawal A., Brumley D., Redebug: Finding unpatched code clones in entire OS distributions, 2012 IEEE Symposium on Security and Privacy (SP’12), pp. 48-62, (2012); Kim S., Woo S., Lee H., Oh H., Vuddy: A scalable approach for vulnerable code clone discovery, 2017 IEEE Symposium on Security and Privacy (SP’17), pp. 595-614, (2017); Pham N.H., Nguyen T.T., Nguyen H.A., Nguyen T.N., Detection of recurring software vulnerabilities, Proceedings of the IEEE/ACM International Conference on Automated Software Engineering (ASE’10), pp. 447-456, (2010); Pradel M., Sen K., DeepBugs: A learning approach to name-based bug detection, Proceedings of the ACM on Programming Languages, 2, (2018); Yan H., Sui Y., Chen S., Xue J., Machine-learning-guided typestate analysis for static use-after-free detection, Proceedings of the 33rd Annual Computer Security Applications Conference (ACSAC’17), pp. 42-54, (2017); Howard Johnson J., Identifying redundancy in source code using fingerprints, Proceedings of the 1993 Conference of the Centre for Advanced Studies on Collaborative Research: Software Engineering - Volume 1 (CASCON’93), pp. 171-183, (1993); Howard Johnson J., Substring matching for clone detection and change tracking, Proceedings 1994 International Conference on Software Maintenance, pp. 120-126, (1994); Howard Johnson J., Visualizing textual redundancy in legacy source, Proceedings of the 1994 Conference of the Centre for Advanced Studies on Collaborative Research (CASCON’94), (1994); Roy C.K., Cordy J.R., NICAD: Accurate detection of near-miss intentional clones using flexible pretty-printing and code normalization, 2008 16th IEEE International Conference on Program Comprehension (ICPC’08), pp. 172-181, (2008); Kamiya T., Kusumoto S., Inoue K., CCFinder: A multilinguistic token-based code clone detection system for large scale source code, IEEE Transactions on Software Engineering, 28, 7, pp. 654-670, (2002); Li Z., Lu S., Myagmar S., Zhou Y., CP-miner: Finding copy-paste and related bugs in large-scale software code, IEEE Transactions on Software Engineering, 32, 3, pp. 176-192, (2006); Sajnani H., Lopes C., A parallel and efficient approach to large scale clone detection, 2013 7th International Workshop on Software Clones (IWSC’13), pp. 46-52, (2013); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., SourcererCC: Scaling code clone detection to big-code, Proceedings of the 38th International Conference on Software Engineering (ICSE’16), pp. 1157-1168, (2016); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings of the 41st International Conference on Software Engineering (ICSE’19), pp. 783-794, (2019); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, Proceedings of the 38th International Conference on Software Engineering (ICSE’16), pp. 297-308, (2016); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, (2019); Chen K., Liu P., Zhang Y., Achieving accuracy and scalability simultaneously in detecting application clones on Android markets, Proceedings of the 36th International Conference on Software Engineering (ICSE’14), pp. 175-186, (2014); Gabel M., Jiang L., Su Z., Scalable detection of semantic clones, Proceedings of the 30th International Conference on Software Engineering (ICSE’08), pp. 321-330, (2008); Komondoor R., Horwitz S., Using slicing to identify duplication in source code, Static Analysis, pp. 40-56, (2001); Krinke J., Identifying similar code with program dependence graphs, Proceedings of the 8th Working Conference on Reverse Engineering (WCRE’01), (2001); Liu C., Chen F., Han J., Yu P., GPLag: Detection of software plagiarism by program dependence graph analysis, Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’06), pp. 872-881, (2006); Sui Y., Cheng X., Zhang G., Wang H., Flow2vec: Value-flow-based precise code embedding, Proceedings of the ACM on Programming Languages, 4, (2020); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering (ASE’16), pp. 87-98, (2016)",,,,,,English,Article,Final,,Scopus,2-s2.0-85105713814,105
Zhang Y.; Liu X.; Du D.,"Zhang, Yuhan (59070181000); Liu, Xueyang (35746287900); Du, Dongdong (7202611255)",59070181000; 35746287900; 7202611255,Static detection of vulnerabilities via graph attention hierarchically,2021,"2021 11th International Workshop on Computer Science and Engineering, WCSE 2021",,,,6,12,6,0,10.18178/wcse.2021.06.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114202299&doi=10.18178%2fwcse.2021.06.002&partnerID=40&md5=6d5bf4b6f0666309c54e4ed8eca9d669,"With the rapid growth of the software industry, the risks of vulnerabilities are inevitably increasing. Deep learning based methods have been widely used in vulnerability detection in recent years. Since the inherent graph structure of source code contains rich semantics, many deep learning works have exploited graph neural networks to enhance code representation. Despite their novel design, learning the structural information in the graph hierarchically and focusing on important nodes are still problems to better capture vulnerability semantics. To tackle this bottleneck, we propose a novel neural model for vulnerability detection. A SAGPool module is designed to automatically chooses important nodes to retain hierarchically in each graph convolution layer. Our model is trained and tested over the REVEAL dataset built on two popular and well-maintained open-source projects. The experimental results demonstrate that our model outperforms the state-of-the-art methods. © 2021 11th International Workshop on Computer Science and Engineering, WCSE 2021. All Rights Reserved.","Lee J., Lee I., Kang J., Self-attention graph pooling[C], International Conference on Machine Learning. PMLR, pp. 3734-3743, (2019); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet?, CoRR, (2020); Russell R.L., Kim L.Y., Hamilton L.H., Lazovich T., Harer J., Ozdemir O., Ellingwood P.M., McConley M.W., Automated vulnerability detection in source code using deep representation learning, 17th IEEE International Conference on Machine Learning and Applications, ICMLA 2018, pp. 757-762, (2018); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, 25th Annual Network and Distributed System Security Symposium, NDSS 2018, (2018); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Wang S., Wang J., SyseVR: A framework for using deep earning to detect software vulnerabilities, CoRR, (2018); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput, 9, 8, pp. 1735-1780, (1997); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using RNN encoder-decoder for statistical machine translation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, pp. 1724-1734, (2014); Zhou Y., Liu S., Siow J.K., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, pp. 10197-10207, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, 4th International Conference on Learning Representations, ICLR 2016, (2016); Roziere B., Lachaux M., Chanussot L., Lample G., Unsupervised translation of programming languages, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, (2020); Schroff F., Kalenichenko D., Philbin J., FaceNet: A unified embedding for face recognition and clustering, IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, pp. 815-823, (2015); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, SP 2014, pp. 590-604, (2014); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks, (2016)",Bauman Moscow State Technical University; Shanghai Maritime University; Tokyo University of Science; University of Houston-Downtown,"2021 11th International Workshop on Computer Science and Engineering, WCSE 2021",19 June 2021 through 21 June 2021,"Shanghai, Virtual",171371,English,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85114202299,108
Zhou Y.; Liu S.; Siow J.; Du X.; Liu Y.,"Zhou, Yaqin (57211306375); Liu, Shangqing (57218717656); Siow, Jingkai (57216460449); Du, Xiaoning (57207130233); Liu, Yang (56911879800)",57211306375; 57218717656; 57216460449; 57207130233; 56911879800,Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks,2019,Advances in Neural Information Processing Systems,32,,,,,,419,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089940996&partnerID=40&md5=360e4ac4b80f50a82fbee08b6e8712d6,"Vulnerability identification is crucial to protect the software systems from attacks for cyber security. It is especially important to localize the vulnerable functions among the source code to facilitate the fix. However, it is a challenging and tedious process, and also requires specialized security expertise. Inspired by the work on manually-defined patterns of vulnerabilities from various code representation graphs and the recent advance on graph neural networks, we propose Devign, a general graph neural network based model for graph-level classification through learning on a rich set of code semantic representations. It includes a novel Conv module to efficiently extract useful features in the learned rich node representations for graph-level classification. The model is trained over manually labeled datasets built on 4 diversified large-scale open-source C projects that incorporate high complexity and variety of real source code instead of synthesis code used in previous works. The results of the extensive evaluation on the datasets demonstrate that Devign outperforms the state of the arts significantly with an average of 10.51% higher accuracy and 8.68% F1 score, increases averagely 4.66% accuracy and 6.37% F1 by the Conv module. © 2019 Neural information processing systems foundation. All rights reserved.","Xu Z., Chen B., Chandramohan M., Liu Y., Song F., Spain: security patch analysis for binaries towards understanding the pain and pills, Proceedings of the 39th International Conference on Software Engineering, pp. 462-472, (2017); Chandramohan M., Xue Y., Xu Z., Liu Y., Cho C. Y., Tan H. B. K., Bingo: Cross-architecture cross-os binary search, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 678-689, (2016); Li Y., Xue Y., Chen H., Wu X., Zhang C., Xie X., Wang H., Liu Y., Cerebro: context-aware adaptive fuzzing for effective vulnerability detection, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 533-544, (2019); Chen H., Xue Y., Li Y., Chen B., Xie X., Wu X., Liu Y., Hawkeye: Towards a desired directed grey-box fuzzer, Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pp. 2095-2108, (2018); Li Y., Chen B., Chandramohan M., Lin S.-W., Liu Y., Tiu A., Steelix: program-state based binary fuzzing, Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, pp. 627-637, (2017); Wang J., Chen B., Wei L., Liu Y., Superion: grammar-aware greybox fuzzing, Proceedings of the 41st International Conference on Software Engineering, pp. 724-735, (2019); Wang J., Chen B., Wei L., Liu Y., Skyfire: Data-driven seed generation for fuzzing, 2017 IEEE Symposium on Security and Privacy (SP), pp. 579-594, (2017); Xue Y., Xu Z., Chandramohan M., Liu Y., Accurate and scalable cross-architecture cross-os binary code search with emulation, IEEE Transactions on Software Engineering, (2018); Neuhaus S., Zimmermann T., Holler C., Zeller A., Predicting vulnerable software components, Proceedings of the 14th ACM Conference on Computer and Communications Security, ser. CCS'07, pp. 529-540, (2007); Nguyen V. H., Tran L. M. S., Predicting vulnerable software components with dependency graphs, Proceedings of the 6th International Workshop on Security Measurements and Metrics, ser. MetriSec'10, pp. 31-38, (2010); Shin Y., Meneely A., Williams L., Osborne J. A., Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities, IEEE Trans. Softw. Eng, 37, 6, pp. 772-787, (2011); CWE List Version 3.1, (2018); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, 25th Annual Network and Distributed System Security Symposium (NDSS 2018), (2018); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 757-762, (2018); Dam H. K., Tran T., Pham T., Ng S. W., Grundy J., Ghose A., Automatic feature learning for vulnerability prediction, (2017); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, Proceedings of the 2014 IEEE Symposium on Security and Privacy, ser. SP'14, pp. 590-604, (2014); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, (2015); Schlichtkrull M., Kipf T. N., Bloem P., Van Den Berg R., Titov I., Welling M., Modeling relational data with graph convolutional networks, European Semantic Web Conference, pp. 593-607, (2018); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); Representation Learning on Networks, (2018); Dai H., Dai B., Song L., Discriminative embeddings of latent variable models for structured data, International conference on machine learning, pp. 2702-2711, (2016); Ying Z., You J., Morris C., Ren X., Hamilton W., Leskovec J., Hierarchical graph representation learning with differentiable pooling, Advances in Neural Information Processing Systems, pp. 4805-4815, (2018); Zhang M., Cui Z., Neumann M., Chen Y., An end-to-end deep learning architecture for graph classification, Thirty-Second AAAI Conference on Artificial Intelligence, (2018); Du X., Chen B., Li Y., Guo J., Zhou Y., Liu Y., Jiang Y., Leopard: Identifying vulnerable code for vulnerability assessment through program metrics, Proceedings of the 41st International Conference on Software Engineering, pp. 60-71, (2019); Zhou Y., Sharma A., Automated identification of security issues from commit messages and bug reports, Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, ser. ESEC/FSE 2017, pp. 914-919, (2017); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, (2017); Snoek J., Larochelle H., Adams R. P., Practical bayesian optimization of machine learning algorithms, Advances in neural information processing systems, pp. 2951-2959, (2012); Yang Z., Yang D., Dyer C., He X., Smola A., Hovy E., Hierarchical attention networks for document classification, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1480-1489, (2016); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, AAAI, 2, 3, (2016); Xu X., Liu C., Feng Q., Yin H., Song L., Song D., Neural network-based graph embedding for cross-platform binary code similarity detection, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 363-376, (2017)",Citadel; Doc.AI; et al.; Lambda; Lyft; Microsoft Research,"33rd Annual Conference on Neural Information Processing Systems, NeurIPS 2019",8 December 2019 through 14 December 2019,Vancouver,161263,English,Conference paper,Final,,Scopus,2-s2.0-85089940996,111
Morgachev G.; Ignatyev V.; Belevantsev A.,"Morgachev, Gleb (57215608458); Ignatyev, Valery (56450707900); Belevantsev, Andrey (22333624800)",57215608458; 56450707900; 22333624800,Detection of variable misuse using static analysis combined with machine learning,2019,"Proceedings - 2019 Ivannikov Ispras Open Conference, ISPRAS 2019",,,8991157,16,24,8,2,10.1109/ISPRAS47671.2019.00009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081319485&doi=10.1109%2fISPRAS47671.2019.00009&partnerID=40&md5=c20c1b1eee9c4f56e23317ce1c8773fb,"Industrial static analyzers are able to detect only several narrow classes of algorithmic errors, for example actual arguments order swapped with formal parameters, forgotten renaming of variable after copy-paste. However, even for these categories essential part of errors is lost because of heuristical design of a checker. We propose the generalization of specified errors in the form of variable misuse problem and deal with it using machine learning. The proposed method uses message propagation through the program model represented as a graph, combining data from multiple analysis levels, including AST, dataflow. We introduce several error criteria, which were evaluated on the set of open source projects with millions of LoC. Testing in close to industrial conditions shows good false positive and missed errors ratio comparable with remaining detectors and allows to include developed checker (after a minor rework) into a general purpose production static analyzer for error detection. © 2019 IEEE.","Koshelev V.K., Ignatiev V.N., Borzilov A.I., Belevantsev A.A., Sharpchecker: Static analysis tool for c# programs, Programming and Computer Software, 43, 4, pp. 268-276, (2017); Coverity Static Application Security Testing: Tool Set for Static Code Analysis, (2019); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, CoRR, (2017); Ivannikov V.P., Belevantsev A.A., Borodin A.E., Ignatiev V.N., Zhurikhin D.M., Avetisyan A.I., Static analyzer svace for finding defects in a source program code, Programming and Computer Software, 40, 5, pp. 265-275, (2014); Belevantsev A., Borodin A., Dudina I., Ignatiev V., Izbyshev A., Polyakov S., Velesevich E., Zhurikhin D., Design and Development of Svace Static Analyzers, 5, pp. 3-9, (2018); Allamanis M., Barr E.T., Devanbu P.T., Sutton C.A., A survey of machine learning for big code and naturalness, CoRR, (2017); Hovsepyan A., Scandariato R., Joosen W., Walden J., Software vulnerability prediction using text analysis techniques, Proceedings of the 4th International Workshop on Security Measurements and Metrics, Ser. MetriSec '12, pp. 7-10, (2012); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, CoRR; Russell R.L., Kim L.Y., Hamilton L.H., Lazovich T., Harer J.A., Ozdemir O., Ellingwood P.M., McConley M.W., Automated vulnerability detection in source code using deep representation learning, CoRR, (2018); Hsiao C.-H., Cafarella M., Narayanasamy S., Using web corpus statistics for program analysis, SIGPLAN Not., 49, 10, pp. 49-65, (2014); Mou L., Li G., Jin Z., Zhang L., Wang T., Tbcnn: A tree-based convolutional neural network for programming language processing, CoRR, (2014); Dam H.K., Pham T., Ng S.W., Tran T., Grundy J., Ghose A., Kim T., Kim C., A deep tree-based model for software defect prediction, CoRR, (2018); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, (2015); Vasic M., Kanade A., Maniatis P., Bieber D., Singh R., Neural Program Repair by Jointly Learning to Localize and Repair, (2019); Rehurek R., Sojka P., Software framework for topic modelling with large corpora, Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks, pp. 45-50, (2010); Mikolov T., Sutskever I., Chen K., Corrado G., Dean J., Distributed representations of words and phrases and their compositionality, Proceedings of the 26th International Conference on Neural Information Processing Systems-Volume 2, Ser. NIPS'13, pp. 3111-3119, (2013); Paszke A., Gross S., Chintala S., Chanan G., Yang E., DeVito Z., Lin Z., Desmaison A., Antiga L., Lerer A., Automatic differentiation in pytorch, NIPS-W, (2017)",,"2019 Ivannikov Ispras Open Conference, ISPRAS 2019",5 December 2019 through 6 December 2019,Moscow,157794,English,Conference paper,Final,,Scopus,2-s2.0-85081319485,112
Wang H.; Ye G.; Tang Z.; Tan S.H.; Huang S.; Fang D.; Feng Y.; Bian L.; Wang Z.,"Wang, Huanting (57213424982); Ye, Guixin (57193613039); Tang, Zhanyong (15822992800); Tan, Shin Hwei (42162322300); Huang, Songfang (56349908000); Fang, Dingyi (8975043000); Feng, Yansong (55387599700); Bian, Lizhong (57221304389); Wang, Zheng (35111811300)",57213424982; 57193613039; 15822992800; 42162322300; 56349908000; 8975043000; 55387599700; 57221304389; 35111811300,Combining Graph-Based Learning with Automated Data Collection for Code Vulnerability Detection,2021,IEEE Transactions on Information Forensics and Security,16,,9293321,1943,1958,15,148,10.1109/TIFS.2020.3044773,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098786569&doi=10.1109%2fTIFS.2020.3044773&partnerID=40&md5=38482a134182eb97d899b34ee5f5e116,"This paper presents FUNDED (Flow-sensitive vUl-Nerability coDE Detection), a novel learning framework for building vulnerability detection models. Funded leverages the advances in graph neural networks (GNNs) to develop a novel graph-based learning method to capture and reason about the program's control, data, and call dependencies. Unlike prior work that treats the program as a sequential sequence or an untyped graph, Funded learns and operates on a graph representation of the program source code, in which individual statements are connected to other statements through relational edges. By capturing the program syntax, semantics and flows, Funded finds better code representation for the downstream software vulnerability detection task. To provide sufficient training data to build an effective deep learning model, we combine probabilistic learning and statistical assessments to automatically gather high-quality training samples from open-source projects. This provides many real-life vulnerable code training samples to complement the limited vulnerable code samples available in standard vulnerability databases. We apply Funded to identify software vulnerabilities at the function level from program source code. We evaluate Funded on large real-world datasets with programs written in C, Java, Swift and Php, and compare it against six state-of-the-art code vulnerability detection models. Experimental results show that Funded significantly outperforms alternative approaches across evaluation settings. © 2005-2012 IEEE.","Sun N., Zhang J., Rimba P., Gao S., Zhang L.Y., Xiang Y., Datadriven cybersecurity incident prediction: A survey, Ieee Commun. Surveys Tuts, 21, 2, pp. 1744-1772, (2019); Wu F., Wang J., Liu J., Wang W., Vulnerability detection with deep learning, Proc. 3rd Ieee Int. Conf. Comput. Commun. (ICCC), pp. 1298-1302, (2017); Lin G., Et al., Software vulnerability discovery via learning multidomain knowledge bases, Ieee Trans. Dependable Secure Comput., Early Access, (2020); Kim S., Woo S., Lee H., Oh H., Vuddy: A scalable approach for vulnerable code clone discovery, Proc. Ieee Symp. Secur. Privacy (SP), pp. 595-614, (2017); Li Z., Et al., Vuldeepecker: A deep learning-based system for vulnerability detection, Proc. Ndss, (2018); Zou D., Wang S., Xu S., Li Z., Jin H., μVulDeePecker: A deep learning-based system for multiclass vulnerability detection, Ieee Trans. Dependable Secure Comput., Early Access, (2019); Lin G., Sheng Wen Q.H., Jun Zhang Y.X., Software vulnerability detection using deep neural networks: A survey, Proc. Ieee, 108, 10, pp. 1825-1848, (2020); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities, (2018); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput, 9, 8, pp. 1735-1780, (1997); Kuck D.J., Kuhn R.H., Padua D.A., Leasure B., Wolfe M., Dependence graphs and compiler optimizations, Proc. 8th Acm Sigplansigact Symp. Princ. Program. Lang. (POPL), pp. 207-218, (1981); Wu Z., Pan S., Chen F., Long G., Zhang C., Philip S.Y., A comprehensive survey on graph neural networks, Ieee Trans. Neural Netw. Learn. Syst., Early Access, (2020); Gao H., Wang Z., Ji S., Large-scale learnable graph convolutional networks, Proc. 24th Acm Sigkdd Int. Conf. Knowl. Discovery Data Mining, pp. 1416-1424, (2018); Wu Y., Liu X., Feng Y., Wang Z., Zhao D., Jointly Learning Entity and Relation Representations for Entity Alignment, (2019); Xu X., Liu C., Feng Q., Yin H., Song L., Song D., Neural networkbased graph embedding for cross-platform binary code similarity detection, Proc. Acm Sigsac Conf. Comput. Commun. Secur, pp. 363-376, (2017); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Proc. Adv. Neural Inf. Process. Syst, pp. 10197-10207, (2019); Pradel M., Sen K., Deepbugs: A learning approach to name-based bug detection, Proc. Acm Program. Lang, 2, pp. 1-25, (2018); Cummins C., Petoumenos P., Murray A., Leather H., Compiler fuzzing through deep learning, Proc. 27th Acm Sigsoft Int. Symp. Softw. Test. Anal, pp. 95-105, (2018); Perl H., Dechand S., Smith M., Arp D., Yamaguchi F., Rieck K., Fahl S., Acar Y., Vccfinder: Finding potential vulnerabilities in opensource projects to assist code audits, Proc. 22nd Acm Sigsac Conf. Comput. Commun. Secur, pp. 426-437, (2015); Li Z., Zou D., Xu S., Jin H., Qi H., Hu J., Vulpecker: An automated vulnerability detection system based on code similarity analysis, Proc. 32nd Annu. Conf. Comput. Secur. Appl, pp. 201-213, (2016); Sabetta A., Bezzi M., A practical approach to the automatic classification of security-relevant commits, Proc. Ieee Int. Conf. Softw. Maintenance Evol. (ICSME), pp. 579-582, (2018); Jacobs R.A., Jordan M.I., Nowlan S.J., Hinton G.E., Adaptive mixtures of local experts, Neural Comput, 3, 1, pp. 79-87, (2012); Rhafer G., Vovk V., A tutorial on conformal prediction, J. Mach. Learn. Res, 9, pp. 371-421, (2008); Zhou Y., Sharma A., Automated identification of security issues from commit messages and bug reports, Proc. 11th Joint Meeting Found. Softw. Eng, pp. 914-919, (2017); Wang X., Sun K., Batcheller A., Jajodia S., Detecting '0-day' vulnerability: An empirical study of secret security patch in oss, Proc. 49th Annual IEEE/IFIP Int. Conf. Dependable Syst. Netw. (DSN), pp. 485-492, (2019); Huang Z., Xu W., Yu K., Bidirectional LSTM-CRF Models for Sequence Tagging, (2015); Ye G., Et al., Deep program structure modeling through multi-relational graph-based learning, Proc. Acm Int. Conf. Parallel Archit. Compilation Techn, pp. 111-123, (2020); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, Proc. Iclr, (2016); Cho K., Et al., Learning phrase representations using rnn encoderdecoder for statistical machine translation, Proc. Empirical Methods Natural Lang. Process. (EMNLP), Doha, Qatar, pp. 1724-1734, (2014); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, Proc. Iclr, (2018); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Proc. Adv. Neural Inf. Process. Syst, pp. 3111-3119, (2013); Rahimi A., Cohn T., Baldwin T., Semi-supervised user geolocation via graph convolutional networks, Proc. Acl, pp. 2009-2019, (2018); Kumar Srivastava R., Greff K., Schmidhuber J., Highway Networks, (2015); Zhang Z., Sabuncu M., Generalized cross entropy loss for training deep neural networks with noisy labels, Proc. Adv. Neural Inf. Process. Syst, pp. 8778-8788, (2018); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, (2014); Pasquale F., The Black Box Society, (2015); Xu K., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks?, Proc. Iclr, (2018); Weisfeiler B., Lehman A., A reduction of a graph to a canonical form and an algebra arising during this reduction, Nauchno-Technicheskaya Informatsia, 2, 9, pp. 12-16, (1968); Common Vulnerabilities and Exposures (CVE), (2019); National Vulnerability Database (NVD), (2020); Goldberg Y., Levy O., Word2vec Explained: Deriving Mikolov et Al.'s Negative-sampling Word-embedding Method, (2014); Balasubramanian V.N., Baker A., Yanez M., Chakraborty S., Panchanathan S., Pycp: An open-source conformal predictions toolkit, Proc. Ifip Int. Conf. Artif. Intell. Appl. Innov, pp. 361-370, (2013); Software Assurance Reference Dataset Project, (2019); Sap Dataset, (2019); Zvd Dataset, (2019); TensorFlow, (2020); Scikit-Learn: Tools for Predictive Data Analysis, (2019); Soot: A Framework for Analyzing and Transforming Java Applications, (2019); Antlr (ANother Tool for Language Recognition), (2019); Joern(Open-Source Code Querying Engine for C/C++.), (2019); Ertel W., On the definition of speedup, Proc. Int. Conf. Parallel Archit. Lang. Eur. Athens, pp. 289-300, (1994); Younis A., Malaiya Y., Anderson C., Ray I., To fear or not to fear that is the question: Code characteristics of a vulnerable functionwith an existing exploit, Proc. 6th Acm Conf. Data Appl. Secur. Privacy, pp. 97-104, (2016); Ognawala S., Amato R.N., Pretschner A., Kulkarni P., Automatically assessing vulnerabilities discovered by compositional analysis, Proc. 1st Int. Workshop Mach. Learn. Softw. Eng. Symbiosis, pp. 16-25, (2018); Mikolov T., Kombrink S., Burget L., Cernocky J., Khudanpur S., Extensions of recurrent neural network language model, Proc. Ieee Int. Conf. Acoust., Speech Signal Process. (ICASSP), pp. 5528-5531, (2011); Long M., Zhu H., Wang J., Jordan M.I., Deep transfer learning with joint adaptation networks, Proc. 34th Int. Conf. Mach. Learn, pp. 2208-2217, (2017); Pan S.J., Yang Q., A survey on transfer learning, Ieee Trans. Knowl. Data Eng, 22, 10, pp. 1345-1359, (2010); Torrey L., Shavlik J., Transfer learning, Proceedings of the Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques, pp. 242-264, (2010); Schlichtkrull M., Kipf T.N., Bloem P., Berg Den R.Van., Titov I., Welling M., Modeling relational data with graph convolutional networks, Proc. Eur. Semantic Web Conf. Crete, pp. 593-607, (2018); Maaten Der L.Van., Hinton G., Visualizing data using t-sne, J. Mach. Learn. Res, 9, pp. 2579-2605, (2008); Hendrycks D., Gimpel K., Early Methods for Detecting Adversarial Images, (2016); Kokalj-Filipovic S., Miller R., Vanhoy G., Adversarial examples in rf deep learning: Detection and physical robustness, Proc. Ieee Global Conf. Signal Inf. Process. (GlobalSIP), pp. 1-5, (2019); Meng D., Chen H., Magnet: A two-pronged defense against adversarial examples, Proc. Acm Sigsac Conf. Comput. Commun. Secur, pp. 135-147, (2017); Loukas A., What Graph Neural Networks Cannot Learn: Depth Vs Width, (2019); Liu C., Et al., Progressive neural architecture search, Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 19-34, (2018); Ribeiro M.T., Singh S., Guestrin C., Why should i trust you?': Explaining the predictions of any classifier, Proc. 22nd Acm Sigkdd Int. Conf. Knowl. Discovery Data Mining, pp. 1135-1144, (2016); Sato R., A Survey on the Expressive Power of Graph Neural Networks, (2020); Findbugs, (2019); Cadar C., Sen K., Symbolic execution for software testing: Three decades later, Commun, Acm, 56, 2, pp. 82-90, (2013); Ramos D.A., Engler D., Under-constrained symbolic execution: Correctness checking for real code, Proc. 24th Usenix Secur. Symp. (USENIX Secur.), pp. 49-64, (2015); Wang K., Su Z., Learning blended, precise semantic program embeddings, Proc. Pldi, pp. 121-134, (2020); Li Y., Wang S., Nguyen T.N., Van Nguyen S., Improving bug detection via context-based code representation learning and attentionbased neural networks, Acm Program. Lang, 3, pp. 1-30, (2019); Wang Z., O'Boyle M., Machine learning in compiler optimization, Proc. Ieee, 106, 11, pp. 1879-1901, (2018); Godefroid P., Peleg H., Singh R., Learn&fuzz: Machine learning for input fuzzing, Proc. 32nd IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 50-59, (2017); Chen Y., Et al., Ptrix: Efficient hardware-assisted fuzzing for cots binary, Proc. Acm Asia Conf. Comput. Commun. Secur, pp. 633-645, (2019); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proc. 31st IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 87-98, (2016); Unruh T., Shastry B., Skoruppa M., Maggi F., Rieck K., Seifert J.-P., Yamaguchi F., Leveraging flawed tutorials for seeding large-scale web vulnerability discovery, Proc. 11th Usenix Workshop Offensive Technol. (WOOT), (2017); Heo K., Oh H., Yi K., Machine-learning-guided selectively unsound static analysis, Proc. IEEE/ACM 39th Int. Conf. Softw. Eng. (ICSE), pp. 519-529, (2017); Gorski S.A., Enck W., Arf: Identifying re-delegation vulnerabilities in android system services, Proc. 12th Conf. Secur. Privacy Wireless Mobile Netw, pp. 151-161, (2019); Huang Z., Lie D., Tan G., Jaeger T., Using safety properties to generate vulnerability patches, Proc. Ieee Symp. Secur. Privacy (SP), pp. 539-554, (2019); Lam A.N., Nguyen A.T., Nguyen H.A., Nguyen T.N., Combining deep learning with information retrieval to localize buggy files for bug reports (n), Proc. 30th IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 476-481, (2015); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, Proc. IEEE/ACM 38th Int. Conf. Softw. Eng. (ICSE), pp. 297-308, (2016); Shu X., Yao D., Ramakrishnan N., Jaeger T., Long-span program behavior modeling and attack detection, Acm Trans. Privacy Secur, 20, 4, pp. 1-28, (2017)",,,,,,English,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85098786569,113
Liu S.; Lin G.; Han Q.-L.; Wen S.; Zhang J.; Xiang Y.,"Liu, Shigang (56195519800); Lin, Guanjun (57195557433); Han, Qing-Long (7202485252); Wen, Sheng (37108669800); Zhang, Jun (57198771239); Xiang, Yang (57114147900)",56195519800; 57195557433; 7202485252; 37108669800; 57198771239; 57114147900,DeepBalance: Deep-Learning and Fuzzy Oversampling for Vulnerability Detection,2020,IEEE Transactions on Fuzzy Systems,28,7,8930093,1329,1343,14,83,10.1109/TFUZZ.2019.2958558,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087818690&doi=10.1109%2fTFUZZ.2019.2958558&partnerID=40&md5=1d6e91446ab3e47e3b789368129fd877,"Software vulnerability has long been an important but critical research issue in cybersecurity. Recently, the machine learning (ML)-based approach has attracted increasing interest in the research of software vulnerability detection. However, the detection performance of existing ML-based methods require further improvement. There are two challenges: one is code representation for ML and the other is class imbalance between vulnerable code and nonvulnerable code. To overcome these challenges, this article develops a DeepBalance system, which combines the new ideas of deep code representation learning and fuzzy-based class rebalancing. We design a deep neural network with bidirectional long short-term memory to learn invariant and discriminative code representations from labeled vulnerable and nonvulnerable code. Then, a new fuzzy oversampling method is employed to rebalance the training data by generating synthetic samples for the class of vulnerable code. To evaluate the performance of the new system, we carry out a series of experiments in a real-world ground-truth dataset that consists of the code from the projects of LibTIFF, LibPNG, and FFmpeg. The results show that the proposed new system can significantly improve the vulnerability detection performance. For example, the improvement is 15% in terms of F-measure. © 1993-2012 IEEE.","Chen X., Et al., Android hiv: A study of repackaging malware for evading machine-learning detection, Ieee Trans. Inf. Forensics Secur., 15, 2020, pp. 987-1001; Zhang J., Xiang Y., Wang Y., Zhou W., Xiang Y., Guan Y., Network traffic classification using correlation information, Ieee Trans. Parallel Distrib. Syst., 24, 1, pp. 104-117, (2013); Sun N., Zhang J., Rimba P., Gao S., Zhang L.Y., Xiang Y., Data-driven cybersecurity incident prediction: A survey, Ieee Commun. Surveys Tuts., 21, 2, pp. 1744-1772, (2019); Perl H., Et al., Vccfinder: Finding potential vulnerabilities in open-source projects to assist code audits, Proc. 22nd Acm Sigsac Conf. Comput. Commun. Secur., pp. 426-437, (2015); Zhang S., Ou X., Caragea D., Predicting cyber risks through National Vulnerability Database, Inf. Secur. J., Global Perspective, 24, 4-6, pp. 194-206, (2015); Alves H., Fonseca B., Antunes N., Experimenting machine learning techniques to predict vulnerabilities, Proc. Ieee 7th Latin-Amer. Symp. Dependable Comput., pp. 151-156, (2016); Younan Y., 25 years of vulnerabilities: 1988-2012, Sourcefire Vulnerability Research Team, (2013); Coulter R., Han Q.-L., Pan L., Zhang J., Xiang Y., Data-driven cyber security in perspective-intelligent traffic analysis, Ieee Trans. Cybern; Soska K., Christin N., Automatically detecting vulnerable websites before they turn malicious, Proc. Usenix Secur. Symp., pp. 625-640, (2014); Younis A., Malaiya Y., Anderson C., Ray I., To fear or not to fear that is the question: Code characteristics of a vulnerable functionwith an existing exploit, Proc. 6th Acm Conf. Data Appl. Secur. Privacy, pp. 97-104, (2016); Huda S., Et al., An ensemble oversampling model for class imbalance problem in software defect prediction, Ieee Access, 6, pp. 24184-24195, (2018); Liu L., De Vel O., Han Q.-L., Zhang J., Xiang Y., Detecting and preventing cyber insider threats: A survey, Ieee Commun. Surveys Tuts., 20, 2, pp. 1397-1417, (2018); Sabottke C., Suciu O., Dumitras T., Vulnerability disclosure in the age of social media: Exploiting Twitter for predicting real-world exploits, Proc. Usenix Secur. Symp., pp. 1041-1056, (2015); Morrison P., Herzig K., Murphy B., Williams L., Challenges with applying vulnerability prediction models, Proc. Symp. Bootcamp Sci. Secur., (2015); Ghaffarian S.M., Shahriari H.R., Software vulnerability analysis and discovery using machine-learning and data-mining techniques: A survey, Acm Comput. Surveys, 50, 4, (2017); Liu S., Zhang J., Xiang Y., Zhou W., Fuzzy-based information decomposition for incomplete and imbalanced data learning, Ieee Trans. Fuzzy Syst., 25, 6, pp. 1476-1490, (2017); Wu T., Wen S., Xiang Y., Zhou W., Twitter spam detection: Survey of new approaches and comparative study, Comput. Secur., 76, pp. 265-284, (2018); Liu S., Dibaei M., Tai Y., Chen C., Zhang J., Xiang Y., Cyber vulnerability intelligence for IoT binary, Ieee Trans. Ind. Informat; Lin G., Et al., Software vulnerability discovery via learning multi-domain knowledge bases, Ieee Trans. Dependable Secure Comput; Shar L.K., Tan H.B.K., Predicting SQL injection and cross site scripting vulnerabilities through mining input sanitization patterns, Inf. Softw. Technol., 55, 10, pp. 1767-1780, (2013); Yamaguchi F., Maier A., Gascon H., Rieck K., Automatic inference of search patterns for taint-style vulnerabilities, Proc. Ieee Symp. Secur. Privacy, pp. 797-812, (2015); Eschweiler S., Yakdan K., Gerhards-Padilla E., Discovre: Efficient cross-architecture identification of bugs in binary code, Proc. Netw. Distrib. Syst. Secur. Symp., (2016); Grieco G., Grinblat G.L., Uzal L., Rawat S., Feist J., Mounier L., Toward large-scale vulnerability discovery using machine learning, Proc. 6th Acm Conf. Data Appl. Secur. Privacy, pp. 85-96, (2016); Chowdhury I., Zulkernine M., Using complexity, coupling, and cohesion metrics as early indicators of vulnerabilities, J. Syst. Archit., 57, 3, pp. 294-313, (2011); Shin Y., Williams L., Can traditional fault prediction models be used for vulnerability prediction?, Empirical Softw. Eng., 18, 1, pp. 25-59, (2013); Yamaguchi F., Lindner F., Rieck K., Vulnerability extrapolation: Assisted discovery of vulnerabilities using machine learning, Proc. 5th Usenix Conf. Offensive Technol., (2011); Poon W.N., Bennin K.E., Huang J., Phannachitta P., Keung J.W., Cross-project defect prediction using a credibility theory based naive Bayes classifier, Proc. Ieee Int. Conf. Softw. Quality, Rel. Secur., pp. 434-441, (2017); Nam J., Pan S.J., Kim S., Transfer defect learning, Proc. Int. Conf. Softw. Eng., pp. 382-391, (2013); Pan S.J., Tsang I.W., Kwok J.T., Yang Q., Domain adaptation via transfer component analysis, Ieee Trans. Neural Netw., 22, 2, pp. 199-210, (2011); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, Proc. 38th Int. Conf. Softw. Eng., pp. 297-308, (2016); Neuhaus S., Zimmermann T., Holler C., Zeller A., Predicting vulnerable software components, Proc. 14th Acm Conf. Comput. Commun. Secur., pp. 529-540, (2007); Scandariato R., Walden J., Hovsepyan A., Joosen W., Predicting vulnerable software components via text mining, Ieee Trans. Softw. Eng., 40, 10, pp. 993-1006, (2014); Dam H.K., Tran T., Pham T., Ng S.W., Grundy J., Ghose A., Automatic Feature Learning for Vulnerability Prediction, (2017); Pinzger M., Nagappan N., Murphy B., Can developer-module networks predict failures?, Proc. 16th Acm Sigsoft Int. Symp. Found. Softw. Eng., pp. 2-12, (2008); Meneely A., Williams L., Secure open source collaboration: An empirical study of Linus' law, Proc. 16th Acm Conf. Comput. Commun. Secur., pp. 453-462, (2009); Liu S., Wang Y., Zhang J., Chen C., Xiang Y., Addressing the class imbalance problem in Twitter spam detection using ensemble learning, Comput. Secur., 69, pp. 35-49, (2017); Chen S., He H., Garcia E.A., Ramoboost: Ranked minority oversam-pling in boosting, Ieee Trans. Neural Netw., 21, 10, pp. 1624-1642, (2010); Bekkar M., Alitouche T.A., Imbalanced data learning approaches review, Int. J. Data Mining Knowl. Manage. Process, 3, 4, (2013); He H., Bai Y., Garcia E.A., Li S., ADASYN: Adaptive synthetic sampling approach for imbalanced learning, Proc Ieee Int. Joint Conf. Neural Netw., pp. 1322-1328, (2008); Jo T., Japkowicz N., Class imbalances versus small disjuncts, Acm Sigkdd Explor. Newslett., 6, 1, pp. 40-49, (2004); Barua S., Islam M.M., Yao X., Murase K., MWMOTE-majority weighted minority oversampling technique for imbalanced data set learning, Ieee Trans. Knowl. Data Eng., 26, 2, pp. 405-425, (2014); Chawla N.V., Bowyer K.W., Hall L.O., Kegelmeyer W.P., Smote: Synthetic minority over-sampling technique, J. Artif. Intell. Res., 16, pp. 321-357, (2002); Hao M., Wang Y., Bryant S.H., An efficient algorithm coupled with synthetic minority over-sampling technique to classify imbalanced pubchem bioassay data, Anal. Chim. Acta, 806, pp. 117-127, (2014); Zhao H., Chen X., Nguyen T., Huang J.Z., Williams G., Chen H., Stratified over-sampling bagging method for random forests on imbal-anced data, Proc. Pacific-Asia Workshop Intell. Secur. Inform., pp. 63-72, (2016); Prati R.C., Batista G.E., Silva D.F., Class imbalance revisited: A new experimental setup to assess the performance of treatment methods, Knowl. Inf. Syst., 45, 1, pp. 247-270, (2015); Ban X., Liu S., Chen C., Chua C., A performance evaluation of deep-learnt features for software vulnerability detection, Concurrency Comput., Practice Experience, 31, (2019); Lin G., Zhang J., Luo W., Pan L., Xiang Y., Poster: Vulnerability discovery with function representation learning from unlabeled projects, Proc. Acm Sigsac Conf. Comput. Commun. Secur., pp. 2539-2541, (2017); Li Z., Et al., VulDeePecker: A deep learning-based system for vulnerability detection, Proc. 25th Annu. Network Distrib. Syst. Secur. Symp. (NDSS), (2018); Yamaguchi F., Lottmann M., Rieck K., Generalized vulnerability extrapolation using abstract syntax trees, Proc. 28th Annu. Comput. Secur. Appl. Conf., pp. 359-368, (2012); Moonen L., Generating robust parsers using island grammars, Proc. Ieee 8th Working Conf. Reverse Eng., pp. 13-22, (2001); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, Proc. 1st Int. Conf. Learn. Representations, Workshop Track, (2013); Casella G., Berger R.L., Statistical Inference, 2, (2002); Lin G., Et al., Cross-project transfer representation learning for vulnerable function discovery, Ieee Trans. Ind. Informat., 14, 7, pp. 3289-3297, (2018); Zhang J., Chen X., Xiang Y., Zhou W., Wu J., Robust network traffic classification, IEEE/ACM Trans. Netw., 23, 4, pp. 1257-1270, (2015); Soman S., Et al., EigenSample: A non-iterative technique for adding samples to small datasets, Appl. Soft Comput., 70, pp. 1064-1077, (2018); Khodayar M., Kaynak O., Khodayar M.E., Rough deep neural architecture for short-term wind speed forecasting, Ieee Trans. Ind. Informat., 13, 6, pp. 2770-2779, (2017)",,,,,,English,Article,Final,,Scopus,2-s2.0-85087818690,114
Lin G.; Zhang J.; Luo W.; Pan L.; Xiang Y.,"Lin, Guanjun (57195557433); Zhang, Jun (55951810400); Luo, Wei (57218392471); Pan, Lei (55800992300); Xiang, Yang (57114147900)",57195557433; 55951810400; 57218392471; 55800992300; 57114147900,Poster: Vulnerability discovery with function representation learning from unlabeled projects,2017,Proceedings of the ACM Conference on Computer and Communications Security,,,,2539,2541,2,111,10.1145/3133956.3138840,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041433336&doi=10.1145%2f3133956.3138840&partnerID=40&md5=8b6e92bb5d8442d175adc77d8de43b50,"In cybersecurity, vulnerability discovery in source code is a fundamental problem. To automate vulnerability discovery, Machine learning (ML) based techniques has attracted tremendous attention. However, existing ML-based techniques focus on the component or file level detection, and thus considerable human effort is still required to pinpoint the vulnerable code fragments. Using source code files also limit the generalisability of the ML models across projects. To address such challenges, this paper targets at the function-level vulnerability discovery in the cross-project scenario. A function representation learning method is proposed to obtain the high-level and generalizable function representations from the abstract syntax tree (AST). First, the serialized ASTs are used to learn project independence features. Then, a customized bi-directional LSTM neural network is devised to learn the sequential AST representations from the large number of raw features. The new function-level representation demonstrated promising performance gain, using a unique dataset where we manually labeled 6000+ functions from three open-source projects. The results confirm that the huge potential of the new AST-based function representation learning. © 2017 author(s).","Chowdhury I., Zulkernine M., Using complexity, coupling, cohesion metrics as early indicators of vulnerabilities, Journal of Systems Architecture, 57, 3, pp. 294-313, (2011); Giger E., D'Ambros M., Pinzger M., Gall H.C., Method-level bug prediction, Proceedings of the ACM-IEEE International Symposium On Empirical Software Engineering and Measurement. ACM, pp. 171-180, (2012); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Moonen L., Generating robust parsers using island grammars, Reverse Engineering 2001. Proceedings. Eighth Working Conference On IEEE, pp. 13-22, (2001); Scandariato R., Walden J., Hovsepyan A., Joosen W., Predicting vulnerable software components via text mining, IEEE Transactions On Software Engineering, 40, 10, pp. 993-1006, (2014); Shin Y., Meneely A., Williams L., Osborne J.A., Evaluating complexity, code churn, developer activity metrics as indicators of software vulnerabilities, IEEE Transactions On Software Engineering, 37, 6, pp. 772-787, (2011); Yamaguchi F., Lindner F., Rieck K., Vulnerability extrapolation: Assisted discovery of vulnerabilities using machine learning, Proceedings of the 5th USENIX Conference On Offensive Technologies, (2011); Yamaguchi F., Lottmann M., Rieck K., Generalized vulnerability extrapolation using abstract syntax trees, Proceedings of the 28th Annual Computer Security Applications Conference ACM, pp. 359-368, (2012)",ACM SIGSAC,"24th ACM SIGSAC Conference on Computer and Communications Security, CCS 2017",30 October 2017 through 3 November 2017,Dallas,131467,English,Conference paper,Final,,Scopus,2-s2.0-85041433336,116
Zhang F.; Chen B.; Zhao Y.; Peng X.,"Zhang, Fengyi (57205029279); Chen, Bihuan (35224542900); Zhao, Yufei (35104118700); Peng, Xin (53865467700)",57205029279; 35224542900; 35104118700; 53865467700,Slice-Based Code Change Representation Learning,2023,"Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",,,,319,330,11,2,10.1109/SANER56733.2023.00038,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160563876&doi=10.1109%2fSANER56733.2023.00038&partnerID=40&md5=e44fc443ec0fa0c3f87ee88b0feecbe4,"Code changes are at the very core of software development and maintenance. Deep learning techniques have been used to build a model from a massive number of code changes to solve software engineering tasks, e.g., commit message generation and bug-fix commit identification. However, existing code change representation learning approaches represent code change as lexical tokens or syntactical AST (abstract syntax tree) paths, limiting the capability to learn semantics of code changes. Besides, they mostly do not consider noisy or tangled code change, hurting the accuracy of solved tasks. To address the above problems, we first propose a slice-based code change representation approach which considers data and control dependencies between changed code and unchanged code. Then, we propose a pre-trained sparse Transformer model, named CCS2VEC, to learn code change representations with three pre-training tasks. Our experiments by fine-tuning our pre-trained model on three downstream tasks have demonstrated the improvement of CCS2VEC over the state-of-the-art CC2VEC. © 2023 IEEE.","Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Computing Surveys, 51, 4, (2018); Bielik P., Raychev V., Vechev M., Programming with big code: Lessons, techniques and applications, SNAPL, pp. 1-10, (2015); Brody S., Alon U., Yahav E., A structural model for contextual code changes, Proceedings of the ACM on Programming Languages, 4, pp. 1-28, (2020); Cabrera Lozoya R., Baumann A., Sabetta A., Bezzi M., Commit2vec: Learning distributed representations of code changes, SN Computer Science, 2, 3, pp. 1-16, (2021); Chakraborty S., Ray B., On multi-modal learning of editing source code, ASE, pp. 443-455, (2021); Chen Y., Santosa A.E., Yi A.M., Sharma A., Sharma A., Lo D., A machine learning approach for vulnerability curation, MSR, pp. 32-42, (2020); Chen Z., Kommrusch S., Tufano M., Pouchet L.-N., Poshyvanyk D., Monperrus M., Sequencer: Sequence-to-sequence learning for endto-end program repair, IEEE Transactions on Software Engineering, 47, 9, pp. 1943-1959, (2021); Child R., Gray S., Radford A., Sutskever I., Generating long sequences with sparse transformers, (2019); Devlin J., Chang M.-W., Lee K., Toutanova K., BERT: Pre-training of deep bidirectional transformers for language understanding, NAACL, pp. 4171-4186, (2019); Ding Y., Ray B., Devanbu P., Hellendoorn V.J., Patching as translation: the data and the metaphor, ASE, pp. 275-286, (2020); Dong J., Lou Y., Zhu Q., Sun Z., Li Z., Zhang W., Hao D., Fira: Finegrained graph-based code change representation for automated commit message generation, ICSE, (2022); Dyer R., Nguyen H.A., Rajan H., Nguyen T.N., Boa: A language and infrastructure for analyzing ultra-large-scale software repositories, ICSE, pp. 422-431, (2013); Ernst M.D., Natural language is a programming language: Applying natural language processing to software development, SNAPL, pp. 1-14, (2017); Ghaffarian S.M., Shahriari H.R., Neural software vulnerability analysis using rich intermediate graph representations of programs, Information Sciences, 553, pp. 189-207, (2021); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Deng S.K., Clement C.B., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., Graphcodebert: Pretraining code representations with data flow, ICLR, (2021); Herzig K., Zeller A., The impact of tangled code changes, MSR, pp. 121-130, (2013); Hoang T., Dam H.K., Kamei Y., Lo D., Ubayashi N., Deepjit: an end-to-end deep learning framework for just-in-time defect prediction, MSR, pp. 34-45, (2019); Hoang T., Kang H.J., Lo D., Lawall J., Cc2vec: Distributed representations of code changes, ICSE, pp. 518-529, (2020); Hoang T., Lawall J., Tian Y., Oentaryo R.J., Lo D., Patchnet: Hierarchical deep learning-based stable patch identification for the linux kernel, IEEE Transactions on Software Engineering, 47, 11, pp. 2471-2486, (2021); Ilse M., Tomczak J., Welling M., Attention-based deep multiple instance learning, ICML, pp. 2127-2136, (2018); Jiang N., Lutellier T., Tan L., Cure: Code-aware neural machine translation for automatic program repair, ICSE, pp. 1161-1173, (2021); Jiang S., Armaly A., McMillan C., Automatically generating commit messages from diffs using neural machine translation, ASE, pp. 135-146, (2017); Kawrykow D., Robillard M.P., Non-essential changes in version histories, ICSE, pp. 351-360, (2011); Lewis M., Liu Y., Goyal N., Ghazvininejad M., Mohamed A., Levy O., Stoyanov V., Zettlemoyer L., BART: Denoising sequence-tosequence pre-training for natural language generation, translation, and comprehension, ACL, pp. 7871-7880, (2020); Li Y., Wang S., Nguyen T.N., Dlfix: Context-based code transformation learning for automated program repair, ICSE, pp. 602-614, (2020); Lin B., Wang S., Wen M., Mao X., Context-aware code change embedding for better patch correctness assessment, ACM Transactions on Software Engineering and Methodology, 31, 3, pp. 1-29, (2022); Lin T., Wang Y., Liu X., Qiu X., A survey of transformers, (2021); Liu Q., Liu Z., Zhu H., Fan H., Du B., Qian Y., Generating commit messages from diffs using pointer-generator network, MSR, pp. 299-309, (2019); Liu S., Gao C., Chen S., Yiu N.L., Liu Y., Atom: Commit message generation based on abstract syntax tree and hybrid ranking, IEEE Transactions on Software Engineering, 48, 5, pp. 1800-1817, (2022); Liu Z., Xia X., Hassan A.E., Lo D., Xing Z., Wang X., Neuralmachine-translation-based commit message generation: how far are we?, ASE, pp. 373-384, (2018); Loyola P., Marrese-Taylor E., Matsuo Y., A neural architecture for generating natural language descriptions from source code changes, ACL, pp. 287-292, (2017); Lutellier T., Pham H.V., Pang L., Li Y., Wei M., Tan L., Coconut: combining context-aware neural translation models using ensemble for program repair, ISSTA, pp. 101-114, (2020); Nguyen-Truong G., Kang H.J., Lo D., Sharma A., Santosa A.E., Sharma A., Ang M.Y., Hermes: Using commit-issue linking to detect vulnerability-fixing commits, SANER, pp. 51-62, (2022); Nie L.Y., Gao C., Zhong Z., Lam W., Liu Y., Xu Z., Coregen: Contextualized code representation learning for commit message generation, Neurocomputing, 459, pp. 97-107, (2021); Pornprasit C., Tantithamthavorn C., Jiarpakdee J., Fu M., Thongtanunam P., Pyexplainer: Explaining the predictions of just-in-time defect models, ASE, pp. 407-418, (2021); Pornprasit C., Tantithamthavorn C.K., Jitline: A simpler, better, faster, finer-grained just-in-time defect prediction, MSR, pp. 369-379, (2021); Qiu F., Gao Z., Xia X., Lo D., Grundy J., Wang X., Deep just-intime defect localization, IEEE Transactions on Software Engineering, (2021); Qureshi S.A., Mehta S., Bhagwan R., Kumar R., Assessing the effectiveness of syntactic structure to learn code edit representations, (2021); Ray B., Hellendoorn V., Godhane S., Tu Z., Bacchelli A., Devanbu P., On the naturalness of buggy code, ICSE, pp. 428-439, (2016); Ribeiro M.T., Singh S., Guestrin C., why should i trust you? explaining the predictions of any classifier, KDD, pp. 1135-1144, (2016); Sabetta A., Bezzi M., A practical approach to the automatic classification of security-relevant commits, ICSME, pp. 579-582, (2018); See A., Liu P.J., Manning C.D., Get to the point: Summarization with pointer-generator networks, ACL, pp. 1073-1083, (2017); Shaw P., Uszkoreit J., Vaswani A., Self-attention with relative position representations, NAACL, pp. 464-468, (2018); Tao Y., Dang Y., Xie T., Zhang D., Kim S., How do software engineers understand code changes? an exploratory study in industry, FSE, pp. 1-11, (2012); Tian H., Li Y., Pian W., Kabore A.K., Liu K., Habib A., Klein J., Bissyande T.F., Predicting patch correctness based on the similarity of failing test cases, ACM Transactions on Software Engineering and Methodology, 31, 4, pp. 1-30, (2022); Tian H., Liu K., Kabore A.K., Koyuncu A., Li L., Klein J., Bissyande T.F., Evaluating representation learning of code changes for predicting patch correctness in program repair, ASE, pp. 981-992, (2020); Tian Y., Lawall J., Lo D., Identifying linux bug fixing patches, ICSE, pp. 386-396, (2012); Tufano M., Pantiuchina J., Watson C., Bavota G., Poshyvanyk D., On learning meaningful code changes via neural machine translation, ICSE, pp. 25-36, (2019); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., An empirical investigation into learning bug-fixing patches in the wild via neural machine translation, ASE, pp. 832-837, (2018); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser S., Polosukhin I., Attention is all you need, NIPS, pp. 5998-6008, (2017); Wang H., Xia X., Lo D., He Q., Wang X., Grundy J., Context-aware retrieval-based deep commit message generation, ACM Transactions on Software Engineering and Methodology, 30, 4, pp. 1-30, (2021); Wu B., Liu S., Feng R., Xie X., Siow J., Lin S.-W., Enhancing security patch identification by capturing structures in commits, IEEE Transactions on Dependable and Secure Computing, (2022); Xu S., Yao Y., Xu F., Gu T., Tong H., Lu J., Commit message generation for source code changes, IJCAI, pp. 3975-3981, (2019); Xu Z., Chen B., Chandramohan M., Liu Y., Song F., Spain: security patch analysis for binaries towards understanding the pain and pills, ICSE, pp. 462-472, (2017); Yahav E., Programming with ""big code, APLAS, pp. 3-8, (2015); Yan M., Xia X., Fan Y., Hassan A.E., Lo D., Li S., Just-in-time defect identification and localization: A two-phase framework, IEEE Transactions on Software Engineering, 48, 1, pp. 82-101, (2022); Yang X., Lo D., Xia X., Zhang Y., Sun J., Deep learning for just-in-time defect prediction, QRS, pp. 17-26, (2015); Ye Z., Guo Q., Gan Q., Qiu X., Zhang Z., Bp-transformer: Modelling long-range context via binary partitioning, (2019); Zafar S., Malik M.Z., Walia G.S., Towards standardizing and improving classification of bug-fix commits, ESEM, pp. 1-6, (2019); Zeng Z., Zhang Y., Zhang H., Zhang L., Deep just-in-time defect prediction: how far are we?, ISSTA, pp. 427-438, (2021); Zhou J., Pacheco M., Wan Z., Xia X., Lo D., Wang Y., Hassan A.E., Finding a needle in a haystack: Automated mining of silent vulnerability fixes, ASE, pp. 705-716, (2021); Zhou X., Han D., Lo D., Simple or complex? together for a more accurate just-in-time defect predictor, ICPC, pp. 229-240, (2022); Zhou Y., Sharma A., Automated identification of security issues from commit messages and bug reports, ESEC/FSE, pp. 914-919, (2017); Zhou Y., Siow J.K., Wang C., Liu S., Liu Y., Spi: Automated identification of security patches via commits, ACM Transactions on Software Engineering and Methodology, 31, 1, pp. 1-27, (2021)",IEEE; IEEE Computer Society; Macau University of Science and Technology (MUST),"30th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",21 March 2023 through 24 March 2023,Macao,188717,English,Conference paper,Final,,Scopus,2-s2.0-85160563876,118
Zhang J.; Maddila C.; Bairi R.; Bird C.; Raizada U.; Agrawal A.; Jhawar Y.; Herzig K.; Van Deursen A.,"Zhang, Jiyang (57222761774); Maddila, Chandra (57200337950); Bairi, Ram (56024417000); Bird, Christian (17433640400); Raizada, Ujjwal (57453727700); Agrawal, Apoorva (57313793700); Jhawar, Yamini (58101834600); Herzig, Kim (35078523000); Van Deursen, Arie (7003969355)",57222761774; 57200337950; 56024417000; 17433640400; 57453727700; 57313793700; 58101834600; 35078523000; 7003969355,Using Large-scale Heterogeneous Graph Representation Learning for Code Review Recommendations at Microsoft,2023,Proceedings - International Conference on Software Engineering,,,,162,172,10,2,10.1109/ICSE-SEIP58684.2023.00020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167921721&doi=10.1109%2fICSE-SEIP58684.2023.00020&partnerID=40&md5=a0274a779711b1042772bf9e7a85e888,"Code review is an integral part of any mature software development process, and identifying the best reviewer for a code change is a well-accepted problem within the software engineering community. Selecting a reviewer who lacks expertise and understanding can slow development or result in more defects. To date, most reviewer recommendation systems rely primarily on historical file change and review information; those who changed or reviewed a file in the past are the best positioned to review in the future.We posit that while these approaches are able to identify and suggest qualified reviewers, they may be blind to reviewers who have the needed expertise and have simply never interacted with the changed files before. Fortunately, at Microsoft, we have a wealth of work artifacts across many repositories that can yield valuable information about our developers. To address the aforementioned problem, we present Coral, a novel approach to reviewer recommendation that leverages a socio-technical graph built from the rich set of entities (developers, repositories, files, pull requests (PRs), work items, etc.) and their relationships in modern source code management systems. We employ a graph convolutional neural network on this graph and train it on two and a half years of history on 332 repositories within Microsoft.We show that Coral is able to model the manual history of reviewer selection remarkably well. Further, based on an extensive user study, we demonstrate that this approach identifies relevant and qualified reviewers who traditional reviewer recommenders miss, and that these developers desire to be included in the review process. Finally, we find that ""classical""reviewer recommendation systems perform better on smaller (in terms of developers) software projects while Coral excels on larger projects, suggesting that there is ""no one model to rule them all."" © 2023 IEEE.","Gousios G., Pinzger M., Deursen A.V., An exploratory study of the pull-based software development model, International Conference on Software Engineering, pp. 345-355, (2014); Rigby P., Cleary B., Painchaud F., Storey M.-A., German D., Contemporary peer review in action: Lessons from open source development, IEEE software, 29, pp. 56-61, (2012); Rigby P.C., Bird C., Convergent contemporary software peer review practices, International Symposium on the Foundations of Software Engineering, pp. 202-212, (2013); Bacchelli A., Bird C., Expectations, outcomes, and challenges of modern code review, International Conference on Software Engineering, pp. 712-721, (2013); Rigby P.C., Storey M.-A., Understanding broadcast based peer review on open source software projects, International Conference on Software Engineering, pp. 541-550, (2011); Bosu A., Greiler M., Bird C., Characteristics of useful code reviews: An empirical study at microsoft, International Working Conference on Mining Software Repositories, pp. 146-156, (2015); Lipcak J., Rossi B., A large-scale study on source code reviewer recommendation, Euromicro Conference on Software Engineering and Advanced Applications (SEAA), pp. 378-387, (2018); Ouni A., Kula R.G., Inoue K., Search-based peer reviewers recommendation in modern code review, 2016 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 367-377, (2016); Jiang J., Yang Y., He J., Blanc X., Zhang L., Who should comment on this pull request? analyzing attributes for more accurate commenter recommendation in pull-based development, Information and Software Technology, 84, pp. 48-62, (2017); Yu Y., Wang H., Yin G., Ling C.X., Reviewer recommender of pull-requests in github, IEEE International Conference on Software Maintenance and Evolution, pp. 609-612, (2014); Yu Y., Wang H., Yin G., Wang T., Reviewer recommendation for pull-requests in github: What can we learn from code review and bug assignment?, Information and Software Technology, 74, pp. 204-218, (2016); Lee J.B., Ihara A., Monden A., Matsumoto K.-I., Patch reviewer recommendation in oss projects, Asia-Pacific Software Engineering Conference (APSEC), 2, pp. 1-6, (2013); Sulun E., Tuzun E., Dogrusoz U., Reviewer recommendation using software artifact traceability graphs, International Conference on Predictive Models and Data Analytics in Software Engineering, pp. 66-75, (2019); Thongtanunam P., Tantithamthavorn C., Kula R.G., Yoshida N., Iida H., Matsumoto K.-I., Who should review my code? a file locationbased code-reviewer recommendation approach for modern code review, International Conference on Software Analysis, Evolution, and Reengineering (SANER), pp. 141-150, (2015); Asthana S., Kumar R., Bhagwan R., Bird C., Bansal C., Maddila C., Mehta S., Ashok B., Whodo: Automating reviewer suggestions at scale, Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 937-945, (2019); Kononenko O., Baysal O., Guerrouj L., Cao Y., Godfrey M.W., Investigating code review quality: Do people and participation matter?, IEEE international conference on software maintenance and evolution (ICSME), pp. 111-120, (2015); Bosu A., Carver J.C., Impact of peer code review on peer impression formation: A survey, International Symposium on Empirical Software Engineering and Measurement, pp. 133-142, (2013); Wu Z., Pan S., Chen F., Long G., Zhang C., Philip S.Y., A comprehensive survey on graph neural networks, IEEE transactions on neural networks and learning systems, 32, pp. 4-24, (2020); Cetin H.A., Dogan E., Tuzun E., A review of code reviewer recommendation studies: Challenges and future directions, Science of Computer Programming, (2021); Balachandran V., Reducing human effort and improving quality in peer code reviews using automatic static analysis and reviewer recommendation, International Conference on Software Engineering, pp. 931-940, (2013); Zanjani M.B., Kagdi H., Bird C., Automatically recommending peer reviewers in modern code review, IEEE Transactions on Software Engineering, 42, pp. 530-543, (2015); Rahman M.M., Roy C.K., Collins J.A., Correct: code reviewer recommendation in github based on cross-project and technology experience, International Conference on Software Engineering Companion, pp. 222-231, (2016); Dogan E., Tuzun E., Tecimer K.A., Guvenir H.A., Investigating the validity of ground truth in code reviewer recommendation studies, International Symposium on Empirical Software Engineering and Measurement (ESEM), pp. 1-6, (2019); English stop words, (2021); Manning C.D., Schutze H., Foundations of Statistical Natural Language Processing, (1999); Hoff P.D., Raftery A.E., Handcock M.S., Latent space approaches to social network analysis, Journal of the american Statistical association, 97, pp. 1090-1098, (2002); Hamilton W.L., Ying R., Leskovec J., Representation learning on graphs: Methods and applications, IEEE Data Eng. Bull., 40, pp. 52-74, (2017); Chen H., Perozzi B., Al-Rfou R., Skiena S., A tutorial on network embeddings, (2018); Zhou J., Cui G., Hu S., Zhang Z., Yang C., Liu Z., Wang L., Li C., Sun M., Graph neural networks: A review of methods and applications, AI Open, 1, pp. 57-81, (2020); Schlichtkrull M., Kipf T.N., Bloem P., Berg R.V.D., Titov I., Welling M., Modeling relational data with graph convolutional networks, European semantic web conference, pp. 593-607, (2018); Nair V., Hinton G.E., Rectified linear units improve restricted boltzmann machines, International Conference on International Conference on Machine Learning, pp. 807-814, (2010); Manning C.D., Raghavan P., Schutze H., Introduction to Information Retrieval, (2008); Stol K.-J., Fitzgerald B., The abc of software engineering research, ACM Trans. Softw. Eng. Methodol., 27, (2018); Agresti A., Categorical data analysis, 482, (2003); Adair J.G., The hawthorne effect: A reconsideration of the methodological artifact, Journal of applied psychology, 69, (1984); General data protection regulation",,"45th IEEE/ACM International Conference on Software Engineering: Software Engineering in Practice, ICSE-SEIP 2023",14 May 2023 through 20 May 2023,Melbourne,190650,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85167921721,119
Dong J.; Lou Y.; Zhu Q.; Sun Z.; Li Z.; Zhang W.; Hao D.,"Dong, Jinhao (57220546220); Lou, Yiling (57189049171); Zhu, Qihao (57218924576); Sun, Zeyu (57211525326); Li, Zhilin (57783626800); Zhang, Wenjie (57204395928); Hao, Dan (23388889700)",57220546220; 57189049171; 57218924576; 57211525326; 57783626800; 57204395928; 23388889700,FIRA: Fine-Grained Graph-Based Code Change Representation for Automated Commit Message Generation,2022,Proceedings - International Conference on Software Engineering,2022-May,,,970,981,11,28,10.1145/3510003.3510069,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133555793&doi=10.1145%2f3510003.3510069&partnerID=40&md5=0b410951296235c34ca7d23bcda92d56,"Commit messages summarize code changes of each commit in nat-ural language, which help developers understand code changes without digging into detailed implementations and play an essen-tial role in comprehending software evolution. To alleviate human efforts in writing commit messages, researchers have proposed var-ious automated techniques to generate commit messages, including template-based, information retrieval-based, and learning-based techniques. Although promising, previous techniques have limited effectiveness due to their coarse-grained code change representations. This work proposes a novel commit message generation technique, FIRA, which first represents code changes via fine-grained graphs and then learns to generate commit messages automati-cally. Different from previous techniques, FIRA represents the code changes with fine-grained graphs, which explicitly describe the code edit operations between the old version and the new version, and code tokens at different granularities (i.e., sub-tokens and integral tokens). Based on the graph-based representation, FIRA generates commit messages by a generation model, which includes a graph-neural-network-based encoder and a transformer-based decoder. To make both sub-tokens and integral tokens as available ingredients for commit message generation, the decoder is further incorporated with a novel dual copy mechanism. We further per-form an extensive study to evaluate the effectiveness of FIRA. Our quantitative results show that FIRA outperforms state-of-the-art techniques in terms of BLEU, ROUGE-L, and METEOR; and our ablation analysis further shows that major components in our technique both positively contribute to the effectiveness of FIRA. In addition, we further perform a human study to evaluate the quality of generated commit messages from the perspective of developers, and the results consistently show the effectiveness of FIRA over the compared techniques. © 2022 ACM.","Uddin Ahmad W., Chakraborty S., Ray B., Chang K., A Transformer-based Approach for Source Code Summarization, (2020); Lei Ba J., Ryan Kiros J., Hinton G.E., Layer Normalization, (2016); Banerjee S., Lavie A., Meteor: An automatic metric for mt evaluation with improved correlation with human judgments, Proceedings of the Acl Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation And/or Summarization., pp. 65-72, (2005); Buse R.P.L., Weimer W.R., Automatically documenting program changes, Proceedings of the IEEE/ACM International Conference on Automated Software Engineering., pp. 33-42, (2010); Campos E.C., De A Maia M., Discovering common bug-fix patterns: A large-scale observational study, Journal of Software: Evolution and Process, 31, 7, (2019); Fernando Cortes-Coy L., Linares-Vasquez M., Aponte J., Poshyvanyk D., On automatically generating commit messages via summarization of source code changes, 2014 IEEE 14th International Working Conference on Source Code Analysis and Manipulation. IEEE, pp. 275-284, (2014); Defferrard M., Bresson X., Vandergheynst P., Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering, (2016); Dragan N., Collard M.L., Hammad M., Maletic J.I., Using stereotypes to help characterize commits, 2011 27th IEEE International Conference on Software Maintenance (ICSM). IEEE, pp. 520-523, (2011); Dragan N., Collard M.L., Maletic J.I., Reverse engineering method stereotypes, 2006 22nd IEEE International Conference on Software Maintenance. IEEE, pp. 24-34, (2006); Dyer R., Anh Nguyen H., Rajan H., Nguyen T.N., Boa: A language and infrastructure for analyzing ultra-large-scale software repositories, 2013 35th International Conference on Software Engineering (ICSE). IEEE, pp. 422-431, (2013); Falleri J., Morandat F., Blanc X., Martinez M., Monperrus M., Fine-grained and accurate source code differencing, Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering., pp. 313-324, (2014); Gori M., Monfardini G., Scarselli F., A new model for learning in graph domains, Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005., 2, pp. 729-734, (2005); Hamilton W.L., Ying R., Leskovec J., Inductive representation learning on large graphs, Proceedings of the 31st International Conference on Neural Information Processing Systems., pp. 1025-1035, (2017); Hanam Q., De Brito F.M.S., Mesbah A., Discovering bug patterns in Javascript, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering., pp. 144-156, (2016); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition., pp. 770-778, (2016); Hoang T., Jin Kang H., Lo D., Lawall J., Cc2vec: Distributed representations of code changes, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering., pp. 518-529, (2020); Huang Y., Jia N., Zhou H., Chen X., Zheng Z., Tang M., Learning human-written commit messages to document code changes, Journal of Computer Science and Technology, 35, 6, pp. 1258-1277, (2020); Rakibul Islam M., Zibran M.F., How bugs are fixed: Exposing bug-fix patterns with edits and nesting levels, Proceedings of the 35th Annual ACM Symposium on Applied Computing., pp. 1523-1531, (2020); Jiang S., Armaly A., McMillan C., Automatically generating commit messages from diffs using neural machine translation, 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 135-146, (2017); Jiang S., McMillan C., Towards automatic generation of short summaries of commits, 2017 IEEE/ACM 25th International Conference on Program Comprehension (ICPC). IEEE, pp. 320-323, (2017); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, (2014); Kipf T.N., Welling M., Semi-supervised Classification with Graph Convolutional Networks, (2016); Russell V.L., Some practical guidelines for effective sample size determination, The American Statistician, 55, 3, pp. 187-193, (2001); Li S., Niu X., Jia Z., Wang J., He H., Wang T., Logtracker: Learning log revision behaviors proactively from software evolution history, Proceedings of the 26th Conference on Program Comprehension., pp. 178-188, (2018); Lin C., Josef Och F., Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics, Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-04)., pp. 605-612, (2004); Liu K., Kim D., Koyuncu A., Li L., Bissyande T.F., Le Traon Y., A closer look at real-world patches, 2018 IEEE International Conference on Software Maintenance and Evolution (ICSME). IEEE, pp. 275-286, (2018); Liu Q., Liu Z., Zhu H., Fan H., Du B., Qian Y., Generating commit messages from diffs using pointer-generator network, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR). IEEE, pp. 299-309, (2019); Liu S., Gao C., Chen S., Lun Yiu N., Liu Y., Atom: Commit message generation based on abstract syntax tree and hybrid ranking, IEEE Transactions on Software Engineering, (2020); Liu Z., Xia X., Hassan A.E., Lo D., Xing Z., Wang X., Neural-machine-translation-based commit message generation: How far are we?, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering., pp. 373-384, (2018); Lou Y., Zhu Q., Dong J., Li X., Sun Z., Hao D., Zhang L., Zhang L., Boosting coverage-based fault localization via graphbased representation learning, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering., pp. 664-676, (2021); Ni Z., Li B., Sun X., Chen T., Tang B., Shi X., Analyzing bug fix for automatic bug cause classification, Journal of Systems and Software, 163, (2020); Yiu Nie L., Gao C., Zhong Z., Lam W., Liu Y., Xu Z., Coregen: Contextualized code representation learning for commit message generation, Neurocomputing, 459, pp. 97-107, (2021); Papineni K., Roukos S., Ward T., Zhu W., Bleu: A method for automatic evaluation of machine translation, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics., pp. 311-318, (2002); Scarselli F., Gori M., Chung Tsoi A., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Transactions on Neural Networks, 20, 1, pp. 61-80, (2008); Shen J., Sun X., Li B., Yang H., Hu J., On automatic summarization of what and why information in source code changes, 2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC), 1, pp. 103-112, (2016); Srivastava N., Hinton G., Krizhevsky A., Sutskever I., Salakhutdinov R., Dropout: A simple way to prevent neural networks from overfitting, The Journal of Machine Learning Research, 15, 1, pp. 1929-1958, (2014); Sun Z., Zhu Q., Xiong Y., Sun Y., Mou L., Zhang L., Treegen: A tree-based transformer architecture for code generation, Proceedings of the AAAI Conference on Artificial Intelligence, 34, pp. 8984-8991, (2020); Tao W., Wang Y., Shi E., Du L., Zhang H., Zhang D., Zhang W., On the Evaluation of Commit Message Generation Models: An Experimental Study, (2021); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention Is All You Need, (2017); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph Attention Networks, (2017); Wang H., Xia X., Lo D., He Q., Wang X., Grundy J., Context-aware retrieval-based deep commit message generation, ACM Transactions on Software Engineering and Methodology (TOSEM), 30, 4, pp. 1-30, (2021); Wilcoxon F., Individual comparisons by ranking methods, Breakthroughs in Statistics., pp. 196-202, (1992); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu Philip S., A comprehensive survey on graph neural networks, IEEE Transactions on Neural Networks and Learning Systems, (2020); Xu S., Yao Y., Xu F., Gu T., Tong H., Lu J., Commit message generation for source code changes, IJCAI, (2019); Yin P., Neubig G., Allamanis M., Brockschmidt M., Gaunt A.L., Learning to Represent Edits, (2018); Zhu Q., Sun Z., Xiao Y., Zhang W., Yuan K., Xiong Y., Zhang L., A syntax-guided edit decoder for neural program repair, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering., pp. 341-353, (2021)",Association for Computing Machinery (ACM); IEEE Computer Society; IEEE Technical Council on Software Engineering (TCSE); Special Interest Group on Software Engineering (SIGSOFT),"44th ACM/IEEE International Conference on Software Engineering, ICSE 2022",22 May 2022 through 27 May 2022,Pittsburgh,180255,English,Conference paper,Final,,Scopus,2-s2.0-85133555793,120
Yousofvand L.; Soleimani S.; Rafe V.,"Yousofvand, Leila (57203662859); Soleimani, Seyfollah (36740004600); Rafe, Vahid (14054926800)",57203662859; 36740004600; 14054926800,Automatic bug localization using a combination of deep learning and model transformation through node classification,2023,Software Quality Journal,31,4,,1045,1063,18,1,10.1007/s11219-023-09625-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150659552&doi=10.1007%2fs11219-023-09625-5&partnerID=40&md5=ca9ae9885894b791b4c68c220de3be7f,"Bug localization is the task of automatically locating suspicious commands in the source code. Many automated bug localization approaches have been proposed for reducing costs and speeding up the bug localization process. These approaches allow developers to focus on critical commands. In this paper, we propose to treat the bug localization problem as a node classification problem. As in the existing training sets, where whole graphs are labeled as buggy and bug-free, it is required first to label all nodes in each graph. To do this, we use the Gumtree algorithm, which labels the nodes by comparing the buggy graphs with their corresponding fixed graphs. In classification, we propose to use a type of graph neural networks (GNNs), GraphSAGE. The used dataset for training and testing is JavaScript buggy code and their corresponding fixed code. The results demonstrate that the proposed method outperforms other related methods. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","A low-cost approximate minimal hitting set algorithm and its application to model-based diagnosis, Proceedings of the Eight Symposium on Abstraction, Reformulation, and Approximation., (2009); On the accuracy of spectrum-based fault localization, Academic and Industrial Conference Practice and Research Techniques -Mutation (Taicpart-Mutation)., (2007); Agrawal H., de Millo R.A., Spafford E., An execution backtracking approach to program debugging, IEEE Software, 8, 5, (1991); Fault-localization techniques for software systems: A literature review, In SIGSOFT Software Engineering Notes., (2014); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, In International Conference on Learning Representations(Iclr)., (2018); Ascari L.C., Araki L.Y., Pozo A.R., Vergilio S.R., Exploring machine learning techniques for fault localization, In Proceedings of 10Th Latin American Test Workshop., (2009); Baah G.K., Podgurski A., Harrold M.J., The probabilistic program dependence graph and its application to fault diagnosis, IEEE Transactions on Software Engineering, 36, 4, (2010); Chen M., Kiciman E., Fratkin E., Fox A., Brewer E., Pinpoint: Problem determination in large, dynamic internet services, In International Conference on Dependable Systems and Networks (DSN)., (2002); On the influence of multiple faults on coverage-based fault localization, In Proceedings of the 2011 International Symposium on Software Testing and Analysis (ISSTA)., (2011); Hoppity: Learning graph transformations to detect and fix bugs in programs, In International Conference on Learning Representations (ICLR)., (2020); Fine-grained and accurate source code differencing, In Proceedings of the 29Th ACM/IEEE International Conference on Automated Software Engineering., (2014); Gazzola L., Micucci D., Mariani L., Automatic software repair: A survey, IEEE Transactions on Software Engineering, 45, 1, (2017); Hao D., Xie T., Zhang L., Wang X., Sun J., Mei H., Test input reduction for result inspection to facilitate fault localization, (2012); Hamilton W.L., Ying R., Leskovec J., Inductive representation learning on large graphs, In Proceedings of the 31St International Conference on Neural Information Processing Systems., (2017); Hovemeyer D., Pugh W., Finding Bugs is Easy, (2004); Hu W., Fey M., Zitnik M., Dong Y., Ren H., Liu B., Catasta M., Leskovec J., Open graph benchmark: Datasets for machine learning on graphs, In Thirty-Fifth Annual Conference on Neural Information Processing Systems. Neurips., (2020); Jensen S.H., Moller A., Thiemann P., Type Analysis for Javascript., (2009); Jones J.A., Harrold M.J., Empirical evaluation of the Tarantula automatic fault-localization technique, In International Conference on Automated Software Engineering (ASE)., (2005); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, In the International Conference on Learning Representations (ICLR)., (2017); Korel B., PELAS – program error-locating assistant system, IEEE Transactions on Software Engineering, 9, (1998); Kim D., Tao Y., Kim S., Zeller A., Where should we fix this bug? A two-phase recommendation model, IEEE Transactions on Software Engineering, 39, 11, (2013); Lee C.-C., Chung P.-C., Tsai J.-R., Chang C.-I., Robust radial basis function neural networks, IEEE Transactions on Systems, 29, 6, (1999); Le Goues C., Automatic Program Repair Using Genetic Programming, (2013); Lukins S.K., Kraft N.A., Etzkorn L.H., Bug localization using latent Dirichlet allocation, Information and Software Technology, 52, 9, (2012); Mayer W., Stumptner M., Model-based debugging: State of the art and future challenges, Electronic Notes in Theoretical Computer Science, 174, 4, (2007); Mateis C., Stumptner M., Wotawa F., Modeling Java Programs for Diagnosis., (2000); Meyers R.A., (2001); Mayer W., Stumptner M., Evaluating models for model-based debugging, In Proceedings of ACM International Conference on Automated Software Engineering., (2008); Mayer W., Stumptner M., Wieland D., Wotawa F., Can AI help to improve debugging substantially? Debugging experiences with value-based models, In Proceedings of European Conference on Artificial Intelligence., (2002); Naish L., Lee H., Ramamohanarao K., A model for spectra-based software diagnosis, Journal of the ACM Transactions on Software Engineering and Methodology, 20, 3, (2011); Paszke A., Sam G., Francisco M., Lerer A., Bradbury J., Chanan G., Killeen T., Lin Z., Gimelshein N., Antiga L., Desmaison A., Kopf A., Yang E., Devito Z., Raison M., Tejani A., Chilamkurthy S., Steiner B., Fang L., Bai J., Chintala S., PyTorch: An imperative style, high-performance deep learning library., (2019); (2021); Qiong G., Xian-Ming W., Zhao W., Bing N., Chun-Sheng X., An improved SMOTE algorithm based on genetic algorithm for imbalanced data classification, Journal of Digital Information Management, 14, 2, (2016); “Retrieval from software libraries for bug localization: A comparative study of generic and composite text models, MSR., (2011); Fault localization with nearest neighbor queries, In Proceedings of International Conference on Automated Software Engineering., (2003); Improving bug localization using structured information retrieval, In Proceedings of IEEE/ACM International Conference on Automated Software Engineering (ASE)., (2013); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, . IEEE Transactions on Neural Networks, pp. 61-80, (2008); Sisman B., Kak A.C., Incorporating version histories in information retrieval based bug localization, In Proceedings of 9Th IEEE Working Conference on Mining Software Repositories., (2012); State of the Octoverse, (2021); Sun Y., Wong A.K.C., Kamel M.S., Classification of imbalancd data: A review, International Journal of Pattern Recognition and Artificial Intelligence, 23, 4, (2009); Wang S., Lo D., Lawall J., Compositional vector space models for improved bug localization, In Proceedings of IEEE International Conference on Software Maintenance and Evolution (ICSME)., (2014); Wang Q., Parnin C., Orso A., Evaluating the usefulness of IR-based fault localization techniques, In Proceedings of International Symposium on Software Testing and Analysis (ISSTA)., (2015); Wang M., Zheng D., Ye Z., Gan Q., Li M., Song X., Zhou J., Ma C., Yu L., Gai Y., Xiao T., He T., Karypis G., Li J., Zhang Z., Deep graph library: A graph-centric, highly-performant package for graph neural networks, In Arxiv, 1909, (2020); Wong W.E., Debroy V., Choi B., A family of code coveragebased heuristics for effective fault, The Journal of Systems and Software (JSS), 83, 2, pp. 188-208, (2010); Wong W.E., Debroy V., Xu D., Towards better fault localization: A crosstab-based statistical approach, IEEE Trans, 42, 3, (2012); Wong W.E., Qi Y., BP neural network-based effective fault localization, International Journal of Software Engineering and Knowledge Engineering, 19, 4, (2009); Wong W.E., Qi Y., BP Neural Network-based Effective Fault Localization, International Journal of Software Engineering and Knowledge Engineering, 19, 4, (2019); Model-based debugging or how to diagnose programs automatically, In Proceedings of International Conference on Industrial and Engineering, Applications of Artificial Intelligence and Expert Systems., (2002); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A comprehensive survey on graph neural networks, IEEE Transactions on Neural Networks and Learning Systems, pp. 1-21, (2020); Graph attention networks, In ICLR., (2018); Vessey I., Expertise in debugging computer programs: A process analysis, International Journal of Man-Machine Studies, 23, 5, (1985); Pointer networks, In Advances in Neural Information Processing Systems., (2015); Zakas N.C., (2013); Zhang M., Cui Z., Neumann M., Chen Y., An end-to-end deep learning architecture for graph classification, In Proceedings of AAAI, Marion Neumann, and Yixin Chen., (2018); Zhou J., Cui G., Hu S., Zhang Z., Yang C., Liu Z., Wang L., Li C., Sun M., Graph neural networks: A review of methods and applications, AI Open, 1, pp. 57-81, (2020); Zhong H., Mei H., Learning a graph-based classifier for fault localization, Science China Information Sciences, 63, (2020); Zhong H., Su Z., An Empirical Study on Real Bug Fixes., (2015); Zhao T., Zhang X., Wang S., GraphSMOTE: Imbalanced node classification on graphs with graph neural networks, In Proceedings of the Fourteenth ACM International Conference on Web Search and Data Mining (WSDM ’21)., (2021)",,,,,,English,Article,Final,,Scopus,2-s2.0-85150659552,121
Zhang J.; Wang X.; Zhang H.; Sun H.; Liu X.; Hu C.; Liu Y.,"Zhang, Jian (58504298500); Wang, Xu (56063606500); Zhang, Hongyu (55685668500); Sun, Hailong (35243585400); Liu, Xudong (24478022500); Hu, Chunming (36091049100); Liu, Yang (56911879800)",58504298500; 56063606500; 55685668500; 35243585400; 24478022500; 36091049100; 56911879800,Detecting Condition-Related Bugs with Control Flow Graph Neural Network,2023,ISSTA 2023 - Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis,,,,1370,1382,12,3,10.1145/3597926.3598142,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167727229&doi=10.1145%2f3597926.3598142&partnerID=40&md5=d1528e96d16abc5373ecd30bb07bcb45,"Automated bug detection is essential for high-quality software development and has attracted much attention over the years. Among the various bugs, previous studies show that the condition expressions are quite error-prone and the condition-related bugs are commonly found in practice. Traditional approaches to automated bug detection are usually limited to compilable code and require tedious manual effort. Recent deep learning-based work tends to learn general syntactic features based on Abstract Syntax Tree (AST) or apply the existing Graph Neural Networks over program graphs. However, AST-based neural models may miss important control flow information of source code, and existing Graph Neural Networks for bug detection tend to learn local neighbourhood structure information. Generally, the condition-related bugs are highly influenced by control flow knowledge, therefore we propose a novel CFG-based Graph Neural Network (CFGNN) to automatically detect condition-related bugs, which includes a graph-structured LSTM unit to efficiently learn the control flow knowledge and long-distance context information. We also adopt the API-usage attention mechanism to leverage the API knowledge. To evaluate the proposed approach, we collect real-world bugs in popular GitHub repositories and build a large-scale condition-related bug dataset. The experimental results show that our proposed approach significantly outperforms the state-of-the-art methods for detecting condition-related bugs.  © 2023 ACM.","Apache Log4j, (2022); (2022); Facebook Infer, (2022); (2022); (2022); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, International Conference on Learning Representations, (2018); Bahdanau D., Hyun Cho K., Bengio Y., Neural machine translation by jointly learning to align and translate, 3rd International Conference on Learning Representations, ICLR 2015, (2015); Bian P., Liang B., Shi W., Huang J., Cai Y., NARminer: discovering negative association rules from code for bug detection, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 411-422, (2018); Bui N.D.Q., Yu Y., Jiang L., Bilateral dependency neural networks for cross-language algorithm classification, 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, pp. 422-433, (2019); Cunha Campos E., De Almeida Maia M., Common bugfix patterns: A large-scale observational study, 2017 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM). IEEE, pp. 404-413, (2017); Cole B., Hakim D., Hovemeyer D., Lazarus R., Pugh W., Stephens K., Improving your software using static analysis to find bugs, Companion to the 21st ACM SIGPLAN symposium on Object-oriented programming systems, languages, and applications, pp. 673-674, (2006); Engler D., Yu Chen D., Hallem S., Chou A., Chelf B., Bugs as deviant behavior: A general approach to inferring errors in systems code, ACM SIGOPS Operating Systems Review, 35, 5, pp. 57-72, (2001); Garg V., Jegelka S., Jaakkola T., Generalization and representational limits of graph neural networks, International Conference on Machine Learning. PMLR, pp. 3419-3430, (2020); Gosling J., Joy B., Steele G.L., Bracha G., Buckley A., The Java Language Specification, (2014); Gu X., Zhang H., Zhang D., Kim S., Deep API learning, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 631-642, (2016); Hangal S., Lam M.S., Tracking down software bugs using automatic anomaly detection, Proceedings of the 24th International Conference on Software Engineering. ICSE 2002. IEEE, pp. 291-301, (2002); Hindle A., Barr E.T., Gabel M., Su Z., Devanbu P., On the naturalness of software, Commun. ACM, 59, 5, pp. 122-131, (2016); Hochreiter S., Schmidhuber J., Long short-term memory, Neural computation, 9, 8, pp. 1735-1780, (1997); Hovemeyer D., Pugh W., Finding bugs is easy, Acm sigplan notices, 39, 12, pp. 92-106, (2004); Hovemeyer D., Pugh W., Finding more null pointer bugs, but not too many, Proceedings of the 7th ACM SIGPLAN-SIGSOFT workshop on Program analysis for software tools and engineering, pp. 9-14, (2007); Jin G., Song L., Shi X., Scherpelz J., Lu S., Understanding and detecting real-world performance bugs, ACM SIGPLAN Notices, 47, 6, pp. 77-88, (2012); Just R., Jalali D., Ernst M.D., Defects4J: A database of existing faults to enable controlled testing studies for Java programs, Proceedings of the 2014 International Symposium on Software Testing and Analysis, pp. 437-440, (2014); Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2014); Lee T., Nam J., Han D., Kim S., Peter I.H., Micro interaction metrics for defect prediction, Proceedings of the 19th ACM SIGSOFT symposium and the 13th European conference on Foundations of software engineering, pp. 311-321, (2011); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, (2015); Li Y., Wang S., Nguyen T.N., Vulnerability detection with fine-grained interpretations, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 292-303, (2021); Li Y., Wang S., Nguyen T.N., Van Nguyen S., Improving bug detection via context-based code representation learning and attention-based neural networks, Proceedings of the ACM on Programming Languages, 3, OOPSLA, pp. 1-30, (2019); Li Z., Zhou Y., PR-Miner: Automatically extracting implicit programming rules and detecting violations in large software code, ACM SIGSOFT Software Engineering Notes, 30, 5, pp. 306-315, (2005); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., SySeVR: AFramework for Using Deep Learning to Detect Software Vulnerabilities, IEEE Transactions on Dependable and Secure Computing, pp. 1-1, (2021); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., VulDeePecker: A Deep Learning-Based System for Vulnerability Detection, 25th Annual Network and Distributed System Security Symposium, NDSS 2018, (2018); Livshits B., Zimmermann T., Dynamine: finding common error patterns by mining software revision histories, ACM SIGSOFT Software Engineering Notes, 30, 5, pp. 296-305, (2005); Benjamin Livshits V., Lam M.S., Tracking pointers with path and context sensitivity for bug detection in C programs, Proceedings of the 9th European software engineering conference held jointly with 11th ACM SIGSOFT international symposium on Foundations of software engineering, pp. 317-326, (2003); Long F., Rinard M., Staged program repair with condition synthesis, Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering, pp. 166-178, (2015); Martinez M., Monperrus M., Mining software repair models for reasoning on the search space of automated program fixing, Empirical Software Engineering, 20, 1, pp. 176-205, (2015); Moser R., Pedrycz W., Succi G., A comparative analysis of the efficiency of change metrics and static code attributes for defect prediction, Proceedings of the 30th international conference on Software engineering, pp. 181-190, (2008); Pawlak R., Monperrus M., Petitprez N., Noguera C., Seinturier L., Spoon: A Library for Implementing Analyses and Transformations of Java Source Code, Software: Practice and Experience, 46, pp. 1155-1179, (2015); Pradel M., Sen K., Deepbugs: A learning approach to namebased bug detection, Proceedings of the ACM on Programming Languages, 2, OOPSLA, pp. 1-25, (2018); Ray B., Hellendoorn V., Godhane S., Tu Z., Bacchelli A., Devanbu P., On the"" naturalness"" of buggy code, 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE). IEEE, pp. 428-439, (2016); Schuster M., Paliwal K.K., Bidirectional recurrent neural networks, IEEE transactions on Signal Processing, 45, 11, pp. 2673-2681, (1997); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, 2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR). IEEE, pp. 542-553, (2018); Vasic M., Kanade A., Maniatis P., Bieber D., Singh R., Neural Program Repair by Jointly Learning to Localize and Repair, International Conference on Learning Representations, (2018); Wang S., Chollak D., Movshovitz-Attias D., Tan L., Bugram: bug detection with n-gram language models, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, pp. 708-719, (2016); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE). IEEE, pp. 297-308, (2016); Wang Y., Wang K., Gao F., Wang L., Learning semantic program embeddings with graph interval neural network, Proceedings of the ACM on Programming Languages, 4, OOPSLA, pp. 1-27, (2020); Wasylkowski A., Zeller A., Mining temporal specifications from object usage, Automated Software Engineering, 18, 3, pp. 263-292, (2011); Wasylkowski A., Zeller A., Lindig C., Detecting object usage anomalies, Proceedings of the the 6th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering, pp. 35-44, (2007); Wu Y., Zou D., Dou S., Yang W., Xu D., Jin H., VulCNN: An Image-inspired Scalable Vulnerability Detection System, 2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE), pp. 2365-2376, (2022); Xie Y., Aiken A., Saturn: A scalable framework for error detection using boolean satisfiability, ACM Transactions on Programming Languages and Systems (TOPLAS), 29, 3, pp. 16-es, (2007); Xiong Y., Wang J., Yan R., Zhang J., Han S., Huang G., Zhang L., Precise condition synthesis for program repair, 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE). IEEE, pp. 416-426, (2017); Xuan J., Martinez M., Demarco F., Clement M., Lamelas Marcote S., Durieux T., Le Berre D., Monperrus M., Nopol: Automatic repair of conditional statement bugs in java programs, IEEE Transactions on Software Engineering, 43, 1, pp. 34-55, (2016); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy. IEEE, pp. 590-604, (2014); You J., Ying R., Leskovec J., Position-aware graph neural networks, International Conference on Machine Learning. PMLR, pp. 7134-7143, (2019); Zafar S., Zubair Malik M., Singh Walia G., Towards standardizing and improving classification of bug-fix commits, 2019 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM). IEEE, pp. 1-6, (2019); Zhang J., Wang X., Zhang H., Sun H., Liu X., Retrieval-based neural source code summarization, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 1385-1397, (2020); Zhang J., Wang X., Zhang H., Sun H., Pu Y., Liu X., Learning to handle exceptions, Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering, pp. 29-41, (2020); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, pp. 783-794, (2019); Zhao G., Huang J., DeepSim: Deep Learning Code Functional Similarity, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (Lake Buena Vista, FL, USA) (ESEC/FSE 2018), pp. 141-151, (2018); Zhong H., Su Z., An empirical study on real bug fixes, 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, 1, pp. 913-923, (2015); Zhong H., Thummalapenta S., Xie T., Zhang L., Wang Q., Mining API mapping for language migration, Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering, 1, pp. 195-204, (2010); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in neural information processing systems, 32, (2019)",ACM SIGSOFT; AITO,"32nd ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2023",17 July 2023 through 21 July 2023,Seattle,190710,English,Conference paper,Final,,Scopus,2-s2.0-85167727229,123
Tang F.; He P.,"Tang, Fanggeng (58539887100); He, Pan (35749710300)",58539887100; 35749710300,Software Defect Prediction using Multi-scale Structural Information,2023,ACM International Conference Proceeding Series,,,,548,556,8,0,10.1145/3594315.3594371,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168248665&doi=10.1145%2f3594315.3594371&partnerID=40&md5=eebaffafd0ee850460b3597b2d4f44c6,"In recent years, most researches have used the sequence of nodes in the abstract syntax tree (AST) of code to extract features for software defect prediction (SDP). While the AST is a kind of graph data, it may ignore some part of the structural information to use the original graph data as a sequence for input. Thus, Graph neural network (GNN) has been used to extract structural information in SDP. However, existing researches ignore that GNN learning is inherently local. It is difficult to interact between remote nodes and to capture long-term dependencies in source code. We apply a combination model of GNN Transformer to predict the software defects. Using an AST directly as the input, GNN extracts local features and structural information between the node and its neighbors. We then encode the relative and absolute positions of the nodes in the AST. The position encodings are passed into the Transformer along with the feature information extracted by GNN to extract the global features, which are the long-term dependencies between nodes. Finally, the extracted fused features are used in the SDP. Experiments on the PROMISE dataset have shown that our method achieves higher F-measure and better identification of defective features in source code than the state-of-the-art SDP method. © 2023 Copyright held by the owner/author(s).","Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, (2017); Belkin M., Niyogi P., Laplacian Eigenmaps for Dimensionality Reduction and Data Representation, 15, 6, pp. 1373-1396, (2003); Chidamber S.R., Kemerer C.F., A metrics suite for object oriented design, IEEE Transactions on Software Engineering, 20, 6, pp. 476-493, (1994); Defferrard M., Bresson X., Vandergheynst P., Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering, Advances in Neural Information Processing Systems, 29, (2016); Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, (2018); Dwivedi V.P., Bresson X., A Generalization of Transformer Networks to Graphs, (2020); Fan G., Diao X., Yu H., Yang K., Chen L., Deep Semantic Feature Learning with Embedded Static Metrics for Software Defect Prediction, 2019 26th Asia-Pacific Software Engineering Conference (APSEC), pp. 244-251, (2019); Gilmer J., Schoenholz S.S., Riley P.F., Vinyals O., Dahl G.E., Neural Message Passing for Quantum Chemistry, Proceedings of the 34th International Conference on Machine Learning (Proceedings of Machine Learning Research vol. 70). PMLR, pp. 1263-1272, (2017); Halstead M.H., Elements of Software Science (Operating and Programming Systems Series), (1977); Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P., On the Naturalness of Software, Proceedings of the 34th International Conference on Software Engineering (Zurich, Switzerland) (ICSE '12), pp. 837-847, (2012); Kreuzer D., Beaini D., Hamilton W., Letourneau V., Tossou P., Rethinking Graph Transformers with Spectral Attention, Advances in Neural Information Processing Systems, 34, pp. 21618-21629, (2021); Kumar R., Singh K.P., SVM with Feature Selection and Extraction Techniques for Defect-Prone Software Module Prediction, Proceedings of Sixth International Conference on Soft Computing for Problem Solving, pp. 279-289, (2017); Li J., He P., Zhu J., Lyu M.R., Software Defect Prediction via Convolutional Neural Network, 2017 IEEE International Conference on Software Quality, Reliability and Security (QRS), pp. 318-328, (2017); Li Y., Gu C., Dullien T., Vinyals O., Kohli P., Graph Matching Networks for Learning the Similarity of Graph Structured Objects, Proceedings of the 36th International Conference on Machine Learning (Proceedings of Machine Learning Research, 97, pp. 3835-3845, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, (2015); Li Z., Jing X., Zhu X., Zhang H., Xu B., Ying S., Heterogeneous Defect Prediction with Two-Stage Ensemble Learning, Automated Software Engg, 26, 3, pp. 599-651, (2019); Liang H., Yu Y., Jiang L., Xie Z., Seml: A Semantic LSTM Model for Software Defect Prediction, IEEE Access, 7, pp. 83812-83824, (2019); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., RoBERTa: A Robustly Optimized BERT Pretraining Approach, (2019); Maron H., Ben-Hamu H., Serviansky H., Lipman Y., Provably Powerful Graph Networks, Advances in Neural Information Processing Systems, 32, (2019); McCabe T.J., A Complexity Measure, IEEE Transactions on Software Engineering SE-2, 4, pp. 308-320, (1976); Morris C., Ritzert M., Fey M., Hamilton W.L., Lenssen J.E., Rattan G., Grohe M., Weisfeiler and Leman Go Neural: Higher-Order Graph Neural Networks, Proceedings of the AAAI Conference on Artificial Intelligence, 33, 1, pp. 4602-4609, (2019); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional Neural Networks over Tree Structures for Programming Language Processing, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (Phoenix, Arizona) (AAAI'16), pp. 1287-1293, (2016); Sandhu P., Lata S., Grewal D.K., Neural Network Approach for Software Defect Prediction Based on Quantitative and Qualitative Factors, International Journal of Computer Theory and Engineering, pp. 298-303, (2012); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser U., Polosukhin I., Attention is All you Need, Advances in Neural Information Processing Systems, 30, (2017); Phan A.V., Le Nguyen M., Bui L.T., Convolutional Neural Networks over Control Flow Graphs for Software Defect Prediction, 2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI), pp. 45-52, (2017); Wang H., Zhuang W., Zhang X., Software Defect Prediction Based on Gated Hierarchical LSTMs, IEEE Transactions on Reliability, 70, 2, pp. 711-727, (2021); Wang S., Liu T., Tan L., Automatically Learning Semantic Features for Defect Prediction, 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE), pp. 297-308, (2016); Wu Z., Jain P., Wright M., Mirhoseini A., Gonzalez J.E., Stoica I., Representing Long-Range Context for Graph Neural Networks with Global Attention, Advances in Neural Information Processing Systems, 34, pp. 13266-13279, (2021); Xu J., Wang F., Ai J., Defect Prediction With Semantics and Context Features of Codes Based on Graph Representation Learning, IEEE Transactions on Reliability, 70, 2, pp. 613-625, (2021); Yang X., Lo D., Xia X., Zhang Y., Sun J., Deep Learning for Just-in-Time Defect Prediction, 2015 IEEE International Conference on Software Quality, Reliability and Security, pp. 17-26, (2015); You J., Liu B., Ying Z., Pande V., Leskovec J., Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation, Advances in Neural Information Processing Systems, 31, (2018); Arar O.F., Ayan K., A feature dependent Naive Bayes approach and its application to the software defect prediction problem, Applied Soft Computing, 59, pp. 197-209, (2017); Siki L., Kurdija A.S., Vladimir K., Sili M., Graph Neural Network for Source Code Defect Prediction, IEEE Access, 10, pp. 10402-10415, (2022)",,"9th International Conference on Computing and Artificial Intelligence, ICCAI 2023",17 March 2023 through 20 March 2023,Tianjin,191353,English,Conference paper,Final,,Scopus,2-s2.0-85168248665,125
Yin Y.; Shi Y.; Zhao Y.; Wahab F.,"Yin, Ying (7403273774); Shi, Yucen (57210821365); Zhao, Yuhai (55350109700); Wahab, Fazal (57734128700)",7403273774; 57210821365; 55350109700; 57734128700,Multi-graph learning-based software defect location,2024,Journal of Software: Evolution and Process,36,4,e2552,,,,3,10.1002/smr.2552,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152077576&doi=10.1002%2fsmr.2552&partnerID=40&md5=05fae7aae53840e8e104ebbedbcab80e,"Software quality is key to the success of software systems. Modern software systems are growing in their worth based on industry needs and becoming more complex, which inevitably increases the possibility of more defects in software systems. Software repairing is time-consuming, especially locating the source files related to specific software defect reports. To locate defective source files more quickly and accurately, automated software defect location technology is generated and has a huge application value. The existing deep learning-based software defect location method focuses on extracting the semantic correlation between the source file and the corresponding defect reports. However, the extensive code structure information contained in the source files is ignored. To this end, we propose a software defect location method, namely, multi-graph learning-based software defect location (MGSDL). By extracting the program dependency graphs for functions, each source file is converted into a graph bag containing multiple graphs (i.e., multi-graph). Further, a multi-graph learning method is proposed, which learns code structure information from multi-graph to establish the semantic association between source files and software defect reports. Experiments' results on four publicly available datasets, AspectJ, Tomcat, Eclipse UI, and SWT, show that MGSDL improves on average 3.88%, 5.66%, 13.23%, 9.47%, and 3.26% over the competitive methods in five evaluation metrics, rank@10, rank@5, MRR, MAP, and AUC, respectively. © 2023 John Wiley & Sons Ltd.","Zhang T., Chen J., Zhan X., Luo X., Lo D., Jiang H., Where2Change: change request localization for app reviews, IEEE Transactions on Software Engineering, 47, 11, pp. 2590-2616, (2021); Zhang T., Wenjun H., Luo X., Ma X., A commit messages-based bug localization for android applications, Int J Softw En Knowledge Eng, 29, 4, pp. 457-487, (2019); Arcega L., Font J., Haugen O., Cetina C., An approach for bug localization in models using two levels: model and metamodel, Softw Syst Model, 18, 6, pp. 3551-3576, (2019); Xiao Y., Keung J., Mi Q., Et al., Improving bug localization with an enhanced convolutional neural network, (2018); Liu C., Fei L., Yan X., Et al., Statistical debugging: a hypothesis testing-based approach, IEEE Trans Softw Eng Se, 32, 10, pp. 831-848, (2006); Lei Y., Xie H., Zhang T., Yan M., Zhou X., Sun C., Feature-FL: feature-based fault localization, IEEE Trans Reliab, 71, 1, pp. 264-283, (2022); Zhou J., Zhang H., Lo D., Where should the bugs be fixed? More accurate information retrieval-based bug localization based on bug reports, pp. 14-24, (2012); Ye X., Bunescu R., Liu C., Learning to rank relevant files for bug reports using domain knowledge, SIGSOFT, pp. 689-699, (2014); Rath M., Mader P., Structured information in bug report descriptions - influence on IR-based bug localization and developers, Softw Qual J, 27, 3, pp. 1315-1337, (2019); Nguyen A.T., Nguyen T.T., Al-Kofahi J., Nguyen H.V., Nguyen T.N., A topic-based approach for narrowing the search space of buggy files from a bug report, pp. 263-272, (2011); Lam A.N., Nguyen A.T., Nguyen H.A., Et al., Bug localization with combination of deep learning and information retrieval, 2017 IEEE/ACM 25th International Conference on Program Comprehension (ICPC), (2017); Huo X., Li M., Zhou Z.H., Learning unified features from natural and programming languages for locating buggy source code, (2016); Zhang T., Sun X., Zheng Z., Li G., Intelligent analysis for software data: research and applications, Frontiers Inf Technol Electron Eng, 23, 5, pp. 661-663, (2022); Shao Y., Liu B., Wang S., Li G., Software defect prediction based on correlation weighted class association rule mining, Knowl Based Syst, 196, (2020); Liu W., Software defect data mining: a survey of severity analysis, J Softw, 14, 10, pp. 457-478, (2019); Gao X., Feng Y., Yin Y., Liu Z., Chen Z., Baowen X., Adaptive test selection for deep neural networks, ICSE, pp. 73-85, (2022); Xiao Y., Bai T., Mingzheng G., Fang C., Chen Z., Certifying robustness of convolutional neural networks with tight linear approximation, CoRR, (2022); Kim Y., Convolutional neural networks for sentence classification, arXiv, (2014); Jia W., Pan S., Zhu X., Cai Z., Zhang C., Multi-graph-view learning for complicated object classification, Int Conf Artif Intell IJCAI, pp. 3953-3959, (2015); Jia W., Zhu X., Zhang C., Philip S.Y., Bag constrained structure pattern mining for multi-graph classification, IEEE Trans Knowl Data Eng, 26, 10, pp. 2382-2396, (2014); Wu J., Zhu X., Zhang C., Yu P.S., Bag constrained structure pattern mining for multi-graph classification, IEEE Trans Knowl Data Eng, 26, 10, pp. 2382-2396, (2014); Weng W., Chen C.-L., Shunxiang W., Li Y.-W., Wen J., An efficient stacking model of multi-label classification based on Pareto optimum, IEEE Access, 7, pp. 127427-127437, (2019); Jiayu W., Leveraging Label Information in Representation Learning for Multi-label Text Classification, (2019); Zhao Y., Wang Y., Wang Z., Zhang C., Multi-graph multi-label learning with dual-granularity labeling, KDD, pp. 2327-2337, (2021); Wu J., Pan S., Zhu X., Zhang C., Wu X., Positive and unlabeled multi-graph learning, IEEE Trans Cybern, 47, 4, pp. 818-829, (2016); Li C., Yin Y., Zhao Y., Et al., Multi-instance multi-label learning by extreme learning machine, Appl Sci, 6, 6, (2016); Shi Y., Yin Y., Wang Z., Et al., How to better utilize code graphs in semantic code search?, ESEC/SIGSOFT FSE, pp. 722-733, (2022); Grohe M., Word2vec, Node2vec, Graph 2vec, X2vec: towards a theory of vector Embeddings of structured data, Pods, pp. 1-16, (2020); Yin Y., Zhao Y., Li C., Zhang B., Improving multi-instance multi-label learning by extreme learning machine, Appl Sci, 6, 6, (2016)",,,,,,English,Article,Final,,Scopus,2-s2.0-85152077576,126
Ma Y.-F.; Du Y.; Li M.,"Ma, Yi-Fan (57456232500); Du, Yali (57226543642); Li, Ming (56994181000)",57456232500; 57226543642; 56994181000,Capturing the Long-Distance Dependency in the Control Flow Graph via Structural-Guided Attention for Bug Localization,2023,IJCAI International Joint Conference on Artificial Intelligence,2023-August,,,2242,2250,8,3,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170357286&partnerID=40&md5=a91320049d84720a0f4e3003c8bc9486,"To alleviate the burden of software maintenance, bug localization, which aims to automatically locate the buggy source files based on the bug report, has drawn significant attention in the software mining community. Recent studies indicate that the program structure in source code carries more semantics reflecting the program behavior, which is beneficial for bug localization. Benefiting from the rich structural information in the Control Flow Graph (CFG), CFG-based bug localization methods have achieved the state-of-the-art performance. Existing CFG-based methods extract the semantic feature from the CFG via the graph neural network. However, the step-wise feature propagation in the graph neural network suffers from the problem of information loss when the propagation distance is long, while the long-distance dependency is rather common in the CFG. In this paper, we argue that the long-distance dependency is crucial for feature extraction from the CFG, and propose a novel bug localization model named sgAttention. In sgAttention, a particularly designed structural-guided attention is employed to globally capture the information in the CFG, where features of irrelevant nodes are masked for each node to facilitate better feature extraction from the CFG. Experimental results on four widely-used open-source software projects indicate that sgAttention averagely improves the state-of-the-art bug localization methods by 32.9% and 29.2% and the state-of-the-art pre-trained models by 5.8% and 4.9% in terms of MAP and MRR, respectively. © 2023 International Joint Conferences on Artificial Intelligence. All rights reserved.","Chen An Ran, Chen Tse-Hsun, Wang Shaowei, Pathidea: Improving information retrieval-based bug localization by re-constructing execution paths using logs, IEEE Transactions on Software Engineering, 48, 8, pp. 2905-2919, (2022); Ciborowska Agnieszka, Damevski Kostadin, Fast changeset-based bug localization with BERT, 44th IEEE/ACM International Conference on Software Engineering, pp. 946-957, (2022); Devlin Jacob, Chang Ming-Wei, Lee Kenton, Toutanova Kristina, BERT: pre-training of deep bidirectional transformers for language understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4171-4186, (2019); Fejzer Mikolaj, Narebski Jakub, Przymus Piotr, Stencel Krzysztof, Tracking buggy files: New efficient adaptive bug localization algorithm, IEEE Transactions on Software Engineering, 48, 7, pp. 2557-2569, (2022); Feng Zhangyin, Guo Daya, Tang Duyu, Duan Nan, Feng Xiaocheng, Gong Ming, Shou Linjun, Qin Bing, Liu Ting, Jiang Daxin, Zhou Ming, CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP, Online Event, pp. 1536-1547, (2020); Fischer Michael, Pinzger Martin, Gall Harald, Populating a release history database from version control and bug tracking systems, International Conference on Software Maintenance, pp. 23-32, (2003); Gay Gregory, Haiduc Sonia, Marcus Andrian, Menzies Tim, On the use of relevance feedback in ir-based concept location, IEEE International Conference on Software Maintenance, pp. 351-360, (2009); Guo Daya, Ren Shuo, Lu Shuai, Feng Zhangyin, Tang Duyu, Liu Shujie, Zhou Long, Duan Nan, Svyatkovskiy Alexey, Fu Shengyu, Tufano Michele, Deng Shao Kun, Clement Colin B., Drain Dawn, Sundaresan Neel, Yin Jian, Jiang Daxin, Zhou Ming, GraphCodeBERT: Pre-training code representations with data flow, 9th International Conference on Learning Representations, Virtual Event. OpenReview.net, (2021); Gupta Rahul, Kanade Aditya, Shevade Shirish K., Neural attribution for semantic bug-localization in student programs, Advances in Neural Information Processing Systems, 32, pp. 11861-11871, (2019); Hellendoorn Vincent J., Sutton Charles, Singh Rishabh, Maniatis Petros, Bieber David, Global relational models of source code, 8th International Conference on Learning Representations, (2020); Huo Xuan, Li Ming, Enhancing the unified features to locate buggy files by exploiting the sequential nature of source code, Proceedings of the 26th International Joint Conference on Artificial Intelligence, pp. 1909-1915, (2017); Huo Xuan, Li Ming, Zhou Zhi-Hua, Learning unified features from natural and programming languages for locating buggy source code, Proceedings of the 25th International Joint Conference on Artificial Intelligence, pp. 1606-1612, (2016); Huo Xuan, Thung Ferdian, Li Ming, Lo David, Shi Shu-Ting, Deep transfer bug localization, IEEE Transactions on Software Engineering, 47, 7, pp. 1368-1380, (2019); Huo Xuan, Li Ming, Zhou Zhi-Hua, Control flow graph embedding based on multi-instance decomposition for bug localization, Proceedings of the 34th AAAI Conference on Artificial Intelligence, 34, pp. 4223-4230, (2020); Jarman Darryl, Berry Jeffrey, Smith Riley, Thung Ferdian, Lo David, Legion: Massively composing rankers for improved bug localization at adobe, IEEE Transactions on Software Engineering, 48, 8, pp. 3010-3024, (2022); Singh Kochhar Pavneet, Tian Yuan, Lo David, Potential biases in bug localization: Do they matter?, Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering, pp. 803-814, (2014); Lam An N., Nguyen Anh T., Nguyen Hoan A., Nguyen Tien N., Combining deep learning with information retrieval to localize buggy files for bug reports (n), 30th IEEE/ACM International Conference on Automated Software Engineering, pp. 476-481, (2015); Lam An N., Nguyen Anh T., Nguyen Hoan A., Nguyen Tien N., Bug localization with combination of deep learning and information retrieval, Proceedings of the 25th International Conference on Program Comprehension, pp. 218-229, (2017); Liang Hongliang, Hang Dengji, Li Xiangyu, Modeling function-level interactions for file-level bug localization, Empirical Software Engineering, 27, 7, (2022); Loshchilov Ilya, Hutter Frank, Decoupled weight decay regularization, 7th International Conference on Learning Representations, (2019); Lukins Stacy K., Kraft Nicholas A., Etzkorn Letha H., Source code retrieval for bug localization using latent dirichlet allocation, Proceedings of the 15th Working Conference on Reverse Engineering, pp. 155-164, (2008); Ma Yi-Fan, Li Ming, The flowing nature matters: feature learning from the control flow graph of source code for bug localization, Machine Learning, 111, 3, pp. 853-870, (2022); Peng Han, Li Ge, Wang Wenhan, Zhao Yunfei, Jin Zhi, Integrating tree path in transformer for code representation, Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, virtual, pp. 9343-9354, (2021); Poshyvanyk Denys, Gueheneuc Yann-Gael, Marcus Andrian, Antoniol Giuliano, Rajlich Vaclav, Feature location using probabilistic ranking of methods based on execution scenarios and information retrieval, IEEE Transactions on Software Engineering, 33, 6, pp. 420-432, (2007); Rahman Mohammad M., Roy Chanchal K., Improving ir-based bug localization with context-aware query reformulation, Proceedings of the 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 621-632, (2018); Saha Ripon K., Lease Matthew, Khurshid Sarfraz, Perry Dewayne E., Improving bug localization using structured information retrieval, 28th IEEE/ACM International Conference on Automated Software Engineering, pp. 345-355, (2013); Vaswani Ashish, Shazeer Noam, Parmar Niki, Uszkoreit Jakob, Jones Llion, Gomez Aidan N., Kaiser Lukasz, Polosukhin Illia, Attention is all you need, Proceedings of the 31st International Conference on Neural Information Processing Systems, pp. 6000-6010, (2017); Wang Yaojing, Yao Yuan, Tong Hanghang, Huo Xuan, Li Ming, Xu Feng, Lu Jian, Bug localization via supervised topic modeling, 18th IEEE International Conference on Data Mining, pp. 607-616, (2018); Wen Ming, Wu Rongxin, Cheung Shing-Chi, Locus: locating bugs from software changes, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, pp. 262-273, (2016); Wong Chu-Pan, Xiong Yingfei, Zhang Hongyu, Hao Dan, Zhang Lu, Mei Hong, Boosting bug-report-oriented fault localization with segmentation and stack-trace analysis, 30th IEEE International Conference on Software Maintenance and Evolution, pp. 181-190, (2014); Yang Shouliang, Cao Junming, Zeng Hushuang, Shen Beijun, Zhong Hao, Locating faulty methods with a mixed RNN and attention model, 29th IEEE/ACM International Conference on Program Comprehension, pp. 207-218, (2021); Ye Xin, Bunescu Razvan, Liu Chang, Learning to rank relevant files for bug reports using domain knowledge, Proceedings of the 22nd ACM SIG-SOFT International Symposium on Foundations of Software Engineering, pp. 689-699, (2014); Ye Xin, Bunescu Razvan C., Liu Chang, Mapping bug reports to relevant files: A ranking model, a fine-grained benchmark, and feature evaluation, IEEE Transactions on Software Engineering, 42, 4, pp. 379-402, (2016); Ying Chengxuan, Cai Tianle, Luo Shengjie, Zheng Shuxin, Ke Guolin, He Di, Shen Yanming, Liu Tie-Yan, Do transformers really perform badly for graph representation?, Advances in Neural Information Processing Systems, 34, pp. 28877-28888, (2021); Youm Klaus Changsun, Ahn June, Lee Eunseok, Improved bug localization based on code change histories and bug reports, Information and Software Technology, 82, pp. 177-192, (2017); Zhang Wen, Li Ziqiang, Wang Qing, Li Juan, Finelocator: A novel approach to method-level fine-grained bug localization by query expansion, Information Software Technology, 110, pp. 121-135, (2019); Zhang Jing-Lei, Xie Rui, Ye Wei, Zhang Yu-Han, Zhang Shi-Kun, Exploiting code knowledge graph for bug localization via bi-directional attention, Proceedings of the 28th International Conference on Program Comprehension, pp. 219-229, (2020); Zhou Jian, Zhang Hong-Yu, Lo David, Where should the bugs be fixed? more accurate information retrieval-based bug localization based on bug reports, 34th International Conference on Software Engineering, pp. 14-24, (2012); Zhu Ziye, Li Yun, Tong Hanghang, Wang Yu, COOBA: Cross-project bug localization via adversarial transfer learning, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, pp. 3565-3571, (2020); Zhu Ming, Suresh Karthik, Reddy Chandan K., Multilingual code snippets training for program translation, Proceedings of the Thirty-Sixth AAAI Conference on Artificial Intelligence, Virtual Event, pp. 11783-11790, (2022)",International Joint Conferences on Artifical Intelligence (IJCAI),"32nd International Joint Conference on Artificial Intelligence, IJCAI 2023",19 August 2023 through 25 August 2023,Macao,191872,English,Conference paper,Final,,Scopus,2-s2.0-85170357286,127
Lin B.; Wang S.; Wen M.; Mao X.,"Lin, Bo (57221479359); Wang, Shangwen (57202087223); Wen, Ming (56111949000); Mao, Xiaoguang (35786043900)",57221479359; 57202087223; 56111949000; 35786043900,Context-Aware Code Change Embedding for Better Patch Correctness Assessment,2022,ACM Transactions on Software Engineering and Methodology,31,3,51,,,,28,10.1145/3505247,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130752121&doi=10.1145%2f3505247&partnerID=40&md5=896d9827ba64bf2c9e1c335c5f5a6100,"Despite the capability in successfully fixing more and more real-world bugs, existing Automated Program Repair (APR) techniques are still challenged by the long-standing overfitting problem (i.e., a generated patch that passes all tests is actually incorrect). Plenty of approaches have been proposed for automated patch correctness assessment (APCA). Nonetheless, dynamic ones (i.e., those that needed to execute tests) are time-consuming while static ones (i.e., those built on top of static code features) are less precise. Therefore, embedding techniques have been proposed recently, which assess patch correctness via embedding token sequences extracted from the changed code of a generated patch. However, existing techniques rarely considered the context information and program structures of a generated patch, which are crucial for patch correctness assessment as revealed by existing studies. In this study, we explore the idea of context-Aware code change embedding considering program structures for patch correctness assessment. Specifically, given a patch, we not only focus on the changed code but also take the correlated unchanged part into consideration, through which the context information can be extracted and leveraged. We then utilize the AST path technique for representation where the structure information from AST node can be captured. Finally, based on several pre-defined heuristics, we build a deep learning based classifier to predict the correctness of the patch. We implemented this idea as Cache and performed extensive experiments to assess its effectiveness. Our results demonstrate that Cache can (1) perform better than previous representation learning based techniques (e.g., Cache relatively outperforms existing techniques by 6%, 3%, and 16%, respectively under three diverse experiment settings), and (2) achieve overall higher performance than existing APCA techniques while even being more precise than certain dynamic ones including PATCH-SIM (92.9% vs. 83.0%). Further results reveal that the context information and program structures leveraged by Cache contributed significantly to its outstanding performance.  © 2022 Association for Computing Machinery.","Abreu R., Zoeteweij P., Van Gemund A.J.C., On the accuracy of spectrum-based fault localization, Testing: Academic and Industrial Conference Practice and Research Techniques-MUTATION IEEE, pp. 89-98, (2007); Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating sequences from structured representations of code, Proceedings of the 7th International Conference on Learning Representations, (2019); Alon U., Sadaka R., Levy O., Yahav E., Structural language models of code, Proceedings of 37th International Conference on Machine Learning, (2020); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation. ACM, pp. 404-419, (2018); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, pp. 401-4029, (2019); Alshammari A., Morris C., Hilton M., Bell J., FlakeFlagger: Predicting flakiness without rerunning tests, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE, pp. 1572-1584, (2021); Bader J., Scott A., Pradel M., Chandra S., Getafix: Learning to fix bugs automatically, Proceedings of the ACM on Programming Languages, 3, pp. 1591-15927, (2019); Breiman L., Friedman J.H., Olshen R.A., Stone C.J., Classification and Regression Trees, (1984); Brody S., Alon U., Yahav E., A structural model for contextual code changes, Proceedings of the ACM on Programming Languages, 4, pp. 1-28, (2020); Chakraborty S., Ding Y., Allamanis M., Ray B., CODIT: Code editing with treebased neural models, IEEE Transactions on Software Engineering, (2020); Chen L., Ouyang Y., Zhang L., Fast and precise on-The-fly patch validation for all, Proceedings of the 43rd International Conference on Software Engineering, (2021); Chen L., Pei Y., Furia C.A., Contract-based program repair without the contracts, Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering, pp. 637-647, (2017); Chen Z., James Kommrusch S., Tufano M., Pouchet L., Poshyvanyk D., Monperrus M., Sequencer: Sequence-To-sequence learning for end-To-end program repair, IEEE Trans. on Software Engineering, 2019, (2019); Csuvik V., Horvath D., Horvath F., Vidacs L., Utilizing source code embeddings to identify correct patches, Proceedings of the 2nd International Workshop on Intelligent Bug Fixing, pp. 18-25, (2020); Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-Training of deep bidirectional transformers for language understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4171-4186, (2019); Durieux T., Madeiral F., Martinez M., Abreu R., Empirical review of Java program repair tools: A large-scale experiment on 2, 141 bugs and 23, 551 repair attempts, Proceedings of the 27th ACM JointMeeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ACM, pp. 302-313, (2019); Durieux T., Monperrus M., DynaMoth: Dynamic code synthesis for automatic program repair, Proceedings of the 11th International Workshop in Automation of Software Test, pp. 85-91, (2016); Durieux T., Monperrus M., IntroClassJava: A Benchmark of 297 Small and Buggy Java Programs, (2016); Ernst M.D., Cockrell J., Griswold W.G., Notkin D., Dynamically discovering likely program invariants to support program evolution, IEEE Transactions on Software Engineering, 27, 2, pp. 99-123, (2001); Ernst M.D., Cockrell J., Griswold W.G., Notkin D., Dynamically discovering likely program invariants to support program evolution, IEEE Transactions on Software Engineering, 27, 2, pp. 99-123, (2001); Falleri J., Morandat F., Blanc X., Martinez M., Monperrus M., Fine-grained and accurate source code differencing, Proceedings of the 29th ACM/ IEEE International Conference on Automated Software Engineering. ACM, pp. 313-324, (2014); Fan Y., Xia X., Lo D., Hassan A.E., Chaff from the wheat: Characterizing and determining valid bug reports, IEEE Transactions on Software Engineering, 46, 5, pp. 495-525, (2018); Fraser G., Arcuri A., EvoSuite: Automatic test suite generation for object-oriented software, Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering, pp. 416-419, (2011); Guo A., Mao X., Yang D., Wang S., An empirical study on the effect of dynamic slicing on automated program repair efficiency, 2018 IEEE International Conference on Software Maintenance and Evolution (ICSME, pp. 554-558, (2018); Kam Ho T., Random decision forests, Proceedings of 3rd International Conference on Document Analysis and Recognition, 1, pp. 278-282, (1995); Hoang T., Jin Kang H., Lawall J., Lo D., CC2Vec: Distributed representations of code changes, Proceedings of the 42nd International Conference on Software Engineering, pp. 518-529, (2020); Hua J., Zhang M., Wang K., Khurshid S., Towards practical program repair with ondemand candidate generation, Proceedings of the 40th International Conference on Software Engineering, pp. 12-23, (2018); Jiang J., Xiong Y., Zhang H., Gao Q., Chen X., Shaping program repair space with existing patches and similar code, Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis. ACM, pp. 298-309, (2018); Just R., Jalali D., Ernst M.D., Defects4J: A database of existing faults to enable controlled testing studies for Java programs, Proceedings of the 23rd International Symposium on Software Testing and Analysis, pp. 437-440, (2014); Karampatsis R., Sutton C.A., How often do single-statement bugs occur the ManySStuBs4J dataset, Proceedings of the 17th Mining Software Repositories IEEE, (2020); Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2014); Kleinbaum D.G., Dietz K., Gail M., Klein M., Logistic Regression, (2002); Kovalenko V., Bogomolov E., Bryksin T., Bacchelli A., PathMiner: A library formining of path-based representations of code, 2019 IEEE/ACM16th International Conference on Mining Software Repositories MSR, pp. 13-17, (2019); Koyuncu A., Liu K., Bissyande T.F., Kim D., Klein J., Monperrus M., Le Traon Y., FixMiner: Mining Relevant Fix Patterns for Automated Program Repair, (2018); Le Q.V., Mikolov T., Distributed representations of sentences and documents, Proceedings of the 31st International Conference on Machine Learning. JMLR.org, pp. 1188-1196, (2014); Xuan-Bach D.L., Bao L., Lo D., Xia X., Li S., Pasareanu C., On reliability of patch correctness assessment, Proceedings of the 41st International Conference on Software Engineering, pp. 524-535, (2019); Xuan-Bach D.L., Chu D., Lo D., Le Goues C., Visser W., S3: Syntax-And semanticguided repair synthesis via programming by examples, Proceedings of the 11th Joint Meeting on Foundations of Software Engineering, pp. 593-604, (2017); Xuan Bach D.L., Lo D., Le Goues C., History driven program repair, Proceedings of the 23rd IEEE International Conference on Software Analysis, Evolution, and Reengineering, pp. 213-224, (2016); Xuan Bach D.L., Thung F., Lo D., Le Goues C., Overfitting in semantics-based automated program repair, Empirical Software Engineering, 23, 5, pp. 3007-3033, (2018); Le Goues C., Vu Nguyen T., Forrest S., Weimer W., GenProg: A generic method for automatic software repair, IEEE Transactions on Software Engineering, 38, 1, pp. 54-72, (2012); Le Goues C., Pradel M., Roychoudhury A., Automated program repair, Commun ACM, 62, 12, pp. 56-65, (2019); Li H., A short introduction to learning to rank, IEICE Transactions on Information and Systems, 94, 10, pp. 1854-1862, (2011); Li Y., Wang S., Nguyen T.N., Van Nguyen S., Improving bug detection via context-based code representation learning and attention-based neural networks, Proceedings of the ACM on Programming Languages, 3, pp. 1621-16230, (2019); Lin B., Wang S., Wen M., Zhang Z., Wu H., Qin Y., Mao X., Understanding the non-repairability factors of automated program repair techniques, 2020 27th Asia-Pacific Software Engineering Conference (APSEC, pp. 71-80, (2020); Lin D., Koppel J., Chen A., Solar-Lezama A., QuixBugs: A multi-lingual program repair benchmark set based on the Quixey challenge, Proceedings Companion of the 2017 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity. ACM, pp. 55-56, (2017); Liu K., Kim D., Bissyande T.F., Kim T., Kim K., Koyuncu A., Kim S., Le Traon Y., Learning to spot and refactor inconsistent method names, Proceedings of the 41st International Conference on Software Engineering, pp. 1-12, (2019); Liu K., Kim D., Koyuncu A., Li L., Bissyande T.F., Le Traon Y., A closer look at real-world patches, Proceedings of the 34th International Conference on Software Maintenance and Evolution, pp. 275-286, (2018); Liu K., Koyuncu A., Bissyande T.F., Kim D., Klein J., Le Traon Y., You cannot fix what you cannot find! An investigation of fault localization bias in benchmarking automated program repair systems, Proceedings of the 12th IEEE International Conference on Software Testing, Verification and Validation. IEEE, pp. 102-113, (2019); Liu K., Koyuncu A., Kim D., Bissyande T.F., AVATAR: Fixing semantic bugs with fix patterns of static analysis violations, Proceedings of the 26th IEEE International Conference on Software Analysis, Evolution and Reengineering. IEEE, pp. 456-467, (2019); Liu K., Koyuncu A., Kim D., Bissyande T.F., TBar: Revisiting template-based automated program repair, Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis. ACM, pp. 31-42, (2019); Liu K., Wang S., Koyuncu A., Kim K., Bissyande T.F., Kim D., Wu P., Klein J., Mao X., Le Traon Y., On the efficiency of test suite based program repair: A systematic assessment of 16 automated repair systems for Java programs, Proceedings of the 42nd International Conference on Software Engineering ACM, pp. 615-627, (2020); Liu X., Zhong H., Mining stackoverflow for program repair, Proceedings of the 25th IEEE International Conference on Software Analysis, Evolution and Reengineering. IEEE, pp. 118-129, (2018); Liu Z., Xia X., Yan M., Li S., Automating just-in-Time comment updating, Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering. ACM, (2020); Long F., Rinard M., Staged program repair with condition synthesis, Proceedings of the 10th Joint Meeting on Foundations of Software Engineering, pp. 166-178, (2015); Long F., Rinard M., An analysis of the search spaces for generate and validate patch generation systems, Proceedings of the 38th International Conference on Software Engineering, pp. 702-713, (2016); Cabrera Lozoya R., Baumann A., Sabetta A., Bezzi M., Commit2vec: Learning distributed representations of code changes, SN Computer Science, 2, 3, pp. 1-16, (2021); Lutellier T., Viet Pham H., Pang L., Li Y., Wei M., Tan L., CoCoNuT: Combining context-Aware neural translation models using ensemble for program repair, Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 101-114, (2020); Van Der L.M., Hinton G., Visualizing data using t-SNE, Journal of Machine Learning Research, 9, pp. 2579-2605, (2008); Madeiral F., Urli S., Maia M., Monperrus M., Bears: An extensible Java bug benchmark for automatic program repair studies, Proceedings of the 26th International Conference on Software Analysis, Evolution and Reengineering, pp. 468-478, (2019); Dan Marinescu P., Cadar C., KATCH: High-coverage testing of software patches, Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering, pp. 235-245, (2013); Martinez M., Monperrus M., Astor: A program repair library for Java (demo), Proceedings of the 25th International Symposium on Software Testing and Analysis, pp. 441-444, (2016); Martinez M., Monperrus M., Ultra-large repair search space with automatically mined templates: The Cardumen mode of Astor, Proceedings of the 10th International Symposium on Search Based Software Engineering, pp. 65-86, (2018); Monperrus M., The living review on automated program repair, HAL/Archives-Ouvertes. Fr, (2018); Nilizadeh A., Leavens G.T., Xuan-Bach D.L., Pasareanu C.S., Cok D.R., Exploring true test overfitting in dynamic automated program repair using formal methods, Proceedings of the 14th IEEE International Conference on Software Testing, Verification and Validation, (2021); Pacheco C., Ernst M.D., Randoop: Feedback-directed random testing for Java, Companion to the 22nd ACM SIGPLAN Conference on Object-oriented Programming Systems and Applications Companion, pp. 815-816, (2007); Patil T.R., Sunil Sherekar S., Performance analysis of Naive Bayes and J48 classification algorithm for data classification, International Journal of Computer Science and Applications, 6, 2, pp. 256-261, (2013); Qi Y., Mao X., Lei Y., Dai Z., Wang C., The strength of random search on automated program repair, Proceedings of the 36th International Conference on Software Engineering. ACM, pp. 254-265, (2014); Qin Y., Wang S., Liu K., Mao X., Bissyande T.F., On the impact of flaky tests in automated program repair, Proceedings of the 28th IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, pp. 295-306, (2021); Rubinstein R.Y., The cross-entropy method for combinatorial and continuous optimization, Methodology and Computing in Applied Probability, 1, pp. 127-190, (1999); Saha R., Lyu Y., Lam W., Yoshida H., Prasad M., Bugs.jar: A large-scale, diverse dataset of real-world Java bugs, Proceedings of the 15th IEEE/ACM International Conference on Mining Software Repositories. ACM, pp. 10-13, (2018); Smith E.K., Barr E.T., Le Goues C., Brun Y., Is the cure worse than the disease overfitting in automated program repair, Proceedings of the 10th Joint Meeting on Foundations of Software Engineering, pp. 532-543, (2015); Sobreira V., Durieux T., Madeiral F., Monperrus M., De Almeida Maia M., Dissection of a bug dataset: Anatomy of 395 patches from Defects4J, Proceedings of the 25th International Conference on Software Analysis, Evolution and Reengineering, pp. 130-140, (2018); Srivastava N., Hinton G.E., Krizhevsky A., Sutskever I., Salakhutdinov R., Dropout: A simple way to prevent neural networks from overfitting, Journal of Machine Learning Research, 15, pp. 1929-1958, (2014); Hwei Tan S., Yoshida H., Prasad M.R., Roychoudhury A., Anti-patterns in search-based program repair, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 727-738, (2016); Tenenbaum J.B., Freeman W.T., Separating style and content with bilinear models, Neural Computation, 12, 6, pp. 1247-1283, (2000); Tian H., Liu K., Kader Kabore A., Koyuncu A., Li L., Klein J., Bissyande T.F., Evaluating representation learning of code changes for predicting patch correctness in program repair, Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering. ACM, (2020); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in Neural Information Processing Systems, pp. 5998-6008, (2017); Wang S., Liu K., Lin B., Li L., Klein J., Mao X., Bissyande T.F., Beep: Fine-grained Fix Localization by Learning to Predict Buggy Code Elements, (2021); Wang S., Wen M., Chen L., Yi X., Mao X., How different is it between machinegenerated and developer-provided patches An empirical study on the correct patches generated by automated program repair techniques, Proceedings of the 13th International Symposium on Empirical Software Engineering and Measurement, pp. 1-12, (2019); Wang S., Wen M., Lin B., Mao X., Lightweight global and local contexts guided method name recommendation with prior knowledge, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE). ACM, pp. 741-753, (2021); Wang S., Wen M., Lin B., Wu H., Qin Y., Zou D., Mao X., Jin H., Automated patch correctness assessment: How far are we, Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering. ACM, pp. 968-980, (2020); Wen M., Chen J., Wu R., Hao D., Cheung S., Context-Aware patch generation for better automated program repair, Proceedings of the 40th International Conference on Software Engineering, pp. 1-11, (2018); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, 2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 87-98, (2016); Wu H., Zhang Z., Wang S., Lei Y., Lin B., Qin Y., Zhang H., Mao X., Peculiar: Smart contract vulnerability detection based on crucial data flow graph and pre-Training techniques, 2021 IEEE 32nd International Symposium on Software Reliability Engineering (ISSRE). IEEE, pp. 378-389, (2021); Xin Q., Reiss S.P., Identifying test-suite-overfitted patches through test case generation, Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis. ACM, pp. 226-236, (2017); Xin Q., Reiss S.P., Leveraging syntax-related code for automated program repair, Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering, pp. 660-670, (2017); Xiong Y., Liu X., Zeng M., Zhang L., Huang G., Identifying patch correctness in testbased program repair, Proceedings of the 40th International Conference on Software Engineering, pp. 789-799, (2018); Xiong Y., Wang J., Yan R., Zhang J., Han S., Huang G., Zhang L., Precise condition synthesis for program repair, Proceedings of the 39th IEEE/ACM International Conference on Software Engineering. IEEE, pp. 416-426, (2017); Xuan J., Martinez M., Demarco F., Clement M., Lamelas Marcote S., Durieux T., Le Berre D., Monperrus M., Nopol: Automatic repair of conditional statement bugs in Java programs, IEEE Transactions on Software Engineering, 43, 1, pp. 34-55, (2017); Yang B., Yang J., Exploring the differences between plausible and correct patches at fine-grained level, Proceedings of the 2nd International Workshop on Intelligent Bug Fixing IEEE, pp. 1-8, (2020); Yang J., Zhikhartsev A., Liu Y., Tan L., Better test cases for better automated program repair, Proceedings of the 11th Joint Meeting on Foundations of Software Engineering, pp. 831-841, (2017); Ye H., Gu J., Martinez M., Durieux T., Monperrus M., Automated classification of overfitting patches with statically extracted code features, IEEE Transactions on Software Engineering, 2021, (2021); Ye H., Martinez M., Monperrus M., Automated patch assessment for program repair at scale, Empirical Software Engineering, 26, 2, pp. 1-38, (2021); Yi J., Hwei Tan S., Mechtaev S., Bohme M., Roychoudhury A., A correlation study between automated program repair and test-suite metrics, Empirical Software Engineering, 23, 5, pp. 2948-2979, (2018); Yin P., Neubig G., Allamanis M., Brockschmidt M., Gaunt A.L., Learning to represent edits, International Conference on Learning Representations, (2019); Yu Z., Martinez M., Danglot B., Durieux T., Monperrus M., Alleviating patch overfitting with automatic test generation: A study of feasibility and effectiveness for the Nopol repair system, Empirical Software Engineering, 24, 1, pp. 33-67, (2019); Yuan Y., Banzhaf W., ARJA: Automated repair of Java programs via multi-objective genetic programming, IEEE Transactions on Software Engineering, (2018); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, pp. 783-794, (2019); Zhang X., Gupta N., Gupta R., Pruning dynamic slices with confidence, 2006 ACM SIGPLAN Conference on Programming Language Design and Implementation, (2006); Zhang Z., Lei Y., Mao X., Li P., CNN-FL: An effective approach for localizing faults using convolutional neural networks, 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, pp. 445-455, (2019); Zhao G., Huang J., DeepSim: Deep learning code functional similarity, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 141-151, (2018); Zou D., Liang J., Xiong Y., Ernst M.D., Zhang L., An empirical study of fault localization families and their combinations, IEEE Transactions on Software Engineering, 2019, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85130752121,128
Zhou C.; He P.; Zeng C.; Ma J.,"Zhou, Chunying (57488965500); He, Peng (55416866700); Zeng, Cheng (35241638700); Ma, Ju (57193682721)",57488965500; 55416866700; 35241638700; 57193682721,Software defect prediction with semantic and structural information of codes based on Graph Neural Networks,2022,Information and Software Technology,152,,107057,,,,21,10.1016/j.infsof.2022.107057,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137157816&doi=10.1016%2fj.infsof.2022.107057&partnerID=40&md5=740103e40f40a306ecea8e7469a5306f,"Context: Most defect prediction methods consider a series of traditional manually designed static code metrics. However, only using these hand-crafted features is impractical. Some researchers use the Convolutional Neural Network (CNN) to capture the potential semantic information based on the program's Syntax Trees (ASTs). In recent years, leveraging the dependency relationships between software modules to construct a software network and using network embedding models to capture the structural information have been helpful in defect prediction. This paper simultaneously takes the semantic and structural information into account and proposes a method called CGCN. Objective: This study aims to validate the feasibility and performance of the proposed method in software defect prediction. Method: Abstract Syntax Trees and a Class Dependency Network (CDN) are first generated based on the source code. For ASTs, symbolic tokens are extracted and encoded into vectors. The numerical vectors are then used as input to the CNN to capture the semantic information. For CDN, a Graph Convolutional Network (GCN) is used to learn the structural information of the network automatically. Afterward, the learned semantic and structural information are combined with different weights. Finally, we concatenate the learned features with traditional hand-crafted features to train a classifier for more accurate defect prediction. Results: The proposed method outperforms the state-of-the-art defect prediction models for both within-project prediction (including within-version and cross-version) and cross-project prediction on 21 open-source projects. In general, within-version prediction achieves better performance in the three prediction tasks. Conclusion: The proposed method of combining semantic and structural information can improve the performance of software defect prediction. © 2022 Elsevier B.V.","Feng S., Keung J., Yu X., Xiao Y., Zhang M., Investigation on the stability of SMOTE-based oversampling techniques in software defect prediction, Inf. Softw. Technol., 139, (2021); Xu Z., Liu J., Luo X., Yang Z., Zhang Y., Yuan P., Tang Y., Zhang T., Software defect prediction based on kernel PCA and weighted extreme learning machine, Inf. Softw. Technol., 106, pp. 182-200, (2019); Qu Y., Zheng Q., Chi J., Jin Y., He A., Cui D., Zhang H., Liu T., Using K-core decomposition on class dependency networks to improve bug prediction model's practical performance, IEEE Trans. Softw. Eng., 47, 2, pp. 348-366, (2019); Qu Y., Chi J., Yin H., Leveraging developer information for efficient effort-aware bug prediction, Inf. Softw. Technol., 137, (2021); Li J., He P., Zhu J., Lyu M.R., Software defect prediction via convolutional neural network, 2017 IEEE International Conference on Software Quality, Reliability and Security, QRS, pp. 318-328, (2017); Wang S., Liu T., Nam J., Tan L., Deep semantic feature learning for software defect prediction, IEEE Trans. Softw. Eng., 46, 12, pp. 1267-1293, (2018); Dam H.K., Tran T., Pham T.T.M., Ng S.W., Grundy J., Ghose A., Automatic feature learning for predicting vulnerable software components, IEEE Trans. Softw. Eng., (2018); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering, SANER, pp. 261-271, (2020); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering, ICSE, pp. 783-794, (2019); Chen L., Ma W., Zhou Y., Xu L., Wang Z., Chen Z., Xu B., Empirical analysis of network measures for predicting high severity software faults, Sci. China Inf. Sci., 59, 12, pp. 1-18, (2016); Li Y., Applying Social Network Analysis to Software Fault-Proneness Prediction, (2017); Ma W., Chen L., Yang Y., Zhou Y., Xu B., Empirical analysis of network measures for effort-aware fault-proneness prediction, Inf. Softw. Technol., 69, pp. 50-70, (2016); Qu Y., Yin H., Evaluating network embedding techniques’ performances in software bug prediction, Empir. Softw. Eng., 26, 4, pp. 1-44, (2021); Qu Y., Liu T., Chi J., Jin Y., Cui D., He A., Zheng Q., node2defect: Using network embedding to improve software defect prediction, 2018 33rd IEEE/ACM International Conference on Automated Software Engineering, ASE, pp. 844-849, (2018); Wu Z., Pan S., Chen F., Long G., Zhang C., Philip S.Y., A comprehensive survey on graph neural networks, IEEE Trans. Neural Netw. Learn. Syst., 32, 1, pp. 4-24, (2020); Zeng C., Zhou C.Y., Lv S.K., He P., Huang J., GCN2defect: Graph Convolutional Networks for SMOTETomek-based Software Defect Prediction, pp. 69-79, (2021); Mo R., Wei S., Feng Q., Li Z., An exploratory study of bug prediction at the method level, Inf. Softw. Technol., 144, (2022); Yu X., Keung J., Xiao Y., Feng S., Li F., Dai H., Predicting the precise number of software defects: Are we there yet?, Inf. Softw. Technol., 146, (2022); Bennin K.E., Keung J., Phannachitta P., Monden A., Mensah S., Mahakil: Diversity based oversampling approach to alleviate the class imbalance issue in software defect prediction, IEEE Trans. Softw. Eng., 44, 6, pp. 534-550, (2017); Yu X., Wu M., Jian Y., Bennin K.E., Fu M., Ma C., Cross-company defect prediction via semi-supervised clustering-based data filtering and MSTrA-based transfer learning, Soft Comput., 22, 10, pp. 3461-3472, (2018); Xu Z., Pang S., Zhang T., Luo X.-P., Liu J., Tang Y.-T., Yu X., Xue L., Cross project defect prediction via balanced distribution adaptation based transfer learning, J. Comput. Sci. Tech., 34, 5, pp. 1039-1062, (2019); Zhou T., Sun X., Xia X., Li B., Chen X., Improving defect prediction with deep forest, Inf. Softw. Technol., 114, pp. 204-216, (2019); He P., Li B., Liu X., Chen J., Ma Y., An empirical study on software defect prediction with a simplified metric set, Inf. Softw. Technol., 59, pp. 170-190, (2015); Zhao K., Xu Z., Zhang T., Tang Y., Yan M., Simplified deep forest model based just-in-time defect prediction for android mobile apps, IEEE Trans. Reliab., 70, 2, pp. 848-859, (2021); Zhao K., Xu Z., Yan M., Xue L., Li W., Catolino G., A compositional model for effort-aware Just-In-Time defect prediction on android apps, IET Softw., 16, 3, pp. 259-278, (2022); Xu Z., Li L., Yan M., Liu J., Luo X., Grundy J., Zhang Y., Zhang X., A comprehensive comparative study of clustering-based unsupervised defect prediction models, J. Syst. Softw., 172, (2021); Yu X., Liu J., Keung J.W., Li Q., Bennin K.E., Xu Z., Wang J., Cui X., Improving ranking-oriented defect prediction using a cost-sensitive ranking SVM, IEEE Trans. Reliab., 69, 1, pp. 139-153, (2019); Yu X., Bennin K.E., Liu J., Keung J.W., Yin X., Xu Z., An empirical study of learning to rank techniques for effort-aware defect prediction, 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering, SANER, pp. 298-309, (2019); He Z., Peters F., Menzies T., Yang Y., Learning from open-source projects: An empirical study on defect prediction, 2013 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, pp. 45-54, (2013); Phan A.V., Le Nguyen M., Bui L.T., Convolutional neural networks over control flow graphs for software defect prediction, 2017 IEEE 29th International Conference on Tools with Artificial Intelligence, ICTAI, pp. 45-52, (2017); Xu Z., Li S., Xu J., Liu J., Luo X., Zhang Y., Zhang T., Keung J., Tang Y., LDFR: Learning deep feature representation for software defect prediction, J. Syst. Softw., 158, (2019); Perozzi B., Al-Rfou R., Skiena S., Deepwalk: Online learning of social representations, pp. 701-710, (2014); Tang J., Qu M., Wang M., Zhang M., Yan J., Mei Q., Line: Large-scale information network embedding, pp. 1067-1077, (2015); Grover A., Leskovec J., node2vec: Scalable feature learning for networks, pp. 855-864, (2016); Hamilton W., Ying Z., Leskovec J., Inductive representation learning on large graphs, Adv. Neural Inf. Process. Syst., 30, (2017); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, (2016); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); Lin C., Ouyang Z., Zhuang J., Chen J., Li H., Wu R., Improving code summarization with block-wise abstract syntax tree splitting, 2021 IEEE/ACM 29th International Conference on Program Comprehension, ICPC, pp. 184-195, (2021); Guo B., Zhang C., Liu J., Ma X., Improving text classification with weighted word embeddings via a multi-channel TextCNN model, Neurocomputing, 363, pp. 366-374, (2019); Ma X., Keung J., Yang Z., Yu X., Li Y., Zhang H., CASMS: Combining clustering with attention semantic model for identifying security bug reports, Inf. Softw. Technol., 147, (2022); Tan Z., Chen J., Kang Q., Zhou M., Abusorrah A., Sedraoui K., Dynamic embedding projection-gated convolutional neural networks for text classification, IEEE Trans. Neural Netw. Learn. Syst., (2021); Yang C.-H.H., Qi J., Chen S.Y.-C., Chen P.-Y., Siniscalchi S.M., Ma X., Lee C.-H., Decentralizing feature extraction with quantum convolutional neural network for automatic speech recognition, ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP, pp. 6523-6527, (2021); Yun S., Oh S.J., Heo B., Han D., Choe J., Chun S., Re-labeling imagenet: from single to multi-labels, from global to localized labels, pp. 2340-2350, (2021); He P., Li B., Ma Y., He L., Using software dependency to bug prediction, Math. Probl. Eng., 2013, (2013); He P., Wang P., Li B., Hu S.-W., An evolution analysis of software system based on multi-granularity software network, Acta Electon. Sin., 46, 2, (2018); Chawla N.V., Bowyer K.W., Hall L.O., Kegelmeyer W.P., SMOTE: synthetic minority over-sampling technique, J. Artificial Intelligence Res., 16, pp. 321-357, (2002); Weiss G.M., Foundations of imbalanced learning, Imbalanced Learning: Foundations, Algorithms, and Applications, pp. 13-41, (2013); Zeng M., Zou B., Wei F., Liu X., Wang L., Effective prediction of three common diseases by combining SMOTE with tomek links technique for imbalanced medical data, 2016 IEEE International Conference of Online Analysis and Computing Science, ICOACS, pp. 225-228, (2016); Zhao Y., Wang Y., Zhang Y., Zhang D., Gong Y., Jin D., ST-TLF: Cross-version defect prediction framework based transfer learning, Inf. Softw. Technol., 149, (2022); Bennin K.E., Tahir A., MacDonell S.G., Borstler J., An empirical study on the effectiveness of data resampling approaches for cross-project software defect prediction, IET Softw., 16, 2, pp. 185-199, (2022); Cliff N., Ordinal Methods for Behavioral Data Analysis, (2014); Le P., Zuidema W., Quantifying the vanishing gradient and long distance dependency problem in recursive neural networks and recursive LSTMs, (2016); Zhen Y., Keung J.W., Xiao Y., Yan X., Zhi J., Zhang J., On the significance of category prediction for code-comment synchronization, ACM Trans. Softw. Eng. Methodol., (2022); Zhang F., Yu X., Keung J., Li F., Xie Z., Yang Z., Ma C., Zhang Z., Improving Stack Overflow question title generation with copying enhanced CodeBERT model and bi-modal information, Inf. Softw. Technol., 148, (2022); Zhu X., Sobihani P., Guo H., Long short-term memory over recursive structures, International Conference on Machine Learning, pp. 1604-1612, (2015); Herbold S., Trautsch A., Grabowski J., A comparative study to benchmark cross-project defect prediction approaches, IEEE Trans. Softw. Eng., 44, 9, pp. 811-833, (2017)",,,,,,English,Article,Final,,Scopus,2-s2.0-85137157816,129
Zhu Z.; Tong H.; Wang Y.; Li Y.,"Zhu, Ziye (57208496559); Tong, Hanghang (7201360533); Wang, Yu (57671264800); Li, Yun (57192529112)",57208496559; 7201360533; 57671264800; 57192529112,Enhancing bug localization with bug report decomposition and code hierarchical network,2022,Knowledge-Based Systems,248,,108741,,,,3,10.1016/j.knosys.2022.108741,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129970669&doi=10.1016%2fj.knosys.2022.108741&partnerID=40&md5=dcf53451ff1638c350a605c6a6f43b2a,"Bug localization, which aims to locate buggy source code files for given bug reports, is a crucial yet challenging software-mining task. Despite remarkable success, the state of the art falls short in handling (1) bug reports with diverse characteristics and (2) programs with wildly different behaviors. In response, this paper proposes a graph-based neural model BLOCO for automated bug localization. To be specific, our proposed model decomposes bug reports into several bug clues to capture bug-related information from various perspectives for highly diverse bug reports. To understand the program in depth, we first design a code hierarchical network structure, Code-NoN, based on basic blocks to represent source code files. Correspondingly, a multilayer graph neural network is tailored to capture program behaviors from the Code-NoN structure of each source code file. Finally, BLOCO further incorporates a bi-affine classifier to comprehensively predict the relationship between the bug reports and source files. Extensive experiments on five large-scale real-world projects demonstrate that the proposed model significantly outperforms existing techniques. © 2022 Elsevier B.V.","Zhou J., Zhang H., Lo D., Where should the bugs be fixed?-more accurate information retrieval-based bug localization based on bug reports, pp. 14-24, (2012); Li X., Jiang H., Liu D., Ren Z., Li G., Unsupervised deep bug report summarization, pp. 144-155, (2018); Wang Q., Parnin C., Orso A., Evaluating the usefulness of IR-based fault localization techniques, Proceedings of the 2015 International Symposium on Software Testing and Analysis, pp. 1-11, (2015); Tian Y., Wijedasa D., Lo D., pp. 1-10, (2016); Du X., Zheng Z., Xiao G., Yin B., The automatic classification of fault trigger based bug report, 2017 IEEE International Symposium on Software Reliability Engineering Workshops, pp. 259-265, (2017); Du X., Zheng Z., Xiao G., Zhou Z., Trivedi K.S., DeepSIM: Deep semantic information-based automatic mandelbug classification, IEEE Trans. Reliab., (2021); Xiao G., Zheng Z., Yin B., Trivedi K.S., Du X., Cai K.-Y., An empirical study of fault triggers in the linux operating system: An evolutionary perspective, IEEE Trans. Reliab., 68, 4, pp. 1356-1383, (2019); Kim D., Tao Y., Kim S., Zeller A., Where should we fix this bug? A two-phase recommendation model, IEEE Trans. Softw. Eng., 39, 11, pp. 1597-1610, (2013); Ye X., Bunescu R., Liu C., Learning to rank relevant files for bug reports using domain knowledge, pp. 689-699, (2014); Wang Y., Yao Y., Tong H., Huo X., Li M., Xu F., Lu J., Bug localization via supervised topic modeling, Proceedings of the 2018 IEEE International Conference on Data Mining, pp. 607-616, (2018); Gharibi R., Rasekh A.H., Sadreddini M.H., Fakhrahmad S.M., Leveraging textual properties of bug reports to localize relevant source files, Inf. Process. Manage., 54, 6, pp. 1058-1076, (2018); Lam A.N., Nguyen A.T., Nguyen H.A., Nguyen T.N., Bug localization with combination of deep learning and information retrieval, pp. 218-229, (2017); Xiao Y., Keung J., Mi Q., Bennin K.E., Improving bug localization with an enhanced convolutional neural network, Proceedings of the 24th Asia-Pacific Software Engineering Conference, pp. 338-347, (2017); Huo X., Li M., Zhou Z.-H., Learning unified features from natural and programming languages for locating buggy source code, pp. 1606-1612, (2016); Xiao Y., Keung J., Mi Q., Bennin K.E., Bug localization with semantic and structural features using convolutional neural network and cascade forest, pp. 101-111, (2018); Huo X., Li M., Enhancing the unified features to locate buggy files by exploiting the sequential nature of source code, pp. 1909-1915, (2017); Kim Y., Convolutional neural networks for sentence classification, pp. 1746-1751, (2014); Zhu Z., Li Y., Wang Y., Wang Y., Tong H., A deep multimodal model for bug localization, Data Min. Knowl. Discov., 35, 4, pp. 1369-1392., (2021); Bahdanau D., Cho K., Bengio Y., Neural machine translation by jointly learning to align and translate, pp. 1-15, (2015); Liang H., Sun L., Wang M., Yang Y., Deep learning with customized abstract syntax tree for bug localization, IEEE Access, 7, pp. 116309-116320, (2019); Zhang J., Xie R., Ye W., Zhang Y., Zhang S., Exploiting code knowledge graph for bug localization via bi-directional attention, pp. 219-229, (2020); Huo X., Li M., Zhou Z.-H., Control flow graph embedding based on multi-instance decomposition for bug localization, pp. 4223-4230, (2020); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in Neural Information Processing Systems, pp. 3111-3119, (2013); Lee G., Jeong J., Seo S., Kim C., Kang P., Sentiment classification with word localization based on weakly supervised learning with a convolutional neural network, Knowl.-Based Syst., 152, pp. 70-82, (2018); Ni J., Tong H., Fan W., Zhang X., Inside the atoms: Ranking on a network of networks, pp. 1356-1365, (2014); Ni J., Tong H., Fan W., Zhang X., Flexible and robust multi-network clustering, pp. 835-844, (2015); Binkley D., Davis M., Lawrie D., Morrell C., To camelcase or under_score, Proceedings of the 17th International Conference on Program Comprehension, pp. 158-167, (2009); Kampffmeyer M., Chen Y., Liang X., Wang H., Zhang Y., Xing E.P., Rethinking knowledge graph propagation for zero-shot learning, pp. 11487-11496, (2019); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, pp. 1-14, (2017); Zhang L., Kang Z., Sun X., Sun H., Zhang B., Pu D., KCRec: Knowledge-aware representation graph convolutional network for recommendation, Knowl.-Based Syst., 230, (2021); Dozat T., Manning C.D., Deep biaffine attention for neural dependency parsing, pp. 1-8, (2017); Kingma D.P., Ba J., Adam: A method for stochastic optimization, pp. 1-15, (2015); Zhu Z., Li Y., Tong H., Wang Y., COOBA: Cross-project bug localization via adversarial transfer learning, pp. 3565-3571, (2020); Marcus A., Sergeyev A., Rajlich V., Maletic J.I., An information retrieval approach to concept location in source code, pp. 214-223, (2004); Lukins S.K., Kraft N.A., Etzkorn L.H., Source code retrieval for bug localization using latent dirichlet allocation, pp. 155-164, (2008); Hoang T., Oentaryo R.J., Le T.-D.B., Lo D., Network-clustered multi-modal bug localization, IEEE Trans. Softw. Eng., 45, 10, pp. 1002-1023, (2018); Shi Z., Keung J., Bennin K.E., Zhang X., Comparing learning to rank techniques in hybrid bug localization, Appl. Soft Comput., 62, pp. 636-648, (2018); Algan G., Ulusoy I., Image classification with deep learning in the presence of noisy labels: A survey, Knowl.-Based Syst., 215, (2021); Tian C., Xu Y., Zuo W., Du B., Lin C.-W., Zhang D., Designing and training of a dual CNN for image denoising, Knowl.-Based Syst., 226, (2021); Zhang S., Chen M., Chen J., Li Y.-F., Wu Y., Li M., Zhu C., Combining cross-modal knowledge transfer and semi-supervised learning for speech emotion recognition, Knowl.-Based Syst., 229, (2021); Wang Q., Feng C., Xu Y., Zhong H., Sheng V.S., A novel privacy-preserving speech recognition framework using bidirectional LSTM, J. Cloud Comput., 9, 1, pp. 1-13, (2020); Wang Y., Li Y., Zhu Z., Tong H., Huang Y., Adversarial learning for multi-task sequence labeling with attention mechanism, IEEE/ACM Trans. Audio Speech Lang. Process., 28, pp. 2476-2488, (2020); Beigi G., Shu K., Guo R., Wang S., Liu H., Privacy preserving text representation learning, pp. 275-276, (2019); Li X., Zhang R., Wang Q., Zhang H., Autoencoder constrained clustering with adaptive neighbors, IEEE Trans. Neural Netw. Learn. Syst., 32, 1, pp. 443-449, (2021); Ding K., Li J., Liu H., Interactive anomaly detection on attributed networks, pp. 357-365, (2019); Pandey S.K., Tripathi A.K., BCV-predictor: A bug count vector predictor of a successive version of the software system, Knowl.-Based Syst., 197, (2020); Hoang T., Lawall J., Tian Y., Oentaryo R.J., Lo D., PatchNet: Hierarchical deep learning-based stable patch identification for the linux kernel, IEEE Trans. Softw. Eng., 47, 11, pp. 2471-2486, (2021); Huo X., Thung F., Li M., Lo D., Shi S.-T., Deep transfer bug localization, IEEE Trans. Softw. Eng., 47, 7, pp. 1368-1380, (2021); Wan X., Zheng Z., Qin F., Qiao Y., Trivedi K.S., Supervised representation learning approach for cross-project aging-related bug prediction, Proceedings of the 30th International Symposium on Software Reliability Engineering, pp. 163-172, (2019); Mou L., Li G., Jin Z., Zhang L., Wang T., TBCNN: A tree-based convolutional neural network for programming language processing, (2014); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings of the 41st International Conference on Software Engineering, pp. 783-794, (2019)",,,,,,English,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85129970669,130
Ma Y.-F.; Li M.,"Ma, Yi-Fan (57456232500); Li, Ming (56994181000)",57456232500; 56994181000,The flowing nature matters: feature learning from the control flow graph of source code for bug localization,2022,Machine Learning,111,3,,853,870,17,7,10.1007/s10994-021-06078-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124741118&doi=10.1007%2fs10994-021-06078-4&partnerID=40&md5=0b5e48501b89aea5d491f3dc8a1b3770,"Bug localization plays an important role in software maintenance. Traditional works treat the source code from the lexical perspective, while some recent researches indicate that exploiting the program structure is beneficial for improving bug localization. Control flow graph (CFG) is a widely used graph representation, which essentially represents the program structure. Although using graph neural network for feature learning is a straightforward way and has been proven effective in various software mining problems, this approach is inappropriate since adjacent nodes in the CFG could be totally unrelated in semantics. On the other hand, previous statements may affect the semantics of subsequent statements along the execution path, which we call the flowing nature of control flow graph. In this paper, we claim that the flowing nature should be explicitly considered and propose a novel model named cFlow for bug localization, which employs a particular designed flow-based GRU for feature learning from the CFG. The flow-based GRU exploits the program structure represented by the CFG to transmit the semantics of statements along the execution path, which reflects the flowing nature. Experimental results on widely-used real-world software projects show that cFlow significantly outperforms the state-of-the-art bug localization methods, indicating that exploiting the program structure from the CFG with respect to the flowing nature is beneficial for improving bug localization. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature.","Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, International Conference on Learning Representations, (2018); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proc. ACM Program. Lang., 3, (2019); Feng Z., Guo D., Tang D.-Y., Duan N., Feng X.-C., Gong M., Shou L.-J., Qin B., Liu T., Jiang D., Et al., CodeBERT: A pre-trained model for programming and natural languages, In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, pp. 1536-1547, (2020); Fischer M., Pinzger M., Gall H., Populating a release history database from version control and bug tracking systems, In International Conference on Software Maintenance, 2003. ICSM 2003. Proceedings., pp. 23-32, (2003); Gay G., Haiduc S., Marcus A., Menzies T., On the use of relevance feedback in ir-based concept location, In 2009 IEEE International Conference on Software Maintenance, pp. 351-360, (2009); Grover A., Leskovec J., Node2vec: Scalable feature learning for networks, Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 855-864, (2016); Huo X., Li M., Enhancing the unified features to locate buggy files by exploiting the sequential nature of source code, Proceedings of the 25Th International Joint Conference on Artificial Intelligence, pp. 1909-1915, (2017); Huo X., Li M., Zhou Z.-H., Learning unified features from natural and programming languages for locating buggy source code, Proceedings of the 25Th International Joint Conference on Artificial Intelligence, pp. 1606-1612, (2016); Control flow graph embedding based on multi-instance decomposition for bug localization, Proceedings of the 34Th AAAI Conference on Artificial Intelligence, Volume 34, pp. 4223-4230, (2020); Huo X., Thung F., Li M., Lo D., Shi S.-T., Deep transfer bug localization, IEEE Transactions on Software Engineering, (2019); Kim Y., Convolutional neural networks for sentence classification, Proceedings of the Conference on Empirical Methods in Natural Lanugage Processing, pp. 1746-1751, (2014); Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2014); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5Th International Conference on Learning Representations, (2017); Kochhar P.S., Tian Y., Lo D., Potential biases in bug localization: Do they matter?, Proceedings of the 29Th ACM/IEEE International Conference on Automated Software Engineering, pp. 803-814, (2014); Lam A.N., Nguyen A.T., Nguyen H.A., Nguyen T.N., Combining deep learning with information retrieval to localize buggy files for bug reports, 2015 30Th IEEE/ACM International Conference on Automated Software Engineering, pp. 476-481, (2015); Lam A.N., Nguyen A.T., Nguyen H.A., Nguyen T.N., Bug localization with combination of deep learning and information retrieval, 2017 IEEE/ACM 25Th International Conference on Program Comprehension, pp. 218-229, (2017); Li Y., Wang S.-H., Nguyen T.N., Dlfix: Context-based code transformation learning for automated program repair, Proceedings of the ACM/IEEE 42Nd International Conference on Software Engineering, ICSE ’20, pp. 602-614, (2020); Li Y., Wang S.-H., Nguyen T.N., Van Nguyen S., Improving bug detection via context-based code representation learning and attention-based neural networks, Proc. ACM Program. Lang., 3, (2019); Li Y.-J., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, (2015); Lukins S.K., Kraft N.A., Etzkorn L.H., Source code retrieval for bug localization using latent dirichlet allocation, 2008 15Th Working Conference on Reverse Engineering, pp. 155-164, (2008); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, (2013); Mou L.-L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Proceedings of the AAAI Conference on Artificial Intelligence, 30, 1, (2016); Niepert M., Ahmed M., Kutzkov K., Learning convolutional neural networks for graphs, Proceedings of the 33Rd International Conference on Machine Learning, Volume 48 of Proceedings of Machine Learning Research, pp. 2014-2023, (2016); Perozzi B., Al-Rfou R., Skiena S., Deepwalk: Online learning of social representations, Proceedings of the 20Th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 701-710, (2014); Poshyvanyk D., Gueheneuc Y.-G., Marcus A., Antoniol G., Rajlich V., Feature location using probabilistic ranking of methods based on execution scenarios and information retrieval, IEEE Transactions on Software Engineering, 33, 6, pp. 420-432, (2007); Rahman M.M., Roy C.K., Improving ir-based bug localization with context-aware query reformulation, Proceedings of the 2018 26Th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 621-632, (2018); Shi S.-T., Li M., Lo D., Thung F., Huo X., Automatic code review by learning the revision of source code, Proceedings of the AAAI Conference on Artificial Intelligence, 33, 1, pp. 4910-4917, (2019); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, International Conference on Learning Representations, (2018); Wei H.-H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, In Proceedings of the 26Th International Joint Conference on Artificial Intelligence, pp. 3034-3040, (2017); White M., Vendome C., Linares-Vasquez M., Poshyvanyk D., Toward deep learning software repositories, 2015 IEEE/ACM 12Th Working Conference on Mining Software Repositories, pp. 334-345, (2015); Ye X., Bunescu R., Liu C., Learning to rank relevant files for bug reports using domain knowledge, Proceedings of the 22Nd ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 689-699, (2014); Youm K.C., Ahn J., Lee E., Improved bug localization based on code change histories and bug reports, Information and Software Technology, 82, pp. 177-192, (2017); Zhang J.-L., Xie R., Ye W., Zhang Y.-H., Zhang S.-K., Exploiting code knowledge graph for bug localization via bi-directional attention, Proceedings of the 28Th International Conference on Program Comprehension, pp. 219-229, (2020); Zhang Y.-Y., Li M., Find me if you can: Deep software clone detection by exploiting the contest between the plagiarist and the detector, Proceedings of the AAAI Conference on Artificial Intelligence, 33, 1, pp. 5813-5820, (2019); Zhou J., Zhang H.-Y., Lo D., Where should the bugs be fixed? More accurate information retrieval-based bug localization based on bug reports, 2012 34Th International Conference on Software Engineering, pp. 14-24, (2012); Zhou Y.-Q., Liu S.-Q., Siow J., Du X.-N., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, In Advances in Neural Information Processing Systems, 32, pp. 10197-10207, (2019)",,,,,,English,Article,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85124741118,131
Deng X.; He P.; Zhou C.Y.,"Deng, Xuan (57872003900); He, Peng (55416866700); Zhou, Chun Ying (57488965500)",57872003900; 55416866700; 57488965500,Data Selection for Cross-Project Defect Prediction with Local and Global Features of Source Code,2022,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",,,,216,219,3,0,10.18293/SEKE2022-086,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137158661&doi=10.18293%2fSEKE2022-086&partnerID=40&md5=4ea2bcb83fee6ceea53c18fb4ca971e3,"An open challenge for cross-project defect prediction (CPDP) is how to select the most appropriate training data for target project to build quality predictor. To our knowledge, existing methods are mostly dominated by traditional hand-crafted features, which do not fully encode the global structure between codes nor the semantics of code tokens. This work is to propose an improved method which is capable of automatically learning features for representing source code, and uses these feataures for training data selection. First, we propose a framework ALGoF to automatically learn the local semantic and global structural features of code files. Then, we analyze the feasibility of the learned features for data selection. Besides, we also validate the effectiveness of ALGoF by comparing with the traditional method. The experiments have been conducted on six defect datasets available at the PROMISE repository. The results show that ALGoF method helps to guide the training data selection for CPDP, and achieves a 48.31% improvement rate of F-measure. Meanwhile, our method has statistically significant advantages over the traditional method, especially when using both the local semantic and global structural features as the representation of code files. The maximum improvement of F-measure can reach 42.6%. © 2022 Knowledge Systems Institute Graduate School. All rights reserved.","Peters F, Menzies T, Marcus A., Better cross company defect prediction[C], Proceedings of the 10th MSR, pp. 409-418, (2013); Grover A., Leskovec J., node2vec: scalable feature learning for networks[C], Proc. of ACM SIGKDD Inte. Conf. on Know. Dis.& Data Min, (2016); Ryu D, Jang J I, Baik J, Et al., A Hybrid Instance Selection Using Nearest-Neighbor for Cross-Project Defect Prediction[J], Journal of Computer Science & Technology, 30, pp. 969-980, (2015); He P, He Y, Yu L, Et al., An Improved Method for Cross-Project Defect Prediction by Simplifying Training Data[J], Mathematical Problems in Engineering, (2018); Hosseini S., Turhan B., Mantyla M., A benchmark study on the effectiveness of search-based data selection and feature selection for cross project defect prediction, Inf. Softw. Technol, 95, pp. 296-312, (2018); Hosseini S, Turhan B., A comparison of similarity based instance selection methods for cross project defect prediction[C], 36th ACM/SIGAPP Symposium on Applied Computing, pp. 1455-1464, (2021); Wang S, Liu T, Nam J, Et al., Deep Semantic Feature Learning for Software Defect Prediction[J], IEEE Transactions on Software Engineering, 46, 12, pp. 1267-1293, (2020); Bin Y., Zhou K., Lu H., Zhou Y., Xu B., Training data selection for cross-project defection prediction: Which approach is better?[C], Int. Sym. on Emp. Soft. Eng. & Meas, pp. 354-363, (2017); Phan A. V., Nguyen M. L., Bui L. T., Convolutional Neural Networks over Control Flow Graphs for Software Defect Prediction, (2018); Qu Y, Liu T, Chi J, Et al., node2defect: using network embedding to improve software defect prediction[C], The 33rd ACM/IEEE Inte. Conf. on Automated Software Engineering, pp. 844-849, (2018); Zeng C, Zhou C Yi, Lv S K, Et al., GCN2defect：Graph Convolutional Networks for SmoteTomek-based Software Defect Prediction, The 32nd Inter. Sym. on Software Reliability Engineering (ISSRE 2021)",Knowledge Systems Institute Graduate School; KSI Research Inc.,"34th International Conference on Software Engineering and Knowledge Engineering, SEKE 2022",1 July 2022 through 10 July 2022,Pittsburgh,182297,English,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85137158661,132
Sikic L.; Kurdija A.S.; Vladimir K.; Silic M.,"Sikic, Lucija (57209640612); Kurdija, Adrian Satja (55123204200); Vladimir, Klemo (24831165400); Silic, Marin (36462812000)",57209640612; 55123204200; 24831165400; 36462812000,Graph Neural Network for Source Code Defect Prediction,2022,IEEE Access,10,,,10402,10415,13,29,10.1109/ACCESS.2022.3144598,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123383541&doi=10.1109%2fACCESS.2022.3144598&partnerID=40&md5=6f026f26f6828fe3c1f1e28156cf823d,"Predicting defective software modules before testing is a useful operation that ensures that the time and cost of software testing can be reduced. In recent years, several models have been proposed for this purpose, most of which are built using deep learning-based methods. However, most of these models do not take full advantage of a source code as they ignore its tree structure or they focus only on a small part of a code. To investigate whether and to what extent information from this structure can be beneficial in predicting defective source code, we developed an end-to-end model based on a convolutional graph neural network (GCNN) for defect prediction, whose architecture can be adapted to the analyzed software, so that projects of different sizes can be processed with the same level of detail. The model processes the information of the nodes and edges from the abstract syntax tree (AST) of the source code of a software module and classifies the module as defective or not defective based on this information. Experiments on open source projects written in Java have shown that the proposed model performs significantly better than traditional defect prediction models in terms of AUC and F-score. Based on the F-scores of the existing <italic>state-of-the-art</italic> models, the model has shown comparable predictive capabilities for the analyzed projects. © 2022 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Menzies T., Milton Z., Turhan B., Cukic B., Jiang Y., Bener A., Defect prediction from static code features: Current results, limitations, new approaches, Autom. Softw. Eng., 17, 2, pp. 375-407, (2010); Lecun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, pp. 436-444, (2015); Wang S., Liu T., Nam J., Tan L., Deep semantic feature learning for software defect prediction, IEEE Trans. Softw. Eng., 46, 12, pp. 1267-1293, (2020); Li J., He P., Zhu J., Lyu M.R., Software defect prediction via convolutional neural network, Proc. Int. Conf. Softw. Qual., Rel. Secur. (QRS), pp. 318-328, (2017); Pan C., Lu M., Xu B., Gao H., An improved CNN model for withinproject software defect prediction, Appl. Sci., 9, 10, (2019); Shi K., Lu Y., Liu G., Wei Z., Chang J., MPT-embedding: An unsupervised representation learning of code for software defect prediction, J. Softw., Evol. Process., 33, 4, (2021); Meilong S., He P., Xiao H., Li H., Zeng C., An approach to semantic and structural features learning for software defect prediction, Math. Problems Eng., 2020, (2020); Dam H.K., Pham T., Ng S.W., Tran T., Grundy J., Ghose A., Kim T., Kim C.-J., Lessons learned from using a deep tree-based model for software defect prediction in practice, Proc. IEEE/ACM 16th Int. Conf. Mining Softw. Repositories (MSR), pp. 46-57, (2019); Liang H., Yu Y., Jiang L., Xie Z., Seml: A semantic LSTM model for software defect prediction, IEEE Access, 7, pp. 83812-83824, (2019); Fan G., Diao X., Yu H., Yang K., Chen L., Software defect prediction via attention-based recurrent neural network, Sci. Program., 2019, (2019); Zhang Q., Wu B., Software defect prediction via transformer, Proc. IEEE 4th Inf. Technol., Netw., Electron. Autom. Control Conf. (ITNEC), pp. 874-879, (2020); Xu J., Wang F., Ai J., Defect prediction with semantics and context features of codes based on graph representation learning, IEEE Trans. Rel., 70, 2, pp. 613-625, (2021); Zhao Z., Yang B., Li G., Liu H., Jin Z., Precise learning of source code contextual semantics via hierarchical dependence structure and graph attention networks, J. Syst. Softw., 184, (2022); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proc. IEEE/ACM 41st Int. Conf. Softw. Eng. (ICSE), pp. 783-794, (2019); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Proc. AAAI Conf. Artif. Intell., pp. 1287-1293, (2016); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proc. 31st IEEE/ACM Int. Conf. Autom. Softw. Eng., pp. 87-98, (2016); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, Proc. IEEE 27th Int. Conf. Softw. Anal., Evol. Reengineering (SANER), pp. 261-271, (2020); Zhao J., Xia K., Fu Y., Cui B., An AST-based code plagiarism detection algorithm, Proc. 10th Int. Conf. Broadband Wireless Comput., Commun. Appl. (BWCCA), pp. 178-182, (2015); Feng J., Cui B., Xia K., A code comparison algorithm based on ast for plagiarism detection, Proc. 4th Int. Conf. Emerg. Intell. Data Web Technol., pp. 393-397, (2013); Bogdanova A., Source code authorship attribution using file embeddings, Proc. ACM SIGPLAN Int. Conf. Syst., Program., Lang., Appl., Softw. Hum., pp. 31-33, (2021); Ullah F., Jabbar S., Al-Turjman F., Programmers' de-anonymization using a hybrid approach of abstract syntax tree and deep learning, Tech-nol. Forecasting Social Change, 159, (2020); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, (2017); Song Q., Jia Z., Shepperd M., Ying S., Liu J., A general software defect-proneness prediction framework, IEEE Trans. Softw. Eng., 37, 3, pp. 356-370, (2010); Dong G., Liu H., Feature engineering for machine learning and data analytics, Feature Generation and Engineering for Software Analytics, pp. 335-358, (2018); Okutan A., Yldz O.T., Software defect prediction using Bayesian networks, Empirical Softw. Eng., 19, 1, pp. 154-181, (2014); Madeyski L., Jureczko M., Which process metrics can significantly improve defect prediction models? An empirical study, Softw. Qual. J., 23, 3, pp. 393-422, (2014); Jiang L., Jiang S., Gong L., Dong Y., Yu Q., Which process metrics are significantly important to change of defects in evolving projects: An empirical study, IEEE Access, 8, pp. 93705-93722, (2020); Bronstein M.M., Bruna J., Lecun Y., Szlam A., Vandergheynst P., Geometric deep learning: Going beyond Euclidean data, IEEE Signal Process. Mag., 34, 4, pp. 18-42, (2017); Ronald Ward I., Joyner J., Lickfold C., Guo Y., Bennamoun M., A Practical Tutorial on Graph Neural Networks, (2020); Defferrard M., Bresson X., Vandergheynst P., Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering, (2016); Bianchi F.M., Grattarola D., Alippi C., Spectral clustering with graph neural networks for graph pooling, Proc. Int. Conf. Mach. Learn., pp. 874-883, (2020); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, (2014); Prechelt L., Early stopping-but when?, Neural Networks: Tricks of the Trade, pp. 55-69, (1998); Jureczko M., Madeyski L., Towards identifying software project clusters with regard to defect prediction, Proc. 6th Int. Conf. Predictive Models Softw. Eng., pp. 1-10, (2010); Jiang Y., Lin J., Cukic B., Menzies T., Variance analysis in software fault prediction models, Proc. 20th Int. Symp. Softw. Rel. Eng., pp. 99-108, (2009); Lujan-Moreno G.A., Howard P.R., Rojas O.G., Montgomery D.C., Design of experiments and response surface methodology to tune machine learning hyperparameters, with a random forest case-study, Expert Syst. Appl., 109, pp. 195-205, (2018); Khoshgoftaar T.M., Gao K., Feature selection with imbalanced data for software defect prediction, Proc. Int. Conf. Mach. Learn. Appl., pp. 235-240, (2009); Nam J., Fu W., Kim S., Menzies T., Tan L., Heterogeneous defect prediction, IEEE Trans. Softw. Eng., 44, 9, pp. 874-896, (2018); Kaur A., Malhotra R., Application of random forest in predicting faultprone classes, Proc. Int. Conf. Adv. Comput. Theory Eng., pp. 37-43, (2008); Guo L., Ma Y., Cukic B., Singh H., Robust prediction of faultproneness by random forests, Proc. 15th Int. Symp. Softw. Rel. Eng., pp. 417-428, (2004); Johnson J.M., Khoshgoftaar T.M., Survey on deep learning with class imbalance, J. Big Data, 6, 1, pp. 1-54, (2019); Bowes D., Hall T., Petri J., Software defect prediction: Do different classifiers find the same defects?, Softw. Qual. J., 26, 2, pp. 525-552, (2018); Friedman M., The use of ranks to avoid the assumption of normality implicit in the analysis of variance, J. Amer. Statist. Assoc., 32, 200, pp. 675-701, (1937); Demar J., Statistical comparisons of classifiers over multiple data sets, J. Mach. Learn. Res., 7, pp. 1-30, (2006); Holm S., A simple sequentially rejective multiple test procedure, Scan-din. J. Statist., 4, pp. 65-70, (1979); Rice J.A., Mathematical Statistics and Data Analysis, (2006); Arcuri A., Briand L., A practical guide for using statistical tests to assess randomized algorithms in software engineering, Proc. 33rd Int. Conf. Softw. Eng., pp. 1-10, (2011); Tantithamthavorn C., McIntosh S., Hassan A.E., Matsumoto K., An empirical comparison of model validation techniques for defect prediction models, IEEE Trans. Softw. Eng., 43, 1, pp. 1-18, (2017); Kalibera T., Jones R., Quantifying Performance Changes with Effect Size Confidence Intervals, (2020); He Q., Shen B., Chen Y., Software defect prediction using semisupervised learning with change burst information, Proc. IEEE 40th Annu. Comput. Softw. Appl. Conf. (COMPSAC), pp. 113-122, (2016); Graves T.L., Karr A.F., Marron J.S., Siy H., Predicting fault incidence using software change history, IEEE Trans. Softw. Eng., 26, 7, pp. 653-661, (2000); Radjenovi D., Heriko M., Torkar R., Sivkovi A., Software fault prediction metrics: A systematic literature review, Inf. Softw. Technol., 55, 8, pp. 1397-1418, (2013); Kim S., Zhang H., Wu R., Gong L., Dealing with noise in defect prediction, Proc. 33rd Int. Conf. Softw. Eng., pp. 481-490, (2011); Choudhary G.R., Kumar S., Kumar K., Mishra A., Catal C., Empirical analysis of change metrics for software fault prediction, Comput. Electr. Eng., 67, pp. 15-24, (2018); Briand L.C., Wust J., Empirical studies of quality models in objectoriented systems, Adv. Comput., 56, pp. 97-166, (2002); Elish M.O., Al-Yafei A.H., Al-Mulhem M., Empirical comparison of three metrics suites for fault prediction in packages of object-oriented systems: A case study of Eclipse, Adv. Eng. Softw., 42, 10, pp. 852-859, (2011); Shatnawi R., Li W., The effectiveness of software metrics in identifying error-prone classes in post-release software evolution process, J. Syst. Softw., 81, 11, pp. 1868-1882, (2008); Jing X.-Y., Ying S., Zhang Z.-W., Wu S.-S., Liu J., Dictionary learning based software defect prediction, Proc. 36th Int. Conf. Softw. Eng., pp. 414-423, (2014); Menzies T., Greenwald J., Frank A., Data mining static code attributes to learn defect predictors, IEEE Trans. Softw. Eng., 33, 1, pp. 2-13, (2007); Chidamber S.R., Kemerer C.F., A metrics suite for object oriented design, IEEE Trans. Softw. Eng., 20, 6, pp. 476-493, (1994); McCabe T.J., A complexity measure, IEEE Trans. Softw. Eng., SE-2, 4, pp. 308-320, (1976); Bansiya J., Davis C.G., A hierarchical model for object-oriented design quality assessment, IEEE Trans. Softw. Eng., 28, 1, pp. 4-17, (2002); Martin R., OO design quality metrics, Anal. Dependencies, 12, pp. 151-170, (1994); Tang M.-H., Kao M.-H., Chen M.-H., An empirical study on object-oriented metrics, Proc. 6th Int. Softw. Metrics Symp., pp. 242-249, (1999); Henderson-Sellers B., Object-Oriented Metrics: Measures Complexity, (1995); Premraj R., Herzig K., Network versus code metrics to predict defects: A replication study, Proc. Int. Symp. Empirical Softw. Eng. Meas., pp. 215-224, (2011); Zimmermann T., Nagappan N., Predicting defects using network analysis on dependency graphs, Proc. 13th Int. Conf. Softw. Eng., pp. 531-540, (2008); He P., Li B., Ma Y., He L., Using software dependency to bug prediction, Math. Problems Eng., 2013, (2013); Viet Phan A., Le Nguyen M., Thu Bui L., Convolutional neural networks over control flow graphs for software defect prediction, Proc. IEEE 29th Int. Conf. Tools Artif. Intell. (ICTAI), pp. 45-52, (2017); Koru A.G., Liu H., Building effective defect-prediction models in practice, IEEE Softw., 22, 6, pp. 23-29, (2005); Asmono R.T., Wahono R.S., Syukur A., Absolute correlation weighted naïve Bayes for software defect prediction, J. Softw. Eng., 1, 1, pp. 38-45, (2015); Xuan X., Lo D., Xia X., Tian Y., Evaluating defect prediction approaches using a massive set of metrics: An empirical study, Proc. 30th Annu. ACM Symp. Appl. Comput., pp. 1644-1647, (2015); Elish K.O., Elish M.O., Predicting defect-prone software modules using support vector machines, J. Syst. Softw., 81, 5, pp. 649-660, (2008); Gray D., Bowes D., Davey N., Sun Y., Christianson B., Software defect prediction using static code metrics underestimates defectproneness, Proc. Int. Joint Conf. Neural Netw. (IJCNN), pp. 1-7, (2010)",,,,,,English,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85123383541,133
Shi K.; Lu Y.; Liu G.; Wei Z.; Chang J.,"Shi, Ke (57209640937); Lu, Yang (56937227200); Liu, Guangliang (57005650000); Wei, Zhenchun (16235377000); Chang, Jingfei (57209640007)",57209640937; 56937227200; 57005650000; 16235377000; 57209640007,MPT-embedding: An unsupervised representation learning of code for software defect prediction,2021,Journal of Software: Evolution and Process,33,4,e2330,,,,16,10.1002/smr.2330,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097534520&doi=10.1002%2fsmr.2330&partnerID=40&md5=8dab33d2af777d2aa2c02a0486aa036e,"Software project defect prediction can help developers allocate debugging resources. Existing software defect prediction models are usually based on machine learning methods, especially deep learning. Deep learning-based methods tend to build end-to-end models that directly use source code-based abstract syntax trees (ASTs) as input. They do not pay enough attention to the front-end data representation. In this paper, we propose a new framework to represent source code called multiperspective tree embedding (MPT-embedding), which is an unsupervised representation learning method. MPT-embedding parses the nodes of ASTs from multiple perspectives and encodes the structural information of a tree into a vector sequence. Experiments on both cross-project defect prediction (CPDP) and within-project defect prediction (WPDP) show that, on average, MPT-embedding provides improvements over the state-of-the-art method. © 2020 John Wiley & Sons, Ltd.","Chidamber S.R., Kemerer C.F., A metrics suite for object oriented design, IEEE Transactions on Software Engineering, 20, 6, pp. 476-493, (1994); Halstead M.H., Elements of Software Science, (1977); Mccabe T.J., A complexity measure, IEEE Trans Soft Engin, SE-2, 4, pp. 308-320, (2006); Harrison R., Counsell S.J., Nithi R.V., An evaluation of the mood set of object-oriented software metrics, IEEE Trans Soft Engin, 24, 6, pp. 491-496, (1998); Chilowicz M., Duris E., Roussel G., Syntax tree fingerprinting for source code similarity detection, pp. 243-247, (2009); Yang J., Hotta K., Higo Y., Igaki H., Kusumoto S., Classification model for code clones based on machine learning, Empir Soft Engin, 20, 4, pp. 1095-1125, (2015); Zibran M.F., Roy C.K., Towards flexible code clone detection, management, and refactoring in IDE, pp. 75-76, (2011); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., Sourcerercc: scaling code clone detection to big-code, pp. 1157-1168, (2016); Le Goues C., Nguyen T., Forrest S., Weimer W., Genprog: A generic method for automatic software repair, Ieee Trans Soft Engin, 38, 1, pp. 54-72, (2012); Bohme M., Soremekun E.O., Chattopadhyay S., Ugherughe E., Zeller A., Where is the bug and how is it fixed? An experiment with practitioners, pp. 117-128, (2017); Jeffrey D., Feng M., Gupta R., Bugfix: a learning-based tool to assist developers in fixing bugs, pp. 70-79, (2009); Steidl D., GAude N., Feature-based detection of bugs in clones, pp. 76-82, (2013); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, pp. 297-308, (2016); Li J., He P., Zhu J., Lyu M.R., Software defect prediction via convolutional neural network, pp. 318-328, (2017); Yang X., Lo D., Xia X., Zhang Y., Sun J., Deep learning for just-in-time defect prediction, pp. 17-26, (2015); Zhao G., Huang J., Deepsim: deep learning code functional similarity, pp. 141-151, (2018); Li L., Feng H., Zhuang W., Meng N., Ryder B., Cclearner: a deep learning-based clone detection approach, pp. 249-260, (2017); Gupta R., Pal S., Kanade A., Shevade S., Deepfix: fixing common c language errors by deep learning, (2017); Goyal P., Ferrara E., Graph embedding techniques, applications, and performance: a survey, Know Based Sys, 151, pp. 78-94, (2018); Cai H., Zheng V.W., Chang K.C., A comprehensive survey of graph embedding: problems, techniques, and applications, IEEE Trans Know Data Engin, 30, 9, pp. 1616-1637, (2018); Garcia-Duran A., Niepert M., Learning graph representations with embedding propagation, Adv Neural Inform Proces Sys, 30, (2017); Perozzi B., Al-Rfou R., Skiena S., Deepwalk: online learning of social representations, pp. 701-710, (2014); Grover A., Leskovec J., Node2vec: scalable feature learning for networks, pp. 855-864, (2016); Wang D., Cui P., Zhu W., Structural deep network embedding, pp. 1225-1234, (2016); Yang Z., Tang J., Cohen W., Multi-modal Bayesian embeddings for learning social knowledge graphs, pp. 2287-2293, (2016); Nikolentzos G., Meladianos P., Vazirgiannis M., Matching node embeddings for graph similarity, (2017); Lessmann S., Baesens B., Mues C., Pietsch S., Benchmarking classification models for software defect prediction: a proposed framework and novel findings, IEEE Trans Soft Engin, 34, 4, pp. 485-496, (2008); Ghotra B., McIntosh S., Hassan A.E., Revisiting the impact of classification techniques on the performance of defect prediction models, 1, pp. 789-800, (2015); Nam J., Fu W., Kim S., Menzies T., Tan L., Heterogeneous defect prediction, IEEE Trans Soft Engin, 44, 9, pp. 874-896, (2018); Lu H., Kocaguneli E., Cukic B., Defect prediction between software versions with active learning and dimensionality reduction, pp. 312-322, (2014); Yang X., Wen W., Ridge and Lasso regression models for cross-version defect prediction, IEEE Trans on Reliab, 67, 3, pp. 885-896, (2018); Zimmermann T., Nagappan N., Gall H., Giger E., Murphy B., Cross-project defect prediction: a large scale experiment on data vs. domain vs. process, pp. 91-100, (2009); Fukushima T., Kamei Y., McIntosh S., Yamashita K., Ubayashi N., An empirical study of just-in-time defect prediction using cross-project models, pp. 172-181, (2014); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, pp. 1287-1293, (2016); Dam H.K., Tran T., Pham T.T.M., Ng S.W., Grundy J., Ghose A., Automatic feature learning for predicting vulnerable software components, IEEE Trans Soft Engin, (2018); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, (2013); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, pp. 3111-3119, (2013); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, (2018); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, ACM SIGPLAN Notices, 53, 4, pp. 404-419, (2018); Alon U., Brody S., Levy O., Yahav E., code2seq: generating sequences from structured representations of code, (2019); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: learning distributed representations of code, Proc ACM Program Lang, 3, POPL, pp. 40:1-40:29, (2019); Kang H.J., Bissyande T.F., Lo D., Assessing the generalizability of code2vec token embeddings, pp. 1-12, (2019); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, pp. 87-98, (2016); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, pp. 542-553, (2018); Ou M., Cui P., Pei J., Zhang Z., Zhu W., Asymmetric transitivity preserving graph embedding, pp. 1105-1114, (2016); Li Y., Wang S., Nguyen T.N., Nguyen S.V., Improving bug detection via context-based code representation learning and attention-based neural networks, Proc ACM Program Lang, 3, OOPSLA, pp. 162:1-162:30, (2019); Xu Z., Li S., Xu J., Liu J., Luo X., Zhang Y., Zhang T., Keung J., Tang Y., LDFR: learning deep feature representation for software defect prediction, J Sys Soft, 158, (2019); Nam J., Pan S.J., Kim S., Transfer defect learning, pp. 382-391, (2013); Dam H.K., Pham T., Ng S.W., Tran T., Grundy J., Ghose A., Kim T., Kim C.-J., Lessons learned from using a deep tree-based model for software defect prediction in practice, pp. 46-57, (2019); Duchi J., Hazan E., Singer Y., Adaptive subgradient methods for online learning and stochastic optimization, J Mach Learn Res, 12, pp. 2121-2159, (2011); D'Ambros M., Lanza M., Robbes R., An extensive comparison of bug prediction approaches, pp. 31-41, (2010); Chidamber S.R., Kemerer C.F., A metrics suite for object oriented design, IEEE Trans Soft Engin, 20, 6, pp. 476-493, (1994); Henderson-Sellers B., Object-Oriented Metrics: Measures of Complexity, (1995); Bansiya J., Davis C.G., A hierarchical model for object-oriented design quality assessment, IEEE Trans Soft Engin, 28, 1, pp. 4-17, (2002); Tang M.-H., Kao M.-H., Chen M.-H., An empirical study on object-oriented metrics, pp. 242-249, (1999); Martin R., Oo design quality metrics-an analysis of dependencies, (1994); McCabe T.J., A complexity measure, IEEE Trans Soft Engin, 4, pp. 308-320, (1976); Zhou T., Sun X., Xia X., Li B., Chen X., Improving defect prediction with deep forest, Inform Soft Tech, 114, pp. 204-216, (2019); Kim S., Zhang H., Wu R., Gong L., Dealing with noise in defect prediction, pp. 481-490, (2011)",,,,,,English,Article,Final,,Scopus,2-s2.0-85097534520,134
Xu J.; Ai J.; Shi T.,"Xu, Jiaxi (57216952150); Ai, Jun (57214531958); Shi, Tao (57215415209)",57216952150; 57214531958; 57215415209,Software Defect Prediction for Specific Defect Types based on Augmented Code Graph Representation,2021,"Proceedings - 2021 8th International Conference on Dependable Systems and Their Applications, DSA 2021",,,,669,678,9,2,10.1109/DSA52907.2021.00097,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123502800&doi=10.1109%2fDSA52907.2021.00097&partnerID=40&md5=5212e2ef64a23438c28141c1e4289fd2,"In a software life cycle, improving quality and identifying and repairing defects has become an important research topic. Previous studies have proposed defect prediction based on artificial measurement features, a method whose quality is unfortunately difficult to guarantee. On the other hand, many current studies have attempted to predict all types of defects using a single model, which is difficult to achieve. In this paper, Augmented-CPG, a new code graph representation, is proposed. Based on this representation, a defect region candidate extraction method related to the defect type is proposed. Graphic neural networks are introduced to learn defect features. We carried out experiments on three different types of defects, and the results show that our method can effectively predict specific types of defects. © 2021 IEEE.","Wong W.E., Li X., Laplante P.A., Be more familiar with our enemies and pave the way forward: A review of the roles bugs played in software failures, Journal of Systems and Software, 133, pp. 68-94, (2017); Wang S., Yao X., Using class imbalance learning for software defect prediction, Ieee Trans. Reliab, 62, 2, pp. 434-443, (2013); Elish K.O., Elish M.O., Predicting defect-prone software modules using support vector machines, J. Syst. Softw, 81, 5, pp. 649-660, (2008); Bai X., Zhou H., Yang H., An hvsm-based gru approach to predict cross-version software defects, Int. J. Performability Eng, 16, 6, pp. 979-990, (2020); Zhou Y., Et al., How far we have progressed in the journey? An examination of cross-project defect prediction, Acm Trans. Softw. Eng. Methodol, 27, 1, (2018); Xu J., Wang F., Ai J., Defect prediction with semantics and context features of codes based on graph representation learning, Ieee Trans. Reliab, pp. 1-13, (2020); Li Y., Wong W.E., Lee S.Y., Wotawa F., Using tri-relation networks for effective software fault-proneness prediction, Ieee Access, 7, pp. 63066-63080, (2019); Weyuker E.J., Ostrand T.J., Bell R.M., Do too many cooks spoil the broth? Using the number of developers to enhance defect prediction models, Empir. Softw. Eng, 13, 5, pp. 539-559, (2008); Viet Phan A., Le Nguyen M., Thu Bui L., Convolutional neural networks over control flow graphs for software defect prediction, Proc.-Int. Conf. Tools with Artif. Intell. Ictai, pp. 45-52, (2018); Tian J., Tian Y., A model based on program slice and deep learning for software defect prediction, Proc.-Int. Conf. Comput. Commun. Networks, Icccn, pp. 2-7, (2020); Guan Z., Wang X., Xin W., Wang J., Zhang L., A survey on deep learning-based source code defect analysis, 2020 5th Int. Conf. Comput. Commun. Syst. Icccs 2020, pp. 167-171, (2020); Chen D., Chen X., Li H., Xie J., Mu Y., Deepcpdp: Deep learning based cross-project defect prediction, Ieee Access, 7, pp. 184832-184848, (2019); Wang S., Liu T., Nam J., Tan L., Deep semantic feature learning for software defect prediction, Ieee Trans. Softw. Eng, 46, 99, pp. 1-22, (2018); Cai Z., Lu L., Qiu S., An abstract syntax tree encoding method for cross-project defect prediction, Ieee Access, 7, pp. 170844-170853, (2019); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, Proc.-IEEE Symp. Secur. Priv, pp. 590-604, (2014); Suneja S., Zheng Y., Zhuang Y., Laredo J., Morari A., Learning to map source code to software vulnerability using code-as-a-graph, Icst, pp. 1-8, (2019); Chakraborry S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet?, , Ieee Trans. Softw. Eng., Vol. Tbd, (2020); Common Weakness Enumeration (CWE; Software Assurance Reference Dataset (SARD; Xu J., Yan L., Wang F., Ai J., A github-based data collection method for software defect prediction, The 6th Ieee International Conference on Dependable Systems and Their Applications (DSA), pp. 100-108, (2020); Zou D., Wang S., Xu S., Li Z., Jin H., UVulDeePecker: A Deep Learning-based System for Multiclass Vulnerability Detection, 5971, 100, pp. 1-13, (2020); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, 1st International Conference on Learning Representations, Iclr 2013-Workshop Track Proceedings, (2013); Scholkopf B., Smola A., Muller K.R., Nonlinear component analysis as akernel eigenvalue problem, Neural Comput, 10, 5, pp. 1299-1319, (1998); Xu K., Jegelka S., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks?, 7th Int. Conf. Learn. Represent. Iclr 2019, pp. 1-17, (2019); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5th Int. Conf. Learn. Represent. Iclr 2017-Conf. Track Proc, pp. 1-14, (2019); Wu F., Zhang T., De Souza A.H., Fifty C., Yu T., Weinberger K.Q., Simplifying graph convolutional networks, 36th Int. Conf. Mach. Learn. Icml 2019, pp. 11884-11894, (2019); Veli Skovi P., Casanova A., Lid P., Cucurull G., Romero A., Bengio Y., Graph attention networks, 6th Int. Conf. Learn. Represent. Iclr 2018-Conf. Track Proc, pp. 1-12, (2018); Hamilton L., Ying R., Leskovec J., Inductive representation learning on large graphs, Advances in Neural Information Processing Systems, pp. 1025-1035, (2017); Niu W., Zhang X., Du X., Zhao L., Cao R., Guizani M., A deep learning based static taint analysis approach for iot software vulnerability location, Meas. J. Int. Meas. Confed, 152, (2020); Wang H., Et al., Combining graph-based learning with automated data collection for code vulnerability detection, Ieee Trans. Inf. Forensics Secur, 16, pp. 1943-1958, (2021); Li Z., Et al., VulDeePecker: A Deep Learning-based System for Vulnerability Detection, (2018); Yang Y., Ai J., Wang F., Defect prediction based on the characteristics of multilayer structure of software network, 2018 Ieee International Conference on Software Quality, Reliability and Security Companion (QRS-C), pp. 27-34, (2018); Fu W., Menzies T., Revisiting Unsupervised Learning for Defect Prediction, pp. 72-83, (2017); Snoek J., Larochelle H., Adams R.P., Practical bayesian optimization of machine learning algorithms, Advances in Neural Information Processing Systems, (2012); Zimmermann T., Premraj R., Zeller A., Predicting defects for eclipse, Proceedings-ICSE 2007 Workshops: Third International Workshop on Predictor Models in Software Engineering, PROMISE'07, (2007); Bennin K.E., Keung J., Phannachitta P., Monden A., Mensah S., Mahakil: Diversity based oversampling approach to alleviate the class imbalance issue in software defect prediction, Ieee Trans. Softw. Eng, 44, 6, pp. 534-550, (2018); Khoshgoftaar T.M., Gao K., Napolitano A., Wald R., A comparative study of iterative and non-iterative feature selection techniques for software defect prediction, Inf. Syst. Front, 16, 5, pp. 801-822, (2014); McCabe T.J., A complexity measure, Ieee Trans. Softw. Eng, 2, 4, pp. 308-320, (1976); Halstead M.H., Elements of Software Science (Operating and Programming Systems Series), (1977); Chidamber And C F Kemerer S., A metric suite for object oriented design, Ieee Trans. Softw. Eng, (1994); Basili V.R., Briand L.C., Melo W.L., A validation of object-oriented design metrics as quality indicators, Ieee Trans. Softw. Eng, 22, 10, pp. 751-761, (1996); Wang F., Ai J., Zou Z., A cluster-based hybrid feature selection method for defect prediction, Proceedings-19th Ieee International Conference on Software Quality, Reliability and Security, Qrs 2019, pp. 1-9, (2019); Lessmann S., Baesens B., Mues C., Pietsch S., Benchmarking classification models for software defect prediction: A proposed framework and novel findings, Ieee Transactions on Software Engineering, 34, 4, pp. 485-496, (2008); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, 30th Aaai Conf. Artif. Intell. AAAI2016, pp. 1287-1293, (2016); Dam H.K., Tran T., Pham T.T.M., Ng S.W., Grundy J., Ghose A., Automatic feature learning for predicting vulnerable software components, Ieee Trans. Softw. Eng, 99, (2018); Fan G., Diao X., Yu H., Yang K., Chen L., Software defect prediction via attention-based recurrent neural network, Sci. Program, 2019, (2019); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities, pp. 1-13, (2018); Li Z., Zou D., Xu S., Chen Z., Zhu Y., Jin H., VulDeeLocator: A Deep Learning-based Fine-grained Vulnerability Detector, 2, pp. 1-15, (2020)",IEEE Reliability Society,"8th International Conference on Dependable Systems and Their Applications, DSA 2021",11 September 2021 through 12 September 2021,Yinchuan,175141,English,Conference paper,Final,,Scopus,2-s2.0-85123502800,135
Shi K.; Lu Y.; Chang J.; Wei Z.,"Shi, Ke (57209640937); Lu, Yang (56937227200); Chang, Jingfei (57209640007); Wei, Zhen (7402258637)",57209640937; 56937227200; 57209640007; 7402258637,PathPair2Vec: An AST path pair-based code representation method for defect prediction,2020,Journal of Computer Languages,59,,100979,,,,38,10.1016/j.cola.2020.100979,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085928963&doi=10.1016%2fj.cola.2020.100979&partnerID=40&md5=2f38eee29116449336d8e934062d0794,"Software project defect prediction (SDP) can predict the bug probability of software by their features and allocate their testing efforts. The existing software defect prediction methods can be divided into two categories: methods based on traditional handcrafted features and methods based on automatically made abstract features, especially those made by deep learning. The current research indicates that deep learning-based automatic features can achieve better performance than handcrafted features. Code2vec (Alon et al. 2019) is one of the best source code representation models, which leverages deep learning to learn automatic representations from code. In this paper, inspired by code2vec, we propose a new AST path pair-based source code representation method (PathPair2Vec) and apply it to software project defect prediction. We first propose the concept of the short path to describe each terminal node and its control logic. Then, we design a new sequence encoding method to code the different parts of the terminal node and its control logic. Finally, by pairs of short paths, we describe the semantic information of code and fuse them by an attention mechanism. Experiments on the PROMISE dataset show that our method improves the F1 score by 17.88% over the state-of-the-art SDP method, and the AST path pair-based source code representation can better identify the defect features of the source code. © 2020 Elsevier Ltd","Fu W., Menzies T., Revisiting unsupervised learning for defect prediction, Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2017, pp. 72-83, (2017); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, Software Engineering (ICSE), 2016 IEEE/ACM 38th International Conference on, pp. 297-308, (2016); Dam H.K., Pham T., Ng S.W., Tran T., Grundy J., Ghose A., Kim T., Kim C.-J., Lessons learned from using a deep tree-based model for software defect prediction in practice, Proceedings of the 16th International Conference on Mining Software Repositories, MSR ’19, pp. 46-57, (2019); Dam H.K., Tran T., Pham T., Ng S.W., Grundy J., Ghose A., Automatic feature learning for vulnerability prediction, (2017); Chidamber S.R., Kemerer C.F., A Metrics Suite for Object Oriented Design, pp. 197-211, (1994); Halstead M.H., Elements of Software Science (Operating and Programming Systems Series), (1978); Mccabe T.J., A complexity measure, IEEE Trans. Softw. Eng., SE-2, 4, pp. 308-320, (2006); Chilowicz M., Duris E., Roussel G., Syntax tree fingerprinting for source code similarity detection, 2009 IEEE 17th International Conference on Program Comprehension, pp. 243-247, (2009); Yang J., Hotta K., Higo Y., Igaki H., Kusumoto S., Classification model for code clones based on machine learning, Empir. Softw. Eng., 20, 4, pp. 1095-1125, (2015); Zibran M.F., Roy C.K., Towards flexible code clone detection, management, and refactoring in IDE, Proceedings of the 5th International Workshop on Software Clones, IWSC ’11, pp. 75-76, (2011); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., SourcererCC: Scaling code clone detection to big-code, 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE), pp. 1157-1168, (2016); Le Goues C., Nguyen T., Forrest S., Weimer W., Genprog: A generic method for automatic software repair, Ieee Trans. Softw. Eng., 38, 1, pp. 54-72, (2012); Bohme M., Soremekun E.O., Chattopadhyay S., Ugherughe E., Zeller A., Where is the bug and how is it fixed? An experiment with practitioners, Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2017, pp. 117-128, (2017); Jeffrey D., Feng M., Gupta R., BugFix: A learning-based tool to assist developers in fixing bugs, 2009 IEEE 17th International Conference on Program Comprehension, pp. 70-79, (2009); Pradel M., Sen K., DeepBugs: A learning approach to name-based bug detection, Proc. ACM Program. Lang., 2, OOPSLA, (2018); Steidl D., Goede N., Ieee R., Feature-based detection of bugs in clones, 2013 7th International Workshop on Software Clones, International Workshop on Software Clones, pp. 76-82, (2013); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, International Conference on Machine Learning, pp. 2091-2100, (2016); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, pp. 2073-2083, (2016); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, 2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR), pp. 542-553, (2018); Raychev V., Vechev M., Krause A., Predicting program properties from ”Big Code”, SIGPLAN Not., 50, 1, pp. 111-124, (2015); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings, (2018); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2018, pp. 404-419, (2018); Alon U., Zilberstein M., Levy O., Yahav E., Code2Vec: Learning distributed representations of code, Proc. ACM Program. Lang., 3, POPL, pp. 401-40:29, (2019); Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating sequences from structured representations of code, International Conference on Learning Representations, (2019); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput., 9, 8, pp. 1735-1780, (1997); Gers F., Schmidhuber J., Cummins F., Learning to forget: Continual prediction with LSTM, Neural Comput., 12, pp. 2451-2471, (2000); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proceedings of the 26th Conference on Program Comprehension, ICPC ’18, pp. 200-210, (2018); Li J., He P., Zhu J., Lyu M.R., Software defect prediction via convolutional neural network, 2017 IEEE International Conference on Software Quality, Reliability and Security (QRS), pp. 318-328, (2017); Chidamber S.R., Kemerer C.F., A metrics suite for object oriented design, IEEE Trans. Softw. Eng., 20, 6, pp. 476-493, (1994); Henderson-Sellers B., Object-Oriented Metrics: Measures of Complexity, (1995); Bansiya J., Davis C.G., A hierarchical model for object-oriented design quality assessment, IEEE Trans. Softw. Eng., 28, 1, pp. 4-17, (2002); Tang M.-H., Kao M.-H., Chen M.-H., An empirical study on object-oriented metrics, Proceedings Sixth International Software Metrics Symposium (Cat. No. PR00403), pp. 242-249, (1999); Martin R., Oo design quality metrics-an analysis of dependencies, (1994); McCabe T.J., A complexity measure, IEEE Trans. Softw. Eng., 4, pp. 308-320, (1976); Nam J., Pan S.J., Kim S., Transfer defect learning, Proceedings of the 2013 International Conference on Software Engineering, ICSE ’13, pp. 382-391, (2013)",,,,,,English,Article,Final,,Scopus,2-s2.0-85085928963,137
Zhang X.; Lu Y.; Shi K.,"Zhang, Xiyu (57222155758); Lu, Yang (56937227200); Shi, Ke (57209640937)",57222155758; 56937227200; 57209640937,CB-Path2Vec: A Cross Block Path Based Representation for Software Defect Prediction,2020,"2020 IEEE 6th International Conference on Computer and Communications, ICCC 2020",,,9344956,1961,1966,5,2,10.1109/ICCC51575.2020.9344956,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101683378&doi=10.1109%2fICCC51575.2020.9344956&partnerID=40&md5=168573d2392fdb2ab881db7e179d77a4,"Software defects are common in software projects and threaten the security of software. Software defect prediction has been proven to be an effective method to solve software security problems, assisting developers in finding potential errors and effectively allocating test resources, in the early stage of the software life cycle. Traditional defect prediction models are designed based on hand-designed metric features, but these features usually cannot capture the semantic and structural information of code. In order to solve this problem, this paper proposes a novel software defect prediction model called CB-Path2Vec, which can automatically learn features composed of Cross Block path for representing source code and use them for software defect prediction. An evaluation on the public PROMISE dataset shows that on average CB-Path2Vec improvements over the state-of-the-art method both on within-project defect prediction (WPDP) and cross-project defect prediction (CPDP). © 2020 IEEE.","Halstead M.H., Elements of software science[J], Elsevierence, (1977); Harrison R., Counsell S.J., An evaluation of the mood set of object-oriented software metrics[J], Ieee Transactions on Software Engineering, 24, 6, (1998); Chidamber S.R., Kemerer C.F., A metrics suite for object oriented design[J], Ieee Transactions on 425 Software Engineering, 20, 6, pp. 476-493, (1994); McCabe T.J., A complexity measure[J], Ieee Transactions on Software Engineering, SE-2, 4, pp. 308-320, (1976); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction[C], Proceedings of the 38th International Conference on Software Engineering-ICSE '16, pp. 297-308, (2016); Li J., He P., Zhu J., Et al., Software defect prediction via convolutional neural network[C], Ieee International Conference on Software Quality, Reliability and Security, Prague, pp. 318-328, (2017); Alon U., Zilberstein M., Levy O., Et al., A general path-based representation for predicting program properties[C], Proceedings of the 39th Acm Sigplan Conference on Programming Language Design and Implementation, pp. 404-419, (2018); Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating sequences from structured representations of code[C], International Conference on Learning Representations, (2019); Alon U., Zilberstein M., Levy O., Et al., Code2vec: Learning distributed representations of code[J], Proceedings of the Acm on Programming Languages New York: Association for Computing Machinery, pp. 40-69, (2019); Chen X., Gu Q., Liu W.S., Liu S.L., Ni C., Survey of static software defect prediction[J], Ruan Jian Xue Bao/Journal of Software, 27, 1, pp. 1-25, (2016); Wang Q., Wu S.J., Li M.S., Software defect prediction[J], Ruan Jian Xue Bao/Journal of Software, 19, 7, pp. 1565-1580, (2008); Hochreiter S., Schmidhuber J., Long short-term memory[J], Neural Computation, 9, 8, pp. 1735-1780, (1997); Shi K., Lu Y., Et al., Pathpair2vec: An ast path pair-based code representation method for defect prediction[J], Journal of Computer Languages, 59, (2020); Nam J., Pan S.J., Kim S., Transfer defect learning[C], International Conference on Software Engineering, pp. 382-391, (2013)",,"6th IEEE International Conference on Computer and Communications, ICCC 2020",11 December 2020 through 14 December 2020,Chengdu,167151,English,Conference paper,Final,,Scopus,2-s2.0-85101683378,138
Yasunaga M.; Liang P.,"Yasunaga, Michihiro (57203242413); Liang, Percy (56646712700)",57203242413; 56646712700,"Graph-based, self-supervised program repair from diagnostic feedback",2020,"37th International Conference on Machine Learning, ICML 2020",PartF168147-14,,,10730,10739,9,54,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094774454&partnerID=40&md5=8d54ec79554fc63afde98c2a36893a75,"We consider the problem of learning to repair programs from diagnostic feedback (e.g., compiler error messages). Program repair is challenging for two reasons: First, it requires reasoning and tracking symbols across source code and diagnostic feedback. Second, labeled datasets available for program repair are relatively small. In this work, we propose novel solutions to these two challenges. First, we introduce a program-feedback graph, which connects symbols relevant to program repair in source code and diagnostic feedback, and then apply a graph neural network on top to model the reasoning process. Second, we present a self-supervised learning paradigm for program repair that leverages unlabeled programs available online to create a large amount of extra program repair examples, which we use to pre-train our models. We evaluate our proposed approach on two applications: correcting introductory programming assignments (DeepFix dataset) and correcting the outputs of program synthesis (SPoC dataset). Our final system, DrRepair, significantly outperforms prior work, achieving 68.2% full repair rate on DeepFix (+22.9% over the prior best), and 48.4% synthesis success rate on SPoC (+3.7% over the prior best). Copyright 2020 by the author(s).","Ahmed U. Z., Kumar P., Karkare A., Kar P., Gulwani S., Compilation error repair: for the student programs, from the student programs, ICSE, (2018); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, ICLR, (2018); Bader J., Scott A., Pradel M., Chandra S., Getafix: Learning to fix bugs automatically, OOPSLA, (2019); Brockschmidt M., Allamanis M., Gaunt A., Generative code modeling with graphs, ICLR, (2019); Chen Z., Kommrusch S. J., Tufano M., Pouchet L.N., Poshyvanyk D., Monperrus M., Sequencer: Sequence-to-sequence learning for end-to-end program repair, IEEE Transactions on Software Engineering, (2019); Devlin J., Chang M.-W., Lee K., Toutanova K., Bert: Pre-training of deep bidirectional transformers for language understanding, NAACL, (2019); Dinella E., Dai H., Li Z., Naik M., Song L., Wang K., Hoppity: Learning graph transformations to detect and fix bugs in programs, ICLR, (2020); Erhan D., Bengio Y., Courville A., Manzagol P.-A., Vincent P., Bengio S., Why does unsupervised pre-training help deep learning?, Journal of MachineLearning Research, (2010); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., Codebert: A pre-trained model for programming and natural languages, (2020); Fitzgerald S., Lewandowski G., McCauley R., Murphy L., Simon B., Thomas L., Zander C., Debugging: finding, fixing and flailing, a multi-institutional study of novice debuggers, Computer Science Education, (2008); Gupta R., Pal S., Kanade A., Shevade S., Deepfix: Fixing common c language errors by deep learning, AAAI, (2017); Gupta R., Kanade A., Shevade S., Neural attribution for semantic bug-localization in student programs, NeurIPS, (2019); Gupta R., Kanade A., Shevade S., Deep reinforcement learning for programming language correction, AAAI, (2019); Hajipour H., Bhattacharya A., Fritz M., Samplefix: Learning to correct programs by sampling diverse fixes, (2019); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Hu W., Liu B., Gomes J., Zitnik M., Liang P., Pande V., Leskovec J., Pre-training graph neural networks, ICLR, (2020); Just R., Jalali D., Ernst M. D., Defects4j: A database of existing faults to enable controlled testing studies for java programs, ISSTA, (2014); Kingma D., Ba J., Adam: A method for stochastic optimization, ICLR, (2015); Kipf T. N., Welling M., Semi-supervised classification with graph convolutional networks, ICLR, (2017); Kulal S., Pasupat P., Chandra K., Lee M., Padon O., Aiken A., Liang P., Spoc: Search-based pseudocode to code, NeurIPS, (2019); Liu B., Tur G., Hakkani-Tur D., Shah P., Heck L., Dialogue learning with human teaching and feedback in end-to-end trainable task-oriented dialogue systems, NAACL, (2018); Mesbah A., Rice A., Johnston E., Glorioso N., Aftandilian E., Learning to repair compilation errors, ESEC/FSE, (2019); Monperrus M., The living review on automated program repair, (2018); Parihar S., Dadachanji Z., Praveen Kumar Singh R. D., Karkare A., Bhattacharya A., Automatic grading and feedback using program repair for introductory programming courses, ACM Conference on Innovation and Technology in Computer Science Education, (2017); Pascanu R., Mikolov T., Bengio Y., On the difficulty of training recurrent neural networks, (2012); Peters M., Neumann M., Iyyer M., Gardner M., Clark C., Lee K., Zettlemoyer L., Deep contextualized word representations, NAACL, (2018); Pradel M., Sen K., Deepbugs: a learning approach to name-based bug detection, OOPSLA, (2018); Pu Y., Narasimhan K., Solar-Lezama A., Barzilay R., sk p: a neural program corrector for moocs, SPLASH Companion, (2016); See A., Liu P. J., Manning C. D., Get to the point: Summarization with pointer-generator networks, ACL, (2017); Seo H., Sadowski C., Elbaum S., Aftandilian E., Bowdidge R., Programmers’ build errors: A case study at google, ICSE, (2014); Srivastava N., Hinton G., Krizhevsky A., Sutskever I., Salakhutdinov R., Dropout: A simple way to prevent neural networks from overfitting, JMLR, (2014); Tarlow D., Moitra S., Rice A., Chen Z., Manzagol P.-A., Sutton C., Aftandilian E., Learning to fix build errors with graph2diff neural networks, (2019); Vasic M., Kanade A., Maniatis P., Bieber D., Singh R., Neural program repair by jointly learning to localize and repair, ICLR, (2019); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A. N., Kaiser L., Polosukhin I., Attention is all you need, NeurIPS, (2017); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, ICLR, (2018); Vincent P., Larochelle H., Bengio Y., Manzagol P.-A., Extracting and composing robust features with denoising autoencoders, ICML, (2008); Wang K., Singh R., Su Z., Dynamic neural program embeddings for program repair, ICLR, (2018); Xu K., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks?, ICLR, (2019); Yasunaga M., Zhang R., Meelu K., Pareek A., Srinivasan K., Radev D. R., Graph-based neural multi-document summarization, CoNLL, (2017); Zhang Y., Qi P., Manning C. D., Graph convolution over pruned dependency trees improves relation extraction, EMNLP, (2018); Zhao R., Bieber D., Swersky K., Tarlow D., Neural networks for modeling source code edits, (2019); Zhong R., Stern M., Klein D., Semantic scaffolds for pseudocode-to-code generation, (2020)",,"37th International Conference on Machine Learning, ICML 2020",13 July 2020 through 18 July 2020,"Virtual, Online",168147,English,Conference paper,Final,,Scopus,2-s2.0-85094774454,139
Loyola P.; Matsuo Y.,"Loyola, Pablo (53984941200); Matsuo, Yutaka (55101964900)",53984941200; 55101964900,Learning Feature Representations from Change Dependency Graphs for Defect Prediction,2017,"Proceedings - International Symposium on Software Reliability Engineering, ISSRE",2017-October,,8109101,361,372,11,6,10.1109/ISSRE.2017.30,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040798659&doi=10.1109%2fISSRE.2017.30&partnerID=40&md5=1717868172cec4ce3bd9499ccd62e29c,"Given the heterogeneity of the data that can be extracted from the software development process, defect prediction techniques have focused on associating different sources of data with the introduction of faulty code, usually relying on handcrafted features. While these efforts have generated considerable progress over the years, little attention has been given to the fact that the performance of any predictive model depends heavily on the representation of the data used, and that different representations can lead to different results. We consider this a relevant problem, as it could be affecting directly the efforts towards generating safer software systems. Therefore, we propose to study the impact of the representation of the data in defect prediction models. To this end, we focus on the use of developer activity data, from which we structure dependency graphs. Then, instead of manually generating features, such as network metrics, we propose two models inspired by recent advances in representation learning which are able to automatically generate feature representations from graph data. These new representations are compared against manually crafted features for defect prediction in real world software projects. Our results show that automatically learned features are competitive, reaching increments in prediction performance up to 13%. © 2017 IEEE.","Nagappan N., Zeller A., Zimmermann T., Herzig K., Murphy B., Change bursts as defect predictors, Software Reliability Engineering (ISSRE), 2010 IEEE 21st International Symposium On. IEEE, pp. 309-318, (2010); Andersen-Gott M., Ghinea G., Bygstad B., Why do commercial companies contribute to open source software, International Journal of Information Management, 32, 2, pp. 106-117, (2012); Bettenburg N., Nagappan M., Hassan A.E., Think locally, act globally: Improving defect and effort prediction models, Proceedings of the 9th IEEE Working Conference On Mining Software Repositories, pp. 60-69, (2012); Zhang F., Mockus A., Keivanloo I., Zou Y., Towards building a universal defect prediction model, Proceedings of the 11th Working Conference On Mining Software Repositories, pp. 182-191, (2014); Nam J., Kim S., Heterogeneous defect prediction, Proceedings of the 2015 10th Joint Meeting On Foundations of Software Engineering, Ser. ESEC/FSE 2015, pp. 508-519, (2015); Bengio Y., Courville A., Vincent P., Representation learning: A review and new perspectives, Pattern Analysis and Machine Intelligence, IEEE Transactions On, 35, 8, pp. 1798-1828, (2013); Brudaru I.I., Zeller A., What is the long-term impact of changes, Proceedings of the 2008 International Workshop On Recommendation Systems for Software Engineering, pp. 30-32, (2008); Herzig K., Just S., Rau A., Zeller A., Predicting defects using change genealogies, Software Reliability Engineering (ISSRE), 2013 IEEE 24th International Symposium On. IEEE, pp. 118-127, (2013); Zimmermann T., Nagappan N., Predicting defects using network analysis on dependency graphs, Proceedings of the 30th International Conference On Software Engineering, pp. 531-540, (2008); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in Neural Information Processing Systems, pp. 3111-3119, (2013); Bengio Y., Ducharme R., Vincent P., Janvin C., A neural probabilistic language model, The Journal of Machine Learning Research, 3, pp. 1137-1155, (2003); Perozzi B., Al-Rfou R., Skiena S., Deepwalk: Online learning of social representations, Proceedings of the 20th ACM SIGKDD International Conference On Knowledge Discovery and Data Mining. ACM, pp. 701-710, (2014); Dyer R., Nguyen H.A., Rajan H., Nguyen T.N., Boa: A language and infrastructure for analyzing ultra-large-scale software repositories, Proceedings of the 2013 International Conference On Software Engineering, pp. 422-431, (2013); Ye X., Bunescu R., Liu C., Learning to rank relevant files for bug reports using domain knowledge, Proceedings of the 22nd ACM SIGSOFT International Symposium On Foundations of Software Engineering, pp. 689-699, (2014); Halstead M.H., Elements of Software Science, 7, (1977); McCabe T.J., A complexity measure, Software Engineering, IEEE Transactions On, 4, pp. 308-320, (1976); Menzies T., Greenwald J., Frank A., Data mining static code attributes to learn defect predictors, Software Engineering, IEEE Transactions On, 33, 1, pp. 2-13, (2007); Weyuker E.J., Ostrand T.J., Bell R.M., Using developer information as a factor for fault prediction, Proceedings of the Third International Workshop On Predictor Models in Software Engineering, (2007); Pinzger M., Nagappan N., Murphy B., Can developer-module networks predict failures, Proceedings of the 16th ACM SIGSOFT International Symposium On Foundations of Software Engineering, pp. 2-12, (2008); Meneely A., Williams L., Snipes W., Osborne J., Predicting failures with developer networks and social network analysis, Proceedings of the 16th ACM SIGSOFT International Symposium On Foundations of Software Engineering, pp. 13-23, (2008); Bird C., Nagappan N., Gall H., Murphy B., Devanbu P., Putting it all together: Using socio-technical networks to predict failures, 2009 20th International Symposium On Software Reliability Engineering, pp. 109-119, (2009); Bird C., Nagappan N., Murphy B., Gall H., Devanbu P., Don't touch my code!: Examining the effects of ownership on software quality, Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference On Foundations of Software Engineering. ACM, pp. 4-14, (2011); Greiler M., Herzig K., Czerwonka J., Code ownership and software quality: A replication study, Proceedings of the 12th Working Conference On Mining Software Repositories, pp. 2-12, (2015); Foucault M., Falleri J.-R., Blanc X., Code ownership in opensource software, Proceedings of the 18th International Conference On Evaluation and Assessment in Software Engineering, (2014); Nam J., Pan S.J., Kim S., Transfer defect learning, Proceedings of the 2013 International Conference On Software Engineering, pp. 382-391, (2013); Zhang F., Hassan A.E., McIntosh S., Zou Y., The use of summation to aggregate software metrics hinders the performance of defect prediction models, IEEE Transactions On Software Engineering, (2016); Tantithamthavorn C., McIntosh S., Hassan A., Matsumoto K., An empirical comparison of model validation techniques for defect prediction models, IEEE Transactions On Software Engineering, (2016); Kim S., Zhang H., Wu R., Gong L., Dealing with noise in defect prediction, Software Engineering (ICSE), 2011 33rd International Conference On, pp. 481-490, (2011); Ghotra B., McIntosh S., Hassan A.E., A large-scale study of the impact of feature selection techniques on defect classification models, Proc. of the International Conference On Mining Software Repositories (MSR), (2017); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, Proceedings of the 38th International Conference On Software Engineering, pp. 297-308, (2016); Hinton G.E., Osindero S., Teh Y.-W., A fast learning algorithm for deep belief nets, Neural Computation, 18, 7, pp. 1527-1554, (2006); Yang X., Lo D., Xia X., Zhang Y., Sun J., Deep learning for justin-time defect prediction, Software Quality, Reliability and Security (QRS), 2015 IEEE International Conference On. IEEE, pp. 17-26, (2015); Loyola P., Matsuo Y., Learning graph representations for defect prediction, Proceedings of the 39th International Conference On Software Engineering Companion, pp. 265-267, (2017); Perozzi B., Kulkarni V., Skiena S., Walklets: Multiscale Graph Embeddings for Interpretable Network Classification, (2016); Grover A., Leskovec J., Node2vec: Scalable Feature Learning for Networks, (2016); Cao S., Lu W., Xu Q., Deep Neural Networks for Learning Graph Representations, (2016); Yanardag P., Vishwanathan S., Deep graph kernels, Proceedings of the 21th ACM SIGKDD International Conference On Knowledge Discovery and Data Mining, pp. 1365-1374, (2015); Tang J., Qu M., Wang M., Zhang M., Yan J., Mei Q., Line: Large-scale information network embedding, Proceedings of the 24th International Conference On World Wide Web, Ser. WWW '15, pp. 1067-1077, (2015); Cao S., Lu W., Xu Q., Grarep: Learning graph representations with global structural information, Proceedings of the 24th ACM International On Conference On Information and Knowledge Management, Ser. CIKM '15, pp. 891-900, (2015); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, Proceedings of ICLR'16, (2016); Niepert M., Ahmed M., Kutzkov K., Learning Convolutional Neural Networks for Graphs, (2016); Bourigault S., Lamprier S., Gallinari P., Representation learning for information diffusion through social networks: An embedded cascade model, Proceedings of the Ninth ACM International Conference On Web Search and Data Mining, Ser. WSDM '16, pp. 573-582, (2016); Ni Y., Xu Q.K., Cao F., Mass Y., Sheinwald D., Zhu H.J., Cao S.S., Semantic documents relatedness using concept graph representation, Proceedings of the Ninth ACM International Conference On Web Search and Data Mining, pp. 635-644, (2016); White M., Vendome C., Linares-Vasquez M., Poshyvanyk D., Toward deep learning software repositories, Proceedings of the 12th Working Conference On Mining Software Repositories, Ser. MSR '15, pp. 334-345, (2015); Mou L., Li G., Liu Y., Peng H., Jin Z., Xu Y., Zhang L., Building Program Vector Representations for Deep Learning, (2014); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, International Conference On Machine Learning (ICML), (2016); Loyola P., Marrese-Taylor E., Matsuo Y., A neural architecture for generating natural language descriptions from source code changes, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pp. 287-292, (2017); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proceedings of the 31st IEEE/ACM International Conference On Automated Software Engineering. ACM, pp. 87-98, (2016); Gu X., Zhang H., Zhang D., Kim S., Deep Api Learning, (2016); Ye X., Shen H., Ma X., Bunescu R., Liu C., From word embeddings to document similarities for improved information retrieval in software engineering, Proceedings of the 38th International Conference On Software Engineering. ACM, pp. 404-415, (2016); German D.M., Hassan A.E., Robles G., Change impact graphs: Determining the impact of prior codechanges, Information and Software Technology, 51, 10, pp. 1394-1408, (2009); Alam O., Adams B., Hassan A.E., A study of the time dependence of code changes, Reverse Engineering 2009. WCRE'09. 16th Working Conference On. IEEE, pp. 21-30, (2009); Herzig K., Zeller A., Mining cause-effect-chains from version histories, Software Reliability Engineering (ISSRE), 2011 IEEE 22nd International Symposium On. IEEE, pp. 60-69, (2011); Firth J.R., A Synopsis of Linguistic Theory, 1930-1955, (1957); Mikolov T., Chen K., Corrado G., Dean J., Efficient Estimation of Word Representations in Vector Space, (2013); Bishop C.M., Pattern recognition, Machine Learning, 128, pp. 1-58, (2006); Goldberg Y., Levy O., Word2vec Explained: Deriving Mikolov, et Al.'s Negative-sampling Word-embedding Method, (2014); Rong X., Word2vec Parameter Learning Explained, (2014); Cancho R.F.I., Sole R.V., The small world of human language, Proceedings of the Royal Society of London B: Biological Sciences, 268, 1482, pp. 2261-2265, (2001); Le Q.V., Mikolov T., Distributed representations of sentences and documents, ICML, 14, pp. 1188-1196, (2014); Bottou L., Large-scale machine learning with stochastic gradient descent, Proceedings of COMPSTAT'2010, pp. 177-186, (2010); Morin F., Bengio Y., Hierarchical probabilistic neural network language model, Aistats, 5, pp. 246-252, (2005); Maaten L.V.D., Hinton G., Visualizing data using t-sne, Journal of Machine Learning Research, 9, pp. 2579-2605, (2008)",IEEE; IEEE Computer Society; IEEE Reliability Society,"28th IEEE International Symposium on Software Reliability Engineering, ISSRE 2017",23 October 2017 through 26 October 2017,Toulouse,132566,English,Conference paper,Final,,Scopus,2-s2.0-85040798659,140
Orvalho P.; Piepenbrock J.; Janota M.; Manquinho V.,"Orvalho, Pedro (57212021087); Piepenbrock, Jelle (57222185731); Janota, Mikoláš (23485687000); Manquinho, Vasco (6507501441)",57212021087; 57222185731; 23485687000; 6507501441,Graph Neural Networks for Mapping Variables Between Programs,2023,Frontiers in Artificial Intelligence and Applications,372,,,1811,1818,7,0,10.3233/FAIA230468,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175817799&doi=10.3233%2fFAIA230468&partnerID=40&md5=bad761c4241bb9c0564fa129bd2312a8,"Automated program analysis is a pivotal research domain in many areas of Computer Science - Formal Methods and Artificial Intelligence, in particular. Due to the undecidability of the problem of program equivalence, comparing two programs is highly challenging. Typically, in order to compare two programs, a relation between both programs' sets of variables is required. Thus, mapping variables between two programs is useful for a panoply of tasks such as program equivalence, program analysis, program repair, and clone detection. In this work, we propose using graph neural networks (GNNs) to map the set of variables between two programs based on both programs' abstract syntax trees (ASTs). To demonstrate the strength of variable mappings, we present three use-cases of these mappings on the task of program repair to fix well-studied and recurrent bugs among novice programmers in introductory programming assignments (IPAs). Experimental results on a dataset of 4166 pairs of incorrect/correct programs show that our approach correctly maps 83% of the evaluation dataset. Moreover, our experiments show that the current state-of-the-art on program repair, greatly dependent on the programs' structure, can only repair about 72% of the incorrect programs. In contrast, our approach, which is solely based on variable mappings, can repair around 88.5%. © 2023 The Authors.","Ahmed U.Z., Fan Z., Yi J., Al-Bataineh O.I., Roychoudhury A., Verifix: Verified repair of programming assignments, ACM Trans. Softw. Eng. Methodol; Aho A.V., Sethi R., Ullman J.D., Compilers: Principles, Techniques, and Tools, Addison-Wesley series in computer science, (1986); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, 6th International Conference on Learning Representations, ICLR 2018, (2018); Allamanis M., Jackson-Flux H., Brockschmidt M., Self-supervised bug detection and repair, NeurIPS, (2021); Ba L.J., Kiros J.R., Hinton G.E., Layer normalization, (2016); Churchill B.R., Padon O., Sharma R., Aiken A., Semantic program alignment for equivalence checking, Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI, pp. 1027-1040, (2019); Cummings D., Nassar M., Structured citation trend prediction using graph neural networks, ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 3897-3901, (2020); Glassman E.L., Scott J., Singh R., Guo P.J., Miller R.C., Overcode: Visualizing variation in student solutions to programming problems at scale, ACM Trans. CHI, (2015); Zarathustra A.G., Jakubuv J., Kaliszyk C., Olsak M., Piepenbrock J., Urban J., The isabelle ENIGMA, 13th International Conference on Interactive Theorem Proving, ITP 2022 volume 237 of LIPIcs, pp. 161-1621, (2022); Gulwani S., Radicek I., Zuleger F., Automated clustering and program repair for introductory programming assignments, PLDI 2018, pp. 465-480, (2018); Gupta R., Kanade A., Shevade S.K., Deep reinforcement learning for syntactic error repair in student programs, The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, pp. 930-937, (2019); Gupta R., Pal S., Kanade A., Shevade S.K., Deepfix: Fixing common C language errors by deep learning, AAAI 2017, pp. 1345-1351, (2017); Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, 8th International Conference on Learning Representations, ICLR, (2020); Hopcroft J.E., Motwani R., Ullman J.D., Introduction to automata theory, languages, and computation, (2007); Jiang L., Misherghi G., Su Z., Glondu S., DECKARD: Scalable and accurate tree-based detection of code clones, 29th International Conference on Software Engineering (ICSE 2007), pp. 96-105, (2007); Jose M., Majumdar R., Cause clue clauses: Error localization using maximum satisfiability, Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2011, pp. 437-446, (2011); Karampatsis R., Sutton C., How often do singlestatement bugs occur: The manysstubs4j dataset, MSR 2020, pp. 573-577, (2020); Ke Y., Stolee K.T., Le Goues C., Brun Y., Repairing programs with semantic code search (T), 30th IEEE/ACM International Conference on Automated Software Engineering, ASE 2015, pp. 295-306, (2015); Kingma D.P., Ba J., Adam: A method for stochastic optimization, 3rd International Conference on Learning Representations, ICLR 2015, (2015); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5th International Conference on Learning Representations, ICLR 2017, (2017); Konighofer R., Bloem R., Automated error localization and correction for imperative programs, International Conference on Formal Methods in Computer-Aided Design, FMCAD '11, pp. 91-100, (2011); Lamraoui S., Nakajima S., A formula-based approach for automatic fault localization of imperative programs, International Conference on Formal Engineering Methods, ICFEM 2014, (2014); Lamraoui S., Nakajima S., A formula-based approach for automatic fault localization of multi-fault programs, JIP, (2016); Liu X., Wang S., Wang P., Wu D., Automatic grading of programming assignments: An approach based on formal semantics, ICSE (SEET) 2019, pp. 126-137, (2019); Liu X., Jang J., Sundaresan N., Allamanis M., Svyatkovskiy A., Adaptivepaste: Code adaptation through learning semantics-aware variable usage representations, (2022); Orvalho P., Janota M., Manquinho V., CPack of IPAs: A C90 Program Benchmark of Introductory Programming Assignments, (2022); Orvalho P., Janota M., Manquinho V., InvAASTCluster: On Applying Invariant-Based Program Clustering to Introductory Programming Assignments, (2022); Orvalho P., Janota M., Manquinho V., MultIPAs: Applying Program Transformations to Introductory Programming Assignments for Data Augmentation, Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2022, pp. 1657-1661, (2022); Orvalho P., Piepenbrock J., Janota M., Manquinho V., Project Proposal: Learning Variable Mappings to Repair Programs, 7th Conference on Artificial Intelligence and Theorem Proving, AITP, (2022); Orvalho P., Piepenbrock J., Janota M., Manquinho V., Graph Neural Networks For Mapping Variables between Programs-Extended Version, (2023); Pradel M., Sen K., Deepbugs: A learning approach to name-based bug detection, ACM Program. Lang, 2, (2018); Rice H.G., Classes of recursively enumerable sets and their decision problems, Transactions of the American Mathematical Society, 74, 2, pp. 358-366, (1953); Schlichtkrull M.S., Kipf T.N., Bloem P., Van Den Berg R., Titov I., Welling M., Modeling relational data with graph convolutional networks, The Semantic Web-15th International Conference, ESWC 2018 volume 10843 of Lecture Notes in Computer Science, pp. 593-607, (2018); Tan S.H., Yi J., Mechtaev Y.S., Roychoudhury A., Codeflaws: A programming competition benchmark for evaluating automated program repair tools, Proceedings of the 39th International Conference on Software Engineering, ICSE 2017, pp. 180-182, (2017); Tarlow D., Moitra S., Rice A., Chen Z., Manzagol P., Sutton C., Aftandilian E., Learning to fix build errors with graph2diff neural networks, ICSE '20: 42nd International Conference on Software Engineering, pp. 19-20, (2020); Vasic M., Kanade A., Maniatis P., Bieber D., Singh R., Neural program repair by jointly learning to localize and repair, 7th International Conference on Learning Representations, ICLR 2019. OpenReview.net, (2019); Vijaymeena M.K., Kavitha K., A survey on similarity measures in text mining, Machine Learning and Applications: An International Journal, 3, 2, pp. 19-28, (2016); Wang K., Singh R., Su Z., Dynamic neural program embeddings for program repair, 6th International Conference on Learning Representations, ICLR 2018. OpenReview.net, (2018); Wang Y., Wang K., Gao F., Wang L., Learning semantic program embeddings with graph interval neural network, Proc. ACM Program. Lang, 4, pp. 1327-1371, (2020); Yasunaga M., Liang P., Graph-based, self-supervised program repair from diagnostic feedback, ICML 2020 volume 119 of Proceedings of Machine Learning Research, pp. 10799-10808, (2020); Zugner D., Kirschstein T., Catasta M., Leskovec J., Gunnemann S., Language-agnostic representation learning of source code from structure and context, 9th International Conference on Learning Representations, ICLR 2021, (2021)",Amazon Alexa; APTIV; et al.; Hewlett Packard; IDEAS; Software Force,"26th European Conference on Artificial Intelligence, ECAI 2023",30 September 2023 through 4 October 2023,Krakow,193052,English,Conference paper,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85175817799,141
Romanov V.; Ivanov V.,"Romanov, Vitaly (57206352983); Ivanov, Vladimir (57195101229)",57206352983; 57195101229,Assessing the Importance of Global Relationships for Source Code Analysis Using Graph Neural Networks,2023,Lecture Notes in Networks and Systems,716 LNNS,,,437,447,10,0,10.1007/978-3-031-35501-1_44,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164256776&doi=10.1007%2f978-3-031-35501-1_44&partnerID=40&md5=a05fe0297af81215f9c24d1f6f3e2057,"Representing the source code as a sequence of tokens does not capture long-distance dependencies and inter-project dependencies. In this study, we analyze to which extent inter-project (global) relationships can be used in machine learning tasks related to source code analysis. Our findings show that information implicitly stored in inter-project relationships can be used to select the next called function among candidates with an accuracy of 92%. We demonstrate that source code embeddings achieve the best performance on transfer learning tasks when they are computed with graph neural networks in a multitask mode. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, International Conference on Learning Representations (ICLR), (2018); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), pp. 404-419; Ben-Nun T., Jakobovits A.S., Hoefler T., Neural code comprehension: a learnable representation of code semantics, Advances in Neural Information Processing Systems, December 2018 (NeurIPS), pp. 3585-3597, (2018); Brauckmann A., Goens A., Ertel S., Castrillon J., Compiler-based graph representations for deep learning models of code, Proceedings of the 29th International Conference on Compiler Construction, pp. 201-211, (2020); Cvitkovic M., Singh B., Anandkumar A., Deep learning on code with an unbounded vocabulary, Machine Learning for Programming (ML4P) Workshop at Federated Logic Conference (FLoC) (2)018; DeFreez D., Thakur A.V., Rubio-Gonzalez C., Path-based function embedding and its application to error-handling specification mining, ESEC/FSE 2018-Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 423-433, (2018); Dinella E., Et al., Hoppity: learning graph transformations to detect and fix bugs in programs, ICLR, 2020, pp. 1-17, (2020); Kanade A., Maniatis P., Balakrishnan G., Shi K., Pre-trained Contextual Embedding of Source Code, pp. 1-22, (2019); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in Neural Information Processing Systems, pp. 3111-3119, (2013); Raychev V., Vechev M., Krause A., Predicting program properties from “big code”, Proceedings of the 42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pp. 111-124, (2015); Wan Y., Et al., Multi-modal attention network learning for semantic source code retrieval, Proceedings-2019 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019, pp. 13-25, (2019); Wang Y., Gao F., Wang L., Wang K., Learning a Static Bug Finder from Data, (2019); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings-International Conference on Software Engineering, pp. 783-794, (2019); Zhou J., Et al., Graph neural networks: a review of methods and applications, AI Open, 1, pp. 57-81, (2020)",,"22nd International Conference on Intelligent Systems Design and Applications, ISDA 2022",12 December 2022 through 14 December 2022,"Virtual, Online",296129,English,Conference paper,Final,,Scopus,2-s2.0-85164256776,142
Vytovtov P.; Chuvilin K.,"Vytovtov, Petr (57199324190); Chuvilin, Kirill (57191364424)",57199324190; 57191364424,Unsupervised classifying of software source code using graph neural networks,2019,"Conference of Open Innovation Association, FRUCT",2019-April,,8711909,518,524,6,7,10.23919/FRUCT.2019.8711909,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066427020&doi=10.23919%2fFRUCT.2019.8711909&partnerID=40&md5=321504e348d93cb779e51a5c899811fc,Usually automated programming systems consist of two parts: Source code analysis and source code generation. This paper is focused on the first part. Automated source code analysis can be useful for errors and vulnerabilities searching and for representing source code snippets for further investigating. Also gotten representations can be used for synthesizing source code snippets of certain types. A machine learning approach is used in this work. The training set is formed by augmented abstract syntax trees of Java classes. A graph autoencoder is trained and a latent representation of Java classes graphs is inspected. Experiments showed that the proposed model can split Java classes graphs to common classes with some business logic implementation and interfaces and utility classes. The results are good enough be used for more accurate software source code generation. © 2019 FRUCT.,"Choi M., Jeong S., Oh H., Choo J., End-to-end prediction of buffer overruns from raw source code via neural memory networks, IJCAI, (2017); Harer J.A., Kim L.Y., Russell R.L., Ozdemir O., Kosta L.R., Rangamani A., Hamilton L.H., Centeno G.I., Key J.R., Ellingwood P.M., McConley M.W., Opper J.M., Chin P., Lazovich T., Automated software vulnerability detection with machine learning, IWSPA, (2018); Vytovtov P., Chuvilin K., Prediction of common weakness probability in c/c++ source code using recurrent neural networks, FRUCT, 21; Wang K., Singh R., Su Z., Dynamic neural program embedding for program repair, ICLR, (2018); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, ICLR, (2018); Alon U., Levy O., Yahav E., Code2seq: Generating sequences from structured representations of code, ICLR, (2019); Cvitkovic M., Singh B., Anandkumar A., Deep learning on code with an unbounded vocabulary, CAV, (2018); Battaglia P.W., Hamrick J.B., Bapst V., Sanchez-Gonzalez A., Zambaldi V., Malinowski M., Tacchetti A., Raposo D., Santoro A., Faulkner R., Gulcehre C., Song F., Ballard A., Gilmer J., Dahl G., Vaswani A., Allen K., Nash C., Langston V., Dyer C., Heess N., Wierstra D., Kohli P., Botvinick M., Vinyals O., Li Y., Pascanu R., Relational Inductive Biases, Deep Learning, and Graph Networks, (2018); MacQueen J., Some methods for classification and analysis of multivariate observations, Proc. 5th Berkeley Symp. on Math. Statistics and Probability, (1967); Ivannikov V.P., Belevantsev A.A., Borodin A.E., Ignatiev V.N., Zhurikhin D.M., Avetisyan A.I., Static analyzer svace for finding of defects in program source code, Proc. of ISP RAS, pp. 231-250, (2014); The LLVM Compiler Infrastructure Project; The History of the !Exploitable Crash Analyzer-Security Research & Defence; Borodin A.E., Belevancev A.A., A static analysis tool svace as a collection of analyzers with various complexity levels, Proc. of ISP RAS, pp. 111-132, (2015); PVS-Studio: Static Code Analysis for C C++C# and Java; Cppcheck-A tool for static c/c++ code analysis; Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Computing Surveys, 51, 4, (2017); Hinton G.E., Salakhutdinov R.R., Reducing the dimensionality of data with neural networks, Science, 313, 5786, (2006); Wu Y., Schuster M., Chen Z., Le Q.V., Norouzi M., MacHerey W., Krikun M., Cao Y., Gao Q., MacHerey K., Klingner J., Shah A., Johnson M., Liu X., Kaiser U., Gouws S., Kato Y., Kudo T., Kazawa H., Stevens K., Kurian G., Patil N., Wang W., Young C., Smith J., Riesa J., Rudnick A., Vinyals O., Corrado G., Hughes M., Dean J., Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation, (2016); Chen X., Liu C., Song D., Tree-to-tree neural networks for program translation, NeurIPS, (2018); Victoria Lin X., Wang C., Zettlemoyer L., Ernst M.D., Nl2bash: A corpus and semantic parser for natural language interface to the linux operating system, LREC, (2018); Scarselli F., Gori M., Tsoi A., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Transactions on Neural Networks, 20, 1, pp. 61-80, (2009); Defferrard M., Bresson X., Vandergheynst P., Convolutional neural networks on graphs with fast localized spectral filtering, NIPS, (2016); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, ICLR, (2017); Rusty1s/pytorch Geometric: Geometric Deep Learning Extension Library for PyTorch; Vytovtov P., Markov E., Source code quality classification based on software metrics, FRUCT, 20; As per the Paper Open Vocabulary Learning on Source Code with a Graph-Structured Cache; Laurens Van Der Maaten L.J.P., Hinton G.E., Visualizing data using t-sne, Journal of Machine Learning Research, 9, pp. 2579-2605, (2008); Kingma D.P., Welling M., Auto-encoding variational bayes, ICLR, (2014); Tolstikhin I., Bousquet O., Gelly S., Schoelkopf B., Wasserstein auto-encoders, ICLR, (2018)",,"24th Conference of Open Innovations Association FRUCT, FRUCT 2019",8 April 2019 through 12 April 2019,Moscow,148023,English,Conference paper,Final,,Scopus,2-s2.0-85066427020,143
Allamanis M.; Brockschmidt M.; Khademi M.,"Allamanis, Miltiadis (39361040300); Brockschmidt, Marc (36676974300); Khademi, Mahmoud (57213246991)",39361040300; 36676974300; 57213246991,Learning to represent programs with graphs,2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",,,,,,,344,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083951710&partnerID=40&md5=db31acc270c475e5034bdd2dae64f154,"Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code’s known sematics. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures. In this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VARNAMING, in which a network attempts to predict the name of a variable given its usage, and VARMISUSE, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VARMISUSE task in many cases. Additionally, our testing showed that VARMISUSE identifies a number of bugs in mature open-source projects. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.","Abadi M., Agarwal A., Barham P., Brevdo E., Chen Z., Citro C., Corrado G.S., Davis A., Dean J., Devin M., Et al., Tensorflow: Large-Scale Machine Learning on Heterogeneous Distributed Systems, (2016); Allamanis M., Barr E.T., Bird C., Sutton C., Learning natural coding conventions, Foundations of Software Engineering (FSE), (2014); Allamanis M., Barr E.T., Bird C., Sutton C., Suggesting accurate method and class names, Foundations of Software Engineering (FSE), (2015); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, International Conference on Machine Learning (ICML), pp. 2091-2100, (2016); Allamanis M., Barr E.T., Devanbu P., Sutton C., A Survey of Machine Learning for Big Code and Naturalness, (2017); Barr E.T., Harman M., Jia Y., Marginean A., Petke J., Automated software transplantation, International Symposium on Software Testing and Analysis (ISSTA), (2015); Al Bessey K.B., Chelf B., Chou A., Fulton B., Hallem S., Henri-Gros C., Kamsky A., McPeak S., Engler D., A few billion lines of code later: Using static analysis to find bugs in the real world, Communications of the ACM, 53, 2, pp. 66-75, (2010); Bhoopchand A., Rocktaschel T., Barr E., Riedel S., Learning Python Code Suggestion with A Sparse Pointer Network, (2016); Bichsel B., Raychev V., Tsankov P., Vechev M., Statistical deobfuscation of android applications, Conference on Computer and Communications Security (CCS), (2016); Bielik P., Raychev V., Vechev M., PHog: Probabilistic model for code, International Conference on Machine Learning (ICML), (2016); Cho K., Van Merrienboer B., Bahdanau D., Bengio Y., On the properties of neural machine translation: Encoder–decoder approaches, Syntax, Semantics and Structure in Statistical Translation, (2014); Defferrard M., Bresson X., Vandergheynst P., Convolutional neural networks on graphs with fast localized spectral filtering, Neural Information Processing Systems (NIPS), pp. 3844-3852, (2016); Gilmer J., Schoenholz S.S., Riley P.F., Vinyals O., Dahl G.E., Neural Message Passing for Quantum Chemistry, (2017); Gori M., Monfardini G., Scarselli F., A new model for learning in graph domains, IEEE International Joint Conference Neural Networks (IJCNN), (2005); Grover A., Leskovec J., Node2vec: Scalable feature learning for networks, International Conference on Knowledge Discovery and Data Mining (SIGKDD), pp. 855-864, (2016); Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P., On the naturalness of software, International Conference on Software Engineering (ICSE), (2012); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks, (2016); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, International Conference on Learning Representations (ICLR), (2015); Maddison C.J., Tarlow D., Structured generative models of natural source code, International Conference on Machine Learning (ICML), (2014); Marcheggiani D., Titov I., Encoding sentences with graph convolutional networks for semantic role labeling, ACL, (2017); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Neural Information Processing Systems (NIPS), (2013); Pennington J., Socher R., Manning C.D., Glove: Global vectors for word representation, EMNLP, (2014); Raychev V., Vechev M., Yahav E., Code completion with statistical language models, Programming Languages Design and Implementation (PLDI), pp. 419-428, (2014); Raychev V., Vechev M., Krause A., Predicting program properties from Big Code, Principles of Programming Languages (POPL), (2015); Raychev V., Bielik P., Vechev M., Probabilistic model for code with decision trees, Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA), (2016); Rice A., Aftandilian E., Jaspan C., Johnston E., Pradel M., Arroyo-Paredes Y., Detecting argument selection defects, Proceedings of the ACM on Programming Languages, 1, OOPSLA, (2017); Schlichtkrull M., Kipf T.N., Bloem P., Van den Berg R., Titov I., Welling M., Modeling Relational Data with Graph Convolutional Network, (2017); Solar-Lezama A., Program Synthesis by Sketching, (2008); Wang M., Tang Y., Wang J., Deng J., Premise selection for theorem proving by deep graph embedding, Advances in Neural Information Processing Systems, pp. 2783-2793, (2017)",,"6th International Conference on Learning Representations, ICLR 2018",30 April 2018 through 3 May 2018,Vancouver,149806,English,Conference paper,Final,,Scopus,2-s2.0-85083951710,144
Guo J.; Liu J.; Liu X.; Wan Y.; Li L.,"Guo, Juncai (58000014600); Liu, Jin (55978402400); Liu, Xiao (52365658400); Wan, Yao (57089582400); Li, Li (58855527300)",58000014600; 55978402400; 52365658400; 57089582400; 58855527300,Summarizing source code with Heterogeneous Syntax Graph and dual position,2023,Information Processing and Management,60,5,103415,,,,1,10.1016/j.ipm.2023.103415,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166740779&doi=10.1016%2fj.ipm.2023.103415&partnerID=40&md5=dc4459ca66428a5d71d2096ab6bda77c,"Code summarization attempts to summarize the semantics of source code by automatically producing brief natural-language descriptions. Most existing work proposes to learn from the Abstract Syntax Tree (AST) and plain text of source code for summary generation. However, little attention has been paid to the structural heterogeneity and layout features of source code. In this paper, we present a novel framework titled HETSUM to address these issues. Specifically, a Heterogeneous Syntax Graph (HSG) is first built by designing six types of augmented edges in AST, which indicates the heterogeneous structure of source code. Meanwhile, a dual position is designed for each token in the source code by considering the layout information. Moreover, we develop a heterogeneous graph neural network in HETSUM to encode the HSG while extracting the code layout features with the Transformer encoder. By assimilating the learned code token vectors into the HSG encoder, HETSUM can capture the relations between its two encoders for improved code representation. To facilitate the generation of high-quality summaries, we integrate a copying mechanism into the decoding procedure while expanding the Transformer decoding sublayer. Extensive experiments on the Java and Python datasets prove that HETSUM is superior to seventeen state-of-the-art baselines. To promote reproducibility studies, we make the implementation of HETSUM available at https://github.com/GJCEXP/HETSUM. © 2023 Elsevier Ltd","Ahmad W., Chakraborty S., Ray B., Chang K.-W., A transformer-based approach for source code summarization, Proceedings of the 58th annual meeting of the Association for Computational Linguistics, pp. 4998-5007, (2020); Ahmad W., Chakraborty S., Ray B., Chang K.-W., Unified pre-training for program understanding and generation, Proceedings of the 2021 conference of the North American Chapter of the Association for Computational Linguistics: Human language technologies, pp. 2655-2668, (2021); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, Proceedings of the 33nd international conference on machine learning, JMLR workshop and conference proceedings, 48, pp. 2091-2100, (2016); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating sequences from structured representations of code, 7th international conference on learning representations, (2019); Ba L.J., Kiros J.R., Hinton G.E., Layer normalization, (2016); Banerjee S., Lavie A., METEOR: an automatic metric for MT evaluation with improved correlation with human judgments, Proceedings of the workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization, pp. 65-72, (2005); Barone A.V.M., Sennrich R., A parallel corpus of Python functions and documentation strings for automated code documentation and code generation, Proceedings of the eighth international joint conference on natural language processing, pp. 314-319, (2017); Bird S., NLTK: The natural language toolkit, ACL 2006, 21st international conference on computational linguistics and 44th annual meeting of the Association for Computational Linguistics, proceedings of the conference, pp. 69-72, (2006); Chen M., Tworek J., Jun H., Yuan Q., Pinto H.P.D., Kaplan J., Et al., Evaluating large language models trained on code, (2021); Cheng W., Hu P., Wei S., Mo R., Keyword-guided abstractive code summarization via incorporating structural and contextual information, Information and Software Technology, 150, (2022); Choi Y., Bak J., Na C., Lee J., Learning sequential and structural information for source code summarization, Findings of the Association for Computational Linguistics, pp. 2842-2851, (2021); Clark K., Luong M., Le Q.V., Manning C.D., ELECTRA: pre-training text encoders as discriminators rather than generators, 8th international conference on learning representations, (2020); de Souza S.C.B., Anquetil N., de Oliveira K.M., A study of the documentation essential to software maintenance, Proceedings of the 23rd annual international conference on design of communication: Documenting & designing for pervasive information, pp. 68-75, (2005); Devlin J., Chang M., Lee K., Toutanova K., BERT: pre-training of deep bidirectional transformers for language understanding, Proceedings of the 2019 conference of the North American Chapter of the Association for Computational Linguistics: Human language technologies, volume 1 (long and short papers), pp. 4171-4186, (2019); Eriguchi A., Hashimoto K., Tsuruoka Y., Tree-to-sequence attentional neural machine translation, Proceedings of the 54th annual meeting of the Association for Computational Linguistics, pp. 823-833, (2016); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Et al., CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics, pp. 1536-1547, (2020); Gao S., Gao C., He Y., Zeng J., Nie L.Y., Xia X., Code structure guided transformer for source code summarization, (2021); Gao Y., Lyu C., M2TS: multi-scale multi-modal approach based on transformer for source code summarization, (2022); Gehring J., Auli M., Grangier D., Yarats D., Dauphin Y.N., Convolutional sequence to sequence learning, Proceedings of the 34th international conference on machine learning, Proceedings of machine learning research, 70, pp. 1243-1252, (2017); Gong Z., Gao C., Wang Y., Gu W., Peng Y., Xu Z., Source code summarization with structural relative position guided transformer, (2022); Gu J., Salza P., Gall H.C., Assemble foundation models for automatic code summarization, IEEE international conference on software analysis, evolution and reengineering, pp. 935-946, (2022); Guo J., Liu J., Wan Y., Li L., Zhou P., Modeling hierarchical syntax structure with triplet position for source code summarization, Proceedings of the 60th annual meeting of the Association for Computational Linguistics (volume 1: long papers), pp. 486-500, (2022); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Et al., GraphCodeBERT: Pre-training code representations with data flow, 9th international conference on learning representations, (2021); Hamilton W.L., Ying R., Leskovec J., Inductive representation learning on large graphs, Proceedings of the 31st international conference on neural information processing systems, pp. 1025-1035, (2017); Haque S., LeClair A., Wu L., McMillan C., Improved automatic summarization of subroutines via attention to file context, MSR ’20: 17th international conference on mining software repositories, pp. 300-310, (2020); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, (2016); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, ICPC ’18: Proceedings of the 26th conference on program comprehension, pp. 200-210, (2018); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation with hybrid lexical and syntactical information, Empirical Software Engineering, 25, 3, pp. 2179-2217, (2020); Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., Summarizing source code with transferred API knowledge, Proceedings of the twenty-seventh international joint conference on artificial intelligence, pp. 2269-2275, (2018); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th annual meeting of the Association for Computational Linguistics (volume 1: long papers), pp. 2073-2083, (2016); Kingma D.P., Ba J., Adam: A method for stochastic optimization, 3rd international conference on learning representations, (2015); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, Proceedings of the 5th international conference on learning representations, (2017); Koehn P., Pharaoh: A beam search decoder for phrase-based statistical machine translation models, Machine translation: From real users to research, 6th conference of the Association for Machine Translation in the Americas, pp. 115-124, (2004); LeClair A., Haque S., Wu L., (2020); Lin C.-Y., ROUGE: A package for automatic evaluation of summaries, Proceedings of the ACL workshop: Text summarization braches out 2004, pp. 74-81, (2004); Liu S., Chen Y., Xie X., Siow J., Liu Y., Automatic code summarization via multi-dimensional semantic fusing in GNN, (2020); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Et al., RoBERTa: A robustly optimized BERT pretraining approach, (2019); OpenAI Y., ChatGPT, (2023); Papineni K., Roukos S., Ward T., Zhu W., Bleu: a method for automatic evaluation of machine translation, Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Phan L.N., Tran H., Le D., Nguyen H., Anibal J.T., Peltekian A., Et al., CoTexT: Multi-task learning with code-text transformer, (2021); Radford A., Wu J., Child R., Luan D., Amodei D., Sutskever I., Language models are unsupervised multitask learners, (2018); Raffel C., Shazeer N., Roberts A., Lee K., Narang S., Matena M., Et al., Exploring the limits of transfer learning with a unified text-to-text transformer, Journal of Machine Learning Research, 21, 140, pp. 1-67, (2020); Shi E., Wang Y., Du L., Zhang H., Han S., Zhang D., Et al., CAST: enhancing code summarization with hierarchical splitting and reconstruction of abstract syntax trees, Proceedings of the 2021 conference on empirical methods in natural language processing, pp. 4053-4062, (2021); Shido Y., Kobayashi Y., Yamamoto A., Miyamoto A., Matsumura T., Automatic source code summarization with extended tree-LSTM, 2019 international joint conference on neural networks, pp. 1-8, (2019); Sun W., Fang C., Chen Y., Zhang Q., Tao G., Han T., Et al., An extractive-and-abstractive framework for source code summarization, (2022); Tai K.S., Socher R., Manning C.D., Improved semantic representations from tree-structured long short-term memory networks, Proceedings of the 53rd annual meeting of the association for computational linguistics and the 7th international joint conference on natural language processing of the Asian Federation of Natural Language Processing, pp. 1556-1566, (2015); Tang Z., Shen X., Li C., Ge J., Huang L., Zhu Z., Et al., AST-trans: Code summarization with efficient tree-structured attention, 44th IEEE/ACM 44th international conference on software engineering, pp. 150-162, (2022); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Et al., Attention is all you need, Advances in neural information processing systems 30: Annual conference on neural information processing systems, pp. 5998-6008, (2017); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Et al., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE international conference on automated software engineering, pp. 397-407, (2018); Wang Y., Dong Y., Lu X., Zhou A., GypSum: Learning hybrid representations for code summarization, (2022); Wang Y., Wang W., Joty S.R., Hoi S.C.H., CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, Proceedings of the 2021 conference on empirical methods in natural language processing, pp. 8696-8708, (2021); Wang R., Zhang H., Lu G., Lyu L., Lyu C., Fret: Functional reinforced transformer with BERT for code summarization, IEEE Access, 8, pp. 135591-135604, (2020); Wang W., Zhang Y., Sui Y., Wan Y., Zhao Z., Wu J., Et al., Reinforcement-learning-guided source code summarization via hierarchical attention, IEEE Transactions on Software Engineering, (2020); Wang W., Zhang Y., Zeng Z., Xu G., Tranŝ3: A transformer-based framework for unifying code summarization and code search, (2020); Wei B., Li Y., Li G., Xia X., Jin Z., Retrieve and refine: exemplar-based neural comment generation, 2020 35th IEEE/ACM international conference on automated software engineering, pp. 349-360, (2020); Wei B., Li G., Xia X., Fu Z., Jin Z., Code generation as a dual task of code summarization, Advances in neural information processing systems, pp. 6563-6573, (2019); Wu H., Zhao H., Zhang M., Code summarization with structure-induced transformer, Findings of the Association for Computational Linguistics, Findings of ACL, pp. 1078-1090, (2021); Xia X., Bao L., Lo D., Xing Z., Hassan A.E., Li S., Measuring program comprehension: a large-scale field study with professionals, Proceedings of the 40th international conference on software engineering, (2018); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE symposium on security and privacy, pp. 590-604, (2014); Yang G., Chen X., Zhou Y., Yu C., DualSC: Automatic generation and summarization of shellcode via transformer and dual learning, IEEE international conference on software analysis, evolution and reengineering, pp. 361-372, (2022); Yao Z., Peddamail J.R., Sun H., CoaCor: Code annotation for code retrieval with reinforcement learning, The world wide web conference, pp. 2203-2214, (2019); Ye W., Xie R., Zhang J., Hu T., Wang X., Zhang S., Leveraging code generation to improve code retrieval and summarization via dual learning, Proceedings of the web conference 2020, pp. 2309-2319, (2020); Zhang J., Wang X., Zhang H., Sun H., Liu X., Retrieval-based neural source code summarization, ICSE ’20: 42nd international conference on software engineering, pp. 1385-1397, (2020); Zhang C., Zhou Q., Qiao M., Tang K., Xu L., Liu F., Re_trans: Combined retrieval and transformer model for source code summarization, (2022); Zhou Y., Shen J., Zhang X., Yang W., Han T., Chen T., Automatic source code summarization with graph attention networks, Journal of Systems and Software, 188, (2022); Zhou Z., Yu H., Fan G., Huang Z., Yang X., Summarizing source code with hierarchical code representation, Information and Software Technology, 143, (2022)",,,,,,English,Article,Final,,Scopus,2-s2.0-85166740779,145
Guo J.; Liu J.; Liu X.; Li L.,"Guo, Juncai (58000014600); Liu, Jin (55978402400); Liu, Xiao (52365658400); Li, Li (58855527300)",58000014600; 55978402400; 52365658400; 58855527300,Summarizing source code through heterogeneous feature fusion and extraction,2024,Information Fusion,103,,102058,,,,0,10.1016/j.inffus.2023.102058,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175065989&doi=10.1016%2fj.inffus.2023.102058&partnerID=40&md5=09eece79fe63cf31d6e773c7b9b352cd,"Code summarization, which seeks to automatically produce a succinct natural-language description to summarize the functionality of source code, plays an essential role in maintaining the software. Currently, plentiful approaches have been proposed to first encode the source code based on its Abstract Syntax Tree (AST), and then decode it into a textual summary. However, most existing works interpret the AST-based syntax structure as a homogeneous graph, without discriminating the different relations between graph nodes (e.g., the parent–child and sibling relations) in a heterogeneous way. To mitigate this issue, this paper proposes HETCOS to extract the syntactic and sequential features of source code by exploring its inherent heterogeneity for code summarization. Specifically, we first build a Heterogeneous Code Graph (HCG) that fuses the syntax structure and code sequence with eight types of edges/relations designed between graph nodes. Moreover, we present a heterogeneous graph neural network for capturing the diverse relations in HCG. The represented HCG is then fed into a Transformer decoder, followed by a multi-head attention-based copying mechanism to support high-quality summary generation. Extensive experiments on the major Java and Python datasets illustrate the superiority of our approach over sixteen state-of-the-art baselines. To promote reproducibility studies, we make the implementation of HETCOS publicly accessible at https://github.com/GJCEXP/HETCOS. © 2023 Elsevier B.V.","de Souza S.C.B., Anquetil N., de Oliveira K.M., A study of the documentation essential to software maintenance, Proceedings of the 23rd Annual International Conference on Design of Communication: Documenting & Designing for Pervasive Information, SIGDOC 2005, Coventry, UK, September 21-23, 2005, pp. 68-75, (2005); Gu X., Zhang H., Kim S., Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE), pp. 933-944, (2018); Yang Z., Shi J., Wang S., Lo D., IncBL: Incremental bug localization, 36th IEEE/ACM International Conference on Automated Software Engineering, ASE 2021, Melbourne, Australia, November 15-19, 2021, pp. 1223-1226, (2021); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation with hybrid lexical and syntactical information, Empir. Softw. Eng., 25, 3, pp. 2179-2217, (2020); Choi Y., Bak J., Na C., Lee J., Learning sequential and structural information for source code summarization, Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021, pp. 2842-2851, (2021); Guo J., Liu J., Wan Y., Li L., Zhou P., Modeling hierarchical syntax structure with triplet position for source code summarization, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, pp. 486-500, (2022); Wang Y., Dong Y., Lu X., Zhou A., GypSum: Learning hybrid representations for code summarization, (2022); Wei B., Li G., Xia X., Fu Z., Jin Z., Code generation as a dual task of code summarization, Advances in Neural Information Processing Systems, pp. 6563-6573, (2019); Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., Summarizing source code with transferred API knowledge, Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018, pp. 2269-2275, (2018); Yao Z., Peddamail J.R., Sun H., CoaCor: Code annotation for code retrieval with reinforcement learning, The World Wide Web Conference, WWW 2019, San Francisco, CA, USA, May 13-17, 2019, pp. 2203-2214, (2019); Ahmad W., Chakraborty S., Ray B., Chang K.-W., A transformer-based approach for source code summarization, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 4998-5007, (2020); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2073-2083, (2016); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating sequences from structured representations of code, 7th International Conference on Learning Representations (ICLR), (2019); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, ICPC ’18: Proceedings of the 26th Conference on Program Comprehension, pp. 200-210, (2018); Shi E., Wang Y., Du L., Zhang H., Han S., Zhang D., Sun H., CAST: enhancing code summarization with hierarchical splitting and reconstruction of abstract syntax trees, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, pp. 4053-4062, (2021); Shido Y., Kobayashi Y., Yamamoto A., Miyamoto A., Matsumura T., Automatic source code summarization with extended tree-LSTM, 2019 International Joint Conference on Neural Networks (IJCNN), pp. 1-8, (2019); Wu H., Zhao H., Zhang M., Code summarization with structure-induced transformer, Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021, Findings of ACL, vol. ACL/IJCNLP 2021, pp. 1078-1090, (2021); Tang Z., Shen X., Li C., Ge J., Huang L., Zhu Z., Luo B., AST-trans: Code summarization with efficient tree-structured attention, 44th IEEE/ACM 44th International Conference on Software Engineering, ICSE 2022, pp. 150-162, (2022); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, 2020 IEEE/ACM International Conference on Program Comprehension (ICPC), (2020); Wang W., Zhang Y., Sui Y., Wan Y., Zhao Z., Wu J., Yu P., Xu G., Reinforcement-learning-guided source code summarization via hierarchical attention, IEEE Trans. Softw. Eng., (2020); Wei B., Li Y., Li G., Xia X., Jin Z., Retrieve and refine: exemplar-based neural comment generation, 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 349-360, (2020); Zhou Y., Shen J., Zhang X., Yang W., Han T., Chen T., Automatic source code summarization with graph attention networks, J. Syst. Softw., 188, (2022); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Hamilton W.L., Ying R., Leskovec J., Inductive representation learning on large graphs, Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS ’17, pp. 1025-1035, (2017); Wang Y., Wang W., Joty S.R., Hoi S.C.H., CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, pp. 8696-8708, (2021); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Chen M., Tworek J., Jun H., Yuan Q., de Oliveira Pinto H.P., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Ray A., Puri R., Krueger G., Petrov M., Khlaaf H., Sastry G., Mishkin P., Chan B., Gray S., Ryder N., Pavlov M., Power A., Kaiser L., Bavarian M., Winter C., Tillet P., Such F.P., Cummings D., Plappert M., Chantzis F., Barnes E., Herbert-Voss A., Guss W.H., Nichol A., Paino A., Tezak N., Tang J., Babuschkin I., Balaji S., Jain S., Saunders W., Hesse C., Carr A.N., Leike J., Achiam J., Misra V., Morikawa E., Radford A., Knight M., Brundage M., Murati M., Mayer K., Welinder P., McGrew B., Amodei D., McCandlish S., Sutskever I., Zaremba W., Evaluating large language models trained on code, (2021); OpenAI M., ChatGPT, (2023); Ye W., Xie R., Zhang J., Hu T., Wang X., Zhang S., Leveraging code generation to improve code retrieval and summarization via dual learning, Proceedings of the Web Conference 2020, pp. 2309-2319, (2020); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016, JMLR Workshop and Conference Proceedings, 48, pp. 2091-2100, (2016); Wang W., Zhang Y., Zeng Z., Xu G., Tranŝ3: A transformer-based framework for unifying code summarization and code search, (2020); Yang G., Chen X., Zhou Y., Yu C., DualSC: Automatic generation and summarization of shellcode via transformer and dual learning, IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022, Honolulu, HI, USA, March 15-18, 2022, pp. 361-372, (2022); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems, pp. 5998-6008, (2017); Liu S., Chen Y., Xie X., Siow J., Liu Y., Automatic code summarization via multi-dimensional semantic fusing in GNN, (2020); Gong Z., Gao C., Wang Y., Gu W., Peng Y., Xu Z., Source code summarization with structural relative position guided transformer, (2022); Tai K.S., Socher R., Manning C.D., Improved semantic representations from tree-structured long short-term memory networks, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015, pp. 1556-1566, (2015); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, SP 2014, pp. 590-604, (2014); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, Proceedings of the 5th International Conference on Learning Representations, ICLR ’17, (2017); Zhang J., Wang X., Zhang H., Sun H., Liu X., Retrieval-based neural source code summarization, ICSE ’20: 42nd International Conference on Software Engineering, pp. 1385-1397, (2020); Haque S., LeClair A., Wu L., McMillan C., Improved automatic summarization of subroutines via attention to file context, MSR ’20: 17th International Conference on Mining Software Repositories, Seoul, Republic of Korea, 29-30 June, 2020, pp. 300-310, (2020); Cheng W., Hu P., Wei S., Mo R., Keyword-guided abstractive code summarization via incorporating structural and contextual information, Inf. Softw. Technol., 150, (2022); Zhang C., Zhou Q., Qiao M., Tang K., Xu L., Liu F., Re_Trans: Combined retrieval and transformer model for source code summarization, (2022); Zhou Z., Yu H., Fan G., Huang Z., Yang X., Summarizing source code with hierarchical code representation, Inf. Softw. Technol., 143, (2022); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); Ahmad W., Chakraborty S., Ray B., Chang K.-W., Unified pre-training for program understanding and generation, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2655-2668, (2021); Phan L.N., Tran H., Le D., Nguyen H., Anibal J.T., Peltekian A., Ye Y., CoTexT: Multi-task learning with code-text transformer, (2021); Devlin J., Chang M., Lee K., Toutanova K., BERT: pre-training of deep bidirectional transformers for language understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pp. 4171-4186, (2019); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., RoBERTa: A robustly optimized BERT pretraining approach, (2019); Clark K., Luong M., Le Q.V., Manning C.D., ELECTRA: pre-training text encoders as discriminators rather than generators, 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020, (2020); Raffel C., Shazeer N., Roberts A., Lee K., Narang S., Matena M., Zhou Y., Li W., Liu P.J., Exploring the limits of transfer learning with a unified text-to-text transformer, J. Mach. Learn. Res., 21, 140, pp. 1-67, (2020); Wang R., Zhang H., Lu G., Lyu L., Lyu C., Fret: Functional reinforced transformer with BERT for code summarization, IEEE Access, 8, pp. 135591-135604, (2020); Sun W., Fang C., Chen Y., Zhang Q., Tao G., Han T., Ge Y., You Y., Luo B., An extractive-and-abstractive framework for source code summarization, (2022); Gu J., Salza P., Gall H.C., Assemble foundation models for automatic code summarization, IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022, Honolulu, HI, USA, March 15-18, 2022, pp. 935-946, (2022); Gao Y., Lyu C., M2TS: multi-scale multi-modal approach based on transformer for source code summarization, (2022); Radford A., Wu J., Child R., Luan D., Amodei D., Sutskever I., Language models are unsupervised multitask learners, (2018); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Deng S.K., Clement C.B., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., GraphCodeBERT: Pre-training code representations with data flow, 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021, (2021); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Cai T., Luo S., Xu K., He D., Liu T., Wang L., GraphNorm: A principled approach to accelerating graph neural network training, Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, Proceedings of Machine Learning Research, 139, pp. 1204-1215, (2021); Eriguchi A., Hashimoto K., Tsuruoka Y., Tree-to-sequence attentional neural machine translation, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pp. 823-833, (2016); Bird S., NLTK: the natural language toolkit, ACL 2006, 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, pp. 69-72, (2006); Papineni K., Roukos S., Ward T., Zhu W., Bleu: a method for automatic evaluation of machine translation, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Banerjee S., Lavie A., METEOR: an automatic metric for MT evaluation with improved correlation with human judgments, Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pp. 65-72, (2005); Lin C.-Y., ROUGE: A package for automatic evaluation of summaries, Proceedings of the ACL Workshop: Text Summarization Braches Out 2004, pp. 74-81, (2004); Kingma D.P., Ba J., Adam: A method for stochastic optimization, 3rd International Conference on Learning Representations, (2015); Koehn P., Pharaoh: A beam search decoder for phrase-based statistical machine translation models, Machine Translation: From Real Users to Research, 6th Conference of the Association for Machine Translation in the Americas, AMTA 2004, pp. 115-124, (2004); Shi Y., Huang Z., Feng S., Zhong H., Wang W., Sun Y., Masked label prediction: Unified message passing model for semi-supervised classification, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI 2021, Virtual Event / Montreal, Canada, 19-27 August 2021, pp. 1548-1554, (2021)",,,,,,English,Article,Final,,Scopus,2-s2.0-85175065989,146
Shi C.; Cai B.; Zhao Y.; Gao L.; Sood K.; Xiang Y.,"Shi, Chaochen (57212017242); Cai, Borui (57202788785); Zhao, Yao (57958939600); Gao, Longxiang (36133254500); Sood, Keshav (56416123500); Xiang, Yong (7201978796)",57212017242; 57202788785; 57958939600; 36133254500; 56416123500; 7201978796,CoSS: Leveraging Statement Semantics for Code Summarization,2023,IEEE Transactions on Software Engineering,49,6,,3472,3486,14,1,10.1109/TSE.2023.3256362,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151331220&doi=10.1109%2fTSE.2023.3256362&partnerID=40&md5=f688da43a2e74f73561d98236d57f320,"Automated code summarization tools allow generating descriptions for code snippets in natural language, which benefits software development and maintenance. Recent studies demonstrate that the quality of generated summaries can be improved by using additional code representations beyond token sequences. The majority of contemporary approaches mainly focus on extracting code syntactic and structural information from abstract syntax trees (ASTs). However, from the view of macro-structures, it is challenging to identify and capture semantically meaningful features due to fine-grained syntactic nodes involved in ASTs. To fill this gap, we investigate how to learn more code semantics and control flow features from the perspective of code statements. Accordingly, we propose a novel model entitled CoSS for code summarization. CoSS adopts a Transformer-based encoder and a graph attention network-based encoder to capture token-level and statement-level semantics from code token sequence and control flow graph, respectively. Then, after receiving two-level embeddings from encoders, a joint decoder with a multi-head attention mechanism predicts output sequences verbatim. Performance evaluations on Java, Python, and Solidity datasets validate that CoSS outperforms nine state-of-the-art (SOTA) neural code summarization models in effectiveness and is competitive in execution efficiency. Further, the ablation study reveals the contribution of each model component.  © 1976-2012 IEEE.","Nazar N., Hu Y., Jiang H., Summarizing software artifacts: A literature review, J. Comput. Sci. Technol, 31, 5, pp. 883-909, (2016); Haiduc S., Aponte J., Marcus A., Supporting program comprehension with source code summarization, Proc. IEEE/ACM 32nd Int. Conf. Softw. Eng, pp. 223-226, (2010); Roehm T., Tiarks R., Koschke R., Maalej W., How do professional developers comprehend software?, Proc. IEEE 34th Int. Conf. Softw. Eng, pp. 255-265, (2012); Shi L., Zhong H., Xie T., Li M., An empirical study on evolution of API documentation, Proc. Int. Conf. Fundam. Approaches Softw. Eng., Springer, pp. 416-431, (2011); Forward A., Lethbridge T.C., The relevance of software documentation, tools and technologies: A survey, Proc. ACM Symp. Document Eng, pp. 26-33, (2002); Haiduc S., Aponte J., Moreno L., Marcus A., On the use of automated text summarization techniques for summarizing source code, Proc. IEEE 17th Work. Conf. Reverse Eng, pp. 35-44, (2010); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proc. 54th Annu. Meeting Assoc. Comput. Linguistics, pp. 2073-2083, (2016); Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Comput. Surveys, 51, 4, pp. 1-37, (2018); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proc. 26th Conf. Prog. Comprehension, pp. 200-210, (2018); Wan Y., Et al., Improving automatic source code summarization via deep reinforcement learning, Proc. IEEE/ACM 33rd Int. Conf. Automated Softw. Eng, pp. 397-407, (2018); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, (2017); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proc. 28th Int. Conf. Prog. Comprehension, pp. 184-195, (2020); Shi E., Et al., Cast: Enhancing code summarization with hierarchical splitting and reconstruction of abstract syntax trees, (2021); Gu J., Chen Z., Monperrus M., Multimodal representation for neural code search, Proc. IEEE Int. Conf. Softw. Maintenance Evol, pp. 483-494, (2021); Feng Z., Et al., CodeBERT: A pre-trained model for programming and natural languages, (2020); LaToza T.D., Venolia G., DeLine R., Maintaining mental models: A study of developer work habits, Proc. 28th Int. Conf. Softw. Eng, pp. 492-501, (2006); Singer J., Lethbridge T., Vinson N., Anquetil N., An examination of software engineering work practices, Proc. CASCON 1st Decade High Impact Papers, pp. 174-188, (2010); Bruschi D., Martignoni L., Monga M., Detecting self-mutating malware using control-flow graph matching, Proc. Int. Conf. Detection Intrusions Malware Vulnerability Assessment, Springer, pp. 129-143, (2006); Cesare S., Xiang Y., Classification ofmalware using structured control flow, Proc. 8th Australas. Symp. Parallel Distrib. Comput, pp. 61-70, (2010); Vaswani A., Et al., Attention is all you need, Proc. Adv. Neural Inf. Process. Syst. Annu. Conf. Neural Inf. Process. Syst., Long Beach, CA, USA, pp. 5998-6008, (2017); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); Rosenfeld R., Two decades of statistical language modeling: Where do we go from here?, Proc. IEEE, 88, 8, pp. 1270-1278, (2000); Wang S., Chollak D., Movshovitz-Attias D., Tan L., Bugram: Bug detection with n-gram language models, Proc. IEEE/ACM 31st Int. Conf. Automated Softw. Eng, pp. 708-719, (2016); Grave E., Joulin A., Usunier N., Improving neural language models with a continuous cache, (2016); Wang W., Et al., Reinforcement-learning-guided source code summarization via hierarchical attention, IEEE Trans. Softw. Eng, 48, 1, pp. 102-119, (2022); Devlin J., Chang M.-W., Lee K., Toutanova K., BERT: Pre-training of deep bidirectional transformers for language understanding, (2018); Yang Z., Dai Z., Yang Y., Carbonell J., Salakhutdinov R.R., Le Q.V., XLNet: Generalized autoregressive pretraining for language understanding, Proc. Adv. Neural Inf. Process. Syst, pp. 5753-5763, (2019); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, (2016); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, Proc. 1st Int. Conf. Learn. Representations, Scottsdale, Arizona, USA, (2013); Clevert D.-A., Unterthiner T., Hochreiter S., Fast and accurate deep network learning by exponential linear units (ELUs), (2015); Williams R.J., Zipser D., A learning algorithm for continually running fully recurrent neural networks, Neural Comput, 1, 2, pp. 270-280, (1989); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., CodeSearchNet challenge: Evaluating the state of semantic code search, (2019); Barone A.V.M., Sennrich R., A parallel corpus of Python functions and documentation strings for automated code documentation and code generation, (2017); Wang W., Zhang Y., Zeng Z., Xu G., Trans 3: A transformer-based framework for unifying code summarization and code search, (2020); Shi C., Xiang Y., Yu J., Gao L., Semantic code search for smart contracts, (2021); Feist J., Grieco G., Groce A., Slither: A static analysis framework for smart contracts, Proc. IEEE/ACM 2nd Int. Workshop Emerg. Trends Softw. Eng. Blockchain, pp. 8-15, (2019); Papineni K., Roukos S., Ward T., Zhu W.-J., BLEU: A method for automatic evaluation ofmachine translation, Proc. 40th Annu. Meeting Assoc. Comput. Linguistics, pp. 311-318, (2002); Lin C.-Y., ROUGE: A package for automatic evaluation of summaries, Proc. Conf. Text Summarization Branches Out, pp. 74-81, (2004); Banerjee S., Lavie A., METEOR: An automatic metric for MT evaluation with improved correlation with human judgments, Proc. ACL Workshop Intrinsic Extrinsic Eval. Measures Mach. Transl. Summarization, pp. 65-72, (2005); Vedantam R., Lawrence Zitnick C., Parikh D., Cider: Consensusbased image description evaluation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 4566-4575, (2015); Gao S., Gao C., He Y., Zeng J., Nie L.Y., Xia X., Code structure guided transformer for source code summarization, (2021); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, Proc. IEEE Symp. Secur. Privacy, pp. 590-604, (2014); Hu X., Gao Z., Xia X., Lo D., Yang X., Automating user notice generation for smart contract functions, Proc. IEEE/ACM 36th Int. Conf. Automated Softw. Eng, pp. 5-17, (2021); Liu S., Chen Y., Xie X., Siow J.K., Liu Y., Retrieval-augmented generation for code summarization via hybrid GNN, Proc. 9th Int. Conf. Learn. Representations, Virtual Event, Austria, OpenReview.net, May 3-7, (2021); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating sequences from structured representations of code, (2018); Wang Y., Et al., CoCoSum: Contextual code summarization with multirelational graph neural network, (2021); Wei B., Li Y., Li G., Xia X., Jin Z., Retrieve and refine: Exemplarbased neural comment generation, Proc. IEEE/ACM 35th Int. Conf. Automated Softw. Eng, pp. 349-360, (2020); Stapleton S., Et al., A human study of comprehension and code summarization, Proc. 28th Int. Conf. Prog. Comprehension, pp. 2-13, (2020); Lin T., Wang Y., Liu X., Qiu X., A survey of transformers, (2021); Hill E., Pollock L., Vijay-Shanker K., Automatically capturing source code context of NL-queries for software maintenance and reuse, Proc. IEEE 31st Int. Conf. Softw. Eng, pp. 232-242, (2009); Sridhara G., Pollock L., Vijay-Shanker K., Generating parameter comments and integrating with method summaries, Proc. IEEE 19th Int. Conf. Prog. Comprehension, pp. 71-80, (2011); McBurney P.W., McMillan C., Automatic documentation generation via source code summarization of method context, Proc. 22nd Int. Conf. Prog. Comprehension, pp. 279-290, (2014); McBurney P.W., McMillan C., Automatic source code summarization of context for Java methods, IEEE Trans. Softw. Eng, 42, 2, pp. 103-119, (2016); Abid N.J., Dragan N., Collard M.L., Maletic J.I., Using stereotypes in the automatic generation of natural language summaries for C++ methods, Proc. IEEE Int. Conf. Softw. Maintenance Evol, pp. 561-565, (2015); Rahman M.M., Roy C.K., Keivanloo I., Recommending insightful comments for source code using crowdsourced knowledge, Proc. IEEE 15th Int. Work. Conf. Source Code Anal. Manipulation, pp. 81-90, (2015); Vassallo C., Panichella S., Di Penta M., Canfora G., Codes: Mining source code descriptions from developers discussions, Proc. 22nd Int. Conf. Prog. Comprehension, pp. 106-109, (2014); Wong E., Liu T., Tan L., CloCom: Mining existing source code for automatic comment generation, Proc. IEEE 22nd Int. Conf. Softw.Anal. Evol. Reengineering, pp. 380-389, (2015); LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, Proc. IEEE/ACM 41st Int. Conf. Softw. Eng, pp. 795-806, (2019); Sui Y., Cheng X., Zhang G., Wang H., Flow2vec: Value-flow-based precise code embedding, Proc. ACM Program. Lang, 4, OOPSLA, pp. 1-27, (2020); Sui Y., Xue J., SVF: Interprocedural static value-flow analysis in LLVM, Proc. 25th Int. Conf. Compiler Construction, pp. 265-266, (2016); Wang X., Et al., CODE-MVP: Learning to represent source code from multiple views with contrastive pre-training, (2022); Hua W., Sui Y., Wan Y., Liu G., Xu G., FCCA: Hybrid code representation for functional clone detection using attention networks, IEEE Trans. Rel, 70, 1, pp. 304-318, (2021); Wan Y., Et al., Multi-modal attention network learning for semantic source code retrieval, Proc. IEEE/ACM34th Int. Conf. Automated Softw. Eng, pp. 13-25, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85151331220,147
Zeng J.; Qu Z.; Cai B.,"Zeng, Jianhui (57841928900); Qu, Zhiheng (57841342900); Cai, Bo (35745538800)",57841928900; 57841342900; 35745538800,Structure and Sequence Aligned Code Summarization with Prefix and Suffix Balanced Strategy,2023,Entropy,25,4,570,,,,0,10.3390/e25040570,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156244162&doi=10.3390%2fe25040570&partnerID=40&md5=e6b87370ba5285c63b699000de0567f2,"Source code summarization focuses on generating qualified natural language descriptions of a code snippet (e.g., functionality, usage and version). In an actual development environment, descriptions of the code are missing or not consistent with the code due to human factors, which makes it difficult for developers to comprehend and conduct subsequent maintenance. Some existing methods generate summaries from the sequence information of code without considering the structural information. Recently, researchers have adopted the Graph Neural Networks (GNNs) to capture the structural information with modified Abstract Syntax Trees (ASTs) to comprehensively represent a source code, but the alignment method of the two information encoder is hard to decide. In this paper, we propose a source code summarization model named SSCS, a unified transformer-based encoder–decoder architecture, for capturing structural and sequence information. SSCS is designed upon a structure-induced transformer with three main novel improvements. SSCS captures the structural information in a multi-scale aspect with an adapted fusion strategy and adopts a hierarchical encoding strategy to capture the textual information from the perspective of the document. Moreover, SSCS utilizes a bidirectional decoder which generates a summary from opposite direction to balance the generation performance between prefix and suffix. We conduct experiments on two public Java and Python datasets to evaluate our method and the result show that SSCS outperforms the state-of-art code summarization methods. © 2023 by the authors.","Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, ASE 2018, pp. 397-407; Hill E., Pollock L.L., Vijay-Shanker K., Automatically capturing source code context of NL-queries for software maintenance and reuse, Proceedings of the 31st International Conference on Software Engineering, ICSE 2009, pp. 232-242; Haiduc S., Aponte J., Moreno L., Marcus A., On the Use of Automated Text Summarization Techniques for Summarizing Source Code, Proceedings of the 17th Working Conference on Reverse Engineering, WCRE 2010, pp. 35-44, (2010); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing Source Code using a Neural Attention Model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, (2016); Allamanis M., Peng H., Sutton C., A Convolutional Attention Network for Extreme Summarization of Source Code, Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, 48, pp. 2091-2100; Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., Summarizing Source Code with Transferred API Knowledge, Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018, pp. 2269-2275; Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is All you Need, Proceedings of the Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, pp. 5998-6008; Ahmad W.U., Chakraborty S., Ray B., Chang K., A Transformer-based Approach for Source Code Summarization, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, pp. 4998-5007, (2020); Wu H., Zhao H., Zhang M., Code Summarization with Structure-induced Transformer, Proceedings of the Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021, pp. 1078-1090, (2021); Gao Y., Lyu C., M2TS: Multi-Scale Multi-Modal Approach Based on Transformer for Source Code Summarization, arXiv, (2022); Gong Z., Gao C., Wang Y., Gu W., Peng Y., Xu Z., Source Code Summarization with Structural Relative Position Guided Transformer, Proceedings of the IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022, pp. 13-24; Guo J., Liu J., Wan Y., Li L., Zhou P., Modeling Hierarchical Syntax Structure with Triplet Position for Source Code Summarization, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, pp. 486-500, (2022); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proceedings of the 26th Conference on Program Comprehension, ICPC 2018, pp. 200-210; LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, Proceedings of the 41st International Conference on Software Engineering, ICSE 2019, pp. 795-806, (2019); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating Sequences from Structured Representations of Code, Proceedings of the 7th International Conference on Learning Representations, ICLR 2019; Shido Y., Kobayashi Y., Yamamoto A., Miyamoto A., Matsumura T., Automatic Source Code Summarization with Extended Tree-LSTM, Proceedings of the International Joint Conference on Neural Networks, IJCNN 2019, pp. 1-8, (2019); Wang Y., Dong Y., Lu X., Zhou A., GypSum: Learning Hybrid Representations for Code Summarization, arXiv, (2022); Choi Y., Bak J., Na C., Lee J., Learning Sequential and Structural Information for Source Code Summarization, Proceedings of the Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021, pp. 2842-2851; Wei B., Li G., Xia X., Fu Z., Jin Z., Code Generation as a Dual Task of Code Summarization, Proceedings of the Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, pp. 6559-6569; Liang Y., Zhu K.Q., Automatic Generation of Text Descriptive Comments for Code Blocks, Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), pp. 5229-5236, (2018); Fernandes P., Allamanis M., Brockschmidt M., Structured Neural Summarization, Proceedings of the 7th International Conference on Learning Representations, ICLR 2019; Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated Graph Sequence Neural Networks, Proceedings of the 4th International Conference on Learning Representations, ICLR 2016; LeClair A., Haque S., Wu L., McMillan C., Improved Code Summarization via a Graph Neural Network, Proceedings of the ICPC ’20: 28th International Conference on Program Comprehension, pp. 184-195, (2020); Wang W., Zhang Y., Sui Y., Wan Y., Zhao Z., Wu J., Yu P.S., Xu G., Reinforcement-Learning-Guided Source Code Summarization Using Hierarchical Attention, IEEE Trans. Softw. Eng, 48, pp. 102-119, (2022); Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, pp. 4171-4186, (2019); Raffel C., Shazeer N., Roberts A., Lee K., Narang S., Matena M., Zhou Y., Li W., Liu P.J., Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer, J. Mach. Learn. Res, 21, pp. 140:1-140:67, (2020); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., CodeBERT: A Pre-Trained Model for Programming and Natural Languages, Proceedings of the Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Wang Y., Wang W., Joty S.R., Hoi S.C.H., CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event/Punta Cana, pp. 8696-8708, (2021); Liu L., Utiyama M., Finch A.M., Sumita E., Agreement on Target-bidirectional Neural Machine Translation, Proceedings of the NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 411-416; Papineni K., Roukos S., Ward T., Zhu W., Bleu: a Method for Automatic Evaluation of Machine Translation, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311-318; Banerjee S., Lavie A., METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments, Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization@ACL 2005, pp. 65-72, (2005); Lin C.Y., ROUGE: A Package for Automatic Evaluation of Summaries, Proceedings of the Text Summarization Branches Out, pp. 74-81, (2004)",,,,,,English,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85156244162,148
Guo J.; Liu J.; Liu X.; Wan Y.; Zhao Y.; Li L.; Liu K.; Klein J.; Bissyandé T.F.,"Guo, Juncai (58000014600); Liu, Jin (55978402400); Liu, Xiao (52365658400); Wan, Yao (57089582400); Zhao, Yanjie (57219535472); Li, Li (58855527300); Liu, Kui (57203748234); Klein, Jacques (56282553000); Bissyandé, Tegawendé F. (36080354200)",58000014600; 55978402400; 52365658400; 57089582400; 57219535472; 58855527300; 57203748234; 56282553000; 36080354200,PyScribe–Learning to describe python code,2024,Software - Practice and Experience,54,3,,501,527,26,0,10.1002/spe.3291,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179352137&doi=10.1002%2fspe.3291&partnerID=40&md5=a6f06e9e93298b54afb8224fcc63ac0b,"Code comment generation, which attempts to summarize the functionality of source code in textual descriptions, plays an important role in automatic software development research. Currently, several structural neural networks have been exploited to preserve the syntax structure of source code based on abstract syntax trees (ASTs). However, they can not well capture both the long-distance and local relations between nodes while retaining the overall structural information of AST. To mitigate this problem, we present a prototype tool titled PyScribe, which extends the Transformer model to a new encoder-decoder-based framework. Particularly, the triplet position is designed and integrated into the node-level and edge-level structural features of AST for producing Python code comments automatically. This paper, to the best of our knowledge, makes the first effort to model the edges of AST as an explicit component for improved code representation. By specifying triplet positions for each node and edge, the overall structural information can be well preserved in the learning process. Moreover, the captured node and edge features go through a two-stage decoding process to yield higher qualified comments. To evaluate the effectiveness of PyScribe, we resort to a large dataset of code-comment pairs by mining Jupyter Notebooks from GitHub, for which we have made it publicly available to support further studies. The experimental results reveal that PyScribe is indeed effective, outperforming the state-ofthe-art by achieving an average BLEU score (i.e., av-BLEU) of (Formula presented.) 0.28. © 2023 The Authors. Software: Practice and Experience published by John Wiley & Sons Ltd.","Stueben M., Self-DOCUMENTING CODE: 67–90, (2018); Raskin J., Comments Are More Important Than Code, ACM Queue, 3, (2005); McBurney P.W., McMillan C., Automatic documentation generation via source code summarization of method context, 22nd International Conference on Program Comprehension, ICPC 2014, Hyderabad, India, June 2-3, 2014, pp. 279-290, (2014); Sridhara G., Hill E., Muppaneni D., Pollock L., Vijay-Shanker K., Towards automatically generating summary comments for Java methods, Proceedings of the IEEE/ACM international conference on Automated software engineering, pp. 43-52, (2010); Sridhara G., Pollock L., Vijay-Shanker K., Automatically detecting and describing high level actions within methods, 2011 33rd International Conference on Software Engineering (ICSE), pp. 101-110, (2011); Robillard P., Schematic pseudocode for program constructs and its computer automation by SCHEMACODE, Commun ACM, 29, pp. 1072-1089, (1986); Ohba M., Gondow K., Toward mining “concept keywords” from identifiers in large software projects, ACM SIGSOFT Softw Eng Notes, 30, 4, pp. 1-5, (2005); Maskeri G., Sarkar S., Heafield K., Mining business topics in source code using latent dirichlet allocation, Proceedings of the 2008 1st India Software Engineering Conference, ISEC'08, pp. 113-120, (2008); Haiduc S., Aponte J., Marcus A., Supporting program comprehension with source code summarization, Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering, pp. 223-226, (2010); Wong E., Yang J., Tan L., AutoComment: Mining question and answer sites for automatic comment generation, 2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 562-567, (2013); Wong E., Liu T., Tan L., CloCom: Mining existing source code for automatic comment generation, 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER), pp. 380-389, (2015); Vaswani A., Shazeer N., Parmar N., Et al., Attention is all you need, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems, pp. 5998-6008, (2017); Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., Summarizing source code with transferred API knowledge, Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018, pp. 2269-2275, (2018); Wei B., Li G., Xia X., Fu Z., Jin Z., Code generation as a dual task of code summarization, Advances in Neural Information Processing Systems, pp. 6563-6573, (2019); Ahmad W., Chakraborty S., Ray B., Chang K.W., A Transformer-based approach for source code summarization, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 4998-5007, (2020); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, ICPC '18: Proceedings of the 26th Conference on Program Comprehension, pp. 200-210, (2018); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation with hybrid lexical and syntactical information, Empir Softw Eng, 25, pp. 2179-2217, (2020); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating sequences from structured representations of code, 7th International Conference on Learning Representations (ICLR), (2019); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, 2020 IEEE/ACM International Conference on Program Comprehension (ICPC), pp. 184-195, (2020); Liu S., Chen Y., Xie X., Siow J., Liu Y., Automatic code summarization via multi-dimensional semantic fusing in GNN, CoRR, (2020); Wan Y., Zhao Z., Yang M., Et al., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Liang Y., Zhu K.Q., Automatic generation of text descriptive comments for code blocks, Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), pp. 5229-5236, (2018); Gehring J., Auli M., Grangier D., Yarats D., Dauphin Y.N., Convolutional sequence to sequence learning, Proceedings of the 34th International Conference on Machine Learning, 70, pp. 1243-1252, (2017); Barone A.V.M., Sennrich R., A parallel corpus of python functions and documentation strings for automated code documentation and code generation, Proceedings of the Eighth International Joint Conference on Natural Language Processing, IJCNLP 2017, pp. 314-319, (2017); LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 795-806, (2019); Chen M., Tworek J., Jun H., Et al., Evaluating large language models trained on code, CoRR, (2021); Wang Y., Wang W., Joty S.R., Hoi S.C.H., CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, pp. 8696-8708, (2021); ChatGPT, (2023); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2073-2083, (2016); Tian H., Liu K., Kabore A.K., Et al., Evaluating representation learning of code changes for predicting patch correctness in program repair, 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020, pp. 981-992, (2020); Wan Y., Shu J., Sui Y., Et al., Multi-modal attention network learning for semantic source code retrieval, 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019, pp. 13-25, (2019); Shido Y., Kobayashi Y., Yamamoto A., Miyamoto A., Matsumura T., Automatic source code summarization with extended tree-LSTM, 2019 International Joint Conference on Neural Networks (IJCNN), pp. 1-8, (2019); Zhou Z., Yu H., Fan G., Effective approaches to combining lexical and syntactical information for code summarization, Softw Pract Exp, 50, 12, pp. 2313-2336, (2020); Choi Y., Bak J., Na C., Lee J., Learning sequential and structural information for source code summarization, Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021, pp. 2842-2851, (2021); Wang X., Wang Y., Mi F., Et al., SynCoBERT: Syntax-guided multi-modal contrastive pre-training for code representation, (2021); Zhao Y., Li L., Wang H., He Q., Grundy J., APIMatchmaker: Matching the right APIs for supporting the development of android apps, IEEE Trans Softw Eng, (2022); Zhao Y., Li L., Sun X., Liu P., Grundy J.C., Icon2Code: Recommending code implementations for Android GUI components, Inf Softw Technol, 138, (2021); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016, 48, pp. 2091-2100, (2016); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proceedings of the 26th International Joint Conference on Artificial Intelligence, pp. 3034-3040, (2017); Cho K., Merrienboer V., Gulcehre C., Et al., Learning phrase representations using RNN encoder-decoder for statistical machine translation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pp. 1724-1734, (2014); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, Proceedings of the 5th International Conference on Learning Representations, (2017); Wang W., Zhang Y., Sui Y., Et al., Reinforcement-learning-guided source code summarization via hierarchical attention, IEEE Trans Softw Eng, (2020); Bird S., NLTK: The natural language toolkit, ACL 2006, 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, pp. 69-72, (2006); Liu K., Kim D., Bissyande T.F., Yoo S., Le Traon Y., Mining fix patterns for FindBugs violations, IEEE Trans Softw Eng, 47, 1, pp. 165-188, (2018); Liu K., Kim D., Bissyande T.F., Et al., Learning to spot and refactor inconsistent method names, Proceedings of the 41st International Conference on Software Engineering, pp. 1-12, (2019); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Proceedings of the 30th AAAI Conference on Artificial Intelligence, pp. 1287-1293, (2016); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings of the IEEE/ACM 41st International Conference on Software Engineering, pp. 783-794, (2019); Le Q.V., Mikolov T., Distributed representations of sentences and documents, Proceedings of the 31st International Conference on Machine Learning, pp. 1188-1196, (2014); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Ba L.J., Kiros J.R., Hinton G.E., Layer normalization, CoRR, (2016); Sun Z., Li L., Liu Y., Du X., Li L., On the importance of building high-quality training datasets for neural code search, The 44th International Conference on Software Engineering (ICSE 2022), (2022); Repplinger J., Chowdhury G.G., Introduction to Modern Information Retrieval, 72, 2, (2019); Kingma D.P., Ba J., Adam: A method for stochastic optimization, 3rd International Conference on Learning Representations, (2015); Papineni K., Roukos S., Ward T., Zhu W., Bleu: A method for automatic evaluation of machine translation, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Banerjee S., Lavie A., METEOR: An automatic metric for MT evaluation with improved correlation with human judgments, Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pp. 65-72, (2005); Lin C.Y., ROUGE: A Package for Automatic Evaluation of Summaries, Proceedings of the ACL Workshop: Text Summarization Braches Out 2004, pp. 74-81, (2004); See A., Liu P.J., Manning C.D., Get to the point: summarization with pointer-generator networks, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pp. 1073-1083, (2017); Zhang J., Wang X., Zhang H., Sun H., Liu X., Retrieval-based neural source code summarization, ICSE '20: 42nd International Conference on Software Engineering, pp. 1385-1397, (2020); Eriguchi A., Hashimoto K., Tsuruoka Y., Tree-to-sequence attentional neural machine translation, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pp. 823-833, (2016); Wu H., Zhao H., Zhang M., Code Summarization with Structure-induced Transformer, ACL/IJCNLP 2021 of Findings of ACL, pp. 1078-1090, (2021); Feng Z., Guo D., Tang D., Et al., CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Liu Y., Ott M., Goyal N., Et al., RoBERTa: A robustly optimized BERT pretraining approach, CoRR, (2019); Raffel C., Shazeer N., Roberts A., Et al., Exploring the limits of transfer learning with a unified text-to-text transformer, J Mach Learn Res, 21, 140, pp. 1-67, (2020); Wang Y., Dong Y., Lu X., Zhou A., GypSum: Learning hybrid representations for code summarization, Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension, (2022); Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-training of deep bidirectional transformers for language understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, pp. 4171-4186, (2019); Zhao Y., Li L., Wang H., Et al., On the impact of sample duplication in machine-learning-based android malware detection, ACM Trans Softw Eng Methodol, 30, 3, pp. 40:1-40:38, (2021); Tao W., Wang Y., Shi E., Et al., On the evaluation of commit message generation models: An experimental study, IEEE International Conference on Software Maintenance and Evolution, ICSME 2021, pp. 126-136, (2021); LeClair A., McMillan C., Recommendations for datasets for source code summarization, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, pp. 3931-3937, (2019); Allamanis M., The adverse effects of code duplication in machine learning models of code, Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software, Onward! 2019, Athens, Greece, October 23-24, 2019, pp. 143-153, (2019)",,,,,,English,Article,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85179352137,149
Zeng J.; He Y.; Zhang T.; Xu Z.; Han Q.,"Zeng, Jianwei (58062883200); He, Yutong (58066440700); Zhang, Tao (55547105895); Xu, Zhou (57212062746); Han, Qiang (36739002000)",58062883200; 58066440700; 55547105895; 57212062746; 36739002000,CLG-Trans: Contrastive learning for code summarization via graph attention-based transformer,2023,Science of Computer Programming,226,,102925,,,,1,10.1016/j.scico.2023.102925,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146339240&doi=10.1016%2fj.scico.2023.102925&partnerID=40&md5=4eafb730187cf493a6ec32d10b197f44,"Automated code summarization is the task of automatically generating natural language descriptions of source code, which is an important research topic in the software engineering field. Many methods in recent studies were based on deep learning techniques, which effectively improve the performance of code summarization. Most of the existing code summarization methods use different kinds of neural networks to learn source code information. Some methods use graph neural network (GNN) to represent abstract syntax tree (AST) and fuse the structural information of source code. However, these methods still have two important issues: 1) they cannot solve the Out-Of-Vocabulary (OOV) problem effectively; 2) the structural information of source code they can capture is limited. In order to address the above-mentioned challenges, we propose a novel automated code summarization model named CLG-Trans in this work. This model uses the Byte Pair Encoding (BPE) algorithm and pointer-generator network to tackle the OOV problem. Then it utilizes the fusion of contrastive learning strategy and dynamic graph attention mechanism to effectively capture rich structure information of source code sequences. Experimental results on Funcom dataset show that CLG-Trans outperforms seven state-of-the-art models (i.e., Hybrid-DRL, Ast-Attendgru, Transformer, codeGnn, Rencos, CodeBERT and SIT) by averagely increasing 19.48% and 13.17% on BLEU scores and ROUGUE-L score, respectively. In addition, CLG-Trans achieves an improvement of 16.14% and 4.70% in BLEU scores and ROUGE-L score compared with our previously proposed model DG-Trans. © 2023 Elsevier B.V.","Adams O., Makarucha A., Neubig G., Bird S., Cohn T., Cross-lingual word embeddings for low-resource language modeling, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pp. 937-947, (2017); Ahmad W., Chakraborty S., Ray B., Chang K.W., A transformer-based approach for source code summarization, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 4998-5007, (2020); Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Comput. Surv., 51, pp. 1-37, (2018); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, International Conference on Machine Learning, pp. 2091-2100, (2016); Bohan L., Hao Z., Junxian H., Mingxuan W., Yiming Y., Lei L., On the sentence embeddings from pre-trained language models, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pp. 9119-9130, (2020); Brody S., Alon U., Yahav E., How attentive are graph attention networks?, (2021); Chen T., Shi H., Tang S., Chen Z., Wu F., Zhuang Y., Cil: contrastive instance learning framework for distantly supervised relation extraction, (2021); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using rnn encoder-decoder for statistical machine translation, (2014); Choi Y., Bak J., Na C., Lee J.H., Learning sequential and structural information for source code summarization, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pp. 2842-2851, (2021); Chopra S., Auli M., Rush A.M., Abstractive sentence summarization with attentive recurrent neural networks, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 93-98, (2016); Cvitkovic M., Singh B., Anandkumar A., Open vocabulary learning on source code with a graph-structured cache, International Conference on Machine Learning, pp. 1475-1485, (2019); Devlin J., Chang M.W., Lee K., Toutanova K., BERT: pre-training of deep bidirectional transformers for language understanding, (2018); Eddy B.P., Robinson J.A., Kraft N.A., Carver J.C., Evaluating source code summarization techniques: replication and expansion, 2013 21st International Conference on Program Comprehension, pp. 13-22, (2013); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., CodeBERT: a pre-trained model for programming and natural languages, (2020); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, (2018); Gao T., Yao X., Chen D., Simcse: simple contrastive learning of sentence embeddings, (2021); Garneau N., Leboeuf J.S., Lamontagne L., Predicting and interpreting embeddings for out of vocabulary words in downstream tasks, (2019); Gong Z., Gao C., Wang Y., Gu W., Peng Y., Xu Z., Source code summarization with structural relative position guided transformer, (2022); Gu X., Zhang H., Kim S., Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering, pp. 933-944, (2018); Gutmann M.U., Hyvarinen A., Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics, J. Mach. Learn. Res., 13, 2, (2012); Haiduc S., Aponte J., Marcus A., Supporting program comprehension with source code summarization, 2010 ACM/IEEE 32nd International Conference on Software Engineering, pp. 223-226, (2010); Haiduc S., Aponte J., Moreno L., Marcus A., On the use of automated text summarization techniques for summarizing source code, 2010 17th Working Conference on Reverse Engineering, pp. 35-44, (2010); Hamel H., Ho-Hsiang W., Tiferet G., Miltiadis A., Marc B., Codesearchnet challenge: evaluating the state of semantic code search, (2019); Hellendoorn V.J., Devanbu P., Are deep neural networks the best choice for modeling source code?, Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, pp. 763-773, (2017); Hill E., Pollock L., Vijay-Shanker K., Automatically capturing source code context of nl-queries for software maintenance and reuse, 2009 IEEE 31st International Conference on Software Engineering, pp. 232-242, (2009); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput., 9, pp. 1735-1780, (1997); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, 2018 IEEE/ACM 26th International Conference on Program Comprehension, pp. 200-210, (2018); Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., Summarizing source code with transferred api knowledge, Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI 2018), pp. 2269-2275, (2018); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2073-2083, (2016); Jianlin S., Jiarun C., Weijie L., Yangyiwen O., Whitening sentence representations for better semantics and faster retrieval, (2021); Jianwei Z., Tao Z., Zhou X., Dg-trans: automatic code summarization via dynamic graph attention-based transformer, The 21st IEEE International Conference on Software Quality, Reliability, and Security, (2021); Karampatsis R.-M., Babii H., Robbes R., Sutton C., Janes A., Big code!= big vocabulary: open-vocabulary models for source code, 2020 IEEE/ACM 42nd International Conference on Software Engineering, pp. 1073-1085, (2020); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, (2016); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Adv. Neural Inf. Process. Syst., 25, pp. 1097-1105, (2012); Le T.H., Chen H., Babar M.A., Deep learning for source code modeling and generation: models, applications, and challenges, ACM Comput. Surv., 53, pp. 1-38, (2020); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proceedings of the 28th International Conference on Program Comprehension, pp. 184-195, (2020); LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, 2019 IEEE/ACM 41st International Conference on Software Engineering, pp. 795-806, (2019); LeClair A., McMillan C., Recommendations for datasets for source code summarization, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, (2015); Lin C.Y., Rouge: a package for automatic evaluation of summaries, Text Summarization Branches Out, pp. 74-81, (2004); Liu S., Chen Y., Xie X., Siow J.K., Liu Y., Retrieval-augmented generation for code summarization via hybrid gnn, International Conference on Learning Representations, (2020); Liu Y., Liu P., Simcls: a simple framework for contrastive learning of abstractive summarization, (2021); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., RoBERTa: a robustly optimized BERT pretraining approach, (2019); Logeswaran L., Honglak L., An efficient framework for learning sentence representations, (2018); McBurney P.W., McMillan C., Automatic documentation generation via source code summarization of method context, Proceedings of the 22nd International Conference on Program Comprehension, pp. 279-290, (2014); Moreno L., Aponte J., Sridhara G., Marcus A., Pollock L., Vijay-Shanker K., Automatic generation of natural language summaries for Java classes, 2013 21st International Conference on Program Comprehension, pp. 23-32, (2013); Moreno L., Marcus A., Automatic software summarization: the state of the art, Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings, pp. 530-531, (2018); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Thirtieth AAAI Conference on Artificial Intelligence, (2016); Nallapati R., Zhou B., Gulcehre C., Xiang B., Et al., Abstractive text summarization using sequence-to-sequence rnns and beyond, (2016); Nazar N., Hu Y., Jiang H., Summarizing software artifacts: a literature review, J. Comput. Sci. Technol., 31, pp. 883-909, (2016); Panichella S., Summarization techniques for code, change, testing, and user feedback, 2018 IEEE Workshop on Validation, Analysis and Evolution of Software Tests (VST), pp. 1-5, (2018); Papineni K., Roukos S., Ward T., Zhu W.J., Bleu: a method for automatic evaluation of machine translation, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Raia H., Sumit C., Yann L., Dimensionality reduction by learning an invariant mapping, 2006 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1735-1742, (2006); Rodeghero P., McMillan C., McBurney P.W., Bosch N., D'Mello S., Improving automated source code summarization via an eye-tracking study of programmers, Proceedings of the 36th International Conference on Software Engineering, pp. 390-401, (2014); Rumelhart D.E., Hinton G.E., Williams R.J., Learning representations by back-propagating errors, Nature, 323, pp. 533-536, (1986); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Trans. Neural Netw., 20, pp. 61-80, (2008); See A., Liu P.J., Manning C.D., Get to the point: summarization with pointer-generator networks, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1073-1083, (2017); Sennrich R., Haddow B., Birch A., Neural machine translation of rare words with subword units, (2015); Shibata Y., Kida T., Fukamachi S., Takeda M., Shinohara A., Shinohara T., Arikawa S., Byte Pair Encoding: A Text Compression Scheme That Accelerates Pattern Matching, (1999); Sridhara G., Hill E., Muppaneni D., Pollock L., Vijay-Shanker K., Towards automatically generating summary comments for Java methods, Proceedings of the IEEE/ACM International Conference on Automated Software Engineering, pp. 43-52, (2010); Sulir M., Poruban J., Source code documentation generation using program execution, Information, 8, (2017); Tomas M., Kai C., Greg C., Jeffrey D., Efficient estimation of word representations in vector space, (2013); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in Neural Information Processing Systems, pp. 5998-6008, (2017); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Wang R., Zhang H., Lu G., Lyu L., Lyu C., Fret: functional reinforced transformer with bert for code summarization, IEEE Access, 8, pp. 135591-135604, (2020); Wang X., Pollock L., Vijay-Shanker K., Automatically generating natural language descriptions for object-related statement sequences, 2017 IEEE 24th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 205-216, (2017); Wei B., Li G., Xia X., Fu Z., Jin Z., Code generation as a dual task of code summarization, (2019); Wong E., Liu T., Tan L., Clocom: mining existing source code for automatic comment generation, 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering, pp. 380-389, (2015); Wong E., Yang J., Tan L., Autocomment: mining question and answer sites for automatic comment generation, 2013 28th IEEE/ACM International Conference on Automated Software Engineering, pp. 562-567, (2013); Wu H., Zhao H., Zhang M., Code summarization with structure-induced transformer, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pp. 1078-1090, (2021); Wu Z., Pan S., Chen F., Long G., Zhang C., Philip S.Y., A comprehensive survey on graph neural networks, IEEE Trans. Neural Netw. Learn. Syst., 32, pp. 4-24, (2020); Xia M., Huang G., Liu L., Shi S., Graph based translation memory for neural machine translation, Proceedings of the AAAI Conference on Artificial Intelligence, pp. 7297-7304, (2019); Xu K., Wu L., Wang Z., Feng Y., Witbrock M., Sheinin V., Graph2seq: graph to sequence learning with attention-based neural networks, (2018); Zhang C., Wang J., Zhou Q., Xu T., Tang K., Gui H., Liu F., A survey of automatic source code summarization, Symmetry, 14, (2022); Zhang J., Wang X., Zhang H., Sun H., Liu X., Retrieval-based neural source code summarization, 2020 IEEE/ACM 42nd International Conference on Software Engineering, pp. 1385-1397, (2020)",,,,,,English,Article,Final,,Scopus,2-s2.0-85146339240,150
Li J.; Wang X.; Lyu C.,"Li, Ji (58305133500); Wang, Xiao (57202890546); Lyu, Chen (57195985796)",58305133500; 57202890546; 57195985796,ACAGNN: Source Code Representation Based on Fine-Grained Multi-view Program Features,2023,Communications in Computer and Information Science,1682 CCIS,,,476,487,11,0,10.1007/978-981-99-2385-4_36,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161117660&doi=10.1007%2f978-981-99-2385-4_36&partnerID=40&md5=06b6e73732a56c7c7766badf6fe78300,"Existing program comprehension models represent a single code feature and coarse code granularity. They tend to consider the shal- low features of source code (e.g., method names, characters, etc.) and ignore the structured features of source code such as Abstract Syntax Tree (AST), Control Flow Graph (CFG), and Application Programming Interface Dependency Graph (ADG), resulting in an incomplete representation of the source code. Although there are approaches to model ASTs, ASTs are efficient in representing code structure information. They have shortcomings in capturing the calling relationships of methods in the code for the entire class library, which does not allow the model to represent the global program accurately. To address these issues, we propose a multi-view source code representation model called ACAGNN, which uses a designed matching mechanism to learn multi-view code structure representation at the node-level and apply it to downstream code classification tasks. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Allamanis M., Brockschmidt M., Smartpaste: Learning to Adapt Source Code. Arxiv Preprint Arxiv, 1705, (2017); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs. Arxiv Preprint Arxiv, 1711, (2017); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, International Conference on Machine Learning, pp. 2091-2100, (2016); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, ACM SIGPLAN Not, 53, 4, pp. 404-419, (2018); Alon U., Zilberstein M., Levy O., Yahav, E.: Code2vec: Learning Distributed Representations of Code. Proc. ACM Program. Lang., 3, POPL, pp. 1-D29, (2019); Brockschmidt M., Allamanis M., Gaunt A.L., Polozov O., Generative Code Modeling with Graphs. Arxiv Preprint Arxiv, 1805, (2018); Cummins C., Petoumenos P., Wang Z., Leather H., Synthesizing benchmarks for predictive modeling, 2017 IEEE/ACM International Symposium on Code Generation and Optimization (CGO), Pp. 86–99. IEEE, (2017); Fernandes P., Allamanis M., Brockschmidt M., Structured Neural Summarization. Arxiv Preprint Arxiv, 1811, (2018); Gu X., Zhang H., Kim S., Deep code search, 2018 IEEE/ACM 40Th International Conference on Software Engineering (ICSE), Pp. 933–944. IEEE, (2018); Hua W., Sui Y., Wan Y., Liu G., Xu G., FCCA: Hybrid code representation for functional clone detection using attention networks, IEEE Trans. Reliab., 70, 1, pp. 304-318, (2020); Huo X., Li M., Zhou Z.H., Et al., Learning Unified Features from Natural and Programming Languages for Locating Buggy Source Code, 16, pp. 1606-1612, (2016); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54Th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2073-2083, (2016); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization. Arxiv Preprint Arxiv, 1412, (2014); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5Th International Conference on Learning Representations, ICLR 2017-Conference Track Proceedings, Toulon, France, (2017); Leclair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proceedings of the 28Th International Conference on Program Comprehension, pp. 184-195, (2020); Li J., Wang Y., Lyu M.R., King I., Code Completion with Neural Attention and Pointer Networks. Arxiv Preprint Arxiv, 1711, (2017); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks. Arxiv Preprint Arxiv, 1511, (2015); Liang Y., Zhu K., Automatic generation of text descriptive comments for code blocks, Proceedings of the AAAI Conference on Artificial Intelligence, 32, (2018); Lu M., Tan D., Xiong N., Chen Z., Li H., Program Classification Using Gated Graph Attention Neural Network for Online Programming Service. Arxiv Preprint Arxiv, 1903, (2019); Lyu C., Wang R., Zhang H., Zhang H., Hu S., Embedding API dependency graph for neural code generation, Empirical Softw. Eng., 26, 4, pp. 1-51, (2021); Mehrotra N., Agarwal N., Gupta P., Anand S., Lo D., Purandare R., Modeling Functional Similarity in Source Code with Graph-Based Siamese Networks. Arxiv Preprint Arxiv, 2011, (2020); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Thirtieth AAAI Conference on Artificial Intelligence, (2016); Pei X., Yu L., Tian S., AMalnet: A deep learning framework based on graph convolutional networks for malware detection, Comput. Secur., 93, (2020); Sachdev S., Li H., Luan S., Kim S., Sen K., Chandra S., Retrieval on source code: A neural code search, Proceedings of the 2Nd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages, pp. 31-41, (2018); Tai K.S., Socher R., Manning C.D., Improved Semantic Representations from Tree-Structured Long Short-Term Memory Networks. Arxiv Preprint Arxiv, 1503, (2015); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, 2020 IEEE 27Th International Conference on Software Analysis, Evolution and Reengineering (SANER), Pp. 261–271. IEEE, (2020); Wang W., Et al., Reinforcement-learning-guided source code summarization via hierarchical attention, IEEE Trans. Softw. Eng., 48, 1, pp. 102-119, (2020); Xiao T., Xu Y., Yang K., Zhang J., Peng Y., Zhang Z., The application of two-level attention models in deep convolutional neural network for fine-grained image classification, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 842-850, (2015); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41St International Conference on Software Engineering (ICSE), pp. 783-794, (2019); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks. Arxiv Preprint Arxiv, 1909, (2019)",,"17th CCF Conference on Computer Supported Cooperative Work and Social Computing, ChineseCSCW 2022",25 November 2022 through 27 November 2022,Taiyuan,294639,English,Conference paper,Final,,Scopus,2-s2.0-85161117660,151
Lu X.; Niu J.,"Lu, Xurong (58560422000); Niu, Jun (36620055100)",58560422000; 36620055100,Enhancing source code summarization from structure and semantics,2023,Proceedings of the International Joint Conference on Neural Networks,2023-June,,,,,,0,10.1109/IJCNN54540.2023.10191872,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169592244&doi=10.1109%2fIJCNN54540.2023.10191872&partnerID=40&md5=04716b0190a2fc92ed349a9eef4cdb7e,"Source code summarization aims to generate concise and high-quality natural language descriptions for code snippets. High-quality code summaries can help developers better understand source codes. Researchers have made great efforts to generate more accurate summaries; however, due to the lack of preservation of source code structure and semantics, previous approaches have struggled to generate summaries that accurately describe the functionality or other major characteristics of codes. In this paper, we propose a novel approach called Code Structure and Semantic Fusion (CSSF) for automatically generating summaries for source code. CSSF can utilize both the structural and semantic information of source codes. To achieve this, we extract the overall structure of the Abstract Syntax Tree (AST) by expanding the AST and using a heterogeneous graph attention network. Furthermore, we use an additional sequence model to obtain the semantic information of the code fragment. Finally, we fuse the two kinds of information through a novel modality fusion method. We evaluate our approach on a widely used Java dataset; experimental results confirm that our approach outperforms existing methods. © 2023 IEEE.","Xia X., Bao L., Lo D., Xing Z., Hassan A.E., Li S., Measuring program comprehension: A large-scale field study with professionals, IEEE Transactions on Software Engineering, 44, 10, pp. 951-976, (2017); Sridhara G., Hill E., Muppaneni D., Pollock L., Vijay-Shanker K., Towards automatically generating summary comments for Java methods, Proceedings of the IEEE/ACM international conference on Automated software engineering, pp. 43-52, (2010); Vassallo C., Panichella S., Di Penta M., Canfora G., Codes: Mining source code descriptions from developers discussions, Proceedings of the 22nd International Conference on Program Comprehension, pp. 106-109, (2014); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2073-2083, (2016); Ahmad W.U., Chakraborty S., Ray B., Chang K.-W., A transformer-based approach for source code summarization, (2020); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proceedings of the 26th conference on program comprehension, pp. 200-210, (2018); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating sequences from structured representations of code, (2018); Xing H., Ge L., Xin X., Lo D., Zhi J., Summarizing source code with transferred api knowledge, Twenty-Seventh International Joint Conference on Artificial Intelligence IJCAI-18, (2018); Gao Y., Lyu C., M2ts: Multi-scale multi-modal approach based on transformer for source code summarization, Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension, pp. 24-35, (2022); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proceedings of the 28th international conference on program comprehension, pp. 184-195, (2020); Zhang A., Lipton Z.C., Li M., Smola A.J., Dive into deep learning, (2021); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Kaiser A.N.G., Polosukhin I., Attention is all you need, Advances in neural information processing systems, 30, (2017); Yan H., Deng B., Li X., Qiu X., Tener: Adapting transformer encoder for named entity recognition, (2019); He R., Ravula A., Kanagal B., Ainslie J., Realformer: Transformer likes residual attention, (2020); Lv Q., Ding M., Liu Q., Chen Y., Feng W., He S., Zhou C., Jiang J., Dong Y., Tang J., Are we really making much progress revisiting, benchmarking and refining heterogeneous graph neural networks, Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining, pp. 1150-1160, (2021); Li G., Xiong C., Thabet A., Ghanem B., Deepergcn: All you need to train deeper gcns, (2020); Papineni K., Roukos S., Ward T., Zhu W.-J., Bleu: A method for automatic evaluation of machine translation, Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Shi E., Wang Y., Du L., Chen J., Han S., Zhang H., Zhang D., Sun H., On the evaluation of neural code summarization, Proceedings of the 44th International Conference on Software Engineering, pp. 1597-1608, (2022); Wang Y., Shi E., Du L., Yang X., Hu Y., Han S., Zhang H., Zhang D., Cocosum: Contextual code summarization with multi-relational graph neural network, (2021); Koehn P., Pharaoh: A beam search decoder for phrase-based statistical machine translation models, Machine Translation: From Real Users to Research: 6th Conference of the Association for Machine Translation in the Americas, AMTA 2004, pp. 115-124, (2004); LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, pp. 795-806, (2019); Zhang J., Wang X., Zhang H., Sun H., Liu X., Retrieval-based neural source code summarization, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 1385-1397, (2020); Haiduc S., Bavota G., Marcus A., Oliveto R., De Lucia A., Menzies T., Automatic query reformulations for text retrieval in software engineering, 2013 35th International Conference on Software Engineering (ICSE). IEEE, pp. 842-851, (2013); Moreno L., Aponte J., Sridhara G., Marcus A., Pollock L., Vijay-Shanker K., Automatic generation of natural language summaries for Java classes, 2013 21st International Conference on Program Comprehension (ICPC). IEEE, pp. 23-32, (2013); Zheng W., Zhou H., Li M., Wu J., Codeattention: Translating source code to comments by exploiting the code constructs, Frontiers of Computer Science, 13, pp. 565-578, (2019); Lu Y., Zhao Z., Li G., Jin Z., Learning to generate comments for api-based code snippets, Software Engineering and Methodology for Emerging Domains: 16th National Conference, NASAC 2017, pp. 3-14, (2019); Liu F., Zhang L., Jin Z., Modeling programs hierarchically with stack-augmented lstm, Journal of Systems and Software, 164, (2020); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, (2018); Haque S., LeClair A., Wu L., McMillan C., Improved automatic summarization of subroutines via attention to file context, Proceedings of the 17th International Conference on Mining Software Repositories, pp. 300-310, (2020); Wang Y., Dong Y., Lu X., Zhou A., Gypsum: Learning hybrid representations for code summarization, Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension, pp. 12-23, (2022); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE international conference on automated software engineering, pp. 397-407, (2018)",Business Events Australia; Destination Goldcoast; et al.; International Neural Network Society (INNS); The University of Queensland Australia; Tourism and Events Queensland,"2023 International Joint Conference on Neural Networks, IJCNN 2023",18 June 2023 through 23 June 2023,Gold Coast,191330,English,Conference paper,Final,,Scopus,2-s2.0-85169592244,153
Kuang L.; Zhou C.; Yang X.,"Kuang, Li (36519008400); Zhou, Cong (57749820000); Yang, Xiaoxian (57189699603)",36519008400; 57749820000; 57189699603,Code comment generation based on graph neural network enhanced transformer model for code understanding in open-source software ecosystems,2022,Automated Software Engineering,29,2,43,,,,6,10.1007/s10515-022-00341-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132075222&doi=10.1007%2fs10515-022-00341-1&partnerID=40&md5=92dc28fb349520100fd5fb371068b6b3,"In open-source software ecosystems, the scale of source code is getting larger and larger, and developers often use various methods (good code comments or method names, etc.) to make the code easier to read and understand. However, high-quality code comments or method names are often unavailable due to tight project schedules or other reasons in open-source software ecosystems such as Github. Therefore, in this work, we try to use deep learning models to generate appropriate code comments or method names to help software development and maintenance, which requires a non-trivial understanding of the code. Therefore, we propose a Graph neural network enhanced Transformer model (GTrans for short) to learn code representation to understand code better. Specifically, GTrans learns code representation from code sequences and graphs. We use a Transformer encoder to capture the global representation from code sequence and a graph neural network (GNN) encoder to focus on the local details in the code graph, and then use a decoder to combine both global and local representations by attention mechanism. We use three public datasets collected from GitHub to evaluate our model. In an extensive evaluation, we show that GTrans outperforms the state-of-the-art models up to 3.8% increase in METEOR metrics on code comment generation and outperforms the state-of-the-art models by margins of 5.8%–9.4% in ROUGE metrics on method name generation after some adjustments on the structure. Empirically, we find the method name generation task depends on more local information than global, and the code comment generation task is in contrast. Our data and code are available at https://github.com/zc-work/GTrans. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","A transformer-based approach for source code summarization, Arxiv Preprint Arxiv:200500653, (2020); Learning to Represent Programs with Graphs. Arxiv Preprint Arxiv, 1711, (2017); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, International Conference on Machine Learning, PMLR, pp. 2091-2100, (2016); Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Comput. Surv. (CSUR), 51, 4, pp. 1-37, (2018); Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating Sequences from Structured Representations of Code, (2018); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proc. ACM Program. Lang, 3, pp. 1-29, (2019); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, ACM SIGPLAN Notices, 53, 4, pp. 404-419, (2018); Banerjee S., Lavie A., Meteor: An automatic metric for mt evaluation with improved correlation with human judgments, Proceedings of the Acl Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation And/Or Summarization, pp. 65-72, (2005); Barone A.V.M., Sennrich R., A parallel corpus of python functions and documentation strings for automated code documentation and code generation, (2017); Chen F., Kim M., Choo J., Novel natural language summarization of program code via leveraging multiple input representations, Findings of the Association for Computational Linguistics: EMNLP 2021, pp. 2510-2520, (2021); Chen X., Liu C., Song D., Tree-to-tree neural networks for program translation, (2018); Chirkova N., Troshin S., Empirical study of transformers for source code, Arxiv Preprint Arxiv:201007987, (2020); Cho K., van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using rnn encoder-decoder for statistical machine translation, Arxiv Preprint Arxiv:14061078, (2014); Eriguchi A., Hashimoto K., Tsuruoka Y., Tree-to-sequence attentional neural machine translation, (2016); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T.D., Codebert: A Pre-Trained Model for Programming and Natural Languages, (2020); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, 7Th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6–9, 2019, Openreview.Net, (2019); Gao S., Gao C., He Y., Zeng J., Nie L.Y., Xia X., Code structure guided transformer for source code summarization, Arxiv Preprint Arxiv:210409340, (2021); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A.S., Graphcodebert: Pre-Training Code Representations with Data Flow., (2020); Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, 8Th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26–30, 2020, Openreview.Net, (2020); Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, International Conference on Learning Representations, (2019); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, 2018 IEEE/ACM 26Th International Conference on Program Comprehension (ICPC), pp. 200-210, (2018); Hu X., Li G., Xia X., Lo D., Lu S.Z., Summarizing Source Code with Transferred Api Knowledge, (2018); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation with hybrid lexical and syntactical information, Emp. Softw. Eng., 25, 3, pp. 2179-2217, (2020); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54Th Annual Meeting of the Association for Computational Linguistics, 1, pp. 2073-2083, (2016); Leclair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proceedings of the 28Th International Conference on Program Comprehension, pp. 184-195, (2020); Leclair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, 2019 IEEE/ACM 41St International Conference on Software Engineering (ICSE), pp. 795-806, (2019); Lin C., Ouyang Z., Zhuang J., Chen J., Li H., Wu R., Improving code summarization with block-wise abstract syntax tree splitting, Arxiv Preprint Arxiv:210307845, (2021); Lin C.Y., Rouge: A package for automatic evaluation of summaries, Text Summarization Branches Out, pp. 74-81, (2004); Luong M.T., Pham H., Manning C.D., Effective Approaches to Attention-Based Neural Machine Translation, (2015); Murphy-Hill E., Parnin C., Black A.P., How we refactor, and how we know it, IEEE Trans. Softw. Eng., 38, 1, pp. 5-18, (2011); Papineni K., Roukos S., Ward T., Zhu W.J., Bleu: A method for automatic evaluation of machine translation, Proceedings of the 40Th Annual Meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Ribeiro L.F., Zhang Y., Gardent C., Gurevych I., Modeling global and local node contexts for text generation from knowledge graphs, Trans. Assoc. Comput. Ling., 8, pp. 589-604, (2020); See A., Liu P.J., Manning C.D., Get to the Point: Summarization with Pointer-Generator Networks, (2017); Shaw P., Uszkoreit J., Vaswani A., Self-Attention with Relative Position Representations, (2018); Shido Y., Kobayashi Y., Yamamoto A., Miyamoto A., Matsumura T., Automatic source code summarization with extended tree-lstm, 2019 International Joint Conference on Neural Networks (IJCNN), pp. 1-8, (2019); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Arxiv Preprint Arxiv:170603762, (2017); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33Rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Wang W., Zhang K., Li G., Jin Z., Learning to represent programs with heterogeneous graphs, Arxiv Preprint Arxiv:201204188, (2020); Wei B., Li G., Xia X., Fu Z., Jin Z., Code generation as a dual task of code summarization, Arxiv Preprint Arxiv:191005923, (2019); Xia X., Bao L., Lo D., Xing Z., Hassan A.E., Li S., Measuring program comprehension: a large-scale field study with professionals, IEEE Trans. Softw. Eng., 44, 10, pp. 951-976, (2017); Xu S., Zhang S., Wang W., Cao X., Guo C., Xu J., Method name suggestion with hierarchical attention networks, Proceedings of the 2019 ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation, pp. 10-21, (2019); Zhang J., Wang X., Zhang H., Sun H., Liu X., Retrieval-based neural source code summarization, 2020 IEEE/ACM 42Nd International Conference on Software Engineering (ICSE, pp. 1385-1397, (2020); Zugner D., Kirschstein T., Catasta M., Leskovec J., Gunnemann S., Language-agnostic representation learning of source code from structure and context, (2021)",,,,,,English,Article,Final,,Scopus,2-s2.0-85132075222,154
Kuang L.; Ge F.; Zhang L.,"Kuang, Li (36519008400); Ge, Fan (57222084148); Zhang, Lingyan (57220094720)",36519008400; 57222084148; 57220094720,Suggesting method names based on graph neural network with salient information modelling,2022,Expert Systems,39,6,e13030,,,,1,10.1111/exsy.13030,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129806202&doi=10.1111%2fexsy.13030&partnerID=40&md5=8030820388d4b8b9471db9601604bba6,"Descriptive method names have a great impact on improving program readability and facilitating software maintenance. Recently, due to high similarity between the task of method naming and text summarization, large amount of research based on natural language processing has been conducted to generate method names. However, method names are much shorter compared to long source code sequences. The salient information of the whole code snippet account for an relatively small part. Additionally, unlike natural language, source code has complicated structure information. Thus, modelling the salient information from highly structured input presents a great challenge. To tackle this problem, we propose a graph neural network (GNN)-based model with a novel salient information selection layer. Specifically, to comprehensively encode the tokens of the source code, we employ a GNN-based encoder, which can be directly applied to the code graph to ensure that the syntactic information of code structure and semantic information of code sequence can be modelled sufficiently. To effectively discriminate the salient information, we introduce an information selection layer which contains two parts: a global filter gate used to filter irrelevant information, and a semantic-aware convolutional layer used to focus on the semantic information contained in code sequence. To improve the precision of the copy mechanism when decoding, we introduce a salient feature enhanced attention mechanism to facilitate the accuracy of copying tokens from input. Experimental results on an open source dataset indicate that our proposed model, equipped with the salient information selection layer, can effectively improve method naming performance compared to other state-of-the-art models. © 2022 John Wiley & Sons Ltd.","Allamanis M., Barr E.T., Bird C., Sutton C., Suggesting accurate method and class names, Proceedings of the 2015 10th joint meeting on foundations of software engineering, pp. 38-49, (2015); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, (2018); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, (2016); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating sequences from structured representations of code, 7th International conference on learning representations, 3, pp. 1-29, (2019); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, Proceedings of the 39th ACM sigplan conference on programming language design and implementation, pp. 404-419, (2018); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proc. ACM Program. Lang., 3, pp. 1-29, (2019); Bahdanau D., Cho K., Bengio Y., Neural machine translation by jointly learning to align and translate. In 3rd International Conference on Learning Representations, ICLR, 2015, San Diego, CA, USA, May 7–9, 2015, (2015); Butler S., Wermelinger M., Yu Y., Sharp H., Relating identifier naming flaws and code quality: An empirical study, 2009 16th working conference on reverse engineering, pp. 31-35, (2009); Cho K., van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using RNN encoder–decoder for statistical machine translation, Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pp. 1724-1734, (2014); Cvitkovic M., Singh B., Anandkumar A., Open vocabulary learning on source code with a graph-structured cache, Proceedings of the 36 international conference on machine learning, 97, pp. 1475-1485, (2019); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization. In International conference on learning representations, (2019); Haiduc S., Aponte J., Marcus A., Supporting program comprehension with source code summarization, 2010 ACM/IEEE 32nd international conference on software engineering, 2, pp. 223-226, (2010); Haiduc S., Aponte J., Moreno L., Marcus A., On the use of automated text summarization techniques for summarizing source code, 2010 17th working conference on reverse engineering, pp. 35-44, (2010); He K., Zhang X., Ren S., Sun J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification, (2015); Host E.W., Ostvold B.M., Debugging method names, Ecoop 2009 – Object-oriented programming, pp. 294-317, (2009); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proceedings of the 26th conference on program comprehension, pp. 200-210, (2018); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th annual meeting of the association for computational linguistics (volume 1: Long papers), pp. 2073-2083, (2016); Jia R., Liang P., Adversarial examples for evaluating reading comprehension systems, (2017); Jiang L., Liu H., Jiang H., Machine learning based recommendation of method names: How far are we, 2019 34th IEEE/ACM international conference on automated software engineering (ase), pp. 602-614, (2019); Kingma D.P., Ba J., Adam: A method for stochastic optimization, 3rd international conference on learning representations, ICLR 2015, conference track proceedings, (2015); Lawrie D., Morrell C., Feild H., Binkley D., What's in a name? A study of identifiers, 14th IEEE international conference on program comprehension (ICPC'06), pp. 3-12, (2006); LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, Proceedings of the 41st international conference on software engineering, pp. 795-806, (2019); Li Y., Zemel R., Brockschmidt M., Tarlow D., Gated graph sequence neural networks, Proceedings of ICLR'16, (2016); Lin C.-Y., ROUGE: A package for automatic evaluation of summaries, Text summarization branches out, pp. 74-81, (2004); Nair V., Hinton G.E., Rectified linear units improve restricted boltzmann machines, Proceedings of the 27th international conference on international conference on machine learning, pp. 807-814, (2010); Nguyen S., Phan H., Le T., Nguyen T.N., Suggesting natural method names to check name consistencies, Proceedings of the ACM/IEEE 42nd international conference on software engineering, pp. 1372-1384, (2020); See A., Liu P.J., Manning C.D., Get to the point, (2017); Sridhara G., Hill E., Muppaneni D., Pollock L., Vijay-Shanker K., Towards automatically generating summary comments for java methods, Proceedings of the IEEE/ACM international conference on automated software engineering, pp. 43-52, (2010); Sutskever I., Vinyals O., Le Q.V., Sequence to sequence learning with neural networks, Proceedings of the 27th international conference on neural information processing systems, 2, pp. 3104-3112, (2014); Takang A.A., Grubb P., Macredie R., The effects of comments and identifier names on program comprehensibility: An experimental investigation, Journal of Programming Languages, 4, pp. 143-167, (1996); Vinyals O., Fortunato M., Jaitly N., Pointer networks, Advances in neural information processing systems, 28, (2015); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE international conference on automated software engineering, pp. 397-407, (2018); Xia X., Bao L., Lo D., Xing Z., Hassan A.E., Li S., Measuring program comprehension: A large-scale field study with professionals, IEEE Transactions on Software Engineering, 44, 10, pp. 951-976, (2018); Xu S., Zhang S., Wang W., Cao X., Guo C., Xu J., Method name suggestion with hierarchical attention networks, Proceedings of the 2019 acm sigplan workshop on partial evaluation and program manipulation, pp. 10-21, (2019); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, 32, pp. 10197-10207, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85129806202,155
Wu B.; Liang B.; Zhang X.,"Wu, Bingting (57462289000); Liang, Bin (57201841373); Zhang, Xiaofang (56461460000)",57462289000; 57201841373; 56461460000,Turn tree into graph: Automatic code review via simplified AST driven graph convolutional network,2022,Knowledge-Based Systems,252,,109450,,,,6,10.1016/j.knosys.2022.109450,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134877579&doi=10.1016%2fj.knosys.2022.109450&partnerID=40&md5=ca398d0bbf9b948417125efb4f7e9d55,"Automatic code review (ACR), which can relieve the costs of manual inspection, is an indispensable and essential task in software engineering. To deal with ACR, existing work is to serialize the abstract syntax tree (AST). However, making sense of the whole AST with sequence encoding approach is a daunting task, mostly due to some redundant nodes in AST hinder the transmission of node information. Not to mention that the serialized representation is inadequate to grasp the information of tree structure in AST. In this paper, we first present a new large-scale Apache Automatic Code Review (AACR) dataset for ACR task since there is still no publicly available dataset in this task. The release of this dataset would push forward the research in this field. Based on it, we propose a novel Simplified AST based Graph Convolutional Network (SimAST-GCN) to deal with ACR task. Concretely, to improve the efficiency of node information dissemination, we first simplify the AST of code by deleting the redundant nodes that do not contain connection attributes, and thus deriving a Simplified AST. Then, we construct a relation graph for each code based on the Simplified AST to properly embody the relations among code fragments of the tree structure into the graph. Subsequently, in the light of the merit of graph structure, we explore a graph convolution networks architecture that follows an attention mechanism to leverage the crucial implications of code fragments to derive code representations. Finally, we exploit a simple but effective subtraction operation in the representations between the original and revised code, enabling the revised difference to be preferably learned for deciding the results of ACR. Experimental results on the AACR dataset illustrate that our proposed model outperforms the state-of-the-art methods. © 2022 Elsevier B.V.","Sadowski C., Soderberg E., Church L., Sipko M., Bacchelli A., Modern code review: a case study at google, pp. 181-190, (2018); Bacchelli A., Bird C., Expectations, outcomes, and challenges of modern code review, 2013 35th International Conference on Software Engineering (ICSE), pp. 712-721, (2013); Thongtanunam P., Tantithamthavorn C., Kula R.G., Yoshida N., Iida H., Matsumoto K.-I., Who should review my code? a file location-based code-reviewer recommendation approach for modern code review, 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER), pp. 141-150, (2015); Zanjani M.B., Kagdi H., Bird C., Automatically recommending peer reviewers in modern code review, IEEE Trans. Softw. Eng., 42, 6, pp. 530-543, (2015); Xia Z., Sun H., Jiang J., Wang X., Liu X., A hybrid approach to code reviewer recommendation with collaborative filtering, 2017 6th International Workshop on Software Mining (SoftwareMining), pp. 24-31, (2017); Balachandran V., Reducing human effort and improving quality in peer code reviews using automatic static analysis and reviewer recommendation, 2013 35th International Conference on Software Engineering (ICSE), pp. 931-940, (2013); Diaz G., Bermejo J.R., Static analysis of source code security: Assessment of tools against SAMATE tests, Inf. Softw. Technol., 55, 8, pp. 1462-1476, (2013); McGraw G., Automated code review tools for security, Computer, 41, 12, pp. 108-111, (2008); Shi S.-T., Li M., Lo D., Thung F., Huo X., Automatic code review by learning the revision of source code, 33, pp. 4910-4917, (2019); Siow J.K., Gao C., Fan L., Chen S., Liu Y., Core: Automating review recommendation for code changes, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 284-295, (2020); Greff K., Srivastava R.K., Koutnik J., Steunebrink B.R., Schmidhuber J., LSTM: A search space odyssey, IEEE Trans. Neural Netw. Learn. Syst., 28, 10, pp. 2222-2232, (2016); Sun P., Zhang R., Jiang Y., Kong T., Xu C., Zhan W., Tomizuka M., Li L., Yuan Z., Wang C., Luo P., Sparse R-CNN: End-to-end object detection with learnable proposals, pp. 14454-14463, (2021); Hovemeyer D., Pugh W., Finding bugs is easy, Acm Sigplan Not., 39, 12, pp. 92-106, (2004); Baxter I.D., Yahin A., Moura L., Sant'Anna M., Bier L., Clone detection using abstract syntax trees, Proceedings. International Conference on Software Maintenance (Cat. No. 98CB36272), pp. 368-377, (1998); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 783-794, (2019); Mou L., Li G., Jin Z., Zhang L., Wang T., TBCNN: A tree-based convolutional neural network for programming language processing, (2014); Shippey T., Bowes D., Hall T., Automatically identifying code features for software defect prediction: Using AST N-grams, Inf. Softw. Technol., 106, pp. 142-160, (2019); Tang D., Qin B., Liu T., Document modeling with gated recurrent neural network for sentiment classification, pp. 1422-1432, (2015); Hindle A., Barr E.T., Gabel M., Su Z., Devanbu P., On the naturalness of software, Commun. ACM, 59, 5, pp. 122-131, (2016); Ray B., Hellendoorn V., Godhane S., Tu Z., Bacchelli A., Devanbu P., On the” naturalness” of buggy code, 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE), pp. 428-439, (2016); Fang C., Liu Z., Shi Y., Huang J., Shi Q., Functional code clone detection with syntax and semantics fusion learning, pp. 516-527, (2020); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Et al., Graphcodebert: Pre-training code representations with data flow, (2020); Zhang C., Li Q., Song D., Aspect-based sentiment classification with aspect-specific graph convolutional networks, (2019); Rehurek R., Sojka P., Software framework for topic modelling with large corpora, Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks, pp. 45-50, (2010); Devlin J., Chang M.-W., Lee K., Toutanova K., BERT: Pre-training of deep bidirectional transformers for language understanding, 1, pp. 4171-4186, (2019); Lin G., Zhang J., Luo W., Pan L., Xiang Y., De Vel O., Montague P., Cross-project transfer representation learning for vulnerable function discovery, IEEE Trans. Ind. Inf., 14, 7, pp. 3289-3297, (2018); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Codebert: A pre-trained model for programming and natural languages, (2020); Fan G., Diao X., Yu H., Yang K., Chen L., Deep semantic feature learning with embedded static metrics for software defect prediction, 2019 26th Asia-Pacific Software Engineering Conference (APSEC), pp. 244-251, (2019); Liu Y., Li Y., Guo J., Zhou Y., Xu B., Connecting software metrics across versions to predict defects, 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 232-243, (2018); Macbeth G., Razumiejczyk E., Ledesma R.D., Cliff's Delta Calculator: A non-parametric effect size program for two groups of observations, Univ. Psychol., 10, 2, pp. 545-555, (2011); Raychev V., Vechev M., Yahav E., Code completion with statistical language models, pp. 419-428, (2014); Allamanis M., Barr E.T., Bird C., Sutton C., Suggesting accurate method and class names, pp. 38-49, (2015); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Thirtieth AAAI Conference on Artificial Intelligence, (2016); Lam A.N., Nguyen A.T., Nguyen H.A., Nguyen T.N., Combining deep learning with information retrieval to localize buggy files for bug reports (n), 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 476-481, (2015); Huo X., Li M., Zhou Z.-H., Et al., Learning unified features from natural and programming languages for locating buggy source code, IJCAI, Vol. 16, pp. 1606-1612, (2016); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, IJCAI, pp. 3034-3040, (2017); Ben-Nun T., Jakobovits A.S., Hoefler T., Neural code comprehension: A learnable representation of code semantics, Adv. Neural Inf. Process. Syst., 31, pp. 3589-3601, (2018); Zhao G., Huang J., Deepsim: deep learning code functional similarity, pp. 141-151, (2018); Li R., Chen B., Zhang F., Sun C., Peng X., Detecting runtime exceptions by deep code representation learning with attention-based graph neural networks, 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER), (2022); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Adv. Neural Inf. Process. Syst., 32, pp. 10197-10207, (2019); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P., Multi-modal attention network learning for semantic source code retrieval, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 13-25, (2019); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, (2017); Choi Y., Bak J., Na C., Lee J.-H., Learning sequential and structural information for source code summarization, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pp. 2842-2851, (2021); Wang X., Wang Y., Mi F., Zhou P., Wan Y., Liu X., Li L., Wu H., Liu J., Jiang X., Syncobert: Syntax-guided multi-modal contrastive pre-training for code representation, (2021); Guo D., Lu S., Duan N., Wang Y., Zhou M., Yin J., UniXcoder: Unified cross-modal pre-training for code representation, pp. 7212-7225, (2022); Wang Y., Wang W., Joty S., Hoi S.C., CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, pp. 8696-8708, (2021); Xue G., Zhong M., Li J., Chen J., Zhai C., Kong R., Dynamic network embedding survey, Neurocomputing, 472, pp. 212-223, (2022); Song X., Li J., Tang Y., Zhao T., Chen Y., Guan Z., Jkt: A joint graph convolutional network based deep knowledge tracing, Inform. Sci., 580, pp. 510-523, (2021); Song X., Li J., Lei Q., Zhao W., Chen Y., Mian A., Bi-CLKT: Bi-graph contrastive learning based knowledge tracing, Knowl.-Based Syst., 241, (2022); Jiang B., Sun P., Luo B., GLMNet: Graph learning-matching convolutional networks for feature matching, Pattern Recognit., 121, (2022); Liang B., Yin R., Gui L., Du J., Xu R., Jointly learning aspect-focused and inter-aspect relations with graph convolutional networks for aspect sentiment analysis, pp. 150-161, (2020); Sun Y., Yu N., Fu G., A discourse-aware graph neural network for emotion recognition in multi-party conversation, Findings of the Association for Computational Linguistics: EMNLP 2021, pp. 2949-2958, (2021); Singh D., Sekar V.R., Stolee K.T., Johnson B., Evaluating how static analysis tools can reduce code review effort, 2017 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC), pp. 101-105, (2017); Rigby P.C., Bird C., Convergent contemporary software peer review practices, pp. 202-212, (2013); Hellendoorn V.J., Tsay J., Mukherjee M., Hirzel M., Towards automating code review at scale, pp. 1479-1482, (2021); Tufan R., Pascarella L., Tufanoy M., Poshyvanykz D., Bavota G., Towards automating code review activities, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), pp. 163-174, (2021)",,,,,,English,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85134877579,156
Zhou Y.; Shen J.; Zhang X.; Yang W.; Han T.; Chen T.,"Zhou, Yu (57071818500); Shen, Juanjuan (57234871100); Zhang, Xiaoqing (57226580662); Yang, Wenhua (56005881100); Han, Tingting (8855275800); Chen, Taolue (55578213700)",57071818500; 57234871100; 57226580662; 56005881100; 8855275800; 55578213700,Automatic source code summarization with graph attention networks,2022,Journal of Systems and Software,188,,111257,,,,18,10.1016/j.jss.2022.111257,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126290388&doi=10.1016%2fj.jss.2022.111257&partnerID=40&md5=e3f7e6aa4ea01ae7593bda0c338965ec,"Source code summarization aims to generate concise descriptions for code snippets in a natural language, thereby facilitates program comprehension and software maintenance. In this paper, we propose a novel approach–GSCS–to automatically generate summaries for Java methods, which leverages both semantic and structural information of the code snippets. To this end, GSCS utilizes Graph Attention Networks to process the tokenized abstract syntax tree of the program, which employ a multi-head attention mechanism to learn node features in diverse representation sub-spaces, and aggregate features by assigning different weights to its neighbor nodes. GSCS further harnesses an additional RNN-based sequence model to obtain the semantic features and optimizes the structure by combining its output with a transformed embedding layer. We evaluate our approach on two widely-adopted Java datasets; the experiment results confirm that GSCS outperforms the state-of-the-art baselines. © 2022 Elsevier Inc.","Ahmad W.U., Chakraborty S., Ray B., Chang K., pp. 4998-5007, (2020); Allamanis M., Peng H., Sutton C., pp. 2091-2100, (2016); Binkley D.W., Source code analysis: A road map, pp. 104-119, (2007); Cho K., pp. 1724-1734, (2014); Chung J., Gulcehre C., Cho K., Bengio Y., Empirical evaluation of gated recurrent neural networks on sequence modeling, (2014); Cornelissen B., Zaidman A., van Deursen A., Moonen L., Koschke R., A systematic survey of program comprehension through dynamic analysis, IEEE Trans. Software Eng., 35, 5, pp. 684-702, (2009); Denkowski M.J., Lavie A., Meteor Universal: Language specific translation evaluation for any target language, pp. 376-380, (2014); Duan J., Zhao H., Qin W., Qiu M., Liu M., pp. 137-142, (2020); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, (2018); Haiduc S., Aponte J., Marcus A., 2, pp. 223-226, (2010); Han Y., Liu M., Jing W., Aspect-level drug reviews sentiment analysis based on double BiGRU and knowledge transfer, IEEE Access, 8, pp. 21314-21325, (2020); He D., Xia Y., Qin T., Wang L., Yu N., Liu T.-Y., Ma W.-Y., Dual learning for machine translation, (2016); Hellendoorn V.J., Devanbu P.T., pp. 763-773, (2017); Hill E., Pollock L.L., Vijay-Shanker K., Automatically capturing source code context of NL-queries for software maintenance and reuse, pp. 232-242, (2009); Hindle A., Barr E.T., Gabel M., Su Z., Devanbu P.T., On the naturalness of software, Commun. ACM, 59, 5, pp. 122-131, (2016); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput., 9, 8, pp. 1735-1780, (1997); Hu X., Li G., Xia X., Lo D., Jin Z., pp. 200-210, (2018); Husain H., Wu H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet challenge: Evaluating the state of semantic code search, (2019); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, 1, (2016); Kingma D.P., Ba J., Adam: A method for stochastic optimization, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7–9, 2015, Conference Track Proceedings, (2015); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, (2017); LeClair A., Haque S., Wu L., McMillan C., pp. 184-195, (2020); LeClair A., Jiang S., McMillan C., pp. 795-806, (2019); Leclair A., Mcmillan C., Recommendations for datasets for source code summarization, (2019); Lin C.-Y., ROUGE: A package for automatic evaluation of summaries, Text Summarization Branches Out, (2004); Luong T., Pham H., Manning C.D., pp. 1412-1421, (2015); Lv J., Du J., Zhou N., Xue Z.B.-B.-C., pp. 157-164, (2020); Maletic J.I., Marcus A., (2001); Ottenstein K.J., Ottenstein L.M., pp. 177-184, (1984); Papineni K., Roukos S., Ward T., Zhu W.-J., Bleu: a method for automatic evaluation of machine translation, Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pp. 311-318, (2002); Schuster M., Paliwal K.K., Bidirectional recurrent neural networks, IEEE Trans. Signal Process., 45, 11, pp. 2673-2681, (1997); Shido Y., Kobayashi Y., Yamamoto A., Miyamoto A., Matsumura T., pp. 1-8, (2019); Song X., Sun H., Wang X., Yan J., A survey of automatic generation of source code comments: Algorithms and techniques, IEEE Access, 7, pp. 111411-111428, (2019); Sridhara G., Hill E., Muppaneni D., Pollock L.L., Vijay-Shanker K., pp. 43-52, (2010); Sridhara G., Pollock L.L., Vijay-Shanker K., pp. 71-80, (2011); Stapleton S., Gambhir Y., LeClair A., Eberhart Z., Weimer W., Leach K., Huang Y., pp. 2-13, (2020); Sutskever I., Vinyals O., Le Q.V., (2014); Takang A.A., Grubb P.A., Macredie R.D., The effects of comments and identifier names on program comprehensibility: an experimental investigation, J. Program. Lang., 4, 3, pp. 143-167, (1996); Tenny T., Program readability: Procedures versus comments, IEEE Trans. Software Eng., 14, 9, pp. 1271-1279, (1988); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is All you Need, pp. 5998-6008, (2017); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); Wei B., Li G., Xia X., Fu Z., Jin Z., Code generation as a dual task of code summarization, pp. 6559-6569, (2019); Wilcoxon F., Some rapid approximate statistical procedures, Ann. New York Acad. Sci., 52, The Place of Statistical Methods in Biological and Chemical Experimentation, pp. 808-814, (2010); Wong E., Yang J., Tan L., pp. 562-567, (2013); Woodfield S.N., Dunsmore H.E., Shen V.Y., The effect of modularization and comments on program comprehension, ICSE ’81, pp. 215-223, (1981); Xia X., Bao L., Lo D., Xing Z., Hassan A.E., Li S., (2018); Zhang J., Wang X., Zhang H., Sun H., Liu X., Retrieval-based neural source code summarization, pp. 1385-1397, (2020); Zhou Y., Yan X., Yang W., Chen T., Huang Z., Augmenting java method comments generation with context information based on neural networks, J. Syst. Softw., 156, Oct., pp. 328-340, (2019); Zugner D., Kirschstein T., Catasta M., Leskovec J., Gunnemann S., Language-agnostic representation learning of source code from structure and context, (2021)",,,,,,English,Article,Final,All Open Access; Green Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85126290388,157
Qu Z.; Hu Y.; Zeng J.; Cai B.; Yang S.,"Qu, Zhiheng (57841342900); Hu, Yi (57413274600); Zeng, Jianhui (57841928900); Cai, Bo (35745538800); Yang, Shun (57841634300)",57841342900; 57413274600; 57841928900; 35745538800; 57841634300,Method Name Generation Based on Code Structure Guidance,2022,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",,,,1101,1110,9,4,10.1109/SANER53432.2022.00127,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135770882&doi=10.1109%2fSANER53432.2022.00127&partnerID=40&md5=900a09371c404e9dc1383cf4e06642b7,"The proper names of software engineering functions and methods can greatly assist developers in understanding and maintaining the code. Most researchers convert the method name generation task into the text summarization task. They take the token sequence and the abstract syntax tree (AST) of source code as input, and generate method names with a decoder. However, most proposed models learn semantic and structural features of the source code separately, resulting in poor performance in the method name generation task. Actually, each token in source code must have a corresponding node in its AST. Inspired by this observation, we propose SGMNG, a structure-guided method name generation model that learns the representation of two combined features. Additionally, we build a code graph called code relation graph (CRG) to describe the code structure clearly. CRG retains the structure of the AST of source code and contains data flows and control flows. SGMNG captures the semantic features of the code by encoding the token sequence and captures the structural features of the code by encoding the CRG. Then, SGMNG matches tokens in the sequence and nodes in the CRG to construct the combination of two features. We demonstrate the effectiveness of the proposed approach on the public dataset Java-Small with 700K samples, which indicates that our approach achieves significant improvement over the state-of-the-art baseline models in the ROUGE metric.  © 2022 IEEE.","Allamanis M., Barr E.T., Bird C., Sutton C., Suggesting accurate method and class names, Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2015, pp. 38-49, (2015); Nguyen S., Phan H., Le T., Nguyen T.N., Suggesting natural method names to check name consistencies, ICSE '20: 42nd International Conference on Software Engineering, Seoul, South Korea, 27 June-19 July, pp. 1372-1384, (2020); Host E.W., Ostvold B.M., Debugging method names, ECOOP 2009-Object-Oriented Programming, 23rd European Conference, 5653, pp. 294-317, (2009); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2018, pp. 404-419, (2018); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: learning distributed representations of code, Proc. ACM Program. Lang., 3, POPL, pp. 401-4029, (2019); Jiang L., Liu H., Jiang H., Machine learning based recommendation of method names: How far are we, 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019, pp. 602-614, (2019); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating sequences from structured representations of code, 7th International Conference on Learning Representations, ICLR 2019, (2019); Bahdanau D., Cho K., Bengio Y., Neural machine translation by jointly learning to align and translate, 3rd International Conference on Learning Representations, ICLR 2015, (2015); Zaremba W., Sutskever I., Vinyals O., Recurrent neural network regularization, (2014); Masci J., Rodola E., Boscaini D., Bronstein M.M., Li H., Geometric deep learning, SIGGRAPH ASIA 2016, pp. 11-150, (2016); Vinyals O., Fortunato M., Jaitly N., Pointer networks, Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, pp. 2692-2700, (2015); Liu K., Kim D., Bissyande T.F., Kim T., Kim K., Koyuncu A., Kim S., Traon Y.L., Learning to spot and refactor inconsistent method names, Proceedings of the 41st International Conference on Software Engineering, ICSE 2019, pp. 1-12, (2019); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, 48, pp. 2091-2100, (2016); Xu S., Zhang S., Wang W., Cao X., Guo C., Xu J., Method name suggestion with hierarchical attention networks, Proceedings of the 2019 ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation, PEPM@POPL 2019, pp. 10-21, (2019); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, 7th International Conference on Learning Representations, ICLR 2019, (2019); Zugner D., Kirschstein T., Catasta M., Leskovec J., Gunnemann S., Language-agnostic representation learning of source code from structure and context, 9th International Conference on Learning Representations, ICLR 2021, (2021); Ge F., Kuang L., Keywords guided method name generation, 29th IEEE/ACM International Conference on Program Comprehension, ICPC 2021, pp. 196-206, (2021); Li H., Zhu J., Zhang J., Zong C., He X., Keywords-guided abstractive sentence summarization, The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, pp. 8196-8203, (2020); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, 1, (2016); Ahmad W.U., Chakraborty S., Ray B., Chang K., A transformerbased approach for source code summarization, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, pp. 4998-5007, (2020); Wei B., Li G., Xia X., Fu Z., Jin Z., Code generation as a dual task of code summarization, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, pp. 6559-6569, (2019); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proceedings of the 26th Conference on Program Comprehension, ICPC 2018, pp. 200-210, (2018); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, ASE 2018, pp. 397-407, (2018); LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, Proceedings of the 41st International Conference on Software Engineering, ICSE 2019, pp. 795-806, (2019); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, ICPC '20: 28th International Conference on Program Comprehension, pp. 184-195, (2020); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using RNN encoder-decoder for statistical machine translation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, pp. 1724-1734, (2014); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, 6th International Conference on Learning Representations, ICLR 2018, (2018); Yu Y., fast: flattening abstract syntax trees for efficiency, Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings, ICSE 2019, pp. 278-279, (2019); Schlichtkrull M.S., Kipf T.N., Bloem P., Van Den Berg R., Titov I., Welling M., Modeling relational data with graph convolutional networks, The Semantic Web-15th International Conference, ESWC 2018, pp. 593-607, (2018); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5th International Conference on Learning Representations, ICLR 2017, (2017); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, 4th International Conference on Learning Representations, ICLR 2016, (2016); Kingma D.P., Ba J., Adam: A method for stochastic optimization, 3rd International Conference on Learning Representations, ICLR 2015, (2015); Lin C.-Y., Rouge: A package for automatic evaluation of summaries, Workshop on Text Summarization Branches Out, Post-Conference Workshop of ACL 2004, pp. 74-81, (2004); Freitag M., Al-Onaizan Y., Beam search strategies for neural machine translation, Proceedings of the First Workshop on Neural Machine Translation, NMT@ACL 2017, pp. 56-60, (2017)",IEEE Computer Society,"29th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",15 March 2022 through 18 March 2022,"Virtual, Online",181173,English,Conference paper,Final,,Scopus,2-s2.0-85135770882,158
Guo J.; Liu J.; Wan Y.; Li L.; Zhou P.,"Guo, Juncai (58000014600); Liu, Jin (55978402400); Wan, Yao (57089582400); Li, Li (56438149900); Zhou, Pingyi (56204333600)",58000014600; 55978402400; 57089582400; 56438149900; 56204333600,Modeling Hierarchical Syntax Structure with Triplet Position for Source Code Summarization,2022,Proceedings of the Annual Meeting of the Association for Computational Linguistics,1,,,486,500,14,10,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139035948&partnerID=40&md5=75c1f5cac559ddb1ae026364e3707e4a,"Automatic code summarization, which aims to describe the source code in natural language, has become an essential task in software maintenance. Our fellow researchers have attempted to achieve such a purpose through various machine learning-based approaches. One key challenge keeping these approaches from being practical lies in the lacking of retaining the semantic structure of source code, which has unfortunately been overlooked by the state-of-the-art methods. Existing approaches resort to representing the syntax structure of code by modeling the Abstract Syntax Trees (ASTs). However, the hierarchical structures of ASTs have not been well explored. In this paper, we propose CODESCRIBE to model the hierarchical syntax structure of code by introducing a novel triplet position for code summarization. Specifically, CODESCRIBE leverages the graph neural network and Transformer to preserve the structural and sequential information of code, respectively. In addition, we propose a pointer-generator network that pays attention to both the structure and sequential tokens of code for a better summary generation. Experiments on two real-world datasets in Java and Python demonstrate the effectiveness of our proposed approach when compared with several state-of-the-art baselines. © 2022 Association for Computational Linguistics.","Ahmad Wasi, Chakraborty Saikat, Ray Baishakhi, Chang Kai-Wei, A transformer-based approach for source code summarization, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 4998-5007, (2020); Ahmad Wasi, Chakraborty Saikat, Ray Baishakhi, Chang Kai-Wei, Unified pre-training for program understanding and generation, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2655-2668, (2021); Allamanis Miltiadis, Peng Hao, Sutton Charles, A convolutional attention network for extreme summarization of source code, Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, pp. 2091-2100, (2016); Alon Uri, Brody Shaked, Levy Omer, Yahav Eran, code2seq: Generating sequences from structured representations of code, 7th International Conference on Learning Representations (ICLR), (2019); Ba Lei Jimmy, Kiros Jamie Ryan, Hinton Geoffrey E., Layer normalization, CoRR, (2016); Banerjee Satanjeev, Lavie Alon, METEOR: an automatic metric for MT evaluation with improved correlation with human judgments, Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pp. 65-72, (2005); Bird Steven, NLTK: the natural language toolkit, ACL 2006, 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, pp. 69-72, (2006); Choi YunSeok, Bak JinYeong, Na CheolWon, Lee Jee-Hyong, Learning sequential and structural information for source code summarization, Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021, pp. 2842-2851, (2021); Clark Kevin, Luong Minh-Thang, Le Quoc V., Manning Christopher D., ELECTRA: pre-training text encoders as discriminators rather than generators, 8th International Conference on Learning Representations, ICLR 2020, (2020); Cozzetti Sergio, de Souza B., Anquetil Nicolas, de Oliveira Kathia Marcal, A study of the documentation essential to software maintenance, Proceedings of the 23rd Annual International Conference on Design of Communication: documenting & Designing for Pervasive Information, SIGDOC 2005, pp. 68-75, (2005); Eriguchi Akiko, Hashimoto Kazuma, Tsuruoka Yoshimasa, Tree-to-sequence attentional neural machine translation, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pp. 823-833, (2016); Feng Zhangyin, Guo Daya, Tang Duyu, Duan Nan, Feng Xiaocheng, Gong Ming, Shou Linjun, Qin Bing, Liu Ting, Jiang Daxin, Zhou Ming, Codebert: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Gehring Jonas, Auli Michael, Grangier David, Yarats Denis, Dauphin Yann N., Convolutional sequence to sequence learning, Proceedings of the 34th International Conference on Machine Learning, volume 70 of Proceedings of Machine Learning Research, pp. 1243-1252, (2017); Gu Xiaodong, Zhang Hongyu, Kim Sunghun, Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE), pp. 933-944, (2018); Hamilton William L., Ying Zhitao, Leskovec Jure, Inductive representation learning on large graphs, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, pp. 1024-1034, (2017); He Kaiming, Zhang Xiangyu, Ren Shaoqing, Sun Jian, Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Hu Xing, Li Ge, Xia Xin, Lo David, Jin Zhi, Deep code comment generation, ICPC'18: Proceedings of the 26th Conference on Program Comprehension, pp. 200-210, (2018); Hu Xing, Li Ge, Xia Xin, Lo David, Jin Zhi, Deep code comment generation with hybrid lexical and syntactical information, Empirical Software Engineering, 25, pp. 2179-2217, (2020); Hu Xing, Li Ge, Xia Xin, Lo David, Lu Shuai, Jin Zhi, Summarizing source code with transferred API knowledge, Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018, pp. 2269-2275, (2018); Iyer Srinivasan, Konstas Ioannis, Cheung Alvin, Zettlemoyer Luke, Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2073-2083, (2016); Kajko-Mattsson Mira, A survey of documentation practice within corrective maintenance, Empirical Software Engineering, 10, 1, pp. 31-55, (2005); Kingma Diederik P., Ba Jimmy, Adam: A method for stochastic optimization, 3rd International Conference on Learning Representations, (2015); Kipf Thomas N., Welling Max, Semi-Supervised Classification with Graph Convolutional Networks, Proceedings of the 5th International Conference on Learning Representations, ICLR'17, (2017); Koehn Philipp, Pharaoh: A beam search decoder for phrase-based statistical machine translation models, Machine Translation: From Real Users to Research, 6th Conference of the Association for Machine Translation in the Americas, AMTA 2004, pp. 115-124, (2004); LeClair Alexander, Haque Sakib, Wu Lingfei, McMillan Collin, Improved code summarization via a graph neural network, 2020 IEEE/ACM International Conference on Program Comprehension (ICPC), pp. 184-195, (2020); Lin Chin-Yew, ROUGE: A package for automatic evaluation of summaries, Proceedings of the ACL Workshop: Text Summarization Braches Out 2004, pp. 74-81, (2004); Liu Shangqing, Chen Yu, Xie Xiaofei, Siow Jingkai, Liu Yang, Automatic code summarization via multi-dimensional semantic fusing in GNN, CoRR, (2020); Mou Lili, Li Ge, Zhang Lu, Wang Tao, Jin Zhi, Convolutional neural networks over tree structures for programming language processing, Proceedings of the 30th AAAI Conference on Artificial Intelligence, pp. 1287-1293, (2016); Nguyen Anh Tuan, Nguyen Tien N., Automatic categorization with deep neural network for open-source java projects, Proceedings of the 39th International Conference on Software Engineering, ICSE 2017, pp. 164-166, (2017); Papineni Kishore, Roukos Salim, Ward Todd, Zhu Wei-Jing, Bleu: a method for automatic evaluation of machine translation, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Phan Long N., Tran Hieu, Le Daniel, Nguyen Hieu, Anibal James T., Peltekian Alec, Ye Yanfang, Cotext: Multi-task learning with code-text transformer, CoRR, (2021); Raffel Colin, Shazeer Noam, Roberts Adam, Lee Katherine, Narang Sharan, Matena Michael, Zhou Yanqi, Li Wei, Liu Peter J., Exploring the limits of transfer learning with a unified text-to-text transformer, Journal of Machine Learning Research, 21, 140, pp. 1-67, (2020); See Abigail, Liu Peter J., Manning Christopher D., Get to the point: Summarization with pointer-generator networks, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, pp. 1073-1083, (2017); Shido Yusuke, Kobayashi Yasuaki, Yamamoto Akihiro, Miyamoto Atsushi, Matsumura Tadayuki, Automatic source code summarization with extended tree-lstm, 2019 International Joint Conference on Neural Networks (IJCNN), pp. 1-8, (2019); Tai Kai Sheng, Socher Richard, Manning Christopher D., Improved semantic representations from tree-structured long short-term memory networks, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015, pp. 1556-1566, (2015); Vaswani Ashish, Shazeer Noam, Parmar Niki, Uszkoreit Jakob, Jones Llion, Gomez Aidan N., Kaiser Lukasz, Polosukhin Illia, Attention is all you need, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems, pp. 5998-6008, (2017); Wan Yao, Zhao Zhou, Yang Min, Xu Guandong, Ying Haochao, Wu Jian, Yu Philip S, Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Wang Wenhua, Zhang Yuqun, Sui Yulei, Wan Yao, Zhao Zhou, Wu Jian, Yu Philip S., Xu Guandong, Reinforcement-learning-guided source code summarization using hierarchical attention, IEEE Trans. Software Eng, 48, 2, pp. 102-119, (2022); Wang Yue, Wang Weishi, Joty Shafiq R., Hoi Steven C. H., Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, pp. 8696-8708, (2021); Wei Bolin, Li Ge, Xia Xin, Fu Zhiyi, Jin Zhi, Code generation as a dual task of code summarization, Advances in Neural Information Processing Systems, pp. 6563-6573, (2019); Wei Bolin, Li Yongmin, Li Ge, Xia Xin, Jin Zhi, Retrieve and refine: Exemplar-based neural comment generation, 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020, pp. 349-360, (2020); Yamaguchi Fabian, Golde Nico, Arp Daniel, Rieck Konrad, Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, SP 2014, pp. 590-604, (2014); Yao Ziyu, Peddamail Jayavardhan Reddy, Sun Huan, Coacor: Code annotation for code retrieval with reinforcement learning, The World Wide Web Conference, WWW 2019, pp. 2203-2214, (2019); Ye Wei, Xie Rui, Zhang Jinglei, Hu Tianxiang, Wang Xiaoyin, Zhang Shikun, Leveraging code generation to improve code retrieval and summarization via dual learning, Proceedings of The Web Conference 2020, pp. 2309-2319, (2020); Zhang Jian, Wang Xu, Zhang Hongyu, Sun Hailong, Liu Xudong, Retrieval-based neural source code summarization, ICSE'20: 42nd International Conference on Software Engineering, pp. 1385-1397, (2020); Zhang Jian, Wang Xu, Zhang Hongyu, Sun Hailong, Wang Kaixuan, Liu Xudong, A novel neural source code representation based on abstract syntax tree, Proceedings of the IEEE/ACM 41st International Conference on Software Engineering, pp. 783-794, (2019)",Amazon Science; Bloomberg Engineering; et al.; Google Research; Liveperson; Meta,"60th Annual Meeting of the Association for Computational Linguistics, ACL 2022",22 May 2022 through 27 May 2022,Dublin,181737,English,Conference paper,Final,,Scopus,2-s2.0-85139035948,159
Wang X.; Wu Q.; Zhang H.; Lyu C.; Jiang X.; Zheng Z.; Lyu L.; Hu S.,"Wang, Xiao (57202890546); Wu, Qiong (57221969385); Zhang, Hongyu (55685668500); Lyu, Chen (57195985796); Jiang, Xue (57221947208); Zheng, Zhuoran (57279212800); Lyu, Lei (57204062203); Hu, Songlin (7404287527)",57202890546; 57221969385; 55685668500; 57195985796; 57221947208; 57279212800; 57204062203; 7404287527,HELoC: Hierarchical Contrastive Learning of Source Code Representation,2022,IEEE International Conference on Program Comprehension,2022-March,,,354,365,11,12,10.1145/3524610.3527896,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133210433&doi=10.1145%2f3524610.3527896&partnerID=40&md5=d8f8aab6c1c776d3d977371794cf1a1c,"Abstract syntax trees (ASTs) play a crucial role in source code representation. However, due to the large number of nodes in an AST and the typically deep AST hierarchy, it is challenging to learn the hierarchical structure of an AST effectively. In this paper, we propose HELoC, a hierarchical contrastive learning model for source code representation. To effectively learn the AST hierarchy, we use contrastive learning to allow the network to predict the AST node level and learn the hierarchical relationships between nodes in a self-supervised manner, which makes the representation vectors of nodes with greater differences in AST levels farther apart in the embedding space. By using such vectors, the structural similarities between code snippets can be measured more precisely. In the learning process, a novel GNN (called Residual Self-attention Graph Neural Network, RSGNN) is designed, which enables HELoC to focus on embedding the local structure of an AST while capturing its overall structure. HELoC is self-supervised and can be applied to many source code related downstream tasks such as code classification, code clone detection, and code clustering after pre-training. Our extensive experiments demonstrate that HELoC outperforms the state-of-the-art source code representation models.  © 2022 ACM.","Gu X., Zhang H., Kim S., Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE), (2018); Sachdev S., Li H., Luan S., Kim S., Sen K., Chandra S., Retrieval on source code: a neural code search, Proceedings of the 2nd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages, (2018); Hua W., Sui Y., Wan Y., Liu G., Xu G., Fcca: Hybrid code representation for functional clone detection using attention networks, IEEE Transactions on Reliability, 70, 1, pp. 304-318, (2020); Bui N.D.Q., Yu Y., Jiang L., Infercode: Self-supervised learning of code representations by predicting subtrees, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), (2021); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER), (2020); Wang W., Li G., Shen S., Xia X., Jin Z., Modular tree network for source code representation learning, ACM Transactions on Software Engineering and Methodology (TOSEM), (2020); Gros D., Sezhiyan H., Devanbu P., Yu Z., Code to comment ""translation"": Data, metrics, baselining & evaluation, 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE), (2020); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, 2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC), (2018); Wang H., Xia X., Lo D., Grundy J., Wang X., Automatic solution summarization for crash bugs, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), (2021); Khanh Dam H., Tran T., Thi Minh Pham T., Wee Ng S., Grundy J., Ghose A., Automatic feature learning for predicting vulnerable software components, IEEE Transactions on Software Engineering, (2018); Pei X., Yu L., Tian S., Amalnet: A deep learning framework based on graph convolutional networks for malware detection, Computers & Security, 93, (2020); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, (2019); Ahmad W., Chakraborty S., Ray B., Chang K., A transformer-based approach for source code summarization, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, (2020); Zhang J., Wang X., Zhang H., Sun H., Liu X., Retrievalbased neural source code summarization, 2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE), (2020); Wang W., Zhang Y., Sui Y., Wan Y., Zhao Z., Wu J., Yu P., Xu G., Reinforcement-learning-guided source code summarization via hierarchical attention, IEEE Transactions on software Engineering, 1, pp. 1-1, (2020); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proceedings of the 28th International Conference on Program Comprehension, (2020); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, International conference on machine learning, (2016); Huo X., Li M., Zhou Z., Et al., Learning unified features from natural and programming languages for locating buggy source code, IJCAI, (2016); Li J., Wang Y., Lyu M.R., King I., Code completion with neural attention and pointer networks, IJCAI, (2018); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, (2016); LeClair A., Bansal A., McMillan C., Ensemble models for neural source code summarization of subroutines, 2021 IEEE International Conference on Software Maintenance and Evolution (ICSME), (2021); Liu S., Chen Y., Xie X., Kai Siow J., Liu Y., Retrievalaugmented generation for code summarization via hybrid gnn, International Conference on Learning Representations, (2020); Liu S., A unified framework to learn program semantics with graph neural networks, 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE), (2020); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), (2019); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Thirtieth AAAI Conference on Artificial Intelligence, (2016); Ji X., Liu L., Zhu J., Code clone detection with hierarchical attentive graph embedding, International Journal of Software Engineering and Knowledge Engineering, 31, 6, pp. 837-861, (2021); Hadsell R., Chopra S., LeCun Y., Dimensionality reduction by learning an invariant mapping, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), (2006); Zugner D., Kirschstein T., Catasta M., Leskovec J., Gunnemann S., Language-agnostic representation learning of source code from structure and context, International Conference on Learning Representations, (2020); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, (2019); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating sequences from structured representations of code, International Conference on Learning Representations, (2018); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, International Conference on Learning Representations, (2018); Mehrotra N., Agarwal N., Gupta P., Anand S., Lo D., Purandare R., Modeling functional similarity in source code with graph-based siamese networks, IEEE Transactions on Software Engineering, (2021); Guo Z., Zhang Y., Lu W., Attention guided graph convolutional networks for relation extraction, (2019); Bui N.D.Q., Yu Y., Jiang L., Self-supervised contrastive learning for code retrieval and summarization via semantic-preserving transformations, Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, (2021); Jain P., Jain A., Zhang T., Abbeel P., Gonzalez J.E., Stoica I., Contrastive code representation learning, (2020); Jiang X., Zheng Z., Lyu C., Li L., Lyu L., Treebert: A treebased pre-trained model for programming language, International Conference on Uncertainty in Artificial Intelligence, UAI, (2021); Guo D., Ren S., Lu S., Feng Z., Tang D., Shujie L.I.U., Zhou L., Duan N., Svyatkovskiy A., Fu S., Et al., Graphcodebert: Pretraining code representations with data flow, International Conference on Learning Representations, (2020); Misra I., Van Der Maaten L., Self-supervised learning of pretextinvariant representations, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, (2020); Rubinstein R., The cross-entropy method for combinatorial and continuous optimization, Methodology and computing in applied probability, 1, 2, pp. 127-190, (1999); Schroff F., Kalenichenko D., Philbin J., Facenet: A unified embedding for face recognition and clustering, Proceedings of the IEEE conference on computer vision and pattern recognition, (2015); Wang Y., Li H., Code completion by modeling flattened abstract syntax trees as graphs, Proceedings of the AAAI Conference on Artificial Intelligence, (2021); Kendall A., Gal Y., Cipolla R., Multi-task learning using uncertainty to weigh losses for scene geometry and semantics, Proceedings of the IEEE conference on computer vision and pattern recognition, (2018); Van Der Maaten L., Hinton G., Visualizing data using t-sne, Journal of machine learning research, 9, 11; Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., Sourcerercc: Scaling code clone detection to big-code, Proceedings of the 38th International Conference on Software Engineering, (2016); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, 2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE), (2016); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, 2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR), (2018); Sheng Tai K., Socher R., Manning C.D., Improved semantic representations from tree-structured long short-term memory networks, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, (2015); Kanungo T., Mount D.M., Netanyahu N.S., Piatko C.D., Silverman R., Wu A.Y., An efficient k-means clustering algorithm: Analysis and implementation, IEEE transactions on pattern analysis and machine intelligence, (2002); Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2014); Liang Y., Zhu K., Automatic generation of text descriptive comments for code blocks, Proceedings of the AAAI Conference on Artificial Intelligence, (2018); Muller R., Kornblith S., Hinton G., When does label smoothing help?, Proceedings of the 33rd International Conference on Neural Information Processing Systems, (2019); Zaremba W., Sutskever I., Learning to execute; Cummins C., Petoumenos P., Wang Z., Leather H., Synthesizing benchmarks for predictive modeling, 2017 IEEE/ACM International Symposium on Code Generation and Optimization (CGO), (2017); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, International Conference on Learning Representations, (2018); Kumar Roy C., Cordy J.R., A survey on software clone detection research, Queen's School of Computing TR, 541, 115, pp. 64-68, (2007); Svajlenko J., Islam J.F., Keivanloo I., Roy C.K., Mamun Mia M., Towards a big data curated benchmark of inter-project code clones, 2014 IEEE International Conference on Software Maintenance and Evolution, (2014); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate tree-based detection of code clones, 29th International Conference on Software Engineering (ICSE'07), (2007); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, IJCAI, (2017); Wu Y., Zou D., Dou S., Yang S., Yang W., Cheng F., Liang H., Jin H., Scdetector: software functional clone detection based on semantic tokens analysis, Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering, (2020); Bui N.D.Q., Yu Y., Jiang L., Bilateral dependency neural networks for cross-language algorithm classification, 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER), (2019); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in neural information processing systems, (2013); Le Q., Mikolov T., Distributed representations of sentences and documents, International conference on machine learning, (2014); Santos J.M., Embrechts M., On the use of the adjusted rand index as a metric for evaluating supervised classification, International conference on artificial neural networks, (2009); Lu M., Tan D., Xiong N., Chen Z., Li H., Program classification using gated graph attention neural network for online programming service, (2019); Mehrotra N., Agarwal N., Gupta P., Anand S., Lo D., Purandare R., Modeling functional similarity in source code with graph-based siamese networks, (2020); Li J., He P., Zhu J., Lyu M.R., Software defect prediction via convolutional neural network, 2017 IEEE International Conference on Software Quality, Reliability and Security (QRS), (2017); Svyatkovskiy A., Kun Deng S., Fu S., Sundaresan N., Intellicode compose: Code generation using transformer, Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, (2020); Sun Z., Zhu Q., Xiong Y., Sun Y., Mou L., Zhang L., Treegen: A tree-based transformer architecture for code generation, Proceedings of the AAAI Conference on Artificial Intelligence, (2020); Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, International conference on learning representations, (2019); Shaw P., Uszkoreit J., Vaswani A., Self-attention with relative position representations, (2018); Peng H., Li G., Wang W., Zhao Y., Jin Z., Advances in Neural Information Processing Systems, Integrating tree path in transformer for code representation, (2021); Howard J., Ruder S., Universal language model fine-tuning for text classification, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, (2018); Devlin J., Chang M., Lee K., Toutanova K., Bert: Pretraining of deep bidirectional transformers for language understanding, NAACL-HLT (1), (2019); Erhan D., Courville A., Bengio Y., Vincent P., Why does unsupervised pre-training help deep learning?, Proceedings of the thirteenth international conference on artificial intelligence and statistics, (2010); Hao Y., Dong L., Wei F., Xu K., Visualizing and understanding the effectiveness of bert, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), (2019); Gidaris S., Singh P., Komodakis N., Unsupervised representation learning by predicting image rotations, ICLR 2018, (2018); Pathak D., Krahenbuhl P., Donahue J., Darrell T., Efros A.A., Context encoders: Feature learning by inpainting, Proceedings of the IEEE conference on computer vision and pattern recognition, (2016); He K., Fan H., Wu Y., Xie S., Girshick R., Momentum contrast for unsupervised visual representation learning, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, (2020); Chen T., Kornblith S., Norouzi M., Hinton G., A simple framework for contrastive learning of visual representations, International conference on machine learning, (2020); Chuang C., Robinson J., Yen-Chen L., Torralba A., Jegelka S., Debiased contrastive learning, (2020); Giorgi J.M., Nitski O., Bader G.D., Wang B., Declutr: Deep contrastive learning for unsupervised textual representations, (2020); Ding Y., Buratti L., Pujar S., Morari A., Ray B., Chakraborty S., Contrastive learning for source code with structural and functional properties, (2021); Chen Q., Lacomis J., Schwartz E.J., Neubig G., Vasilescu B., Le Goues C., Varclr: Variable semantic representation pretraining via contrastive learning, (2021); Van Den Oord A., Li Y., Vinyals O., Representation learning with contrastive predictive coding, (2018); Chopra S., Hadsell R., LeCun Y., Learning a similarity metric discriminatively, with application to face verification, 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05), (2005)",,"30th IEEE/ACM International Conference on Program Comprehension, ICPC 2022",16 May 2022 through 17 May 2022,Pittsburgh,180257,English,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85133210433,160
Hou S.; Chen L.; Ye Y.,"Hou, Shifu (56572013400); Chen, Lingwei (56571903100); Ye, Yanfang (57323577100)",56572013400; 56571903100; 57323577100,Summarizing Source Code from Structure and Context,2022,Proceedings of the International Joint Conference on Neural Networks,2022-July,,,,,,3,10.1109/IJCNN55064.2022.9892013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140713399&doi=10.1109%2fIJCNN55064.2022.9892013&partnerID=40&md5=5f620b70d83f1491fb0fcaeaf72aadaf,"Modern software developers tend to engage in social coding platforms to reuse code snippets to expedite the development process, while the codes on such platforms are often suffering from comments being mismatched, missing or outdated. This puts the code search and comprehension in difficulty, and increases the burden of maintenance for software building upon these codes. As summarizing code is beneficial yet it is very expensive for manual operation, in this paper, we elaborate an automatic and effective code summarization paradigm to address this laborious challenge. We represent a given code snippet as an abstract syntax tree (AST), and generate a set of compositional root-to-leaf paths to make the AST accessible regarding code context and structure in a less complex yet expressive way. Accordingly, we design a tree-based transformer model, called TreeXFMR, on these paths to summarize source code in a hierarchical attention operation. This yields two advantages on code representation learning: (1) attention mechanisms at token-and path-level attend the semantics and interactions of source code from different aspects; (2) bi-level positional encodings introduced reveal the intra- and inter-path structure of AST and improve the unambiguity of the representations. During decoding, TreeXFMR attends such learned representations to produce each output of natural language word. We further pre-train the transformer to achieve faster and better training convergence results. Extensive experiments on the code collection from GitHub demonstrate the effectiveness of TreeXFMR, which significantly outperforms state-of-the-art baselines. © 2022 IEEE.","Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Computing Surveys (CSUR), 51, 4, pp. 1-37, (2018); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, International conference on machine learning., pp. 2091-2100, (2016); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating sequences from structured representations of code, (2018); Bielik P., Raychev V., Vechev M., Program synthesis for character level language modelling, International conference on learning representations, (2017); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using rnn encoder-decoder for statistical machine translation, (2014); Dai Z., Yang Z., Yang Y., Carbonell J., Le Q.V., Salakhutdinov R., Transformer-xl: Attentive language models beyond a fixed-length context, (2019); Dey R., Salem F.M., Gate-variants of gated recurrent unit (gru) neural networks, 2017 IEEE 60th international midwest symposium on circuits and systems (MWSCAS)., pp. 1597-1600, (2017); Eddy B.P., Robinson J.A., Kraft N.A., Carver J.C., Evaluating source code summarization techniques: Replication and expansion, 2013 21st International Conference on Program Comprehension (ICPC)., pp. 13-22, (2013); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Codebert: A pre-trained model for programming and natural languages, (2020); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization. International conference on learning representations, (2019); Graves A., Long short-term memory, Supervised sequence labelling with recurrent neural networks, pp. 37-45, (2012); Gu X., Zhang H., Kim S., Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)., pp. 933-944, (2018); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Et al., Graphcodebert: Pre-training code representations with data flow, International conference on learning representations, (2021); Haiduc S., Aponte J., Marcus A., Supporting program comprehension with source code summarization, 2010 acm/ieee 32nd international conference on software engineering, 2, pp. 223-226, (2010); Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, International conference on learning representations, (2019); Hochreiter S., Schmidhuber J., Long short-term memory, Neural computation, 9, 8, pp. 1735-1780, (1997); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, ICPC., pp. 200-210, (2018); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, ACL., pp. 2073-2083, (2016); Kim M., Sazawal V., Notkin D., Murphy G., An empirical study of code clone genealogies, Proceedings of the 10th European software engineering conference., pp. 187-196, (2005); Li Z., Lu S., Myagmar S., Zhou Y., Cp-miner: Finding copy-paste and related bugs in large-scale software code, IEEE Transactions on software Engineering, 32, 3, pp. 176-192, (2006); Loyola P., Marrese-Taylor E., Matsuo Y., A neural architecture for generating natural language descriptions from source code changes, (2017); Luong M.T., Pham H., Manning C.D., Effective approaches to attention-based neural machine translation, (2015); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, NeurIPS, (2013); Papineni K., Roukos S., Ward T., Zhu W.J., Bleu: A method for automatic evaluation of machine translation, Association for Computational Linguistics., pp. 311-318, (2002); Rodeghero P., McMillan C., McBurney P.W., Bosch N., D'Mello S., Improving automated source code summarization via an eye-tracking study of programmers, ICSE., pp. 390-401, (2014); Shen Y., Tan S., Sordoni A., Courville A., Ordered neurons: Integrating tree structures into recurrent neural networks, International conference on learning representations, (2019); Sutskever I., Vinyals O., Le Q.V., Sequence to sequence learning with neural networks, (2014); Tai K.S., Socher R., Manning C.D., Improved semantic representations from tree-structured long short-term memory networks, Association for Computational Linguistics., pp. 1556-1566, (2015); Vasilescu B., Filkov V., Serebrenik A., Stackoverflow and github: Associations between software development and crowdsourced knowledge, 2013 International Conference on Social Computing., pp. 188-195, (2013); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, (2017); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering., pp. 397-407, (2018); Werbos P.J., Backpropagation through time: What it does and how to do it, Proceedings of the IEEE, 78, 10, pp. 1550-1560, (1990); Wiseman S., Rush A.M., Sequence-to-sequence learning as beamsearch optimization, Empirical Methods in Natural Language Processing (EMNLP), (2016); Wong E., Yang J., Tan L., Autocomment: Mining question and answer sites for automatic comment generation, 2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)., pp. 562-567, (2013); Xia X., Bao L., Lo D., Xing Z., Hassan A.E., Li S., Measuring program comprehension: A large-scale field study with professionals, IEEE Transactions on Software Engineering, 44, 10, pp. 951-976, (2017); Yao Z., Peddamail J.R., Sun H., Coacor: Code annotation for code retrieval with reinforcement learning, The World Wide Web Conference., pp. 2203-2214, (2019); Zhang J., Wang X., Zhang H., Sun H., Liu X., Retrieval-based neural source code summarization, 2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)., pp. 1385-1397, (2020); Zugner D., Kirschstein T., Catasta M., Leskovec J., Gunnemann S., Language-agnostic representation learning of source code from structure and context, (2021)",,"2022 International Joint Conference on Neural Networks, IJCNN 2022",18 July 2022 through 23 July 2022,Padua,183333,English,Conference paper,Final,,Scopus,2-s2.0-85140713399,161
Jin D.; Liu P.; Zhu Z.,"Jin, Dun (57388416100); Liu, Peiyu (9041327700); Zhu, Zhenfang (26325162200)",57388416100; 9041327700; 26325162200,Automatically Generating Code Comment Using Heterogeneous Graph Neural Networks,2022,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",,,,1078,1088,10,0,10.1109/SANER53432.2022.00125,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135841227&doi=10.1109%2fSANER53432.2022.00125&partnerID=40&md5=ca88a884cb1bb226fb8db79ee007e615,"Code summarization aims to generate readable summaries that describe the functionality of source code pieces. The main purpose of the code summarization is to help software developers understand the code and save their precious time. However, since programming languages are highly structured, it is challenging to generate high-quality code summaries. For this reason, this paper proposes a new approach named CCHG to automatically generate code comments. Compared to recent models that use additional information such as Abstract Syntax Trees as input, our proposed method only uses the most original code as input. We believe that programming languages are the same as natural languages. Each line of code is equivalent to a sentence, representing an independent meaning. Therefore, we split the entire code snippet into several sentence-level code. Coupled with token-level code, there are two types of code that need to be processed. So we propose heterogeneous graph networks to process the sentence-level and token-level code. Even though we do not introduce additional structural knowledge, the experimental results show that our model has a considerable performance, which indicates that our model can fully learn structural information and sequence information from code snippets.  © 2022 IEEE.","Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2073-2083, (2016); Haque S., Bansal A., Wu L., McMillan C., Action word prediction for neural source code summarization, 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, pp. 330-341, (2021); Choi Y.S., Bak J.Y., Na C.W., Lee J.H., Learning sequential and structural information for source code summarization, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pp. 2842-2851, (2021); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, 2018 IEEE/ACM 26th International Conference on Program Comprehension, pp. 200-20010, (2018); Wu H., Zhao H., Zhang M., Code summarization with structureinduced transformer, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pp. 1078-1090, (2020); Ahmad W., Chakraborty S., Ray B., Chang K.-W., A transformerbased approach for source code summarization, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 4998-5007, (2020); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in neural information processing systems, pp. 5998-6008, (2017); Zhang C., Song D., Huang C., Swami A., Chawla N.V., Heterogeneous graph neural network, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 793-803, (2019); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); Sridhara G., Hill E., Muppaneni D., Pollock L., Vijay-Shanker K., Towards automatically generating summary comments for java methods, Proceedings of the IEEE/ACM international conference on Automated software engineering, pp. 43-52, (2010); Sridhara G., Pollock L., Vijay-Shanker K., Automatically detecting and describing high level actions within methods, 2011 33rd International Conference on Software Engineering, pp. 101-110, (2011); Haiduc S., Aponte J., Marcus A., Supporting program comprehension with source code summarization, 2010 acm/ieee 32nd international conference on software engineering, pp. 223-226, (2010); Haiduc S., Aponte J., Moreno L., Marcus A., On the use of automated text summarization techniques for summarizing source code, 2010 17th Working Conference on Reverse Engineering, pp. 35-44, (2010); Wong E., Yang J., Tan L., Autocomment: Mining question and answer sites for automatic comment generation, 2013 28th IEEE/ACM International Conference on Automated Software Engineering, pp. 562-567, (2013); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proceedings of the 28th International Conference on Program Comprehension, pp. 184-195, (2020); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation with hybrid lexical and syntactical information, Empirical Software Engineering, pp. 2179-2217, (2020); Haiduc S., Marcus A., On the use of domain terms in source code, 2008 16th IEEE International Conference on Program Comprehension, pp. 113-122, (2008); Sridhara G., Hill E., Muppaneni D., Pollock L., Vijay-Shanker K., Towards automatically generating summary comments for java methods, Proceedings of the IEEE/ACM international conference on Automated software engineering, pp. 43-52, (2010); Bahdanau D., Cho K.H., Bengio Y., Neural machine translation by jointly learning to align and translate, 3rd International Conference on Learning Representations, (2015); Wong E., Liu T., Tan L., Clocom: Mining existing source code for automatic comment generation, 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER), pp. 380-389, (2015); Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., Summarizing source code with transferred api knowledge, Proceedings of the 27th International Joint Conference on Artificial Intelligence, pp. 2269-2275, (2018); Huang Y., Huang S., Chen H., Chen X., Zheng Z., Luo X., Jia N., Hu X., Zhou X., Towards automatically generating block comments for code snippets, Information and Software Technology, (2020); Shahbazi R., Sharma R., Fard F.H., Api2com: On the improvement of automatically generated code comments using api documentations, (2021); Liu S., Chen Y., Xie X., Siow J.K., Liu Y., Retrieval-augmented generation for code summarization via hybrid gnn, International Conference on Learning Representations, (2020); Liang Z., Du J., Shao Y., Ji H., Gated graph neural attention networks for abstractive summarization, Neurocomputing, 431, pp. 128-136, (2021); Mohsen F., Wang J., Al-Sabahi K., A hierarchical self-attentive neural extractive summarizer via reinforcement learning (hsasrl), Applied Intelligence, pp. 1-14, (2020); Li H., Zhu J., Zhang J., Zong C., He X., Keywords-guided abstractive sentence summarization, Proceedings of the AAAI Conference on Artificial Intelligence, 34, 5, pp. 8196-8203, (2020); Li Z., Peng Z., Tang S., Zhang C., Ma H., Text summarization method based on double attention pointer network, IEEE Access, 8, pp. 11279-11288, (2020); Huang Y.J., Kurohashi S., Extractive summarization considering discourse and coreference relations based on heterogeneous graph, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pp. 3046-3052, (2021); Wang D., Liu P., Zheng Y., Qiu X., Huang X.-J., Heterogeneous graph neural networks for extractive document summarization, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 6209-6219, (2020); Lin C., Ouyang Z., Zhuang J., Chen J., Li H., Wu R., Improving code summarization with block-wise abstract syntax tree splitting, 2021 IEEE/ACM 29th International Conference on Program Comprehension, pp. 184-195, (2021); Papineni K., Roukos S., Ward T., Zhu W.-J., Bleu: A method for automatic evaluation of machine translation, Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Banerjee S., Lavie A., Meteor: An automatic metric for mt evaluation with improved correlation with human judgments, Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization, pp. 65-72, (2005); Lin C.-Y., Rouge: A package for automatic evaluation of summaries, Text summarization branches out, pp. 74-81, (2004); Wei B., Li G., Xia X., Fu Z., Jin Z., Code generation as a dual task of code summarization, Advances in Neural Information Processing Systems, pp. 6563-6573, (2019); Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2014); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Shaw P., Uszkoreit J., Vaswani A., Self-attention with relative position representations, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 464-468, (2018); See A., Liu P.J., Manning C.D., Get to the point: Summarization with pointer-generator networks, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pp. 1073-1083, (2017); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Codebert: A pre-trained model for programming and natural languages, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, pp. 1536-1547, (2020); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, International Conference on Learning Representations, (2018)",IEEE Computer Society,"29th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",15 March 2022 through 18 March 2022,"Virtual, Online",181173,English,Conference paper,Final,,Scopus,2-s2.0-85135841227,162
Zhang F.; Chen B.; Li R.; Peng X.,"Zhang, Fengyi (57205029279); Chen, Bihuan (35224542900); Li, Rongfan (59099724400); Peng, Xin (53865467700)",57205029279; 35224542900; 59099724400; 53865467700,A hybrid code representation learning approach for predicting method names,2021,Journal of Systems and Software,180,,111011,,,,6,10.1016/j.jss.2021.111011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107616552&doi=10.1016%2fj.jss.2021.111011&partnerID=40&md5=e96fd839823d7d7ff6490f49b2347f9b,"Program semantic properties such as class names, method names, and variable names and types play an important role in software development and maintenance. Method names are of particular importance because they provide the cornerstone of abstraction for developers to communicate with each other for various purposes (e.g., code review and program comprehension). Existing method name prediction approaches often represent code as lexical tokens or syntactical AST (abstract syntax tree) paths, making them difficult to learn code semantics and hindering their effectiveness in predicting method names. Initial attempts have been made to represent code as execution traces to capture code semantics, but suffer scalability in collecting execution traces. In this paper, we propose a hybrid code representation learning approach, named METH2SEQ, to encode a method as a sequence of distributed vectors. METH2SEQ represents a method as (1) a bag of paths on the program dependence graph, (2) a sequence of typed intermediate representation statements and (3) a sentence of natural language comment, to scalably capture code semantics. The learned sequence of vectors of a method is fed to a decoder model to predict method names. Our evaluation with a dataset of 280.5K methods in 67 Java projects has demonstrated that METH2SEQ outperforms the two state-of-the-art code representation learning approaches in F1-score by 92.6% and 36.6%, while also outperforming two state-of-the-art method name prediction approaches in F1-score by 85.6% and 178.1%. © 2021 Elsevier Inc.","Abebe S.L., Arnaoudova V., Tonella P., Antoniol G., Gueheneuc Y., pp. 235-244, (2012); Allamanis M., Barr E.T., Bird C., Devanbu P., Marron M., Sutton C., Mining semantic loop idioms, IEEE Trans. Softw. Eng., 44, 7, pp. 651-668, (2018); Allamanis M., Barr E.T., Bird C., Sutton C., pp. 281-293, (2014); Allamanis M., Barr E.T., Bird C., Sutton C., pp. 38-49, (2015); Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Comput. Surv., 51, 4, (2018); Allamanis M., Brockschmidt M., Khademi M., (2018); Allamanis M., Peng H., Sutton C., pp. 2091-2100, (2016); Allamanis M., Sutton C., pp. 207-216, (2013); Allamanis M., Sutton C., pp. 472-483, (2014); Allamanis M., Tarlow D., Gordon A., Wei Y., pp. 2123-2132, (2015); Alon U., Brody S., Levy O., Yahav E., (2019); Alon U., Zilberstein M., Levy O., Yahav E., pp. 404-419, (2018); Alon U., Zilberstein M., Levy O., Yahav E., (2019); Arnaoudova V., Di Penta M., Antoniol G., Linguistic antipatterns: What they are and how developers perceive them, Empir. Softw. Eng., 21, 1, pp. 104-158, (2016); Arnaoudova V., pp. 187-196, (2013); Bavishi R., Pradel M., Sen K., Context2Name: A deep learning-based approach to infer natural variable names from usage contexts, (2018); Ben-Nun T., Jakobovits A.S., Hoefler T., pp. 3585-3597, (2018); Bengio Y., Courville A., Vincent P., Representation learning: A review and new perspectives, IEEE Trans. Pattern Anal. Mach. Intell., 35, 8, pp. 1798-1828, (2013); Bhatia S., Kohli P., Singh R., pp. 60-70, (2018); Bielik P., Raychev V., Vechev M., pp. 1-10, (2015); Bielik P., Raychev V., Vechev M.P., pp. 2933-2942, (2016); Binkley D., Davis M., Lawrie D., Maletic J.I., Morrell C., Sharif B., The impact of identifier style on effort and comprehension, Empir. Softw. Eng., 18, 2, pp. 219-276, (2013); Binkley D., Hearn M., Lawrie D., pp. 203-206, (2011); Brockschmidt M., Allamanis M., Gaunt A.L., Polozov O., (2018); Buch L., Andrzejak A., pp. 95-104, (2019); Bui N.D., Jiang L., Yu Y., pp. 758-761, (2018); Bui N.D.Q., Yu Y., Jiang L., (2021); Butler S., Wermelinger M., Yu Y., Sharp H., pp. 31-35, (2009); Butler S., Wermelinger M., Yu Y., Sharp H., pp. 156-165, (2010); Butler S., Wermelinger M., Yu Y., Sharp H., pp. 93-102, (2011); Cai H., Zheng V.W., Chang K.C.-C., A comprehensive survey of graph embedding: Problems, techniques, and applications, IEEE Trans. Knowl. Data Eng., 30, 9, pp. 1616-1637, (2018); Campbell J.C., Hindle A., Amaral J.N., pp. 252-261, (2014); Chen C., Su T., Meng G., Xing Z., Liu Y., pp. 665-676, (2018); Chen C., Xing Z., Liu Y., Ong K.L.X., Mining likely analogical apis across third-party libraries via large-scale unsupervised api semantics embedding, IEEE Trans. Softw. Eng., 47, 3, pp. 432-447, (2021); Cho K., van Merrienboer B., pp. 1724-1734, (2014); Cortes-Coy L.F., Linares-Vasquez M., Aponte J., Poshyvanyk D., pp. 275-284, (2014); Cvitkovic M., Singh B., Anandkumar A., pp. 1475-1485, (2019); DeFreez D., Thakur A.V., Rubio-Gonzalez C., pp. 423-433, (2018); Deissenboeck F., Pizka M., Concise and consistent naming, Softw. Qual. J., 14, 3, pp. 261-282, (2006); Desai A., Gulwani S., Hingorani V., Jain N., Karkare A., Marron M., Roy S., Et al., pp. 345-356, (2016); DQ B.N., Yu Y., Jiang L., pp. 422-433, (2019); Ernst M.D., pp. 1-14, (2017); Franks C., Tu Z., Devanbu P., Hellendoorn V., pp. 705-708, (2015); Fu W., Menzies T., pp. 49-60, (2017); Gu X., Zhang H., Kim S., pp. 933-944, (2018); Gu X., Zhang H., Zhang D., Kim S., Deep A.P., pp. 631-642, (2016); Gu X., Zhang H., Zhang D., Kim S., pp. 3675-3681, (2017); Guerrouj L., Bourque D., Rigby P.C., pp. 639-642, (2015); Guo J., Cheng J., Cleland-Huang J., pp. 3-14, (2017); Gupta R., Kanade A., Shevade S., pp. 930-937, (2019); Gupta R., Pal S., Kanade A., Shevade S., pp. 1345-1351, (2017); Gvero T., Kuncak V., pp. 416-432, (2015); Habib A., Pradel M., Neural bug finding: A study of opportunities and challenges, (2019); Hassan F., Mostafa S., Lam E.S., Wang X., pp. 38-47, (2017); Hellendoorn V.J., Bird C., Barr E.T., Allamanis M., pp. 152-162, (2018); Hellendoorn V.J., Devanbu P., Are deep neural networks the best choice for modeling source code?, pp. 763-773, (2017); Henkel J., Lahiri S.K., Liblit B., Reps T., pp. 163-174, (2018); Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P., pp. 837-847, (2012); Hoang T., Dam H.K., Kamei Y., Lo D., Ubayashi N., pp. 34-45, (2019); Host E.W., pp. 294-317, (2009); Hsiao C.-H., Cafarella M., Narayanasamy S., pp. 49-65, (2014); Hu X., Li G., Xia X., Lo D., Jin Z., pp. 200-210, (2018); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation with hybrid lexical and syntactical information, Empir. Softw. Eng., 25, 3, pp. 2179-2217, (2020); Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., pp. 2269-2275, (2018); Huo X., Li M., Zhou Z., pp. 1606-1612, (2016); Huo X., Thung F., Li M., Lo D., Shi S.-T., Deep transfer bug localization, IEEE Trans. Softw. Eng., (2019); Iyer S., Konstas I., Cheung A., Zettlemoyer L., pp. 2073-2083, (2016); Jiang S., Armaly A., McMillan C., pp. 135-146, (2017); Jiang L., Liu H., Jiang H., pp. 602-614, (2019); Karaivanov S., Raychev V., Vechev M., pp. 173-184, (2014); Kim S., Kim D., Automatic identifier inconsistency detection using code dictionary, Empir. Softw. Eng., 21, 2, pp. 565-604, (2016); Lam A.N., Nguyen A.T., Nguyen H.A., Nguyen T.N., pp. 476-481, (2015); Lam A.N., Nguyen A.T., Nguyen H.A., Nguyen T.N., pp. 218-229, (2017); Lawrie D., Feild H., Binkley D., pp. 139-148, (2006); Lawrie D., Morrell C., Feild H., Binkley D., pp. 3-12, (2006); Le T.-D.B., Lo D., pp. 106-117, (2018); Le Q., Mikolov T., pp. 1188-1196, (2014); LeClair A., Jiang S., McMillan C., pp. 795-806, (2019); Lee S., Wu R., Cheung S.-C., Kang S., Automatic detection and update suggestion for outdated api names in documentation, IEEE Trans. Softw. Eng., 47, 4, pp. 653-675, (2021); Li L., Feng H., Zhuang W., Meng N., Ryder B., pp. 249-260, (2017); Li J., He P., Zhu J., Lyu M.R., pp. 318-328, (2017); Li X., Jiang H., Kamei Y., Chen X., Bridging semantic gaps between natural languages and APIs with word embedding, IEEE Trans. Softw. Eng., 46, 10, pp. 1081-1097, (2020); Li X., Li W., Zhang Y., Zhang L., pp. 169-180, (2019); Li J., Wang Y., Lyu M.R., King I., pp. 4159-4165, (2018); Li Y., Wang S., Nguyen T.N., Van Nguyen S., Improving bug detection via context-based code representation learning and attention-based neural networks, Proc. ACM Program. Lang., 3, OOPSLA, pp. 1621-162:30, (2019); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., SySeVR: A framework for using deep learning to detect software vulnerabilities, IEEE Trans. Dependable Secure Comput., (2021); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., (2018); Liblit B., Begel A., Sweetser E., (2006); Liu K., Kim D., Bissyande T.F., Kim T., Kim K., Koyuncu A., Kim S., Traon Y.L., pp. 1-12, (2019); Liu Z., Xia X., Hassan A.E., Lo D., Xing Z., Wang X., Neural-machine-translation-based commit message generation: how far are we?, pp. 373-384, (2018); Loyola P., Marrese-Taylor E., Matsuo Y., pp. 287-292, (2017); Luong T., Pham H., Manning C.D., pp. 1412-1421, (2015); Maddison C., Tarlow D., pp. 649-657, (2014); Malik R.S., Patra J., Pradel M., pp. 304-315, (2019); Menzies T., Majumder S., Balaji N., Brey K., Fu W., pp. 554-563, (2018); Mesbah A., Rice A., Johnston E., Glorioso N., Aftandilian E., (2019); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, (2013); Mikolov T., Sutskever I., Chen K., Corrado G., Dean J., pp. 3111-3119, (2013); Mou L., Li G., Zhang L., Wang T., Jin Z., pp. 1287-1293, (2016); Movshovitz-Attias D., Cohen W.W., pp. 35-40, (2013); Murali V., Chaudhuri S., Jermaine C., pp. 151-162, (2017); Nguyen A.T., Nguyen T.N., pp. 858-868, (2015); Nguyen A.T., Nguyen T.T., Nguyen T.N., pp. 651-654, (2013); Nguyen T.D., Nguyen A.T., Nguyen T.N., Mapping A.P., pp. 756-758, (2016); Nguyen T.T., Nguyen A.T., Nguyen H.A., Nguyen T.N., pp. 532-542, (2013); Nguyen A.T., Nguyen T.T., Nguyen H.A., Tamrawi A., Nguyen H.V., Al-Kofahi J., Nguyen T.N., pp. 69-79, (2012); Nguyen T.T., Nguyen H.A., Pham N.H., Al-Kofahi J.M., Nguyen T.N., pp. 383-392, (2009); Nguyen T.D., Nguyen A.T., Phan H.D., Nguyen T.N., Exploring A.P., pp. 438-449, (2017); Nguyen A.T., Nguyen T.D., Phan H.D., Nguyen T.N., pp. 323-334, (2018); Nguyen T.T., Pham H.V., Vu P.M., Nguyen T.T., Learning A.P., pp. 416-427, (2016); Nguyen A., Rigby P., Nguyen T., Palani D., Karanfil M., Nguyen T., pp. 194-205, (2018); Nguyen T., Tran N., Phan H., Nguyen T., Truong L., Nguyen A.T., Nguyen H.A., Nguyen T.N., pp. 551-562, (2018); Oda Y., Fudaba H., Neubig G., Hata H., Sakti S., Toda T., Nakamura S., pp. 574-584, (2015); Peng H., Mou L., Li G., Liu Y., Zhang L., Jin Z., pp. 547-553, (2015); Pennington J., Socher R., Manning C., pp. 1532-1543, (2014); Perozzi B., Al-Rfou R., Skiena S., pp. 701-710, (2014); Phan H., Nguyen H., Tran N., Truong L., Nguyen A., Nguyen T., pp. 632-642, (2018); Pradel M., Sen K., DeepBugs: A learning approach to name-based bug detection, Proc. ACM Program. Lang., 2, OOPSLA, pp. 1471-147:25, (2018); Pu Y., Narasimhan K., Solar-Lezama A., Barzilay R., pp. 39-40, (2016); Quirk C., Mooney R., Galley M., pp. 878-888, (2015); Rabinovich M., Stern M., Klein D., pp. 1139-1149, (2017); Raychev V., Bielik P., Vechev M., Krause A., pp. 761-774, (2016); Raychev V., Vechev M., Krause A., pp. 111-124, (2015); Raychev V., Vechev M., Yahav E., pp. 419-428, (2014); Seidel E.L., Sibghat H., Chaudhuri K., Weimer W., Jhala R., Learning to blame: Localizing novice type errors with data-driven diagnosis, Proc. ACM Program. Lang., 1, OOPSLA, pp. 601-60:27, (2017); Sui Y., Cheng X., Zhang G., Wang H., Flow2vec: Value-flow-based precise code embedding, Proc. ACM Program. Lang., 4, OOPSLA, (2020); Sun Z., Zhu Q., Mou L., Xiong Y., Li G., Zhang L., pp. 7055-7062, (2019); Sun Z., Zhu Q., Xiong Y., Sun Y., Mou L., Zhang L., pp. 8984-8991, (2020); Sutskever I., Vinyals O., Le Q.V., pp. 3104-3112, (2014); Takang A.A., Grubb P.A., Macredie R.D., The effects of comments and identifier names on program comprehensibility: an experimental investigation, J. Program. Lang., 4, 3, pp. 143-167, (1996); Tran H., Tran N., Nguyen S., Nguyen H., Nguyen T.N., pp. 1165-1175, (2019); Tu Z., Su Z., Devanbu P., pp. 269-280, (2014); Tufano M., Pantiuchina J., Watson C., Bavota G., Poshyvanyk D., pp. 25-36, (2019); Tufano M., Watson C., Bavota G., pp. 832-837, (2018); Tufano M., Watson C., Bavota G., pp. 542-553, (2018); Vallee-Rai R., Co P., Gagnon E., Hendren L., Lam P., Sundaresan V., (1999); Vallee-Rai R., Hendren L.J., Jimple: Simplifying Java bytecode for analyses and transformations: Technical Report, (1998); Van Nguyen T., Nguyen A.T., Nguyen T.N., Characterizing A.P., pp. 749-751, (2016); Vasilescu B., Casalnuovo C., Devanbu P., pp. 683-693, (2017); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P., pp. 13-25, (2019); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., pp. 397-407, (2018); Wang K., Learning scalable and precise representation of program semantics, (2019); Wang S., Liu T., Tan L., pp. 297-308, (2016); Wang K., Singh R., Su Z., (2018); Wang K., Su Z., Learning blended, precise semantic program embeddings, (2019); White M., Tufano M., Vendome C., Poshyvanyk D., pp. 87-98, (2016); White M., Vendome C., Linares-Vasquez M., Poshyvanyk D., pp. 334-345, (2015); Xiao Y., Keung J., Bennin K.E., Mi Q., Improving bug localization with word embedding and enhanced convolutional neural networks, Inf. Softw. Technol., 105, pp. 17-29, (2019); Xie R., Chen L., Ye W., Li Z., Hu T., Du D., Zhang S., pp. 434-444, (2019); Yahav E., pp. 3-8, (2015); Yang X., Lo D., Xia X., Zhang Y., Sun J., pp. 17-26, (2015); Ye X., Shen H., Ma X., Bunescu R., Liu C., pp. 404-415, (2016); Yefet N., Alon U., Yahav E., Adversarial examples for models of code, Proc. ACM Program. Lang., 4, OOPSLA, (2020); Yin P., Neubig G., pp. 440-450, (2017); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., pp. 783-794, (2019); Zhao G., Huang J., pp. 141-151, (2018); Zhou Y., Liu S., Siow J., Du X., Liu Y., pp. 10197-10207, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85107616552,163
Ge F.; Kuang L.,"Ge, Fan (57222084148); Kuang, Li (36519008400)",57222084148; 36519008400,Keywords Guided Method Name Generation,2021,IEEE International Conference on Program Comprehension,2021-May,,9463019,196,206,10,7,10.1109/ICPC52881.2021.00027,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113196338&doi=10.1109%2fICPC52881.2021.00027&partnerID=40&md5=3fd814c4f9f0acd066e3e0edeede365e,"High quality method names are descriptive and readable, which are helpful for code development and maintenance. The majority of recent research suggest method names based on the text summarization approach. They take the token sequence and abstract syntax tree of the source code as input, and generate method names through a powerful neural network based model. However, the tokens composing the method name are closely related to the entity name within its method implementation. Actually, high proportions of the tokens in method name can be found in its corresponding method implementation, which makes it possible for incorporating these common shared token information to improve the performance of method naming task. Inspired by this key observation, we propose a two-stage keywords guided method name generation approach to suggest method names. Specifically, we decompose the method naming task into two subtasks, including keywords extraction task and method name generation task. For the keywords extraction task, we apply a graph neural network based model to extract the keywords from source code. For the method name generation task, we utilize the extracted keywords to guide the method name generation model. We apply a dual selective gate in encoder to control the information flow, and a dual attention mechanism in decoder to combine the semantics of input code sequence and keywords. Experiment results on an open source dataset demonstrate that keywords guidance can facilitate method naming task, which enables our model to outperform the competitive state-of-The-Art models by margins of 1.5%-3.5% in ROUGE metrics. Especially when programs share one common token with method names, our approach improves the absolute ROUGE-1 score by 7.8%.  © 2021 IEEE.","Lawrie D., Et al., What?s in a name? a study of identifiers, Proceedings of the 14th Ieee International Conference on Program Comprehension, Ieee, pp. 3-12, (2006); Takang A.A., Grubb P.A., MacRedie R.D., The effects of comments and identifier names on program comprehensibility: An experimental investigation, J. Prog. Lang, 4, 3, pp. 143-167, (1996); Kim S., Kim D., Automatic identifier inconsistency detection using code dictionary, Empirical Software Engineering, 21, 2, pp. 565-604, (2016); Murphy-Hill E.R., Parnin C., Black A.P, How we refactor, and how we know it, Proceedings of the 31st International Conference on Software Engineering, pp. 287-297, (2009); Host E.W., Ostvold B.M., Debugging method names, European Conference on Object-Oriented Programming, pp. 294-317, (2009); Jiang L., Liu H., Jiang H., Machine learning based recommendation of method names: How far are we, Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering, Ieee, pp. 602-614, (2019); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, Proceedings of the 39th Acm Sigplan Conference on Programming Language Design and Implementation, Acm, pp. 404-419, (2018); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proceedings of the 46th Acm SIGPLAN-SIGACT Symposium on Principles of Programming Languages, 3, pp. 401-4029; Alon U., Brody S., Levy O., Yahav E., code2seq: Generating Sequences from Structured Representations of Code, (2018); Bahdanau D., Cho K., Bengio Y., Neural Machine Translation by Jointly Learning to Align and Translate, (2014); Nguyen S., Phan H.D., Le T., Nguyen T.N., Suggesting natural method names to check name consistencies, Proceedings of the ACM/ Ieee 42nd International Conference on Software Engineering, pp. 1372-1384, (2020); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, Proceedings of the 33nd International Conference on Machine Learning, pp. 2091-2100, (2016); Xu S., Zhang S., Wang W., Cao X., Guo C., Xu J., Method name suggestion with hierarchical attention networks, Proceedings of the 2019 Acm Sigplan Workshop on Partial Evaluation and Program Manipulation, Acm, pp. 10-21, (2019); Fernandes P., Allamanis M., Brockschmidt M., Structured Neural Summarization, (2018); Allamanis M., Sutton C., 2013. ""mining source code repositories at massive scale using language modeling, Proceedings of the 10th Ieee Working Conference on Mining Software Repositories Ieee Cs, pp. 207-216, (2013); See A., Liu P.J., Manning C.D., Get to the point: Summarization with pointer-generator networks, Proceedings of the Annual Meeting of the Association for Computational Linguistics, (2017); Liu K., Kim D., Et al., Learning to spot and refactor inconsistent method names, Proceedings of the 41th International Conference on Software Engineering Acm, pp. 1-12, (2019); Allamanis M., Barr E.T., Bird C., Sutton C., Suggesting accurate method and class names, Proceedings of the 10th Joint Meeting on Foundations of Software Engineering, pp. 38-49, (2015); Vinyals O., Fortunato M., Jaitly N., Pointer networks, Advances in Neural Information Processing Systems, pp. 2692-2700, (2015); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics Volume 1: Long Papers, 1, pp. 2073-2083, (2016); Ahmad W.U., Chakraborty S., Ray B., A Transformer-based Approach for Source Code Summarization, (2020); Vaswani A., Shazeer N., Et al., Attention is all you need, Advances in Neural Information Processing Systems, pp. 5998-6008, (2017); Wei B., Li G., Xia X., Fu Z., Jin Z., Code generation as a dual task of code summarization, Advances in Neural Information Processing Systems, pp. 6563-6573, (2019); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proceedings of the 26th Conference on Program Comprehension, pp. 200-210, (2018); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/ Ieee International Conference on Automated Software Engineering, Acm, pp. 397-407, (2018); LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, Proceedings of the 41st IEEE/ACM International Conference on Software Engineering, Ieee, pp. 795-806, (2019); LeClair A., Haque S., Wu L., McMillan C., Improved Code Summarization Via a Graph Neural Network[J], (2020); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, (2015); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning Phrase Representations Using Rnn Encoder-decoder for Statistical Machine Translation, (2014); Kingma D., Ba J., Adam: A Method for Stochastic Optimization, (2014); Li H., Zhu J., Zhang J., Zong C., He X., Keywords-guided abstractive sentence summarization, Aaai, 34, 5, pp. 8196-8203; Lin C., ROUGE: A package for automatic evaluation of summaries, Text Summarization Branches out, (2004); Rada M., Tarau P., Textrank: Bringing order into text, Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pp. 404-411, (2004)",,"29th IEEE/ACM International Conference on Program Comprehension, ICPC 2021",20 May 2021 through 21 May 2021,"Virtual, Online",171042,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85113196338,164
Liu S.; Chen Y.; Xie X.; Siow J.; Liu Y.,"Liu, Shangqing (57218717656); Chen, Yu (57196265741); Xie, Xiaofei (57224943843); Siow, Jingkai (57216460449); Liu, Yang (56911879800)",57218717656; 57196265741; 57224943843; 57216460449; 56911879800,RETRIEVAL-AUGMENTED GENERATION FOR CODE SUMMARIZATION VIA HYBRID GNN,2021,ICLR 2021 - 9th International Conference on Learning Representations,,,,,,,52,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121205001&partnerID=40&md5=a4d297a0cd465773b6670095c2fff13e,"Source code summarization aims to generate natural language summaries from structured code snippets for better understanding code functionalities. However, automatic code summarization is challenging due to the complexity of the source code and the language gap between the source code and natural language summaries. Most previous approaches either rely on retrieval-based (which can take advantage of similar examples seen from the retrieval database, but have low generalization performance) or generation-based methods (which have better generalization performance, but cannot take advantage of similar examples). This paper proposes a novel retrieval-augmented mechanism to combine the benefits of both worlds. Furthermore, to mitigate the limitation of Graph Neural Networks (GNNs) on capturing global graph structure information of source code, we propose a novel attention-based dynamic graph to complement the static graph representation of the source code, and design a hybrid message passing GNN for capturing both the local and global structural information. To evaluate the proposed approach, we release a new challenging benchmark, crawled from diversified large-scale open-source C projects (total 95k+ unique functions in the dataset). Our method achieves the state-of-the-art performance, improving existing methods by 1.42, 2.44 and 1.29 in terms of BLEU-4, ROUGE-L and METEOR. © 2021 ICLR 2021 - 9th International Conference on Learning Representations. All rights reserved.","Ahmad Wasi Uddin, Chakraborty Saikat, Ray Baishakhi, Chang Kai-Wei, A transformer-based approach for source code summarization, (2020); Allamanis Miltiadis, The adverse effects of code duplication in machine learning models of code, Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software, pp. 143-153, (2019); Allamanis Miltiadis, Brockschmidt Marc, Khademi Mahmoud, Learning to represent programs with graphs, (2017); Allamanis Miltiadis, Barr Earl T, Devanbu Premkumar, Sutton Charles, A survey of machine learning for big code and naturalness, ACM Computing Surveys (CSUR), 51, 4, pp. 1-37, (2018); Alon Uri, Brody Shaked, Levy Omer, Yahav Eran, code2seq: Generating sequences from structured representations of code, (2018); Bahdanau Dzmitry, Cho Kyunghyun, Bengio Yoshua, Neural machine translation by jointly learning to align and translate, (2014); Banerjee Satanjeev, Lavie Alon, Meteor: An automatic metric for mt evaluation with improved correlation with human judgments, Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization, pp. 65-72, (2005); Valerio Miceli Barone Antonio, Sennrich Rico, A parallel corpus of python functions and documentation strings for automated code documentation and code generation, (2017); Beck Daniel, Haffari Gholamreza, Cohn Trevor, Graph-to-sequence learning using gated graph neural networks, (2018); Bellman Richard, Dynamic programming, Science, 153, 3731, pp. 34-37, (1966); Bengio Samy, Vinyals Oriol, Jaitly Navdeep, Shazeer Noam, Scheduled sampling for sequence prediction with recurrent neural networks, Advances in Neural Information Processing Systems, pp. 1171-1179, (2015); Chen Deli, Lin Yankai, Li Wei, Li Peng, Zhou Jie, Sun Xu, Measuring and relieving the oversmoothing problem for graph neural networks from the topological view, AAAI, pp. 3438-3445, (2020); Chen Yu, Wu Lingfei, Zaki Mohammed, Iterative deep graph learning for graph neural networks: Better and robust node embeddings, Advances in Neural Information Processing Systems, 33, (2020); Chen Yu, Wu Lingfei, Zaki Mohammed J., Graphflow: Exploiting conversation flow with graph neural networks for conversational machine comprehension, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, pp. 1230-1236, (2020); Chen Yu, Wu Lingfei, Zaki Mohammed J., Reinforcement learning based graph-to-sequence model for natural question generation, Proceedings of the 8th International Conference on Learning Representations, (2020); Chen Yu, Wu Lingfei, Zaki Mohammed J, Toward subgraph guided knowledge graph question generation with graph neural networks, (2020); Du Xiaoning, Xie Xiaofei, Li Yi, Ma Lei, Liu Yang, Zhao Jianjun, Deepstellar: Model-based quantitative analysis of stateful deep learning systems, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 477-487, (2019); Eddy Brian P, Robinson Jeffrey A, Kraft Nicholas A, Carver Jeffrey C, Evaluating source code summarization techniques: Replication and expansion, 2013 21st International Conference on Program Comprehension (ICPC), pp. 13-22, (2013); Fernandes Patrick, Allamanis Miltiadis, Brockschmidt Marc, Structured neural summarization, (2018); Haiduc Sonia, Aponte Jairo, Moreno Laura, Marcus Andrian, On the use of automated text summarization techniques for summarizing source code, 2010 17th Working Conference on Reverse Engineering, pp. 35-44, (2010); Hamilton Will, Ying Zhitao, Leskovec Jure, Inductive representation learning on large graphs, Advances in neural information processing systems, pp. 1024-1034, (2017); He Kaiming, Zhang Xiangyu, Ren Shaoqing, Sun Jian, Deep residual learning for image recognition, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, (2016); Hochreiter Sepp, Schmidhuber Jurgen, Long short-term memory, Neural computation, 9, 8, pp. 1735-1780, (1997); Hu Xing, Li Ge, Xia Xin, Lo David, Jin Zhi, Deep code comment generation, Proceedings of the 26th Conference on Program Comprehension, pp. 200-210, (2018); Hu Xing, Li Ge, Xia Xin, Lo David, Lu Shuai, Jin Zhi, Summarizing source code with transferred api knowledge, (2018); Iyer Srinivasan, Konstas Ioannis, Cheung Alvin, Zettlemoyer Luke, Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2073-2083, (2016); Jiang Siyuan, Armaly Ameer, McMillan Collin, Automatically generating commit messages from diffs using neural machine translation, 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 135-146, (2017); Kamiya Toshihiro, Kusumoto Shinji, Inoue Katsuro, Ccfinder: a multilinguistic token-based code clone detection system for large scale source code, IEEE Transactions on Software Engineering, 28, 7, pp. 654-670, (2002); Kipf Thomas N, Welling Max, Semi-supervised classification with graph convolutional networks, (2016); LeClair Alexander, Haque Sakib, Wu Linfgei, McMillan Collin, Improved code summarization via a graph neural network, (2020); Li Guohao, Muller Matthias, Thabet Ali K., Ghanem Bernard, Deepgcns: Can gcns go as deep as cnns?, 2019 IEEE/CVF International Conference on Computer Vision, ICCV 2019, pp. 9266-9275, (2019); Li Yujia, Tarlow Daniel, Brockschmidt Marc, Zemel Richard, Gated graph sequence neural networks, (2015); Li Zhenmin, Lu Shan, Myagmar Suvda, Zhou Yuanyuan, Cp-miner: Finding copy-paste and related bugs in large-scale software code, IEEE Transactions on software Engineering, 32, 3, pp. 176-192, (2006); Lin Chin-Yew, ROUGE: A package for automatic evaluation of summaries, Text Summarization Branches Out, pp. 74-81, (2004); Liu Shangqing, Gao Cuiyun, Chen Sen, Yiu Nie Lun, Liu Yang, Atom: Commit message generation based on abstract syntax tree and hybrid ranking, IEEE Transactions on Software Engineering, (2020); Liu Zhongxin, Xia Xin, Hassan Ahmed E, Lo David, Xing Zhenchang, Wang Xinyu, Neural-machine-translation-based commit message generation: how far are we?, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 373-384, (2018); Luong Minh-Thang, Pham Hieu, Manning Christopher D, Effective approaches to attention-based neural machine translation, (2015); Ma Lei, Juefei-Xu Felix, Zhang Fuyuan, Sun Jiyuan, Xue Minhui, Li Bo, Chen Chunyang, Su Ting, Li Li, Liu Yang, Et al., Deepgauge: Multi-granularity testing criteria for deep learning systems, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 120-131, (2018); Norcliffe-Brown Will, Vafeias Stathis, Parisot Sarah, Learning conditioned graph structures for interpretable visual question answering, Advances in Neural Information Processing Systems, pp. 8344-8353, (2018); Papineni Kishore, Roukos Salim, Ward Todd, Zhu Wei-Jing, Bleu: a method for automatic evaluation of machine translation, Proceedings of the 40th annual meeting on association for computational linguistics, pp. 311-318, (2002); Siow Jing Kai, Gao Cuiyun, Fan Lingling, Chen Sen, Liu Yang, Core: Automating review recommendation for code changes, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 284-295, (2020); Vaswani Ashish, Shazeer Noam, Parmar Niki, Uszkoreit Jakob, Jones Llion, Gomez Aidan N, Kaiser Lukasz, Polosukhin Illia, Attention is all you need, Advances in neural information processing systems, pp. 5998-6008, (2017); Velickovic Petar, Cucurull Guillem, Casanova A., Romero A., Lio P., Bengio Yoshua, Graph attention networks, (2018); Wan Yao, Zhao Zhou, Yang Min, Xu Guandong, Ying Haochao, Wu Jian, Yu Philip S, Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Wei Bolin, Li Ge, Xia Xin, Fu Zhiyi, Jin Zhi, Code generation as a dual task of code summarization, Advances in Neural Information Processing Systems, pp. 6563-6573, (2019); Wong Edmund, Yang Jinqiu, Tan Lin, Autocomment: Mining question and answer sites for automatic comment generation, 2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 562-567, (2013); Wong Edmund, Liu Taiyue, Tan Lin, Clocom: Mining existing source code for automatic comment generation, 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER), pp. 380-389, (2015); Xie Xiaofei, Ma Lei, Juefei-Xu Felix, Xue Minhui, Chen Hongxu, Liu Yang, Zhao Jianjun, Li Bo, Yin Jianxiong, See Simon, Deephunter: a coverage-guided fuzz testing framework for deep neural networks, Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 146-157, (2019); Xie Xiaofei, Ma Lei, Wang Haijun, Li Yuekang, Liu Yang, Li Xiaohong, Diffchaser: Detecting disagreements for deep neural networks, IJCAI, pp. 5772-5778, (2019); Xu Kun, Wu Lingfei, Wang Zhiguo, Sheinin Vadim, Graph2seq: Graph to sequence learning with attention-based neural networks, (2018); Xu Kun, Wu Lingfei, Wang Zhiguo, Yu Mo, Chen Liwei, Sheinin Vadim, Sql-to-text generation with graph-to-sequence model, (2018); Yamaguchi Fabian, Golde Nico, Arp Daniel, Rieck Konrad, Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, pp. 590-604, (2014); Zhang Jian, Wang Xu, Zhang Hongyu, Sun Hailong, Liu Xudong, Retrieval-based neural source code summarization, Proceedings of the 42nd International Conference on Software Engineering, (2020); Zhao Lingxiao, Akoglu Leman, Pairnorm: Tackling oversmoothing in gnns, (2019); Zhou Yaqin, Liu Shangqing, Siow Jingkai, Du Xiaoning, Liu Yang, Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, pp. 10197-10207, (2019); Zhu Jie, Li Junhui, Zhu Muhua, Qian Longhua, Zhang Min, Zhou Guodong, Modeling graph structure in transformer for better amr-to-text generation, (2019)",Amazon; DeepMind; et al.; Facebook AI; Microsoft; OpenAI,"9th International Conference on Learning Representations, ICLR 2021",3 May 2021 through 7 May 2021,"Virtual, Online",186703,English,Conference paper,Final,,Scopus,2-s2.0-85121205001,165
Zhang X.; Yang S.; Duan L.; Lang Z.; Shi Z.; Sun L.,"Zhang, Xiaoling (57217097025); Yang, Shouguo (57210284288); Duan, Luqian (57446140200); Lang, Zhe (57238903500); Shi, Zhiqiang (55726763700); Sun, Limin (35308519200)",57217097025; 57210284288; 57446140200; 57238903500; 55726763700; 35308519200,Transformer-XL with Graph Neural Network for Source Code Summarization,2021,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",,,,3436,3441,5,3,10.1109/SMC52423.2021.9658619,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124318560&doi=10.1109%2fSMC52423.2021.9658619&partnerID=40&md5=03ee09ce85de4e698cecdde03bb3d2ba,"Source code summarization is the task of generating a readable natural language to describe the functionality of source code. Code summarization is rapidly expanding, especially as the research takes great advantage of advances in neural networks and artificial intelligence technologies. Some mainstream methods input the structural information (abstract syntax tree (AST)) of the source code into the language model to generate relatively satisfactory comments. However, existing methods can not capture code's long dependencies from AST for effective code summarization. In this paper, we provide a novel way to generate code summaries by combining a graph-based neural network and a Transformer-XL network. We utilize the graph-based neural network to better capture the structure information of AST, and the Transformer-XL network to learn important tokens in the AST and alleviate the problem of long dependency. We evaluate our technique on the standard Java dataset. The experimental results show that the effectiveness of our model is remarkable. It pushes the precision score to 60.73% (5.21% absolute improvement) and the F1 score to 51.06%.  © 2021 IEEE.","Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Acl, pp. 2073-2083, (2016); Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., Summarizing source code with transferred api knowledge, IJCAI-18, pp. 2269-2275, (2018); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, Icml, 48, pp. 2091-2100, (2016); Moore J., Gelman B., Slater D., A convolutional neural network for language-Agnostic source code summarization, Proceedings of the 14th International Conference on Evaluation of Novel Approaches to Software Engineering, 1, pp. 15-26, (2019); Ahmad W., Chakraborty S., Ray B., Chang K.-W., A transformerbased approach for source code summarization, ACL., pp. 4998-5007, (2020); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Icpc, pp. 200-210, (2018); LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, Icse, pp. 795-806, (2019); Alon U., Levy O., Yahav E., Code2seq: Generating sequences from structured representations of code, Iclr, (2019); Khandelwal U., He H., Qi P., Jurafsky D., Sharp nearby, fuzzy far away: How neural language models use context, Acl, pp. 284-294, (2018); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez L.U., Kaiser I., Polosukhin A.N., Attention is all you need, Nips, 30, (2017); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, Iclr, (2018); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Icpc, pp. 184-195, (2020); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proc. Acm Program. Lang., 3, (2019); Dai Z., Yang Z., Yang Y., Carbonell J., Le Q., Salakhutdinov R., Transformer-xl: Attentive language models beyond a fixed-length context, Acl, pp. 2978-2988, (2019); Haiduc S., Aponte J., Moreno L., Marcus A., On the use of automated text summarization techniques for summarizing source code, 2010 17th Working Conference on Reverse Engineering, pp. 35-44, (2010); McBurney P.W., McMillan C., Automatic source code summarization of context for Java methods, Ieee Transactions on Software Engineering, 42, 2, pp. 103-119, (2016); Sridhara G., Hill E., Muppaneni D., Pollock L., Vijay-Shanker K., Towards automatically generating summary comments for Java methods, IEEE/ACM Ase, pp. 43-52, (2010); Rastkar S., Murphy G.C., Bradley A.W., Generating natural language summaries for crosscutting source code concerns, Icsm, pp. 103-112, (2011); Sridhara G., Pollock L., Vijay-Shanker K., Automatically detecting and describing high level actions within methods, Icse, pp. 101-110, (2011); Loyola P., Marrese-Taylor E., Matsuo Y., A neural architecture for generating natural language descriptions from source code changes, Acl, pp. 287-292, (2017); Lu Y., Zhao Z., Li G., Jin Z., Learning to generate comments for api-based code snippets, Software Engineering and Methodology for Emerging Domains, pp. 3-14, (2017); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Ase, pp. 397-407, (2018); Liang Y., Zhu K., Automatic Generation of Text Descriptive Comments for Code Blocks, (2018); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, International Conference on Learning Representations, (2019); Choi Y., Kim S., Lee J.-H., Source code summarization using attention-based keyword memory networks, 2020 Ieee International Conference on Big Data and Smart Computing (BigComp), pp. 564-570, (2020); Wang R., Zhang H., Lu G., Lyu L., Lyu C., Fret: Functional reinforced transformer with bert for code summarization, Ieee Access, 8, pp. 135591-135604, (2020); Xu K., Wu L., Wang Z., Feng Y., Witbrock M., Sheinin V., Graph2seq: Graph to Sequence Learning with Attention-based Neural Networks, (2018); LeClair A., McMillan C., Recommendations for datasets for source code summarization, NAACL-HLT, pp. 3931-3937, (2019); Haque S., LeClair A., Wu L., McMillan C., Improved automatic summarization of subroutines via attention to file context, Msr, pp. 300-310, (2020)",,"2021 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2021",17 October 2021 through 20 October 2021,Melbourne,176213,English,Conference paper,Final,,Scopus,2-s2.0-85124318560,166
Zeng J.; Zhang T.; Xu Z.,"Zeng, Jianwei (58062883200); Zhang, Tao (55547105895); Xu, Zhou (57212062746)",58062883200; 55547105895; 57212062746,DG-Trans: Automatic Code Summarization via Dynamic Graph Attention-based Transformer,2021,"IEEE International Conference on Software Quality, Reliability and Security, QRS",2021-December,,,786,795,9,1,10.1109/QRS54544.2021.00088,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146199326&doi=10.1109%2fQRS54544.2021.00088&partnerID=40&md5=1d7eda6868c42c29189049d9fd3a7224,"Automatic code summarization is an important topic in the software engineering field, which aims to automatically generate the description for the source code. Based on Graph Neural Networks (GNN), most existing methods apply them to Abstract Syntax Tree (AST) to achieve code summarization. However, these methods face two major challenges: 1) they can only capture limited structural information of the source code; 2) they did not effectively solve Out-Of-Vocabulary (OOV) problems by reducing vocabulary size. In order to resolve these problems, in this paper, we propose a novel code summarization model named Dynamic Graph attention-based Transformer (DG-Trans for short), which effectively captures abundant information of the code subword sequence and utilizes the fusion of dynamic graph attention mechanism and Transformer. Extensive experiments show that DG-Trans is able to outperform state-of-the-art models (such as Ast-Attendgru, Transformer, and CodeGNN) by averagely increasing 8.39% and 8.86% on BLEU scores and ROUGUE-L, respectively. © 2021 IEEE.","Ahmad Wasi Uddin, Chakraborty Saikat, Ray Baishakhi, Chang Kai-Wei, A transformer-based approach for source code summarization, ACL, (2020); Allamanis Miltiadis, Barr Earl T, Devanbu Premkumar, Sutton Charles, A survey of machine learning for big code and naturalness, ACM Computing Surveys (CSUR), 51, 4, pp. 1-37, (2018); Allamanis Miltiadis, Peng Hao, Sutton Charles, A convolutional attention network for extreme summarization of source code, International conference on machine learning, pp. 2091-2100, (2016); Bahdanau Dzmitry, Cho Kyunghyun, Bengio Yoshua, Neural machine translation by jointly learning to align and translate, (2014); Brody Shaked, Alon Uri, Yahav Eran, How attentive are graph attention networks, (2021); Cho Kyunghyun, Van Merrienboer Bart, Gulcehre Caglar, Bahdanau Dzmitry, Bougares Fethi, Schwenk Holger, Bengio Yoshua, Learning phrase representations using rnn encoder-decoder for statistical machine translation, (2014); Chopra Sumit, Auli Michael, Rush Alexander M, Abstractive sentence summarization with attentive recurrent neural networks, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 93-98, (2016); Cvitkovic Milan, Singh Badal, Anandkumar Animashree, Open vocabulary learning on source code with a graph-structured cache, International Conference on Machine Learning, pp. 1475-1485, (2019); Devlin Jacob, Chang Ming-Wei, Lee Kenton, Toutanova Kristina, Bert: Pre-training of deep bidirectional transformers for language understanding, (2018); Eddy Brian P, Robinson Jeffrey A, Kraft Nicholas A, Carver Jeffrey C, Evaluating source code summarization techniques: Replication and expansion, 2013 21st International Conference on Program Comprehension (ICPC), pp. 13-22, (2013); Feng Zhangyin, Guo Daya, Tang Duyu, Duan Nan, Feng Xiaocheng, Gong Ming, Shou Linjun, Qin Bing, Liu Ting, Jiang Daxin, Et al., Codebert: A pre-trained model for programming and natural languages, (2020); Gu Xiaodong, Zhang Hongyu, Kim Sunghun, Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE), pp. 933-944, (2018); Haiduc Sonia, Aponte Jairo, Marcus Andrian, Supporting program comprehension with source code summarization, 2010 acm/ieee 32nd international conference on software engineering, 2, pp. 223-226, (2010); Hellendoorn Vincent J, Devanbu Premkumar, Are deep neural networks the best choice for modeling source code, Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, pp. 763-773, (2017); Hochreiter Sepp, Schmidhuber Jurgen, Long short-term memory, Neural computation, 9, 8, pp. 1735-1780, (1997); Hu Xing, Li Ge, Xia Xin, Lo David, Jin Zhi, Deep code comment generation, 2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC), pp. 200-210, (2018); Iyer Srinivasan, Konstas Ioannis, Cheung Alvin, Zettlemoyer Luke, Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2073-2083, (2016); Jean Sebastien, Cho Kyunghyun, Memisevic Roland, Bengio Yoshua, On using very large target vocabulary for neural machine translation, (2014); Karampatsis Rafael-Michael, Babii Hlib, Robbes Romain, Sutton Charles, Janes Andrea, Big code!= big vocabulary: Open-vocabulary models for source code, 2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE), pp. 1073-1085, (2020); Kipf Thomas N, Welling Max, Semi-supervised classification with graph convolutional networks, (2016); Krizhevsky Alex, Sutskever Ilya, Hinton Geoffrey E, Imagenet classification with deep convolutional neural networks, Advances in neural information processing systems, 25, pp. 1097-1105, (2012); Le Triet HM, Chen Hao, Babar Muhammad Ali, Deep learning for source code modeling and generation: Models, applications, and challenges, ACM Computing Surveys (CSUR), 53, 3, pp. 1-38, (2020); LeClair Alexander, Haque Sakib, Wu Lingfei, McMillan Collin, Improved code summarization via a graph neural network, Proceedings of the 28th International Conference on Program Comprehension, pp. 184-195, (2020); LeClair Alexander, Jiang Siyuan, McMillan Collin, A neural model for generating natural language summaries of program subroutines, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 795-806, (2019); LeClair Alexander, McMillan Collin, Recommendations for datasets for source code summarization, (2019); LeCun Yann, Bengio Yoshua, Hinton Geoffrey, Deep learning, nature, 521, 7553, pp. 436-444, (2015); Li Yujia, Tarlow Daniel, Brockschmidt Marc, Zemel Richard, Gated graph sequence neural networks, (2015); Lin Chin-Yew, Rouge: A package for automatic evaluation of summaries, Text summarization branches out, pp. 74-81, (2004); Liu Shangqing, Chen Yu, Xie Xiaofei, Siow Jing Kai, Liu Yang, Retrieval-augmented generation for code summarization via hybrid gnn, International Conference on Learning Representations, (2020); Moreno Laura, Aponte Jairo, Sridhara Giriprasad, Marcus Andrian, Pollock Lori, Vijay-Shanker K, Automatic generation of natural language summaries for java classes, 2013 21st International Conference on Program Comprehension (ICPC), pp. 23-32, (2013); Mou Lili, Li Ge, Zhang Lu, Wang Tao, Jin Zhi, Convolutional neural networks over tree structures for programming language processing, Thirtieth AAAI Conference on Artificial Intelligence, (2016); Nallapati Ramesh, Zhou Bowen, Gulcehre Caglar, Xiang Bing, Et al., Abstractive text summarization using sequence-to-sequence rnns and beyond, (2016); Papineni Kishore, Roukos Salim, Ward Todd, Zhu Wei-Jing, Bleu: a method for automatic evaluation of machine translation, Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Rodeghero Paige, McMillan Collin, McBurney Paul W, Bosch Nigel, D'Mello Sidney, Improving automated source code summarization via an eye-tracking study of programmers, Proceedings of the 36th international conference on Software engineering, pp. 390-401, (2014); Rumelhart David E, Hinton Geoffrey E, Williams Ronald J, Learning representations by back-propagating errors, nature, 323, 6088, pp. 533-536, (1986); Scarselli Franco, Gori Marco, Chung Tsoi Ah, Hagenbuchner Markus, Monfardini Gabriele, The graph neural network model, IEEE transactions on neural networks, 20, 1, pp. 61-80, (2008); See Abigail, Liu Peter J, Manning Christopher D, Get to the point: Summarization with pointer-generator networks, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1073-1083, (2017); Sennrich Rico, Haddow Barry, Birch Alexandra, Neural machine translation of rare words with subword units, (2015); Shibata Yusuxke, Kida Takuya, Fukamachi Shuichi, Takeda Masayuki, Shinohara Ayumi, Shinohara Takeshi, Arikawa Setsuo, Byte pair encoding: A text compression scheme that accelerates pattern matching, (1999); Sridhara Giriprasad, Hill Emily, Muppaneni Divya, Pollock Lori, Vijay-Shanker K, Towards automatically generating summary comments for java methods, Proceedings of the IEEE/ACM international conference on Automated software engineering, pp. 43-52, (2010); Vaswani Ashish, Shazeer Noam, Parmar Niki, Uszkoreit Jakob, Jones Llion, Gomez Aidan N, Kaiser ukasz, Polosukhin Illia, Attention is all you need, Advances in neural information processing systems, pp. 5998-6008, (2017); Velickovic Petar, Cucurull Guillem, Casanova Arantxa, Romero Adriana, Lio Pietro, Bengio Yoshua, Graph attention networks, (2017); Wan Yao, Zhao Zhou, Yang Min, Xu Guandong, Ying Haochao, Wu Jian, Yu Philip S, Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Wei Bolin, Li Ge, Xia Xin, Fu Zhiyi, Jin Zhi, Code generation as a dual task of code summarization, (2019); Wu Zonghan, Pan Shirui, Chen Fengwen, Long Guodong, Zhang Chengqi, Yu Philip S, A comprehensive survey on graph neural networks, IEEE transactions on neural networks and learning systems, 32, 1, pp. 4-24, (2020); Zhang Jian, Wang Xu, Zhang Hongyu, Sun Hailong, Liu Xudong, Retrieval-based neural source code summarization, 2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE), pp. 1385-1397, (2020); Zhu Yuxiang, Pan Minxue, Automatic code summarization: A systematic literature review, (2019)",,"21st International Conference on Software Quality, Reliability and Security, QRS 2021",6 December 2021 through 10 December 2021,Hainan,177710,English,Conference paper,Final,,Scopus,2-s2.0-85146199326,167
Lu M.; Liu Y.; Li H.; Tan D.; He X.; Bi W.; Li W.,"Lu, Mingming (55276383700); Liu, Yan (57206693004); Li, Haifeng (57189334346); Tan, Dingwu (57205481945); He, Xiaoxian (8977798300); Bi, Wenjie (23388662200); Li, Wendbo (57206696351)",55276383700; 57206693004; 57189334346; 57205481945; 8977798300; 23388662200; 57206696351,Hyperbolic function embedding: Learning hierarchical representation for functions of source code in hyperbolic space,2019,Symmetry,11,2,254,,,,4,10.3390/sym11020254,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061872138&doi=10.3390%2fsym11020254&partnerID=40&md5=6c5c53d9c208b17eb6077ad1121a8f2b,"Recently, source code mining has received increasing attention due to the rapid increase of open-sourced code repositories and the tremendous values implied in this large dataset, which can help us understand the organization of functions or classes in different software and analyze the impact of these organized patterns on the software behaviors. Hence, learning an effective representation model for the functions of source code, from a modern view, is a crucial problem. Considering the inherent hierarchy of functions, we propose a novel hyperbolic function embedding (HFE) method, which can learn a distributed and hierarchical representation for each function via the Poincaré ball model. To achieve this, a function call graph (FCG) is first constructed to model the call relationship among functions. To verify the underlying geometry of FCG, the Ricci curvature model is used. Finally, an HFE model is built to learn the representations that can capture the latent hierarchy of functions in the hyperbolic space, instead of the Euclidean space, which are usually used in those state-of-the-art methods. Moreover, HFE is more compact in terms of lower dimensionality than the existing graph embedding methods. Thus, HFE is more effective in terms of computation and storage. To experimentally evaluate the performance of HFE, two application scenarios, namely, function classification and link prediction, have been applied. HFE achieves up to 7.6% performance improvement compared to the chosen state-of-the-art methods, namely, Node2vec and Struc2vec. © 2019 by the authors.","Allamanis M., Barr E.T., Devanbu P., Sutton C., A Survey ofMachine Learning for Big Code and Naturalness, ACM Comput. Surv, 51, pp. 1-37, (2018); Gupta R., Pal S., Kanade A., Shevade S., DeepFix: Fixing Common C Language Errors by Deep Learning, Proceedings of the AAAI, pp. 1345-1351, (2017); Hu X., Wei Y., Li G., Jin Z., CodeSum: Translate Program Language to Natural Language, (2017); Knuth D.E., Literate Programming, Comput. J, 27, pp. 97-111, (1984); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Adv. Neural Inf. Process. Syst, 26, pp. 3111-3119, (2013); Gu X., Zhang H., Zhang D., Kim S., Deep API Learning, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering 2016, (2016); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pp. 2073-2083, (2016); Piech C., Huang J., Nguyen A., Phulsuksombati M., Sahami M., Guibas L., Learning Program Embeddings to Propagate Feedback on Student Code, (2015); Nguyen T.D., Nguyen A.T., Phan H.D., Nguyen T.N., Exploring API Embedding for API Usages and Applications, Proceedings of the 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE), (2017); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional Neural Networks over Tree Structures for Programming Language Processing, Proceedings of the AAAI, (2014); Chamberlain B.P., Clough J., Deisenroth M.P., Neural Embeddings of Graphs in Hyperbolic Space, (2017); Krioukov D., Papadopoulos F., Kitsak M., Vahdat A., Boguna M., Hyperbolic Geometry of Complex Networks, Phys. Rev. E Stat. Nonlinear Soft Matter Phys, 82, (2010); Verbeek K., Suri S., Metric Embedding, Hyperbolic Space, and Social Networks, (2016); Nickel M., Kiela D., Poincaré Embeddings for Learning Hierarchical Representations, Proceedings of the Advances in Neural Information Processing Systems, (2017); Lohkamp J., Metrics of Negative Ricci Curvature, Ann. Math, 140, pp. 655-683, (1994); Ollivier Y., Ricci curvature of Markov chains on metric spaces, J. Funct. Anal, 256, pp. 810-864, (2009); Grover A., Leskovec J., Node2vec: Scalable Feature Learning for Networks, Proceedings of the ACMSigkdd International Conference on Knowledge Discovery & DataMining, (2016); Ribeiro L.F.R., Saverese P.H.P., Figueiredo D.R., Struc2vec: Learning Node Representations from Structural Identity, Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, (2017); Vilnis L.M., A.Word Representations via Gaussian Embedding; Allamanis M., Peng H., Sutton C., A Convolutional Attention Network for Extreme Summarization of Source Code, Proceedings of the International Conference on Machine Learning, (2016); Dam H.K., Tran T., Pham T.T.M., A deep language model for software code, (2016); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, (2017); Allamanis M., Chanthirasegaran P., Kohli P., Sutton C., Learning Continuous Semantic Representations of Symbolic Expressions, Proceedings of the 34th International Conference on Machine Learning, (2017); Li Y., Tarlow D., Brockschmidt M., Zemel R., GatedGraph SequenceNeuralNetworks; Jurgen J., Liu S., Ollivier's Ricci Curvature, Local Clustering and Curvature-Dimension Inequalities on Graphs, Discr. Comput. Geometry, 51, pp. 300-322, (2014); Villani C., Optimal Transport. Grundlehren Der MathematischenWissenschaften, The Analysis of Linear Partial Differential Operators, (2009); Ollivier Y., Villani C., A Curved Brunn-Minkowski Inequality on the Discrete Hypercube, Or: What Is the Ricci Curvature of the Discrete Hypercube?, SIAM J. Discr. Math, 26, pp. 983-996, (2012); Shi J., Zhang W., Wang Y., Shape Analysis with HyperbolicWasserstein Distance, Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), (2016); Santambrogio F., Optimal transport for applied mathematicians, Progress in Nonlinear Differential Equations & Their Applications, pp. 99-102, (2015); Gromov M., Hyperbolic groups, Essays in Group Theory, (1987); Zhang H., Reddi S.J., Sra S., Riemannian SVRG: Fast Stochastic Optimization on Riemannian Manifolds, Proceedings of the Advances in Neural Information Processing Systems, (2016); Bonnabel S., Stochastic Gradient Descent on Riemannian Manifolds, IEEE Trans. Autom. Control, 58, pp. 2217-2229, (2013); Jonckheere E., Lou M., Bonahon F., Baryshnikov Y., Euclidean versus Hyperbolic Congestion in Idealized versus Experimental Networks, Internet Math, 7, pp. 1-27, (2011); Wang C., Jonckheere E., Brun T., Differential geometric treewidth estimation in adiabatic quantum computation, Quant. Inf. Process, 15, pp. 3951-3966, (2016); Gulcehre C., Denil M., Malinowski M., Razavi A., Pascanu R., Hermann K.M., Battaglia P., Bapst V., Raposo D., Santoro A., Et al., Hyperbolic Attention Networks, (2010)",,,,,,English,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85061872138,168
Du C.; Li Y.; Wang Y.; Yu J.,"Du, Changsheng (58538681500); Li, Yong (57188935137); Wang, Yue (58855422800); Yu, Junjie (58759284800)",58538681500; 57188935137; 58855422800; 58759284800,Study on Automatic Code Summary Generation Method based on Graph Neural Network,2023,"Proceedings - 2023 10th International Conference on Dependable Systems and Their Applications, DSA 2023",,,,35,41,6,0,10.1109/DSA59317.2023.00015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179505390&doi=10.1109%2fDSA59317.2023.00015&partnerID=40&md5=0ec978da5b42e327c8a031c00cb980f3,"Automatic code summary generation techniques can help developers and other technical personnel to understand and comprehend the functions and structure of code more quickly. In existing methods of automatic code abstraction generation, there is a problem of poor utilization of code structure information, therefore, a model of automatic code abstraction generation based on graph neural network is proposed. Firstly, the abstract syntax tree is extracted from the code, and then the abstract syntax tree of the code is transformed into a graph representation using control flow statements in the data stream, which is trained by a graph convolutional neural network, and the obtained training results are fused with the original sequence representation to finally obtain a source code representation that incorporates the semantic information of the code context and structural information. Meanwhile, to improve the stability of the summary generation model, a deep learning model based on a multi-headed self-attentive mechanism is used to improve the existing sequence-to-sequence summary generation model. The accuracy and stability of the model-generated summaries are improved. Validation was performed on publicly available datasets, and experimental results show that the method achieves better results on BLEU-4, METEOR, and ROUGE-L metrics compared to other baseline models.  © 2023 IEEE.","Xia X., Bao L., Lo D., Et al., Measuring program comprehension: A large-scale field study with professionals[J], IEEE Transactions on Software Engineering, 44, 10, pp. 951-976, (2017); Sridhara G., Hill E., Muppaneni D., Et al., Towards automatically generating summary comments for Java methods[C], 25th IEEE/ACM International Conference on Automated Software Engineering, pp. 43-52, (2010); Iyer S., Konstas I., Cheung A., Et al., Summarizing source code using a neural attention model[C], 54th Annual Meeting of the Association for Computational Linguistics, pp. 2073-2083, (2016); Hochreiter S., Jurgen S., Long short-term memory[J], Neural computation, 9, 8, pp. 1735-1780, (1997); Hu X., Li G., Xia X., Et al., Deep code comment generation[C], 26th conference on program comprehension, pp. 200-210, (2018); Kang H.J., Bissyande T.F., Lo D., Assessing the Generalizability of Code2vec Token Embeddings[C], 2019 34th IEEE/ACM International Conference on Automated Software Engineering, pp. 1-12, (2019); LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines[C], IEEE/ACM 41st International Conference on Software Engineering, pp. 795-806, (2019); Ahmad W.U., Chakraborty S., Ray B., Et al., A Transformer-based Approach for Source Code Summarization[C], The 58th Annual Meeting of the Association for Computational Linguistics, pp. 4998-5007, (2021); Sulthana R., Jovith A., LSTM and RNN to Predict COVID Cases: Lethality's and Tests in GCC Nations and India, International Journal of Performability Engineering, 17, 3, (2021); Alagarsamy S., James V., RNN LSTM-based deep hybrid learning model for text classification using machine learning variant xgboost, International Journal of Performability Engineering, 18, 8, (2022); LeCun Y., Bottou L., Bengio Y., Et al., Gradient-Based Learning Applied to Document Recognition[J], Proceedings of the IEEE, 86, 11, pp. 2278-2324, (1998); Bruna J., Zaremba W., Szlam A., Et al., Spectral Networks and Locally Connected Networks on Graphs[J], (2013); Shuai M., Jianwei L., Zuo X., A Review of Graph Neural Networks, Journal of Computer Research and Development, 59, 1, pp. 47-80, (2022); Bo W., Xun L., Shusen Z., Et al., Frontier Progress and Applications of Graph Neural Networks, Chinese Journal of Computers, 45, 1, pp. 35-68, (2022); Wu Z., Pan S., Chen F., Et al., A comprehensive survey on graph neural networks[J], IEEE transactions on neural networks and learning systems, 32, 1, pp. 4-24, (2020); Mnih V., Heess N., Graves A., Recurrent Models of Visual Attention[J], Computer Vision and Image Understanding, 141, C, pp. 1-20, (2015); Bahdanau D., Cho K., Bengio Y., Neural Machine Translation by Jointly Learning to Align and Translate[J], (2014); Papineni K., Roukos S., Ward T., Et al., Bleu: A method for automatic evaluation of machine translation[C], 40th annual meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Brown P.F., Della Pietra V.J., Desouza P.V., Et al., Class-based n-gram models of natural language[J], Computational linguistics, 18, 4, pp. 467-480, (1992); Banerjee S., Lavie A., METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments[C], The ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pp. 65-72, (2005); Chin-Yew L., ROUGE: A Package for Automatic Evaluation of Summaries[C], pp. 74-81, (2004)",,"10th International Conference on Dependable Systems and Their Applications, DSA 2023",10 August 2023 through 11 August 2023,Tokyo,194487,English,Conference paper,Final,,Scopus,2-s2.0-85179505390,169
Yang G.; Jin T.; Dou L.,"Yang, Guang (55716844300); Jin, Tiancheng (57209419932); Dou, Liang (43260930900)",55716844300; 57209419932; 43260930900,Heterogeneous Directed Hypergraph Neural Network over abstract syntax tree (AST) for Code Classification,2023,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",2023-July,,,274,279,5,1,10.18293/SEKE2023-136,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170092438&doi=10.18293%2fSEKE2023-136&partnerID=40&md5=0db69ae8a2a9b72d28c356d2d0fef154,"Code classification is a difficult issue in program understanding and automatic coding. Due to the elusive syntax and complicated semantics in programs, most existing studies use techniques based on abstract syntax tree (AST) and graph neural network (GNN) to create code representations for code classification. These techniques utilize the structure and semantic information of the code, but they only take into account pairwise associations and neglect the high-order correlations that already exist between nodes in the AST, which may result in the loss of code structural information. On the other hand, while a general hypergraph can encode high-order data correlations, it is homogeneous and undirected which will result in a lack of semantic and structural information such as node types, edge types, and directions between child nodes and parent nodes when modeling AST. In this study, we propose to represent AST as a heterogeneous directed hypergraph (HDHG) and process the graph by heterogeneous directed hypergraph neural network (HDHGN) for code classification. Our method improves code understanding and can represent high-order data correlations beyond paired interactions. We assess heterogeneous directed hypergraph neural network (HDHGN) on public datasets of Python and Java programs. Our method outperforms previous AST-based and GNN-based methods, which demonstrates the capability of our model. © 2023 Knowledge Systems Institute Graduate School. All rights reserved.","Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, AAAI, (2016); Gilda S., Source code classification using neural networks, 2017 14th International Joint Conference on Computer Science and Software Engineering (JCSSE), pp. 1-6, (2017); Vagavolu D., Swarna K. C., Chimalakonda S., A mocktail of source code representations, ASE, (2021); Wang W., Zhang K., Li G., Jin Z., Learning to represent programs with heterogeneous graphs, 2022 IEEE/ACM 30th International Conference on Program Comprehension (ICPC), pp. 378-389, (2022); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 783-794, (2019); Lu M., Wang Y., Tan D., Zhao L., Student program classification using gated graph attention neural network, IEEE Access, 9, pp. 87857-87868, (2021); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating sequences from structured representations of code, ICLR, (2019); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, pp. 1-29, (2019); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, 2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC), pp. 200-20010, (2018); Liu S., Chen Y., Xie X., Siow J., Liu Y., Retrieval-augmented generation for code summarization via hybrid gnn, ICLR, (2021); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate tree-based detection of code clones, 29th International Conference on Software Engineering (ICSE’07), pp. 96-105, (2007); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, ASE, (2016); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, ICLR, (2018); Long T., Xie Y., Chen X., Zhang W., Cao Q., Yu Y., Multiview graph representation for programming language processing: An investigation into algorithm detection, AAAI, (2022); Huang J., Yang J., Unignn: a unified framework for graph and hypergraph neural networks, IJCAI, (2021); Feng Y., You H., Zhang Z., Ji R., Gao Y., Hypergraph neural networks, AAAI Conference on Artificial Intelligence, (2018); Puri R., Kung D. S., Janssen G., Zhang W., Domeniconi G., Zolotov V., Dolby J., Chen J., Choudhury M., Decker L., Thost V., Buratti L., Pujar S., Ramji S., Finkler U., Malaika S., Reiss F., Codenet: A large-scale ai for code dataset for learning a diversity of coding tasks, (2021); Bui N. D. Q., Yu Y., Jiang L., Treecaps: Tree-based capsule networks for source code processing, AAAI, (2021); Hellendoorn V. J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, ICLR, (2020); Berge C., Graphs and hypergraphs, (1973); Gallo G., Longo G., Pallottino S., Directed hypergraphs and applications, Discret. Appl. Math, 42, pp. 177-201, (1993); Sun Y., Han J., Mining heterogeneous information networks: Principles and methodologies, Mining Heterogeneous Information Networks: Principles and Methodologies, (2012); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A. N., Kaiser L., Polosukhin I., Attention is all you need, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems, pp. 5998-6008, (2017); Cai T., Luo S., Xu K., He D., Liu T.-Y., Wang L., Graphnorm: A principled approach to accelerating graph neural network training, ICML, (2021); Kipf T. N., Welling M., Semi-supervised classification with graph convolutional networks, ICLR, (2017); Xu K., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks?, ICLR, (2019)",Knowledge Systems Institute; KSI Research Inc.,"35th International Conference on Software Engineering and Knowledge Engineering, SEKE 2023",1 July 2023 through 10 July 2023,"Hybrid, San Francisco",191784,English,Conference paper,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85170092438,170
Long T.; Xie Y.; Chen X.; Zhang W.; Cao Q.; Yu Y.,"Long, Ting (57226487356); Xie, Yutong (57270109400); Chen, Xianyu (57218353860); Zhang, Weinan (56108513500); Cao, Qinxiang (57197812931); Yu, Yong (8723751600)",57226487356; 57270109400; 57218353860; 56108513500; 57197812931; 8723751600,Multi-View Graph Representation for Programming Language Processing: An Investigation into Algorithm Detection,2022,"Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022",36,,,5792,5799,7,5,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147550181&partnerID=40&md5=59c88dcae8e71c3b1db0eb1776516e66,"Program representation, which aims at converting program source code into vectors with automatically extracted features, is a fundamental problem in programming language processing (PLP). Recent work tries to represent programs with neural networks based on source code structures. However, such methods often focus on the syntax and consider only one single perspective of programs, limiting the representation power of models. This paper proposes a multi-view graph (MVG) program representation method. MVG pays more attention to code semantics and simultaneously includes both data flow and control flow as multiple views. These views are then combined and processed by a graph neural network (GNN) to obtain a comprehensive program representation that covers various aspects. We thoroughly evaluate our proposed MVG approach in the context of algorithm detection, an important and challenging subfield of PLP. Specifically, we use a public dataset POJ-104 and also construct a new challenging dataset ALG-109 to test our method. In experiments, MVG outperforms previous methods significantly, demonstrating our model's strong capability of representing source code. © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","Aho A. V., Sethi R., Ullman J. D., Compilers, principles, techniques, Addison wesley, 7, 8, (1986); Allamanis M., Barr E. T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Computing Surveys (CSUR), 51, 4, pp. 1-37, (2018); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, International Conference on Learning Representations, (2018); Allen F. E., Control flow analysis, ACM Sigplan Notices, 5, pp. 1-19, (1970); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, (2019); Ben-Nun T., Jakobovits A. S., Hoefler T., Neural code comprehension: a learnable representation of code semantics, Advances in Neural Information Processing Systems, pp. 3585-3597, (2018); Bui N. D., Yu Y., Jiang L., TreeCaps: Tree-based capsule networks for source code processing, Proceedings of the 35th AAAI Conference on Artificial Intelligence, (2021); Chen X., Liu C., Song D., Tree-to-tree neural networks for program translation, NIPS'18 Proceedings of the 32nd International Conference on Neural Information Processing Systems, 31, pp. 2552-2562, (2018); Cho K., van Merrienboer B., Bahdanau D., Bengio Y., On the Properties of Neural Machine Translation: Encoder-Decoder Approaches, Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pp. 103-111, (2014); Ciniselli M., Cooper N., Pascarella L., Poshyvanyk D., Di Penta M., Bavota G., An empirical study on the usage of BERT models for code completion, 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR), pp. 108-119, (2021); Farrow R., Kennedy K., Zucconi L., Graph grammars and global program data flow analysis, 17th Annual Symposium on Foundations of Computer Science (sfcs 1976), pp. 42-56, (1976); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Code-BERT: A Pre-Trained Model for Programming and Natural Languages, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, pp. 1536-1547, (2020); Fraser C. W., Hanson D. R., A retargetable C compiler: design and implementation, (1995); Gu X., Zhang H., Zhang D., Kim S., DeepAM: migrate APIs with multi-modal sequence to sequence learning, IJCAI'17 Proceedings of the 26th International Joint Conference on Artificial Intelligence, pp. 3675-3681, (2017); Harer J. A., Kim L. Y., Russell R. L., Ozdemir O., Kosta L. R., Rangamani A., Hamilton L. H., Centeno G. I., Key J. R., Ellingwood P. M., Et al., Automated software vulnerability detection with machine learning, (2018); Hochreiter S., Schmidhuber J., Long short-term memory, Neural computation, 9, 8, pp. 1735-1780, (1997); Kingma D. P., Ba J., Adam: A method for stochastic optimization, (2014); Le Q., Mikolov T., Distributed representations of sentences and documents, International conference on machine learning, pp. 1188-1196, (2014); Li Y., Tarlow D., Brockschmidt M., Zemel R. S., Gated Graph Sequence Neural Networks, ICLR, (2016); McInnes L., Healy J., Melville J., Umap: Uniform manifold approximation and projection for dimension reduction, (2018); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Thirtieth AAAI Conference on Artificial Intelligence, (2016); Muchnick S., Et al., Advanced compiler design implementation, (1997); Nie L., Jiang H., Ren Z., Sun Z., Li X., Query expansion based on crowd knowledge for code search, IEEE Transactions on Services Computing, 9, 5, pp. 771-783, (2016); Piech C., Huang J., Nguyen A., Phulsuksombati M., Sahami M., Guibas L., Learning program embeddings to propagate feedback on student code, International conference on machine Learning, pp. 1093-1102, (2015); Wang K., Learning Scalable and Precise Representation of Program Semantics, (2019); Wang K., Su Z., Singh R., Dynamic Neural Program Embeddings for Program Repair, International Conference on Learning Representations, (2018); Wang R., Zhang H., Lu G., Lyu L., Lyu C., Fret: Functional reinforced transformer with BERT for code summarization, IEEE Access, 8, pp. 135591-135604, (2020); Xia X., Bao L., Lo D., Xing Z., Hassan A. E., Li S., Measuring program comprehension: a large-scale field study with professionals, Proceedings of the 40th International Conference on Software Engineering, pp. 584-584, (2018); Yao Z., Peddamail J. R., Sun H., CoaCor: Code Annotation for Code Retrieval with Reinforcement Learning, The World Wide Web Conference, pp. 2203-2214, (2019); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks, Advances in Neural Information Processing Systems, pp. 10197-10207, (2019); Zuo F., Li X., Young P., Luo L., Zeng Q., Zhang Z., Neural Machine Translation Inspired Binary Code Similarity Comparison beyond Function Pairs, representations, 48, (2019)",Association for the Advancement of Artificial Intelligence,"36th AAAI Conference on Artificial Intelligence, AAAI 2022",22 February 2022 through 1 March 2022,"Virtual, Online",185285,English,Conference paper,Final,,Scopus,2-s2.0-85147550181,171
Zhang K.; Wang W.; Zhang H.; Li G.; Jin Z.,"Zhang, Kechi (57706554300); Wang, Wenhan (57216463961); Zhang, Huangzhao (57216617353); Li, Ge (55901136600); Jin, Zhi (8961795500)",57706554300; 57216463961; 57216617353; 55901136600; 8961795500,Learning to Represent Programs with Heterogeneous Graphs,2022,IEEE International Conference on Program Comprehension,2022-March,,,378,389,11,26,10.1145/3524610.3527905,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133172400&doi=10.1145%2f3524610.3527905&partnerID=40&md5=67576308d1c90ff9f1cafa4129a545ce,"Code representation, which transforms programs into vectors with semantics, is essential for source code processing. We have witnessed the effectiveness of incorporating structural information (i.e., graph) into code representations in recent years. Specifically, the abstract syntax tree (AST) and the AST-augmented graph of the program contain much structural and semantic information, and most existing studies apply them for code representation. The graph adopted by existing approaches is homogeneous, i.e., it discards the type information of the edges and the nodes lying within AST. That may cause plausible obstruction to the representation model. In this paper, we propose to leverage the type information in the graph for code representation. To be specific, we propose the heterogeneous program graph (HPG), which provides the types of the nodes and the edges explicitly. Furthermore, we employ the heterogeneous graph transformer (HGT) architecture to generate representations based on HPG, considering the type of information during processing. With the additional types in HPG, our approach can capture complex structural information, produce accurate and delicate representations, and finally perform well on certain tasks. Our in-depth evaluations upon four classic datasets for two typical tasks (i.e., method name prediction and code classification) demonstrate that the heterogeneous types in HPG benefit the representation models. Our proposed HPG+HGT also outperforms the SOTA baselines on the subject tasks and datasets.  © 2022 ACM.","Ahmad W., Chakraborty S., Ray B., Chang K., A Transformer-based Approach for Source Code Summarization, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 4998-5007, (2020); Allamanis M., Barr E.T., Bird C., Sutton C., Suggesting accurate method and class names, Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2015, pp. 38-49, (2015); Allamanis M., Barr E.T., Ducousso S., Gao Z., Typilus: neural type hints, Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 91-105, (2020); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, International Conference on Learning Representations, (2018); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, International conference on machine learning, pp. 2091-2100, (2016); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating Sequences from Structured Representations of Code, International Conference on Learning Representations, (2019); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: learning distributed representations of code, Proc. ACM Program. Lang., 3, pp. 401-4029, (2019); Brockschmidt M., Allamanis M., Gaunt A.L., Polozov O., Generative Code Modeling with Graphs, International Conference on Learning Representations, (2019); Bui Q.N.D., Yu Y., Jiang L., TreeCaps: Tree-Based Capsule Networks for Source Code Processing, Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, pp. 30-38, (2021); Cai R., Liang Z., Xu B., Li Z., Hao Y., Chen Y., TAG: Type Auxiliary Guiding for Code Comment Generation, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 291-301, (2020); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, pp. 1724-1734, (2014); Dinella E., Dai H., Li Z., Naik M., Song L., Wang K., Hoppity: Learning Graph Transformations to Detect and Fix Bugs in Programs, International Conference on Learning Representations, (2020); Duvenaud D., Maclaurin D., Aguilera-Iparraguirre J., Gomez-Bombarelli R., Hirzel T., Aspuru-Guzik A., Adams R.P., Convolutional Networks on Graphs for Learning Molecular Fingerprints, Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, pp. 2224-2232, (2015); Fernandes P., Allamanis M., Brockschmidt M., Structured Neural Summarization, International Conference on Learning Representations, (2019); Gilmer J., Schoenholz S.S., Riley P.F., Vinyals O., Dahl G.E., Neural Message Passing for Quantum Chemistry, International Conference on Machine Learning, pp. 1263-1272, (2017); Gori M., Monfardini G., Scarselli F., A new model for learning in graph domains, Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2, pp. 729-734, (2005); Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, International Conference on Learning Representations, (2020); Hochreiter S., Schmidhuber J., Long Short-Term Memory, Neural Comput., 9, 8, pp. 1735-1780, (1997); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, 2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC). IEEE, pp. 200-20010, (2018); Hu Z., Dong Y., Wang K., Sun Y., Heterogeneous graph transformer, Proceedings of The Web Conference, pp. 2704-2710, (2020); Husain H., Wu H., Gazit T., Allamanis M., Brockschmidt M., CodeSearchNet challenge: Evaluating the state of semantic code search, (2019); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing Source Code using a Neural Attention Model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, 1, (2016); Jiang L., Liu H., Jiang H., Machine Learning Based Recommendation of Method Names: How Far are We, 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019, pp. 602-614, (2019); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks, International Conference on Learning Representations, (2017); Kohavi R., Longbotham R., Online Controlled Experiments and A/B Testing, Encyclopedia of machine learning and data mining, 7, 8, pp. 922-929, (2017); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated Graph Sequence Neural Networks, International Conference on Learning Representations, (2016); Li Y., Wang S., Nguyen T.N., A Context-based Automated Approach for Method Name Consistency Checking and Suggestion, 43rd IEEE/ACM International Conference on Software Engineering, ICSE 2021, pp. 574-586, (2021); Liu K., Kim D., Bissyande T.F., Kim T., Kim K., Koyuncu A., Kim S., Le Traon Y., Learning to spot and refactor inconsistent method names, Proceedings of the 41st International Conference on Software Engineering, ICSE 2019, pp. 1-12, (2019); Loshchilov I., Hutter F., Decoupled Weight Decay Regularization, 7th International Conference on Learning Representations, ICLR 2019, (2019); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional Neural Networks over Tree Structures for Programming Language Processing, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, pp. 1287-1293, (2016); Nguyen S., Phan H., Le T., Nguyen T.N., Suggesting natural method names to check name consistencies, ICSE '20: 42nd International Conference on Software Engineering, pp. 1372-1384, (2020); Perozzi B., Al-Rfou R., Skiena S., Deepwalk: Online learning of social representations, Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 701-710, (2014); Puri R., Kung D.S., Janssen G., Zhang W., Domeniconi G., Zolotov V., Dolby J., Chen J., Choudhury M., Decker L., Thost V., Buratti L., Pujar S., Ramji S., Finkler U., Malaika S., Reiss F., CodeNet: A Large-Scale AI for Code Dataset for Learning a Diversity of Coding Tasks, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2), (2021); Qiu J., Tang J., Ma H., Dong Y., Wang K., Tang J., Deepinf: Social influence prediction with deep learning, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 2110-2119, (2018); Rabinovich M., Stern M., Klein D., Abstract Syntax Networks for Code Generation and Semantic Parsing, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pp. 1139-1149, (2017); Sharma T., Kechagia M., Georgiou S., Tiwari R., Sarro F., A Survey on Machine Learning Techniques for Source Code Analysis, (2021); Shaw P., Uszkoreit J., Vaswani A., Self-Attention with Relative Position Representations, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2, pp. 464-468, (2018); Si X., Dai H., Raghothaman M., Naik M., Song L., Learning loop invariants for program verification, Advances in Neural Information Processing Systems, pp. 7751-7762, (2018); Sun Y., Han J., Mining Heterogeneous Information Networks: Principles and Methodologies, (2012); Svajlenko J., Islam J.F., Keivanloo I., Kumar Roy C., Mamun Mia M., Towards a Big Data Curated Benchmark of Inter-project Code Clones, 30th IEEE International Conference on Software Maintenance and Evolution, pp. 476-480, (2014); Sheng Tai K., Socher R., Manning C.D., Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks, (2015); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in neural information processing systems, pp. 5998-6008, (2017); Vinyals O., Fortunato M., Jaitly N., Pointer networks, Advances in neural information processing systems, pp. 2692-2700, (2015); Wang D.C., Appel A.W., Korn J.L., Serra C.S., The Zephyr Abstract Syntax Description Language, Proceedings of the Conference on Domain-Specific Languages, DSL'97, pp. 213-228, (1997); Wang S., Wen M., Lin B., Mao X., Lightweight global and local contexts guided method name recommendation with prior knowledge, ESEC/FSE '21: 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 741-753, (2021); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting Code Clones with Graph Neural Network and Flow-Augmented Abstract Syntax Tree, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, pp. 261-271, (2020); Wang X., Ji H., Shi C., Wang B., Ye Y., Cui P., Yu P.S., Heterogeneous graph attention network, The World WideWeb Conference, pp. 2022-2032, (2019); Wang Y., Wang K., Gao F., Wang L., Learning semantic program embeddings with graph interval neural network, Proc. ACM Program. Lang., 4, pp. 1371-13727, (2020); Wei J., Goyal M., Durrett G., Dillig I., LambdaNet: Probabilistic Type Inference using Graph Neural Networks, International Conference on Learning Representations, (2019); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A Comprehensive Survey on Graph Neural Networks, IEEE Trans. Neural Networks Learn. Syst., 32, 1, pp. 4-24, (2021); Xu K., Hu W., Leskovec J., Jegelka S., How Powerful are Graph Neural Networks?, International Conference on Learning Representations, (2019); Yang Z., Dai Z., Yang Y., Carbonell J.G., Salakhutdinov R., Le Q.V., XLNet: Generalized Autoregressive Pretraining for Language Understanding, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, pp. 5754-5764, (2019); Yin P., Neubig G., TRANX: A Transition-based Neural Abstract Syntax Parser for Semantic Parsing and Code Generation, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pp. 7-12, (2018); Yin P., Neubig G., Allamanis M., Brockschmidt M., Gaunt A.L., Learning to Represent Edits, International Conference on Learning Representations, (2019); Zhang C., Song D., Huang C., Swami A., Chawla N.V., Heterogeneous graph neural network, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 793-803, (2019); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings of the 41st International Conference on Software Engineering, ICSE 2019, pp. 783-794, (2019); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, pp. 10197-10207, (2019); Zugner D., Kirschstein T., Catasta M., Leskovec J., Gunnemann S., Language-Agnostic Representation Learning of Source Code from Structure and Context, 9th International Conference on Learning Representations, ICLR 2021, (2021)",,"30th IEEE/ACM International Conference on Program Comprehension, ICPC 2022",16 May 2022 through 17 May 2022,Pittsburgh,180257,English,Conference paper,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85133172400,172
Wu Q.; Jiang X.; Zheng Z.; Gao X.; Lyu C.; Lyu L.,"Wu, Qiong (57221969385); Jiang, Xue (57221947208); Zheng, Zhuoran (57279212800); Gao, Xuejian (57221956553); Lyu, Chen (57195985796); Lyu, Lei (57204062203)",57221969385; 57221947208; 57279212800; 57221956553; 57195985796; 57204062203,Code Representation Based on Hybrid Graph Modelling,2021,Communications in Computer and Information Science,1516 CCIS,,,298,306,8,0,10.1007/978-3-030-92307-5_35,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121904967&doi=10.1007%2f978-3-030-92307-5_35&partnerID=40&md5=b4be88d3b89f31e430c408dceff98715,"Several sequence- or abstract syntax tree (AST)-based models have been proposed for modelling lexical-level and syntactic-level information of source code. However, an effective method of learning code semantic information is still lacking. Thus, we propose a novel code representation method based on hybrid graph modelling, called HGCR. HGCR is a code information extraction model. Specifically, in HGCR, two novel graphs, the Structure Graph (SG) and the Execution Data Flow Graph (EDFG), are first extracted from AST to model the syntactic structural and semantic information of source code, respectively. Then, two improved graph neural networks are applied to learn the graphs to obtain an effective code representation. We demonstrate the effectiveness of our model on two common code understanding tasks: code classification and code clone detection. Empirically, our model outperforms state-of-the-art models. © 2021, Springer Nature Switzerland AG.","Allamanis M., Peng H., Sutton C., A Convolutional Attention Network for Extreme Summarization of Source Code, (2016); Gu W., Et al., CRaDLe: Deep code retrieval based on semantic dependency learning, Neural Netw, 141, pp. 385-394, (2021); Hindle A., Barr E.T., Gabel M., Su Z., Devanbu P., On the naturalness of software, Commun. ACM, 59, pp. 122-131, (2016); Hua W., Sui Y., Wan Y., Liu G., Xu G., FCCA: Hybrid code representation for functional clone detection using attention networks, IEEE Trans. Reliabil., 70, pp. 304-318, (2020); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, (2014); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks, (2017); Mehrotra N., Agarwal N., Gupta P., Anand S., Lo D., Purandare R., Modeling Functional Similarity in Source Code with Graph-Based Siamese Networks. Arxiv Preprint Arxiv, 2011, (2020); Sun Z., Zhu Q., Xiong Y., Sun Y., Mou L., Zhang L., TreeGen: A tree-based transformer architecture for code generation, AAAI, (2020); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, MSR, (2018); Vaswani A., Et al., Attention is All You Need, (2017); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph Attention Networks, (2018); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, SANER, (2020); Wang Y., Li H., Code Completion by Modeling Flattened Abstract Syntax Trees as Graphs. Arxiv Preprint Arxiv, 2103, (2021)",,"28th International Conference on Neural Information Processing, ICONIP 2021",8 December 2021 through 12 December 2021,"Virtual, Online",269629,English,Conference paper,Final,,Scopus,2-s2.0-85121904967,173
Wen X.-C.; Chen Y.; Gao C.; Zhang H.; Zhang J.M.; Liao Q.,"Wen, Xin-Cheng (57226098194); Chen, Yupan (57712885800); Gao, Cuiyun (57189036288); Zhang, Hongyu (55685668500); Zhang, Jie M. (57209508429); Liao, Qing (55903680000)",57226098194; 57712885800; 57189036288; 55685668500; 57209508429; 55903680000,Vulnerability Detection with Graph Simplification and Enhanced Graph Representation Learning,2023,Proceedings - International Conference on Software Engineering,,,,2275,2286,11,12,10.1109/ICSE48619.2023.00191,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171196046&doi=10.1109%2fICSE48619.2023.00191&partnerID=40&md5=10fc8fedd7bbaa32d682dafa677fb841,"Prior studies have demonstrated the effectiveness of Deep Learning (DL) in automated software vulnerability detection. Graph Neural Networks (GNNs) have proven effective in learning the graph representations of source code and are commonly adopted by existing DL-based vulnerability detection methods. However, the existing methods are still limited by the fact that GNNs are essentially difficult to handle the connections between long-distance nodes in a code structure graph. Besides, they do not well exploit the multiple types of edges in a code structure graph (such as edges representing data flow and control flow). Consequently, despite achieving state-of-the-art performance, the existing GNN-based methods tend to fail to capture global information (i.e., long-range dependencies among nodes) of code graphs. To mitigate these issues, in this paper, we propose a novel vulnerability detection framework with grAph siMplification and enhanced graph rePresentation LEarning, named AMPLE. AMPLE mainly contains two parts: 1) graph simplification, which aims at reducing the distances between nodes by shrinking the node sizes of code structure graphs; 2) enhanced graph representation learning, which involves one edge-aware graph convolutional network module for fusing heterogeneous edge information into node representations and one kernel-scaled representation module for well capturing the relations between distant graph nodes. Experiments on three public benchmark datasets show that AMPLE outperforms the state-of-the-art methods by 0.39%-35.32% and 7.64%-199.81% with respect to the accuracy and F1 score metrics, respectively. The results demonstrate the effectiveness of AMPLE in learning global information of code graphs for vulnerability detection. © 2023 IEEE.","The exactis breach: 5 things you need to know., (2000); Wannacry ransomware attack., (2000); National vulnerability database., (2022); Cyber security vulnerability statistics and facts of 2022, (2022); 2022 open source security and risk analysis report., (2022); Cherem S., Princehouse L., Rugina R., Practical memory leak detection using guarded value-flow analysis, Proceedings of the ACM SIGPLAN 2007 Conference on Programming Language Design and Implementation, pp. 480-491, (2007); Fan G., Wu R., Shi Q., Xiao X., Zhou J., Zhang C., Smoke: scalable path-sensitive memory leak detection for millions of lines of code, Proceedings of the 41st International Conference on Software Engineering, ICSE 2019, pp. 72-82, (2019); Heine D.L., Lam M.S., Static detection of leaks in polymorphic containers, 28th International Conference on Software Engineering (ICSE 2006), pp. 252-261, (2006); Kroening D., Tautschnig M., CBMC-C bounded model checker-(competition contribution), Tools and Algorithms for the Construction and Analysis of Systems-20th International Conference, TACAS 2014, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2014, 8413, pp. 389-391, (2014); Ji X., Yang J., Xu J., Feng L., Li X., Interprocedural path-sensitive resource leaks detection for C programs, Proceedings of the Fourth Asia-Pacific Symposium on Internetware, Internetware 2012, pp. 191-199, (2012); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, 25th Annual Network and Distributed System Security Symposium, NDSS 2018, (2018); Russell R.L., Kim L.Y., Hamilton L.H., Lazovich T., Harer J., Ozdemir O., Ellingwood P.M., McConley M.W., Automated vulnerability detection in source code using deep representation learning, 17th IEEE International Conference on Machine Learning and Applications, ICMLA 2018, pp. 757-762, (2018); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: A framework for using deep learning to detect software vulnerabilities, IEEE Trans. Dependable Secur. Comput., 19, 4, pp. 2244-2258, (2022); Dam H.K., Tran T., Pham T., Ng S.W., Grundy J., Ghose A., Automatic feature learning for vulnerability prediction, (2017); Wu Y., Zou D., Dou S., Yang W., Xu D., Jin H., Vulcnn: An imageinspired scalable vulnerability detection system, 44th IEEE/ACM 44th International Conference on Software Engineering, ICSE 2022, pp. 2365-2376, (2022); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, SP 2014, pp. 590-604, (2014); Zhou Y., Liu S., Siow J.K., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, pp. 10197-10207, (2019); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Deng S.K., Clement C.B., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., Graphcodebert: Pre-training code representations with data flow, 9th International Conference on Learning Representations, ICLR 2021, (2021); Nguyen X., Joty S.R., Hoi S.C.H., Socher R., Tree-structured attention with hierarchical accumulation, 8th International Conference on Learning Representations, ICLR 2020, (2020); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet?, (2020); Li Y., Wang S., Nguyen T.N., Vulnerability detection with finegrained interpretations, ESEC/FSE '21: 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 292-303, (2021); Zhu D., Dai X., Chen J., Pre-train and learn: Preserving global information for graph neural networks, J. Comput. Sci. Technol., 36, 6, pp. 1420-1430, (2021); Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, 8th International Conference on Learning Representations, ICLR 2020, (2020); Alon U., Yahav E., On the bottleneck of graph neural networks and its practical implications, 9th International Conference on Learning Representations, ICLR 2021, (2021); Li Q., Han Z., Wu X., Deeper insights into graph convolutional networks for semi-supervised learning, Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), pp. 3538-3545, (2018); Pei H., Wei B., Chang K.C., Lei Y., Yang B., Geom-gcn: Geometric graph convolutional networks, 8th International Conference on Learning Representations, ICLR 2020, (2020); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Trans. Neural Networks, 20, 1, pp. 61-80, (2009); Wu L., Chen Y., Shen K., Guo X., Gao H., Li S., Pei J., Long B., Graph neural networks for natural language processing: A survey, (2021); Fan J., Li Y., Wang S., Nguyen T.N., A C/C++code vulnerability dataset with code changes and CVE summaries, MSR '20: 17th International Conference on Mining Software Repositories, pp. 508-512, (2020); Dosovitskiy A., Beyer L., Kolesnikov A., Weissenborn D., Zhai X., Unterthiner T., Dehghani M., Minderer M., Heigold G., Gelly S., Uszkoreit J., Houlsby N., An image is worth 16x16 words: Transformers for image recognition at scale, 9th International Conference on Learning Representations, ICLR 2021, (2021); Ioffe S., Szegedy C., Batch normalization: Accelerating deep network training by reducing internal covariate shift, Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, 37, pp. 448-456, (2015); Gao S., Gao C., Wang C., Sun J., Lo D., CARBON: A counterfactual reasoning based framework for neural code comprehension debiasing, (2022); Wang C., Yang Y., Gao C., Peng Y., Zhang H., Lyu M.R., No more fine-tuning? an experimental evaluation of prompt tuning in code intelligence, Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2022, pp. 382-394, (2022); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, 1st International Conference on Learning Representations, ICLR 2013, (2013); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, 6th International Conference on Learning Representations, ICLR 2018, (2018); Duan X., Wu J., Ji S., Rui Z., Luo T., Yang M., Wu Y., Vulsniper: Focus your attention to shoot fine-grained vulnerabilities, Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, pp. 4665-4671, (2019); Song Z., Wang J., Liu S., Zhiyang F., Yang K., Hgvul: A code vulnerability detection method based on heterogeneous source-level intermediate representation, Security and Communication Networks, (2022); Gao S., Gao C., He Y., Zeng J., Nie L.Y., Xia X., Code structure guided transformer for source code summarization, (2021); Ma W., Zhao M., Soremekun E.O., Hu Q., Zhang J.M., Papadakis M., Cordy M., Xie X., Traon Y.L., Graphcode2vec: Generic code embedding via lexical and program dependence analyses, 19th IEEE/ACM International Conference on Mining Software Repositories, MSR 2022, pp. 524-536; Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012, Proceedings of a meeting held December 3-6, pp. 1106-1114, (2012); LeCun Y., Bottou L., Bengio Y., Haffner P., Gradient-based learning applied to document recognition, Proc. IEEE, 86, 11, pp. 2278-2324, (1998); Alhumoud S.O., Wazrah A.A.A., Arabic sentiment analysis using recurrent neural networks: A review, Artif. Intell. Rev., 55, 1, pp. 707-748, (2022); Mikolov T., Zweig G., Context dependent recurrent neural network language model, 2012 IEEE Spoken Language Technology Workshop (SLT), pp. 234-239, (2012); Gong X., Xing Z., Li X., Feng Z., Han Z., Joint prediction of multiple vulnerability characteristics through multi-task learning, 24th International Conference on Engineering of Complex Computer Systems, ICECCS 2019, pp. 31-40, (2019); Gori M., Monfardini G., Scarselli F., A new model for learning in graph domains, Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2, pp. 729-734, (2005); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Trans. Neural Networks, 20, 1, pp. 61-80, (2009); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, 4th International Conference on Learning Representations, ICLR 2016, (2016); Cao S., Sun X., Bo L., Wu R., Li B., Tao C., MVD: memory-related vulnerability detection based on flow-sensitive graph neural networks, (2022); Fu M., Tantithamthavorn C., Linevul: A transformer-based linelevel vulnerability prediction, (2022); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, SP 2014, pp. 590-604, (2014); Wang Y., Li H., Code completion by modeling flattened abstract syntax trees as graphs, Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, pp. 14015-14023, (2021); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, pp. 5998-6008, (2017); Liu L., Jiang H., He P., Chen W., Liu X., Gao J., Han J., On the variance of the adaptive learning rate and beyond, 8th International Conference on Learning Representations, ICLR 2020, (2020); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5th International Conference on Learning Representations, ICLR 2017, (2017); Schlichtkrull M.S., Kipf T.N., Bloem P., Van Den Berg R., Titov I., Welling M., Modeling relational data with graph convolutional networks, The Semantic Web-15th International Conference, ESWC 2018, ser. Lecture Notes in Computer Science, pp. 593-607, (2018); Cwe-77",,"45th IEEE/ACM International Conference on Software Engineering, ICSE 2023",15 May 2023 through 16 May 2023,Melbourne,190685,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85171196046,175
Wang K.; Yan M.; Zhang H.; Hu H.,"Wang, Kesu (57221335373); Yan, Meng (56230838000); Zhang, He (55685593500); Hu, Haibo (55740755700)",57221335373; 56230838000; 55685593500; 55740755700,Unified Abstract Syntax Tree Representation Learning for Cross-Language Program Classification,2022,IEEE International Conference on Program Comprehension,2022-March,,,390,400,10,7,10.1145/3524610.3527915,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133153756&doi=10.1145%2f3524610.3527915&partnerID=40&md5=39053c8e722b50b94b0c9375c39fd15b,"Program classification can be regarded as a high-level abstraction of code, laying a foundation for various tasks related to source code comprehension, and has a very wide range of applications in the field of software engineering, such as code clone detection, code smell classification, defects classification, etc. The cross-language program classification can realize code transfer in different programming languages, and can also promote cross-language code reuse, thereby helping developers to write code quickly and reduce the development time of code transfer. Most of the existing studies focus on the semantic learning of the code, whilst few studies are devoted to cross-language tasks. The main challenge of cross-language program classification is how to extract semantic features of different programming languages. In order to cope with this difficulty, we propose a Unified Abstract Syntax Tree (namely UAST in this paper) neural network. In detail, the core idea of UAST consists of two unified mechanisms. First, UAST learns an AST representation by unifying the AST traversal sequence and graph-like AST structure for capturing semantic code features. Second, we construct a mechanism called unified vocabulary, which can reduce the feature gap between different programming languages, so it can achieve the role of cross-language program classification. Besides, we collect a dataset containing 20,000 files of five programming languages, which can be used as a benchmark dataset for the cross-language program classification task. We have done experiments on two datasets, and the results show that our proposed approach out-performs the state-of-the-art baselines in terms of four evaluation metrics (Precision, Recall, F1-score, and Accuracy).  © 2022 ACM.","Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, pp. 1-29, (2019); Azcona D., Arora P., Hsiao I., Smeaton A., user2code2vec: Embeddings for profiling students based on distributional representations of source code, Proceedings of the 9th International Conference on Learning Analytics & Knowledge. ACM, pp. 86-95, (2019); Baker B.S., A program for identifying duplicated code, Computing Science and Statistics, pp. 49-49, (1993); Barchi F., Parisi E., Urgese G., Ficarra E., Acquaviva A., Exploration of Convolutional Neural Network models for source code classification, Engineering Applications of Artificial Intelligence, 97, (2021); Bellon S., Koschke R., Antoniol G., Krinke J., Merlo E., Comparison and evaluation of clone detection tools, IEEE Transactions on software engineering, 33, 9, pp. 577-591, (2007); Ben-Nun T., Shoshana Jakobovits A., Hoefler T., Neural code comprehension: A learnable representation of code semantics, Advances in Neural Information Processing Systems, 31, pp. 3585-3597, (2018); Borstler J., Feature-oriented classification for software reuse, Proceedings of the 7th International Conference on Software Engineering and Knowledge Engineering, 95, pp. 22-24, (1995); Bui N.D.Q., Yu Y., Jiang L., Bilateral dependency neural networks for cross-language algorithm classification, Proceedings of the 26th International Conference on Software Analysis, Evolution and Reengineering. IEEE, pp. 422-433, (2019); Bui N.D.Q., Yu Y., Jiang L., InferCode: Self-supervised learning of code representations by predicting subtrees, Proceedings of the 43rd International Conference on Software Engineering. IEEE, pp. 1186-1197, (2021); Chopra S., Hadsell R., LeCun Y., Learning a similarity metric discriminatively, with application to face verification, 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05), 1, pp. 539-546, (2005); Clark K.L., Darlington J., Algorithm classification through synthesis, The computer journal, 23, 1, pp. 61-65, (1980); Conneau A., Lample G., Cross-lingual language model pretraining, Advances in Neural Information Processing Systems, 32, pp. 7059-7069, (2019); De Boer P., Kroese D.P., Mannor S., Rubinstein R.Y., A tutorial on the cross-entropy method, Annals of operations research, 134, 1, pp. 19-67, (2005); Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-training of deep bidirectional transformers for language understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. ACL, pp. 29-35, (2019); Drucker H., Burges C.J.C., Kaufman L., Smola A., Vapnik V., Et al., Support vector regression machines, Advances in neural information processing systems, 9, pp. 155-161, (1997); Elman J.L., Finding structure in time, Cognitive science, 14, 2, pp. 179-211, (1990); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., CodeBERT: A pretrained model for programming and natural languages, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings. ACL, pp. 1536-1547, (2020); Arcelli Fontana F., Zanoni M., Code smell severity classification using machine learning techniques, Knowledge-Based Systems, 128, pp. 43-58, (2017); Friedman N., Geiger D., Goldszmidt M., Bayesian network classifiers, Machine learning, 29, 2, pp. 131-163, (1997); Graves A., Schmidhuber J., Framewise phoneme classification with bidirectional LSTM and other neural network architectures, Neural networks, 18, 5-6, pp. 602-610, (2005); Harer J.A., Kim L.Y., Russell R.L., Ozdemir O., Kosta L.R., Rangamani A., Hamilton L.H., Centeno G.I., Key J.R., Ellingwood P.M., Et al., Automated software vulnerability detection with machine learning, (2018); Huang J., Li J., Yu D., Deng L., Gong Y., Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers, Proceedings of the 2013 International Conference on Acoustics, Speech and Signal Processing. IEEE, pp. 7304-7308, (2013); Jiang L., Su Z., Automatic mining of functionally equivalent code fragments via random testing, Proceedings of the 18th International Symposium on Software Testing and Analysis. ACM, pp. 81-92, (2009); Kalchbrenner N., Grefenstette E., Blunsom P., A convolutional neural network for modelling sentences, (2014); Kim K., Kim D., Bissyande T.F., Choi E., Li L., Klein J., Le Traon Y., FaCoY: a code-to-code search engine, Proceedings of the 40th International Conference on Software Engineering. ACM, pp. 946-957, (2018); Kingma D.P., Ba J., Adam: A method for stochastic optimization, Proceedings of the 3rd International Conference on Learning Representations. OpenReview, (2015); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, (2016); Li J., He P., Zhu J., Lyu M.R., Software defect prediction via convolutional neural network, Proceedings of the 2017 International Conference on Software Quality, Reliability and Security. IEEE, pp. 318-328, (2017); Li L., Feng H., Zhuang W., Meng N., Ryder B., Cclearner: A deep learning-based clone detection approach, Proceedings of 33rd International Conference on Software Maintenance and Evolution. IEEE, pp. 249-260, (2017); Ma Y., Fakhoury S., Christensen M., Arnaoudova V., Zogaan W., Mirakhorli M., Automatic classification of software artifacts in open-source applications, Proceedings of the 15th International Conference on Mining Software Repositories. ACM, pp. 414-425, (2018); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, (2013); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Proceedings of the 30th AAAI Conference on Artificial Intelligence. ACM, (2016); Tuan Nguyen A., Thanh Nguyen T., Nguyen T.N., Migrating code with statistical machine translation, Proceedings of the 36th International Conference on Software Engineering Companion. ACM, pp. 544-547, (2014); Peng H., Li G., Wang W., Zhao Y., Jin Z., Integrating tree path in transformer for code representation, Proceedings of the 35th Conference on Neural Information Processing Systems, (2021); Peters F., Than Tun T., Yu Y., Nuseibeh B., Text filtering and ranking for security bug report prediction, IEEE Transactions on Software Engineering, 45, 6, pp. 615-631, (2017); Ross Quinlan J., Induction of decision trees, Machine learning, 1, 1, pp. 81-106, (1986); Scarselli F., Gori M., Chung Tsoi A., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE transactions on neural networks, 20, 1, pp. 61-80, (2008); Shimonaka K., Sumi S., Higo Y., Kusumoto S., Identifying auto-generated code by using machine learning techniques, Proceedings of the 7th International Workshop on Empirical Software Engineering in Practice. IEEE, pp. 18-23, (2016); Taherkhani A., Korhonen A., Malmi L., Recognizing algorithms using language constructs, software metrics and roles of variables: An experiment with sorting algorithms, Comput. J., 54, 7, pp. 1049-1066, (2011); Ugurel S., Krovetz R., Lee Giles C., What's the code? automatic classification of source code archives, Proceedings of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, pp. 632-638, (2002); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Proceedings of the 31st Conference on Neural Information Processing Systems, pp. 5998-6008, (2017); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, Proceedings of the 38th International Conference on Software Engineering. ACM, pp. 297-308, (2016); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, Proceedings of the 27th International Conference on Software Analysis, Evolution and Reengineering. IEEE, pp. 261-271, (2020); Wei J., Goyal M., Durrett G., Dillig I., Lambdanet: Probabilistic type inference using graph neural networks, Proceedings of the 8th International Conference on Learning Representations. OpenReview, (2020); Ye F., Zhou S., Venkat A., Marucs R., Tatbul N., Jahan Tithi J., Petersen P., Mattson T., Kraska T., Dubey P., Et al., Misim: An end-to-end neural code similarity system, (2020); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings of the 41st International Conference on Software Engineering. IEEE, pp. 783-794, (2019); Zhang Y., Wallace B., A sensitivity analysis of (and practitioners' guide to) convolutional neural networks for sentence classification, (2015)",,"30th IEEE/ACM International Conference on Program Comprehension, ICPC 2022",16 May 2022 through 17 May 2022,Pittsburgh,180257,English,Conference paper,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85133153756,176
Lu M.; Wang Y.; Tan D.; Zhao L.,"Lu, M. (55276383700); Wang, Y. (57219203049); Tan, D. (57205481945); Zhao, L. (55493602800)",55276383700; 57219203049; 57205481945; 55493602800,Student Program Classification Using Gated Graph Attention Neural Network,2021,IEEE Access,9,,9367198,87857,87868,11,6,10.1109/ACCESS.2021.3063475,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117607455&doi=10.1109%2fACCESS.2021.3063475&partnerID=40&md5=26575eb8c4dfa836f1de5454370cb284,"Source code mining has received increasing attention, among which code classification plays a significant role in code understanding and automatic coding. Most source code mining efforts aim at the source code of projects, which are usually large and standardized, but less for student programs. There are two differences between project codes and student programs. On the one hand, some work on project codes is based on relatively single information, which is far from enough for student programs. Because student programs are relatively small, which makes them contain less information. Consequently, it is necessary to mine as much information as possible in student programs. On the other hand, the variable or function naming and the structure of the student programs are usually irregular, as compared with the source codes of projects. To learn from student programs, we proposed a Graph Neural Network (GNN) based model, which integrates data flow and function call information to the Abstract Syntax Tree (AST), and applies an improved GNN model to the integrated graph to achieve the state-of-art student program classification accuracy. The experiment results have shown that the proposed work can classify student programs with accuracy over 97%. © 2013 IEEE.","Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, Acm Comput. Surv, 51, 4, pp. 1-37, (2018); Allamanis M., Peng H., Sutton C., A Convolutional Attention Network for Extreme Summarization of Source Code, (2016); Devanbu P., On the naturalness of software, Proc. 6th India Softw. Eng. Conf. (ISEC), (2013); Gu X., Zhang H., Zhang D., Kim S., Deep API learning, Proc. 24th Acm Sigsoft Int. Symp. Found. Softw. Eng., pp. 631-642, (2016); Lu Y., Li G., Miao R., Jin Z., Learning embeddings of API tokens to facilitate deep learning based program processing, Knowledge Science, Engineering and Management, (2016); Raychev V., Vechev M., Yahav E., Code completion with statistical language models, Acm Sigplan Notices, 49, 6, pp. 419-428, (2014); Bui N., Jiang L., Yu Y., Cross-language learning for program classification using bilateral tree-based convolutional neural networks, Proc. 32nd Aaai Conf. Artif. Intell. (AAAI), (2018); Maddison C., Tarlow D., Structured Generative Models of Natural Source Code, (2014); Peng H., Mou L., Li G., Liu Y., Zhang L., Jin Z., Building program vector representations for deep learning, Knowledge Science, Engineering and Management, (2015); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Proc. Aaai Conf. Artif. Intell., pp. 1287-1293, (2016); Mou L., Men R., Li G., Xu Y., Zhang L., Yan R., Jin Z., Recognizing Entailment and Contradiction by Tree-based Convolution, (2015); Raychev V., Vechev M., Krause A., Predicting program properties from `big code, Acm Sigplan Notices, 50, 1, pp. 111-124, (2015); Allamanis M., Brockschmidt M., Khademi M., Learning to rep- resent programs with graphs, Proc. Int. Conf. Learn. Represent, (2017); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, Proc. Int. Conf. Learn. Represent, (2015); Bhoopchand A., Rocktschel T., Barr E., Riedel S., Learning python code suggestion with a sparse pointer network, Proc. Int. Conf. Learn. Represent, (2017); Defferrard M., Bresson X., Vandergheynst P., Convolutional neural networks on graphs with fast localized spectral -ltering, Proc. Adv. Neural Inf. Process. Syst., pp. 3844-3852, (2016); Kipf T., Welling M., Semi-supervised classification with graph con- volutional networks, Proc. Int. Conf. Learn. Represent, (2017); Vytovtov P., Chuvilin K., Unsupervised classifying of software source code using graph neural networks, Proc. 24th Conf. Open Innov. Assoc. (FRUCT), pp. 518-524, (2019); Gori M., Monfardini G., Scarselli F., A new model for learning in graph domains, Proc. Ieee Int. Joint Conf. Neural Netw, 2, pp. 729-734, (2005); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, Ieee Trans. Neural Netw, 20, 1, pp. 61-80, (2009); Cho K., Merrienboer B.V., Bahdanau D., Bengio Y., On the proper- ties of neural machine translation: Encoder-decoder approaches, Comput. Sci, (2014); Miller F., Vandome A., McBrewster J., Abstract Syntax Tree, (2010); Liu X., Tang Y., Similarity analysis of malware's function- call graphs, Comput. Eng. Sci, 36, 3, pp. 481-486, (2014); Olenick B.M., Szyperski C.A., Hunt D.G., Hughes G.L., Manis W.A., Zmrhal T., Accessing and Manipulating Data in a Data Flow Graph, (2010); Kingma D., Ba J., Adam: A method for stochastic optimization, Comput. Sci., (2014); Glorot X., Bengio Y., Understanding the difficulty of training deep feed forward neural networks, Proc. 30th Int. Conf. Artif. Intell. Statist, pp. 249-256, (2010); Srivastava N., Hinton G., Krizhevsky A., Sutskever I., Salakhutdinov R., Dropout: A simple way to prevent neural networks from over fitting, J. Mach. Learn. Res, 15, 1, pp. 1929-1958, (2014)",,,,,,English,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85117607455,177
Shi E.; Wang Y.; Du L.; Zhang H.; Han S.; Zhang D.; Sun H.,"Shi, Ensheng (57226182242); Wang, Yanlin (57222817085); Du, Lun (57200386094); Zhang, Hongyu (55685668500); Han, Shi (55487844700); Zhang, Dongmei (55717568500); Sun, Hongbin (55729283500)",57226182242; 57222817085; 57200386094; 55685668500; 55487844700; 55717568500; 55729283500,CoCoAST: Representing Source Code via Hierarchical Splitting and Reconstruction of Abstract Syntax Trees,2023,Empirical Software Engineering,28,6,135,,,,1,10.1007/s10664-023-10378-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173621153&doi=10.1007%2fs10664-023-10378-9&partnerID=40&md5=c13a0a2c7d54cce36d56f84297dc75a7,"Recently, machine learning techniques especially deep learning techniques have made substantial progress on some code intelligence tasks such as code summarization, code search, clone detection, etc. How to represent source code to effectively capture the syntactic, structural, and semantic information is a key challenge. Recent studies show that the information extracted from abstract syntax trees (ASTs) is conducive to code representation learning. However, existing approaches fail to fully capture the rich information in ASTs due to the large size/depth of ASTs. In this paper, we propose a novel model CoCoAST that hierarchically splits and reconstructs ASTs to comprehensively capture the syntactic and semantic information of code without the loss of AST structural information. First, we hierarchically split a large AST into a set of subtrees and utilize a recursive neural network to encode the subtrees. Then, we aggregate the embeddings of subtrees by reconstructing the split ASTs to get the representation of the complete AST. Finally, we combine AST representation carrying the syntactic and structural information and source code embedding representing the lexical information to obtain the final neural code representation. We have applied our source code representation to two common program comprehension tasks, code summarization and code search. Extensive experiments have demonstrated the superiority of CoCoAST. To facilitate reproducibility, our data and code are available https://github.com/s1530129650/CoCoAST . © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Ahmad W.U., Chakraborty S., Ray B., Chang K., A transformer-based approach for source code summarization, ACL, (2020); Ahmad W.U., Chakraborty S., Ray B., Chang K., Unified pre-training for program understanding and generation, NAACL-HLT, pp. 2655-2668, (2021); Allamanis M., Barr E.T., Bird C., Sutton C.A., Suggesting accurate method and class names, FSE, (2015); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, ICLR, (2018); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, ICML, JMLR Workshop and Conference Proceedings, Jmlr.Org, 48, pp. 2091-2100, (2016); Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating Sequences from Structured Representations of Code, (2019); Alon U., Yahav E., On the Bottleneck of Graph Neural Networks and Its Practical Implications, (2021); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning Distributed Representations of Code, (2019); Banerjee S., Lavie A., METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments, (2005); Bansal A., Haque S., McMillan C., Project-level encoding for neural source code summarization of subroutines, ICPC, IEEE, pp. 253-264, (2021); Bengio Y., Frasconi P., Simard P.Y., The Problem of Learning Long-Term Dependencies in Recurrent Networks, (1993); Cho K., van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using RNN encoder-decoder for statistical machine translation, EMNLP, ACL, pp. 1724-1734, (2014); Du L., Shi X., Wang Y., Shi E., Han S., Zhang D., Is a single model enough? Mucos: A multi-model ensemble learning approach for semantic code search, CIKM, ACM, pp. 2994-2998, (2021); Eddy B.P., Robinson J.A., Kraft N.A., Carver J.C., Evaluating source code summarization techniques: Replication and expansion, ICPC, IEEE Computer Society, pp. 13-22, (2013); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., Codebert: A pre-trained model for programming and natural languages, In: EMNLP (Findings), (2020); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, In: ICLR, (2019); Fout A., Byrd J., Shariat B., Ben-Hur A., Protein interface prediction using graph convolutional networks, pp. 6530-6539, (2017); Franks C., Tu Z., Devanbu P.T., Hellendoorn V., CACHECA: A cache language model based code suggestion tool, ICSE, IEEE Computer Society, 2, pp. 705-708, (2015); Gao S., Gao C., He Y., Zeng J., Nie L.Y., Xia X., Code Structure Guided Transformer for Source Code Summarization, (2021); Garg V.K., Jegelka S., Jaakkola T.S., Generalization and representational limits of graph neural networks, ICML, Proceedings of Machine Learning Research, PMLR, 119, pp. 3419-3430, (2020); Gros D., Sezhiyan H., Devanbu P., Yu Z., Code to comment “translation”: Data, metrics, baselining & evaluation, In: ASE, (2020); Gu J., Chen Z., Monperrus M., Multimodal representation for neural code search, IEEE International Conference on Software Maintenance and Evolution, ICSME 2021, Luxembourg, pp. 483-494, (2021); Gu W., Li Z., Gao C., Wang C., Zhang H., Xu Z., Lyu M.R., Cradle: Deep code retrieval based on semantic dependency learning, Neural Networks, 141, pp. 385-394, (2021); Gu X., Zhang H., Kim S., Deep code search, ICSE, pp. 933-944, (2018); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Deng S.K., Lement C.B., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., (2021) Graphcodebert: Pre-training code representations with data flow, 9Th International Conference on Learning Representations, ICLR 2021; Haiduc S., Aponte J., Moreno L., Marcus A., On the use of automated text summarization techniques for summarizing source code, In:Wcre, IEEE Computer Society, pp. 35-44, (2010); Haije T., Automatic Comment Generation Using a Neural Translation Model. Bachelor’s Thesis, (2016); Haldar R., Wu L., Xiong J., Hockenmaier J., A multi-perspective architecture for semantic code search, Proceedings of the 58Th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, Association for Computational Linguistics, pp. 8563-8568, (2020); Haque S., Leclair A., Wu L., McMillan C., Improved automatic summarization of subroutines via attention to file context, In: MSR, (2020); He K., Fan H., Wu Y., Xie S., Girshick RB (2020) Momentum contrast for unsupervised visual representation learning, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020, pp. 9726-9735; Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global Relational Models of Source Code, (2020); Hu X., Li G., Xia X., Lo D., Jin Z., Deep Code Comment Generation, (2018); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation with hybrid lexical and syntactical information, Empirical Software Engineering, (2019); Hu X., Li G., Xia X., Lo D., Jin Z., Summarizing Source Code with Transferred Api Knowledge, (2018); Huang J., Tang D., Shou L., Gong M., Xu K., Jiang D., Zhou M., Duan N., Cosqa: 20, 000+ web queries for code search and question answering, ACL, (2021); Husain H., Wu H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet challenge: Evaluating the state of semantic code search, Corr, (2019); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, ACL, (2016); Iyyer M., Manjunatha V., Boyd-Graber J.L., Iii H.D., Deep unordered composition rivals syntactic methods for text classification, 1, pp. 1681-1691, (2015); Jain P., Jain A., Zhang T., Abbeel P., Gonzalez J., Stoica I., Contrastive code representation learning, EMNLP, Association for Computational Linguistics, 1, pp. 5954-5971, (2021); Jiang X., Zheng Z., Lyu C., Li L., Lyu L., Treebert: A tree-based pre-trained model for programming language, UAI, Proceedings of Machine Learning Research, AUAI Press, 161, pp. 54-63, (2021); Kanade A., Maniatis P., Balakrishnan G., Shi K., Pre-Trained Contextual Embedding of Source Code. Arxiv, 2001, (2020); Kim Y., Convolutional neural networks for sentence classification, In: EMNLP, ACL Pp, pp. 1746-1751, (2014); Leclair A., Bansal A., McMillan C., Ensemble models for neural source code summarization of subroutines, In: ICSME, IEEE, pp. 286-297, (2021); Leclair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network., pp. 18-195, (2020); Leclair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, (2019); Li W., Qin H., Yan S., Shen B., Chen Y., Learning code-query interaction for enhancing code searches, In: ICSME, IEEE, pp. 115-126, (2020); Libovicky J., Helcl J., Marecek D., Input combination strategies for multi-source transformer decoder, In: WMT, (2018); Lin C., ROUGE: A package for automatic evaluation of summaries, In: ACL, (2004); Lin C., Och F.J., Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics, In: ACL, pp. 605-612, (2004); Ling C., Lin Z., Zou Y., Xie B., Adaptive deep code search, ICPC ’20: 28Th International Conference on Program Comprehension, Seoul, Republic of Korea, pp. 48-59, (2020); Ling X., Wu L., Wang S., Pan G., Ma T., Xu F., Liu A.X., Wu C., Ji S., Deep graph matching and searching for semantic code retrieval, ACM Trans Knowl Discov Data, 15, 5, pp. 1-88, (2021); Linstead E., Bajracharya S.K., Ngo T.C., Rigor P., Lopes C.V., Baldi P., Sourcerer: mining and searching internet-scale software repositories, Data Min Knowl Discov, 18, 2, pp. 300-336, (2009); Liu F., Li G., Zhao Y., Jin Z., Multi-task learning based pre-trained language model for code completion, ASE, pp. 473-485, (2020); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., Roberta: A Robustly Optimized BERT Pretraining Approach. Arxiv, 1907, (2019); Loshchilov I., Hutter F., Decoupled weight decay regularization, In: ICLR, (2019); Lu M., Sun X., Wang S., Lo D., Duan Y., Query expansion via wordnet for effective code search, SANER, IEEE Computer Society, pp. 545-549, (2015); Lv F., Zhang H., Lou J., Wang S., Zhang D., Zhao J., Codehow: Effective code search based on API understanding and extended boolean model (E), ASE, IEEE Computer Society, pp. 260-270, (2015); McMillan C., Grechanik M., Poshyvanyk D., Xie Q., Fu C., Portfolio: Finding relevant functions and their usage, ICSE, ACM, pp. 111-120, (2011); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, AAAI, (2016); Representation Learning with Contrastive Predictive Coding, (2018); Papineni K., Roukos S., Ward T., Zhu W., Bleu: A method for automatic evaluation of machine translation, pp. 311-318, (2002); Parr T., The definitive ANTLR 4 reference (2 ed.), (2013); Rodeghero P., McMillan C., McBurney P.W., Bosch N., D'Mello S.K., Improving automated source code summarization via an eye-tracking study of programmers, In: ICSE, ACM, pp. 390-401, (2014); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., Sourcerercc: Scaling code clone detection to big-code, ICSE, ACM, pp. 1157-1168, (2016); See A., Liu P.J., Manning C.D., Get to the Point: Summarization with Pointergenerator Networks, (2017); Shi E., Gu W., Wang Y., Du L., Zhang H., Han S., Zhang D., Sun H., Enhancing semantic code search with multimodal contrastive learning and soft data augmentation., (2022); Shi E., Wang Y., Du L., Chen J., Han S., Zhang H., Zhang D., Sun H., On the evaluation of neural code summarization, (2022); Shi E., Wang Y., Du L., Zhang H., Han S., Zhang D., Sun H., CAST: Enhancing code summarization with hierarchical splitting and reconstruction of abstract syntax trees, pp. 4053-4062, (2021); Shi L., Mu F., Chen X., Wang S., Wang J., Yang Y., Li G., Xia X., Wang Q., Are we building on the rock? On the importance of data preprocessing for code summarization, ESEC/SIGSOFT FSE, ACM, pp. 107-119, (2022); Shin E.C.R., Allamanis M., Brockschmidt M., Polozov A., Program synthesis and semantic parsing with learned code idioms, pp. 10824-10834, (2019); Shuai J., Xu L., Liu C., Yan M., Xia X., Lei Y., Improving code search with coattentive representation learning, ICPC ’20: 28Th International Conference on Program Comprehension, Seoul, Republic of Korea, ACM Pp 196–207 July, 13-15, (2020); Sridhara G., Hill E., Muppaneni D., Pollock L.L., Vijay-Shanker K., Towards Automatically Generating Summary Comments for Java Methods, pp. 43-52, (2010); Sun Z., Li L., Liu Y., Du X., Li L., On the importance of building high-quality training datasets for neural code search, ICSE, ACM, pp. 1609-1620, (2022); Svyatkovskiy A., Deng S.K., Fu S., Sundaresan N., Intellicode compose: Code generation using transformer, ESEC/SIGSOFT FSE, ACM, pp. 1433-1443, (2020); Tai K.S., Socher R., Manning C.D., Improved semantic representations from treestructured long short-term memory networks, The Association for Computer Linguistics Pp, pp. 1556-1566, (2015); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, NIPS, pp. 5998-6008, (2017); Vedantam R., Zitnick C.L., Parikh D., Cider: Consensus-based image description evaluation, CVPR, (2015); Wan Y., Shu J., Suiy X.G., Zhao Z., Wu J.P.S., Multi-modal attention network learning for semantic source code retrieval, In: ASE, IEEE, pp. 13-25, (2019); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, ASE, (2018); Wang X., Wang Y., Mi F., Zhou P., Wan Y., Liu X., Li L., Wu H., Liu J., Jiang X., Syncobert: Syntax-guided multi-modal contrastive pre-training for code representation., (2021); Wang Y., Du L., Shi E., Hu Y., Han S., Zhang D., Cocogum: Contextual code summarization with multi-relational gnn on umls, Tech Rep, Microsoft, (2020); Wang Y., Li H., Code completion by modeling flattened abstract syntax trees as graphs, In: AAAI, (2021); Wang Y., Wang W., Joty S.R., Hoi S.C.H., Codet5: Identifier-aware unified pretrained encoder-decoder models for code understanding and generation, EMNLP (1), pp. 8696-8708, (2021); Wei B., Li G., Xia X., Fu Z., Jin Z., Code generation as a dual task of code summarization, Neurips, pp. 6559-6569, (2019); Wei B., Li Y., Li G., Xia X., Jin Z., Retrieve and refine: Exemplar-based neural comment generation, ASE, IEEE, pp. 349-360, (2020); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, ASE, ACM, pp. 87-98, (2016); Wilcoxon F., Katti S., Wilcox R.A., Critical values and probability levels for the wilcoxon rank sum test and the wilcoxon signed rank test, Selected tables in mathematical statistics, 1, pp. 171-259, (1970); Wu H., Zhao H., Zhang M., Code summarization with structure-induced transformer, ACL/IJCNLP (Findings), Findings of ACL, Vol. ACL/IJCNLP 2021, Association for Computational Linguistics, pp. 1078-1090, (2021); Wu Y., Lian D., Xu Y., Wu L., Chen E., Graph convolutional networks with markov random field reasoning for social spammer detection, pp. 1054-1061, (2020); Wu Z., Xiong Y., Yu S.X., Lin D., Unsupervised feature learning via non-parametric instance discrimination, CVPR, Computer Vision Foundation /IEEE Computer Society, pp. 3733-3742, (2018); Yang M., Zhou M., Li Z., Liu J., Pan L., Xiong H., King I., Hyperbolic Graph Neural Networks: A Review of Methods and Applications, (2022); Ye W., Xie R., Zhang J., Hu T., Wang X., Zhang S (2020) Leveraging code generation to improve code retrieval and summarization via dual learning, WWW’20: Theweb Conference 2020, Taipei, Taiwan, ACM / IW3C2 Pp 2309–2319. 20-24, (2020); Yu X., Huang Q., Wang Z., Feng Y., Zhao D., Towards context-aware code comment generation, pp. 3938-3947, (2020); Zhang J., Panthaplackel S., Nie P., Mooney R.J., Li J.J., Gligoric M., Learning to generate code comments from class hierarchies., (2021); Zhang J., Wang X., Zhang H., Sun H., Liu X., Retrieval-based neural source code summarization, In: ICSE, (2020); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, In: ICSE, (2019); Zhu Q., Sun Z., Liang X., Xiong Y., Zhang L., (, 35Th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020, pp. 883-894, (2020)",,,,,,English,Article,Final,,Scopus,2-s2.0-85173621153,178
Yang J.; Fu C.; Deng F.; Wen M.; Guo X.; Wan C.,"Yang, Jia (57188768184); Fu, Cai (57199741768); Deng, Fengyang (57760500000); Wen, Ming (56111949000); Guo, Xiaowei (58549220900); Wan, Chuanhao (58184695600)",57188768184; 57199741768; 57760500000; 56111949000; 58549220900; 58184695600,Toward Interpretable Graph Tensor Convolution Neural Network for Code Semantics Embedding,2023,ACM Transactions on Software Engineering and Methodology,32,5,115,,,,1,10.1145/3582574,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168769136&doi=10.1145%2f3582574&partnerID=40&md5=ba7fac921dc538ffe1e6a93800dcd2d5,"Intelligent deep learning-based models have made significant progress for automated source code semantics embedding, and current research works mainly leverage natural language-based methods and graph-based methods. However, natural language-based methods do not capture the rich semantic structural information of source code, and graph-based methods do not utilize rich distant information of source code due to the high cost of message-passing steps.In this article, we propose a novel interpretable model, called graph tensor convolution neural network (GTCN), to generate accurate code embedding, which is capable of comprehensively capturing the distant information of code sequences and rich code semantics structural information. First, we propose to utilize a high-dimensional tensor to integrate various heterogeneous code graphs with node sequence features, such as control flow, data flow. Second, inspired by the current advantages of graph-based deep learning and efficient tensor computations, we propose a novel interpretable graph tensor convolution neural network for learning accurate code semantic embedding from the code graph tensor. Finally, we evaluate three popular applications on the GTCN model: variable misuse detection, source code prediction, and vulnerability detection. Compared with current state-of-the-art methods, our model achieves higher scores with respect to the top-1 accuracy while costing less training time.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Zhou Y., Source codes of the paper: Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, (2019); Wang Y., Source codes of the paper: Learning semantic program embeddings with graph interval neural network, (2020); Hellendoorn V.J., Source codes of the paper: Global relational models of source code, (2020); Feng Z., Source codes of the paper: CodeBERT: A pre-trained model for programming and natural languages, (2021); Yang J., Source codes of this paper, (2022); Yang J., Source codes of this paper, (2022); Li Y., Source codes of the paper: Vulnerability detection with fine-grained interpretations, (2021); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, 6th International Conference on Learning Representations, (2018); Aye G.A., Kaiser G.E., Sequence model design for code completion in the modern IDE, CoRR, (2020); Baraniuk R.G., More is less: Signal processing and the data deluge, Science, 331, 6018, pp. 717-719, (2011); Bichsel B., Raychev V., Tsankov P., Vechev M.T., Statistical deobfuscation of Android applications, ACM SIGSAC Conference on Computer and Communications Security, pp. 343-355, (2016); Bielik P., Raychev V., Vechev M.T., PHOG: Probabilistic model for code, 33rd International Conference on Machine Learning, pp. 2933-2942, (2016); Cai T., Luo S., Xu K., GraphNorm: A principled approach to accelerating graph neural network training, 38th International Conference on Machine Learning, pp. 1204-1215, (2021); Cao S., Sun X., Bo L., Et al., 2022. MVD: Memory-related vulnerability detection based on flow-sensitive graph neural networks, 44th IEEE/ACM 44th International Conference on Software Engineering, pp. 1456-1468; Cheng L., Shi Q., Towards overfitting avoidance: Tuning-free tensor-aided multi-user channel estimation for 3D massive MIMO communications, IEEE J. Sel. Top. Sig. Process., 15, 3, pp. 832-846, (2021); Cheng X., Wang H., Hua J., Et al., 2021, ACM Trans. Softw. Eng. Methodol., 30, 3; Cherkassky V., The nature of statistical learning theory, IEEE Trans. Neural Netw., 8, 6, (1997); Cichocki A., Mandic D.P., Tensor decompositions for signal processing applications: From two-way to multiway component analysis, IEEE Sig. Process. Mag., 32, 2, pp. 145-163, (2015); Feng Z., Guo D., Tang D., Et al., 2020. CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16–20 November 2020 (Findings of ACL), 2020, pp. 1536-1547; Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, 7th International Conference on Learning Representations, (2019); Gidel G., Jebara T., Lacoste-Julien S., Frank-Wolfe algorithms for Saddle point problems, 20th International Conference on Artificial Intelligence and Statistics AISTATS, pp. 362-371, (2017); Grohe M., 2020. word2vec, node2vec, graph2vec, X2vec: Towards a theory of vector embeddings of structured data, 39th ACM Symposium on Principles of Database Systems, pp. 1-16; Guo D., Ren S., Lu S., GraphCodeBERT: Pre-training code representations with data flow, 9th International Conference on Learning Representations, (2021); Guo X., Yao Q., Kwok J.T.-Y., Efficient Sparse low-rank tensor completion using the Frank-Wolfe algorithm, 31st AAAI Conference on Artificial Intelligence, pp. 1948-1954, (2017); Hanayama K., Matsumoto S., Kusumoto S., Humpback: Code completion system for Dockerfile based on language models (short paper), Joint Proceedings of SEED & NLPaSE co-located with 27th Asia Pacific Software Engineering Conference, pp. 67-73, (2020); Hawkins D.M., The problem of overfitting, J. Chem. Inf. Model., 44, 1, pp. 1-12, (2004); Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, 8th International Conference on Learning Representations, (2020); Hindle A., Barr E.T., Su Z., Et al., On the naturalness of software, 34th International Conference on Software Engineering, pp. 837-847, (2012); Horenko I., On a scalable entropic breaching of the overfitting barrier for small data problems in machine learning, Neural Comput, 32, 8, pp. 1563-1579, (2020); Huang R., Li K., Arora A., Efficient MDI adaptation for n-gram language models, 21st Annual Conference of the International Speech Communication Association, pp. 4916-4920, (2020); Huang Z., Li X., Ye Y., Ng M.K., MR-GCN: Multi-relational graph convolutional networks based on generalized tensor product, 29th International Joint Conference on Artificial Intelligence, pp. 1258-1264, (2020); Jaggi M., Revisiting Frank-Wolfe: Projection-free sparse convex optimization, 30th International Conference on Machine Learning, pp. 427-435, (2013); Jain P., Thakkar O., Thakurta A., Differentially private matrix completion, revisited, CoRR, (2017); Jayadeva, Sharma M., Soman S., Pant H., Ultra-sparse classifiers through minimizing the VC dimension in the empirical feature space—submitted to the special issue on “off the mainstream: Advances in neural networks and machine learning for pattern recognition, Neural Process. Lett., 48, 2, pp. 881-913, (2018); Jukic A., Filipovic M., Supervised feature extraction for tensor objects based on maximization of mutual information, Pattern Recognit. Lett., 34, 13, pp. 1476-1484, (2013); Kajo I., Kamel N.S., Ruichek Y., Self-motion-assisted tensor completion method for background initialization in complex video sequences, IEEE Trans. Image Process., 29, 2020, pp. 1915-1928, (2020); Karampatsis R.-M., Babii H., Robbes R., Sutton C., Janes A., Big code != big vocabulary: Open-vocabulary models for source code, 42nd International Conference on Software Engineering, pp. 1073-1085, (2020); Kempf D., Hess R., Muthing S., Bastian P., Automatic code generation for high-performance discontinuous Galerkin methods on modern architectures, ACM Trans. Math. Softw., 47, 1, (2021); Khaire U.M., Dhanalakshmi R., High-dimensional microarray dataset classification using an improved adam optimizer (iAdam), J. Amb. Intell. Humaniz. Comput., 11, 11, pp. 5187-5204, (2020); Khavari B., Rabusseau G., Lower and upper bounds on the VC-dimension of tensor network models, CoRR, (2021); Kilmer M.E., Martin C.D., Factorization strategies for third-order tensors, Linear Algeb. Applic., 435, 3, pp. 641-658, (2011); Kim S., Zhao J., Tian Y., Chandra S., Code prediction by feeding trees to transformers, 43rd IEEE/ACM International Conference on Software Engineering, pp. 150-162, (2021); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5th International Conference on Learning Representations, (2017); Kuo B.-C., Landgrebe D.A., A covariance estimator for small sample size classification problems and its application to feature extraction, IEEE Trans. Geosci. Rem. Sensor, 40, 4, pp. 814-819, (2002); Li J., Wang Y., Lyu M.R., King I., Code completion with neural attention and pointer networks, 27th International Joint Conference on Artificial Intelligence, pp. 4159-4165, (2018); Li X., Qiu K., Qian C., Zhao G., An adversarial machine learning method based on OpCode N-grams feature in malware detection, 5th IEEE International Conference on Data Science in Cyberspace, pp. 380-387, (2020); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, 4th International Conference on Learning Representations, (2016); Li Y., Wang S., Nguyen T.N., Vulnerability detection with fine-grained interpretations, 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 292-303, (2021); Li Z., Xing Y., Huang J., Et al., Large-scale online multi-view graph neural network and applications, Fut. Gen. Comput. Syst., 116, 2021, pp. 145-155, (2021); Li-Mei Z., Li-Shan Q., Song-Can C., A survey of feature extraction and classifier design based on tensor pattern, J. Shandong Univ. (Eng. Sci.), 39, 1, pp. 6-14, (2009); Liu F., Li G., Wei B., A self-attentional neural architecture for code completion with multi-task learning, 28th International Conference on Program Comprehension, pp. 37-47, (2020); Liu F., Li G., Zhao Y., Jin Z., Multi-task learning based pre-trained language model for code completion, 35th IEEE/ACM International Conference on Automated Software Engineering, pp. 473-485, (2020); Liu R., Lin Z., Su Z., Tang K., Feature extraction by learning Lorentzian metric tensor and its extensions, Pattern Recognit, 43, 10, pp. 3298-3306, (2010); Liu X., You X., Zhang X., Tensor graph convolutional networks for text classification, 34th AAAI Conference on Artificial Intelligence, pp. 8409-8416, (2020); Myburgh J.C., Mouton C., Davel M.H., Tracking translation invariance in CNNs, CoRR, (2021); Nguyen A.T., Nguyen T.N., Graph-based statistical language model for code, 37th IEEE/ACM International Conference on Software Engineering, pp. 858-868, (2015); Nguyen A.T., Nguyen T.T., Nguyen H.A., Graph-based pattern-oriented, context-sensitive source code completion, 34th International Conference on Software Engineering, pp. 69-79, (2012); Nguyen S., Phan H., Le T., Nguyen T.N., Suggesting natural method names to check name consistencies, 42nd International Conference on Software Engineering, pp. 1372-1384, (2020); Pandey V., Overcoming overfitting and large weight update problem in linear rectifiers: Thresholded exponential rectified linear units, CoRR, (2020); Pham N.H., Nguyen T.T., Nguyen H.A., Nguyen T.N., Detection of recurring software vulnerabilities, 25th IEEE/ACM International Conference on Automated Software Engineering, pp. 447-456, (2010); Le Quoc D., Gregor F., Arnautov S., Kunkel R., Bhatotia P., Fetzer C., 2021, CoRR; Rahman MdM., Watanobe Y., Nakamura K., A neural network based intelligent support model for program code completion, Sci. Program., 2020, 742, pp. 1-18, (2020); Ratre A., Pankajakshan V., Tucker tensor decomposition-based tracking and Gaussian mixture model for anomaly localisation and detection in surveillance videos, IET Comput. Vis., 12, 6, pp. 933-940, (2018); Romaniuk M., N-gram models for code completion in Pharo, 4th International Conference on the Art, Science, and Engineering of Programming, pp. 227-228, (2020); Russell R.L., Kim L.Y., Hamilton L.H., Et al., Automated vulnerability detection in source code using deep representation learning, 17th IEEE International Conference on Machine Learning and Applications, pp. 757-762, (2018); Schlichtkrull M.S., Kipf T.N., Bloem P., Et al., Modeling relational data with graph convolutional networks, The Semantic Web—15th International Conference, ESWC 2018, Heraklion, Crete, Greece (Lecture Notes in Computer Science), 10843, pp. 593-607, (2018); Sennrich R., Haddow B., Birch A., Neural machine translation of rare words with subword units, 54th Annual Meeting of the Association for Computational Linguistics, (2016); Sun P., Lan J., Li J., Et al., Combining deep reinforcement learning with graph neural networks for optimal VNF placement, IEEE Commun. Lett., 25, 1, pp. 176-180, (2021); Svyatkovskiy A., Zhao Y., Fu S., Sundaresan N., 25th ACM International Conference on Knowledge Discovery & Data Mining, pp. 2727-2735, (2019); Tjandra A., Sakti S., Manurung R., Gated recurrent neural tensor network, International Joint Conference on Neural Networks, pp. 448-455, (2016); Waner S., Introduction to differential geometry and general relativity, Lecture Notes by Stefan Waner, with a Special Guest Lecture, (1986); Wang H., Ye G., Tang Z., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans. Inf. Forens. Secur., 16, 2021, pp. 1943-1958, (2021); Wang W., Zhang K., Li G., Jin Z., Learning to Represent Programs with Heterogeneous Graphs, (2020); Wang Y., Wang K., Gao F., Et al., 2020, Proc. ACM Program. Lang., 4; Wu Y., Wang X., Zhang A., He X., Chua T.-S., Discovering invariant rationales for graph neural networks, 10th International Conference on Learning Representations, (2022); Xu L., Cheng L., Wong N., Wu Y.-C., Overfitting avoidance in tensor train factorization and completion: Prior analysis and inference, IEEE International Conference on Data Mining, pp. 1439-1444, (2021); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, IEEE Symposium on Security and Privacy, pp. 590-604, (2014); Yun S., Jeong M., Kim R., Et al., Graph transformer networks, Annual Conference on Neural Information Processing Systems, pp. 11960-11970, (2019); Zhang W., Lin Z., Tang X., Tensor linear Laplacian discrimination (TLLD) for feature extraction, Pattern Recognit, 42, 9, pp. 1941-1948, (2009); Zhang Y., Tino P., Leonardis A., Tang K., A survey on neural network interpretability, IEEE Trans. Emerg. Top. Comput. Intell., 5, 5, pp. 726-742, (2021); Zhou Y., Liu S., Siow J.K., Et al., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Annual Conference on Neural Information Processing Systems, pp. 10197-10207, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85168769136,179
Zhang G.; Merrill M.A.; Liu Y.; Heer J.; Althoff T.,"Zhang, Ge (59103432600); Merrill, Mike A. (57191505323); Liu, Yang (57857167100); Heer, Jeffrey (6603794736); Althoff, Tim (55430316500)",59103432600; 57191505323; 57857167100; 6603794736; 55430316500,CORAL: COde RepresentAtion learning with weakly-supervised transformers for analyzing data analysis,2022,EPJ Data Science,11,1,14,,,,3,10.1140/epjds/s13688-022-00327-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126774781&doi=10.1140%2fepjds%2fs13688-022-00327-9&partnerID=40&md5=a8e32194694d6166b5290864d0fc7867,"Large scale analysis of source code, and in particular scientific source code, holds the promise of better understanding the data science process, identifying analytical best practices, and providing insights to the builders of scientific toolkits. However, large corpora have remained unanalyzed in depth, as descriptive labels are absent and require expert domain knowledge to generate. We propose a novel weakly supervised transformer-based architecture for computing joint representations of code from both abstract syntax trees and surrounding natural language comments. We then evaluate the model on a new classification task for labeling computational notebook cells as stages in the data analysis process from data import to wrangling, exploration, modeling, and evaluation. We show that our model, leveraging only easily-available weak supervision, achieves a 38% increase in accuracy over expert-supplied heuristics and outperforms a suite of baselines. Our model enables us to examine a set of 118,000 Jupyter Notebooks to uncover common data analysis patterns. Focusing on notebooks with relationships to academic articles, we conduct the largest study of scientific code to date and find that notebooks which devote an higher fraction of code to the typically labor-intensive process of wrangling data in expectation exhibit decreased citation counts for corresponding papers. We also show significant differences between academic and non-academic notebooks, including that academic notebooks devote substantially more code to wrangling and exploring data, and less on modeling. © 2022, The Author(s).","Kluyver T., Ragan-Kelley B., Perez F., Granger B.E., Bussonnier M., Frederic J., Kelley K., Hamrick J.B., Grout J., Corlay S., Et al., Jupyter notebooks-a publishing format for reproducible computational workflows, Positioning and power in academic publishing: players, agents and agendas, (2016); Foster E.D., Deardorff A., Open science framework (OSF), J. Med. Libr. Assoc., 105, 2, pp. 203-206, (2017); Ayers P Libguides: Citing & Publishing Software: Publishing Research Software; Pradal C., Varoquaux G., Langtangen H.P., Publishing scientific software matters, J Comput Sci, 4, 5, pp. 311-312, (2013); Liu Y., Althoff T., Heer J., Paths explored, paths omitted, paths obscured: decision points & selective reporting in end-to-end data analysis, CHI, (2020); Rule A., Tabard A., Hollan J.D., Exploration and explanation in computational notebooks, CHI, (2018); Rehman M.S., Towards understanding data analysis workflows using a large notebook corpus, SIGMOD, (2019); Wang J., Li L., Zeller A., Better code, better sharing: on the need of analyzing Jupyter notebooks, ICSE, pp. 53-56, (2020); Wang J., Li L., Zeller A., Better code, better sharing: on the need of analyzing Jupyter notebooks, ICSE, (2020); Kery M.B., Radensky M., Arya M., John B.E., Myers B.A., The story in the notebook: exploratory data science using a literate programming tool, CHI, (2018); Kandel S., Paepcke A., Hellerstein J.M., Heer J., Enterprise data analysis and visualization: an interview study. TVCG, (2012); Wongsuphasawat K., Liu Y., Heer J., Goals, Process, and Challenges of Exploratory Data Analysis: An Interview Study, 1911, (2019); Alspaugh S., Zokaei N., Liu A., Jin C., Hearst M.A., Futzing and moseying: interviews with professional data analysts on exploration practices, IEEE Trans Vis Comput Graph, 25, 1, pp. 22-31, (2018); Johanson A., Hasselbring W., Software engineering for computational science: past, present, future, Comput Sci Eng, 20, pp. 90-109, (2018); Kery M.B., Horvath A., Myers B., Variolite: supporting exploratory programming by data scientists, CHI, (2017); Hill C., Bellamy R., Erickson T., Burnett M., Trials and tribulations of developers of intelligent systems: A field study, VL/HCC, pp. 162-170, (2016); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, NeurIPS, (2017); Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding, 1810, (2018); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, NeurIPS, (2013); Tai K.S., Socher R., Manning C.D., Improved semantic representations from tree-structured long short-term memory networks, Corr, 1503, (2015); Mou L., Li G., Jin Z., Zhang L., Wang T., TBCNN: A tree-based convolutional neural network for programming language processing, Corr, 1409, (2014); Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P., On the naturalness of software, ICSE, (2012); Tu Z., Su Z., Devanbu P., On the localness of software, FSE, (2014); Nguyen T.T., Nguyen A.T., Nguyen H.A., Nguyen T.N., A statistical semantic language model for source code, ESEC/FSE, (2013); Allamanis M., Sutton C., Mining source code repositories at massive scale using language modeling, 2013 10th working conference on mining software repositories (MSR), (2013); Raychev V., Vechev M., Yahav E., Code completion with statistical language models, SIGPLAN, (2014); Kwon T., Su Z., Modeling high-level behavior patterns for precise similarity analysis of software, ICDM, (2011); Movshovitz-Attias D., Cohen W., Natural language models for predicting programming comments, ACL, (2013); Bielik P., Raychev V., Vechev M., Phog: probabilistic model for code, ICML, (2016); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, SIGPLAN, pp. 404-419, (2018); Li J., Wang Y., Lyu M.R., King I., Code Completion with Neural Attention and Pointer Networks, (2017); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, 1711, (2017); Zhang Y., Xu F.F., Li S., Meng Y., Wang X., Li Q., Han J., Higitclass: keyword-driven hierarchical classification of github repositories, ICDM, pp. 876-885, (2019); Shetty M., Bansal C., Kumar S., Rao N., Nagappan N., Zimmermann T., Neural Knowledge Extraction from Cloud Service Incidents, 2007, (2020); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: learning distributed representations of code, POPL, 3, (2019); Allamanis M., Barr E., Bird C., Sutton C., Learning natural coding conventions, FSE, (2014); Acharya M., Xie T., Pei J., Xu J., Mining api patterns as partial orders from source code: from usage scenarios to specifications, ESEC/FSE, (2007); Nguyen T.D., Nguyen A.T., Phan H.D., Nguyen T.N., Exploring api embedding for api usages and applications, ICSE, (2017); Ratner A., Bach S.H., Ehrenberg H., Fries J., Wu S., Re C., Snorkel: Rapid training data creation with weak supervision, VLDB, (2019); Hamilton W., Ying Z., Leskovec J., Inductive representation learning on large graphs, NeurIPS, (2017); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks, 1609, (2016); Wu M., Pan S., Zhu X., Zhou C., Pan L., Domain-adversarial graph neural networks for text classification, ICDM, (2019); Schlichtkrull M., Kipf T.N., Bloem P., Van Den Berg R., Titov I., Welling M., Modeling relational data with graph convolutional networks, European semantic web conference, (2018); Zhang M., Chen Y., Link prediction based on graph neural networks, NeurIPS, (2018); Defferrard M., Bresson X., Vandergheynst P., Convolutional neural networks on graphs with fast localized spectral filtering, NeurIPS, (2016); Ying Z., You J., Morris C., Ren X., Hamilton W., Leskovec J., Hierarchical graph representation learning with differentiable pooling, NeurIPS, (2018); Dai H., Dai B., Song L., Discriminative embeddings of latent variable models for structured data, ICML, (2016); Duvenaud D.K., Maclaurin D., Iparraguirre J., Bombarell R., Hirzel T., Aspuru-Guzik A., Adams R.P., Convolutional networks on graphs for learning molecular fingerprints, NeurIPS, (2015); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Trans Neural Netw, 20, 1, pp. 61-80, (2008); Battaglia P.W., Hamrick J.B., Bapst V., Sanchez-Gonzalez A., Zambaldi V., Malinowski M., Tacchetti A., Raposo D., Santoro A., Faulkner R., Et al., Relational Inductive Biases, Deep Learning, and Graph Networks, 1806, (2018); Fernandes P., Allamanis M., Brockschmidt M., Structured Neural Summarization, 1811, (2018); Brockschmidt M., Allamanis M., Gaunt A.L., Polozov O., Generative Code Modeling with Graphs, 1805, (2018); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph Attention Networks, 1710, (2017); Chen L., Ali Babar M., Nuseibeh B., Characterizing architecturally significant requirements, IEEE Softw, 30, pp. 38-45, (2013); Anonymous CORAL: Code Representation Learning with Weakly-Supervised Transformers for Analyzing Data Analysis; Agashe R., Iyer S., Zettlemoyer L., JuICe: a large scale distantly supervised dataset for open domain context-based code generation, Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP), pp. 5435-5445, (2019); Pimentel J.F., Murta L., Braganholo V., Freire J., A large-scale study about quality and reproducibility of Jupyter notebooks, 2019 IEEE/ACM 16th international conference on mining software repositories (MSR), pp. 507-517, (2019); Jetbrains Data Science in 2018, (2018); Kelley K., Granger B., Jupyter frontends: From the classic jupyter notebook to jupyterlab, nteract, and beyond, Jupytercon, (2017); Landis J., Koch G., The measurement of observer agreement for categorical data, Biometrics, 33, 1, pp. 159-174, (1977); Krippendorff K., Content analysis: an introduction to its methodology, (2004); Gilmer J., Schoenholz S.S., Riley P.F., Vinyals O., Dahl G.E., Neural message passing for quantum chemistry, ICML, (2017); Ba J.L., Kiros J.R., Hinton GE (2016), Layer Normalization, (1607); Weston J., Bengio S., Usunier N., Wsabie: scaling up to large vocabulary image annotation, IJCAI, (2011); Socher R., Karpathy A., Le Q.V., Manning C.D., Ng A.Y., Grounded compositional semantics for finding and describing images with sentences, TACL, (2014); Iyyer M., Guha A., Chaturvedi S., Boyd-Graber J., Daume H., Feuding families and former friends: unsupervised learning for dynamic fictional relationships, NAACL-HLT, (2016); He R., Lee W.S., Ng H.T., Dahlmeier D., An unsupervised neural attention model for aspect extraction, ACL, (2017); Blei D.M., Ng A.Y., Jordan M.I., Latent Dirichlet allocation, J Mach Learn Res, 3, pp. 993-1022, (2003); Merrill M.A., Zhang G., Althoff T., MULTIVERSE: mining collective data science knowledge from code on the web to suggest alternative analysis approaches, Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining, pp. 1212-1222, (2021); Chen M., Tworek J., Jun H., Yuan Q., Pinto H., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Ray A., Puri R., Krueger G., Petrov M., Khlaaf H., Sastry G., Mishkin P., Chan B., Gray S., Ryder N., Pavlov M., Power A., Kaiser L., Bavarian M., Winter C., Tillet P., Such F.P., Cummings D., Plappert M., Chantzis F., Barnes E., Herbert-Voss A., Guss W.H., Nichol A., Paino A., Tezak N., Tang J., Babuschkin I., Balaji S., Jain S., Saunders W., Hesse C., Carr A.N., Leike J., Achiam J., Misra V., Morikawa E., Radford A., Knight M., Brundage M., Murati M., Mayer K., Welinder P., McGrew B., Amodei D., McCandlish S., Sutskever I., Zaremba W., Evaluating Large Language Models Trained on Code, (2021); Lo K., Wang L.L., Neumann M., Kinney R., Weld D.S., S2ORC: the semantic scholar open research corpus, ACL, (2020)",,,,,,English,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85126774781,180
Zügner D.; Kirschstein T.; Catasta M.; Leskovec J.; Günnemann S.,"Zügner, Daniel (57188995298); Kirschstein, Tobias (57195935362); Catasta, Michele (25649295200); Leskovec, Jure (12241436100); Günnemann, Stephan (35242528700)",57188995298; 57195935362; 25649295200; 12241436100; 35242528700,LANGUAGE-AGNOSTIC REPRESENTATION LEARNING OF SOURCE CODE FROM STRUCTURE AND CONTEXT,2021,ICLR 2021 - 9th International Conference on Learning Representations,,,,,,,73,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149138769&partnerID=40&md5=4e233116ed104a3bb5d58e031d653e5b,"Source code (Context) and its parsed abstract syntax tree (AST; Structure) are two complementary representations of the same computer program. Traditionally, designers of machine learning models have relied predominantly either on Structure or Context. We propose a new model, which jointly learns on Context and Structure of source code. In contrast to previous approaches, our model uses only language-agnostic features, i.e., source code and features that can be computed directly from the AST. Besides obtaining state-of-the-art on monolingual code summarization on all five programming languages considered in this work, we propose the first multilingual code summarization model. We show that jointly training on non-parallel data from multiple programming languages improves results on all individual languages, where the strongest gains are on low-resource languages. Remarkably, multilingual training only from Context does not lead to the same improvements, highlighting the benefits of combining Structure and Context for representation learning on code. © 2021 ICLR 2021 - 9th International Conference on Learning Representations. All rights reserved.","Acharya Mithun, Xie Tao, Pei Jian, Xu Jun, Mining api patterns as partial orders from source code: From usage scenarios to specifications, Proceedings of the the 6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering, ESEC-FSE'07, pp. 25-34, (2007); Allamanis Miltiadis, Barr Earl T., Bird Christian, Sutton Charles, Learning natural coding conventions, Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering, FSE 2014, pp. 281-293; Allamanis Miltiadis, Barr Earl T., Bird Christian, Sutton Charles, Suggesting accurate method and class names, Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2015, pp. 38-49, (2015); Allamanis Miltiadis, Peng Hao, Sutton Charles, A convolutional attention network for extreme summarization of source code, International conference on machine learning, pp. 2091-2100, (2016); Allamanis Miltiadis, Brockschmidt Marc, Khademi Mahmoud, Learning to represent programs with graphs, International Conference on Learning Representations, (2018); Alon Uri, Zilberstein Meital, Levy Omer, Yahav Eran, A general path-based representation for predicting program properties, Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2018, pp. 404-419, (2018); Alon Uri, Brody Shaked, Levy Omer, Yahav Eran, code2seq: Generating sequences from structured representations of code, International Conference on Learning Representations, (2019); Alon Uri, Zilberstein Meital, Levy Omer, Yahav Eran, code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, pp. 1-29, (2019); Battaglia Peter W, Hamrick Jessica B, Bapst Victor, Sanchez-Gonzalez Alvaro, Zambaldi Vinicius, Malinowski Mateusz, Tacchetti Andrea, Raposo David, Santoro Adam, Faulkner Ryan, Et al., Relational inductive biases, deep learning, and graph networks, (2018); Bhoopchand Avishkar, Rocktaschel Tim, Barr Earl, Riedel Sebastian, Learning python code suggestion with a sparse pointer network, (2016); Bichsel Benjamin, Raychev Veselin, Tsankov Petar, Vechev Martin, Statistical deobfuscation of android applications, Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, CCS'16, pp. 343-355, (2016); Bielik Pavol, Raychev Veselin, Vechev Martin, Phog: probabilistic model for code, International Conference on Machine Learning, pp. 2933-2942, (2016); Bojchevski Aleksandar, Klicpera Johannes, Perozzi Bryan, Kapoor Amol, Blais Martin, Rozemberczki Benedek, Lukasik Michal, Gunnemann Stephan, Scaling graph neural networks with approximate pagerank, Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery amp; Data Mining, KDD'20, pp. 2464-2473, (2020); Bourgeois Dylan, Learning representations of source code from structure and context, (2019); Conneau Alexis, Lample Guillaume, Cross-lingual language model pretraining, Advances in Neural Information Processing Systems, 32, pp. 7059-7069, (2019); Dai Hanjun, Dai Bo, Song Le, Discriminative embeddings of latent variable models for structured data, International conference on machine learning, pp. 2702-2711, (2016); Dai Zihang, Yang Zhilin, Yang Yiming, Carbonell Jaime, Le Quoc V, Salakhutdinov Ruslan, Transformer-xl: Attentive language models beyond a fixed-length context, (2019); Dam Hoa Khanh, Tran Truyen, Pham Trang, A deep language model for software code, FSE 2016: Proceedings of the Foundations Software Engineering International Symposium [The Conference], (2016); Defferrard Michael, Bresson Xavier, Vandergheynst Pierre, Convolutional neural networks on graphs with fast localized spectral filtering, Advances in neural information processing systems, pp. 3844-3852, (2016); Duvenaud David K, Maclaurin Dougal, Iparraguirre Jorge, Bombarell Rafael, Hirzel Timothy, Aspuru-Guzik Alan, Adams Ryan P, Convolutional networks on graphs for learning molecular fingerprints, Advances in neural information processing systems, pp. 2224-2232, (2015); Fernandes Patrick, Allamanis Miltiadis, Brockschmidt Marc, Structured neural summarization, International Conference on Learning Representations, (2019); Gori Marco, Monfardini Gabriele, Scarselli Franco, A new model for learning in graph domains, Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005, 2, pp. 729-734; Hamilton William L., Ying Rex, Leskovec Jure, Inductive representation learning on large graphs, NIPS, (2017); Hellendoorn Vincent J., Sutton Charles, Singh Rishabh, Maniatis Petros, Bieber David, Global relational models of source code, International Conference on Learning Representations, (2020); Hindle Abram, Barr Earl T., Su Zhendong, Gabel Mark, Devanbu Premkumar, On the naturalness of software, Proceedings of the 34th International Conference on Software Engineering, ICSE'12, pp. 837-847, (2012); Hochreiter Sepp, Schmidhuber Jurgen, Long short-term memory, Neural computation, 9, 8, pp. 1735-1780, (1997); Hu Weihua, Fey Matthias, Zitnik Marinka, Dong Yuxiao, Ren Hongyu, Liu Bowen, Catasta Michele, Leskovec Jure, Open graph benchmark: Datasets for machine learning on graphs, Advances in Neural Information Processing Systems, 33, pp. 22118-22133, (2020); Husain Hamel, Wu Ho-Hsiang, Gazit Tiferet, Allamanis Miltiadis, Brockschmidt Marc, Codesearchnet challenge: Evaluating the state of semantic code search, (2019); Kanade Aditya, Maniatis Petros, Balakrishnan Gogul, Shi Kensen, Learning and evaluating contextual embedding of source code, Proceedings of the 37th International Conference on Machine Learning, (2020); Kipf Thomas N., Welling Max, Semi-supervised classification with graph convolutional networks, International Conference on Learning Representations (ICLR), (2017); Klicpera Johannes, Bojchevski Aleksandar, Gunnemann Stephan, Predict then propagate: Graph neural networks meet personalized pagerank, International Conference on Learning Representations (ICLR), (2019); Klicpera Johannes, Weissenberger Stefan, Gunnemann Stephan, Diffusion improves graph learning, Conference on Neural Information Processing Systems (NeurIPS), (2019); Klicpera Johannes, Gross Janek, Gunnemann Stephan, Directional message passing for molecular graphs, International Conference on Learning Representations (ICLR), (2020); Li Jian, Wang Yue, Lyu Michael R, King Irwin, Code completion with neural attention and pointer networks, (2017); Li Yujia, Tarlow Daniel, Brockschmidt Marc, Zemel Richard, Gated graph sequence neural networks, (2015); van der Maaten Laurens, Hinton Geoffrey, Visualizing data using t-sne, Journal of machine learning research, 9, pp. 2579-2605, (2008); Maddison Chris, Tarlow Daniel, Structured generative models of natural source code, International Conference on Machine Learning, pp. 649-657, (2014); Mou Lili, Li Ge, Zhang Lu, Wang Tao, Jin Zhi, Convolutional neural networks over tree structures for programming language processing, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, AAAI'16, pp. 1287-1293, (2016); Nguyen Trong Duc, Nguyen Anh Tuan, Phan Hung Dang, Nguyen Tien N., Exploring api embedding for api usages and applications, Proceedings of the 39th International Conference on Software Engineering, ICSE'17, pp. 438-449, (2017); Page Lawrence, Brin Sergey, Motwani Rajeev, Winograd Terry, The pagerank citation ranking: Bringing order to the web, (1999); Radford Alec, Wu Jeffrey, Child Rewon, Luan David, Amodei Dario, Sutskever Ilya, Language models are unsupervised multitask learners, OpenAI Blog, 1, 8, (2019); Raychev Veselin, Vechev Martin, Yahav Eran, Code completion with statistical language models, Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI'14, pp. 419-428, (2014); Scarselli Franco, Gori Marco, Chung Tsoi Ah, Hagenbuchner Markus, Monfardini Gabriele, The graph neural network model, IEEE Transactions on Neural Networks, 20, 1, pp. 61-80, (2008); Schlichtkrull Michael, Kipf Thomas N., Bloem Peter, van den Berg Rianne, Titov Ivan, Welling Max, Modeling relational data with graph convolutional networks, The Semantic Web, pp. 593-607, (2018); Shaw Peter, Uszkoreit Jakob, Vaswani Ashish, Self-attention with relative position representations, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pp. 464-468, (2018); Shen Yikang, Tan Shawn, Sordoni Alessandro, Courville Aaron, Ordered neurons: Integrating tree structures into recurrent neural networks, International Conference on Learning Representations, (2019); Shiv Vighnesh, Quirk Chris, Novel positional encodings to enable tree-based transformers, Advances in Neural Information Processing Systems, pp. 12081-12091, (2019); Socher Richard, Perelygin Alex, Wu Jean, Chuang Jason, Manning Christopher D, Ng Andrew Y, Potts Christopher, Recursive deep models for semantic compositionality over a sentiment treebank, Proceedings of the 2013 conference on empirical methods in natural language processing, pp. 1631-1642, (2013); Tai Kai Sheng, Socher Richard, Manning Christopher D, Improved semantic representations from tree-structured long short-term memory networks, (2015); Vaswani Ashish, Shazeer Noam, Parmar Niki, Uszkoreit Jakob, Jones Llion, Gomez Aidan N, Kaiser Lukasz, Polosukhin Illia, Attention is all you need, Advances in neural information processing systems, pp. 5998-6008, (2017); Velickovic Petar, Cucurull Guillem, Casanova Arantxa, Romero Adriana, Lio Pietro, Bengio Yoshua, Graph Attention Networks, International Conference on Learning Representations, (2018); Vinyals Oriol, Fortunato Meire, Jaitly Navdeep, Pointer networks, Advances in neural information processing systems, pp. 2692-2700, (2015); Wang Song, Chollak Devin, Movshovitz-Attias Dana, Tan Lin, Bugram: Bug detection with n-gram language models, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, ASE 2016, pp. 708-719; Xu Keyulu, Hu Weihua, Leskovec Jure, Jegelka Stefanie, How powerful are graph neural networks?, International Conference on Learning Representations, (2019); Yang Zhilin, Dai Zihang, Yang Yiming, Carbonell Jaime, Salakhutdinov Russ R, Le Quoc V, Xlnet: Generalized autoregressive pretraining for language understanding, Advances in neural information processing systems, pp. 5754-5764, (2019); Ying Zhitao, You Jiaxuan, Morris Christopher, Ren Xiang, Hamilton Will, Leskovec Jure, Hierarchical graph representation learning with differentiable pooling, Advances in neural information processing systems, pp. 4800-4810, (2018); You Jiaxuan, Ying Rex, Leskovec Jure, Position-aware graph neural networks, Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pp. 7134-7143, (2019); Zhang Muhan, Chen Yixin, Link prediction based on graph neural networks, Advances in Neural Information Processing Systems, pp. 5165-5175, (2018)",Amazon; DeepMind; et al.; Facebook AI; Microsoft; OpenAI,"9th International Conference on Learning Representations, ICLR 2021",3 May 2021 through 7 May 2021,"Virtual, Online",186703,English,Conference paper,Final,,Scopus,2-s2.0-85149138769,182
Tang B.; Li B.; Bo L.; Wu X.; Cao S.; Sun X.,"Tang, Ben (57214680006); Li, Bin (56342840400); Bo, Lili (57204660270); Wu, Xiaoxue (56650282600); Cao, Sicong (57222584216); Sun, Xiaobing (24829988300)",57214680006; 56342840400; 57204660270; 56650282600; 57222584216; 24829988300,GrasP: Graph-to-Sequence Learning for Automated Program Repair,2021,"IEEE International Conference on Software Quality, Reliability and Security, QRS",2021-December,,,819,828,9,2,10.1109/QRS54544.2021.00091,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146199863&doi=10.1109%2fQRS54544.2021.00091&partnerID=40&md5=6bc06b1dda865890b178f523886edc45,"Many deep learning models, for example, neural machine translation (NMT) models, have been developed for Automated Program Repair (APR). Due to the advantages of NMT model's strong generalization ability and less manual in-tervention, NMT-based methods perform well in APR. However, previous NMT-based APR approaches regard a code snippet as a sequence of tokens, which ignores the inherent structure of code. In this paper, we propose a novel end-to-end approach with Graph-to-Sequence learning, GrasP, to generate patches for buggy methods. To better represent the buggy method, we use a graph based on abstract syntax tree (AST) to represent the source code. In order to learn complex graph representation, we introduce the attention-based encoder-decoder model for graph-to-sequence learning. The empirical evaluation on the popular benchmark Defects4J shows that GrasP can generate compilable patches for 75 bugs, of which 34 patches are correct. © 2021 IEEE.","Sun X., Zhou T., Wang R., Duan Y., Bo L., Chang J., Experience report: investigating bug fixes in machine learning frameworks/libraries, Frontiers Comput. Sci, 15, 6, (2021); Lu J., Sun X., Li B., Bo L., Zhang T., BEAT: considering question types for bug question answering via templates, Knowl. Based Syst, 225, (2021); Cao S., Sun X., Bo L., Wei Y., Li B., BGNN4VD: Constructing bidirectional graph neural-network for vulnerability detection, Inf. Softw. Technol, 136, (2021); Sun X., Peng X., Li B., Li B., Wen W., IPSETFUL: an iterative process of selecting test cases for effective fault localization by exploring concept lattice of program spectra, Frontiers Comput. Sci, 10, 5, pp. 812-831, (2016); Ni Z., Li B., Sun X., Chen T., Tang B., Shi X., Analyzing bug fix for automatic bug cause classification, J. Syst. Softw, 163, (2020); Goues C. L., Pradel M., Roychoudhury A., Chandra S., Automatic program repair, IEEE Softw, 38, 4, pp. 22-27, (2021); Shariffdeen R. S., Noller Y., Grunske L., Roychoudhury A., Concolic program repair, PLDI '21: 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation, pp. 390-405, (2021); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., An empirical investigation into learning bug-fixing patches in the wild via neural machine translation, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 832-837, (2018); Chen Z., Kommrusch S. J., Tufano M., Pouchet L.-N., Poshyvanyk D., Monperrus M., Sequencer: Sequence-to-sequence learning for endto-end program repair, IEEE Transactions on Software Engineering, (2019); Lutellier T., Pham H. V., Pang L., Li Y., Wei M., Tan L., Coconut: Combining context-aware neural translation models using ensemble for program repair, Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 101-114, (2020); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, (2017); Xu K., Wu L., Wang Z., Feng Y., Witbrock M., Sheinin V., Graph2seq: Graph to sequence learning with attention-based neural networks, (2018); Just R., Jalali D., Ernst M. D., Defects4j: A database of existing faults to enable controlled testing studies for java programs, Proceedings of the 2014 International Symposium on Software Testing and Analysis, pp. 437-440, (2014); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2073-2083, (2016); Vinyals O., Fortunato M., Jaitly N., Pointer networks, Advances in Neural Information Processing Systems, 28, pp. 2692-2700, (2015); Jiang N., Lutellier T., Tan L., Cure: Code-aware neural machine translation for automatic program repair, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, pp. 1161-1173, (2021); Li Y., Wang S., Nguyen T. N., Dlfix: Context-based code transformation learning for automated program repair, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 602-614, (2020); Falleri J., Morandat F., Blanc X., Martinez M., Monperrus M., Fine-grained and accurate source code differencing, ACM/IEEE International Conference on Automated Software Engineering, ASE '14, pp. 313-324, (2014); Wiseman S., Rush A. M., Sequence-to-sequence learning as beamsearch optimization, (2016); Liu K., Koyuncu A., Kim D., Bissyande T. F., Tbar: Revisiting template-based automated program repair, Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 31-42, (2019); Wilt C. M., Thayer J. T., Ruml W., A comparison of greedy search algorithms, third annual symposium on combinatorial search, (2010); Xuan J., Martinez M., Demarco F., Clement M., Marcote S. L., Durieux T., Le Berre D., Monperrus M., Nopol: Automatic repair of conditional statement bugs in java programs, IEEE Transactions on Software Engineering, 43, 1, pp. 34-55, (2016); Qi Z., Long F., Achour S., Rinard M., An analysis of patch plausibility and correctness for generate-and-validate patch generation systems, Proceedings of the 2015 International Symposium on Software Testing and Analysis, pp. 24-36, (2015); Le Goues C., Nguyen T., Forrest S., Weimer W., Genprog: A generic method for automatic software repair, Ieee transactions on software engineering, 38, 1, pp. 54-72, (2011); Koyuncu A., Liu K., Bissyande T. F., Kim D., Klein J., Monperrus M., Le Traon Y., Fixminer: Mining relevant fix patterns for automated program repair, Empirical Software Engineering, pp. 1-45, (2020); Chakraborty S., Allamanis M., Ray B., Codit: Code editing with tree-based neural machine translation, (2018)",,"21st International Conference on Software Quality, Reliability and Security, QRS 2021",6 December 2021 through 10 December 2021,Hainan,177710,English,Conference paper,Final,,Scopus,2-s2.0-85146199863,183
Liu L.; Nguyen H.; Karypis G.; Sengamedu S.,"Liu, Linfeng (57216865169); Nguyen, Hoan (55459278800); Karypis, George (15069396800); Sengamedu, Srinivasan (23135605300)",57216865169; 55459278800; 15069396800; 23135605300,Universal Representation for Code,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12714 LNAI,,,16,28,12,4,10.1007/978-3-030-75768-7_2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111035967&doi=10.1007%2f978-3-030-75768-7_2&partnerID=40&md5=4ef743435f71959828255e3974d6b29c,"Learning from source code usually requires a large amount of labeled data. Despite the possible scarcity of labeled data, the trained model is highly task-specific and lacks transferability to different tasks. In this work, we present effective pre-training strategies on top of a novel graph-based code representation, to produce universal representations for code. Specifically, our graph-based representation captures important semantics between code elements (e.g., control flow and data flow). We pre-train graph neural networks on the representation to extract universal code properties. The pre-trained model then enables the possibility of fine-tuning to support various downstream applications. We evaluate our model on two real-world datasets – spanning over 30M Java methods and 770K Python methods. Through visualization, we reveal discriminative properties in our universal code representation. By comparing multiple benchmarks, we demonstrate that the proposed framework achieves state-of-the-art results on method name prediction and code graph link prediction. © 2021, Springer Nature Switzerland AG.","Dinella E., Dai H., Li Z., Naik M., Song L., Wang K., Hoppity: Learning Graph Transformations to Detect and Fix Bugs in Programs, (2019); Cambronero J., Li H., Kim S., Sen K., Chandra S., When deep learning met code search, ESEC/FSE, pp. 964-974, (2019); Raychev V., Vechev M., Yahav E., Code completion with statistical language models, PLDI, pp. 419-428, (2014); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, (2018); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional Neural Networks over Tree Structures for Programming Language Processing, (2016); Hu W., Et al., Open Graph Benchmark: Datasets for Machine Learning on Graphs, (2020); Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P., On the naturalness of software, ICSE, Pp. 837–847. IEEE, (2012); Ioannidis V.N., Zheng D., Karypis G., PanRep: Universal node embeddings for heterogeneous graphs, DLG-KDD, (2020); Wu Z., Pan S., Chen F., Long G., Zhang C., Philip S.Y., A Comprehensive Survey on Graph Neural Networks. In: TNNLS, (2020); Hu W., Et al., Strategies for Pre-Training Graph Neural Networks, (2020); Jin W., Et al., Self-Supervised Learning on Graphs: Deep Insights and New Direction. Arxiv Preprint, (2020); Kanade A., Maniatis P., Balakrishnan G., Shi K., Learning and Evaluating Contextual Embedding of Source Code, (2020); Feng Z., Et al., Codebert: A Pre-Trained Model for Programming and Natural Languages, (2020); Svyatkovskiy A., Deng S.K., Fu S., Sundaresan N., IntelliCode compose: Code generation using transformer, ESEC/FSE, (2020); Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating Sequences from Structured Representations of Code, (2019); Ferrante J., Ottenstein K.J., Warren J.D., The Program Dependence Graph and Its Use in Optimization, (1987); Ahmed N.K., Neville J., Rossi R.A., Duffield N.G., Willke T.L., Graphlet decomposition: Framework, algorithms, and applications, KAIS, 50, 3, pp. 689-722, (2017); Zhang Y., Yang Q., A Survey on Multi-Task Learning, (2017); Bojanowski P., Grave E., Joulin A., Mikolov T., Enriching word vectors with subword information, TACL, 5, pp. 135-146, (2017); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, (2015); Wang M., Et al., Deep graph library: A graph-centric, highly-performant package for graph neural networks, Arxiv, (2019); van der Maaten L., Hinton G., Visualizing Data Using T-Sne. JMLR 9, pp. 2579-2605, (2008); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, (2016); Yang B., Yih W.-T., He X., Gao J., Deng L., Embedding Entities and Relations for Learning and Inference in Knowledge Bases, (2015)",,"25th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2021",11 May 2021 through 14 May 2021,"Virtual, Online",260369,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85111035967,184
Du Y.; Yu Z.,"Du, Yali (57226543642); Yu, Zhongxing (7404345847)",57226543642; 7404345847,Pre-training Code Representation with Semantic Flow Graph for Effective Bug Localization,2023,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,,,579,591,12,2,10.1145/3611643.3616338,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171247925&doi=10.1145%2f3611643.3616338&partnerID=40&md5=e08baefee4d93ec33ea9e8ad9a0cf336,"Enlightened by the big success of pre-training in natural language processing, pre-trained models for programming languages have been widely used to promote code intelligence in recent years. In particular, BERT has been used for bug localization tasks and impressive results have been obtained. However, these BERT-based bug localization techniques suffer from two issues. First, the pre-trained BERT model on source code does not adequately capture the deep semantics of program code. Second, the overall bug localization models neglect the necessity of large-scale negative samples in contrastive learning for representations of changesets and ignore the lexical similarity between bug reports and changesets during similarity estimation. We address these two issues by 1) proposing a novel directed, multiple-label code graph representation named Semantic Flow Graph (SFG), which compactly and adequately captures code semantics, 2) designing and training SemanticCodeBERT based on SFG, and 3) designing a novel Hierarchical Momentum Contrastive Bug Localization technique (HMCBL). Evaluation results show that our method achieves state-of-the-art performance in bug localization. © 2023 ACM.","Allamanis M., Barr E.T., Bird C., Sutton C., Learning Natural Coding Conventions, Proceedings of the 22nd ACM SIGSOFT In-ternational Symposium on Foundations of Software Engineering, (2014); Allamanis M., Barr E.T., Devanbu P., Sutton C., A Survey of Machine Learning for Big Code and Naturalness, ACM Comput. Surv, (2018); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, International Conference on Learning Representations, (2018); Allamanis M., Sutton C., Mining Idioms from Source Code, Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering, (2014); Alon U., Zilberstein M., Levy O., Yahav E., A General Path-Based Representation for Predicting Program Properties, SIGPLAN Not, (2018); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning Distributed Representations of Code, Proc. ACM Program. Lang. POPL, (2019); Ben-Nun T., Jakobovits A.S., Hoe-Er T., Neural Code Comprehension: A Learnable Representation of Code Semantics, Proceedings of the 32nd International Conference on Neural Information Processing Systems. Curran Associates Inc, (2018); Bichsel B., Raychev V., Tsankov P., Vechev M., Statistical Deobfuscation of Android Applications, Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, (2016); Bui N.D.Q., Yu Y., Jiang L., Self-Supervised Contrastive Learning for Code Retrieval and Summarization via Semantic-Preserving Transformations, The 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, Virtual Event. ACM, (2021); Buratti L., Pujar S., Bornea M., McCarley S., Zheng Y., Rossiello G., Morari A., Laredo J., Thost V., Zhuang Y., Et al., Exploring software naturalness through neural language models, (2020); Cao X., Shi Y., Wang J., Yu H., Wang X., Yan Z., Cross-modal Knowledge Graph Contrastive Learning for Machine Learning Method Recommendation, MM '22: The 30th ACM International Conference on Multimedia. ACM, (2022); Chae K., Oh H., Heo K., Yang H., Automatically Generating Features for Learning Program Analysis Heuristics for C-like Languages, Proc. ACM Program. Lang, (2017); Chen Q., Lacomis J., Schwartz E.J., Neubig G., Vasilescu B., Le Goues C., VarCLR: Variable Semantic Representation Pre-training via Contrastive Learning, 44th IEEE/ACM 44th International Conference on Software Engineering. ACM, (2022); Chen T., Kornblith S., Norouzi M., Hinton G., A simple framework for contrastive learning of visual representations, Interna-tional conference on machine learning. PMLR, (2020); Chen X., Fan H., Girshick R.B., He K., Improved Baselines with Momentum Contrastive Learning, (2020); Cho H., Seol J., Lee S., Masked Contrastive Learning for Anomaly Detection, Proceedings of the Thirtieth International Joint Conference on Arti-cial Intelligence, Virtual Event / Montreal. ijcai.org, (2021); Ciborowska A., Damevski K., Fast changeset-based bug localization with BERT, 2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE), (2022); Ciborowska A., Decker M.J., Damevski K., Online Adaptable Bug Localization for Rapidly Evolving Software, (2022); Cummins C., Petoumenos P., Wang Z., Leather H., End-to-End Deep Learning of Optimization Heuristics, 2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT), (2017); David Y., Alon U., Yahav E., Neural reverse engineering of stripped binaries using augmented control-ow graphs, Proceedings of the ACM on Programming Languages, (2020); Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, (2018); Du Y., Wei Y., Ji W., Liu F., Luo X., Nie L., Multi-queue Momentum Contrast for Microvideo-Product Retrieval, Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining, WSDM 2023, (2023); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., Codebert: A pre-trained model for programming and natural languages, (2020); Guo D., Lu S., Duan N., Wang Y., Zhou M., Yin J., UniXcoder: Uni-ed Cross-Modal Pre-training for Code Representation; Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Deng S.K., Clement C.B., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., Graphcodebert: Pre-training code representations with data-ow, (2021); Guo J., Cheng J., Cleland-Huang J., Semantically Enhanced Software Traceability Using Deep Learning Techniques, 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE), (2017); Gupta R., Pal S., Kanade A., Shevade S., DeepFix: Fixing Common C Language Errors by Deep Learning, Proceedings of the Thirty-First AAAI Conference on Arti-cial Intelligence. AAAI Press, (2017); He K., Fan H., Wu Y., Xie S., Girshick R., Momentum contrast for unsupervised visual representation learning, Proceed-ings of the IEEE/CVF conference on computer vision and pattern recognition, (2020); Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P., On the Naturalness of Software, Proceedings of the 34th International Conference on Software Engineering, (2012); Hu X., Wei Y., Li G., Jin Z., CodeSum: Translate Program Language to Natural Language, (2017); Huo X., Li M., Zhou Z., Control Flow Graph Embedding Based on Multi-Instance Decomposition for Bug Localization, The Thirty-Fourth AAAI Conference on Arti-cial Intelligence, AAAI 2020, (2020); Huo X., Thung F., Li M., Lo D., Shi S., Deep transfer bug localization, IEEE Transactions on software engineering, (2019); Husain H., Wu H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet challenge: Evaluating the state of semantic code search, (2019); Io-E S., Szegedy C., Batch normalization: Accelerating deep network training by reducing internal covariate shift, International conference on machine learning, (2015); Jiang X., Zheng Z., Lyu C., Li L., Lyu L., Treebert: A tree-based pre-trained model for programming language, Uncertainty in Arti-cial Intelligence. PMLR, (2021); Johnson J., Douze M., Jegou H., Billion-scale similarity search with GPUS, IEEE Transactions on Big Data, (2019); Jones J.A., Harrold M.J., Empirical evaluation of the tarantula automatic fault-localization technique, Proceedings of the 20th IEEE/ACM international Conference on Automated software engineering, (2005); Kanade A., Maniatis P., Balakrishnan G., Shi K., Pretrained contextual embedding of source code, (2019); Kang M., Park J., ContraGAN: Contrastive Learning for Conditional Image Generation, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, (2020); Khattab O., Zaharia M., ColBERT: E-cient and E-ective Passage Search via Contextualized Late Interaction over BERT, Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval. ACM, (2020); Kim D., Tao Y., Kim S., Zeller A., Where should we-x this bug.a two-phase recommendation model, IEEE transactions on software Engineering, (2013); Kim K., Ghatpande S., Liu K., Koyuncu A., Kim D., Bissyande T.F., Klein J., Le Traon Y., DigBug-Pre/post-processing operator selection for accurate bug localization, Journal of Systems and Software, (2022); Kremenek T., Ng A.Y., Engler D., A Factor Graph Model for Software Bug Finding, Proceedings of the 20th International Joint Conference on Arti-cal Intelligence, (2007); Lam A.N., Nguyen A.T., Nguyen H.A., Nguyen T.N., Bug localization with combination of deep learning and information retrieval, 2017 IEEE/ACM 25th International Conference on Program Comprehension (ICPC), (2017); Lan H., Chen L., Li B., Accelerated Device Placement Optimization with Contrastive Learning, ICPP 2021: 50th International Conference on Parallel Processing. ACM, (2021); Li Z., Jiang Z., Chen X., Cao K., Gu Q., Laprob: A label propagation-based software bug localization method, Information and Software Technology, (2021); Lin J., Liu Y., Zeng Q., Jiang M., Cleland-Huang J., Traceability Transformed: Generating More Accurate Links with Pre-Trained BERT Models, Proceedings of the 43rd International Conference on Software Engineering, (2021); Liu C., Yan X., Fei L., Han J., Midki- S.P., SOBER: Statistical model-based bug localization, ACM SIGSOFT Software Engineering Notes, (2005); Loshchilov I., Hutter F., DecoupledWeight Decay Regularization, 7th International Conference on Learning Representations. OpenReview.net, (2019); Lou Y., Zhu Q., Dong J., Li X., Sun Z., Hao D., Zhang L., Zhang L., Boosting coverage-based fault localization via graphbased representation learning, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, (2021); Ma Y., Du Y., Li M., Capturing the Long-Distance Dependency in the Control Flow Graph via Structural-Guided Attention for Bug Localization, Proceedings of the Thirty-Second International Joint Conference on Arti-cial Intelligence, IJCAI 2023, (2023); Ma Y., Li M., The-owing nature matters: Feature learning from the control-ow graph of source code for bug localization, Mach. Learn, (2022); Ma Y., Li M., Learning from the Multi-Level Abstraction of the Control Flow Graph via Alternating Propagation for Bug Localization, IEEE International Conference on Data Mining. IEEE, (2022); Maas A.L., Hannun A.Y., Ng A.Y., Et al., Recti-er nonlinearities improve neural network acoustic models, Proc. icml, (2013); Mahajan G., Chaudhary N., Design and development of novel hybrid optimization-based convolutional neural network for software bug localization, Soft Computing, (2022); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional Neural Networks over Tree Structures for Programming Language Processing, Pro-ceedings of the Thirtieth AAAI Conference on Arti-cial Intelligence. AAAI Press, (2016); Murali V., Gross L., Qian R., Chandra S., Industry-scale IR-based bug localization: A perspective from Facebook, 2021 IEEE/ACM 43rd International Conference on Software Engineering: Software Engi-neering in Practice, (2021); Ni C., Wang W., Yang K., Xia X., Liu K., Lo D., The best of both worlds: Integrating semantic features with expert features for defect prediction and localization, Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, (2022); Van Den Oord A., Li Y., Vinyals O., Representation learning with contrastive predictive coding, (2018); Papadakis M., Le Traon Y., Metallaxis-FL: Mutation-based fault localization, Software Testing, Veri-cation and Reliability, (2015); Pawlak R., Monperrus M., Petitprez N., Noguera C., Seinturier L., Spoon: A Library for Implementing Analyses and Transformations of Java Source Code, Software: Practice and Experience, (2015); Pradel M., Murali V., Qian R., Machalica M., Meijer E., Chandra S., Sca-e: Bug localization on millions of-les, Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, (2020); Pradel M., Sen K., DeepBugs: A Learning Approach to Name-Based Bug Detection, Proc. ACM Program. Lang, (2018); Qi B., Sun H., Yuan W., Zhang H., Meng X., DreamLoc: A Deep Relevance Matching-Based Framework for bug Localization, IEEE Transactions on Reliability, (2022); Qi S., Jin R., Paik J., eMoCo: Sentence Representation Learning With Enhanced Momentum Contrast, Proceedings of the 5th International Conference on Computer Science and Software Engineering, (2022); Qian Y., Zhang Y., Wen Q., Ye Y., Zhang C., Rep2Vec: Repository Embedding via Heterogeneous Graph Adversarial Contrastive Learning, KDD '22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. ACM, (2022); Qiu F., Yan M., Xia X., Wang X., Fan Y., Hassan A.E., Lo D., JITO: A tool for just-in-time defect identi-cation and localization, Proceedings of the 28th ACM joint meeting on european software engineering conference and symposium on the foundations of software engineering, (2020); Rahman M.M., Roy C.K., Improving IR-based bug localization with context-aware query reformulation, Proceedings of the 2018 26th ACM joint meeting on European software engineering conference and symposium on the foundations of software engineering, (2018); Robertson S.E., Walker S., Hancock-Beaulieu M., Experimentation as a way of life: Okapi at TREC, Inf. Process. Manag, (2000); Rosa G., Pascarella L., Scalabrino S., Tufano R., Bavota G., Lanza M., Oliveto R., Evaluating SZZ Implementations Through a Developer-Informed Oracle, Proceedings of the 43rd International Conference on Software Engineering, (2021); Saha R.K., Lease M., Khurshid S., Perry D.E., Improving bug localization using structured information retrieval, 2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE), (2013); Shivaji S., Whitehead E.J., Akella R., Kim S., Reducing features to improve code change-based bug prediction, IEEE Transactions on Software Engineering, (2012); Smytzek M., Zeller A., SFLKit: Aworkbench for statistical fault localization, Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, (2022); Tao C., Zhan Q., Hu X., Xia X., C4: Contrastive crosslanguage code clone detection, Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension. ACM, (2022); Urli S., Yu Z., Seinturier L., Monperrus M., How to design a program repair bot insights from the repairnator project, 2018 IEEE/ACM 40th international conference on software engineering: Software engi-neering in practice Track (ICSE-SEIP), (2018); Vessey I., Expertise in debugging computer programs: A process analysis, International Journal of Man-Machine Studies, (1985); Wang M., Lin Z., Zou Y., Xie B., CoRA: Decomposing and Describing Tangled Code Changes for Reviewer, Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering, (2020); Wang X., Yin K., Ouyang Q., Wen X., Zhang S., Zhang W., Cao L., Han J., Jin X., Pei D., Identifying Erroneous Software Changes through Self-Supervised Contrastive Learning on Time Series Data, IEEE 33rd International Symposium on Software Reliability Engineering, ISSRE 2022, (2022); Wen M., Wu R., Cheung S., Locus: Locating Bugs from Software Changes, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, (2016); Wong W.E., Gao R., Li Y., Abreu R., Wotawa F., A survey on software fault localization, IEEE Transactions on Software Engineering, (2016); Wu R., Wen M., Cheung S., Zhang H., Changelocator: Locate crash-inducing changes based on crash reports, Empirical Software Engineering, (2018); Wu Z., Xiong Y., Yu S.X., Lin D., Unsupervised feature learning via non-parametric instance discrimination, Proceedings of the IEEE conference on computer vision and pattern recognition, (2018); Xie H., Lei Y., Yan M., Yu Y., Xia X., Mao X., A Universal Data Augmentation Approach for Fault Localization, Proceedings of the 44th International Conference on Software Engineering, (2022); Yu Z., Bai C., Cai K., Mutation-Oriented Test Data Augmentation for GUI Software Fault Localization, Inf. Softw. Technol, (2013); Yu Z., Bai C., Cai K., Does the Failing Test Execute a Single or Multiple Faults. An Approach to Classifying Failing Tests, Proceedings of the 37th International Conference on Software Engineering-Volume 1. IEEE Press, (2015); Yu Z., Hu H., Bai C., Cai K., Wong W.E., GUI Software Fault Localization Using N-gram Analysis, 2011 IEEE 13th International Symposium on High-Assurance Systems Engineering, (2011); Yu Z., Martinez M., Chen Z., Bissyande T.F., Monperrus M., Learning the Relation between Code Features and Code Transforms With Structured Prediction, IEEE Transactions on Software Engineering, (2023); Yu Z., Martinez M., Danglot B., Durieux T., Monperrus M., Alleviating Patch Over-tting with Automatic Test Generation: A Study of Feasibility and E-ectiveness for the Nopol Repair System, Empirical Softw. Engg, (2019); Zhang C., Peng X., Zhou T., Sha C., Yan Z., Chen Y., Yang H., TraceCRL: Contrastive representation learning for microservice trace analysis, Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, publisher = ACM, (2022); Zhang J., Xie R., Ye W., Zhang Y., Zhang S., Exploiting code knowledge graph for bug localization via bi-directional attention, Proceedings of the 28th International Conference on Program Comprehension, (2020); Zhou J., Zhang H., Lo D., Where Should the Bugs Be Fixed-More Accurate Information Retrieval-Based Bug Localization Based on Bug Reports, Proceedings of the 34th International Conference on Software Engineering. IEEE Press, (2012); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: E-ective Vulnerability Identi-cation by Learning Comprehensive Program Semantics via Graph Neural Networks, (2019); Zhu Z., Li Y., Tong H., Wang Y., Cooba: Cross-project bug localization via adversarial transfer learning, IJCAI, (2020); Zhu Z., Li Y., Wang Y., Wang Y., Tong H., A deep multimodal model for bug localization, Data Mining and Knowledge Discovery, (2021); Zhu Z., Tong H., Wang Y., Li Y., Enhancing bug localization with bug report decomposition and code hierarchical network, Knowledge-Based Systems, (2022); Zou W., Lo D., Chen Z., Xia X., Feng Y., Xu B., How Practitioners Perceive Automated Bug Report Management Techniques, IEEE Transactions on Software Engineering, (2020)",ACM SIGSOFT; Ant Group; et al.; Google; JetBrains; Meta,"31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2023",3 December 2023 through 9 December 2023,San Francisco,195093,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85171247925,185
Lin Z.; Li G.; Zhang J.; Deng Y.; Zeng X.; Zhang Y.; Wan Y.,"Lin, Zehao (57212018473); Li, Guodun (57219692240); Zhang, Jingfeng (59069515000); Deng, Yue (57709786200); Zeng, Xiangji (57322220800); Zhang, Yin (55920642700); Wan, Yao (57089582400)",57212018473; 57219692240; 59069515000; 57709786200; 57322220800; 55920642700; 57089582400,XCode: Towards Cross-Language Code Representation with Large-Scale Pre-Training,2022,ACM Transactions on Software Engineering and Methodology,31,3,52,,,,5,10.1145/3506696,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130754433&doi=10.1145%2f3506696&partnerID=40&md5=b2c60159ed514b3de7d7cdd2aaa6e896,"Source code representation learning is the basis of applying artificial intelligence to many software engineering tasks such as code clone detection, algorithm classification, and code summarization. Recently, many works have tried to improve the performance of source code representation from various perspectives, e.g., introducing the structural information of programs into latent representation. However, when dealing with rapidly expanded unlabeled cross-language source code datasets from the Internet, there are still two issues. Firstly, deep learning models for many code-specific tasks still suffer from the lack of high-quality labels. Secondly, the structural differences among programming languages make it more difficult to process multiple languages in a single neural architecture.To address these issues, in this article, we propose a novel Cross-language Code representation with a large-scale pre-Training (XCode) method. Concretely, we propose to use several abstract syntax trees and ELMo-enhanced variational autoencoders to obtain multiple pre-Trained source code language models trained on about 1.5 million code snippets. To fully utilize the knowledge across programming languages, we further propose a Shared Encoder-Decoder (SED) architecture which uses the multi-Teacher single-student method to transfer knowledge from the aforementioned pre-Trained models to the distilled SED. The pre-Trained models and SED will cooperate to better represent the source code. For evaluation, we examine our approach on three typical downstream cross-language tasks, i.e., source code translation, code clone detection, and code-To-code search, on a real-world dataset composed of programming exercises with multiple solutions. Experimental results demonstrate the effectiveness of our proposed approach on cross-language code representations. Meanwhile, our approach performs significantly better than several code representation baselines on different downstream tasks in terms of multiple automatic evaluation metrics.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Abadi M., Barham P., Chen J., Chen Z., Davis A., Dean J., Devin M., Ghemawat S., Irving G., Isard M., Kudlur M., Levenberg J., Monga R., Moore S., Gordon Murray D., Steiner B., Tucker P.A., Vasudevan V., Warden P., Wicke M., Yu Y., Zheng X., TensorFlow: A system for large-scale machine learning, Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2016, pp. 265-283, (2016); Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Computing Surveys (CSUR), 51, 4, (2018); Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating sequences from structured representations of code, Proceedings of the 7th International Conference on Learning Representations, (2019); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, ACM SIGPLAN Notices, 53, 4, pp. 404-419, (2018); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, pp. 1-29, (2019); Win T., Aung W., Wan Y., Huo H., Sui Y., Multi-Triage: A multi-Task learning framework for bug triage, Journal of Systems and Software, 184, (2022); Bahuleyan H., Mou L., Vechtomova O., Poupart P., Variational attention for sequence-Tosequence models, Proceedings of the 27th International Conference on Computational Linguistics, pp. 1672-1682, (2018); Banerjee S., Lavie A., METEOR: An automatic metric for MT evaluation with improved correlation with human judgments, Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation And/or Summarization@ACL 2005, pp. 65-72, (2005); Barbez A., Khomh F., Gueheneuc Y., Deep learning anti-patterns from code metrics history, Proceedings of the 2019 IEEE International Conference on Software Maintenance and Evolution, ICSME 2019, pp. 114-124, (2019); Bhoopchand A., Rocktaschel T., Barr E.T., Riedel S., Learning Python Code Suggestion with A Sparse Pointer Network, (2016); Brown T.B., Mann B., Ryder N., Subbiah M., Kaplan J., Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A., Agarwal S., Herbert-Voss A., Krueger G., Henighan T., Child R., Ramesh A., Ziegler D.M., Wu J., Winter C., Hesse C., Chen M., Sigler E., Litwin M., Gray S., Chess B., Clark J., Berner C., McCandlish S., Radford A., Sutskever I., Amodei D., Language models are few-shot learners, Proceedings of the Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, (2020); Bui N.D.Q., Yu Y., Jiang L., InferCode: Self-supervised learning of code representations by predicting subtrees, 43rd IEEE/ACM International Conference on Software Engineering (ICSE21), pp. 1186-1197, (2021); Cambronero J., Li H., Kim S., Sen K., Chandra S., When deep learning met code search, Proceedings of the ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 964-974, (2019); Paolo Casale F., Dalca A.V., Saglietti L., Listgarten J., Fusi N., Gaussian process prior variational autoencoders, Proceedings of the Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, pp. 10390-10401, (2018); Chen J., Wu Z., Wang Z., You H., Zhang L., Yan M., Practical accuracy estimation for efficient deep neural network testing, ACM Transactions on Software Engineering and Methodology, 29, 4, pp. 301-3035, (2020); Chen M., Tang Q., Wiseman S., Gimpel K., Controllable paraphrase generation with a syntactic exemplar, Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, 1, pp. 5972-5984, (2019); Chen M., Tang Q., Wiseman S., Gimpel K., A multi-Task approach for disentangling syntax and semantics in sentence representations, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 1, pp. 2453-2464, (2019); Chen Q., Zhou M., A neural framework for retrieval and summarization of source code, Proceedings of the 33rd ACM/ IEEE International Conference on Automated Software Engineering, pp. 826-831, (2018); Chen X., Liu C., Song D., Tree-To-Tree neural networks for program translation, Proceedings of the Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, pp. 2552-2562, (2018); Chi Z., Dong L., Wei F., Wang W., Mao X., Huang H., Cross-lingual natural language generation via pre-Training, Proceedings of the 34th AAAI Conference on Artificial Intelligence, AAAI 2020, the 32nd Innovative Applications of Artificial Intelligence Conference, IAAI 2020, the 10th AAAI Symposium on Educational Advances in Artificial Intelligence, pp. 7570-7577, (2020); Choi Y., Choi M., Kim M., Ha J., Kim S., Choo J., StarGAN: Unified generative adversarial networks formulti-domain image-To-image translation, IEEE Conference on Computer Vision and Pattern Recognition (CVPR18), pp. 8789-8797, (2018); Collard M.L., John Decker M., Maletic J.I., SrcML: An infrastructure for the exploration, analysis, and manipulation of source code: A tool demonstration, IEEE International Conference on Software Maintenance, Eindhoven, pp. 516-519, (2013); Conneau A., Lample G., Cross-lingual language model pretraining, Proceedings of the Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, pp. 7057-7067, (2019); Cummins C., Petoumenos P., Murray A., Leather H., Compiler fuzzing through deep learning, Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 95-105, (2018); Cvitkovic M., Singh B., Anandkumar A., Open vocabulary learning on source code with a graph-structured cache, Proceedings of the 36th International Conference on Machine Learning, pp. 1475-1485, (2019); David Y., Alon U., Yahav E., Neural reverse engineering of stripped binaries using augmented control flow graphs, Proceedings of the ACM on Programming Languages, 4, pp. 2251-22528, (2020); Davis A.L., Data flow program graphs, Computer, 15, 2, pp. 26-41, (1982); Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-Training of deep bidirectional transformers for language understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 1, pp. 4171-4186, (2019); Eric M., Goel R., Paul S., Sethi A., Agarwal S., Gao S., Kumar A., Kumar Goyal A., Ku P., Hakkani-Tor D., MultiWOZ 2.1: A consolidated multi-domain dialogue dataset with state corrections and state tracking baselines, Proceedings of the 12th Language Resources and Evaluation Conference, LREC 2020, pp. 422-428, (2020); Fan Y., Tian F., Qin T., Li X., Liu T., Learning to teach, Proceedings of the 6th International Conference on Learning Representations, ICLR 2018, (2018); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A pre-Trainedmodel for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Firat O., Cho K., Bengio Y., Multi-way, multilingual neural machine translation with a shared attention mechanism, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 866-875, (2016); Ganin Y., Ustinova E., Ajakan H., Germain P., Larochelle H., Laviolette F., Marchand M., Lempitsky V.S., Domain-Adversarial training of neural networks, Proceedings of the Domain Adaptation in Computer Vision Applications, pp. 189-209, (2017); Gao Y., Wang Z., Liu S., Yang L., Sang W., Cai Y., TECCD: A tree embedding approach for code clone detection, Proceedings of the 2019 IEEE International Conference on Software Maintenance and Evolution, ICSME 2019, pp. 145-156, (2019); Gao Z., Xia X., Grundy J., Lo D., Li Y., Generating question titles for stack overflow from mined code snippets, ACM Transactions on Software Engineering and Methodology, 29, 4, pp. 261-2637, (2020); Godefroid P., Peleg H., Singh R., Learn&Fuzz: Machine learning for input fuzzing, Proceedings of the 32nd IEEE/ACMInternational Conference on Automated Software Engineering, ASE 2017, pp. 50-59, (2017); Gu X., Zhang H., Kim S., Deep code search, Proceedings of the 40th International Conference on Software Engineering, ICSE 2018, pp. 933-944, (2018); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Kun Deng S., Clement C.B., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., GraphCodeBERT: Pre-Training code representations with data flow, 9th International Conference on Learning Representations, ICLR 2021, (2021); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, IEEE Conference on Computer Vision and Pattern Recognition (CVPR16), pp. 770-778, (2016); Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P., On the naturalness of software, Proceedings of the 2012 34th International Conference on Software Engineering, pp. 837-847, (2012); Hinton G.E., Vinyals O., Dean J., Distilling the Knowledge in A Neural Network, (2015); Hochreiter S., Schmidhuber J., Long short-Term memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Hong H., Zhang J., Zhang Y., Wan Y., Sui Y., Fix-filter-fix: Intuitively connect anymodels for effective bug fixing, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, pp. 3495-3504, (2021); Hsu W., Zhang Y., Glass J.R., Unsupervised domain adaptation for robust speech recognition via variational autoencoder-based data augmentation, Proceedings of the 2017 IEEE Automatic Speech Recognition and Understanding Workshop, ASRU 2017, pp. 16-23, (2017); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proceedings of the 26th Conference on Program Comprehension, ICPC 2018, pp. 200-210, (2018); Hu Z., Yang Z., Liang X., Salakhutdinov R., Xing E.P., Toward controlled generation of text, Proceedings of the 34th International Conference on Machine Learning, ICML 2017, pp. 1587-1596, (2017); Huang H., Li Z., He R., Sun Z., Tan T., IntroVAE: Introspective variational autoencoders for photographic image synthesis, Proceedings of the Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, pp. 52-63, (2018); Huo X., Thung F., Li M., Lo D., Shi S., Deep transfer bug localization, IEEE Transactions on Software Engineering, 47, 7, pp. 1368-1380, (2021); Jiang L., Rewcastle R., Denny P., Tempero E.D., CompareCFG: Providing visual feedback on code quality using control flow graphs, Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education, pp. 493-499, (2020); Jouppi N.P., Young C., Patil N., Patterson D.A., Agrawal G., Bajwa R., Bates S., Bhatia S., Boden N., Borchers A., Boyle R., Cantin P., Chao C., Clark C., Coriell J., Daley M., Dau M., Dean J., Gelb B., Vazir G.T., Gottipati R., Gulland W., Hagmann R., Richard Ho C., Hogberg D., Hu J., Hundt R., Hurt D., Ibarz J., Jaffey A., Jaworski A., Kaplan A., Khaitan H., Killebrew D., Koch A., Kumar N., Lacy S., Laudon J., Law J., Le Chris Leary D., Liu Z., Lucke K., Lundin A., Mackean G., Maggiore A., Mahony M., Miller K., Nagarajan R., Narayanaswami R., Ni R., Nix K., Norrie T., Omernick M., Penukonda N., Phelps A., Ross J., Ross M., Salek A., Samadiani E., Severn C., Sizikov G., Snelham M., Souter J., Steinberg D., Swing A., Tan M., Thorson G., Tian B., Toma H., Tuttle E., Vasudevan V., Walter R., Wang W., Wilcox E., Hyun Yoon D., In-datacenter performance analysis of a tensor processing unit, Proceedings of the 44th Annual International Symposium on Computer Architecture, ISCA 2017, pp. 1-12, (2017); Kim K., Kim D., Bissyande T.F., Choi E., Li L., Klein J., Le Traon Y., FaCoY: A code-To-code search engine, Proceedings of the 40th International Conference on Software Engineering, ICSE 2018, pp. 946-957, (2018); Kim Y., Convolutional neural networks for sentence classification, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, pp. 1746-1751, (2014); Kim Y., Rush A.M., Sequence-level knowledge distillation, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, pp. 1317-1327, (2016); Kingma D.P., Welling M., Auto-encoding variational bayes, Proceedings of the 2nd International Conference on Learning Representations, ICLR 2014, (2014); Le Cun Y., Bengio Y., Convolutional Networks for Images, Speech, and Time Series, pp. 255-258, (1998); Lee J., Cho K., Hofmann T., Fully character-level neural machine translation without explicit segmentation, Transactions of the Association for Computational Linguistics, 5, pp. 365-378, (2017); Lin C., ROUGE: A package for automatic evaluation of summaries, Proceedings of the Text Summarization Branches Out, pp. 74-81, (2004); Lin Z., Huang X., Ji F., Chen H., Zhang Y., Task-oriented conversation generation using heterogeneous memory networks, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pp. 4557-4566, (2019); Liu F., Zhang L., Jin Z., Modeling programs hierarchically with stack-Augmented LSTM, Journal of Systems and Software, 164, (2020); Liu P., Qiu X., Huang X., Recurrent neural network for text classification with multi-Task learning, Proceedings of the 25th International Joint Conference on Artificial Intelligence, pp. 2873-2879, (2016); Liu S., Gao C., Chen S., Yiu Nie L., Liu Y., ATOM: Commit message generation based on abstract syntax tree and hybrid ranking, IEEE Transactions on Software Engineering, 1, pp. 1-1, (2020); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., RoBERTa: A Robustly Optimized BERT Pretraining Approach, (2019); Liu Z., Indra Winata G., Xu P., Lin Z., Fung P., Cross-lingual spoken language understanding with regularized representation alignment, Proceedings of the 2020 Conference on EmpiricalMethods in Natural Language Processing, EMNLP 2020, pp. 7241-7251, (2020); Lu S., Guo D., Ren S., Huang J., Svyatkovskiy A., Blanco A., Clement C.B., Drain D., Jiang D., Tang D., Li G., Zhou L., Shou L., Zhou L., Tufano M., Gong M., Zhou M., Duan N., Sundaresan N., Kun Deng S., Fu S., Liu S., CodeXGLUE: A machine learning benchmark dataset for code understanding and generation, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round, 1, (2021); Matiisen T., Oliver A., Cohen T., Schulman J., Teacher-student curriculum learning, IEEE Transactions on Neural Networks and Learning Systems, 31, 9, pp. 3732-3740, (2020); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, Proceedings of the 1st International Conference on Learning Representations, ICLR 2013, (2013); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Proceedings of the 13th AAAI Conference on Artificial Intelligence, pp. 1287-1293, (2016); Wazed Nafi K., Shekha Kar T., Roy B., Roy C.K., Schneider K.A., CLCDSA: Cross language code clone detection using syntactical features and API documentation, Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019, pp. 1026-1037, (2019); Neamtiu I., Foster J.S., Hicks M., Understanding source code evolution using abstract syntax tree matching, ACM SIGSOFT Software Engineering Notes, 30, 4, pp. 1-5, (2005); Bui D., Nghi Q., Yu Y., Jiang L., Bilateral dependency neural networks for cross-language algorithm classification, Proceedings of the 26th IEEE International Conference on Software Analysis, Evolution and Reengineering, pp. 422-433, (2019); Papineni K., Roukos S., Ward T., Zhu W., Bleu: A method for automatic evaluation of machine translation, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Paszke A., Gross S., Massa F., Lerer A., Bradbury J., Chanan G., Killeen T., Lin Z., Gimelshein N., Antiga L., Desmaison A., Kopf A., Yang E.Z., Devito Z., Raison M., Tejani A., Chilamkurthy S., Steiner B., Fang L., Bai J., Chintala S., Py-Torch: An imperative style, high-performance deep learning library, Proceedings of the Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, pp. 8024-8035, (2019); Peng S., Ji F., Lin Z., Cui S., Chen H., Zhang Y., MTSS: Learn from multiple domain teachers and become a multi-domain dialogue expert, Proceedings of the 34th AAAI Conference on Artificial Intelligence, AAAI 2020, the 32nd Innovative Applications of Artificial Intelligence Conference, IAAI 2020, the 10th AAAI Symposium on Educational Advances in Artificial Intelligence, pp. 8608-8615, (2020); Phannachitta P., On an optimal analogy-based software effort estimation, Information and Software Technology, 125, (2020); Rahman M.D., Watanobe Y., Nakamura K., Source code assessment and classification based on estimated error probability using attentive LSTM language model and its application in programming education, Applied Sciences, 10, 8, (2020); Roziere B., Lachaux M., Chanussot L., Lample G., Unsupervised translation of programming languages, Proceedings of the Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, (2020); Rumelhart D.E., Hinton G.E., Williams R.J., Learning representations by back-propagating errors, Nature, 323, 6088, pp. 533-536, (1986); Schuster M., Paliwal K.K., Bidirectional recurrent neural networks, IEEE Transactions on Signal Processing, 45, 11, pp. 2673-2681, (1997); Shido Y., Kobayashi Y., Yamamoto A., Miyamoto A., Matsumura T., Automatic source code summarization with extended tree-LSTM, Proceedings of the International Joint Conference on Neural Networks, pp. 1-8, (2019); Szegedy C., Ioffe S., Vanhoucke V., Alemi A.A., Inception-v4, inception-resnet and the impact of residual connections on learning, Proceedings of the 31st AAAI Conference on Artificial Intelligence, February 4-9, 2017, pp. 4278-4284, (2017); Tan M., Le Q.V., EfficientNet: Rethinking model scaling for convolutional neural networks, Proceedings of the 36th International Conference on Machine Learning, ICML 2019, pp. 6105-6114, (2019); Tan X., Ren Y., He Tao Qin D., Zhao Z., Liu T., Multilingual neural machine translation with knowledge distillation, Proceedings of the 7th International Conference on Learning Representations, ICLR 2019, (2019); Tian G., Wang Q., Zhao Y., Guo L., Sun Z., Lv L., Smart contract classification with a Bi-LSTM based approach, IEEE Access, 8, pp. 43806-43816, (2020); Tolke J., Implementation of a lattice boltzmann kernel using the compute unified device architecture developed by nVIDIA, Computing and Visualization in Science, 13, 1, (2010); Tong H., Liu B., Wang S., Software defect prediction using stacked denoising autoencoders and two-stage ensemble learning, Information and Software Technology, 96, pp. 94-111, (2018); Tran C., Tang Y., Li X., Gu J., Cross-lingual retrieval for iterative self-supervised training, Proceedings of the Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, (2020); Tufano M., Watson C., Bavota G., Di M., Martin White P., Poshyvanyk D., An empirical study on learning bug-fixing patches in the wild via neural machine translation, ACM Transactions on Software Engineering and Methodology, 28, 4, pp. 191-1929, (2019); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Proceedings of the Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, pp. 5998-6008, (2017); Vedantam R., Lawrence Zitnick C., Parikh D., CIDEr: Consensus-based image description evaluation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, pp. 4566-4575, (2015); Venkatakeerthy S., Aggarwal R., Jain S., Sankar Desarkar M., Upadrasta R., Srikant Y.N., IR2Vec: A Flow Analysis Based Scalable Infrastructure for Program Encodings, (2019); Wan Y., Shu J., Sui Y., Xu G., Zhao Jianwu Z., Yu P.S., Multi-modal attention network learning for semantic source code retrieval, Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019, pp. 13-25, (2019); Wan Y., Zhao Z., Yang M., Xu G., Ying Jianwu H., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/ IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Wang S., Cao J., Yu P., Deep learning for spatio-Temporal data mining: A survey, IEEE Transactions on Knowledge and Data Engineering, 2020, (2020); Wang W., Li G., Shen S., Xia X., Jin Z., Modular tree network for source code representation learning, ACM Transactions on Software Engineering and Methodology, 29, 4, pp. 1-23, (2020); Wang W., Zhang K., Li G., Jin Z., Learning to represent programs with heterogeneous graphs, CoRR, (2020); Wang X., Huang Q., Celikyilmaz A., Gao J., Shen D., Wang Y., Yang Wang W., Zhang L., Reinforced cross-modal matching and self-supervised imitation learning for vision-language navigation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6629-6638, (2019); Wang X., Wang Y., Mi F., Zhou P., Wan Y., Liu X., Li L., Wu H., Liu J., Jiang X., Syn-CoBERT: Syntax-guided Multi-modal Contrastive Pre-Training for Code Representation, (2021); White M., Vendome C., Linares-Vasquez M., Poshyvanyk D., Toward deep learning software repositories, Proceedings of the 2015 IEEE/ACM 12th Working Conference on Mining Software Repositories, pp. 334-345, (2015); Xiao Y., Keung J., Bennin K.E., Mi Q., Improving bug localization with word embedding and enhanced convolutional neural networks, Information and Software Technology, 105, pp. 17-29, (2019); Xu A., Dai T., Chen H., Ming Z., Li W., Vulnerability detection for source code using contextual LSTM, Proceedings of the 2018 5th International Conference on Systems and Informatics, pp. 1225-1230, (2018); Xu B., Ye D., Xing Z., Xia X., Chen G., Li S., Predicting semantically linkable knowledge in developer online forums via convolutional neural network, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, ASE 2016, pp. 51-62, (2016); Xu J., Durrett G., Spherical latent spaces for stable variational autoencoders, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 4503-4513, (2018); Yang Y., Xia X., Lo D., Grundy J.C., A survey on deep learning for software engineering, ACM Comput. Surv, 2021, (2021); Yang Z., Dai Z., Yang Y., Carbonell J., Salakhutdinov R.R., Le Q.V., Xlnet: Generalized autoregressive pretraining for language understanding, Proceedings of the Advances in Neural Information Processing Systems, pp. 5753-5763, (2019); Yin P., Zhou C., He J., Neubig G., StructVAE: Tree-structured latent variable models for semi-supervised semantic parsing, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, 1, pp. 754-765, (2018); Yuan C., Wei S., Wang Y., You Y., Guan S., Liang Z., Android applications categorization using bayesian classification, Proceedings of the International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery, pp. 173-176, (2016); Zhang J., Hong H., Zhang Y., Wan Y., Liu Y., Sui Y., Disentangled code representation learning for multiple programming languages, Proceedings of the Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021, pp. 4454-4466, (2021); Zhao D., Xing Z., Chen C., Xia X., Li G., ActionNet: Vision-based workflow action recognition from programming screencasts, Proceedings of the 41st International Conference on Software Engineering, ICSE 2019, pp. 350-361, (2019); Zhao G., Huang J., DeepSim: Deep learning code functional similarity, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (Lake Buena Vista, FL), pp. 141-151, (2018); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Proceedings of the Advances in Neural Information Processing Systems, pp. 10197-10207, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85130754433,186
Wang D.; Yu Y.; Li S.; Dong W.; Wang J.; Qing L.,"Wang, Deze (57212529423); Yu, Yue (55566298800); Li, Shanshan (55741045700); Dong, Wei (57190581192); Wang, Ji (56259417500); Qing, Liao (55903680000)",57212529423; 55566298800; 55741045700; 57190581192; 56259417500; 55903680000,MulCode: A Multi-task Learning Approach for Source Code Understanding,2021,"Proceedings - 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2021",,,9426045,48,59,11,12,10.1109/SANER50967.2021.00014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106562192&doi=10.1109%2fSANER50967.2021.00014&partnerID=40&md5=19013a3e0211265450216dfea0cf9212,"Recent years have witnessed the significant rise of Deep Learning (DL) techniques applied to source code. Researchers exploit DL for a multitude of tasks and achieve impressive results. However, most tasks are explored separately, resulting in a lack of generalization of the solutions. In this work, we propose MulCode, a multi-task learning approach for source code understanding that learns unified representation space for tasks, with the pre-trained BERT model for the token sequence and the Tree-LSTM model for abstract syntax trees. Furthermore, we integrate two source code views into a hybrid representation via the attention mechanism and set learnable uncertainty parameters to adjust the tasks' relationship.We train and evaluate MulCode in three downstream tasks: comment classification, author attribution, and duplicate function detection. In all tasks, MulCode outperforms the state-of-the-art techniques. Moreover, experiments on three unseen tasks demonstrate the generalization ability of MulCode compared with state-of-the-art embedding methods. © 2021 IEEE.","Devanbu P., Dwyer M., Elbaum S., Lowry M., Moran K., Poshyvanyk D., Ray B., Singh R., Zhang X., Deep Learning & Software Engineering: State of Research and Future Directions, (2020); Gu X., Zhang H., Kim S., Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE). IEEE, pp. 933-944, (2018); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P., Multimodal attention network learning for semantic source code retrieval, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 13-25, (2019); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, 1, pp. 2073-2083, (2016); Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating Sequences from Structured Representations of Code, (2018); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, 2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR), pp. 542-553, (2018); Zhao G., Huang J., Deepsim: Deep learning code functional similarity, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 141-151, (2018); Li J., Wang Y., Lyu M.R., King I., Code completion with neural attention and pointer networks, Proceedings of the 27th International Joint Conference on Artificial Intelligence, pp. 4159-4225, (2018); Liu F., Li G., Wei B., Xia X., Fu Z., Jin Z., A self-attentional neural architecture for code completion with multi-task learning, Proceedings of the 28th International Conference on Program Comprehension, pp. 37-47, (2020); Kang H.J., Bissyande T.F., Lo D., Assessing the generalizability of code2vec token embeddings, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 1-12, (2019); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, pp. 1-29, (2019); Chen Q., Zhou M., A neural framework for retrieval and summarization of source code, 2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 826-831, (2018); Yao Z., Peddamail J.R., Sun H., Coacor: Code annotation for code retrieval with reinforcement learning, The World Wide Web Conference, pp. 2203-2214, (2019); Hoang T., Kang H.J., Lo D., Lawall J., Cc2vec: Distributed representations of code changes, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 518-529, (2020); Wei B., Li G., Xia X., Fu Z., Jin Z., Code generation as a dual task of code summarization, Advances in Neural Information Processing Systems, pp. 6563-6573, (2019); Steidl D., Hummel B., Juergens E., Quality analysis of source code comments, 2013 21st International Conference on Program Comprehension (Icpc), pp. 83-92, (2013); Krsul I., Spafford E., Authorship analysis: Identifying the author of a program, Comput. Secur, 16, pp. 233-257, (1997); Baxter I.D., Yahin A., Moura L., Sant'Anna M., Bier L., Clone detection using abstract syntax trees, Proceedings. International Conference on Software Maintenance (Cat. No. 98CB36272), pp. 368-377, (1998); Kendall A., Gal Y., Cipolla R., Multi-task learning using uncertainty to weigh losses for scene geometry and semantics, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7482-7491, (2018); Holmes G., Donkin A., Witten I.H., Weka: A machine learning workbench, Proceedings of ANZIIS'94-Australian New Zealnd Intelligent Information Systems Conference, pp. 357-361, (1994); Crawshaw M., Multi-task Learning with Deep Neural Networks: A Survey, (2020); Pan S.J., Yang Q., A survey on transfer learning, IEEE Transactions on Knowledge and Data Engineering, 22, 10, pp. 1345-1359, (2009); Peters M.E., Neumann M., Iyyer M., Gardner M., Clark C., Lee K., Zettlemoyer L., Deep contextualized word representations, Proceedings of NAACL-HLT, pp. 2227-2237, (2018); Radford A., Narasimhan K., Salimans T., Sutskever I., Improving Language Understanding by Generative Pre-training, (2018); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in Neural Information Processing Systems, pp. 5998-6008, (2017); Devlin J., Chang M.-W., Lee K., Toutanova K., Bert: Pre-training of Deep Bidirectional Transformers for Language Understanding, (2018); Tai K.S., Socher R., Manning C.D., Improved Semantic Representations from Tree-structured Long Short-term Memory Networks, (2015); Corazza A., Maggio V., Scanniello G., Coherence of comments and method implementations: A dataset and an empirical investigation, Software Quality Journal, 26, 2, pp. 751-777, (2018); Stamatatos E., A survey of modern authorship attribution methods, Journal of the American Society for Information Science and Technology, 60, 3, pp. 538-556, (2009); Quiring E., Maier A., Rieck K., Misleading authorship attribution of source code using adversarial learning, 28th {USENIX} Security Symposium ({USENIX} Security 19), pp. 479-496, (2019); Compton R., Frank E., Patros P., Koay A., Embedding Java Classes with code2vec: Improvements from Variable Obfuscation, (2020); Ferenc R., Toth Z., Ladanyi G., Siket I., Gyimothy T., A public unified bug dataset for Java, Proceedings of the 14th International Conference on Predictive Models and Data Analytics in Software Engineering, pp. 12-21, (2018); Ben-David A., Comparison of classification accuracy using cohen's weighted kappa, Expert Systems with Applications, 34, 2, pp. 825-832, (2008); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, (2014); Srivastava N., Hinton G., Krizhevsky A., Sutskever I., Salakhutdinov R., Dropout: A simple way to prevent neural networks from overfitting, The Journal of Machine Learning Research, 15, 1, pp. 1929-1958, (2014); Platt J., Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines, (1998); Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Computing Surveys (CSUR), 51, 4, pp. 1-37, (2018); DeFreez D., Thakur A.V., Rubio-Gonzalez C., Path-based function embedding and its application to error-handling specification mining, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 423-433, (2018); Yin P., Deng B., Chen E., Vasilescu B., Neubig G., Learning to mine aligned code and natural language pairs from stack overflow, 2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR), pp. 476-486, (2018); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, 2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC). IEEE, pp. 200-20010, (2018); He D., Xia Y., Qin T., Wang L., Yu N., Liu T.-Y., Ma W.-Y., Dual learning for machine translation, Advances in Neural Information Processing Systems, pp. 820-828, (2016); Wang W., Zhang Y., Zeng Z., Xu G., Trans 3: A Transformerbased Framework for Unifying Code Summarization and Code Search, (2020); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Codebert: A Pre-trained Model for Programming and Natural Languages, (2020); Liu P., Qiu X., Huang X., Adversarial Multi-task Learning for Text Classification, (2017); Dong D., Wu H., He W., Yu D., Wang H., Multi-task learning for multiple language translation, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, 1, pp. 1723-1732, (2015); McCann B., Keskar N.S., Xiong C., Socher R., The Natural Language Decathlon: Multitask Learning As Question Answering, (2018); Wulfmeier M., Abdolmaleki A., Hafner R., Springenberg J.T., Neunert M., Hertweck T., Lampe T., Siegel N., Heess N., Riedmiller M., Regularized Hierarchical Policies for Compositional Transfer in Robotics, (2019); Hausman K., Springenberg J.T., Wang Z., Heess N., Riedmiller M., Learning an embedding space for transferable robot skills, International Conference on Learning Representations, (2018); Diba A., Fayyaz M., Sharma V., Paluri M., Gall J., Stiefelhagen R., Van Gool L., Holistic Large Scale Video Understanding, (2019); Pasunuru R., Bansal M., Multi-task Video Captioning with Video and Entailment Generation, (2017); Deng L., Hinton G., Kingsbury B., New types of deep neural network learning for speech recognition and related applications: An overview, 2013 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, pp. 8599-8603, (2013); Luong M.-T., Le Q.V., Sutskever I., Vinyals O., Kaiser L., Multitask Sequence to Sequence Learning, (2015); Liu X., He P., Chen W., Gao J., Multi-task Deep Neural Networks for Natural Language Understanding, (2019); Sun Y., Wang S., Li Y.-K., Feng S., Tian H., Wu H., Wang H., Ernie 2.0: A continual pre-training framework for language understanding, AAAI, pp. 8968-8975, (2020)",IEEE Computer Society,"28th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2021",9 March 2021 through 12 March 2021,"Virtual, Honolulu",168914,English,Conference paper,Final,,Scopus,2-s2.0-85106562192,187
Liu S.; Xie X.; Siow J.; Ma L.; Meng G.; Liu Y.,"Liu, Shangqing (57218717656); Xie, Xiaofei (55268560900); Siow, Jingkai (57216460449); Ma, Lei (55479591700); Meng, Guozhu (56747189200); Liu, Yang (56911879800)",57218717656; 55268560900; 57216460449; 55479591700; 56747189200; 56911879800,GraphSearchNet: Enhancing GNNs via Capturing Global Dependencies for Semantic Code Search,2023,IEEE Transactions on Software Engineering,49,4,,2839,2855,16,16,10.1109/TSE.2022.3233901,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147215823&doi=10.1109%2fTSE.2022.3233901&partnerID=40&md5=4f9fb5cff1da1852cf94db76ca82598e,"Code search aims to retrieve accurate code snippets based on a natural language query to improve software productivity and quality. With the massive amount of available programs such as (on GitHub or Stack Overflow), identifying and localizing the precise code is critical for the software developers. In addition, Deep learning has recently been widely applied to different code-related scenarios, e.g., vulnerability detection, source code summarization. However, automated deep code search is still challenging since it requires a high-level semantic mapping between code and natural language queries. Most existing deep learning-based approaches for code search rely on the sequential text i.e., feeding the program and the query as a flat sequence of tokens to learn the program semantics while the structural information is not fully considered. Furthermore, the widely adopted Graph Neural Networks (GNNs) have proved their effectiveness in learning program semantics, however, they also suffer the problem of capturing the global dependencies in the constructed graph, which limits the model learning capacity. To address these challenges, in this paper, we design a novel neural network framework, named GraphSearchNet, to enable an effective and accurate source code search by jointly learning the rich semantics of both source code and natural language queries. Specifically, we propose to construct graphs for the source code and queries with bidirectional GGNN (BiGGNN) to capture the local structural information of the source code and queries. Furthermore, we enhance BiGGNN by utilizing the multi-head attention module to supplement the global dependencies that BiGGNN missed to improve the model learning capacity. The extensive experiments on Java and Python programming language from the public benchmark CodeSearchNet confirm that GraphSearchNet outperforms current state-of-the-art works by a significant margin.  © 1976-2012 IEEE.","Liu C., Xia X., Lo D., Gao C., Yang X., Grundy J., Opportunities and challenges in code search tools, ACM Comput. Surv., 54, 9, pp. 1-40, (2021); Bajracharya S.K., Lopes C.V., Analyzing and mining a code search engine usage log, Empirical Softw. Eng., 17, 4, pp. 424-466, (2012); Lu M., Sun X., Wang S., Lo D., Duan Y., Query expansion via wordNet for effective code search, Proc. IEEE 22nd Int. Conf. Softw. Anal. Evol. Reengineering, pp. 545-549, (2015); Bajracharya S., Et al., Sourcerer: A search engine for open source code supporting structure-based search, Proc. 21st ACM SIGPLAN Symp. Object-Oriented Program. Syst. Lang.s Appl., pp. 681-682, (2006); Krugler K., Krugle code search architecture, Finding Source Code on the Web for Remix and Reuse, pp. 103-120, (2013); Haiduc S., Bavota G., Marcus A., Oliveto R., De Lucia A., Menzies T., Automatic query reformulations for text retrieval in software engineering, Proc. IEEE 35th Int. Conf. Softw. Eng., pp. 842-851, (2013); Hill E., Pollock L., Vijay-Shanker K., Improving source code search with natural language phrasal representations of method signatures, Proc. IEEE/ACM 26th Int. Conf. Automated Softw. Eng., pp. 524-527, (2011); McMillan C., Grechanik M., Poshyvanyk D., Xie Q., Fu C., Portfolio: Finding relevant functions and their usage, Proc. 33rd Int. Conf. Softw. Eng., pp. 111-120, (2011); Lv F., Zhang H., Lou J.-G., Wang S., Zhang D., Zhao J., CodeHow: Effective code search based on API understanding and extended boolean model (e), Proc. IEEE/ACM 30th Int. Conf. Automated Softw. Eng., pp. 260-270, (2015); Miller G.A., WordNet: An Electron. Lexical Database, (1998); Liu C., Xia X., Lo D., Liu Z., Hassan A.E., Li S., CodeMatcher: Searching code based on sequential semantics of important query words, ACM Trans. Softw. Eng. Methodol., 31, 1, pp. 1-37; Gu X., Zhang H., Kim S., Deep code search, Proc. IEEE/ ACM 40th Int. Conf. Softw. Eng., pp. 933-944, (2018); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet challenge: Evaluating the state of semantic code search, (2019); Yao Z., Peddamail J.R., Sun H., CoaCor: Code annotation for code retrieval with reinforcement learning, Proc. World Wide Web Conf., pp. 2203-2214, (2019); Haldar R., Wu L., Xiong J., Hockenmaier J., A multi-perspective architecture for semantic code search, Proc. 58th Annu. Meeting Assoc. Comput. Linguistics, pp. 8563-8568; Shuai J., Xu L., Liu C., Yan M., Xia X., Lei Y., Improving code search with co-attentive representation learning, Proc. 28th Int. Conf. Prog. Comprehension, 2020, pp. 196-207; Wan Y., Et al., Multi-modal attention network learning for semantic source code retrieval, (2019); Fang S., Tan Y.-S., Zhang T., Liu Y., Self-attention networks for code search, Inf. Softw. Technol., 134; Ishtiaq A.A., Et al., Bert2code: Can pretrained language models be leveraged for code search?, 2021; Du L., Shi X., Wang Y., Shi E., Han S., Zhang D., Is a single model enough?, Mucos: A multi-model ensemble learning for semantic code search; Hochreiter S., Schmidhuber J., Long short-term memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Vaswani A., Et al., Attention is all you need, Proc. Adv. Neural Inf. Process. Syst., pp. 5998-6008, (2017); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Proc. 30th AAAI Conf. Artif. Intell., pp. 1287-1293, (2016); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, (2015); Liu S., Chen Y., Xie X., Siow J.K., Liu Y., Retrieval-augmented generation for code summarization via hybrid GNN, Proc. Int. Conf. Learn. Representations; Alon U., Yahav E., On the bottleneck of graph neural networks and its practical implications, Proc. Int. Conf. Learn. Representations; Li H., Kim S., Chandra S., Neural code search evaluation dataset, (2019); Yan S., Yu H., Chen Y., Shen B., Jiang L., Are the code snippets what we are searching for? A benchmark and an empirical study on code search with natural-language queries, Proc. IEEE 27th Int. Conf. Softw. Anal. Evol. Reengineering, 2020, pp. 344-354; De Marneffe M.-C., Et al., Generating typed dependency parses from phrase structure parses, Proc. Int. Conf. Lang. Resour. Eval., pp. 449-454, (2006); Chen Y., Wu L., Zaki M.J., Reinforcement learning based graph-to-sequence model for natural question generation, (2019); Hamilton W., Ying Z., Leskovec J., Inductive representation learning on large graphs, Proc. Adv. Neural Inf. Process. Syst., pp. 1024-1034, (2017); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, (2016); Xu K., Wu L., Wang Z., Feng Y., Witbrock M., Sheinin V., Graph2Seq: Graph to sequence learning with attention-based neural networks, (2018); Fan W., Et al., Graph neural networks for social recommendation, Proc. World Wide Web Conf., pp. 417-426, (2019); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, (2017); Duvenaud D.K., Et al., Convolutional networks on graphs for learning molecular fingerprints, Proc. Adv. Neural Inf. Process. Syst., pp. 2224-2232, (2015); Nair V., Hinton G.E., Rectified linear units improve restricted boltzmann machines, Proc. Int. Conf. Mach. Learn., pp. 807-814, (2010); Cho K., Et al., Learning phrase representations using rnn encoder-decoder for statistical machine translation, (2014); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Proc. Adv. Neural Inf. Process. Syst., (2019); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, (2018); Allamanis M., Barr E.T., Ducousso S., Gao Z., Typilus: Neural type hints, Proc. 41st ACM SIGPLAN Conf. Program. Lang. Des. Implementation, 2020, pp. 91-105; Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, Proc. Int. Conf. Learn. Representations; Su D., Xu Y., Dai W., Ji Z., Yu T., Fung P., Multi-hop question generation with graph convolutional network; Chen Y., Wu L., Zaki M.J., GraphFlow: Exploiting conversation flow with graph neural networks for conversational machine comprehension, (2019); Song L., Wang Z., Yu M., Zhang Y., Florian R., Gildea D., Exploring graph-structured passage representation for multihop reading comprehension with graph neural networks, (2018); De Cao N., Aziz W., Titov I., Question answering by reasoning across documents with graph convolutional networks, (2018); Annervaz K., Chowdhury S.B.R., Dukkipati A., Learning beyond datasets: Knowledge graph augmented neural networks for natural language processing, (2018); Li Q., Han Z., Wu X.-M., Deeper insights into graph convolutional networks for semi-supervised learning, Proc. 32nd AAAI Conf. Artif. Intell., pp. 3538-3545, (2018); Oono K., Suzuki T., Graph neural networks exponentially lose expressive power for node classification, (2019); Gu X., Zhang H., Zhang D., Kim S., Deep API learning, Proc. 24th ACM SIGSOFT Int. Symp. Found.s Softw. Eng., pp. 631-642, (2016); Cvitkovic M., Singh B., Anandkumar A., Open vocabulary learning on source code with a graph-structured cache, Proc. Int. Conf. Mach. Learn., pp. 1475-1485, (2019); Jurafsky D., Martin J.H., Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition, (2000); Keselj V., Speech and Language Processing, (2009); De Marneffe M.-C., Manning C.D., Stanford typed dependencies manual, (2008); Xu K., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks?, (2018); Collobert R., Weston J., Bottou L., Karlen M., Kavukcuoglu K., Kuksa P., Natural language processing (almost) from scratch, J. Mach. Learn. Res., 12, pp. 2493-2537, (2011); Frome A., Et al., Devise: A deep visual-semantic embedding model, Proc. Adv. Neural Inform. Process. Syst. 26: 27th Annu. Conf. Neural Inform. Process. Syst. Proc. Meeting, pp. 2121-2129, (2013); Rice A., Features-javac, (2018); Honnibal M., Montani I., spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing, (2017); Gormley C., Tong Z., Elasticsearch: The Definitive Guide: A Distributed Real-Time Search and Analytics Engine, (2015); Cambronero J., Li H., Kim S., Sen K., Chandra S., When deep learning met code search, Proc. 27th ACM Joint Meeting Eur. Softw. Eng. Conf. Symp. Foundations Softw. Eng., pp. 964-974, (2019); Xu L., Et al., Two-stage attention-based model for code search with textual and structural features, Proc. IEEE Int. Conf. Softw. Anal. Evol. Reengineering, 2021, pp. 342-353; Feng Z., Et al., CodeBERT: A pre-trained model for programming and natural languages; Lu S., Et al., CodeXGLUE: A machine learning benchmark dataset for code understanding and generation; Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2014); Bahdanau D., Cho K., Bengio Y., Neural machine translation by jointly learning to align and translate, (2014); Luong M.-T., Pham H., Manning C.D., Effective approaches to attention-based neural machine translation, (2015); Maybury M., Advances in Automatic Text Summarization, (1999); Liu Y., Lapata M., Text summarization with pretrained encoders, (2019); Guo D., Et al., Graphcodebert: Pre-training code representations with data flow, 2020; Wang Y., Wang W., Joty S., Hoi S.C., Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation; Schutze H., Manning C.D., Raghavan P., Introduction to Information Retrieval, (2008); Zhu Q., Sun Z., Liang X., Xiong Y., Zhang L., OCoR: An overlapping-aware code retriever, Proc. IEEE/ACM 35th Int. Conf. Automated Softw. Eng., 2020, pp. 883-894; Norcliffe-Brown W., Vafeias S., Parisot S., Learning conditioned graph structures for interpretable visual question answering, Proc. Adv. Neural Inf. Process. Syst., pp. 8334-8343, (2018); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating sequences from structured representations of code, (2018); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proc. ACM Program. Lang., 3, pp. 1-29, (2019); Liu S., Gao C., Chen S., Yiu N.L., Liu Y., ATOM: Commit message generation based on abstract syntax tree and hybrid ranking, IEEE Trans. Softw. Eng., 48, 5, pp. 1800-1817, (2022); Frantzeskou G., MacDonell S., Stamatatos E., Gritzalis S., Examining the significance of high-level programming features in source code author classification, J. Syst. Softw., 81, 3, pp. 447-460, (2008); Linares-Vasquez M., McMillan C., Poshyvanyk D., Grechanik M., On using machine learning to automatically classify software applications into domain categories, Empirical Softw. Eng., 19, 3, pp. 582-618, (2014); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, (2014); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proc. IEEE/ACM 41st Int. Conf. Softw. Eng., pp. 783-794, (2019); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proc. 26th Int. Joint Conf. Artif. Intell., pp. 3034-3040, (2017)",,,,,,English,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85147215823,188
Cai B.; Yu Y.; Hu Y.,"Cai, Bo (35745538800); Yu, Yaoxiang (57421325600); Hu, Yi (57413274600)",35745538800; 57421325600; 57413274600,CSSAM: Code Search via Attention Matching of Code Semantics and Structures,2023,"Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",,,,402,413,11,1,10.1109/SANER56733.2023.00045,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160518672&doi=10.1109%2fSANER56733.2023.00045&partnerID=40&md5=7e48b84e94fed7f1284f7dfb216876a4,"Code search greatly improves developers' coding efficiency by retrieving reusable code segments with natural language queries. Despite the continuous efforts in improving both the effectiveness and efficiency of code search, two issues remained unsolved. First, programming languages have inherent strong structural linkages, and feature mining of code as text form would omit the structural information contained inside it. Second, there is a potential semantic relationship between code and query, it is challenging to align code and text across sequences so that vectors are spatially consistent during similarity matching.To tackle both issues, in this paper, a code search model named CSSAM (Code Semantics and Structures Attention Matching) is proposed. By introducing semantic and structural matching mechanisms, CSSAM effectively extracts and fuses multidimensional code features. Specifically, the cross and co-attention layer was developed to facilitate high-latitude spatial alignment of code and query at the token level. By leveraging the residual interaction, a matching module is designed to preserve more code semantics and descriptive features, which enhances the relevance between the code and its corresponding query text. Besides, to improve the model's comprehension of the code's inherent structure, a code representation structure named CSRG (Code Semantic Representation Graph) is proposed for jointly representing abstract syntax tree nodes and the data flow of the codes. According to the experimental results on two publicly available datasets containing 475k and 330k code segments, CSSAM significantly outperforms the baselines in terms of achieving the highest SR@1/5/10, MRR, and NDCG@50 on both datasets, respectively. Moreover, the ablation study is conducted to quantitatively measure the impact of each key component of CSSAM on the efficiency and effectiveness of code search, which offers insights into the improvement of advanced code search solutions. © 2023 IEEE.","McMillan C., Grechanik M., Poshyvanyk D., Xie Q., Fu C., Portfolio: finding relevant functions and their usage, Proceedings of the 33rd International Conference on Software Engineering, ICSE 2011, pp. 111-120, (2011); Fei L., Zhang H., Lou J.G., Wang S., Zhao J., Codehow: Effective code search based on api understanding and extended boolean model (e), 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE), (2015); Gu X., Zhang H., Kim S., Deep code search, Proceedings of the 40th International Conference on Software Engineering, ICSE 2018, pp. 933-944, (2018); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: learning distributed representations of code, Proc. ACM Program. Lang., 3, pp. 401-4029, (2019); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proceedings of the 26th Conference on Program Comprehension, ICPC 2018, pp. 200-210, (2018); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, 4th International Conference on Learning Representations, ICLR 2016, (2016); Bronstein M.M., Bruna J., LeCun Y., Szlam A., Vandergheynst P., Geometric deep learning: Going beyond euclidean data, IEEE Signal Process. Mag., 34, 4, pp. 18-42, (2017); Hamilton W.L., Ying R., Leskovec J., Representation learning on graphs: Methods and applications, IEEE Data Eng. Bull., 40, 3, pp. 52-74, (2017); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P.S., Multimodal attention network learning for semantic source code retrieval, 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019, pp. 13-25, (2019); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., Codebert: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Wang Y., Wang W., Joty S.R., Hoi S.C.H., Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, pp. 8696-8708, (2021); Grazia L.D., Pradel M., Code search: A survey of techniques for finding code, ACM Computing Surveys (CSUR), (2022); Baker B.S., On finding duplication and near-duplication in large software systems, Proceedings of 2nd Working Conference on Reverse Engineering, pp. 86-95, (1995); Bajracharya S.K., Ossher J., Lopes C.V., Leveraging usage similarity for effective retrieval of examples in code repositories, Proceedings of the eighteenth ACM SIGSOFT international symposium on Foundations of software engineering, pp. 157-166, (2010); Hill E., Pollock L., Vijay-Shanker K., Improving source code search with natural language phrasal representations of method signatures, 2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011), pp. 524-527, (2011); Arwan A., Rochimah S., Akbar R.J., Source code retrieval on stackoverflow using lda, 2015 3rd International Conference on Information and Communication Technology (ICoICT), pp. 295-299, (2015); Niu H., Keivanloo I., Zou Y., Learning to rank code examples for code search engines, Empirical Software Engineering, 22, 1, pp. 259-291, (2017); Aizawa A., An information-theoretic perspective of tf-idf measures, Information Processing & Management, 39, 1, pp. 45-65, (2003); Jiang H., Nie L., Sun Z., Ren Z., Kong W., Zhang T., Luo X., Rosf: Leveraging information retrieval and supervised learning for recommending code snippets, IEEE Transactions on Services Computing, 12, 1, pp. 34-46, (2016); Li X., Jiang H., Kamei Y., Chen X., Bridging semantic gaps between natural languages and apis with word embedding, IEEE Transactions on Software Engineering, 46, 10, pp. 1081-1097, (2018); Mitra B., Craswell N., Et al., An introduction to neural information retrieval, Foundations and Trends® in Information Retrieval, 13, 1, pp. 1-126, (2018); Xu J., He X., Li H., Deep learning for matching in search and recommendation, The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, pp. 1365-1368, (2018); Wang X., Hua Y., Kodirov E., Hu G., Garnier R., Robertson N.M., Ranked list loss for deep metric learning, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 5207-5216, (2019); Wang C., Nong Z., Gao C., Li Z., Zeng J., Xing Z., Liu Y., Enriching query semantics for code search with reinforcement learning, Neural Networks, 145, pp. 22-32, (2022); Liu C., Xia X., Lo D., Liu Z., Hassan A.E., Li S., Codematcher: Searching code based on sequential semantics of important query words, ACM Transactions on Software Engineering and Methodology (TOSEM), 31, 1, pp. 1-37, (2021); LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 795-806, (2019); Buch L., Andrzejak A., Learning-based recursive aggregation of abstract syntax trees for code clone detection, 26th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2019, pp. 95-104, (2019); Luan S., Yang D., Barnaby C., Sen K., Chandra S., Aroma: code recommendation via structural code search, Proc. ACM Program. Lang., 3, pp. 1521-15228, (2019); Ling X., Wu L., Wang S., Pan G., Ma T., Xu F., Liu A.X., Wu C., Ji S., Deep graph matching and searching for semantic code retrieval, ACM Trans. Knowl. Discov. Data, 15, 5, pp. 881-8821, (2021); Zugner D., Kirschstein T., Catasta M., Leskovec J., Gunnemann S., Language-agnostic representation learning of source code from structure and context, 9th International Conference on Learning Representations, ICLR 2021, (2021); Tai K.S., Socher R., Manning C.D., Improved semantic representations from tree-structured long short-term memory networks, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015, pp. 1556-1566, (2015); Haldar R., Wu L., Xiong J., Hockenmaier J., A multi-perspective architecture for semantic code search, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, pp. 8563-8568, (2020); Joulin A., Grave E., Bojanowski P., Douze M., Jegou H., Mikolov T., Fasttext.zip: Compressing text classification models, (2016); Bojanowski P., Grave E., Joulin A., Mikolov T., Enriching word vectors with subword information, (2016); Perozzi B., Al-Rfou R., Skiena S., Deepwalk: online learning of social representations, The 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '14, pp. 701-710, (2014); Le Q.V., Mikolov T., Distributed representations of sentences and documents, Proceedings of the 31th International Conference on Machine Learning, ICML 2014, 32, pp. 1188-1196, (2014); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, 1st International Conference on Learning Representations, ICLR 2013, (2013); Wang J., Zhu L., Dai T., Wang Y., Deep memory network with bi-lstm for personalized context-aware citation recommendation, Neurocomputing, 410, pp. 103-113, (2020); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5th International Conference on Learning Representations, ICLR 2017, (2017); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, 6th International Conference on Learning Representations, ICLR 2018, (2018); Kingma D.P., Ba J., Adam: A method for stochastic optimization, 3rd International Conference on Learning Representations, ICLR 2015, (2015); Xu L., Yang H., Liu C., Shuai J., Yan M., Lei Y., Xu Z., Two-stage attention-based model for code search with textual and structural features, 28th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2021, pp. 342-353, (2021); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation with hybrid lexical and syntactical information, Empir. Softw. Eng., 25, 3, pp. 2179-2217, (2020); Husain H., Wu H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet challenge: Evaluating the state of semantic code search, CoRR, (2019)",IEEE; IEEE Computer Society; Macau University of Science and Technology (MUST),"30th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",21 March 2023 through 24 March 2023,Macao,188717,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85160518672,189
Bibi N.; Maqbool A.; Rana T.; Afzal F.; Akgul A.; Eldin S.M.,"Bibi, Nazia (57208992640); Maqbool, Ayesha (57216201992); Rana, Tauseef (57206163105); Afzal, Farkhanda (56094716300); Akgul, Ali (58486733300); Eldin, Sayed M. (57925959400)",57208992640; 57216201992; 57206163105; 56094716300; 58486733300; 57925959400,Enhancing Semantic Code Search With Deep Graph Matching,2023,IEEE Access,11,,,52392,52411,19,3,10.1109/ACCESS.2023.3263878,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153339400&doi=10.1109%2fACCESS.2023.3263878&partnerID=40&md5=21f77dc33aad580599fa5861d5673b96,"The job of discovering appropriate code snippets against a natural language query is an important task for software developers. Appropriate code retrieval increases software productivity and quality as well. In contrast to traditional information retrieval techniques, code search necessitates bridging the semantic breach between programming languages and natural language to search code fragments. Deep neural networks for search codes have recently been a hot topic in research. The standard neural code quest approaches present source code and query in the form of text as independent embedding, then calculate the semantic similarity between them using vector distance (e.g., using cosine similarity). Although recent research utilized query and code snippets during code search, it overlooked the contained rich semantic information and deep structural features between them. In this study, we are also dealing with the problem of code search by providing a deep neural solution that facilitates software developers during software development. Our proposed model effectively used neural graph matching and a searching approach for semantic code retrieval. It first converts both query and code fragments in graph format and then the semantic matching module is used to facilitate the process of matching that will retrieve the best-matched code snippets. It not only exploits the enriched semantic meanings and features, but it also uses the cross-attention mechanism to learn the fine-grained similarity that exists between query and code. The proposed model's evaluation is done using the Codesearchnet dataset with six representative programming languages. It provides comparatively good results as compared to existing baselines. It enables users to find required code snippets, and ranking is used to retrieve top 10 results. The accuracy of the proposed system is approximately 97%.  © 2013 IEEE.","Hill E., Pollock L., Vijay-Shanker K., Improving source code search with natural language phrasal representations of method signatures, Proc. 26th IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 524-527, (2011); Linstead E., Bajracharya S., Ngo T., Rigor P., Lopes C., Baldi P., Sourcerer: Mining and searching internet-scale software repositories, Data Mining Knowl. Discovery, 18, 2, pp. 300-336, (2009); Lv F., Zhang H., Lou J.-G., Wang S., Zhang D., Zhao J., CodeHow: Effective code search based on API understanding and extended Boolean model (E), Proc. 30th IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 260-270, (2015); McMillan C., Grechanik M., Poshyvanyk D., Xie Q., Fu C., Portfolio: Finding relevant functions and their usage, Proc. 33rd Int. Conf. Softw. Eng., pp. 111-120, (2011); Sindhgatta R., Using an information retrieval system to retrieve source code samples, Proc. 28th Int. Conf. Softw. Eng., pp. 905-908, (2006); Ling X., Wu L., Wang S., Pan G., Ma T., Xu F., Liu A.X., Wu C., Ji S., Deep graph matching and searching for semantic code retrieval, Acm Trans. Knowl. Discovery from Data, 15, 5, pp. 1-21, (2021); Page L., Brin S., Motwani R., Winograd T., The Pagerank Citation Ranking: Bringing Order to the Web, (1999); Gu X., Zhang H., Kim S., Deep code search, Proc. IEEE/ACM 40th Int. Conf. Softw. Eng. (ICSE), pp. 933-944, (2018); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning Phrase Representations Using Rnn Encoder-decoder for Statistical Machine Translation, (2014); Cambronero J., Li H., Kim S., Sen K., Chandra S., When deep learning met code search, Proc. 27th Acm Joint Meeting Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng., pp. 964-974, (2019); Haldar R., Wu L., Xiong J., Hockenmaier J., A Multi-perspective Architecture for Semantic Code Search, (2020); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., CodeSearchNet Challenge: Evaluating the State of Semantic Code Search, (2019); Sachdev S., Li H., Luan S., Kim S., Sen K., Chandra S., Retrieval on source code: A neural code search, Proc. 2nd Acm Sigplan Int. Workshop Mach. Learn. Program. Lang., pp. 31-41, (2018); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P., Multimodal attention network learning for semantic source code retrieval, Proc. 34th IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 13-25, (2019); Yao Z., Peddamail J.R., Sun H., CoaCor: Code annotation for code retrieval with reinforcement learning, Proc. World Wide Web Conf., pp. 2203-2214, (2019); Yoon K., Convolutional Neural Networks for Sentence Classification [OL], (2014); Hochreiter S., Schmidhuber J., Long short-Term memory, Neural Comput., 9, 8, pp. 1735-1780, (1997); Devlin J., Chang M.-W., Lee K., Toutanova K., BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding, (2018); Kha Q.-H., Ho Q.-T., Le N.Q.K., Identifying SNARE proteins using an alignment-free method based on multiscan convolutional neural network and PSSM profiles, J. Chem. Inf. Model., 62, 19, pp. 4820-4826, (2022); Sua J.N., Lim S.Y., Yulius M.H., Su X., Yapp E.K.Y., Le N.Q.K., Yeh H.-Y., Chua M.C.H., Incorporating convolutional neural networks and sequence graph transform for identifying multilabel protein lysine PTM sites, Chemometric Intell. Lab. Syst., 206, (2020); Liu J., Kim S., Murali V., Chaudhuri S., Chandra S., Neural query expansion for code search, Proc. 3rd Acm Sigplan Int. Workshop Mach. Learn. Program. Lang., pp. 29-37, (2019); Zhu Q., Sun Z., Liang X., Xiong Y., Zhang L., OCoR: An overlapping-Aware code retriever, Proc. 35th IEEE/ACM Int. Conf. Automated Softw. Eng., pp. 883-894, (2020); Gu W., Li Z., Gao C., Wang C., Zhang H., Xu Z., Lyu M.R., CRaDLe: Deep code retrieval based on semantic dependency learning, Neural Netw., 141, pp. 385-394, (2021); Ling C., Lin Z., Zou Y., Xie B., Adaptive deep code search, Proc. 28th Int. Conf. Program Comprehension, pp. 48-59, (2020); Lam A.N., Nguyen A.T., Nguyen H.A., Nguyen T.N., Bug localization with combination of deep learning and information retrieval, Proc. IEEE/ACM 25th Int. Conf. Program Comprehension (ICPC), pp. 218-229, (2017); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proc. 28th Int. Conf. Program Comprehension, pp. 184-195, (2020); Li Y., Wang S., Nguyen T.N., Van Nguyen S., Improving bug detection via context-based code representation learning and attentionbased neural networks, Acm Program. Lang., 3, pp. 1-30, (2019); Wang W., Li G., Shen S., Xia X., Jin Z., Modular tree network for source code representation learning, Acm Trans. Softw. Eng. Methodology, 29, 4, pp. 1-23, (2020); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proc. IEEE/ACM 41st Int. Conf. Softw. Eng. (ICSE), pp. 783-794, (2019); Lan Z., Chen M., Goodman S., Gimpel K., Sharma P., Soricut R., ALBERT: A Lite Bert for Self-supervised Learning of Language Representations, (2019); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A Pre-Trained Model for Programming and Natural Languages, (2020); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Kun Deng S., Clement C., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., GraphCodeBERT: Pretraining Code Representations with Data Flow, (2020); Bojanowski P., Grave E., Joulin A., Mikolov T., Enriching word vectors with subword information, Trans. Assoc. Comput. Linguistics, 5, pp. 135-146, (2017); Ahmad W.U., Chakraborty S., Ray B., Chang K.-W., A Transformerbased Approach for Source Code Summarization, (2020); Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating Sequences from Structured Representations of Code, (2018); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proc. Program. Lang. (ACM), 3, pp. 1-29, (2019); Fernandes P., Allamanis M., Brockschmidt M., Structured Neural Summarization, (2018); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proc. 54th Annu. Meeting Assoc. Comput. Linguistics (Long Papers), 1, pp. 2073-2083, (2016); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Proc. Adv. Neural Inf. Process. Syst., 30, (2017); Oda Y., Fudaba H., Neubig G., Hata H., Sakti S., Toda T., Nakamura S., Learning to generate pseudo-code from source code using statistical machine translation, Proc. 30th IEEE/ACMInt. Conf. Automated Softw. Eng. (ASE), pp. 574-584, (2015); Brockschmidt M., Allamanis M., Gaunt A.L., Polozov O., Generative Code Modeling with Graphs, (2018); Alon U., Sadaka R., Levy O., Yahav E., Structural language models of code, Proc. Int. Conf. Mach. Learn., pp. 245-256, (2020); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, (2015); Hamilton W., Ying Z., Leskovec J., Inductive representation learning on large graphs, Proc. Adv. Neural Inf. Process. Syst., 30, (2017); Kipf T.N., Welling M., Semi-supervised Classification with Graph Convolutional Networks, (2016); Xu K., Wu L., Wang Z., Feng Y., Witbrock M., Sheinin V., Graph2Seq: Graph to Sequence Learning with Attention-based Neural Networks, (2018); Nair V., Hinton G.E., Rectified linear units improve restricted Boltzmann machines, Proc. 27th Int. Conf. Mach. Learn. (ICML), pp. 807-814, (2010); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, (2017); Cvitkovic M., Singh B., Anandkumar A., Open vocabulary learning on source code with a graph-structured cache, Proc. Int. Conf. Mach. Learn., pp. 1475-1485, (2019); Martin J.H., Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition., (2009); Chomsky N., Three models for the description of language, Ieee Trans. Inf. Theory, IT-2, 3, pp. 113-124, (1956); Rong Y., Xu T., Huang J., Huang W., Cheng H., Ma Y., Wang Y., Derr T., Wu L., Ma T., Deep graph learning: Foundations, advances and applications, Proc. 26th Acm Sigkdd Int. Conf. Knowl. Discovery Data Mining, pp. 3555-3556, (2020); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A comprehensive survey on graph neural networks, Ieee Trans. Neural Netw. Learn. Syst., 32, 1, pp. 4-24, (2021); Bronstein M.M., Bruna J., LeCun Y., Szlam A., Vandergheynst P., Geometric deep learning: Going beyond Euclidean data, Ieee Signal Process. Mag., 34, 4, pp. 18-42, (2017); Chen Y., Wu L., Zaki M., Iterative deep graph learning for graph neural networks: Better and robust node embeddings, Proc. Nips, 33, pp. 19314-19326, (2020); Gilmer J., Schoenholz S.S., Riley P.F., Vinyals O., Dahl G.E., Neural message passing for quantum chemistry, Proc. Int. Conf. Mach. Learn., pp. 1263-1272, (2017); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, Ieee Trans. Neural Netw., 20, 1, pp. 61-80, (2009); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph Attention Networks, (2017); Xu K., Hu W., Leskovec J., Jegelka S., Howpowerful Are Graph Neural Networks?, (2018); Zhang M., Chen Y., Link prediction based on graph neural networks, Proc. Adv. Neural Inf. Process. Syst., 31, (2018); Errica F., Podda M., Bacciu D., Micheli A., A Fair Comparison of Graph Neural Networks for Graph Classification, (2019); Wu L., Yen I.E.-H., Zhang Z., Xu K., Zhao L., Peng X., Xia Y., Aggarwal C., Scalable global alignment graph kernel using random features: From node embedding to graph embedding, Proc. 25th Acm Sigkdd Int. Conf. Knowl. Discovery Data Mining, pp. 1418-1428, (2019); Bai Y., Ding H., Bian S., Chen T., Sun Y., Wang W., SimGNN: A neural network approach to fast graph similarity computation, Proc. 12th Acm Int. Conf. Web Search Data Mining, pp. 384-392, (2019); Ling X., Wu L., Wang S., Ma T., Xu F., Liu A.X., Wu C., Ji S., Multilevel graph matching networks for deep graph similarity learning, Ieee Trans. Neural Netw. Learn. Syst., 34, 2, pp. 799-813, (2023); Zhang Z., Xiang Y., Wu L., Xue B., Nehorai A., KerGM: Kernelized graph matching, Proc. Adv. Neural Inf. Process. Syst., 32, (2019); Schlichtkrull M., Kipf T.N., Bloem P., Berg R.V.D., Titov I., Welling M., Modeling relational data with graph convolutional networks, Proc. Eur. Semantic Web Conf., pp. 593-607, (2018); Wang S., Jiang J., A Compare-Aggregate Model for Matching Text Sequences, (2016); Li H., Kim S., Chandra S., Neural Code Search Evaluation Dataset, (2019); Balntas V., Riba E., Ponsa D., Mikolajczyk K., Learning local feature descriptors with triplets and shallow convolutional neural networks, Proc. Brit. Mach. Vis. Conf., (2016); Du L., Shi X., Wang Y., Shi E., Han S., Zhang D., Is a single model enough? MuCoS: A multi-model ensemble learning approach for semantic code search, Proc. 30th ACMInt. Conf. Inf. Knowl. Manage., pp. 2994-2998, (2021); Wang Y., Du L., Shi E., Hu Y., Han S., Zhang D., CoCoGum: Contextual Code Summarization with Multi-relational Gnn on UMLs, (2020); Wang Y., Wang W., Joty S., Hoi S.C.H., CodeT5: Identifier-Aware Unified Pre-Trained Encoder-decoder Models for Code Understanding and Generation, (2021); Huang J., Tang D., Shou L., Gong M., Xu K., Jiang D., Zhou M., Duan N., CoSQA: 20, 000+ Web Queries for Code Search and Question Answering, (2021); Iyyer M., Manjunatha V., Boyd-Graber J., Daume H., Deep unordered composition rivals syntactic methods for text classification, Proc. 53rd Annu. Meeting Assoc. Comput. Linguistics 7th Int. Joint Conf. Natural Lang. Process. (Long Papers), pp. 1681-1691, (2015); Wang Z., Hamza W., Florian R., Bilateral Multi-perspective Matching for Natural Language Sentences, (2017); He K., Fan H., Wu Y., Xie S., Girshick R., Momentum contrast for unsupervised visual representation learning, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 9729-9738, (2020); Ye W., Xie R., Zhang J., Hu T., Wang X., Zhang S., Leveraging code generation to improve code retrieval and summarization via dual learning, Proc. Web Conf., pp. 2309-2319, (2020); Gu J., Chen Z., Monperrus M., Multimodal representation for neural code search, Proc. Ieee Int. Conf. Softw. Maintenance Evol. (ICSME), pp. 483-494, (2021); Li W., Qin H., Yan S., Shen B., Chen Y., Learning code-query interaction for enhancing code searches, Proc. Ieee Int. Conf. Softw. Maintenance Evol. (ICSME), pp. 115-126, (2020); Shuai J., Xu L., Liu C., Yan M., Xia X., Lei Y., Improving code search with co-Attentive representation learning, Proc. 28th Int. Conf. Program Comprehension, pp. 196-207, (2020); Raffel C., Shazeer N., Roberts A., Lee K., Narang S., Matena M., Zhou Y., Li W., Liu P.J., Exploring the limits of transfer learning with a unified text-To-Text transformer, J. Mach. Learn. Res., 21, 140, pp. 1-67, (2020)",,,,,,English,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85153339400,190
Shi Y.; Yin Y.; Wang Z.; Lo D.; Zhang T.; Xia X.; Zhao Y.; Xu B.,"Shi, Yucen (57210821365); Yin, Ying (7403273774); Wang, Zhengkui (37089837400); Lo, David (35269388000); Zhang, Tao (55547105895); Xia, Xin (54586248800); Zhao, Yuhai (55350109700); Xu, Bowen (57189036787)",57210821365; 7403273774; 37089837400; 35269388000; 55547105895; 54586248800; 55350109700; 57189036787,How to better utilize code graphs in semantic code search?,2022,ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,,,722,733,11,8,10.1145/3540250.3549087,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143074294&doi=10.1145%2f3540250.3549087&partnerID=40&md5=3fff757818bd06978797e83b1081d809,"Semantic code search greatly facilitates software reuse, which enables users to find code snippets highly matching user-specified natural language queries. Due to the rich expressive power of code graphs (e.g., control-flow graph and program dependency graph), both of the two mainstream research works (i.e., multi-modal models and pre-trained models) have attempted to incorporate code graphs for code modelling. However, they still have some limitations: First, there is still much room for improvement in terms of search effectiveness. Second, they have not fully considered the unique features of code graphs. In this paper, we propose a Graph-to-Sequence Converter, namely G2SC. Through converting the code graphs into lossless sequences, G2SC enables to address the problem of small graph learning using sequence feature learning and capture both the edges and nodes attribute information of code graphs. Thus, the effectiveness of code search can be greatly improved. In particular, G2SC first converts the code graph into a unique corresponding node sequence by a specific graph traversal strategy. Then, it gets a statement sequence by replacing each node with its corresponding statement. A set of carefully designed graph traversal strategies guarantee that the process is one-to-one and reversible. G2SC enables capturing rich semantic relationships (i.e., control flow, data flow, node/relationship properties) and provides learning model-friendly data transformation. It can be flexibly integrated with existing models to better utilize the code graphs. As a proof-of-concept application, we present two G2SC enabled models: GSMM (G2SC enabled multi-modal model) and GSCodeBERT (G2SC enabled CodeBERT model). Extensive experiment results on two real large-scale datasets demonstrate that GSMM and GSCodeBERT can greatly improve the state-of-the-art models MMAN and GraphCodeBERT by 92% and 22% on R@1, and 63% and 11.5% on MRR, respectively.  © 2022 ACM.","Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, International conference on machine learning, pp. 2091-2100, (2016); Allamanis M., Tarlow D., Gordon A., Wei Y., Bimodal modelling of source code and natural language, International conference on machine learning, pp. 2123-2132, (2015); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, pp. 1-29, (2019); Bajracharya S., Ngo T., Linstead E., Dou Y., Rigor P., Baldi P., Lopes C., Sourcerer: A search engine for open source code supporting structure-based search, Companion to the 21st ACM SIGPLAN symposium on Object-oriented programming systems, languages, and applications, pp. 681-682, (2006); Krishna Bajracharya S., Videira Lopes C., Analyzing and mining a code search engine usage log, Empirical Software Engineering, 17, 4-5, pp. 424-466, (2012); Khanh Dam H., Tran T., Pham T., A deep language model for software code, (2016); Devlin J., Chang M.-W., Lee K., Toutanova K., Bert: Pre-training of deep bidirectional transformers for language understanding, (2018); Du L., Shi X., Wang Y., Shi E., Han S., Zhang D., Is a Single Model Enough MuCoS: A Multi-Model Ensemble Learning for Semantic Code Search, (2021); Fang S., Tan Y.-S., Zhang T., Liu Y., Self-Attention Networks for Code Search, Information and Software Technology, (2021); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A Pre-Trained Model for Programming and Natural Languages (Findings of ACL, Vol. EMNLP 2020)., pp. 1536-1547, (2020); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Transactions on Programming Languages and Systems (TOPLAS), 9, 3, pp. 319-349, (1987); Gu J., Chen Z., Monperrus M., Multimodal Representation for Neural Code Search, 2021 IEEE International Conference on Software Maintenance and Evolution (ICSME). IEEE, pp. 483-494, (2021); Gu X., Zhang H., Kim S., Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE). IEEE, pp. 933-944, (2018); Gu X., Zhang H., Zhang D., Kim S., Deep API learning, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 631-642, (2016); Gu X., Zhang H., Zhang D., Kim S., DeepAM: Migrate APIs with multi-modal sequence to sequence learning, (2017); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Kun Deng S., Clement C.B., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., GraphCodeBERT: Pre-training Code Representations with Data Flow, 9th International Conference on Learning Representations, ICLR 2021, (2021); Gvero T., Kuncak V., Interactive synthesis using free-form queries, 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, Vol. 2. IEEE, pp. 689-692, (2015); Hill E., Pollock L., Vijay-Shanker K., Improving source code search with natural language phrasal representations of method signatures, 2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011). IEEE, pp. 524-527, (2011); Hu W., Fey M., Zitnik M., Dong Y., Ren H., Liu B., Catasta M., Leskovec J., Open graph benchmark: Datasets for machine learning on graphs, (2020); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, 2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC). IEEE, pp. 200-20010, (2018); Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., Summarizing source code with transferred api knowledge, (2018); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet challenge: Evaluating the state of semantic code search, (2019); Keivanloo I., Rilling J., Zou Y., Spotting working code examples, Proceedings of the 36th International Conference on Software Engineering, pp. 664-675, (2014); Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2014); Koders, (2020); Krugle, (2020); Ngoc Lam A., Tuan Nguyen A., Anh Nguyen H., Nguyen T.N., Combining deep learning with information retrieval to localize buggy files for bug reports (n), 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 476-481, (2015); Li X., Jiang H., Kamei Y., Chen X., Bridging semantic gaps between natural languages and APIs with word embedding, IEEE Transactions on Software Engineering, (2018); Lu J., Wei Y., Sun X., Li B., Wen W., Zhou C., Interactive query reformulation for source-code search with word relations, IEEE Access, 6, pp. 75660-75668, (2018); Lu M., Sun X., Wang S., Lo D., Duan Y., Query expansion via wordnet for effective code search, 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER). IEEE, pp. 545-549, (2015); Lv F., Zhang H., Lou J.-G., Wang S., Zhang D., Zhao J., Codehow: Effective code search based on api understanding and extended boolean model (e), 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 260-270, (2015); McMillan C., Grechanik M., Poshyvanyk D., Xie Q., Fu C., Portfolio: finding relevant functions and their usage, Proceedings of the 33rd International Conference on Software Engineering, pp. 111-120, (2011); Mikolov T., Karafiat M., Burget L., Cernocky J., Khudanpur S., Recurrent neural network based language model, Interspeech, 2, pp. 1045-1048, (2010); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, (2014); Duc Nguyen T., Tuan Nguyen A., Dang Phan H., Nguyen T.N., Exploring API embedding for API usages and applications, 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE). IEEE, pp. 438-449, (2017); ohloh, (2020); Peng H., Mou L., Li G., Liu Y., Zhang L., Jin Z., Building program vector representations for deep learning, International Conference on Knowledge Science, Engineering and Management, pp. 547-553, (2015); Piech C., Huang J., Nguyen A., Phulsuksombati M., Sahami M., Guibas L., Learning program embeddings to propagate feedback on student code, (2015); Raffel C., Shazeer N., Roberts A., Lee K., Narang S., Matena M., Zhou Y., Li W., Liu P.J., Exploring the limits of transfer learning with a unified text-to-text transformer, (2019); Masudur Rahman M., Roy C.K., QUICKAR: Automatic query reformulation for concept location using crowdsourced knowledge, 2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 220-225, (2016); Raychev V., Vechev M., Yahav E., Code completion with statistical language models, Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 419-428, (2014); Reiss S.P., Semantics-based code search, 2009 IEEE 31st International Conference on Software Engineering. IEEE, pp. 243-253, (2009); Sutskever I., Vinyals O., Le Q.V., Sequence to sequence learning with neural networks, (2014); Van Nguyen T., Tuan Nguyen A., Dang Phan H., Duc Nguyen T., Nguyen T.N., Combining word2vec with revised vector space model for better code retrieval, 2017 IEEE/ACM 39th International Conference on Software Engineering Companion (ICSE-C). IEEE, pp. 183-185, (2017); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P., Multi-modal attention network learning for semantic source code retrieval, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 13-25, (2019); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Wang Y., Wang W., Joty S., Hoi S.C.H., Codet5: Identifieraware unified pre-trained encoder-decoder models for code understanding and generation, (2021); Wei B., Li G., Xia X., Fu Z., Jin Z., Code generation as a dual task of code summarization, Advances in Neural Information Processing Systems, pp. 6563-6573, (2019); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, 2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 87-98, (2016); Xia X., Lo D., An effective change recommendation approach for supplementary bug fixes, automated software engineering, 24, 2, pp. 455-498, (2017); Xu L., Yang H., Liu C., Shuai J., Yan M., Lei Y., Xu Z., Two-Stage Attention-Based Model for Code Search with Textual and Structural Features, 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, pp. 342-353, (2021); Yao Z., Reddy Peddamail J., Sun H., Coacor: Code annotation for code retrieval with reinforcement learning, The World Wide Web Conference, pp. 2203-2214, (2019); Ye W., Xie R., Zhang J., Hu T., Wang X., Zhang S., Leveraging code generation to improve code retrieval and summarization via dual learning, Proceedings of The Web Conference 2020, pp. 2309-2319, (2020); Zhang H., Jain A., Khandelwal G., Kaushik C., Ge S., Hu W., Bing developer assistant: improving developer productivity by recommending sample code, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 956-961, (2016); Zhou J., Walker R.J., API deprecation: A retrospective analysis and detection method for code examples on the web, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 266-277, (2016)",ACM SIGSOFT; National University of Singapore,"30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2022",14 November 2022 through 18 November 2022,Singapore,184166,English,Conference paper,Final,,Scopus,2-s2.0-85143074294,191
Zhao W.; Liu Y.,"Zhao, Wei (57466082900); Liu, Yan (56023515500)",57466082900; 56023515500,Utilizing Edge Attention in Graph-Based Code Search,2022,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",,,,60,66,6,0,10.18293/SEKE2022-078,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137157657&doi=10.18293%2fSEKE2022-078&partnerID=40&md5=5a5fdb1837e9cbd46a4d24033f0e7cb9,"Code search refers to searching code snippets with specific functions in a large codebase according to natural language description. Classic code search approaches, using information retrieval technologies, fail to utilize code semantics and bring noisy and irrelevant. During the last recent years, there has been an ample increase in the number of deep learning-based approaches, which embeds lexical semantics into unified vectors to achieve higher-level mapping between natural language queries and source code. However, these approaches are struggling with how to mine and utilize deep code semantics. In this work, we study how to leverage deeper source code semantics in graph-based source code search, given graph-based representation is a promising way of capturing program and has rich explainability. We propose a novel code search approach called EAGCS (Edge Attention-based Graph Code Search), which is composed of a novel code graph representation method called APDG (Advanced Program Dependence Graph) and a graph neural network called EAGGNN (Edge Attention-based GGNN) which can learn the latent code semantics of APDG. Experiment results demonstrate that our model outperforms the GGNN-based search model and DeepCS. Moreover, our comparison study shows that different edge enhancement strategies have different contributions to learning the code semantics. © 2022 Knowledge Systems Institute Graduate School. All rights reserved.","Brandt J., Guo P. J., Lewenstein J., Dontcheva M., Klemmer S. R., Two studies of opportunistic programming: interleaving web foraging, learning, and writing code, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 1589-1598, (2009); Kevic K., Fritz T., Automatic search term identification for change tasks, Companion Proceedings of the 36th International Conference on Software Engineering, pp. 468-471, (2014); Nerur S., Balijepally V. G., Theoretical reflections on agile development methodologies, Communications of the ACM, pp. 79-83, (2007); Github; Stack Overflow; Gu X., Zhang H., Kim S., Deep Code Search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE), pp. 933-944, (2018); Ben-Nun T., Jakobovits A. S., Hoefler T., Neural code comprehension: A learnable representation of code semantics, Advances in Neural Information Processing Systems, (2018); Neamtiu I., Foster J. S., Hicks M., Understanding source code evolution using abstract syntax tree matching, Proceedings of the 2005 international workshop on Mining software repositories, pp. 1-5, (2005); Ling X., Wu L., Wang S., Pan G., Ma T., Xu F., Liu A. X., Wu C., Ji S., Deep graph matching and searching for semantic code retrieval, ACM Transactions on Knowledge Discovery from Data (TKDD), pp. 1-21, (2021); Zeng C., Yu Y., Li S., Xia X., Wang Z., Geng M., Xiao B., Dong W., Liao X., deGraphCS: Embedding Variable-based Flow Graph for Neural Code Search, (2021); Ferrante J., Ottenstein K. J., Warren J. D., The program dependence graph and its use in optimization, ACM Transactions on Programming Languages and Systems (TOPLAS), pp. 319-349, (1987); Patil S. S., Automated Vulnerability Detection in Java Source Code using J-CPG and Graph Neural Network, (2021); Li Y., Zemel R., Brockschmidt M., Tarlow D., Gated Graph Sequence Neural Networks, Proceedings of ICLR'16, (2016); Lv F., Zhang H., Lou J. -g., Wang S., Zhang D., Zhao J., CodeHow: Effective Code Search Based on API Understanding and Extended Boolean Model (E), 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 260-270, (2015); McMillan C., Grechanik M., Poshyvanyk D., Xie Q., Fu C., Portfolio: finding relevant functions and their usage, Proceedings of the 33rd International Conference on Software Engineering, pp. 111-120, (2011); Shuai J., Xu L., Liu C., Yan M., Xia X., Lei Y., Improving code search with co-attentive representation learning, Proceedings of the 28th International Conference on Program Comprehension, pp. 196-207, (2020); Fang S., Tan Y. S., Zhang T., Liu Y., Self-Attention Networks for Code Search, Information and Software Technology, 134, (2021); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P., Multi-modal attention network learning for semantic source code retrieval, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 13-25, (2019); Liu S., Xie X., Siow J., Ma L., Meng G., Liu Y., GraphSearchNet: Enhancing GNNs via Capturing Global Dependency for Semantic Code Search, (2021); Sirres R., Bissyande T. F., Kim D., Lo D., Klein J., Kim K., Traon Y. L., Augmenting and structuring user queries to support efficient free-form code search, Empirical Software Engineering, 23, 5, pp. 2622-2654, (2018); Xuan L., Wang Q., Jin Z., Description Reinforcement Based Code Search, Journal of Software, (2017); Kenter T., Borisov A., De Rijke M., Siamese cbow: Optimizing word embeddings for sentence representations, (2016); Lazaridou A., Pham N. T., Baroni M., Combining language and vision with a multimodal skip-gram model, (2015); Lam P., Bodden E., Lhotak O., Hendren L., The Soot framework for Java program analysis: a retrospective, Cetus Users and Compiler Infastructure Workshop (CETUS 2011), 15, 35, (2011); Kingma D. P., Ba J., Adam: A method for stochastic optimization, (2014)",Knowledge Systems Institute Graduate School; KSI Research Inc.,"34th International Conference on Software Engineering and Knowledge Engineering, SEKE 2022",1 July 2022 through 10 July 2022,Pittsburgh,182297,English,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85137157657,192
Ling X.; Wu L.; Wang S.; Pan G.; Ma T.; Xu F.; Liu A.X.; Wu C.; Ji S.,"Ling, Xiang (57201738965); Wu, Lingfei (56937260100); Wang, Saizhuo (57219760371); Pan, Gaoning (57212103746); Ma, Tengfei (57194786822); Xu, Fangli (57203385200); Liu, Alex X. (57203657062); Wu, Chunming (8061852400); Ji, Shouling (36918358000)",57201738965; 56937260100; 57219760371; 57212103746; 57194786822; 57203385200; 57203657062; 8061852400; 36918358000,Deep Graph Matching and Searching for Semantic Code Retrieval,2021,ACM Transactions on Knowledge Discovery from Data,15,5,3447571,,,,54,10.1145/3447571,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108944290&doi=10.1145%2f3447571&partnerID=40&md5=14c8a672080f2758dab68933fd5645df,"Code retrieval is to find the code snippet from a large corpus of source code repositories that highly matches the query of natural language description. Recent work mainly uses natural language processing techniques to process both query texts (i.e., human natural language) and code snippets (i.e., machine programming language), however, neglecting the deep structured features of query texts and source codes, both of which contain rich semantic information. In this article, we propose an end-to-end deep graph matching and searching (DGMS) model based on graph neural networks for the task of semantic code retrieval. To this end, we first represent both natural language query texts and programming language code snippets with the unified graph-structured data, and then use the proposed graph matching and searching model to retrieve the best matching code snippet. In particular, DGMS not only captures more structural information for individual query texts or code snippets, but also learns the fine-grained similarity between them by cross-attention based semantic matching operations. We evaluate the proposed DGMS model on two public code retrieval datasets with two representative programming languages (i.e., Java and Python). Experiment results demonstrate that DGMS significantly outperforms state-of-the-art baseline models by a large margin on both datasets. Moreover, our extensive ablation studies systematically investigate and illustrate the impact of each part of DGMS. © 2021 ACM.","Ahmad W., Chakraborty S., Ray B., Chang K., A transformer-based approach for source code summarization, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 4998-5007, (2020); Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Computing Surveys, 51, 4, pp. 1-37, (2018); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, Proceedings of the International Conference on Learning Representations, (2018); Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating sequences from structured representations of code, Proceedings of the International Conference on Learning Representations, (2019); Alon U., Sadaka R., Levy O., Yahav E., Structural language models of code, Proceedings of the Thirty-seventh International Conference on Machine Learning. PMLR, Virtual Event, pp. 245-256, (2020); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, pp. 401-4029, (2019); Bai Y., Ding H., Bian S., Chen T., Sun Y., Wang W., Simgnn: A neural network approach to fast graph similarity computation, Proceedings of the 12th ACM International Conference on Web Search and Data Mining, pp. 384-392, (2019); Balntas V., Riba E., Ponsa D., Mikolajczyk K., Learning local feature descriptors with triplets and shallow convolutional neural networks, Proceedings of the British Machine Vision Conference, (2016); Bojanowski P., Grave E., Joulin A., Mikolov T., Enriching word vectors with subword information, Transactions of the Association for Computational Linguistics, 5, pp. 135-146, (2017); Brockschmidt M., Allamanis M., Gaunt A.L., Polozov O., Generative code modeling with graphs, Proceedings of the International Conference on Learning Representations, (2019); Bromley J., Guyon I., Lecun Y., Sackinger E., Shah R., Signature verification using a ""siamese"" time delay neural network, Proceedings of the Advances in Neural Information Processing Systems, pp. 737-744, (1993); Bronstein M.M., Bruna J., Lecun Y., Szlam A., Vandergheynst P., Geometric deep learning: Going beyond euclidean data, IEEE Signal Processing Magazine, 34, 4, pp. 18-42, (2017); Cambronero J., Li H., Kim S., Sen K., Chandra S., When deep learning met code search, Proceedings of the 2019 27th ACMJoint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 964-974, (2019); Chen Y., Wu L., Zaki M., Iterative deep graph learning for graph neural networks: Better and robust node embeddings, Proceedings of the Advances in Neural Information Processing Systems, (2020); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using rnn encoder-decoder for statistical machine translation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pp. 1724-1734, (2014); Chomsky N., Three models for the description of language, IRE Transactions on Information Theory, 2, 3, pp. 113-124, (1956); Collobert R., Bengio S., Links between perceptrons, mlps and svms, Proceedings of the 21st International Conference on Machine Learning, (2004); Cvitkovic M., Singh B., Anandkumar A., Open vocabulary learning on source code with a graph-structured cache, Proceedings of the 36th International Conference on Machine Learning, pp. 1475-1485, (2019); Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-training of deep bidirectional transformers for language understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4171-4186, (2019); Errica F., Podda M., Bacciu D., Micheli A., A fair comparison of graph neural networks for graph classification, Proceedings of the International Conference on Learning Representations, (2020); Releasing A New Benchmark and Data Set for Evaluating Neural Code Search Models, (2019); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, Proceedings of the International Conference on Learning Representations, (2019); Fey M., Lenssen J.E., Fast graph representation learning with pytorch geometric, Proceedings of the ICLR Workshop on Representation Learning on Graphs AndManifolds, (2019); Gilmer J., Schoenholz S.S., Riley P.F., Vinyals O., Dahl G.E., Neural message passing for quantum chemistry, Proceedings of the 34th International Conference on Machine Learning, pp. 1263-1272, (2017); Gu X., Zhang H., Kim S., Deep code search, Proceedings of the 40th International Conference on Software Engineering, pp. 933-944, (2018); Haldar R., Wu L., Xiong J., Hockenmaier J., A multi-perspective architecture for semantic code search, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 8563-8568, (2020); Hamilton W., Ying Z., Leskovec J., Inductive representation learning on large graphs, Proceedings of the Advances in Neural Information Processing Systems, pp. 1024-1034, (2017); Hill E., Pollock L., Vijay-Shanker K., Improving source code search with natural language phrasal representations of method signatures, Proceedings of the 26th IEEE/ACM International Conference on Automated Software Engineering, pp. 524-527, (2011); Hochreiter S., Schmidhuber J., Long short-termmemory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Husain H., Wu H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet Challenge: Evaluating the State of Semantic Code Search, (2019); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2073-2083, (2016); Jurafsky D., Martin J.H., Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition (3rd Draft Ed. ), (2019); Kim Y., Convolutional neural networks for sentence classification, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pp. 1746-1751, (2014); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, Proceedings of the 5th International Conference on Learning Representations, (2017); Leclair A., Haque S., Wu L., McMillan C., Improved Code Summarization Via A Graph Neural Network, (2020); Li H., Kim S., Chandra S., Neural Code Search Evaluation Dataset, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, Proceedings of the 4th International Conference on Learning Representations, (2016); Ling X., Wu L., Wang S., Ma T., Xu F., Liu A.X., Wu C., Ji S., Multi-Level Graph Matching Networks for Deep Graph Similarity Learning, (2020); Linstead E., Bajracharya S., Ngo T., Rigor P., Lopes C., Baldi P., Sourcerer: Mining searching internet-scale software repositories, Data Mining and Knowledge Discovery, 18, 2, pp. 300-336, (2009); Lv F., Zhang H., Lou J., Wang S., Zhang D., Zhao J., Codehow: Effective code search based on api understanding and extended boolean model, Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering. IEEE Computer Society, Lincoln, NE, pp. 260-270, (2015); Manning C.D., Surdeanu M., Bauer J., Finkel J., Bethard S.J., McClosky D., The stanford corenlp natural language processing toolkit, Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, Baltimore, MD, pp. 55-60, (2014); McMillan C., Grechanik M., Poshyvanyk D., Xie Q., Fu C., Portfolio: Finding relevant functions and their usage, Proceedings of the 33rd International Conference on Software Engineering, pp. 111-120, (2011); Oda Y., Fudaba H., Neubig G., Hata H., Sakti S., Toda T., Nakamura S., Learning to generate pseudo-code from source code using statistical machine translation (t), Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering. IEEE Computer Society, Lincoln, NE, pp. 574-584, (2015); Page L., Brin S., Motwani R., Winograd T., The pagerank citation ranking: Bringing order to the web, Technical Report 1999-66. Stanford InfoLab, (1999); Paszke A., Gross S., Massa F., Lerer A., Bradbury J., Chanan G., Killeen T., Lin Z., Gimelshein N., Antiga L., Desmaison A., Kopf A., Yang E., Devito Z., Raison M., Tejani A., Chilamkurthy S., Steiner B., Fang L., Bai J., Chintala S., PyTorch: An imperative style, high-performance deep learning library, Proceedings of the Advances in Neural Information Processing Systems, pp. 8026-8037, (2019); Pennington J., Socher R., Manning C.D., GloVe: Global vectors for word representation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pp. 1532-1543, (2014); Rong Y., Xu T., Huang J., Huang W., Cheng H., Ma Y., Wang Y., Derr T., Wu L., Ma T., Deep graph learning: Foundations, advances and applications, Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, pp. 3555-3556, (2020); Sachdev S., Li H., Luan S., Kim S., Sen K., Chandra S., Retrieval on source code: A neural code search, Proceedings of the 2nd ACM SIGPLAN InternationalWorkshop on Machine Learning and Programming Languages, pp. 31-41, (2018); Scarselli F., Gori M., Chung Tsoi A., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Transactions on Neural Networks, 20, 1, pp. 61-80, (2008); Schlichtkrull M., Kipf T.N., Bloem P., Van Den Berg R., Titov I., Welling M., Modeling relational data with graph convolutional networks, Proceedings of the European Semantic Web Conference, pp. 593-607, (2018); Sindhgatta R., Using an information retrieval system to retrieve source code samples, Proceedings of the 28th International Conference on Software Engineering, pp. 905-908, (2006); Slonneger K., Kurtz B.L., Formal Syntax and Semantics of Programming Languages, (1995); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser U., Polosukhin I., Attention is all you need, Proceedings of the Advances in Neural Information Processing Systems, pp. 5998-6008, (2017); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, Proceedings of the 6th International Conference on Learning Representations, (2018); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P., Multi-modal attention network learning for semantic source code retrieval, Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering, pp. 13-25, (2019); Wang S., Jiang J., A compare-aggregate model for matching text sequences, Proceedings of the International Conference on Learning Representations, (2017); Wang Z., Hamza W., Florian R., Bilateral multi-perspective matching for natural language sentences, Proceedings of the 26th International Joint Conference on Artificial Intelligence, pp. 4144-4150, (2017); Wu L., En-Hsu Yen I., Zhang Z., Xu K., Zhao L., Peng X., Xia Y., Aggarwal C., Scalable global alignment graph kernel using random features: From node embedding to graph embedding, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 1418-1428, (2019); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu Philip S., A comprehensive survey on graph neural networks, IEEE Transactions on Neural Networks and Learning Systems, 32, 1, pp. 4-24, (2021); Xie T., Grossman J.C., Crystal graph convolutional neural networks for an accurate and interpretable prediction of material properties, Physical Review Letters, 120, 14, (2018); Xu K., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks?, Proceedings of the 7th International Conference on Learning Representations, (2019); Yao Z., Reddy Peddamail J., Sun H., CoaCor: Code annotation for code retrieval with reinforcement learning, Proceedings of the World Wide Web Conference, pp. 2203-2214, (2019); Zhang M., Chen Y., Link prediction based on graph neural networks, Proceedings of the Advances in Neural Information Processing Systems, pp. 5165-5175, (2018); Zhang Z., Xiang Y., Wu L., Xue B., Nehorai A., KerGM: Kernelized graph matching, Proceedings of the Advances in Neural Information Processing Systems, pp. 3335-3346, (2019)",,,,,,English,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85108944290,193
Wan Y.; Shu J.; Sui Y.; Xu G.; Zhao Z.; Wu J.; Yu P.,"Wan, Yao (57089582400); Shu, Jingdong (57214675282); Sui, Yulei (54788439800); Xu, Guandong (8987733300); Zhao, Zhou (55959624600); Wu, Jian (56197228100); Yu, Philip (7402366049)",57089582400; 57214675282; 54788439800; 8987733300; 55959624600; 56197228100; 7402366049,Multi-modal attention network learning for semantic source code retrieval,2019,"Proceedings - 2019 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019",,,8952337,13,25,12,118,10.1109/ASE.2019.00012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074667252&doi=10.1109%2fASE.2019.00012&partnerID=40&md5=091ed6e4921d176bf474c05372e6bc36,"Code retrieval techniques and tools have been playing a key role in facilitating software developers to retrieve existing code fragments from available open-source repositories given a user query (e.g., a short natural language text describing the functionality for retrieving a particular code snippet). Despite the existing efforts in improving the effectiveness of code retrieval, there are still two main issues hindering them from being used to accurately retrieve satisfiable code fragments from large-scale repositories when answering complicated queries. First, the existing approaches only consider shallow features of source code such as method names and code tokens, but ignoring structured features such as abstract syntax trees (ASTs) and control-flow graphs (CFGs) of source code, which contains rich and well-defined semantics of source code. Second, although the deep learning-based approach performs well on the representation of source code, it lacks the explainability, making it hard to interpret the retrieval results and almost impossible to understand which features of source code contribute more to the final results. To tackle the two aforementioned issues, this paper proposes MMAN, a novel Multi-Modal Attention Network for semantic source code retrieval. A comprehensive multi-modal representation is developed for representing unstructured and structured features of source code, with one LSTM for the sequential tokens of code, a Tree-LSTM for the AST of code and a GGNN (Gated Graph Neural Network) for the CFG of code. Furthermore, a multi-modal attention fusion layer is applied to assign weights to different parts of each modality of source code and then integrate them into a single hybrid representation. Comprehensive experiments and analysis on a large-scale real-world dataset show that our proposed model can accurately retrieve code snippets and outperforms the state-of-the-art methods. © 2019 IEEE.","GitHub, (2019); StackOverflow, (2019); Reiss S.P., Semantics-based code search, Proceedings of the 31st International Conference on Software Engineering, pp. 243-253, (2009); Lu M., Sun X., Wang S., Lo D., Duan Y., Query expansion via wordnet for effective code search, 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER), pp. 545-549, (2015); Lv F., Zhang H., Lou J.-G., Wang S., Zhang D., Zhao J., Codehow: Effective code search based on api understanding and extended boolean model (e), 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 260-270, (2015); Gu X., Zhang H., Kim S., Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE), pp. 933-944, (2018); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, pp. 87-98, (2016); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Aho A.V., Sethi R., Ullman J.D., Compilers, Principles, Techniques, 7, 8, (1986); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Tai K.S., Socher R., Manning C.D., Improved Semantic Representations from Tree-Structured Long Short-Term Memory Networks, (2015); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, (2015); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, AAAI, 2, 3, (2016); Piech C., Huang J., Nguyen A., Phulsuksombati M., Sahami M., Guibas L., Learning Program Embeddings to Propagate Feedback on Student Code, (2015); Parisotto E., Mohamed A.-R., Singh R., Li L., Zhou D., Kohli P., Neuro-Symbolic Program Synthesis, (2016); Maddison C., Tarlow D., Structured generative models of natural source code, International Conference on Machine Learning, pp. 649-657, (2014); Dam H.K., Tran T., Pham T., A Deep Language Model for Software Code, (2016); Ling W., Grefenstette E., Hermann K.M., Kocisky T., Senior A., Wang F., Blunsom P., Latent Predictor Networks for Code Generation, (2016); Allamanis M., Tarlow D., Gordon A., Wei Y., Bimodal modelling of source code and natural language, International Conference on Machine Learning, pp. 2123-2132, (2015); Chen J., Zhuge H., Abstractive text-image summarization using multi-modal attentional hierarchical rnn, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 4046-4056, (2018); Zhang J.-G., Zou P., Li Z., Wan Y., Pan X., Gong Y., Yu P.S., Multi-modal generative adversarial network for short product title generation in mobile e-commerce, NAACL HLT 2019, pp. 64-72, (2019); Kim K.-M., Choi S.-H., Kim J.-H., Zhang B.-T., Multimodal dual attention memory for video story question answering, Proceedings of the European Conference on Computer Vision (ECCV), pp. 673-688, (2018); Hori C., Alamri H., Wang J., Wichern G., Hori T., Cherian A., Marks T.K., Cartillier V., Lopes R.G., Das A., Et al., End-to-end audio visual scene-Aware dialog using multimodal attention-based video features, ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 2352-2356, (2019); Carvalho M., Cadne R., Picard D., Soulier L., Thome N., Cord M., Cross-modal retrieval in the cooking context: Learning semantic text-image embeddings, The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, pp. 35-44, (2018); Ma L., Lu Z., Shang L., Li H., Multimodal convolutional neural networks for matching image and sentence, Proceedings of the IEEE International Conference on Computer Vision, pp. 2623-2631, (2015); Cao Y., Long M., Wang J., Yang Q., Yu P.S., Deep visual-semantic hashing for cross-modal retrieval, Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1445-1454, (2016); Jiang Q.-Y., Li W.-J., Deep cross-modal hashing, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3232-3240, (2017); Bahdanau D., Cho K., Bengio Y., Neural Machine Translation by Jointly Learning to Align and Translate, (2014); You Q., Jin H., Wang Z., Fang C., Luo J., Image captioning with semantic attention, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4651-4659, (2016); Xiao T., Xu Y., Yang K., Zhang J., Peng Y., Zhang Z., The application of two-level attention models in deep convolutional neural network for fine-grained image classification, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 842-850, (2015); Lu J., Yang J., Batra D., Parikh D., Hierarchical question-image co-Attention for visual question answering, Advances in Neural Information Processing Systems, pp. 289-297, (2016); Mnih V., Heess N., Graves A., Et al., Recurrent models of visual attention, Advances in Neural Information Processing Systems, pp. 2204-2212, (2014); Stollenga M.F., Masci J., Gomez F., Schmidhuber J., Deep networks with internal selective attention through feedback connections, Advances in Neural Information Processing Systems, pp. 3545-3553, (2014); Gregor K., Danihelka I., Graves A., Rezende D.J., Wierstra D., Draw: A Recurrent Neural Network for Image Generation, (2015); Xu K., Ba J., Kiros R., Cho K., Courville A., Salakhudinov R., Zemel R., Bengio Y., Show, attend and tell: Neural image caption generation with visual attention, International Conference on Machine Learning, pp. 2048-2057, (2015); Yang Z., He X., Gao J., Deng L., Smola A., Stacked attention networks for image question answering, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 21-29, (2016); Xiong C., Merity S., Socher R., Dynamic memory networks for visual and textual question answering, International Conference on Machine Learning, pp. 2397-2406, (2016); Shih K.J., Singh S., Hoiem D., Where to look: Focus regions for visual question answering, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4613-4621, (2016); Li J., Luong M.-T., Jurafsky D., A Hierarchical Neural Autoencoder for Paragraphs and Documents, (2015); Rush A.M., Chopra S., Weston J., A Neural Attention Model for Abstractive Sentence Summarization, (2015); Kumar A., Irsoy O., Ondruska P., Iyyer M., Bradbury J., Gulrajani I., Zhong V., Paulus R., Socher R., Ask me anything: Dynamic memory networks for natural language processing, International Conference on Machine Learning, pp. 1378-1387, (2016); Nam H., Ha J.-W., Kim J., Dual attention networks for multimodal reasoning and matching, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 299-307, (2017); Paulus R., Xiong C., Socher R., A Deep Reinforced Model for Abstractive Summarization, (2017); Zhang H., Goodfellow I., Metaxas D., Odena A., Self-Attention Generative Adversarial Networks, (2018); Baltrusaitis T., Ahuja C., Morency L.-P., Multimodal machine learning: A survey and taxonomy, IEEE Transactions on Pattern Analysis and Machine Intelligence, 41, 2, pp. 423-443, (2019); Luong M.-T., Pham H., Manning C.D., Effective Approaches to Attention-Based Neural Machine Translation, (2015); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in Neural Information Processing Systems, pp. 5998-6008, (2017); Cheng J., Dong L., Lapata M., Long Short-Term Memory-Networks for Machine Reading, (2016); Parikh A.P., Tackstrom O., Das D., Uszkoreit J., A Decomposable Attention Model for Natural Language Inference, (2016); Chung J., Gulcehre C., Cho K., Bengio Y., Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling, (2014); Kiros R., Salakhutdinov R., Zemel R.S., Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models, (2014); Martin R.C., Clean Code: A Handbook of Agile Software Craftsmanship, (2009); Sui Y., Xue J., Svf: Interprocedural static value-flow analysis in llvm, Proceedings of the 25th International Conference on Compiler Construction, pp. 265-266, (2016); Sui Y., Ye D., Xue J., Detecting memory leaks statically with full-sparse value-flow analysis, IEEE Transactions on Software Engineering, 40, 2, pp. 107-122, (2014); Sui Y., Xue J., On-demand strong update analysis via value-flow refinement, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, 2016, pp. 460-473; Kilickaya M., Erdem A., Ikizler-Cinbis N., Erdem E., Re-Evaluating Automatic Metrics for Image Captioning, (2016); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, (2014)",ACM SIGAI; Association for Computing Machinery (ACM); IEEE; IEEE Computer Society; IEEE Technical Council on Software Engineering (TCSE); Special Interest Group on Software Engineering (SIGSOFT),"34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019",10 November 2019 through 15 November 2019,San Diego,156781,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85074667252,194
Mehrotra N.; Sharma A.; Jindal A.; Purandare R.,"Mehrotra, Nikita (57220046769); Sharma, Akash (58734869200); Jindal, Anmol (58599040200); Purandare, Rahul (21743722600)",57220046769; 58734869200; 58599040200; 21743722600,Improving Cross-Language Code Clone Detection via Code Representation Learning and Graph Neural Networks,2023,IEEE Transactions on Software Engineering,49,11,,4846,4868,22,3,10.1109/TSE.2023.3311796,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171552856&doi=10.1109%2fTSE.2023.3311796&partnerID=40&md5=184af2dea409f1cc30a0e20bdf4e97d8,"Code clone detection is an important aspect of software development and maintenance. The extensive research in this domain has helped reduce the complexity and increase the robustness of source code, thereby assisting bug detection tools. However, the majority of the clone detection literature is confined to a single language. With the increasing prevalence of cross-platform applications, functionality replication across multiple languages is common, resulting in code fragments having similar functionality but belonging to different languages. Since such clones are syntactically unrelated, single language clone detection tools are not applicable in their case. In this article, we propose a semi-supervised deep learning-based tool Rubhus, capable of detecting clones across different programming languages. Rubhus uses the control and data flow enriched abstract syntax trees (ASTs) of code fragments to leverage their syntactic and structural information and then applies graph neural networks (GNNs) to extract this information for the task of clone detection. We demonstrate the effectiveness of our proposed system through experiments conducted over datasets consisting of Java, C, and Python programs and evaluate its performance in terms of precision, recall, and F1 score. Our results indicate that Rubhus outperforms the state-of-the-art cross-language clone detection tools.  © 1976-2012 IEEE.","Roy C.K., Cordy J.R., A survey on software clone detection research, (2007); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proc. 31st IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE)., pp. 87-98, (2016); Kraft N.A., Bonds B.W., Smith R.K., Cross-language clone detection, Proc. 20th Int. Conf. Softw. Eng. Knowl. Eng. (SEKE), pp. 54-59, (2008); Baxter I., Yahin A., De Moura L., Sant'Anna M., Bier L., Clone detection using abstract syntax trees, Proc. Int. Conf. Softw. Maintenance (Cat. No. 98CB36272), pp. 368-377, (1998); Li Z., Lu S., Myagmar S., Zhou Y., CP-miner: A tool for finding copy-paste and related bugs in operating system code, Proc. OSDI, pp. 176-192, (2004); Roy C.K., Cordy J.R., A mutation/injection-based automatic framework for evaluating code clone detection tools, Proc. Int. Conf. Softw. Testing, Verification, Validation Workshops, pp. 157-166, (2009); Monden A., Nakae D., Kamiya T., Sato S., Matsumoto K., Software quality analysis by code clones in industrial legacy software, Proc. 8th IEEE Symp. Softw. Metrics, pp. 87-94, (2002); Thummalapenta S., Cerulo L., Aversano L., Di Penta M., An empirical study on the maintenance of source code clones, Empirical Softw. Eng., 15, pp. 1-34, (2010); Mondal M., Roy C.K., Schneider K.A., Does cloned code increase maintenance effort?, Proc. IEEE 11th Int. Workshop Softw. Clones (IWSC), pp. 1-7, (2017); Fjeldberg H.-C., Polyglot programming a business perspective, (2008); Mayer P., Kirsch M., Le M.-A., On multi-language software development, cross-language links and accompanying tools: A survey of professional software developers, J. Softw. Eng. Res. Develop., 5, 12, (2017); Shrestha N., Barik T., Parnin C., It's like python but: Towards supporting transfer of programming language knowledge, Proc. IEEE Symp. Vis. Lang. Hum.-Centric Comput. (VL/HCC), pp. 177-185, (2018); Wu Q., Anderson J.R., Problem-solving transfer among programming languages, (1990); Zhao G., Huang J., Deepsim: Deep learning code functional similarity, Proc. 26th ACM Joint Meeting Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng. (ESEC/FSE)., pp. 141-151, (2018); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate tree-based detection of code clones, Proc. 29th Int. Conf. Softw. Eng. (ICSE), pp. 96-105, (2007); Wei H.-H., Li M., Positive and unlabeled learning for detecting software functional clones with adversarial training, Proc. 27th Int. Joint Conf. Artif. Intell. (IJCAI), pp. 2840-2846, (2018); Saini V., Farmahinifarahani F., Lu Y., Baldi P., Lopes C.V., Oreo: Detection of clones in the twilight zone, Proc. ESEC/FSE, pp. 354-365, (2018); Ray B., Kim M., Person S., Rungta N., Detecting and characterizing semantic inconsistencies in ported code, Proc. 28th IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 367-377, (2013); Yue R., Gao Z., Meng N., Xiong Y., Wang X., Morgenthaler J.D., Automatic clone recommendation for refactoring based on the present and the past, Proc. IEEE Int. Conf. Softw. Maintenance Evol. (ICSME)., pp. 115-126; Al-Omari F., Keivanloo I., Roy C.K., Rilling J., Detecting clones across microsoft .net programming languages, Proc. 19th Work. Conf. Reverse Eng., pp. 405-414, (2012); Cheng X., Peng Z., Jiang L., Zhong H., Yu H., Zhao J., Mining revision histories to detect cross-language clones without intermediates, Proc. 31st IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 696-701, (2016); Nafi K.W., Kar T.S., Roy B., Roy C.K., Schneider K.A., CLCSDA: Cross language code clone detection using syntactical features and API documentation, Proc. 34th IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE)., pp. 1026-1037, (2019); Perez D., Chiba S., Cross-language clone detection by learning over abstract syntax trees, Proc. 16th Int. Conf. Mining Softw. Repositories (MSR)., pp. 518-528, (2019); Sun F., Hoffmann J., Verma V., Tang J., InfoGraph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization, Proc. 8th Int. Conf. Learn. Representations (ICLR); Mehrotra N., Agarwal N., Gupta P., Anand S., Lo D., Purandare R., Modeling functional similarity in source code with graph-based Siamese networks, IEEE Trans. Softw. Eng., 48, 10, pp. 3771-3789, (2022); Yu H., Lam W., Chen L., Li G., Xie T., Wang Q., Neural detection of semantic code clones via tree-based convolution, Proc. 27th Int. Conf. Program Comprehension (ICPC)., pp. 70-80, (2019); Svajlenko J., Islam J.F., Keivanloo I., Roy C.K., Mia M.M., Towards a big data curated benchmark of inter-project code clones, Proc. IEEE Int. Conf. Softw. Maintenance Evol., pp. 476-480, (2014); Hu J., Shen L., Sun G., Squeeze-and-excitation networks, Proc. IEEE/CVF Conf. Comput. Vision Pattern Recognit., pp. 7132-7141, (2018); Lample G., Ott M., Conneau A., Denoyer L., Ranzato M., Phrasebased & neural unsupervised machine translation, Proc. Conf. Empirical Methods Natural Lang. Process., pp. 5039-5049, (2018); Zhang S., Tong H., Xu J., MacIejewski R., Graph convolutional networks: A comprehensive review, Comput. Soc. Netw., 6, 12, (2019); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A comprehensive survey on graph neural networks, IEEE Trans. Neural Netw. Learn. Syst., 32, 1, pp. 4-24, (2021); Bronstein M.M., Bruna J., LeCun Y., Szlam A., Vandergheynst P., Geometric deep learning: Going beyond Euclidean data, IEEE Signal Process. Mag., 34, 4, pp. 18-42, (2017); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, Proc. 5th Int. Conf. Learn. Representations (ICLR).; Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proc. IEEE/ACM 41st Int. Conf. Softw. Eng. (ICSE), pp. 783-794, (2019); Wei H.-H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proc. 26th Int. Joint Conf. Artif. Intell. (IJCAI)., pp. 3034-3040, (2017); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, Proc. IEEE 27th Int. Conf. Softw. Anal., Evol. Reengineering (SANER), pp. 261-271, (2020); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, (2017); Li Y., Wang S., Nguyen T.N., Van Nguyen S., Improving bug detection via context-based code representation learning and attentionbased neural networks, Proc. ACM Program. Lang., 3, pp. 1621-16230, (2019); White M., Tufano M., Martinez M., Monperrus M., Poshyvanyk D., Sorting and transforming program repair ingredients via deep learning code similarities, Proc. IEEE 26th Int. Conf. Softw. Anal., Evol. Reengineering (SANER), pp. 479-490, (2019); Wang K., Singh R., Su Z., Dynamic neural program embeddings for program repair, Proc. 6th Int. Conf. Learn. Representations (ICLR).; Chen Z., Kommrusch S.J., Tufano M., Pouchet L.-N., Poshyvanyk D., Monperrus M., SequenceR: Sequence-to-sequence learning for end-to-end program repair, IEEE Trans. Softw. Eng., 47, 9, pp. 1943-1959, (2021); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, Proc. 33nd Int. Conf. Mach. Learn. (ICML), 48, pp. 2091-2100; LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proc. 28th Int. Conf. Program Comprehension. Seoul, South Korea, pp. 184-195; Chen X., Liang C., Yu A.W., Zhou D., Song D., Le Q.V., Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension, Proc. Int. Conf. Learn. Representations, (2020); Shin R., Polosukhin I., Song D., Improving neural program synthesis with inferred execution traces, Proc. 32nd Int. Conf. Neural Inf. Process. Syst. (NIPS)., pp. 8931-8940, (2018); Burges C.J.C., Bottou L., Ghahramani Z., Weinberger K.Q., Distributed representations of words and phrases and their compositionality, 27th Ann. Conf. Neural Inf. Proc. Sys, (2013); Bromley J., Guyon I., LeCun Y., Sackinger E., Shah R., Signature verification using a 'Siamese' time delay neural network, Proc. 6th Int. Conf. Neural Inf. Process. Syst. (NIPS)., pp. 737-744, (1993); Vinyals O., Bengio S., Kudlur M., Order matters: Sequence to sequence for sets; Van Bruggen D., Et al., Javaparser/javaparser: Release javaparser-parent-3.16.1; Lattner C., Adve V., LLVM: A compilation framework for lifelong program analysis transformation, Proc. Int. Symp. Code Gener. Optim. (CGO), pp. 75-86, (2004); Python: A Dynamic, Open Source Programming Language, (2019); Fey M., Lenssen J.E., Fast graph representation learning with PyTorch Geometric, Proc. ICLR Workshop Representation Learn. Graphs Manifolds, (2019); Shang W., Sohn K., Almeida D., Lee H., Understanding and improving convolutional neural networks via concatenated rectified linear units, Proc. 33rd Int. Conf. Mach. Learn. (ICML), 48, pp. 2217-2225, (2016); Glorot X., Bengio Y., Understanding the difficulty of training deep feedforward neural networks, Proc. 13th Int. Conf. Artif. Intell. Statist., 9, pp. 249-256; Kingma D.P., Ba J., ADAM: A method for stochastic optimization; (2021); (2021); (2021); Kamp M., Kreutzer P., Philippsen M., Sesame: A data set of semantically similar java methods, Proc. IEEE/ACM 16th Int. Conf. Mining Softw. Repositories (MSR)., pp. 529-533, (2019); Tao C., Zhan Q., Hu X., Xia X., C4: Contrastive cross-language code clone detection, Proc. IEEE/ACM 30th Int. Conf. Program Comprehension (ICPC), pp. 413-424, (2022); Guo D., Et al., GraphCodeBERT: Pre-training code representations with data flow, 9th Int. Conf. Learn. Represent. (ICLR), (2021); Lin Z., Et al., Xcode: Towards cross-language code representation with large-scale pre-training, ACM Trans. Softw. Eng. Methodology, 31, 3, pp. 1-44, (2022); Mathew G., Parnin C., Stolee K.T., SLACC: Simion-based language agnostic code clones, Proc. 42nd Int. Conf. Softw. Eng. (ICSE), pp. 210-221; Vislavski T., Rakic G., Cardozo N., Budimac Z., LICCA: A tool for cross-language clone detection, Proc. IEEE 25th Int. Conf. Softw. Anal., Evol. Reengineering (SANER), pp. 512-516, (2018); Cheng X., Peng Z., Jiang L., Zhong H., Yu H., Zhao J., CLCMINER: Detecting cross-language clones without intermediates, IEICE Trans. Inf. Syst., E100.D, pp. 273-284, (2017); Cordy J.R., Roy C.K., The NiCad clone detector, Proc. IEEE 19th Int. Conf. Program Comprehension, pp. 219-220, (2011); Kamiya T., Kusumoto S., Inoue K., CCFinder: A multilinguistic token-based code clone detection system for large scale source code, IEEE Trans. Softw. Eng., 28, 7, pp. 654-670, (2002); Defferrard M., Bresson X., Vandergheynst P., Convolutional neural networks on graphs with fast localized spectral filtering, Proc. Adv. Neural Inf. Process. Syst. 29, Annu. Conf. Neural Inf. Process. Syst., pp. 3837-3845; Cliff N., Dominance statistics: Ordinal analyses to answer ordinal questions, Psychological Bull., 114, 3, (1993); Kang H.J., Bissyande T.F., Lo D., Assessing the generalizability of code2vec token embeddings, Proc. 34th IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 1-12, (2019); Krinke J., Ragkhitwetsagul C., BigCloneBench considered harmful for machine learning, Proc. IEEE 16th Int. Workshop Softw. Clones (IWSC), pp. 1-7, (2022); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., SourcererCC: Scaling code clone detection to big-code, Proc. 38th Int. Conf. Softw. Eng., pp. 1157-1168, (2016); Krinke J., Identifying similar code with program dependence graphs, Proc. 8th Work. Conf. Reverse Eng., pp. 301-309, (2001); Budimac Z., Rakic G., Savic M., SSQSA architecture, Proc. 5th Balkan Conf. Inform. (BCI)., pp. 287-290, (2012); Mathew G., Stolee K.T., Cross-language code search using static and dynamic analyses, Proc. 29th ACM Joint Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng. (ESEC/FSE), pp. 205-217",,,,,,English,Article,Final,,Scopus,2-s2.0-85171552856,195
Yu D.; Yang Q.; Chen X.; Chen J.; Xu Y.,"Yu, Dongjin (35176839900); Yang, Quanxin (57218480612); Chen, Xin (57102336800); Chen, Jie (57203334789); Xu, Yihang (57223924930)",35176839900; 57218480612; 57102336800; 57203334789; 57223924930,Graph-based code semantics learning for efficient semantic code clone detection,2023,Information and Software Technology,156,,107130,,,,8,10.1016/j.infsof.2022.107130,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144452421&doi=10.1016%2fj.infsof.2022.107130&partnerID=40&md5=6e1b8c80ca04b3a15872a41e4d6a3a30,"Recent studies have shown that high-quality code semantics learning can effectively improve the performance of code clone detection. However, existing approaches suffer from two major drawbacks: (a) insufficient utilization of code representations, leading to inefficient semantics learning, and (b) low efficiency of clone detection, resulting in massive detection time. Therefore, we are motivated to propose an efficient semantics learning method while speeding up the detection process. Specifically, to address the first one, we adopt either CFG (Control Flow Graph) or PDG (Program Dependency Graph) as our initial code representation because of their rich semantic information. Further, we propose a novel graph-based code semantics learning method, which can capture critical information at token, statement, edge, and graph levels. To address the second one, we design a Siamese graph-matching network based on attention mechanisms. It can uniformly generate graph embeddings for code fragments and facilitate parallel detection of semantic clones, thus significantly boosting the speed of semantic clone detection. We evaluated our approach on two Java benchmark datasets, Google Code Jam and BigCloneBench. The experimental results show that our model outperforms the SOTA (State-Of-The-Art) lightweight models and is over 20x faster in detection. In addition, our model performs on par with the large Bert-based models and is over 110x faster in detection. Our code and dataset are available online at: https://github.com/HduDBSI/CodeGraph4CCDetector. © 2022","Walker A., Cerny T., Song E., Open-source tools and benchmarks for code-clone detection: Past, present, and future trends, SIGAPP Appl. Comput. Rev., 19, 4, pp. 28-39, (2020); (2020); Balazinska M., Merlo E., Dagenais M., Lague B., Kontogiannis K., Advanced clone-analysis to support object-oriented system refactoring, Proceedings Seventh Working Conference on Reverse Engineering, pp. 98-107, (2000); Chen W.-K., Li B., Gupta R., Code compaction of matching single-entry multiple-exit regions, Proceedings of the 10th International Conference on Static Analysis, SAS ’03, pp. 401-417, (2003); Meng N., Hua L., Kim M., McKinley K.S., Does automated refactoring obviate systematic editing?, 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, 1, pp. 392-402, (2015); Tsantalis N., Mazinanian D., Krishnan G.P., Assessing the refactorability of software clones, IEEE Trans. Softw. Eng., 41, 11, pp. 1055-1090, (2015); Tsantalis N., Mazinanian D., Rostami S., Clone refactoring with lambda expressions, 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE, pp. 60-70, (2017); Baker B.S., On finding duplication and near-duplication in large software systems, Proceedings of 2nd Working Conference on Reverse Engineering, pp. 86-95, (1995); Nishi M.A., Damevski K., Scalable code clone detection and search based on adaptive prefix filtering, J. Syst. Softw., 137, MAR., pp. 130-142, (2018); Patenaude J.-F., Merlo E., Dagenais M., Lague B., Extending software quality assessment techniques to java systems, Proceedings Seventh International Workshop on Program Comprehension, pp. 49-56, (1999); Fang S., Tan Y.-S., Zhang T., Liu Y., Self-attention networks for code search, Inf. Softw. Technol., 134, (2021); Holmes R., Murphy G.C., Using structural context to recommend source code examples, Proceedings. 27th International Conference on Software Engineering, 2005. ICSE 2005, pp. 117-125, (2005); Vinayakarao V., Purandare R., Nori A.V., Structurally heterogeneous source code examples from unstructured knowledge sources, Proceedings of the 2015 Workshop on Partial Evaluation and Program Manipulation, PEPM ’15, pp. 21-26, (2015); Lazzarini Lemos O.A., Bajracharya S., Ossher J., Masiero P.C., Lopes C., A test-driven approach to code search and its application to the reuse of auxiliary functionality, Inf. Softw. Technol., 53, 4, pp. 294-306, (2011); Ciesielski V., Wu N., Tahaghoghi S., Evolving similarity functions for code plagiarism detection, Proceedings of the 10th Annual Conference on Genetic and Evolutionary Computation, GECCO ’08, pp. 1453-1460, (2008); Muxin L., Research on code plagiarism detection based on code clone detection technologies, 2021 2nd International Conference on Big Data and Informatization Education, ICBDIE, pp. 274-277, (2021); Cheers H., Lin Y., A novel graph-based program representation for java code plagiarism detection, Proceedings of the 3rd International Conference on Software Engineering and Information Management, ICSIM ’20, pp. 115-122, (2020); Li Y., Wang B., Hu B., Semantically find similar binary codes with mixed key instruction sequence, Inf. Softw. Technol., 125, (2020); Jiang L., Su Z., Chiu E., Context-based detection of clone-related bugs, Proceedings of the the 6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC-FSE ’07, pp. 55-64, (2007); Li Z., Lu S., Myagmar S., Zhou Y., CP-Miner: finding copy-paste and related bugs in large-scale software code, IEEE Trans. Softw. Eng., 32, 3, pp. 176-192, (2006); Ebrahimi N., Trabelsi A., Islam M.S., Hamou-Lhadj A., Khanmohammadi K., An HMM-based approach for automatic detection and classification of duplicate bug reports, Inf. Softw. Technol., 113, pp. 98-109, (2019); Lei M., Li H., Li J., Aundhkar N., Kim D.-K., Deep learning application on code clone detection: A review of current knowledge, J. Syst. Softw., 184, (2022); Mostaeen G., Roy B., Roy C.K., Schneider K., Svajlenko J., A machine learning based framework for code clone validation, J. Syst. Softw., 169, (2020); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering, SANER, pp. 261-271, (2020); Guo D., Ren S., Lu S., Feng Z., Tang D., LiU S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Deng S.K., Clement C., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., GraphCodeBERT: Pre-training code representations with data flow, International Conference on Learning Representations, (2021); Sui Y., Cheng X., Zhang G., Wang H., Flow2Vec: Value-flow-based precise code embedding, Proc. ACM Program. Lang., 4, OOPSLA, (2020); Zhao G., Huang J., DeepSim: Deep learning code functional similarity, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2018, pp. 141-151, (2018); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., SourcererCC: Scaling code clone detection to big-code, 2016 IEEE/ACM 38th International Conference on Software Engineering, ICSE, pp. 1157-1168, (2016); Wang P., Svajlenko J., Wu Y., Xu Y., Roy C.K., CCAligner: A token based large-gap clone detector, Proceedings of the 40th International Conference on Software Engineering, ICSE ’18, pp. 1066-1077, (2018); Golubev Y., Poletansky V., Povarov N., Bryksin T., Multi-threshold token-based code clone detection, 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER, pp. 496-500, (2021); Li Z., Wu Y., Peng B., Chen X., Sun Z., Liu Y., Yu D., SeCNN: A semantic CNN parser for code comment generation, J. Syst. Softw., 181, (2021); Perez D., Chiba S., Cross-language clone detection by learning over abstract syntax trees, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories, MSR, pp. 518-528, (2019); Buch L., Andrzejak A., Learning-based recursive aggregation of abstract syntax trees for code clone detection, 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering, SANER, pp. 95-104, (2019); Yu H., Lam W., Chen L., Li G., Xie T., Wang Q., Neural detection of semantic code clones via tree-based convolution, 2019 IEEE/ACM 27th International Conference on Program Comprehension, ICPC, pp. 70-80, (2019); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering, ICSE, pp. 783-794, (2019); Wang W., Li G., Shen S., Xia X., Jin Z., Modular tree network for source code representation learning, ACM Trans. Softw. Eng. Methodol., 29, 4, (2020); Wei H.-H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proceedings of the 26th International Joint Conference on Artificial Intelligence, IJCAI ’17, pp. 3034-3040, (2017); Tronicek Z., Indexing source code and clone detection, Inf. Softw. Technol., 144, (2022); Zhao Z., Yang B., Li G., Liu H., Jin Z., Precise learning of source code contextual semantics via hierarchical dependence structure and graph attention networks, J. Syst. Softw., 184, (2022); Zhou Y., Shen J., Zhang X., Yang W., Han T., Chen T., Automatic source code summarization with graph attention networks, J. Syst. Softw., 188, (2022); Zou Y., Ban B., Xue Y., Xu Y., CCGraph: a PDG-based code clone detector with approximate graph matching, 2020 35th IEEE/ACM International Conference on Automated Software Engineering, ASE, pp. 931-942, (2020); Yuan Y., Kong W., Hou G., Hu Y., Watanabe M., Fukuda A., From local to global semantic clone detection, 2019 6th International Conference on Dependable Systems and their Applications, DSA, pp. 13-24, (2020); Mehrotra N., Agarwal N., Gupta P., Anand S., Lo D., Purandare R., Modeling functional similarity in source code with graph-based siamese networks, IEEE Trans. Softw. Eng., (2021); Zhang F., Chen B., Li R., Peng X., A hybrid code representation learning approach for predicting method names, J. Syst. Softw., 180, (2021); Wu Y., Zou D., Dou S., Yang S., Yang W., Cheng F., Liang H., Jin H., SCDetector: Software functional clone detection based on semantic tokens analysis, 2020 35th IEEE/ACM International Conference on Automated Software Engineering, ASE, pp. 821-833, (2020); Hua W., Sui Y., Wan Y., Liu G., Xu G., FCCA: Hybrid code representation for functional clone detection using attention networks, IEEE Trans. Reliab., 70, 1, pp. 304-318, (2021); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2018); Diehl F., Edge contraction pooling for graph neural networks, (2019); Yang Q., Yu D., Zhang Z., Yao Y., Chen L., Spatiotemporal trident networks: Detection and localization of object removal tampering in video passive forensics, IEEE Trans. Circuits Syst. Video Technol., 31, 10, pp. 4131-4144, (2021); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., RoBERTa: A robustly optimized BERT pretraining approach, (2019); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A pre-trained model for programming and natural languages, (2020); Google code jam, (2016); Svajlenko J., Islam J.F., Keivanloo I., Roy C.K., Mia M.M., Towards a big data curated benchmark of inter-project code clones, 2014 IEEE International Conference on Software Maintenance and Evolution, pp. 476-480, (2014); Jiang L., Misherghi G., Su Z., Glondu S., DECKARD: Scalable and accurate tree-based detection of code clones, 29th International Conference on Software Engineering (ICSE’07), pp. 96-105, (2007); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, 2016 31st IEEE/ACM International Conference on Automated Software Engineering, ASE, pp. 87-98, (2016); Ragkhitwetsagul C., Krinke J., Marnette B., A picture is worth a thousand words: Code clone detection based on image similarity, 2018 IEEE 12th International Workshop on Software Clones, IWSC, pp. 44-50, (2018); Wang Y., Liu D., Image-based clone code detection and visualization, 2019 International Conference on Artificial Intelligence and Advanced Manufacturing, AIAM, pp. 168-175, (2019); Xue H., Venkataramani G., Lan T., Clone-slicer: Detecting domain specific binary code clones through program slicing, Proceedings of the 2018 Workshop on Forming an Ecosystem Around Software Transformation, FEAST ’18, pp. 27-33, (2018); Xue H., Venkataramani G., Lan T., Clone-Hunter: Accelerated bound checks elimination via binary code clone detection, Proceedings of the 2nd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages, MAPL 2018, pp. 11-19, (2018); Li Y., Gu C., Dullien T., Vinyals O., Kohli P., Graph matching networks for learning the similarity of graph structured objects, (2019); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, (2013); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, (2017); Lin T.-Y., Goyal P., Girshick R., He K., Dollar P., Focal loss for dense object detection, IEEE Trans. Pattern Anal. Mach. Intell., 42, 2, pp. 318-327, (2020); Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2017)",,,,,,English,Article,Final,,Scopus,2-s2.0-85144452421,196
Dai L.,"Dai, Linfeng (58561429700)",58561429700,A study on the application of graph neural network in code clone detection: Improving the performance of code clone detection through graph neural networks and attention mechanisms,2023,ACM International Conference Proceeding Series,,,,172,176,4,1,10.1145/3605801.3605834,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169707859&doi=10.1145%2f3605801.3605834&partnerID=40&md5=c24ef0d4d173cbc93d0289bd51b243ab,"With the increasing scale of software and the growing number of software developers, code cloning has become an important issue in software engineering. To detect code clones, this paper proposes a new method that converts source code into an Abstract Syntax Tree (AST), then adds edges from the Control Flow Graph (CFG) and Data Flow Graph (DFG) to the AST to form a graph. We then feed the graph into the Graph Matching Network (GMN) model and Pairwise Node Comparison (PNC) captures the edge and node information of the graph to calculate the graph similarity, thus converting code clone detection into a binary classification problem. Finally, experiments are conducted on the public dataset BigCloneBench, and the results show that the proposed method has high accuracy and scalability in code clone detection relative to other methods. © 2023 ACM.","Min H., Li Ping Z., Survey on software clone detection research, Proceedings of the 2019 3rd International Conference on Management Engineering, Software Engineering and Service Sciences, pp. 9-16, (2019); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, IEEE/ACM International Conference on Automated Software Engineering. ACM., (2016); Wei H., Ming L., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Twenty-Sixth International Joint Conference on Artificial Intelligence., (2017); Zhang J., Wang X., Zhang H., Sun H., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). ACM., (2019); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, (2020); Li Y., Gu C., Dullien T., Vinyals O., Kohli P., Graph matching networks for learning the similarity of graph structured objects., (2019); Socher R., Chen D., Manning C.D., Ng A.Y., Reasoning with neural tensor networks for knowledge base completion., (2013); Mayrand J., Leblanc C., Merlo E.M., Experiment on the automatic detection of function clones in a software system using metrics, International Conference on Software Maintenance. IEEE., (1996); Baker B.S., Parameterized pattern matching: Algorithms and applications, Journal of Computer & System Sciences, 52, 1, pp. 28-42, (1996); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., Sourcerercc: scaling code clone detection to big-code., (2016); Jiang L.X., Misherghi G., Su Z.D., Et al., Deckard: Scalable and accurate tree-based detection of code clones, PROC INT CONF SOFTW ENG., (2007); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree., (2020); Gilmer J., Schoenholz S.S., Riley P.F., Vinyals O., Dahl G.E., Neural message passing for quantum chemistry., (2017); Wei H., Ming L., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Twenty-Sixth International Joint Conference on Artificial Intelligence., (2017); Svajlenko J., Roy C., Bigcloneeval: A clone detection tool evaluation framework with bigclonebench., (2016); Tran N.K., Cheng W., Multiplicative tree-structured long short-term memory networks for semantic representations, Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics., (2018); Zhang J., Wang X., Zhang H., Sun H., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). ACM., (2019)",,"2nd International Conference on Networks, Communications and Information Technology, CNCIT 2023",16 June 2023 through 18 June 2023,Qinghai,191643,English,Conference paper,Final,,Scopus,2-s2.0-85169707859,197
Mehrotra N.; Agarwal N.; Gupta P.; Anand S.; Lo D.; Purandare R.,"Mehrotra, Nikita (57220046769); Agarwal, Navdha (57192808860); Gupta, Piyush (57221036138); Anand, Saket (14036950100); Lo, David (35269388000); Purandare, Rahul (21743722600)",57220046769; 57192808860; 57221036138; 14036950100; 35269388000; 21743722600,Modeling Functional Similarity in Source Code With Graph-Based Siamese Networks,2022,IEEE Transactions on Software Engineering,48,10,,3771,3789,18,14,10.1109/TSE.2021.3105556,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113236624&doi=10.1109%2fTSE.2021.3105556&partnerID=40&md5=23c76e79cd41b745e2448d8240e34e32,"Code clones are duplicate code fragments that share (nearly) similar syntax or semantics. Code clone detection plays an important role in software maintenance, code refactoring, and reuse. A substantial amount of research has been conducted in the past to detect clones. A majority of these approaches use lexical and syntactic information to detect clones. However, only a few of them target semantic clones. Recently, motivated by the success of deep learning models in other fields, including natural language processing and computer vision, researchers have attempted to adopt deep learning techniques to detect code clones. These approaches use lexical information (tokens) and(or) syntactic structures like abstract syntax trees (ASTs) to detect code clones. However, they do not make sufficient use of the available structural and semantic information, hence limiting their capabilities. This paper addresses the problem of semantic code clone detection using program dependency graphs and geometric neural networks, leveraging the structured syntactic and semantic information. We have developed a prototype tool Holmes, based on our novel approach and empirically evaluated it on popular code clone benchmarks. Our results show that Holmes performs considerably better than the other state-of-the-art tool, TBCCD. We also assessed Holmes on unseen projects and performed cross dataset experiments to evaluate the generalizability of Holmes. Our results affirm that Holmes outperforms TBCCD since most of the pairs that Holmes detected were either undetected or suboptimally reported by TBCCD. © 1976-2012 IEEE.","Baxter I.D., Yahin A., Moura L., Sant'Anna M., Bier L., Clone detection using abstract syntax trees, Proc. Int. Conf. Softw. Maintenance, pp. 368-377, (1998); Roy C.K., Cordy J.R., A survey on software clone detection research, (2007); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proc. 31st IEEE/ACM Int. Conf. Autom. Softw. Eng., pp. 87-98, (2016); Thummalapenta S., Cerulo L., Aversano L., Di Penta M., An empirical study on the maintenance of source code clones, Empir. Softw. Eng., 15, pp. 1-34, (2010); Mondal M., Roy C.K., Schneider K.A., Does cloned code increase maintenance effort?, Proc. IEEE 11th Int. Workshop Softw. Clones, pp. 1-7, (2017); Li Z., Lu S., Myagmar S., Zhou Y., CP-Miner: A tool for finding copy-paste and related bugs in operating system code, Proc. 6th Conf. Symp. Operating Syst. Des. Implementation, (2004); Roy C.K., Cordy J.R., A mutation/injection-based automatic framework for evaluating code clone detection tools, Proc. Int. Conf. Softw. Testing Verification Validation Workshops, pp. 157-166, (2009); Monden A., Nakae D., Kamiya T., Sato S., Matsumoto K., Software quality analysis by code clones in industrial legacy software, Proc. 8th IEEE Symp. Softw. Metrics, pp. 87-94, (2002); Kapser C., Godfrey M.W., Cloning considered harmful"" considered harmful, Proc. 13th Work. Conf. Reverse Eng., pp. 19-28, (2006); Keivanloo I., Rilling J., Zou Y., Spotting working code examples, Proc. 36th Int. Conf. Softw. Eng., pp. 664-675, (2014); Zibran M.F., Roy C.K., Towards flexible code clone detection, management, and refactoring in IDE, Proc. 5th Int. Workshop Softw. Clones, pp. 75-76, (2011); Jiang L., Su Z., Chiu E., Context-based detection of clonerelated bugs, Proc. 6th Joint Meeting Eur. Softw. Eng. Conf. ACM SIGSOFT Symp. Found. Softw. Eng., pp. 55-64, (2007); Kim H., Jung Y., Kim S., Yi K., MeCC: Memory comparisonbased clone detector, Proc. 33rd Int. Conf. Softw. Eng., pp. 301-310, (2011); Jiang L., Misherghi G., Su Z., Glondu S., DECKARD: Scalable and accurate tree-based detection of code clones, Proc. 29th Int. Conf. Softw. Eng., pp. 96-105, (2007); Yu H., Lam W., Chen L., Li G., Xie T., Wang Q., Neural detection of semantic code clones via tree-based convolution, Proc. 27th Int. Conf. Program Comprehension, pp. 70-80, (2019); Zhao G., Huang J., DeepSim: Deep learning code functional similarity, Proc. 26th ACM Joint Meeting Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng., pp. 141-151, (2018); Wei H.-H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proc. 26th Int. Joint Conf. Artif. Intell., pp. 3034-3040, (2017); Wei H.-H., Li M., Positive and unlabeled learning for detecting software functional clones with adversarial training, Proc. 27th Int. Joint Conf. Artif. Intell., 2018, pp. 2840-2846; Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, Proc. IEEE 27th Int. Conf. Softw. Anal. Evol. Reeng., pp. 261-271, (2020); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proc. 31st IEEE/ACM Int. Conf. Autom. Softw. Eng., pp. 87-98, (2016); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, Proc. IEEE/ACM 15th Int. Conf. Mining Softw. Repositories, pp. 542-553, (2018); Li L., Feng H., Zhuang W., Meng N., Ryder B., CCLearner: A deep learning-based clone detection approach, Proc. IEEE Int. Conf. Softw. Maintenance Evol., pp. 249-260, (2017); Krinke J., Identifying similar code with program dependence graphs, Proc. 8th Work. Conf. Reverse Eng., pp. 301-309, (2001); Gabel M., Jiang L., Su Z., Scalable detection of semantic clones, Proc. 30th Int. Conf. Softw. Eng., pp. 321-330, (2008); Vallee-Rai R., Gagnon E., Hendren L.J., Lam P., Pominville P., Sundaresan V., Optimizing java bytecode using the soot framework: Is it feasible, Proc. 9th Int. Conf. Compiler Construction, pp. 18-34, (2000); Fey M., Lenssen J.E., Fast graph representation learning with pytorch geometric, Proc. ICLR Workshop Representation Learn. Graphs Manifolds, (2019); Binkley D., Source code analysis: A road map, Proc. Future Softw. Eng., pp. 104-119, (2007); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Trans. Program. Lang. Syst., 9, pp. 319-349, (1987); Horwitz S., Identifying the semantic and textual differences between two versions of a program, Proc. ACM SIGPLAN Conf. Program. Lang. Des. Implementation, pp. 234-245, (1990); Podgurski A., Clarke L., The implications of program dependencies for software testing, debugging, and maintenance, Proc. ACM SIGSOFT 3rd Symp. Softw. Testing Anal. Verification, pp. 168-178, (1989); Hinton G.E., Connectionist learning procedures, Artif. Intell., 40, 1-3, pp. 185-234, (1989); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput., 9, 8, pp. 1735-1780, (1997); LeCun Y., Bengio Y., Convolutional Networks for Images, Speech, and Time Series, pp. 255-258, (1998); Bronstein M.M., Bruna J., LeCun Y., Szlam A., Vandergheynst P., Geometric deep learning: Going beyond euclidean data, IEEE Signal Process. Mag., 34, 4, pp. 18-42, (2017); Hu J., Shen L., Sun G., Squeeze-and-excitation networks, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 7132-7141, (2018); Lample G., Ott M., Conneau A., Denoyer L., Ranzato M., Phrase-based & neural unsupervised machine translation, Proc. Conf. Empir. Methods Natural Lang. Process., pp. 5039-5049, (2018); Vaswani A., Et al., Attention is all you need, Proc. 31st Int. Conf. Neural Inf. Process. Syst., pp. 6000-6010, (2017); Zhang S., Tong H., Xu J., MacIejewski R., Graph convolutional networks: A comprehensive review, Comput. Soc. Netw., 6, (2019); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A comprehensive survey on graph neural networks, IEEE Trans. Neural Netw. Learn. Syst., 32, 1, pp. 4-24, (2021); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proc. 28th Int. Conf. Program Comprehension, pp. 184-195, (2020); Wang X., Zhang T., Wu R., Xin W., Hou C., CPGVA: Code property graph based vulnerability analysis by deep learning, Proc. 10th Int. Conf. Adv. INFOCOMM Technol., pp. 184-188, (2018); Tufano M., Pantiuchina J., Watson C., Bavota G., Poshyvanyk D., On learning meaningful code changes via neural machine translation, Proc. IEEE/ACM 41st Int. Conf. Softw. Eng., pp. 25-36, (2019); Bruna J., Zaremba W., Szlam A., LeCun Y., Spectral networks and locally connected networks on graphs, Proc. Int. Conf. Learn. Representations, (2014); Micheli A., Neural network for graphs: A contextual constructive approach, IEEE Trans. Neural Netw., 20, 3, pp. 498-511, (2009); Bromley J., Guyon I., LeCun Y., Seackinger E., Shah R., Signature verification using a ""siamese"" time delay neural network, Proc. 6th Int. Conf. Neural Inf. Process. Syst., pp. 737-744, (1993); Baldi P., Chauvin Y., Neural networks for fingerprint recognition, Neural Comput., 5, 3, pp. 402-418, (1993); Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating sequences from structured representations of code, Proc. 7th Int. Conf. Learn. Representations, (2019); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proc. ACM Program. Lang., 3, POPL, pp. 401-4029, (2019); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, Proc. Int. Conf. Learn. Representations, (2018); Chen X., Liang C., Yu A.W., Zhou D., Song D., Le Q.V., Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension, Proc. Int. Conf. Learn. Representations, (2020); Shin R., Polosukhin I., Song D., Improving neural program synthesis with inferred execution traces, Proc. 32nd Int. Conf. Neural Inf. Process. Syst., pp. 8931-8940, (2018); Wang K., Singh R., Su Z., Dynamic neural program embedding for program repair, (2018); Chen Z., Kommrusch S.J., Tufano M., Pouchet L., Poshyvanyk D., Monperrus M., SEQUENCER: Sequence-to-sequence learning for end-to-end program repair, (2019); White M., Tufano M., Martynez M., Monperrus M., Poshyvanyk D., Sorting and transforming program repair ingredients via deep learning code similarities, Proc. IEEE 26th Int. Conf. Softw. Anal. Evol. Reeng., pp. 479-490, (2019); Li Y., Wang S., Nguyen T.N., DLFix: Context-based code transformation learning for automated program repair, Proc. ACM/IEEE 42nd Int. Conf. Softw. Eng., pp. 602-614, (2020); Li Y., Wang S., Nguyen T.N., Van Nguyen S., Improving bug detection via context-based code representation learning and attention-based neural networks, Proc. ACM Program. Lang., 3, (2019); Allamanis M., Peng H., Sutton C.A., A convolutional attention network for extreme summarization of source code, Proc. 33rd Int. Conf. Mach. Learn., 48, pp. 2091-2100, (2016); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, Proc. Int. Conf. Learn. Representations, (2018); Liu Z., Et al., GeniePath: Graph neural networks with adaptive receptive paths, Proc. AAAI Conf. Artif. Intell., 33, pp. 4424-4431, (2019); Xu K., Li C., Tian Y., Sonobe T., Kawarabayashi K., Jegelka S., Representation learning on graphs with jumping knowledge networks, Proc. 35th Int. Conf. Mach. Learn., pp. 5449-5458, (2018); Beck D., Haffari G., Cohn T., Graph-to-sequence learning using gated graph neural networks, Proc. 56th Annu. Meeting Assoc. Comput. Linguistics, pp. 273-283, (2018); Cytron R., Ferrante J., Rosen B.K., Wegman M.N., Zadeck F.K., Efficiently computing static single assignment form and the control dependence graph, ACM Trans. Program. Lang. Syst., 13, 4, pp. 451-490, (1991); Grunwald D., Srinivasan H., Data flow equations for explicitly parallel programs, SIGPLAN Notices, 28, pp. 159-168, (1993); Allen F.E., Cocke J., A program data flow analysis procedure, Commun. ACM, 19, (1976); Maas A.L., Hannun A.Y., Ng A.Y., Rectifier nonlinearities improve neural network acoustic models, Proc. ICML Workshop Deep Learn. Audio Speech Lang. Process., (2013); He K., Zhang X., Ren S., Sun J., Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification, Proc. IEEE Int. Conf. Comput. Vis., pp. 1026-1034, (2015); Kingma D.P., Ba J., Adam: A method for stochastic optimization, Proc. Int. Conf. Learn. Representations, (2015); Gupta P., Mehrotra N., Purandare R., JCoffee: Using compiler feedback to make partial code snippets compilable, Proc. IEEE Int. Conf. Softw. Maintenance Evol., pp. 810-813, (2020); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., SourcererCC: Scaling code clone detection to big-code, Proc. IEEE/ACM 38th Int. Conf. Softw. Eng., pp. 1157-1168, (2016); Kamp M., Kreutzer P., Philippsen M., SeSaMe: A data set of semantically similar Java methods, Proc. 16th Int. Conf. Mining Softw. Repositories, pp. 529-533, (2019); Svajlenko J., Islam J.F., Keivanloo I., Roy C.K., Mia M.M., Towards a big data curated benchmark of inter-project code clones, Proc. IEEE Int. Conf. Softw. Maintenance Evol., pp. 476-480, (2014); Wagner S., Abdulkhaleq A., Bogicevic I., Ostberg J.-P., Ramadani J., How are functionally similar code clones syntactically different? An empirical study and a benchmark, PeerJ PrePrints, 4, (2016); Efron B., Tibshirani R., An Introduction to the Bootstrap. Equitable Building, (1993); Van Der Maaten L., Hinton G., Visualizing data using t-SNE, J. Mach. Learn. Res., 9, pp. 2579-2605, (2008); Kamiya T., Kusumoto S., Inoue K., CCFinder: A multilinguistic token-based code clone detection system for large scale source code, IEEE Trans. Softw. Eng., 28, 7, pp. 654-670, (2002); Li Z., Lu S., Myagmar S., Zhou Y., CP-Miner: Finding copypaste and related bugs in large-scale software code, IEEE Trans. Softw. Eng., 32, 3, pp. 176-192, (2006); Baker B.S., A program for identifying duplicated code, Comput. Sci. Statist., pp. 49-57, (1992); Cordy J., Roy C., The NiCad clone detector, Proc. IEEE 19th Int. Conf. Program Comprehension, pp. 219-220, (2011); Komondoor R., Horwitz S., Using slicing to identify duplication in source code, Proc. 8th Int. Symp. Static Anal., pp. 40-56, (2001); Krinke J., Identifying similar code with program dependence graphs, Proc. 8th Work. Conf. Reverse Eng., pp. 301-309, (2001); Su F.-H., Bell J., Harvey K., Sethumadhavan S., Kaiser G., Jebara T., Code relatives: Detecting similarly behaving software, Proc. 24th ACM SIGSOFT Int. Symp. Found. Softw. Eng., pp. 702-714, (2016); Marcus A., Maletic J.I., Identification of high-level concept clones in source code, Proc. 16th Annu. Int. Conf. Autom. Softw. Eng., pp. 107-114, (2001); Abd-El-Hafiz S.K., A metrics-based data mining approach for software clone detection, Proc. IEEE 36th Annu. Comput. Softw. Appl. Conf., pp. 35-41, (2012); Saini V., Farmahinifarahani F., Lu Y., Baldi P., Lopes C.V., Oreo: Detection of clones in the twilight zone, Proc. 26th ACM Joint Meeting Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng., pp. 354-365, (2018); Mathew G., Parnin C., Stolee K.T., SLACC: Simion-based language agnostic code clones, Proc. ACM/IEEE 42nd Int. Conf. Softw. Eng., pp. 210-221, (2020); Li Y., Gu C., Dullien T., Vinyals O., Kohli P., Graph matching networks for learning the similarity of graph structured objects, Proc. 36th Int. Conf. Mach. Learn., 97, pp. 3835-3845, (2019); Xu X., Liu C., Feng Q., Yin H., Song L., Song D., Neural network- based graph embedding for cross-platform binary code similarity detection, Proc. ACM SIGSAC Conf. Comput. Commun. Secur., pp. 363-376, (2017); Song L., Structure2vec: Deep learning for security analytics over graphs, (2018); Gupta R., Pal S., Kanade A., Shevade S., DeepFix: Fixing common C language errors by deep learning, Proc. 31st AAAI Conf. Artif. Intell., pp. 1345-1351, (2017); Wang K., Learning scalable and precise representation of program semantics, (2019); Ben-Nun T., Jakobovits A.S., Hoefler T., Neural code comprehension: A learnable representation of code semantics, Proc. 32nd Int. Conf. Neural Inf. Process. Syst., pp. 3589-3601, (2018); Hoang T., Kang H.J., Lo D., Lawall J., CC2Vec: Distributed representations of code changes, Proc. ACM/IEEE 42nd Int. Conf. Softw. Eng., pp. 518-529, (2020); Kang H.J., Bissyande T.F., Lo D., Assessing the generalizability of code2vec token embeddings, Proc. 34th IEEE/ACM Int. Conf. Autom. Softw. Eng., pp. 1-12, (2019)",,,,,,English,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85113236624,198
Hu Y.; Zou D.; Peng J.; Wu Y.; Shan J.; Jin H.,"Hu, Yutao (57880867900); Zou, Deqing (8935128200); Peng, Junru (57552602300); Wu, Yueming (57202109788); Shan, Junjie (57924454100); Jin, Hai (56434989100)",57880867900; 8935128200; 57552602300; 57202109788; 57924454100; 56434989100,TreeCen: Building Tree Graph for Scalable Semantic Code Clone Detection,2022,ACM International Conference Proceeding Series,,,109,,,,10,10.1145/3551349.3556927,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146924679&doi=10.1145%2f3551349.3556927&partnerID=40&md5=276d014d1c9463673e20d8750580700a,"Code clone detection is an important research problem that has attracted wide attention in software engineering. Many methods have been proposed for detecting code clone, among which text-based and token-based approaches are scalable but lack consideration of code semantics, thus resulting in the inability to detect semantic code clones. Methods based on intermediate representations of codes can solve the problem of semantic code clone detection. However, graph-based methods are not practicable due to code compilation, and existing tree-based approaches are limited by the scale of trees for scalable code clone detection. In this paper, we propose TreeCen, a scalable tree-based code clone detector, which satisfies scalability while detecting semantic clones effectively. Given the source code of a method, we first extract its abstract syntax tree (AST) based on static analysis and transform it into a simple graph representation (i.e., tree graph) according to the node type, rather than using traditional heavyweight tree matching. We then treat the tree graph as a social network and adopt centrality analysis on each node to maintain the tree details. By this, the original complex tree can be converted into a 72-dimensional vector while containing comprehensive structural information of the AST. Finally, these vectors are fed into a machine learning model to train a detector and use it to find code clones. We conduct comparative evaluations on effectiveness and scalability. The experimental results show that TreeCen maintains the best performance of the other six state-of-the-art methods (i.e., SourcererCC, RtvNN, DeepSim, SCDetector, Deckard, and ASTNN) with F1 scores of 0.99 and 0.95 on BigCloneBench and Google Code Jam datasets, respectively. In terms of scalability, TreeCen is about 79 times faster than the other state-of-the-art tree-based semantic code clone detector (ASTNN), about 13 times faster than the fastest graph-based approach (SCDetector), and even about 22 times faster than the one-time trained token-based detector (RtvNN).  © 2022 ACM.","BigCloneBench, (2022); Blackducks, (2022); Fossid, (2022); Google Code Jam, (2022); javalang, (2022); joern, (2022); networkx, (2022); NVIDIA, (2022); Scantist, (2022); sklearn, (2022); Akram J., Shi Z., Mumtaz M., Luo P., DCCD: An Efficient and Scalable Distributed Code Clone Detection Technique for Big Code, Proceedings of the 30th International Conference on Software Engineering and Knowledge Engineering (SEKE'18), pp. 353-354, (2018); Al-Ekram R., Kapser C., Holt R., Godfrey M., Cloning by accident: An empirical study of source code cloning across software systems, Proceedings of the 2005 International Symposium on Empirical Software Engineering (ISESE'05), pp. 10-30, (2005); Alvarez-Socorro A.J., Herrera-Almarza G.C., Gonzalez-Diaz L.A., Eigencentrality based on dissimilarity measures reveals central nodes in complex networks, Scientific Reports, 5, 1, pp. 1-10, (2015); Bellon S., Koschke R., Antoniol G., Krinke J., Merlo E., Comparison and evaluation of clone detection tools, IEEE Transactions on Software Engineering, 33, 9, pp. 577-591, (2007); Bui Q.N.D., Yu Y., Jiang L., Infercode: Self-supervised learning of code representations by predicting subtrees, Proceedings of the 43rd International Conference on Software Engineering (ICSE'21), pp. 1186-1197, (2021); Coles N., It's not what you know-it's who you know that counts. Analysing serious crime groups as social networks, British Journal of Criminology, 41, 4, pp. 580-594, (2001); Fang C., Liu Z., Shi Y., Huang J., Shi Q., Functional code clone detection with syntax and semantics fusion learning, Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA'20), pp. 516-527; Freeman L.C., A set of measures of centrality based on betweenness, Sociometry, pp. 35-41, (1977); Freeman L.C., Centrality in social networks conceptual clarification, Social Networks, 1, 3, pp. 215-239, (1978); Gharehyazie M., Ray B., Filkov V., Some from here, some from there: Cross-project code reuse in github, Proceedings of the 14th International Conference on Mining Software Repositories (MSR'17), pp. 291-301, (2017); Gode N., Koschke R., Incremental clone detection, Proceedings of the 13th European Conference on Software Maintenance and Reengineering (CSMR'09), pp. 219-228, (2009); Harris M., Sengupta S., Owens J.D., Parallel prefix sum (scan) with CUDA, GPU Gems, 3, 39, pp. 851-876, (2007); Hua W., Sui Y., Wan Y., Liu G., Xu G., Fcca: Hybrid code representation for functional clone detection using attention networks, IEEE Transactions on Reliability, 70, 1, pp. 304-318, (2020); Ishihara T., Hotta K., Higo Y., Igaki H., Kusumoto S., Inter-project functional clone detection toward building libraries-an empirical study on 13, 000 projects, Proceedings of the 19th Working Conference on Reverse Engineering (WCRE'12), pp. 387-391, (2012); Jeong H., Mason S.P., Barabasi A.-L., Oltvai Z.N., Lethality and centrality in protein networks, Nature, 411, 6833, pp. 41-42, (2001); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate tree-based detection of code clones, Proceedings of the 29th International Conference on Software Engineering (ICSE'07), pp. 96-105, (2007); Kamiya T., CCFinderX: An interactive code clone analysis environment, Code Clone Analysis, pp. 31-44, (2021); Kamiya T., Kusumoto S., Inoue K., CCFinder: A multilinguistic token-based code clone detection system for large scale source code, IEEE Transactions on Software Engineering, 28, 7, pp. 654-670, (2002); Katz L., A new status index derived from sociometric analysis, Psychometrika, 18, 1, pp. 39-43, (1953); Lavoie T., Eilers-Smith M., Merlo E., Challenging cloning related problems with GPU-based algorithms, Proceedings of the 4th International Workshop on Software Clones (IWSC'10), pp. 25-32, (2010); Li G., Wu Y., Roy C.K., Sun J., Peng X., Zhan N., Hu B., Ma J., SAGA: Efficient and large-scale detection of near-miss clones with GPU acceleration, Proceedings of the 27th International Conference on Software Analysis, Evolution and Reengineering (SANER'20), pp. 272-283, (2020); Li L., Feng H., Zhuang W., Meng N., Ryder B., CCLearner: A deep learning-based clone detection approach, Proceedings of the 2017 IEEE International Conference on Software Maintenance and Evolution (ICSME'17), pp. 249-260, (2017); Liang Y., Zhu K., Automatic generation of text descriptive comments for code blocks, Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI'18), 32, (2018); Liu X., Bollen J., Nelson M.L., Van De Sompel H., Co-authorship networks in the digital library research community, Information Processing & Management, 41, 6, pp. 1462-1480, (2005); Livieri S., Higo Y., Matushita M., Inoue K., Verylarge scale code clone analysis and visualization of open source programs using distributed CCFinder: D-CCFinder, Proceedings of the 29th International Conference on Software Engineering (ICSE'07), pp. 106-115, (2007); Lopes C.V., Maj P., Martins P., Saini V., Yang D., Zitny J., Sajnani H., Vitek J., DéjàVu: A map of code duplicates on GitHub, Proceedings of the 2017 ACM on Programming Languages (OOPSLA'17), pp. 1-28, (2017); Marchiori M., Latora V., Harmony in the small-world, Physica A: Statistical Mechanics and its Applications, 285, 3-4, pp. 539-546, (2000); Mondal M., Roy C.K., Schneider K.A., Does cloned code increase maintenance effort, Proceedings of the 11th International Workshop on Software Clones (IWSC'17), pp. 1-7, (2017); Mou L., Li G., Jin Z., Zhang L., Wang T., TBCNN: A tree-based convolutional neural network for programming language processing, (2014); Akanda Nishi M., Damevski K., Scalable code clone detection and search based on adaptive prefix filtering, Journal of Systems and Software, 137, pp. 130-142, (2018); Ossher J., Sajnani H., Lopes C., File cloning in open source Java projects: The good, the bad, and the ugly, 2011 27th IEEE International Conference on Software Maintenance (ICSM). IEEE, pp. 283-292, (2011); Kumar Roy C., Cordy J.R., A survey on software clone detection research, Queen's School of Computing TR, 541, 115, pp. 64-68, (2007); Roy C.K., Cordy J.R., NICAD: Accurate detection of nearmiss intentional clones using flexible pretty-printing and code normalization, Proceedings of the 16th International Conference on Program Comprehension (ICPC'08), pp. 172-181, (2008); Sajnani H., Saini V., Lopes C., A parallel and efficient approach to large scale clone detection, Journal of Software: Evolution and Process, 27, 6, pp. 402-429, (2015); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., Sourcerercc: Scaling code clone detection to big-code, Proceedings of the 38th International Conference on Software Engineering (ICSE'16), pp. 1157-1168, (2016); Svajlenko, Et al., Bigclonebench, Code Clone Analysis, pp. 93-105, (2021); Svajlenko J., Roy C.K., Evaluating clone detection tools with bigclonebench, Proceedings of the 2015 IEEE International Conference on Software Maintenance and Evolution (ICSME'15), pp. 131-140, (2015); Svajlenko J., Roy C.K., CloneWorks: A fast and flexible large-scale near-miss clone detection tool, Proceedings of the 39th International Conference on Software Engineering (ICSE'17), pp. 177-179, (2017); Wang P., Svajlenko J., Wu Y., Xu Y., Roy C.K., CCAligner: A token based large-gap clone detector, Proceedings of the 40th International Conference on Software Engineering (ICSE'18), pp. 1066-1077, (2018); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, Proceedings of the 27th International Conference on Software Analysis, Evolution and Reengineering (SANER'20), pp. 261-271, (2020); Wang X., Wu Q., Zhang H., Lyu C., Jiang X., Zheng Z., Lyu L., Hu S., HELoC: Hierarchical Contrastive Learning of Source Code Representation, (2022); Wei H., Li M., Supervised Deep Features for Software Functional Clone Detection by Exploiting Lexical and Syntactical Information in Source Code, Proceedings of the 2017 International Joint Conferences on Artificial Intelligence (IJCAI'17), pp. 3034-3040, (2017); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proceedings of the 27th International Conference on Automated Software Engineering (ASE'16), pp. 87-98, (2016); Wu Y., Zou D., Dou S., Yang S., Yang W., Cheng F., Liang H., Jin H., SCDetector: software functional clone detection based on semantic tokens analysis, Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering (ASE'20), pp. 821-833, (2020); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings of the 41st International Conference on Software Engineering (ICSE'19), pp. 783-794, (2019); Zhao G., Huang J., Deepsim: Deep learning code functional similarity, Proceedings of the 26th Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (FSE'18), pp. 141-151, (2018)",Ford; Google; HUAWEI; IBM; Meta; Oakland University,"37th IEEE/ACM International Conference on Automated Software Engineering, ASE 2022",10 October 2022 through 14 October 2022,Rochester,186042,English,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85146924679,199
Liu H.; Zhao H.; Han C.; Hou L.,"Liu, Hu (58180217100); Zhao, Hui (55619298524); Han, Changhao (57321777200); Hou, Lu (57188589131)",58180217100; 55619298524; 57321777200; 57188589131,Low-Complexity Code Clone Detection using Graph-based Neural Networks,2022,"Proceedings - 2022 18th International Conference on Mobility, Sensing and Networking, MSN 2022",,,,797,802,5,2,10.1109/MSN57253.2022.00129,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152299989&doi=10.1109%2fMSN57253.2022.00129&partnerID=40&md5=9f953d397742cd6b27e23a5711dbace7,"Code clone detection is of great significance for intellectual property protection and software maintenance. Deep learning has been applied in some research and achieved better performance than traditional methods. To adapt to more application scenarios and improve the detection efficiency, this paper proposes a low-complex code clone detection with the graph- based neural network. As the input of the neural network, code features are represented by abstract syntax trees (ASTs), in which the redundant edges are removed. The operation of pruning avoids interference in the message passing of the network and reduces the size of the graph. Then, the graph pairs for the code clone detection are sent into the message passing neural networks (MPNN). In addition, the gated recurrent unit (GRU) is used to learn the information between graph pairs to avoid the operation of Graph mapping. After multiple iterations, the attention mechanism is used to read out the graph vector, and the cosine similarity is calculated on the graph vector to obtain the code similarity. Through the experiments on two datasets, the results show that the proposed clone detection scheme removes about 20 % of the redundant edges and reduces 25 % of model weights, 16% of multiply-accumulate operations (MACs). In the end, the proposed method effectively reduces the training time of graph neural network while presenting a similar performance to the baseline network. © 2022 IEEE.","Cordy J.R., Roy C.K., The nicad clone detector, Ieee 19th Int. Conf. Program Comprehension, pp. 219-220, (2011); Amme W., Heinze T.S., Schafer A., You Look so Different: Finding Structural Clones and Subclones in Java Source Code, Ieee International Conference on Software Maintenance and Evolution (ICSME), pp. 70-80, (2021); Kamiya T., Kusumoto S., Inoue K., Ccfinder: A multilinguistic token-based code clone detection system for large scale source code, Ieee Trans. Softw. Eng, 28, 7, pp. 654-670, (2002); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate tree-based detection of code clones, The 29th Int. Conf. Softw. Eng, pp. 96-105, (2007); Krinke J., Identifying similar code with program dependence graphs, Proceedings Eighth Working Conference on Reverse Engineering, pp. 301-309, (2001); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings of the 41st International Conference on Software Engineering. Ieee Press, pp. 783-794, (2019); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, 27th Int. Conf. Software Analysis, Volution and Reengineering, pp. 261-271, (2020); Ji X., Liu L., Zhu J., Code Clone Detection with Hierarchical Attentive Graph Embedding, International Journal of Software Engineering and Knowledge Engineering, 31, 6, pp. 837-861, (2021); Hua W., Sui Y., Wan Y., Liu G., Xu G., FCCA: Hybrid Code Representation for Functional Clone Detection Using Attention Networks, Ieee Transactions on Reliability, 70, 1, pp. 304-318, (2021); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning Phrase Representations Using Rnn Encoder-Decoder for Statistical Machine Translation, (2014); Li Y., Gu C., Dullien T., Vinyals O., Kohli P., Graph matching networks for learning the similarity of graph structured objects, International Conference on Machine Learning, pp. 3835-3845, (2019); Svajlenko J., Islam J.F., Keivanloo I., Roy C.K., Mia M.M., Towards a big data curated benchmark of inter-project code clones, 2014 Ieee International Conference on Software Maintenance and Evolution, pp. 476-480, (2014); Gilmer J., Schoenholz S.S., Riley P.F., Vinyals O., Dahl G.E., Neural message passing for quantum chemistry, Proceedings of the 34th International Conference on Machine Learning, 70, pp. 1263-1272, (2017); Zhao G., Huang J., Deepsim: Deep learning code functional similarity, Proceedings of the 2018 26th Acm Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 141-151, (2018)",City University of Hong Kong; Hong Kong Polytechnic University; Sun Yat-sen University,"18th International Conference on Mobility, Sensing and Networking, MSN 2022",14 December 2022 through 16 December 2022,"Virtual, Online",187575,English,Conference paper,Final,,Scopus,2-s2.0-85152299989,200
Hu B.; Wu Y.; Peng X.; Sha C.; Wang X.; Fu B.; Zhao W.,"Hu, Bin (57216463679); Wu, Yijian (56093266500); Peng, Xin (53865467700); Sha, Chaofeng (8419449500); Wang, Xiaochen (57773089900); Fu, Baiqiang (57772915600); Zhao, Wenyun (8320355200)",57216463679; 56093266500; 53865467700; 8419449500; 57773089900; 57772915600; 8320355200,Predicting Change Propagation between Code Clone Instances by Graph-based Deep Learning,2022,IEEE International Conference on Program Comprehension,2022-March,,,425,436,11,1,10.1145/3524610.3527766,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133200335&doi=10.1145%2f3524610.3527766&partnerID=40&md5=8c8aeedb22b2c682a2e4551b6716b887,"Code clones widely exist in open-source and industrial software projects and are still recognized as a threat to software main-tenance due to the additional effort required for the simultaneous maintenance of multiple clone instances and potential defects caused by inconsistent changes in clone instances. To alleviate the threat, it is essential to accurately and efficiently make the decisions of change propagation between clone instances. Based on an exploratory study on clone change propagation with five famous open-source projects, we find that a clone class can have both propagation-required changes and propagation-free changes and thus fine-grained change propagation decision is required. Based on the findings, we propose a graph-based deep learning approach to predict the change propagation requirements of clone instances. We develop a graph representation, named Fused Clone Program Dependency Graph (FC-PDG), to capture the textual and structural code contexts of a pair of clone instances along with the changes on one of them. Based on the representation, we design a deep learning model that uses a Relational Graph Convolutional Network (R-GCN) to predict the change propagation requirement. We evaluate the approach with a dataset constructed based on 51 open-source Java projects, which includes 24,672 pairs of matched changes and 38,041 non-matched changes. The results show that the approach achieves high precision (83.1%), recall (81.2%), and F1-score (82.1%). Our further evaluation with three other open-source projects confirms the generality of the trained clone change propagation prediction model.  © 2022 ACM.","Aversano L., Cerulo L., Di Penta M., How Clones are Maintained: An Empirical Study, 11th European Conference on Software Maintenance and Reengineering, Software Evolution in Complex Software Intensive Systems, CSMR 2007, pp. 81-90, (2007); Barbour L., An L., Khomh F., Zou Y., Wang S., An investigation of the fault-proneness of clone evolutionary patterns, Softw. Qual. J., 26, 4, pp. 1187-1222, (2018); Barbour L., Khomh F., Zou Y., Late propagation in software clones, IEEE 27th International Conference on Software Maintenance, ICSM 2011, pp. 273-282, (2011); Barbour L., Khomh F., Zou Y., An empirical study of faults in late propagation clone genealogies, J. Softw. Evol. Process., 25, 11, pp. 1139-1165, (2013); Bazrafshan S., Evolution of Near-Miss Clones, 12th IEEE International Working Conference on Source Code Analysis and Manipulation, SCAM 2012, pp. 74-83, (2012); Cheng X., Zhong H., Chen Y., Hu Z., Zhao J., Rule-directed code clone synchronization, 24th IEEE International Conference on Program Comprehension, ICPC 2016, pp. 1-10, (2016); De Wit M., Zaidman A., Van Deursen A., Managing code clones using dynamic change tracking and resolution, 25th IEEE International Conference on Software Maintenance (ICSM 2009), pp. 169-178, (2009); Duala-Ekoko E., Robillard M.P., Tracking Code Clones in Evolving Software, 29th International Conference on Software Engineering (ICSE 2007), pp. 158-167, (2007); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A Pre-Trained Model for Programming and Natural Languages, (2020); Ferrante J., Ottenstein K.J., Warren J.D., The Program Dependence Graph and Its Use in Optimization, ACM Trans. Program. Lang. Syst., 9, 3, pp. 319-349, (1987); Gode N., Evolution of Type-1 Clones, Ninth IEEE International Working Conference on Source Code Analysis and Manipulation, SCAM 2009, pp. 77-86, (2009); Gode N., Harder J., Oops!. I changed it again, Proceeding of the 5th ICSE InternationalWorkshop on Software Clones, IWSC 2011, pp. 14-20, (2011); Gode N., Koschke R., Frequency and risks of changes to clones, Proceedings of the 33rd International Conference on Software Engineering, ICSE 2011, pp. 311-320, (2011); Hata H., Mizuno O., Kikuno T., Historage: fine-grained version control system for Java, Proceedings of the 12th International Workshop on Principles of Software Evolution and the 7th annual ERCIMWorkshop on Software Evolution, EVOL/IWPSE 2011, pp. 96-100, (2011); Higo Y., Kusumoto S., Code Clone Detection on Specialized PDGs with Heuristics, 15th European Conference on Software Maintenance and Reengineering, CSMR 2011, pp. 75-84, (2011); Hu B., Wu Y., Peng X., Sun J., Zhan N., Wu J., Assessing Code Clone Harmfulness: Indicators, Factors, and Counter Measures, 28th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2021, pp. 225-236, (2021); Huang K., Chen B., Peng X., Zhou D., Wang Y., Liu Y., Zhao W., ClDiff: generating concise linked code differences, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, ASE 2018, pp. 679-690, (2018); Inoue K., Higo Y., Yoshida N., Choi E., Kusumoto S., Kim K., Park W., Lee E., Experience of finding inconsistently-changed bugs in code clones of mobile software, Proceeding of the 6th InternationalWorkshop on Software Clones, IWSC 2012, pp. 94-95; Rakibul I.M., Zibran M.F., On the characteristics of buggy code clones: A code quality perspective, 12th IEEE International Workshop on Software Clones, IWSC 2018, pp. 23-29, (2018); Jablonski P., Hou D., Aiding Software Maintenance with Copy-and-Paste Clone-Awareness, The 18th IEEE International Conference on Program Comprehension, ICPC 2010, pp. 170-179, (2010); Kamiya T., Kusumoto S., Inoue K., CCFinder: A Multilinguistic Token-Based Code Clone Detection System for Large Scale Source Code, IEEE Trans. Software Eng., 28, 7, pp. 654-670, (2002); Kim M., Sazawal V., Notkin D., Murphy G.C., An empirical study of code clone genealogies, Proceedings of the 10th European Software Engineering Conference held jointly with 13th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 187-196, (2005); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, 3rd International Conference on Learning Representations, ICLR 2015, (2015); Krinke J., A Study of Consistent and Inconsistent Changes to Code Clones, 14th Working Conference on Reverse Engineering (WCRE 2007), pp. 170-178, (2007); Li G., Wu Y., Roy C.K., Sun J., Peng X., Zhan N., Hu B., Ma J., SAGA: Efficient and Large-Scale Detection of Near-Miss Clones with GPU Acceleration, 27th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2020, pp. 272-283, (2020); Lin Y., Peng X., Xing Z., Zheng D., Zhao W., Clone-based and interactive recommendation for modifying pasted code, Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2015, pp. 520-531, (2015); Lozano A., Wermelinger M., Nuseibeh B., Evaluating the Harmfulness of Cloning: A Change Based Experiment, Fourth International Workshop on Mining Software Repositories, MSR 2007 (ICSEWorkshop), (2007); Mondal M., Saidur Rahman Md., Roy C.K., Schneider K.A., Is cloned code really stable?, Empir. Softw. Eng., 23, 2, pp. 693-770, (2018); Mondal M., Roy C.K., Schneider K.A., Automatic ranking of clones for refactoring through mining association rules, 2014 Software EvolutionWeek-IEEE Conference on Software Maintenance, Reengineering, and Reverse Engineering, CSMR-WCRE 2014, pp. 114-123, (2014); Mondal M., Roy C.K., Schneider K.A., Prediction and ranking of co-change candidates for clones, 11th Working Conference on Mining Software Repositories, MSR 2014, Proceedings, pp. 32-41, (2014); Mondal M., Roy C.K., Schneider K.A., A comparative study on the intensity and harmfulness of late propagation in nearmiss code clones, Softw. Qual. J., 24, 4, pp. 883-915, (2016); Mondal M., Roy C.K., Schneider K.A., Bugproneness and late propagation tendency of code clones: A Comparative study on different clone types, J. Syst. Softw., 144, pp. 41-59, (2018); Anh Nguyen H., Thanh Nguyen T., Pham N.H., Al-Kofahi J.M., Nguyen T.N., Clone Management for Evolving Software, IEEE Trans. Software Eng., 38, 5, pp. 1008-1026, (2012); Thanh Nguyen T., Anh Nguyen H., Pham N.H., Al-Kofahi J.M., Nguyen T.N., Clone-Aware Configuration Management, ASE 2009, 24th IEEE/ACM International Conference on Automated Software Engineering, pp. 123-134, (2009); Rahman F., Bird C., Devanbu P.T., Clones: what is that smell?, Empir. Softw. Eng., 17, 4-5, pp. 503-530, (2012); Ruff L., Gornitz N., Deecke L., Ahmed Siddiqui S., Vandermeulen R.A., Binder A., Muller E., Kloft M., Deep One-Class Classification, Proceedings of the 35th International Conference on Machine Learning, ICML 2018, 80, pp. 4390-4399, (2018); Saha R.K., Roy C.K., Schneider K.A., An automatic framework for extracting and classifying near-miss clone genealogies, IEEE 27th International Conference on Software Maintenance, ICSM 2011, pp. 293-302, (2011); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., SourcererCC: scaling code clone detection to big-code, Proceedings of the 38th International Conference on Software Engineering, ICSE 2016, pp. 1157-1168, (2016); Sejr Schlichtkrull M., Kipf T.N., Bloem P., Van Den Berg R., Titov I., Welling M., Modeling Relational Data with Graph Convolutional Networks, The Semantic Web-15th International Conference, ESWC 2018, Proceedings (Lecture Notes in Computer Science Vol. 10843), pp. 593-607, (2018); Tokui S., Yoshida N., Choi E., Inoue K., Clone Notifier: Developing and Improving the System to Notify Changes of Code Clones, 27th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2020, pp. 642-646, (2020); Uemura K., Mori A., Choi E., Iida H., Tracking Method-Level Clones and a Case Study, 13th IEEE International Workshop on Software Clones, IWSC 2019, pp. 27-33, (2019); Wang X., Dang Y., Zhang L., Zhang D., Lan E., Mei H., Predicting Consistency-Maintenance Requirement of Code Clones at Copy-and-Paste Time, IEEE Trans. Software Eng., 40, 8, pp. 773-794, (2014); Yue R., Gao Z., Meng N., Xiong Y., Wang X., David Morgenthaler J., Automatic Clone Recommendation for Refactoring Based on the Present and the Past, 2018 IEEE International Conference on Software Maintenance and Evolution, ICSME 2018, pp. 115-126, (2018); Zhang F., Khoo S., An empirical study on clone consistency prediction based on machine learning, Inf. Softw. Technol., 136, (2021); Zhang F., Khoo S., Su X., Predicting Consistent Clone Change, 27th IEEE International Symposium on Software Reliability Engineering, ISSRE 2016, pp. 353-364, (2016); Zhang F., Khoo S., Su X., Predicting change consistency in a clone group, Journal of Systems and Software, 134, pp. 105-119, (2017); Zhang F., Khoo S., Su X., Improving Maintenance-Consistency Prediction During Code Clone Creation, IEEE Access, 8, pp. 82085-82099, (2020); Zou Y., Ban B., Xue Y., Xu Y., CCGraph: a PDGbased code clone detector with approximate graph matching, 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020, pp. 931-942, (2020)",,"30th IEEE/ACM International Conference on Program Comprehension, ICPC 2022",16 May 2022 through 17 May 2022,Pittsburgh,180257,English,Conference paper,Final,,Scopus,2-s2.0-85133200335,201
Lu Z.; Li R.; Hu H.; Zhou W.-A.,"Lu, Zhicheng (57222150709); Li, Ruochen (57808638900); Hu, Huamiao (56808482400); Zhou, Wen-An (36095059500)",57222150709; 57808638900; 56808482400; 36095059500,A code clone detection algorithm based on graph convolution network with AST tree edge,2021,"Proceedings - 2021 21st International Conference on Software Quality, Reliability and Security Companion, QRS-C 2021",,,,1027,1032,5,1,10.1109/QRS-C55045.2021.00156,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140923450&doi=10.1109%2fQRS-C55045.2021.00156&partnerID=40&md5=cdb1920d1758a453955a77a6c54f6ec9,"Detecting code cloning will prevent it from bringing risks such as vulnerabilities and intellectual property disputes in complex software systems such as large-scale defense software systems and commercial software systems. In the field of deep code clone detection, neural networks such as Tree-CNN and Tree-LSTM, which extract features from AST (abstract syntax tree), can't collect global information of upper and lower nodes, and information can't flow globally, but graph neural network can avoid this problem. This paper presents a method of edging AST, and uses GCN (Graph Convolutional Network) and GAT(Graph Attention Networks) to extract code feature vector. Finally, the experiment is carried out on BigCloneBench data set, using several common binary classification indexes, and analyzing the time consumption, it is concluded that the effect and time efficiency of using graph neural network for code clone detection are significantly improved, especially for the code fragments with completely different semantics.  © 2021 IEEE.","Bellon S., Koschke R., Antoniol G., Krinke J., Merlo E., Comparison and evaluation of clone detection tools, IEEE Tran on Software Engineering, 33, 9, (2007); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs[C], International Conference on Learning Representations (ICLR), pp. 241-251, (2018); Li Y., Tarlow D., Brockschmidt M., Et al., Gated graph sequence neural networks[C], International Conference on Learning Representations (ICLR), pp. 151-171, (2015); Defferrard M., Bresson X., Vandergheynst P., Convolutional neural networks on graphs with fast localized spectral filtering[C], Neural Information Processing Systems (NIPS), pp. 3844-3852, (2016); Velikovi P., Cucurull G., Casanova A., Graph Attention Networks[C], International Conference on Learning Representations (ICLR), pp. 17-30, (2018); Svajlenko J., Islam J.F., Keivanloo I., Et al., Towards a big data curated benchmark of inter-project code clones[C], ICSME, pp. 476-480, (2014); Zhang J., Wang X., Zhang H., Et al., A Novel Neural Source Code Representation Based on Abstract Syntax Tree [C], 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 784-794, (2019); Yu H., Lam W., Chen L., Li G., Xie T., Wang Q., Neural Detection of Semantic Code Clones via Tree-Based Convolution, IEEE/ACM 27th International Conference on Program Comprehension (ICPC), (2019); Wu Z., Pan S., Chen F., Zhang C., Yu P.S., Et al., A Comprehensive Survey on Graph Neural Networks[J], IEEE Transactions on Neural Networks and Learning Systems, 32, 1, pp. 4-24, (2020); Mou L., Li G., Zhang L., Et al., Convolutional neural networks over tree structures for programming language processing[C], AAAI, pp. 4-12, (2016); Zeng J., Ben K., Li X., Et al., Fast Code Clone Detection Based on Weighted Recursive Autoencoders[J], IEEE Access, 11, 7, pp. 125062-125078, (2019)",,"21st International Conference on Software Quality, Reliability and Security Companion, QRS-C 2021",6 December 2021 through 10 December 2021,"Virtual, Hainan",178383,English,Conference paper,Final,,Scopus,2-s2.0-85140923450,202
Xu K.; Liu Y.,"Xu, Kun (57203100870); Liu, Yan (56023515500)",57203100870; 56023515500,SCCD-GAN: An Enhanced Semantic Code Clone Detection Model Using GAN,2021,"2021 IEEE 4th International Conference on Electronics and Communication Engineering, ICECE 2021",,,,16,22,6,2,10.1109/ICECE54449.2021.9674552,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125205818&doi=10.1109%2fICECE54449.2021.9674552&partnerID=40&md5=f22e2f0159ad2ce1329266e99268e3e1,"Code clone refers to a pair of semantically similar but syntactically similar or different code fragments that exist in code base. Excessive code clones in software system will cause a negative impact on system development and maintenance. In recent years, as deep learning has become a hot research area of machine learning, researchers have tried to apply deep learning techniques to code clone detection tasks. They have proposed a series of detection techniques using including unstructured (code in the form of sequential tokens) and structured (code in the form of abstract syntax trees and control-flow graphs) information to detect semantically similar but syntactically different code clone, which is the most difïîcult-to-detect clone type. However, although these methods have achieved an important improvement in the precision of semantic code clone detection, the corresponding false positive rate(FPR) is also at a very high level, making these methods unable to be effectively applied to real-world code bases. This paper proposed S C C D - G A N, an enhanced semantic code clone detection model which based on a graph representation form of programs and uses Graph Attention Network to measure the similarity of code pairs and achieved a lower detection F P R than existing methods. We built the graph representation of the code by expanding the control flow and data flow information to the original abstract syntax tree, and equipped with an attention mechanism to our model that focuses on the most important code parts and features which contribute much to the final detection precision. We implemented and evaluated our proposed method based on the benchmark dataset in the field of code clone detectionBigCloneBench2 and Google Code Jam. S C C D - G A N performed better than the existing state-of-the-art methods in terms of precision and false positive rate. ©2021 IEEE","Rattan D., Bhatia R., Singh M., Software clone detection: A systematic review[J], Information and Software Technology, 55, 7, pp. 1165-1199, (2013); White M., Tufano M., Vendome C., Et al., Deep learning code fragments for code clone detection[C], 2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 87-98, (2016); Zhao G., Huang J., DeepSim: Deep learning code functional similarity, Proceedings of The 2018 26th A C M Joint Meeting on European Software Engineering Conference and Symposium on The Foundations of Software Engineering (ESEC/FSE 2018), pp. 141-151, (2018); Baxter I.D., Yahin A., Moura L., Sant'Anna M., Bier L., Clone detection using abstract syntax trees, Proc. of The Int'L Conf. on Software Maintenance., pp. 368-377, (1998); Yuan Y., Guo Y., Boreas: An Accurate and Scalable Token-Based Approach to Code Clone Detection[C], pp. 286-289, (2012); Raheja K., Tekchandani R., An emerging approach towards code clone detection: Metric based approach on byte code[J], International Journal of Advanced Research in Computer Science and Software Engineering, 3, 5, (2013); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate tree-based detection of code clones, Proc. of The 29th Int'L Conf. on Software Engineering. IEEE Computer Society, pp. 96-105, (2007); Mehrotra N., Agarwal N., Gupta P., Et al., Modeling functional similarity in source code with graph-based Siamese networks[J], IEEE Transactions on Software Engineering; Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs[J], (2017); Zhang D., Yin J., Zhu X., Zhang C., Network representation learning: A survey, IEEE Transactions on Big Data, 6, 1, pp. 3-28; Zhang J., Wang X., Zhang H., Et al., A novel neural source code representation based on abstract syntax tree[C], 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 783-794, (2019); Sheneamer A., A survey of software clone detection techniques[J], International Journal of Computer Applications, Foundation of Computer Science, 137, 10, pp. 1-21, (2016); Roy C.K., Cordy J.R., A survey on software clone detection research, QueenâA ""Z S School of Computing TR, 541, 115, pp. 64-68, (2007); Tai K.S., Socher R., Manning C.D., Improved semantic representations from tree-structured long short-term memory networks, Proceedings of The 53rd Annual Meeting of The Association for Computational Linguistics and The 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), (2015); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, IJCAI, pp. 3034-3040, (2017); Li L., Feng H., Zhuang W., Meng N., Ryder B., CClearner: A deep learning-based clone detection approach, Proc. of The Int'L Conf. on Software Maintenance and Evolution (ICSME)., pp. 249-260, (2017); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proceedings of The 31st IEEE/ACM International Conference on Automated Software Engineer¬ Ing, pp. 87-98, (2016); Svajlenko J., Roy C.K., Evaluating Clone Detection Tools with Bigclonebench[C], pp. 131-140, (2015); Roy C., Zibran M., Koschke R., The Vision of Software Clone Management: Past, Present, and Future, pp. 18-33, (2014); Roy C.K., Cordy J.R., NICAD: Accurate detection of near-miss intentional clones using flexible pretty-printing and code normalization, Proc. of The 16th IEEE Int'L Conf. on Program Comprehension., (2008)",IEEE Xi'an Broadcast Technology Chapter; Xi'an University of Technology,"4th IEEE International Conference on Electronics and Communication Engineering, ICECE 2021",17 December 2021 through 19 December 2021,"Virtual, Xi'an",176481,English,Conference paper,Final,,Scopus,2-s2.0-85125205818,203
Wu Y.; Zou D.; Dou S.; Yang S.; Yang W.; Cheng F.; Liang H.; Jin H.,"Wu, Yueming (57202109788); Zou, Deqing (8935128200); Dou, Shihan (57221458503); Yang, Siru (57221476743); Yang, Wei (55607069500); Cheng, Feng (58728488400); Liang, Hong (58590283200); Jin, Hai (56434989100)",57202109788; 8935128200; 57221458503; 57221476743; 55607069500; 58728488400; 58590283200; 56434989100,SCDetector: Software Functional Clone Detection Based on Semantic Tokens Analysis,2020,"Proceedings - 2020 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020",,,9285662,821,833,12,42,10.1145/3324884.3416562,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099212810&doi=10.1145%2f3324884.3416562&partnerID=40&md5=7637baf6c518b1c7013ceb5c4b83a3ee,"Code clone detection is to find out code fragments with similar functionalities, which has been more and more important in software engineering. Many approaches have been proposed to detect code clones, in which token-based methods are the most scalable but cannot handle semantic clones because of the lack of consideration of program semantics. To address the issue, researchers conduct program analysis to distill the program semantics into a graph representation and detect clones by matching the graphs. However, such approaches suffer from low scalability since graph matching is typically time-consuming. In this paper, we propose SCDetector to combine the scalability of token-based methods with the accuracy of graph-based methods for software functional clone detection. Given a function source code, we first extract the control flow graph by static analysis. Instead of using traditional heavyweight graph matching, we treat the graph as a social network and apply social-network-centrality analysis to dig out the centrality of each basic block. Then we assign the centrality to each token in a basic block and sum the centrality ofthe same token in different basic blocks. By this, a graph is turned into certain tokens with graph details (i.e., centrality), called semantic tokens. Finally, these semantic tokens are fed into a Siamese architecture neural network to train a code clone detector. We evaluate SCDetector on two large datasets of functionally similar code. Experimental results indicate that our system is superior to four state-of-the-art methods (i.e., SourcererCC, Deckard, RtvNN, and ASTNN) and the time cost of SCDetector is 14 times less than a traditional graph-based method (i.e., CCSharp) on detecting semantic clones. © 2020 ACM.","Google Code Jam, (2017); (2020); A Java Optimization Framework (Soot), (2020); Platform for C/C++ Code Analysis (Joern), (2020); Software for Complex Networks (Networkx), (2020); Tensors and Dynamic Neural Networks in Python with Strong GPU Acceleration (PyTorch), (2020); T.J. Watson Libraries for Analysis (WALA), (2020); Bahdanau D., Cho K., Bengio Y., Neural Machine Translation by Jointly Learning to Align and Translate, (2014); Balazinska M., Merlo E., Dagenais M., Lague B., Kontogiannis K., Measuring clone based reengineering opportunities, Proceedings Ofthe 6th International Software Metrics Symposium (ISMS'99), pp. 292-303, (1999); Baldi P., Chauvin Y., Neural networks for fingerprint recognition, Neural Computation, 5, 3, pp. 402-418, (1993); Bellon S., Koschke R., Antoniol G., Krinke J., Merlo E., Comparison and evaluation of clone detection tools, IEEE Transactions on Software Engineering, 33, 9, pp. 577-591, (2007); Chen K., Liu P., Zhang Y., Achieving accuracy and scalability simultaneously in detecting application clones on android markets, Proceedings Ofthe 36th International Conference on Software Engineering (ICSE'14), pp. 175-186, (2014); Coles N., It's not what you know-It's who you know that counts. Analysing serious crime groups as social nehvorks, British Journal afCriminology, 41, 4, pp. 580-594, (2001); Ducasse S., Rieger M., Demeyer S., A language independent approach for detecting duplicated code, Proceedings Ofthe 1999 International Conference on Software Maintenance (ICSM'99), pp. 109-118, (1999); Elva R., Leavens G.T., Jsctracker: A Semantic Clone Detection Tool for Java Code, (2012); Faust K., Centrality in affiliation networks, Social Networks, 19, 2, pp. 157-191, (1997); Freeman L.C., A set of measures of centrality based on betweenness, Sociometry, 40, 1, pp. 35-41, (1977); Freeman L.C., Centrality in social networks conceptual clarification, Social Networks, 1, 3, pp. 215-239, (1978); German D.M., Penta M.D., Gueheneuc Y.-G., Antoniol G., Code siblings: Technical and legal implications of copying code between applications, Proceedings Ofthe 6th International Working Conference on Mining Software Repositories (MSR'09), pp. 81-90, (2009); Gode N., Koschke R., Incremental clone detection, Proceedings of the 2009 European Conference on Software Maintenance and Reengineering (ECSMR'09), pp. 219-228, (2009); Guimera R., Mossa S., Turtschi A., Nunes Amaral L.A., The worldwide air transportation network: Anomalous centrality, community structure, and cities' global roles, The National Academy ofSciences, 102, 22, pp. 7794-7799, (2005); Ishihara T., Hotta K., Higo Y., Igaki H., Kusumoto S., Inter-project functional clone detection toward building libraries: An empirical study on 13,000 projects, Proceedings Ofthe 19th Working Conference on Reverse Engineering (WCRE'12), pp. 387-391, (2012); Jeong H., Mason S.P., Barabasi A.L., Ollvai Z.N., Lethality and centrality in protein networks, Nature, 411, 6833, pp. 41-42, (2001); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate tree-based detection ofcode clones, Proceedings Ofthe 29th International Conference on Software Engineering (ICSE'07), pp. 96-105, (2007); Jiang L., Suo Z., Automatic mining of functionally equivalent code fragments via random testing, Proceedings of the 18th International Symposium on Software Testing andAnalysis (ISSTA'09), pp. 81-92, (2009); Howard Johnson J., Substring matching for clone detection and change tracking, Proceedings of the 1994 International Conference on Software Maintenance (ICSM'94), pp. 120-126, (1994); Kamiya T., Agee: An execution-semantic clone detection tool, Proceedings Ofthe 21st International Conference on Program Comprehension (ICPC'13), pp. 227-229, (2013); Kamiya T., Kusumoto S., Inoue K., CCFinder: A multilinguistic token-based code clone detection system for large scale source code, IEEE Transactions on Software Engineering, 28, 7, pp. 654-670, (2002); Katz L., A new status index derived from sociometric analysis, Psychometrika, 18, 1, pp. 39-43, (1953); Keivanloo I., Rilling J., Charland P., Internet-scale real-time code clone search via multi-level indexing, Proceedings Ofthe 18th Working Conference on Reverse Engineering (WCRE'II), pp. 23-27, (2011); Keivanloo I., Roy C.K., Rilling J., SebyTe: A semantic clone detection tool for intermediate languages, Proceedings Ofthe 20th International Conference on Program Comprehension (ICPC'12), pp. 247-249, (2012); Komondoor R., Horwitz S., Using slicing to identify duplication in source code, Proceedings Ofthe 2001 International Static Analysis Symposium (ISAS'OI), pp. 40-56, (2001); Koschke R., Large-scale inter-system clone detection using suffix trees, Proceedings of the 16th European Conference on Software Maintenance and Reengineering (ECSME'12), pp. 309-318, (2012); Krinke J., Identifying similar code with program dependence graphs, Proceedings Ofthe 8th Working Conference on Reverse Engineering (WCRE'OI), pp. 301-309, (2001); Li L., Feng H., Zhuang W., Meng N., Ryder B., CClearner: A deep learning-based clone detection approach, Proceedings Ofthe 2017 International Conference on Software Maintenance and Evolution (ICSME'17), pp. 249-260, (2017); Liu X., Bollen J., Nelson M.L., van de Sompel H., Co-authorship networks in the digital library research community, Information Processing & Management, 41, 6, pp. 1462-1480, (2005); Mayrand J., Leblanc C., Merlo E., Experiment on the automatic detection of function clones in a software system using metrics, Proceedings of the 1996 International Conference on Software Maintenance (ICSM'96), pp. 244-253, (1996); Mikolov T., Chen K., Corrado G., Dean J., Efficient Estimation Ofword Representations in Vector Space, (2013); Patenaude J.F., Merlo E., Dagenais M., Lague B., Extending software quality assessment techniques to Java systems, Proceedings Ofthe 7th International Workshop on Program Comprehension (IWPC'99), pp. 49-56, (1999); Roy C.K., Cordy J.R., NICAD: Accurate detection of near-miss intentional clones using flexible pretty-printing and code normalization, Proceedings of the 2008 International Conference on Program Comprehension (ICPC'08), pp. 172-181, (2008); Roy C.K., Cordy J.R., A survey on software clone detection research, Queen'S School of Computing 1R, 541, 115, pp. 64-68, (2007); Saini V., Farmahinifarahani F., Lu Y., Baldi P., Lopes C.V., Oreo: Detection of clones in the twilight zone, Proceedings of the 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations ofSoftware Engineering (FSE'18), pp. 354-365, (2018); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., SourcererCC: Scaling code clone detection to big code, Proceedings Ofthe 38th International Conference on Software Engineering (ICSE'16), pp. 1157-1168, (2016); Sheneamer A., Kalita J., Semantic clone detection using machine learning, Proceedings Ofthe 15th International Conference on Machine Learning andApplications (ICMLA'16), pp. 1024-1028, (2016); Svajlenko J., Islam J.F., Keivanloo I., Roy C.K., Mia M.M., Towards a big data curated benchmark of inter-project code clones, Proceedings Ofthe 2014 International Conference on Software Maintenance and Evolution (ICSME'14), pp. 476-480, (2014); Tai K.S., Socher R., Manning C.D., Improved Semantic Representations from Tree-Structured Long Short-Term Memory Networks, (2015); Tang D., Qin B., Liu T., Document modeling with gated recurrent neural network for sentiment classification, Proceedings Afthe 2015 Conference on Empirical Methods in Natural Language Processing (CMNLP'15), pp. 1422-1432, (2015); Tufano M., Watson C., Bavota G., Penta M.D., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, Proceedings Ofthe 15th International Conference on Mining Software Repositories (MSR'18), pp. 542-553, (2018); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones U., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Proceddings Ofthe 2017 Conference on Neural Information Processing Systems (NIPS'17), pp. 5998-6008, (2017); Wang M., Wang P., Xu Y., CCSharp: An efficient three-phase code clone detector using modified pdgs, Proceedings Ofthe 24th Asia-Pacific Software Engineering Conference (APSEC'17), pp. 100-109, (2017); Wang P., Svajlenko J., Wu Y., Xu Y., Roy C.K., CCaligner: A token based large-gap clone detector, Proceedings Ofthe 40th International Conference on Software Engineering (ICSE'18), pp. 1066-1077, (2018); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proceedings Ofthe 2017 International Joint Conferences on Artificial Intelligence (IJCAI'17), pp. 3034-3040, (2017); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proceedings of the 31st International Conference on Automated Software Engineering (ASE'16), pp. 87-98, (2016); Wu Y., Li X., Zou D., Yang W., Zhang X., Jin H., MalScan: Fast market-wide mobile malware scanning by social-network centrality analysis, Proceedings Ofthe 34th International Conference onAutomated Software Engineering (ASE'19), pp. 139-150, (2019); Yang W., Xiao X., Andow B., Li S., Xie T., Enck W., AppContext: Differentiating malicious and benign mobile app behaviors using context, Proceedings of the 37th International Conference on Software Engineering (ICSE'IS), pp. 303-313, (2015); Zaremba W., Sutskever I., Learning to Execute, (2014); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings Ofthe 41stInternational Conference on Software Engineering (ICSE'19), pp. 783-794, (2019); Zhao G., Huang J., DeepSim: Deep learning code functional similarity, Proceedings Ofthe 26th ACM Joint Meeting on European Software Engineering Conference andSymposium on theFoundations ofSoftwareEngineering (FSE'18), pp. 141-151, (2018)",Deakin University; Monash University; NASA Ames Research Centre,"35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020",22 September 2020 through 25 September 2020,"Virtual, Melbourne",166082,English,Conference paper,Final,,Scopus,2-s2.0-85099212810,204
Wang W.; Li G.; Ma B.; Xia X.; Jin Z.,"Wang, Wenhan (57216463961); Li, Ge (55901136600); Ma, Bo (57216462837); Xia, Xin (54586248800); Jin, Zhi (8961795500)",57216463961; 55901136600; 57216462837; 54586248800; 8961795500,Detecting Code Clones with Graph Neural Network and Flow-Augmented Abstract Syntax Tree,2020,"SANER 2020 - Proceedings of the 2020 IEEE 27th International Conference on Software Analysis, Evolution, and Reengineering",,,9054857,261,271,10,167,10.1109/SANER48275.2020.9054857,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083565137&doi=10.1109%2fSANER48275.2020.9054857&partnerID=40&md5=bf82acc679eee5776a729dba7d685a8d,"Code clones are semantically similar code fragments pairs that are syntactically similar or different. Detection of code clones can help to reduce the cost of software maintenance and prevent bugs. Numerous approaches of detecting code clones have been proposed previously, but most of them focus on detecting syntactic clones and do not work well on semantic clones with different syntactic features. To detect semantic clones, researchers have tried to adopt deep learning for code clone detection to automatically learn latent semantic features from data. Especially, to leverage grammar information, several approaches used abstract syntax trees (AST) as input and achieved significant progress on code clone benchmarks in various programming languages. However, these AST-based approaches still can not fully leverage the structural information of code fragments, especially semantic information such as control flow and data flow. To leverage control and data flow information, in this paper, we build a graph representation of programs called flow-augmented abstract syntax tree (FA-AST). We construct FA-AST by augmenting original ASTs with explicit control and data flow edges. Then we apply two different types of graph neural networks (GNN) on FA-AST to measure the similarity of code pairs. As far as we have concerned, we are the first to apply graph neural networks on the domain of code clone detection. We apply our FA-AST and graph neural networks on two Java datasets: Google Code Jam and BigCloneBench. Our approach outperforms the state-of-the-art approaches on both Google Code Jam and BigCloneBench tasks. © 2020 IEEE.","Roy C.K., Cordy J.R., A survey on software clone detection research, Queen's School of Computing TR, 541, 115, pp. 64-68, (2007); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering. ACM, pp. 87-98, (2016); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, IJCAI, pp. 3034-3040, (2017); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings of the 41st International Conference on Software Engineering, pp. 783-794, (2019); Tai K.S., Socher R., Manning C.D., Improved semantic representations from tree-structured long short-term memory networks, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 1556-1566, (2015); Zhao G., Huang J., Deepsim: Deep learning code functional similarity, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ACM, pp. 141-151, (2018); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, (2015); Li Y., Gu C., Dullien T., Vinyals O., Kohli P., Graph matching networks for learning the similarity of graph structured objects, International Conference on Machine Learning, pp. 3835-3845, (2019); Svajlenko J., Islam J.F., Keivanloo I., Roy C.K., Mia M.M., Towards a big data curated benchmark of inter-project code clones, 2014 IEEE International Conference on Software Maintenance and Evolution. IEEE, pp. 476-480, (2014); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Transactions on Neural Networks, 20, 1, pp. 61-80, (2008); Gilmer J., Schoenholz S.S., Riley P.F., Vinyals O., Dahl G.E., Neural message passing for quantum chemistry, Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp. 1263-1272, (2017); Zhou J., Cui G., Zhang Z., Yang C., Liu Z., Sun M., Graph Neural Networks: A Review of Methods and Applications, (2018); Cho K., Van Merrienboer B., Bahdanau D., Bengio Y., On the Properties of Neural Machine Translation: Encoder-decoder Approaches, (2014); Google Code Jam, (2016); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate tree-based detection of code clones, Proceedings of the 29th International Conference on Software Engineering. IEEE Computer Society, pp. 96-105, (2007); Socher R., Pennington J., Huang E.H., Ng A.Y., Manning C.D., Semi-supervised recursive autoencoders for predicting sentiment distributions, Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, pp. 151-161, (2011); Fey M., Lenssen J.E., Fast Graph Representation Learning with Pytorch Geometric, (2019); Kingma D.P., Ba J., Adam: A method for stochastic optimization, 3rd International Conference on Learning Representations, ICLR 2015, (2015); Li L., Feng H., Zhuang W., Meng N., Ryder B., Cclearner: A deep learning-based clone detection approach, 2017 IEEE International Conference on Software Maintenance and Evolution (ICSME). IEEE, pp. 249-260, (2017); Wei H., Li M., Positive and unlabeled learning for detecting software functional clones with adversarial training, IJCAI, pp. 2840-2846, (2018); Saini V., Farmahinifarahani F., Lu Y., Baldi P., Lopes C.V., Oreo: Detection of clones in the twilight zone, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ACM, pp. 354-365, (2018); Phan A.V., Le Nguyen M., Bui L.T., Convolutional neural networks over control flow graphs for software defect prediction, 2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI). IEEE, pp. 45-52, (2017); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs, (2017); Brockschmidt M., Allamanis M., Gaunt A.L., Polozov O., Generative Code Modeling with Graphs, (2018)",IEEE Computer Society; Western University,"27th IEEE International Conference on Software Analysis, Evolution, and Reengineering, SANER 2020",18 February 2020 through 21 February 2020,London,158982,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85083565137,205
Cai J.; Li B.; Zhang T.; Zhang J.; Sun X.,"Cai, Jie (57578657800); Li, Bin (56342840400); Zhang, Tao (55547105895); Zhang, Jiale (55951743400); Sun, Xiaobing (24829988300)",57578657800; 56342840400; 55547105895; 55951743400; 24829988300,Fine-grained smart contract vulnerability detection by heterogeneous code feature learning and automated dataset construction,2024,Journal of Systems and Software,209,,111919,,,,1,10.1016/j.jss.2023.111919,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180003952&doi=10.1016%2fj.jss.2023.111919&partnerID=40&md5=f8c6ac95fe3f1d112dae245ff2f18316,"Context: Recently, several deep learning based smart contract vulnerability detection approaches have been proposed. However, challenges still exist in applying deep learning for fine-grained vulnerability detection in smart contracts, including the lack of the dataset with sufficient statement-level labeled smart contract samples and neglect of heterogeneity between syntax and semantic features during code feature learning. Objective: To utilize deep learning for fine-grained smart contract vulnerability detection, we propose a security best practices (SBP) based dataset construction approach to address the scarcity of datasets. Moreover, we propose a syntax-sensitive graph neural network to address the challenge of heterogeneous code feature learning. Method: The dataset construction approach is motivated by the insight that smart contract code fragments guarded by security best practices may contain vulnerabilities in their original unguarded code form. Thus, we locate and strip security best practices from the smart contract code to recover its original vulnerable code form and perform sample labeling. Meanwhile, as the heterogeneity between tree-structured syntax features embodied inside the abstract syntax tree (AST) and graph-structured semantic features reflected by relations between statements, we propose a code graph whose nodes are each statement's AST subtree with a syntax-sensitive graph neural network that enhances the graph neural network by a child-sum tree-LSTM cell to learn these heterogeneous features for fine-grained smart contract vulnerability detection. Results: We compare our approach with three state-of-the-art deep learning-based approaches that only support contract-level vulnerability detection and two popular static analysis-based approaches that support fine detection granularity. The experiment results show that our approach outperforms the baselines at both coarse and fine granularities. Conclusion: In this paper, we propose utilizing security best practices inside the smart contract code to construct the dataset with statement-level labels. To learn both tree-structured syntax and graph-structured semantic code features, we propose a syntax-sensitive graph neural network. The experimental results show that our approach outperforms the baselines. © 2023 Elsevier Inc.","pp. 454-469, (2020); Brody S., Alon U., Yahav E., How attentive are graph attention networks?, (2021); Bui N.D.Q., Yu Y., Jiang L., Infercode: Self-supervised learning of code representations by predicting subtrees, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), pp. 1186-1197, (2021); Buterin V., Vyper documentation, (2018); ConsenSys, Mythril, (2021); ConsenSys, Solc-typed-ast, (2022); Dannen C., Introducing Ethereum and Solidity, Vol. 1, (2017); pp. 530-541, (2020); Falkon S., The story of the DAO—Its history and consequences, (2017); Feist J., Grieco G., Groce A., Slither: a static analysis framework for smart contracts, 2019 IEEE/ACM 2nd International Workshop on Emerging Trends in Software Engineering for Blockchain (WETSEB), pp. 8-15, (2019); Feng X., HuangGai, (2021); Gao Z., Jiang L., Xia X., Lo D., Grundy J., Checking smart contracts with structural code embedding, IEEE Trans. Softw. Eng., 47, 12, pp. 2874-2891, (2020); pp. 415-427, (2020); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Et al., Graphcodebert: Pre-training code representations with data flow, (2020); Hagberg A., Swart P., S. Chult D., Exploring Network Structure, Dynamics, and Function using NetworkX: Technical Report, (2008); Hu T., Li B., Pan Z., Qian C., Detect defects of solidity smart contract based on the knowledge graph, IEEE Trans. Reliab., (2023); Huang J., Zhou K., Xiong A., Li D., Smart contract vulnerability detection model based on multi-task learning, Sensors, 22, 5, (2022); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, (2016); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, (2015); Liu Z., Qian P., Wang X., Zhu L., He Q., Ji S., Smart contract vulnerability detection: From pure neural network to interpretable graph feature and expert pattern fusion, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI 2021, Virtual Event / Montreal, Canada, 19-27 August 2021, pp. 2751-2759, (2021); Liu Z., Qian P., Wang X., Zhuang Y., Qiu L., Wang X., Combining graph neural networks with expert knowledge for smart contract vulnerability detection, IEEE Trans. Knowl. Data Eng., (2021); pp. 254-269, (2016); Mossberg M., Manzano F., Hennenfent E., Groce A., Grieco G., Feist J., Brunson T., Dinaburg A., Manticore: A user-friendly symbolic execution framework for binaries and smart contracts, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 1186-1189, (2019); pp. 1736-1740, (2022); Rodler M., Li W., Karame G.O., Davi L., Sereum: Protecting existing smart contracts against re-entrancy attacks, (2018); pp. 621-640, (2020); Tai K.S., Socher R., Manning C.D., Improved semantic representations from tree-structured long short-term memory networks, (2015); pp. 9-16, (2018); pp. 67-82, (2018); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); (2019); Wang H., Ye G., Tang Z., Tan S.H., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans. Inf. Forensics Secur., 16, pp. 1943-1958, (2020); Wu H., Zhang Z., Wang S., Lei Y., Lin B., Qin Y., Zhang H., Mao X., Peculiar: Smart contract vulnerability detection based on crucial data flow graph and pre-training techniques, 32nd IEEE International Symposium on Software Reliability Engineering, ISSRE 2021, Wuhan, China, October 25-28, 2021, pp. 378-389, (2021); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, pp. 590-604, (2014); Yu X., Zhao H., Hou B., Ying Z., Wu B., DeeSCVHunter: A deep learning-based framework for smart contract vulnerability detection, International Joint Conference on Neural Networks, IJCNN 2021, Shenzhen, China, July 18-22, 2021, pp. 1-8, (2021); Zhang L., Chen W., Wang W., Jin Z., Zhao C., Cai Z., Chen H., CBGRU: A detection method of smart contract vulnerability based on a hybrid model, Sensors, 22, 9, (2022); Zhang Y., Liu D., Toward vulnerability detection for ethereum smart contracts using graph-matching network, Future Internet, 14, 11, (2022); Zhang L., Wang J., Wang W., Jin Z., Su Y., Chen H., Smart contract vulnerability detection combined with multi-objective detection, Comput. Netw., 217, (2022); Zhang P., Xiao F., Luo X., A framework and dataset for bugs in ethereum smart contracts, 2020 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 139-150, (2020); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Adv. Neural Inf. Process. Syst., 32, (2019); Zhou H., Milani Fard A., Makanju A., The state of ethereum smart contracts security: Vulnerabilities, countermeasures, and tool support, J. Cybersecur. Priv., 2, 2, pp. 358-378, (2022); Zhuang Y., Liu Z., Qian P., Liu Q., Wang X., He Q., Smart contract vulnerability detection using graph neural network, IJCAI, pp. 3283-3290, (2020)",,,,,,English,Article,Final,,Scopus,2-s2.0-85180003952,206
Lin X.; Zhou M.; Cao S.; Wang J.; Sun X.,"Lin, Xingwei (57204721791); Zhou, Mingxuan (58745342900); Cao, Sicong (57222584216); Wang, Jiashui (57250802800); Sun, Xiaobing (24829988300)",57204721791; 58745342900; 57222584216; 57250802800; 24829988300,The Best of Both Worlds: Integrating Semantic Features with Expert Features for Smart Contract Vulnerability Detection,2024,Communications in Computer and Information Science,1897 CCIS,,,17,31,14,1,10.1007/978-981-99-8104-5_2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178561279&doi=10.1007%2f978-981-99-8104-5_2&partnerID=40&md5=f8a3114024c599eb4600438405b97f26,"Over the past few years, smart contract suffers from serious security threats of vulnerabilities, resulting in enormous economic losses. What’s worse, due to the immutable and irreversible features, vulnerable smart contracts which have been deployed in the the blockchain can only be detected rather than fixed. Conventional approaches heavily rely on hand-crafted vulnerability rules, which is time-consuming and difficult to cover all the cases. Recent deep learning approaches alleviate this issue but fail to explore the integration of them together to boost the smart contract vulnerability detection yet. Therefore, we propose to build a novel model, SmartFuSE, for the smart contract vulnerability detection by leveraging the best of semantic features and expert features. SmartFuSE performs static analysis to respectively extract vulnerability-specific expert patterns and joint graph structures at the function-level to frame the rich program semantics of vulnerable code, and leverages a novel graph neural network with the hybrid attention pooling layer to focus on critical vulnerability features. To evaluate the effectiveness of our proposed SmartFuSE, we conducted extensive experiments on 40k contracts in two benchmarks. The experimental results demonstrate that SmartFuSE can significantly outperform state-of-the-art analysis-based and DL-based detectors. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, Proceedings of the 6Th International Conference on Learning Representations (ICLR, (2018); Bhargavan K., Et al., Formal verification of smart contracts: Short paper, Proceedings of the 2016 ACM Workshop on Programming Languages and Analysis for Security, PLAS@CCS 2016, Vienna, Austria, October 24, 2016, Pp. 91–96. ACM, (2016); Cai J., Li B., Zhang J., Sun X., Chen B., Combine sliced joint graph with graph neural networks for smart contract vulnerability detection, J. Syst. Softw., 195, (2023); Cao S., Sun X., Bo L., Wei Y., Li B., BGNN4VD: Constructing bidirectional graph neural-network for vulnerability detection, Inf. Softw. Technol., 136, (2021); Cao S., Sun X., Bo L., Wu R., Li B., Tao C., MVD: Memory-related vulnerability detection based on flow-sensitive graph neural networks, Proceedings of the 44Th IEEE/ACM International Conference on Software Engineering (ICSE), pp. 1456-1468, (2022); Falkon S., The Story of the Dao-Its History and Consequences, (2017); Feist J., Grieco G., Groce A., Slither: A static analysis framework for smart contracts, Proceedings of the 2Nd International Workshop on Emerging Trends in Software Engineering for Blockchain (WETSEB@ICSE), Pp. 8–15. IEEE / ACM, (2019); Gao Z., Jiang L., Xia X., Lo D., Grundy J., Checking smart contracts with structural code embedding, IEEE Trans. Software Eng., 47, 12, pp. 2874-2891, (2021); Hang L., Kim D., Reliable task management based on a smart contract for runtime verification of sensing and actuating tasks in IoT environments, Sensors, 20, 4, (2020); Hirai Y., Defining the ethereum virtual machine for interactive theorem provers, FC 2017. LNCS, Vol. 10323, pp. 520-535, (2017); Jiang B., Liu Y., Chan W.K., Contractfuzzer: Fuzzing smart contracts for vulnerability detection, Proceedings of the 33Rd ACM/IEEE International Conference on Automated Software Engineering (ASE), pp. 259-269, (2018); Kalra S., Goel S., Dhawan M., Sharma S., ZEUS: Analyzing safety of smart contracts, Proceedings of the 25Th Annual Network and Distributed System Security Symposium (NDSS). the Internet Society, (2018); Kingma D.P., Ba J., Adam: A method for stochastic optimization, Proceedings of the 3Rd International Conference on Learning Representations (ICLR, (2015); Lee J., Lee I., Kang J., Self-attention graph pooling, Proceedings of the 36Th International Conference on Machine Learning (ICML), 97, pp. 3734-3743, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, Proceedings of the 4Th International Conference on Learning Representations (ICLR, (2016); Liu Z., Qian P., Wang X., Zhuang Y., Qiu L., Wang X., Combining Graph Neural Networks with Expert Knowledge for Smart Contract Vulnerability Detection. Arxiv Preprint Arxiv, 2107, (2021); Liu Z., Qian P., Wang X., Zhuang Y., Qiu L., Wang X., Combining graph neural networks with expert knowledge for smart contract vulnerability detection, IEEE Trans. Knowl. Data Eng., 35, 2, pp. 1296-1310, (2023); Luu L., Chu D., Olickel H., Saxena P., Hobor A., Making smart contracts smarter, Proceedings of the 23Rd ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 254-269, (2016); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Proceedings of the 27Th Annual Conference on Neural Information Processing Systems (Neurips), pp. 3111-3119, (2013); Mueller B., A Framework for Bug Hunting on the Ethereum Blockchain, (2017); Nakamoto S., Bitcoin: A Peer-To-Peer Electronic Cash System, (2008); Park J., Youn T., Kim H., Rhee K., Shin S., Smart contract-based review system for an IoT data marketplace, Sensors, 18, 10, (2018); Pierro G.A., Tonelli R., Marchesi M., An organized repository of ethereum smart contracts’ source codes and metrics, Future Internet, 12, 11, (2020); Qian P., Liu Z., He Q., Zimmermann R., Wang X., Towards automated reentrancy detection for smart contracts based on sequential models, IEEE Access, 8, pp. 19685-19695, (2020); Tann W.J., Han X.J., Gupta S.S., Ong Y., Towards Safer Smart Contracts: A Sequence Learning Approach to Detecting Vulnerabilities. Arxiv Preprint Arxiv, 1811, (2018); Tikhomirov S., Voskresenskaya E., Ivanitskiy I., Takhaviev R., Marchenko E., Alexandrov Y., Smartcheck: Static analysis of ethereum smart contracts, Proceedings of the 1St IEEE/ACM International Workshop on Emerging Trends in Software Engineering for Blockchain (WETSEB@ICSE), pp. 9-16, (2018); Tsankov P., Dan A.M., Drachsler-Cohen D., Gervais A., Bunzli F., Vechev M.T., Securify: Practical security analysis of smart contracts, Proceedings of the 25Th ACM SIGSAC Conference on Computer and Communications Security (CCS), pp. 67-82, (2018); Wang M., Et al., Deep Graph Library: A Graph-Centric, Highly-Performant Package for Graph Neural Networks. Arxiv Preprint Arxiv, 1909, (2019); Wei Y., Sun X., Bo L., Cao S., Xia X., Li B., A comprehensive study on security bug characteristics, J. Softw. Evol. Process., 33, 10, (2021); Weiser M., Program slicing, IEEE Trans. Softw. Eng., 10, 4, pp. 352-357, (1984); Wood G., Ethereum: A Secure Decentralised Generalised Transaction Ledger, (2014); Wu H., Et al., Peculiar: Smart contract vulnerability detection based on crucial data flow graph and pre-training techniques, Proceedings of the 32Nd IEEE International Symposium on Software Reliability Engineering (ISSRE), pp. 378-389, (2021); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A comprehensive survey on graph neural networks, IEEE Trans. Neural Netw. Learn. Syst., 32, 1, pp. 4-24, (2021); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, Proceedings of the 35Th IEEE Symposium on Security and Privacy (SP), pp. 590-604, (2014); Zhang Y., Kasahara S., Shen Y., Jiang X., Wan J., Smart contract-based access control for the internet of things, IEEE Internet Things J, 6, 2, pp. 1594-1605, (2019); Zhou Y., Liu S., Siow J.K., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Proceedings of the 33Rd Annual Conference on Neural Information Processing Systems (Neurips), pp. 10197-10207, (2019); Zhuang Y., Liu Z., Qian P., Liu Q., Wang X., He Q., Smart contract vulnerability detection using graph neural network, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence (IJCAI), pp. 3283-3290, (2020)",,"5th International Conference on Blockchain and Trustworthy Systems, BlockSys 2023",8 August 2023 through 10 August 2023,Haikou,304759,English,Conference paper,Final,,Scopus,2-s2.0-85178561279,207
Jin S.; Zhai Y.; Zhong Y.; Cui J.; Xu L.; Sun H.; Lei Y.,"Jin, Shifeng (58744689400); Zhai, Yijun (58745522700); Zhong, Yuxuan (58745733200); Cui, Jifu (58744896800); Xu, Lei (58150775100); Sun, Hongxia (58744689500); Lei, Yan (55541448200)",58744689400; 58745522700; 58745733200; 58744896800; 58150775100; 58744689500; 55541448200,Securing Blockchain Using Propagation Chain Learning,2024,Communications in Computer and Information Science,1896 CCIS,,,107,118,11,0,10.1007/978-981-99-8101-4_8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178555785&doi=10.1007%2f978-981-99-8101-4_8&partnerID=40&md5=d10b162261ba84eb31e50767ce0658e7,"Smart contract vulnerabilities are the most common and severe type of blockchain vulnerability, which may result in very serious economic and property losses. Vulnerability detection and repair are necessary to ensure the security of the blockchain. Currently, the-state-of-art smart contract vulnerability detection methods (e.g. Oyente and Securify) use heuristics based on human-designed algorithms, which have certain shortcomings in different application scenarios. Therefore, this paper proposes a smart contract vulnerability detection method, i.e. CuVuD, which uses Propagation Chain Learning to solve the current vulnerability detection problem. This method first parses the source code, then obtains and trims the propagation chain of smart contracts, and finally detects vulnerabilities in smart contracts. To verify the effectiveness of CuVuD, this paper compares the CuVuD method with seven the-state-of-art smart contract vulnerability detection methods on a large-scale smart contract dataset based on the Solidity language. The experimental results show that CuVuD’s effectiveness in detecting smart contract vulnerabilities is significantly higher than seven the-state-of-art smart contract vulnerability detection methods, significantly improving the ability to detect vulnerabilities. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Buterin V., A Next Generation Smart Contract & Decentralized Application Platform, (2015); Feist J., Grieco G., Groce A., Slither: A static analysis framework for smart contracts, IEEE/ACM 2Nd International Workshop on Emerging Trends in Software Engineering for Blockchain (WETSEB), pp. 8-15, (2019); Ferreira J.F., Cruz P., Durieux T., Abreu R., Smartbugs: A framework to analyze solidity smart contracts, 35Th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 1349-1352, (2020); Gao Z., Jayasundara V., Jiang L., Xia X., Lo D., Grundy J.C., Smartembed: A tool for clone and bug detection in smart contracts through structural code embedding, IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 394-397, (2019); Guo A., Mao X., Yang D., Wang S., An empirical study on the effect of dynamic slicing on automated program repair efficiency, 2018 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 554-558, (2018); Guo D., Et al., Graphcodebert: Pre-training code representations with data flow, Arxiv Abs/2009, (2020); Huang T.H.D., Hunting the ethereum smart contract: Color-inspired inspection of potential attacks, Arxiv Abs/1807, (2018); Jiang B., Liu Y., Chan W.K., Contractfuzzer: Fuzzing smart contracts for vulnerability detection, 2018 33Rd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 259-269, (2018); Kalra S., Goel S., Dhawan M., Sharma S., Zeus: Analyzing safety of smart contracts, Network and Distributed System Security Symposium, (2018); Liu H., Liu C., Zhao W., Jiang Y., Sun J., S-gram: Towards semantic-aware security auditing for Ethereum smart contracts, 2018 33Rd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 814-819, (2018); Liu Z., Qian P., Wang X., Zhuang Y., Qiu L., Wang X., Combining graph neural networks with expert knowledge for smart contract vulnerability detection, IEEE Trans. Knowl. Data Eng., 35, pp. 1296-1310, (2021); Luu L., Chu D.H., Olickel H., Saxena P., Hobor A., Making smart contracts smarter, Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, (2016); Mossberg M., Et al., Manticore: A user-friendly symbolic execution framework for binaries and smart contracts, 34Th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 1186-1189, (2019); Mueller B., Mythril-Reversing and Bug Hunting Framework for the Ethereum Blockchain, (2017); Nakamoto S., Bitcoin: A Peer-To-Peer Electronic Cash System, (2008); Pradel M., Sen K., Deepbugs: A learning approach to name-based bug detection, Proc. ACM Program. Lang., 2, pp. 1-25, (2018); Szabo N., Smart Contracts: Building Blocks for Digital Markets, (2018); Tann W.J.W., Han X.J., Gupta S.S., Ong Y., Towards safer smart contracts: A sequence learning approach to detecting security threats, Arxiv: Cryptographyandsecurity, (2018); Tikhomirov S., Voskresenskaya E., Ivanitskiy I., Takhaviev R., Marchenko E., Alexandrov Y., Smartcheck: Static analysis of ethereum smart contracts, 2018 IEEE/ACM 1St International Workshop on Emerging Trends in Software Engineering for Blockchain (WETSEB), pp. 9-16, (2018); Torres C.F., Schutte J., State R., Osiris: Hunting for integer bugs in ethereum smart contracts, Proceedings of the 34Th Annual Computer Security Applications Conference, (2018); Tsankov P., Dan A.M., Drachsler-Cohen D., Gervais A., Buenzli F., Vechev M.T., Securify: Practical security analysis of smart contracts, Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, (2018); Vaswani A., Et al., Attention is all you need, Arxiv Abs/1706, (2017); Yang X., Chen Y., Chen X., Effective scheme against 51% attack on proof-of-work blockchain with history weighted information, IEEE International Conference on Blockchain (Blockchain), pp. 261-265, (2019); Zhang Z., Lei Y., Mao X., Li P., CNN-FL: An effective approach for localizing faults using convolutional neural networks, IEEE 26Th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 445-455, (2019); Zhang Z., Lei Y., Mao X., Yan M., Xu L., Zhang X., A study of effectiveness of deep learning in locating real faults, Inf. Softw. Technol., 131, (2021); Zhou E., Et al., Security assurance for smart contract, 9Th IFIP International Conference on New Technologies, Mobility and Security (NTMS), pp. 1-5, (2018); Zhuang Y., Liu Z., Qian P., Liu Q., Wang X., He Q., Smart contract vulnerability detection using graph neural network, International Joint Conference on Artificial Intelligence, (2020)",,"5th International Conference on Blockchain and Trustworthy Systems, BlockSys 2023",8 August 2023 through 10 August 2023,Haikou,304759,English,Conference paper,Final,,Scopus,2-s2.0-85178555785,208
Zou L.; Gong C.; Wu Z.; Tan J.; Tang J.; Jiang Z.; Li D.,"Zou, Lihan (58744956600); Gong, Changhao (58745164000); Wu, Zhen (58657674900); Tan, Jie (58830487200); Tang, Junnan (58745784800); Jiang, Zigui (57191406269); Li, Dan (57188875664)",58744956600; 58745164000; 58657674900; 58830487200; 58745784800; 57191406269; 57188875664,A General Smart Contract Vulnerability Detection Framework with Self-attention Graph Pooling,2024,Communications in Computer and Information Science,1897 CCIS,,,3,16,13,1,10.1007/978-981-99-8104-5_1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178549654&doi=10.1007%2f978-981-99-8104-5_1&partnerID=40&md5=8591d0a411982e39de09c9421fa30b06,"In recent years, the increasing development of Web 3.0 has generated growing attention toward blockchain and smart contracts. However, due to their immutability, smart contracts still exhibit various vulnerabilities that hackers can exploit, resulting in significant losses. Numerous smart contracts on various blockchains, including Ethereum, have been attacked due to various vulnerabilities. The inefficiency of detecting these vulnerabilities has become a major bottleneck in advancing blockchain and smart contracts. Although detecting smart contract vulnerabilities has attracted much attention, most existing machine learning-based methods rely on adequate expert knowledge and target only specific known vulnerabilities via binary classification models. To address this limitation, our proposed approach introduced a general vulnerability detection method that can be applied to identify various common vulnerabilities via a uniform framework. We leveraged the Abstract Syntax Trees (AST) and self-attention-based graph pooling models to generate topological graphs from smart contract code analysis. We adopted Graph Neural Networks for vulnerability detection. Experimental results demonstrated that the proposed approach exhibited satisfactory performance in detecting multiple and unseen vulnerabilities compared to traditional methods. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Sankar L.S., Sindhu M., Sethumadhavan M., Survey of consensus protocols on blockchain applications, Proceedings of the ICACCS, pp. 1-5, (2017); Zhang P., Schmidt D.C., White J., Et al., Blockchain technology use cases in healthcare, Advances in Computers, Vol. 111, Pp. 1–41. Elsevier, (2018); Qian P., Liu Z., Wang X., Et al., Digital resource rights confirmation and infringement tracking based on smart contracts, 2019 IEEE 6Th International Conference on Cloud Computing and Intelligence Systems (CCIS), pp. 62-67, (2019); Saberi S., Kouhizadeh M., Sarkis J., Et al., Blockchain technology and its relationships to sustainable supply chain management, Int. J. Prod. Res., 57, 7, pp. 2117-2135, (2019); Tang X., Gan J., Jiang Z., A graph neural network-based code recommendation method for smart contract development, International Conference on Service Science (ICSS), Zhuhai, China, pp. 248-254, (2022); Sayeed S., Marco-Gisbert H., Caira T., Smart contract: Attacks and protections, IEEE Access, 8, pp. 24416-24427, (2020); Luu L., Chu D.H., Olickel H., Et al., Making smart contracts smarter, Proceedings of the ACM SIGSAC Conference on Computer and Communications Security, 2016, pp. 254-269, (2016); Qian P., Liu Z., He Q., Et al., Towards automated reentrancy detection for smart contracts based on sequential models, IEEE Access, 8, pp. 19685-19695, (2020); Zhuang Y., Liu Z., Qian P., Et al., Smart Contract Vulnerability Detection Using Graph Neural Network, pp. 3283-3290, (2020); Liu Z., Qian P., Wang X., Et al., Combining graph neural networks with expert knowledge for smart contract vulnerability detection, IEEE Trans. Knowl. Data Eng., 35, pp. 1296-1310, (2021); Bhargavan K., Delignat-Lavaud A., Fournet C., Et al., Formal verification of smart contracts: Short paper, Proceedings of The. ACM Workshop on Programming Languages and Analysis for Security, 2016, pp. 91-96, (2016); Hildenbrandt E., Saxena M., Rodrigues N., Et al., Kevm: A complete formal semantics of the ethereum virtual machine, 2018 IEEE 31St Computer Security Foundations Symposium (CSF), pp. 204-217, (2018); Zhang M., Cui Z., Neumann M., Et al., An end-to-end deep learning architecture for graph classification, Proceedings of the AAAI Conference on Artificial Intelligence, 32, 1, (2018); Errica F., Podda M., Bacciu D., Et al., A Fair Comparison of Graph Neural Networks for Graph Classification. Arxiv Preprint Arxiv, 1912, (2019); Zhou Y., Liu S., Siow J., Et al., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Adv. Neural Inf. Process. Syst., 32, (2019); Allamanis M., Brockschmidt M., Khademi M., Learning to Represent Programs with Graphs. Arxiv Preprint Arxiv, 1711, (2017); Lee J., Lee I., Kang J., Self-attention graph pooling, International Conference on Machine Learning, pp. 3734-3743, (2019); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks. Arxiv Preprint Arxiv, 1609, (2016); Gao H., Ji S., Graph u-net, Proceedings of the 36Th International Conference on Machine Learning (ICML), (2019); Cangea C., Velickovic P., Jovanovic N., Kipf T., Lió, ‘P.: Towards Sparse Hierarchical Graph Classifiers. Arxiv Preprint Arxiv, 1811, (2018); Durieux T., Ferreira J.F., Abreu R., Et al., Empirical review of automated analysis tools on 47,587 ethereum smart contracts, Proceedings of the ACM/IEEE 42Nd International Conference on Software Engineering, pp. 530-541, (2020); Luu L., Chu D.-H., Olickel H., Saxena P., Hobor A., Making smart contracts smarter, Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 254-269, (2016); Mueller B., Smashing ethereum smart contracts for fun and real profit, 9Th Annual HITB Security Conference (Hitbsecconf ), 54, (2018); Tikhomirov S., Voskresenskaya E., Ivanitskiy I., Takhaviev R., Marchenko E., Alexandrov Y., Smartcheck: Static analysis of ethereum smart contracts, WET-SEB, pp. 9-16, (2018); Tsankov P., Dan A., Drachsler-Cohen D., Gervais A., Buenzli F., Vechev M., Securify: Practical security analysis of smart contracts, Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, Ser. CCS 2018. New York, NY, USA, Pp. 67–82 Association for Computing Machinery, (2018); Feist J., Grieco G., Groce A., Slither: A static analysis framework for smart contracts, WETSEB, pp. 8-15, (2019); Goller C., Kuchler A., Learning task-dependent distributed representations by backpropagation through structure, Proceedings of ICNN, 1, pp. 347-352, (1996); Sak H., Senior A., Beaufays F., Long short-term memory recurrent neural network architectures for large scale acoustic modeling, Fifteenth Annual Conference of the International Speech Communication Association, (2014); Chung J., Gulcehre C., Cho, K., Bengio, Y, Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling, Arxiv Preprint Arxiv, 1412, (2014); Zhuang Y., Liu Z., Qian P., Liu Q., Wang X., He Q., Smart contract vulnerability detection using graph neural network, Proceedings of the IJCAI-20, 7, pp. 3283-3290, (2020); Hamilton W., Ying Z., Leskovec J., Inductive representation learning on large graphs, Adv. Neural Inf. Process. Syst., 30, (2017)",,"5th International Conference on Blockchain and Trustworthy Systems, BlockSys 2023",8 August 2023 through 10 August 2023,Haikou,304759,English,Conference paper,Final,,Scopus,2-s2.0-85178549654,209
Gong P.; Yang W.; Wang L.; Wei F.; HaiLaTi K.; Liao Y.,"Gong, Peng (58635496400); Yang, Wenzhong (55501058300); Wang, Liejun (16833826600); Wei, Fuyuan (57225888100); HaiLaTi, KeZiErBieKe (58634109900); Liao, Yuanyuan (55320220700)",58635496400; 55501058300; 16833826600; 57225888100; 58634109900; 55320220700,GRATDet: Smart Contract Vulnerability Detector Based on Graph Representation and Transformer,2023,"Computers, Materials and Continua",76,2,,1439,1462,23,0,10.32604/cmc.2023.038878,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173516910&doi=10.32604%2fcmc.2023.038878&partnerID=40&md5=37853fef490b5fe9dc00287a0e0e8bf6,"Smart contracts have led to more efficient development in finance and healthcare, but vulnerabilities in contracts pose high risks to their future applications. The current vulnerability detection methods for contracts are either based on fixed expert rules, which are inefficient, or rely on simplistic deep learning techniques that do not fully leverage contract semantic information. Therefore, there is ample room for improvement in terms of detection precision. To solve these problems, this paper proposes a vulnerability detector based on deep learning techniques, graph representation, and Transformer, called GRATDet. The method first performs swapping, insertion, and symbolization operations for contract functions, increasing the amount of small sample data. Each line of code is then treated as a basic semantic element, and information such as control and data relationships is extracted to construct a new representation in the form of a Line Graph (LG), which shows more structural features that differ from the serialized presentation of the contract. Finally, the node information and edge information of the graph are jointly learned using an improved Transformer–GP model to extract information globally and locally, and the fused features are used for vulnerability detection. The effectiveness of the method in reentrancy vulnerability detection is verified in experiments, where the F1 score reaches 95.16%, exceeding state-of-the-art methods. © 2023 Tech Science Press. All rights reserved.","Nakamoto S., Bitcoin: A peer-to-peer electronic cash system, (2008); Wood G., Ethereum: A secure decentralised generalised transaction ledger, (2013); Buterin V., A next-generation smart contract and decentralized application platform, (2014); Mehar M. I., Shier C. L., Giambattista A., Gong E., Fletcher G., Et al., Understanding a revolutionary and f lawed grand experiment in blockchain: The DAO attack, Journal of Cases on Information Technology, 21, 1, pp. 19-32, (2019); Lin G., Wen S., Han Q. L., Zhang J., Xiang Y., Software vulnerability detection using deep neural networks: A survey, Proceedings of the IEEE, 108, 10, pp. 1825-1848, (2020); Huang T. H. D., Hunting the ethereum smart contract: Color-inspired inspection of potential attacks, (2018); Qian P., Liu Z., He Q., Zimmermann R., Wang X., Towards automated reentrancy detection for smart contracts based on sequential models, IEEE Access, 8, pp. 19685-19695, (2020); Yu X., Zhao H., Hou B., Ying Z., Wu B., DeeSCVHunter: A deep learning-based framework for smart contract vulnerability detection, 2021 Int. Joint Conf. on Neural Networks (IJCNN), pp. 1-8, (2021); Zhuang Y., Liu Z., Qian P., Liu Q., Wang X., Et al., Smart contract vulnerability detection using graph neural network, Int. Joint Conf. on Artificial Intelligence(IJCAI), pp. 3283-3290, (2020); Liu Z., Qian P., Wang X., Zhu L., He Q., Et al., Smart contract vulnerability detection: From pure neural network to interpretable graph feature and expert pattern fusion, (2021); Liu Z., Qian P., Wang X., Zhuang Y., Qiu L., Et al., Combining graph neural networks with expert knowledge for smart contract vulnerability detection, IEEE Transactions on Knowledge and Data Engineering, 3, (2021); Mueller B., Mythril—Reversing and Bug Hunting Framework for the Ethereum Blockchain, (2017); Luu L., Chu D. H., Olickel H., Saxena P., Hobor A., Making smart contracts smarter, Proc. of the 2016 ACM SIGSAC Conf. on Computer and Communications Security, pp. 254-269, (2016); Tikhomirov S., Voskresenskaya E., Ivanitskiy I., Takhaviev R., Marchenko E., Et al., Smartcheck: Static analysis of ethereum smart contracts, Proc. of the 1st Int. Workshop on Emerging Trends in Software Engineering for Blockchain, pp. 9-16, (2018); Tsankov P., Dan A., Drachsler-Cohen D., Gervais A., Buenzli F., Et al., Securify: Practical security analysis of smart contracts, Proc. of the 2018 ACM SIGSAC Conf. on Computer and Communications Security, pp. 67-82, (2018); Feist J., Grieco G., Groce A., Slither: A static analysis framework for smart contracts, 2019 IEEE/ACM 2nd Int. Workshop on Emerging Trends in Software Engineering for Blockchain (WETSEB), pp. 8-15, (2019); Mossberg M., Manzano F., Hennenfent E., Groce A., Grieco G., Et al., Manticore: A user-friendly symbolic execution framework for binaries and smart contracts, 2019 34th IEEE/ACM Int. Conf. on Automated Software Engineering (ASE), pp. 1186-1189, (2019); Li Z., Zou D., Xu S., Ou X., Jin H., Et al., Vuldeepecker: A deep learning-based system for vulnerability detection, Proc. of the 25th Annual Network and Distributed System Security Symp. (NDSS), (2018); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Et al., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE Int. Conf. on Machine Learning and Applications (ICMLA), pp. 757-762, (2018); Ziems N., Wu S., Security vulnerability detection using deep learning natural language processing, IEEE INFOCOM 2021-IEEE Conf. on Computer Communications Workshops (INFOCOM WKSHPS), pp. 1-6, (2021); Lin G., Zhang J., Luo W., Pan L., Xiang Y., Et al., Cross-project transfer representation learning for vulnerable function discovery, IEEE Transactions on Industrial Informatics, 14, 7, pp. 3289-3297, (2018); Bilgin Z., Ersoy M. A., Soykan E. U., Tomur E., Comak P., Et al., Vulnerability prediction from source code using machine learning, IEEE Access, 8, pp. 150672-150684, (2020); Wu H., Zhang Z., Wang S., Lei Y., Lin B., Et al., Peculiar: Smart contract vulnerability detection based on crucial data f low graph and pre-training techniques, 2021 IEEE 32nd Int. Symp. on Software Reliability Engineering (ISSRE), pp. 378-389, (2021); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, 32, pp. 10197-10207, (2019); Wang H., Ye G., Tang Z., Tan S. H., Huang S., Et al., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Transactions on Information Forensics and Security, 16, pp. 1943-1958, (2020); Zhang L., Chen W., Wang W., Jin Z., Zhao C., Et al., Cbgru: A detection method of smart contract vulnerability based on a hybrid model, Sensors, 22, 9, (2022); Wu H., Dong H., He Y., Duan Q., Smart contract vulnerability detection based on hybrid attention mechanism model, Applied Sciences, 13, 2, (2023); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Et al., Attention is all you need, Advances in Neural Information Processing Systems, 30, pp. 5998-6008, (2017); Liu Z., Lin Y., Cao Y., Hu H., Wei Y., Et al., Swin transformer: Hierarchical vision transformer using shifted windows, Proc. of the IEEE/CVF Int. Conf. on Computer Vision, pp. 10012-10022, (2021); Gad W., Alokla A., Nazih W., Aref M., Salem A., DLBT: Deep learning-based transformer to generate Pseudo-Code from source code, Computers, Materials & Continua, 70, 2, pp. 3117-3132, (2022); Cheng X., Wang H., Hua J., Xu G., Sui Y., Deepwukong: Statically detecting software vulnerabilities using deep graph neural network, ACM Transactions on Software Engineering and Methodology (TOSEM), 30, 3, pp. 1-33, (2021); Wei J., Zou K., Eda: Easy data augmentation techniques for boosting performance on text classification tasks, Proc. of the 2019 Conf. on Empirical Methods in Natural Language Processing and the 9th Int. Joint Conf. on Natural Language Processing (EMNLP-IJCNLP), pp. 6382-6388, (2019); tree-sitter-solidity; Hellendoorn V. J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, Int. Conf.on Learning Representations, (2019); Shaw P., Uszkoreit J., Vaswani A., Self-attention with relative position representations, Proc. of the 2018 Conf. of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2, pp. 464-468, (2018); Le Q., Mikolov T., Distributed representations of sentences and documents, Int. Conf. on Machine Learning, pp. 1188-1196, (2014); Schlag I., Smolensky P., Fernandez R., Jojic N., Schmidhuber J., Et al., Enhancing the transformer with explicit relational encoding for math problem solving, (2019); Ferreira J. F., Cruz P., Durieux T., Abreu R., Smartbugs: A framework to analyze solidity smart contracts, Proc. of the 35th IEEE/ACM Int. Conf. on Automated Software Engineering, pp. 1349-1352, (2020); Wang W., Tu Z., Rethinking the value of transformer components, Proc. of the 28th Int. Conf. on Computational Linguistics, pp. 6019-6029, (2020)",,,,,,English,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85173516910,210
Liu Z.; Qian P.; Wang X.; Zhuang Y.; Qiu L.; Wang X.,"Liu, Zhenguang (56177043100); Qian, Peng (57217637690); Wang, Xiaoyang (56286360800); Zhuang, Yuan (57220550287); Qiu, Lin (57200583058); Wang, Xun (35171979500)",56177043100; 57217637690; 56286360800; 57220550287; 57200583058; 35171979500,Combining Graph Neural Networks with Expert Knowledge for Smart Contract Vulnerability Detection,2023,IEEE Transactions on Knowledge and Data Engineering,35,2,,1296,1310,14,84,10.1109/TKDE.2021.3095196,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109397423&doi=10.1109%2fTKDE.2021.3095196&partnerID=40&md5=7bd04392f0c0af5571c7a03762d62919,"Smart contract vulnerability detection draws extensive attention in recent years due to the substantial losses caused by hacker attacks. Existing efforts for contract security analysis heavily rely on rigid rules defined by experts, which are labor-intensive and non-scalable. More importantly, expert-defined rules tend to be error-prone and suffer the inherent risk of being cheated by crafty attackers. Recent researches focus on the symbolic execution and formal analysis of smart contracts for vulnerability detection, yet to achieve a precise and scalable solution. Although several methods have been proposed to detect vulnerabilities in smart contracts, there is still a lack of effort that considers combining expert-defined security patterns with deep neural networks. In this paper, we explore using graph neural networks and expert knowledge for smart contract vulnerability detection. Specifically, we cast the rich control- and data- flow semantics of the source code into a contract graph. To highlight the critical nodes in the graph, we further design a node elimination phase to normalize the graph. Then, we propose a novel temporal message propagation network to extract the graph feature from the normalized graph, and combine the graph feature with designed expert patterns to yield a final detection system. Extensive experiments are conducted on all the smart contracts that have source code in Ethereum and VNT Chain platforms. Empirical results show significant accuracy improvements over the state-of-the-art methods on three types of vulnerabilities, where the detection accuracy of our method reaches 89.15, 89.02, and 83.21 percent for reentrancy, timestamp dependence, and infinite loop vulnerabilities, respectively. © 1989-2012 IEEE.","Dinh T.T.A., Wang J., Chen G., Liu R., Ooi B.C., Tan K.-L., BLOCKBENCH: A framework for analyzing private blockchains, Proc ACM Int. Conf. Manage. Data, pp. 1085-1100, (2017); Yaga D., Mell P., Roby N., Scarfone K., Blockchain technology overview, ArXiv 1906 11078, (2019); Badertscher C., Maurer U., Tschudi D., Zikas V., Bitcoin as a transaction ledger: A composable treatment, Proc. Annu. Int. Cryptol. Conf, pp. 324-356, (2017); Dhawan M., Analyzing safety of smart contracts, Proc. Netw. Distrib. Syst. Secur. Symp, pp. 16-17, (2017); Tsikhanovich M., Magdon-Ismail M., Ishaq M., Zikas V., PD-ML-Lite: Private distributed machine learning from lighweight cryptography, ArXiv 1901 07986, pp. 1-28, (2019); Dinh T.T.A., Liu R., Zhang M., Chen G., Ooi B.C., Wang J., Untangling blockchain: A data processing view of blockchain systems, IEEE Trans. Knowl. Data Eng, 30, 7, pp. 1366-1385, (2018); Sankar L.S., Sindhu M., Sethumadhavan M., Survey of consensus protocols on blockchain applications, Proc. 4th Int. Conf. Adv. Comput. Commun. Syst, pp. 1-5, (2017); Luu L., Chu D.-H., Olickel H., Saxena P., Hobor A., Making smart contracts smarter, Proc ACM SIGSAC Conf. Comput. Commun. Secur, pp. 254-269, (2016); Antonopoulos A.M., Wood G., Ethereum M., Building Smart Contracts and Dapps. Sebastopol, CA, USA, (2018); Bahga A., Madisetti V.K., Blockchain platform for industrial internet of things, J. Softw. Eng. Appl, 9, 10, (2016); Buterin V., Et al., A next-generation smart contract and decentralized application platform, White Paper, 3, (2014); Kokina J., Mancha R., Pachamanova D., Blockchain: Emergent industry adoption and implications for accounting, J. Emerg. Technol. Accounting, 14, 2, pp. 91-100, (2017); The DAOsmart Contract, Website, (2016); King of the Ether, Webiste, (2016); An In-depth Look at the Parity Multisig Bug, Website, (2017); Tikhomirov S., Voskresenskaya E., Ivanitskiy I., Takhaviev R., Marchenko E., Alexandrov Y., SmartCheck: Static analysis of ethereum smart contracts, Proc IEEE/ACM 1st Int. Workshop Emerg. Trends Softw. Eng. Blockchain, pp. 9-16, (2018); Jiang B., Liu Y., Chan W., ContractFuzzer: Fuzzing smart contracts for vulnerability detection, Proc. 33rd ACM/ IEEE Int. Conf. Automated Softw. Eng, pp. 259-269, (2018); Tsankov P., Dan A., Drachsler-Cohen D., Gervais A., Buenzli F., Vechev M., Securify: Practical security analysis of smart contracts, Proc ACM SIGSAC Conf. Comput. Commun. Secur, pp. 67-82, (2018); Qian P., Liu Z., He Q., Zimmermann R., Wang X., Towards automated reentrancy detection for smart contracts based on sequential models, IEEE Access, 8, pp. 19685-19695, (2020); Zhuang Y., Liu Z., Qian P., Liu Q., Wang X., He Q., Smart contract vulnerability detection using graph neural network, Proc. Int. Joint Conf. Artif. Intell, pp. 3283-3290, (2020); Tann W.J., Han X.J., Gupta S.S., Ong Y., Towards safer smart contracts: A sequence learning approach to detecting vulnerabilities, ArXiv 1811 06632, pp. 1-12, (2018); Bhargavan K., Et al., Formal verification of smart contracts: Short paper, Proc ACM Workshop Program. Lang. Anal. Secur, pp. 91-96, (2016); Grishchenko I., Maffei M., Schneidewind C., A semantic framework for the security analysis of Ethereum smart contracts, Proc. Int. Conf. Princ. Secur. Trust, pp. 243-269, (2018); Hildenbrandt E., Et al., KEVM: A complete formal semantics of the Ethereum virtual machine, Proc IEEE 31st Comput. Secur. Found. Symp, pp. 204-217, (2018); Hirai Y., Defining the Ethereum virtual machine for interactive theorem provers, Proc. Int. Conf. Financial Cryptogr. Data Secur, pp. 520-535, (2017); Nikolic I., Kolluri A., Sergey I., Saxena P., Hobor A., Finding the greedy, prodigal, and suicidal contracts at scale, Proc. Annu. Comput. Secur. Appl. Conf, pp. 653-663, (2018); Kalra S., Goel S., Dhawan M., Sharma S., Zeus: Analyzing safety of smart contracts, Proc. Netw. Distrib. Syst. Secur. Symp, pp. 1-15, (2018); Liu C., Liu H., Cao Z., Chen Z., Chen B., Roscoe B., ReGuard: Finding reentrancy bugs in smart contracts, Proc IEEE/ACM 40th Int. Conf. Softw. Eng. Companion, pp. 65-68, (2018); Rodler M., Li W., Karame G.O., Davi L., Sereum: Protecting existing smart contracts against re-entrancy attacks, Proc. Netw. Distrib. Syst. Secur. Symp, pp. 1-15, (2019); Wang W., Song J., Xu G., Li Y., Wang H., Su C., ContractWard: Automated vulnerability detection models for Ethereum smart contracts, IEEE Trans. Netw. Sci. Eng., Early Access, 8, 2, pp. 1133-1144, (2020); Atzei N., Bartoletti M., Cimoli T., A survey of attacks on Ethereum smart contracts (SoK), Proc. Int. Conf. Princ. Secur. Trust, pp. 164-186, (2017); Zhang M., Cui Z., Neumann M., Chen Y., An end-To-end deep learning architecture for graph classification, Proc. 32nd AAAI Conf. Artif. Intell, pp. 4438-4445, (2018); Wang H., Et al., Incremental subgraph feature selection for graph classification, IEEE Trans. Knowl. Data Eng, 29, 1, pp. 128-142, (2017); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Proc. Int. Conf. Neural Inf. Process. Syst, pp. 10197-10207, (2019); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, Proc. Int. Conf. Learn. Representations, pp. 1-16, (2018); Cai H., Zheng V.W., Chang K.C.-C., A comprehensive survey of graph embedding: Problems, techniques, and applications, IEEE Trans. Knowl. Data Eng, 30, 9, pp. 1616-1637, (2018); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, Proc. 5th Int. Conf. Learn. Representations, pp. 1-14, (2017); Defferrard M., Bresson X., Vandergheynst P., Convolutional neural networks on graphs with fast localized spectral filtering, Proc. Int. Conf. Neural Inf. Process. Syst, pp. 3844-3852, (2016); Zhou X., Et al., Graph convolutional network hashing, IEEE Trans. Cybern, 50, 4, pp. 1460-1472, (2020); Wei Y., Wang X., Nie L., He X., Hong R., Chua T.-S., MMGCN: Multi-modal graph convolution network for personalized recommendation of micro-video, Proc. 27th ACM Int. Conf. Multimedia, pp. 1437-1445, (2019); Li R., Wang S., Zhu F., Huang J., Adaptive graph convolutional neural networks, Proc. 32nd AAAI Conf. Artif. Intell, pp. 3546-3553, (2018); Micheli A., Neural network for graphs: A contextual constructive approach, IEEE Trans. Neural Netw, 20, 3, pp. 498-511, (2009); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, Proc. 6th Int. Conf. Learn. Representations, pp. 1-12, (2018); Zhang J., Shi X., Xie J., Ma H., King I., Yeung D., GaAN: Gated attention networks for learning on large and spatiotemporal graphs, Proc. 34th Conf. Uncertainty Artif. Intell., Monterey, California, USA, pp. 339-349, (2018); Gilmer J., Schoenholz S.S., Riley P.F., Vinyals O., Dahl G.E., Neural message passing for quantum chemistry, Proc. 34th Int. Conf. Mach. Learn, pp. 1263-1272, (2017); Xu X., Liu C., Feng Q., Yin H., Song L., Song D., Neural network-based graph embedding for cross-platform binary code similarity detection, Proc ACM SIGSAC Conf. Comput. Commun. Secur, pp. 363-376, (2017); Shen S., Shinde S., Ramesh S., Roychoudhury A., Saxena P., Neuro-symbolic execution: Augmenting symbolic execution with neural constraints, Proc. Netw. Distrib. Syst. Secur. Symp, pp. 1-15, (2019); Rossi R.A., Zhou R., Ahmed N.K., Deep inductive graph representation learning, IEEE Trans. Knowl. Data Eng, 32, 3, pp. 438-452, (2020); Etherscan Website, (2015); Vntchain Website, (2018); Ethereum Website, (2015); Mueller B., A framework for bug hunting on the ethereum blockchain, Webiste, (2017); Feist J., Grieco G., Groce A., Slither: A static analysis framework for smart contracts, Proc. 2nd Int. Workshop Emerg. Trends Softw. Eng. Blockchain, pp. 8-15, (2019); Carbin M., Misailovic S., Kling M., Rinard M.C., Detecting and escaping infinite loops with jolt, Proc. Eur. Conf. Object-Oriented Program, pp. 609-633, (2011); Kling M., Misailovic S., Carbin M., Rinard M., Bolt: Ondemand infinite loop escape in unmodified binaries, ACM SIGPLAN Notices, 47, 10, pp. 431-450, (2012); Ibing A., Mai A., A fixed-point algorithm for automated static detection of infinite loops, Proc IEEE 16th Int. Symp. High Assurance Syst. Eng, pp. 44-51, (2015); Burnim J., Jalbert N., Stergiou C., Sen K., Looper: Lightweight detection of infinite loops at runtime, Proc IEEE/ACM Int. Conf. Automated Softw. Eng, pp. 161-169, (2009); Goller C., Kuchler A., Learning task-dependent distributed representations by backpropagation through structure, Proc. Int. Conf. Neural Netw, pp. 347-352, (1996); Sak H., Senior A., Beaufays F., Long short-Term memory recurrent neural network architectures for large scale acoustic modeling, Proc. 15th Annu. Conf. Int. Speech Commun. Assoc, pp. 338-342, (2014); Chung J., Gulcehre C., Cho K., Bengio Y., Empirical evaluation of gated recurrent neural networks on sequence modeling, ArXiv 1412.3555, pp. 1-9, (2014); Phan A.V., Le Nguyen M., Bui L.T., Convolutional neural networks over control flow graphs for software defect prediction, Proc IEEE 29th Int. Conf. Tools Artif. Intell, pp. 45-52, (2017); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, Proc IEEE Symp. Secur. Privacy, pp. 590-604, (2014); Suneja S., Zheng Y., Zhuang Y., Laredo J., Morari A., Learning to map source code to software vulnerability using code-As-A-graph, ArXiv 2006 08614, pp. 1-8, (2020); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Proc. AAAI Conf. Artif. Intell, pp. 1287-1293, (2016); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proc IEEE/ACM41st Int. Conf. Softw. Eng, pp. 783-794, (2019)",,,,,,English,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85109397423,211
Nguyen H.H.; Nguyen N.-M.; Xie C.; Ahmadi Z.; Kudendo D.; Doan T.-N.; Jiang L.,"Nguyen, Hoang H. (57222727288); Nguyen, Nhat-Minh (57821893700); Xie, Chunyao (57873687900); Ahmadi, Zahra (56600274000); Kudendo, Daniel (6603157921); Doan, Thanh-Nam (57822142100); Jiang, Lingxiao (55473381400)",57222727288; 57821893700; 57873687900; 56600274000; 6603157921; 57822142100; 55473381400,MANDO-HGT: Heterogeneous Graph Transformers for Smart Contract Vulnerability Detection,2023,"Proceedings - 2023 IEEE/ACM 20th International Conference on Mining Software Repositories, MSR 2023",,,,334,346,12,2,10.1109/MSR59073.2023.00052,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166351291&doi=10.1109%2fMSR59073.2023.00052&partnerID=40&md5=f758ad7d33f8d0cc7ac1d0b7bb8e088c,"Smart contracts in blockchains have been increasingly used for high-value business applications. It is essential to check smart contracts' reliability before and after deployment. Although various program analysis and deep learning techniques have been proposed to detect vulnerabilities in either Ethereum smart contract source code or bytecode, their detection accuracy and scalability are still limited. This paper presents a novel framework named MANDO-HGT for detecting smart contract vulnerabilities. Given Ethereum smart contracts, either in source code or bytecode form, and vulnerable or clean, MANDO-HGT custom-builds heterogeneous contract graphs (HCGs) to represent control-flow and/or function-call information of the code. It then adapts heterogeneous graph transformers (HGTs) with customized meta relations for graph nodes and edges to learn their embeddings and train classifiers for detecting various vulnerability types in the nodes and graphs of the contracts more accurately. We have collected more than 55K Ethereum smart contracts from various data sources and verified the labels for 423 buggy and 2,742 clean contracts to evaluate MANDO-HGT. Our empirical results show that MANDO-HGT can significantly improve the detection accuracy of other state-of-the-art vulnerability detection techniques that are based on either machine learning or conventional analysis techniques. The accuracy improvements in terms of F1-score range from 0.7% to more than 76% at either the coarse-grained contract level or the fine-grained line level for various vulnerability types in either source code or bytecode. Our method is general and can be retrained easily for different vulnerability types without the need for manually defined vulnerability patterns.  © 2023 IEEE.","Frizzo-Barker J., Chow-White P.A., Adams P.R., Mentanko J., Ha D., Green S., Blockchain as a disruptive technology for business: A systematic review, International Journal of Information Management, 51, (2020); Bhushan B., Sinha P., Sagayam K.M., Andrew J., Untangling blockchain technology: A survey on state of the art, security threats, privacy services, applications and future research directions, Computers & Electrical Engineering, 90, (2021); Chen J., Xia X., Lo D., Grundy J., Yang X., Maintenance-related concerns for post-deployed ethereum smart contract development: issues, techniques, and future challenges, Empirical Software Engineering, 26, 6, pp. 1-44, (2021); Jiang B., Liu Y., Chan W., ContractFuzzer: Fuzzing smart contracts for vulnerability detection, 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 259-269, (2018); Luu L., Chu D.-H., Olickel H., Saxena P., Hobor A., Making smart contracts smarter, the ACM SIGSAC conference on computer and communications security (CCS), pp. 254-269, (2016); Mossberg M., Manzano F., Hennenfent E., Groce A., Grieco G., Feist J., Brunson T., Dinaburg A., Manticore: A user-friendly symbolic execution framework for binaries and smart contracts, the 34th IEEE/ACM International Conference on Automated Software Engineering, pp. 1186-1189, (2019); Feist J., Grieco G., Groce A., Slither: a static analysis framework for smart contracts, IEEE/ACM 2nd International Workshop on Emerging Trends in Software Engineering for Blockchain, pp. 8-15, (2019); Tikhomirov S., Voskresenskaya E., Ivanitskiy I., Takhaviev R., Marchenko E., Alexandrov Y., SmartCheck: Static analysis of ethereum smart contracts, the 1st International Workshop on Emerging Trends in Software Engineering for Blockchain, pp. 9-16, (2018); Tsankov P., Dan A., Cohen D.D., Gervais A., Buenzli F., Vechev M., Securify: Practical security analysis of smart contracts, 25th ACM Conference on Computer and Communications Security, (2018); Permenev A., Dimitrov D., Tsankov P., Drachsler-Cohen D., Vechev M., Verx: Safety verification of smart contracts, 2020 IEEE symposium on security and privacy (SP), pp. 1661-1677, (2020); Hildenbrandt E., Saxena M., Rodrigues N., Zhu X., Daian P., Guth D., Moore B., Park D., Zhang Y., Stefanescu A., Et al., KEVM: A complete formal semantics of the ethereum virtual machine, IEEE 31st Computer Security Foundations Symposium (CSF), pp. 204-217, (2018); Zhuang Y., Liu Z., Qian P., Liu Q., Wang X., He Q., Smart contract vulnerability detection using graph neural network, IJCAI, 2020, pp. 3283-3290; Han S., Liang B., Huang J., Shi W., DC-Hunter: Detecting dangerous smart contracts via bytecode matching, Journal of Cyber Security, (2020); Liu Z., Qian P., Wang X., Zhuang Y., Qiu L., Wang X., Combining graph neural networks with expert knowledge for smart contract vulnerability detection, IEEE Transactions on Knowledge and Data Engineering; Zhao H., Su P., Wei Y., Gai K., Qiu M., GAN-enabled code embedding for reentrant vulnerabilities detection, Knowledge Science, Engineering and Management, 2021, pp. 585-597; Bo Z., Chenhan S., Xiaoyan P., Yang A., Juncheng T., Anqi Y., Semantic-aware graph neural network for smart contract bytecode vulnerability detection, Advanced Engineering Sciences, 54, 2, pp. 49-55; Gao Z., Jiang L., Xia X., Lo D., Grundy J., Checking smart contracts with structural code embedding, IEEE Transactions on Software Engineering; Sun Y., Han J., Mining heterogeneous information networks: a structural analysis approach, Acm Sigkdd Explorations Newsletter, 14, 2, pp. 20-28, (2013); Dong Y., Chawla N.V., Swami A., metapath2vec: Scalable representation learning for heterogeneous networks, the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 135-144, (2017); Wang X., Ji H., Shi C., Wang B., Ye Y., Cui P., Yu P.S., Heterogeneous graph attention network, The World Wide Web Conference, pp. 2022-2032, (2019); Hu Z., Dong Y., Wang K., Sun Y., Heterogeneous graph transformer, Proceedings of The Web Conference, 2020, pp. 2704-2710; Nguyen H.H., Nguyen N.-M., Xie C., Ahmadi Z., Kudendo D., Doan T.N., Jiang L., MANDO: Multi-level heterogeneous graph embeddings for fine-grained detection of smart contract vulnerabilities, 9th IEEE International Conference on Data Science and Advanced Analytics (DSAA); Durieux T., Ferreira J.F., Abreu R., Cruz P., Empirical review of automated analysis tools on 47,587 ethereum smart contracts, the ACM/IEEE 42nd International Conference on Software Engineering, 2020, pp. 530-541; Ferreira J.F., Cruz P., Durieux T., Abreu R., Smartbugs: a framework to analyze solidity smart contracts, the 35th IEEE/ACM International Conference on Automated Software Engineering, 2020, pp. 1349-1352; Ghaleb A., Pattabiraman K., How effective are smart contract analysis tools? evaluating smart contract static analysis tools using bug injection, the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis; Lundberg S.M., Lee S.-I., A unified approach to interpreting model predictions, Advances in neural information processing systems, 30, (2017); Duval A., Malliaros F., Graphsvx: Shapley value explanations for graph neural networks, European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD); Nguyen T.D., Pham L.H., Sun J., Lin Y., Minh Q.T., sFuzz: An efficient adaptive fuzzer for solidity smart contracts, the ACM/IEEE 42nd International Conference on Software Engineering, 2020, pp. 778-788; Ashraf I., Ma X., Jiang B., Chan W.K., GasFuzzer: Fuzzing ethereum smart contract binaries to expose gas-oriented exception security vulnerabilities, IEEE Access, 8, (2020); Liu Y., Li Y., Lin S.-W., Yan Q., ModCon: A model-based testing platform for smart contracts, 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE), 2020, pp. 1601-1605; Huang Y., Jiang B., Chan W.K., EOSFuzzer: Fuzzing eosio smart contracts for vulnerability detection, 12th Asia-Pacific Symposium on Internetware, 2020, pp. 99-109; Jiang B., Chen Y., Wang D., Ashraf I., Chan W., WANA: Symbolic execution of wasm bytecode for extensible smart contract vulnerability detection, IEEE 21st International Conference on Software Quality, Reliability and Security (QRS), 2021, pp. 926-937; Weiss K., Schutte J., Annotary: A concolic execution system for developing secure smart contracts, European Symposium on Research in Computer Security, pp. 747-766, (2019); So S., Hong S., Oh H., smartest: Effectively hunting vulnerable transaction sequences in smart contracts through language model-guided symbolic execution, 30th USENIX Security Symposium, 2021, pp. 1361-1378; MythX Tech: Behind the scenes of smartcontract security analysis, (2019); Xue Y., Ma M., Lin Y., Sui Y., Ye J., Peng T., Cross-contract static analysis for detecting practical reentrancy vulnerabilities in smart contracts, 35th IEEE/ACM International Conference on Automated Software Engineering (ASE), 2020, pp. 1029-1040; Schneidewind C., Grishchenko I., Scherer M., Maffei M., eThor: Practical and provably sound static analysis of ethereum smart contracts, ACM SIGSAC Conference on Computer and Communications Security, 2020, pp. 621-640; Grishchenko I., Maffei M., Schneidewind C., Foundations and tools for the static analysis of ethereum smart contracts, International Conference on Computer Aided Verification, pp. 51-78, (2018); EtherTrust: Sound static analysis of ethereum bytecode, (2018); Wang A., Wang H., Jiang B., Chan W.K., Artemis: An improved smart contract verification tool for vulnerability detection, 2020 7th International Conference on Dependable Systems and Their Applications (DSA), pp. 173-181, (2020); Tolmach P., Li Y., Lin S.-W., Liu Y., Li Z., A survey of smart contract formal specification and verification, ACM Computing Surveys (CSUR), 54, 7, pp. 1-38; Park D., Zhang Y., Saxena M., Daian P., Rosu G., A formal verification tool for ethereum vm bytecode, 26th ACM ESEC/FSE, pp. 912-915, (2018); Jiao J., Kan S., Lin S.-W., Sanan D., Liu Y., Sun J., Semantic understanding of smart contracts: Executable operational semantics of solidity, IEEE Symposium on Security and Privacy (SP), 2020, pp. 1695-1712; Grishchenko I., Maffei M., Schneidewind C., A semantic framework for the security analysis of ethereum smart contracts, International Conference on Principles of Security and Trust, pp. 243-269, (2018); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 17th IEEE international conference on machine learning and applications (ICMLA), pp. 757-762, (2018); Cheng X., Wang H., Hua J., Zhang M., Xu G., Yi L., Sui Y., Static detection of control-flow-related vulnerabilities using graph embedding, 2019 24th International Conference on Engineering of Complex Computer Systems (ICECCS), pp. 41-50, (2019); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in neural information processing systems, 32, (2019); Li Z., Zou D., Xu S., Chen Z., Zhu Y., Jin H., VulDeeLocator: a deep learning-based fine-grained vulnerability detector, IEEE Transactions on Dependable and Secure Computing; Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet, IEEE Transactions on Software Engineering; Wu Y., Zou D., Dou S., Yang W., Xu D., Jin H., VulCNN: An image-inspired scalable vulnerability detection system, ICSE; Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., SySeVR: A framework for using deep learning to detect software vulnerabilities, IEEE Transactions on Dependable and Secure Computing; Cheng X., Wang H., Hua J., Xu G., Sui Y., DeepWukong: Statically detecting software vulnerabilities using deep graph neural network, ACM Transactions on Software Engineering and Methodology (TOSEM), 30, 3, pp. 1-33; Cao S., Sun X., Bo L., Wei Y., Li B., BGNN4VD: Constructing bidirectional graph neural-network for vulnerability detection, Information and Software Technology, 136; Zhang K., Wang W., Zhang H., Li G., Jin Z., Learning to represent programs with heterogeneous graphs, ICPC; Wang W., Song J., Xu G., Li Y., Wang H., Su C., ContractWard: Automated vulnerability detection models for ethereum smart contracts, IEEE Transactions on Network Science and Engineering, 8, 2, pp. 1133-1144, (2020); Gogineni A.K., Swayamjyoti S., Sahoo D., Sahu K.K., Kishore R., Multi-class classification of vulnerabilities in smart contracts using AWD-LSTM, with pre-trained encoder inspired from natural language processing, IOP SciNotes, 1, 3, (2020); Huang T.H.-D., Hunting the ethereum smart contract: Color-inspired inspection of potential attacks, (2018); Lutz O., Chen H., Fereidooni H., Sendner C., Dmitrienko A., Sadeghi A.R., Koushanfar F., ESCORT: Ethereum smart contracts vulnerability detection using deep neural network and transfer learning; Tann W.J.-W., Han X.J., Gupta S.S., Ong Y.-S., Towards safer smart contracts: A sequence learning approach to detecting security threats, (2018); Huang J., Han S., You W., Shi W., Liang B., Wu J., Wu Y., Hunting vulnerable smart contracts via graph embedding based bytecode matching, IEEE Transactions on Information Forensics and Security, 16, pp. 2144-2156, (2021); Zhou X., Han D., Lo D., Assessing generalizability of CodeBERT, IEEE International Conference on Software Maintenance and Evolution (ICSME), 2021, pp. 425-436; Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Deng S.K., Clement C.B., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., GraphCodeBERT: Pre-training code representations with data flow, 9th International Conference on Learning Representations, ICLR 2021, Virtual Event; Wang Y., Wang W., Joty S., Hoi S.C., CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 8696-8708, (2021); Bui N.D., Yu Y., Jiang L., InferCode: Self-supervised learning of code representations by predicting subtrees, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), pp. 1186-1197, (2021); Vagavolu D., Swarna K.C., Chimalakonda S., A mocktail of source code representations, 36th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 1296-1300, (2021); Yang S., Gu X., Shen B., Self-supervised learning of smart contract representations, ICPC; Contro F., Crosara M., Ceccato M., Dalla Preda M., Ethersolve: Computing an accurate control-flow graph from ethereum bytecode, 2021 IEEE/ACM 29th International Conference on Program Comprehension (ICPC), pp. 127-137, (2021); Liu Z., Qian P., Wang X., Zhu L., He Q., Ji S., Smart contract vulnerability detection: From pure neural network to interpretable graph feature and expert pattern fusion; Wood G., Et al., Ethereum: A secure decentralised generalised transaction ledger, Ethereum project yellow paper, 151, pp. 1-32, (2014); Chen H., Pendleton M., Njilla L., Xu S., A survey on ethereum systems security: Vulnerabilities, attacks, and defenses, ACM Computing Surveys (CSUR), 53, 3, pp. 1-43, (2020); Grover A., Leskovec J., node2vec: Scalable feature learning for networks, the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 855-864, (2016); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in neural information processing systems, pp. 5998-6008, (2017); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, International Conference on Learning Representations, (2018); Abstraction layer for smart contract build systems; Contro F., Crosara M., Cmariano, SeUniVr/EtherSolve: Version used for ICPC-2021 paper, (2021); Tang J., Qu M., Wang M., Zhang M., Yan J., Mei Q., Line: Large-scale information network embedding, WWW, (2015); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, (2016); Mueller B., Smashing smart contracts for fun and real profit, 9th annual HITB Security Conference, pp. 2-51; Shapley L.S., A Value for n-Person Games, pp. 307-318, (2016)",ACM Special Interest Group on Software Engineering (SIGSOFT); Association for Computing Machinery (ACM); GitHub; Huawei Canada; IEEE Computer Society; IEEE Technical Council on Software Engineering (TCSE),"20th IEEE/ACM International Conference on Mining Software Repositories, MSR 2023",15 May 2023 through 16 May 2023,Melbourne,190670,English,Conference paper,Final,,Scopus,2-s2.0-85166351291,213
Zhang Y.; Liu D.,"Zhang, Yujian (57189007291); Liu, Daifu (57193516615)",57189007291; 57193516615,Toward Vulnerability Detection for Ethereum Smart Contracts Using Graph-Matching Network,2022,Future Internet,14,11,326,,,,8,10.3390/fi14110326,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147411558&doi=10.3390%2ffi14110326&partnerID=40&md5=6170681772b53722d0bebb4332e655c7,"With the blooming of blockchain-based smart contracts in decentralized applications, the security problem of smart contracts has become a critical issue, as vulnerable contracts have resulted in severe financial losses. Existing research works have explored vulnerability detection methods based on fuzzing, symbolic execution, formal verification, and static analysis. In this paper, we propose two static analysis approaches called ASGVulDetector and BASGVulDetector for detecting vulnerabilities in Ethereum smart contacts from source-code and bytecode perspectives, respectively. First, we design a novel intermediate representation called abstract semantic graph (ASG) to capture both syntactic and semantic features from the program. ASG is based on syntax information but enriched by code structures, such as control flow and data flow. Then, we apply two different training models, i.e., graph neural network (GNN) and graph matching network (GMN), to learn the embedding of ASG and measure the similarity of the contract pairs. In this way, vulnerable smart contracts can be identified by calculating the similarity to labeled ones. We conduct extensive experiments to evaluate the superiority of our approaches to state-of-the-art competitors. Specifically, ASGVulDetector improves the best of three source-code-only static analysis tools (i.e., SmartCheck, Slither, and DR-GCN) regarding the F1 score by 12.6% on average, while BASGVulDetector improves that of the three detection tools supporting bytecode (i.e., ContractFuzzer, Oyente, and Securify) regarding the F1 score by 25.6% on average. We also investigate the effectiveness and advantages of the GMN model for detecting vulnerabilities in smart contracts. © 2022 by the authors.","Ethereum: Blockchain App Platform; Nick S., Formalizing and Securing Relationships on Public Networks, First Monday, 2, pp. 1-21, (1997); Khan S.N., Loukil F., Ghedira-Guegan C., Benkhelifa E., Bani-Hani A., Blockchain smart contracts: Applications, challenges, and future trends, Peer-to-Peer Netw. Appl, 14, pp. 2901-2905, (2021); Vacca A., Sorbo A.D., A.Visaggio C., Canfora G., A systematic literature review of blockchain and smart contract development: Techniques, tools, and open challenges, J. Syst. Softw, 174, (2021); Izhar M.M., Louis S.C., Alana G., Elgar G., Gabrielle F., Ryan S., Understanding a revolutionary and flawed grand experiment in blockchain: The DAO attack, J. Cases Inf. Technol, 21, pp. 19-32, (2019); Destefanis G., Marchesi M., Ortu M., Tonelli R., Bracciali A., Hierons R., Smart contracts vulnerabilities: A call for blockchain software engineering?, Proceedings of the 2018 International Workshop on Blockchain Oriented Software Engineering, pp. 19-25; Enmei L., Wenjun L., Static analysis of integer overflow of smart contracts in ethereum, Proceedings of the 2020 4th International Conference on Cryptography, Security and Privacy, pp. 110-115; Liu Z., Qian P., Wang X., Zhu L., He Q., Ji S., Smart Contract Vulnerability Detection: From Pure Neural Network to Interpretable Graph Feature and Expert Pattern Fusion, Proceedings of the 30th International Joint Conference on Artificial Intelligence, pp. 2751-2759; Zhou L., Qin K., Cully A., Livshits B., Gervais A., On the Just-In-Time Discovery of Profit-Generating Transactions in DeFi Protocols, Proceedings of the 2021 IEEE Symposium on Security and Privacy, pp. 919-936; Perez D., Livshits B., Smart Contract Vulnerabilities: Vulnerable Does Not Imply Exploited, Proceedings of the 30th USENIX Security Symposium, pp. 1325-1341; Jiang B., Liu Y., Chan W.K., ContractFuzzer: Fuzzing smart contracts for vulnerability detection, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 259-269; Grieco G., Song W., Cygan A., Feist J., Groce A., Echidna: Effective, Usable, and Fast Fuzzing for Smart Contracts, Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 557-560; Wustholz V., Christakis M., Harvey: A Greybox Fuzzer for Smart Contracts, Proceedings of the 28th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 1398-1409; Nguyen T.D., Pham L.H., Sun J., Lin Y., Minh Q.T., sFuzz: An efficient adaptive fuzzer for solidity smart contracts, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 778-788; Luu L., Chu D.H., Olickel H., Saxena P., Hobor A., Making Smart Contracts Smarter, Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 254-269; Torres C.F., Schutte J., State R., Osiris: Hunting for Integer Bugs in Ethereum Smart Contracts, Proceedings of the 34th Annual Computer Security Applications Conference, pp. 664-676; Mossberg M., Manzano F., Hennenfent E., Groce A., Grieco G., Feist J., Brunson T., Dinaburg A., Manticore: A User-Friendly Symbolic Execution Framework for Binaries and Smart Contracts, Proceedings of the 2019 34th IEEE/ACM International Conference on Automated Software Engineering, pp. 1186-1189; So S., Hong S., Oh H., SmarTest: Effectively Hunting Vulnerable Transaction Sequences in Smart Contracts through Language Model-Guided Symbolic Execution, Proceedings of the 30th USENIX Security Symposium, pp. 1361-1378; Lin S.W., Tolmach P., Liu Y., Li Y., SolSEE: A Source-Level Symbolic Execution Engine for Solidity, Proceedings of the 2022 ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 1-6; Bai X., Cheng Z., Duan Z., Hu K., Formal Modeling and Verification of Smart Contracts, Proceedings of the 2018 7th International Conference on Software and Computer Applications, pp. 322-326; Tsankov P., Dan A., Drachsler-Cohen D., Gervais A., Bunzli F., Vechev M., Securify: Practical Security Analysis of Smart Contracts, Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pp. 67-82; Albert E., Correas J., Gordillo P., Roman-Diez G., Rubio A., SAFEVM: A safety verifier for Ethereum smart contracts, Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 386-389; Antonino P., Roscoe A.W., Solidifier: Bounded model checking solidity using lazy contract deployment and precise memory modelling, Proceedings of the 36th Annual ACM Symposium on Applied Computing, pp. 1788-1797; Tikhomirov S., Voskresenskaya E., Ivanitskiy I., Takhaviev R., Marchenko E., Alexandrov Y., SmartCheck: Static Analysis of Ethereum Smart Contracts, Proceedings of the 2018 IEEE/ACM 1st International Workshop on Emerging Trends in Software Engineering for Blockchain, pp. 9-16; Feist J., Grieco G., Groce A., Slither: A Static Analysis Framework for Smart Contracts, Proceedings of the 2019 IEEE/ACM 2nd International Workshop on Emerging Trends in Software Engineering for Blockchain, pp. 8-15; Xue Y., Ma M., Lin Y., Sui Y., Ye J., Peng T., Cross-Contract Static Analysis for Detecting Practical Reentrancy Vulnerabilities in Smart Contracts, Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering, pp. 1029-1040; Zhuang Y., Liu Z., Qian P., Liu Q., Wang X., He Q., Smart Contract Vulnerability Detection Using Graph Neural Networks, Proceedings of the 29th International Joint Conference on Artificial Intelligence, pp. 3283-3290; Alharby M., Aldweesh A., van Moorsel A., Blockchain-based Smart Contracts: A Systematic Mapping Study, Proceedings of the 2018 International Conference on Cloud Computing, Big Data and Blockchain, pp. 1-6; Khan Z.A., Namin A.S., Ethereum Smart Contracts: Vulnerabilities and their Classifications, Proceedings of the 2020 IEEE International Conference on Big Data, pp. 1-10; Chen J., Xia X., Lo D., Grundy J., Luo X., Chen T., Defining Smart Contract Defects on Ethereum, IEEE Trans. Softw. Eng, 48, pp. 327-345, (2022); Fan W., Ma Y., Li Q., He Y., Zhao E., Tang J., Yin D., Graph Neural Networks for Social Recommendation, Proceedings of the 2019 World Wide Web Conference, pp. 417-426; Zhao L., Li Z., Al-Dubai A.Y., Min G., Li J., Hawbani A., Zomaya A.Y., A Novel Prediction-Based Temporal Graph Routing Algorithm for Software-Defined Vehicular Networks, IEEE Trans. Intell. Transp. Syst, 23, pp. 13275-13290, (2022); Li Y., Gu C., Dullien T., Vinyals O., Kohli P., Graph Matching Networks for Learning the Similarity of Graph Structured Objects, Proceedings of the 36th International Conference on Machine Learning, pp. 3835-3845; Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, Proceedings of the 2018 International conference on learning representations, pp. 1-17; Contro F., Crosara M., Ceccato M., Preda M.D., EtherSolve: Computing an Accurate Control-Flow Graph from Ethereum Bytecode, Proceedings of the 29th International Conference on Program Comprehension, pp. 127-137; Wood G., Ethereum: A Secure Decentralised Generalised Transaction Ledger; Ferreira J.F., Cruz P., Durieux T., Abreu R., SmartBugs: A Framework to Analyze Solidity Smart Contracts, Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering, pp. 1349-1352; Ghaleb A., Pattabiraman K., How effective are smart contract analysis tools? evaluating smart contract static analysis tools using bug injection, Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 415-427",,,,,,English,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85147411558,214
Cai J.; Li B.; Zhang J.; Sun X.; Chen B.,"Cai, Jie (57578657800); Li, Bin (56342840400); Zhang, Jiale (55951743400); Sun, Xiaobing (24829988300); Chen, Bing (55723019600)",57578657800; 56342840400; 55951743400; 24829988300; 55723019600,Combine sliced joint graph with graph neural networks for smart contract vulnerability detection,2023,Journal of Systems and Software,195,,111550,,,,20,10.1016/j.jss.2022.111550,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141321797&doi=10.1016%2fj.jss.2022.111550&partnerID=40&md5=71e722ea23da022d024f0445104f170d,"Smart contract security has drawn extensive attention in recent years because of the enormous economic losses caused by vulnerabilities. Even worse, fixing bugs in a deployed smart contract is difficult, so developers must detect security vulnerabilities in a smart contract before deployment. Existing smart contract vulnerability detection efforts heavily rely on fixed rules defined by experts, which are inefficient and inflexible. To overcome the limitations of existing vulnerability detection approaches, we propose a GNN based approach for smart contract vulnerability detection. First, we construct a graph representation for a smart contract function with syntactic and semantic features by combining abstract syntax tree (AST), control flow graph (CFG), and program dependency graph (PDG). To further strengthen the presentation ability of our approach, we perform program slicing to normalize the graph and eliminate the redundant information unrelated to vulnerabilities. Then, we use a Bidirectional Gated Graph Neural-Network model with hybrid attention pooling to identify potential vulnerabilities in smart contract functions. Empirical results show that our approach can achieve 89.2% precision and 92.9% recall in smart contract vulnerability detection on our dataset and reveal the effectiveness and efficiency of our approach. © 2022 Elsevier Inc.","Alt L., Reitwiessner C., SMT-based verification of solidity smart contracts, (2018); Bojanowski P., Grave E., Joulin A., Mikolov T., Enriching word vectors with subword information, Trans. Assoc. Comput. Linguist., 5, pp. 135-146, (2017); Brent L., Grech N., Lagouvardos S., Scholz B., Smaragdakis Y., Ethainter: a smart contract security analyzer for composite vulnerabilities, Proceedings of the 41st ACM SIGPLAN International Conference on Programming Language Design and Implementation, PLDI 2020, London, UK, June 15-20, 2020, pp. 454-469, (2020); Brent L., Jurisevic A., Kong M., Liu E., Gauthier F., Gramoli V., Holz R., Scholz B., Vandal: A scalable security analysis framework for smart contracts, (2018); Falkon S., The story of the DAO—Its history and consequences, (2017); Feist J., Grieco G., Groce A., Slither: a static analysis framework for smart contracts, (2019); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Trans. Program. Lang. Syst. (TOPLAS), 9, 3, pp. 319-349, (1987); pp. 1349-1352, (2020); Gao Z., Jiang L., Xia X., Lo D., Grundy J., Checking smart contracts with structural code embedding, IEEE Trans. Softw. Eng., (2020); pp. 415-427, (2020); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Et al., Graphcodebert: Pre-training code representations with data flow, (2020); Hang L., Kim D.-H., Reliable task management based on a smart contract for runtime verification of sensing and actuating tasks in IoT environments, Sensors, 20, 4, (2020); He J., Balunovic M., Ambroladze N., Tsankov P., Vechev M.T., Learning to fuzz from symbolic execution with application to smart contracts, Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, CCS 2019, London, UK, November 11-15, 2019, pp. 531-548, (2019); Huang T.H.-D., Hunting the ethereum smart contract: Color-inspired inspection of potential attacks, (2018); Jiang B., Liu Y., Chan W.K., Contractfuzzer: Fuzzing smart contracts for vulnerability detection, 2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 259-269, (2018); Joon-Wie Tann W., Jie Han X., Gupta S.S., Ong Y.-S., Towards safer smart contracts: A sequence learning approach to detecting security threats, pp. arXiv-1811, (2018); Kalra S., Goel S., Dhawan M., Sharma S., ZEUS: analyzing safety of smart contracts, 25th Annual Network and Distributed System Security Symposium, NDSS 2018, San Diego, California, USA, February 18-21, 2018, (2018); Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2014); Krupp J., Rossow C., TeEther: Gnawing at ethereum to automatically exploit smart contracts, 27th USENIX Security Symposium, USENIX Security 2018, Baltimore, MD, USA, August 15-17, 2018, pp. 1317-1333, (2018); Lee J., Lee I., Kang J., Self-attention graph pooling, International Conference on Machine Learning, pp. 3734-3743, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, 4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings, (2016); pp. 254-269; Luu L., Chu D.-H., Olickel H., Saxena P., Hobor A., Making smart contracts smarter, Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, Vienna, Austria, October 24-28, 2016, pp. 254-269, (2016); Mossberg M., Manzano F., Hennenfent E., Groce A., Grieco G., Feist J., Brunson T., Dinaburg A., Manticore: A user-friendly symbolic execution framework for binaries and smart contracts, 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019, San Diego, CA, USA, November 11-15, 2019, pp. 1186-1189, (2019); de Moura L.M., Bjorner N., Z3: An efficient SMT solver, Tools and Algorithms for the Construction and Analysis of Systems, 14th International Conference, TACAS 2008, Held As Part of the Joint European Conferences on Theory and Practice of Software, ETAPS 2008, Budapest, Hungary, March 29-April 6, 2008. Proceedings, Lecture Notes in Computer Science, 4963, pp. 337-340, (2008); Mueller B., Smashing ethereum smart contracts for fun and real profit, (2018); Nakamoto S., Bitcoin: A peer-to-peer electronic cash system, Decentralized Bus. Rev., (2008); Nikolic I., Kolluri A., Sergey I., Saxena P., Hobor A., Finding the greedy, prodigal, and suicidal contracts at scale, Proceedings of the 34th Annual Computer Security Applications Conference, ACSAC 2018, San Juan, PR, USA, December 03-07, 2018, pp. 653-663, (2018); Osborne C., DAO maker crowdfunding platform loses $7M in latest DeFi exploit, (2021); Parity Technologies, A postmortem on the parity multi-sig library self-destruct, (2017); Park J.-S., Youn T.-Y., Kim H.-B., Rhee K.-H., Shin S.-U., Smart contract-based review system for an IoT data marketplace, Sensors, 18, 10, (2018); Pierro G.A., Tonelli R., Marchesi M., An organized repository of ethereum smart contracts’ source codes and metrics, Future Internet, 12, 11, (2020); Qian P., Liu Z., He Q., Zimmermann R., Wang X., Towards automated reentrancy detection for smart contracts based on sequential models, IEEE Access, 8, pp. 19685-19695, (2020); Rodler M., Li W., Karame G.O., Davi L., Sereum: Protecting existing smart contracts against Re-entrancy attacks, 26th Annual Network and Distributed System Security Symposium, NDSS 2019, San Diego, California, USA, February 24-27, 2019, (2019); (2019); Szabo N., Formalizing and securing relationships on public networks, First Monday, (1997); Tann A., Han X.J., Gupta S.S., Ong Y.-S., Towards safer smart contracts: A sequence learning approach to detecting vulnerabilities, pp. 1371-1385, (2018); pp. 9-16, (2018); pp. 67-82; Tsankov P., Dan A.M., Drachsler-Cohen D., Gervais A., Bunzli F., Vechev M.T., Securify: Practical security analysis of smart contracts, Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, CCS 2018, Toronto, on, Canada, October 15-19, 2018, pp. 67-82, (2018); Wang M., Zheng D., Ye Z., Gan Q., Li M., Song X., Zhou J., Ma C., Yu L., Gai Y., Xiao T., He T., Karypis G., Li J., Zhang Z., Deep graph library: A graph-centric, highly-performant package for graph neural networks, (2019); Wood G., Reitwiessner C., Beregszaszi A., Hirai Y., Et al., The solidity contract-oriented programming language, (2014); Wood G., Et al., Ethereum: A secure decentralised generalised transaction ledger, Ethereum Proj. Yellow Pap., 151, 2014, pp. 1-32, (2014); Wright T., DAO maker crowdfunding platform loses $7m in latest DeFi exploit, (2021); Wu H., Zhang Z., Wang S., Lei Y., Lin B., Qin Y., Zhang H., Mao X., Peculiar: Smart contract vulnerability detection based on crucial data flow graph and pre-training techniques, 2021 IEEE 32nd International Symposium on Software Reliability Engineering (ISSRE), pp. 378-389, (2021); Zhang Y., Kasahara S., Shen Y., Jiang X., Wan J., Smart contract-based access control for the internet of things, IEEE Internet Things J., 6, 2, pp. 1594-1605, (2018); Zhang P., Xiao F., Luo X., A framework and dataset for bugs in ethereum smart contracts, 2020 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 139-150, (2020); Zhou E., Hua S., Pi B., Sun J., Nomura Y., Yamashita K., Kurihara H., Security assurance for smart contract, 9th IFIP International Conference on New Technologies, Mobility and Security, NTMS 2018, Paris, France, February 26-28, 2018, pp. 1-5, (2018); Zhuang Y., Liu Z., Qian P., Liu Q., Wang X., He Q., Smart contract vulnerability detection using graph neural network, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020, pp. 3283-3290, (2020)",,,,,,English,Article,Final,,Scopus,2-s2.0-85141321797,215
Han D.; Li Q.; Zhang L.; Xu T.,"Han, Daojun (15044271700); Li, Qiuyue (59079937400); Zhang, Lei (56496724400); Xu, Tao (57216878829)",15044271700; 59079937400; 56496724400; 57216878829,A Smart Contract Vulnerability Detection Model Based on Syntactic and Semantic Fusion Learning,2023,Wireless Communications and Mobile Computing,2023,,9212269,,,,3,10.1155/2023/9212269,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148101619&doi=10.1155%2f2023%2f9212269&partnerID=40&md5=4adcc873283819266ee40faf9bb4c941,"As a trusted decentralized application, smart contracts manage a large number of digital assets on the blockchain. Vulnerability detection of smart contracts is an important part of ensuring the security of digital assets. At present, many researchers extract features of smart contract source code for vulnerability detection based on deep learning methods. However, the current research mainly focuses on the single representation form of the source code, which cannot fully obtain the rich semantic and structural information contained in the source code, so it is not conducive to the detection of various and complex smart contract vulnerabilities. Aiming at this problem, this paper proposes a vulnerability detection model based on the fusion of syntax and semantic features. The syntactic and semantic representation of the source code is obtained from the abstract syntax tree and control flow graph of the smart contract through TextCNN and Graph Neural Network. The syntactic and semantic features are fused, and the fused features are used to detect vulnerabilities. Experiments show that the detection accuracy and recall rate of this model have been improved on the detection tasks of five types of vulnerabilities, with an average precision of 96% and a recall rate of 90%, which can effectively identify smart contract vulnerabilities.  © 2023 Daojun Han et al.","Szabo N., Smart Contracts: Building Blocks for Digital Markets, (1996); Wang X.B., Yang X.Y., Shu X.F., Zhao L., Formal verification of smart contracts based on MSVL, Journal of Software, 6, 32, pp. 1849-1866, (2021); Ying-Li Z.H.A.N.G., Jia-Li M.A., Zi-Ang L.I.U., Xin L.I.U., Rui Z.H.O.U., Overview of Vulnerability Detection Methods for Ethereum Solidity Smart Contracts, 49, 3, (2022); Feng H., Fu X., Sun H., Wang H., Zhang Y., Efficient Vulnerability Detection Based on Abstract Syntax Tree and Deep Learning, pp. 722-727; Lv L., Wu Z., Zhang J., Zhang L., Tan Z., Tian Z., A VMD and LSTM based hybrid model of load forecasting for power grid security, IEEE Transactions on Industrial Informatics, 18, 9, pp. 6474-6482, (2022); Okegbile S.D., Cai J., Yi C., Niyato D., Human digital twin for personalized healthcare: Vision, architecture and future directions, IEEE Network, pp. 1-7, (2022); Cao D., Huang J., Zhang X., Liu X., FTCLNet: Convolutional LSTM with Fourier Transform for Vulnerability Detection, pp. 539-546; Yi C., Cai J., Su Z., A multi-user mobile computation offloading and transmission scheduling mechanism for delay-sensitive applications, IEEE Transactions on Mobile Computing, 19, 1, pp. 29-43, (2020); Kim K.B., Lee J., Automated generation of test cases for smart contract security analyzers, IEEE Access, 8, pp. 209377-209392, (2020); Qiu J., Tian Z., Du C., Zuo Q., Su S., Fang B., A survey on access control in the age of internet of things, IEEE Internet of Things Journal, 7, 6, pp. 4682-4696, (2020); Gao Z., When Deep Learning Meets Smart Contracts, pp. 1400-1402; Wang W., Song J., Xu G., Li Y., Wang H., Su C., ContractWard: Automated vulnerability detection models for Ethereum smart contracts, IEEE Transactions on Network Science and Engineering, 8, 2, pp. 1133-1144, (2021); Zhang L., Huang Z., Liu W., Guo Z., Zhang Z., Weather radar echo prediction method based on convolution neural network and long short-term memory networks for sustainable e-agriculture, Journal of Cleaner Production, 298, (2021); Lv L., Wu Z., Zhang L., Gupta B.B., Tian Z., An edge-AI based forecasting approach for improving smart microgrid efficiency, IEEE Transactions on Industrial Informatics, 18, 11, pp. 7946-7954, (2022); Xu Y., Hu G., You L., Cao C., Derhab A., A novel machine learning-based analysis model for smart contract vulnerability, Security and Communication Networks, 2021, (2021); Zhang L., Huo Y., Ge Q., Ma Y., Liu Q., Ouyang W., A privacy protection scheme for IoT big data based on time and frequency limitation, Wireless Communications and Mobile Computing, 2021, (2021); Qiao C., Brown K., Zhang F., Tian Z., Federated adaptive asynchronous clustering algorithm for wireless mesh networks, IEEE Transactions on Knowledge and Data Engineering, (2021); Sun Y., Tian Z., Li M., Su S., Du X., Guizani M., Honeypot identification in softwarized industrial cyber-physical systems, IEEE Transactions on Industrial Informatics, 17, 8, pp. 5542-5551, (2021); Feist J., Greico G., Groce A., Slither: A Static Analysis Framework for Smart Contracts, pp. 8-15; Yi C., Cai J., Zhang T., Zhu K., Chen B., Wu Q., Workload re-allocation for edge computing with server collaboration: A cooperative queueing game approach, IEEE Transactions on Mobile Computing, (2021); Sun Y., Tian Z., Li M., Zhu C., Guizani N., Automated attack and defense framework toward 5G security, IEEE Network, 34, 5, pp. 247-253, (2020); Zhang L., Xu C., Gao Y., Han Y., Du X., Tian Z., Improved Dota2 lineup recommendation model based on a bidirectional LSTM, Tsinghua Science and Technology, 25, 6, pp. 712-720, (2020); Lv L., Chen J., Zhang Z., Wang B., Zhang L., A numerical solution of a class of periodic coupled matrix equations, Journal of the Franklin Institute, 358, 3, pp. 2039-2059, (2021); Tikhomirov S., Voskresenskaya E., Ivanitskiy I., Takhaviev R., Marchenko E., Alexandrov Y., Smart Check: Static Analysis of Ethereum Smart Contracts, pp. 9-16; Luu L., Chu D.-H., Olickel H., Saxena P., Hobor A., Making Smart Contracts Smarter, pp. 254-269; Jiang B., Liu Y., Chan W.K., Contract Fuzzer: Fuzzing Smart Contracts for Vulnerability Detection, pp. 259-269; Tann W.J.-W., Han X.J., Sengupta S., Ong Y.J.A., Towards Safer Smart Contracts: A Sequence Learning Approach to Detecting Vulnerabilities, (2018); Qiao C., Qiu J., Tan Z., Min G., Zomaya A.Y., Tian Z., Evaluation mechanism for decentralized collaborative pattern learning in heterogeneous vehicular networks, IEEE Transactions on Intelligent Transportation Systems, pp. 1-10, (2022); Zhang L., Tang S., Lv L., An finite iterative algorithm for sloving periodic Sylvester bimatrix equations, Journal of the Franklin Institute, 357, 15, pp. 10757-10772, (2020); Yi C., Cai J., Zhu K., Wang R., A queueing game based management framework for fog computing with strategic computing speed control, IEEE Transactions on Mobile Computing, 21, 5, pp. 1537-1551, (2022); Zhuang Y., Liu Z., Qian P., Liu Q., Wang X., He Q., Smart Contract Vulnerability Detection Using Graph Neural Networks; Lv L., Tang S., Zhang L., Parametric solutions to generalized periodic Sylvester bimatrix equations, Journal of the Franklin Institute, 357, 6, pp. 3601-3621, (2020); Qian P., Liu Z.G., He Q.M., Huang B.T., Tian D.Z., Wang X., Smart contract vulnerability detection technique: A survey, Journal of Software, 33, 8, pp. 3059-3085, (2022); Mikolov T., Sutskever I., Chen K., Corrado G., Dean J., Distributed Representations of Words and Phrases and Their Compositionality, pp. 3111-3119; Kim Y., Convolutional Neural Networks for Sentence Classification, pp. 1746-1751; Yi C., Huang S., Cai J., Joint resource allocation for device-to-device communication assisted fog computing, IEEE Transactions on Mobile Computing, 20, 3, pp. 1076-1091, (2021); Lv L., Chen J., Zhang L., Zhang F., Gradient-based neural networks for solving periodic Sylvester matrix equations, Journal of the Franklin Institute, 359, 18, pp. 10849-10866, (2022); Kipf T., Welling M., Semi-supervised Classification with Graph Convolutional Networks, (2017); Ashizawa N., Yanai N., Cruz J.P., Okamura S., Eth2Vec: Learning Contract-wide Code Representations for Vulnerability Detection on Ethereum Smart Contracts, pp. 47-59; Veloso N., Conkas: A Modular and Static Analysis Tool for Ethereum Bytecode, (2021); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Bv M., Gulcehre C., Learning Phrase Representations Using RNN Encoder-decoder for Statistical Machine Translation, pp. 1724-1734",,,,,,English,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85148101619,216
Han D.; Li Q.; Zhang L.; Xu T.,"Han, Daojun (15044271700); Li, Qiuyue (59079937400); Zhang, Lei (56496724400); Xu, Tao (57216878829)",15044271700; 59079937400; 56496724400; 57216878829,A smart contract vulnerability detection model based on graph neural networks,2022,"2022 4th International Conference on Frontiers Technology of Information and Computer, ICFTIC 2022",,,,834,837,3,3,10.1109/ICFTIC57696.2022.10075325,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152192949&doi=10.1109%2fICFTIC57696.2022.10075325&partnerID=40&md5=f0465ad00d8a06b470ad570a20b799cc,"In recent years, smart contract vulnerability detection methods mostly view smart contract source code as natural language for processing, which cannot fully capture the semantic and structural features of the source code and has a high rate of false positives and missing positives. To improve the accuracy of vulnerability detection, this paper uses Graph Neural Network to obtain the semantic and structural information of the source code and Convolutional Neural Network to assist learning. We propose a graph neural network-based vulnerability detection model for smart contracts, which transforms smart contracts into control flow graphs, learns graph embedding using graph neural networks, and introduces Convolutional Neural Networks to learn the node order information of control flow graphs, and finally performs vulnerability detection using graph embedding and node order information. Experimenting on real datasets, our accuracy and F1 values are improved and the model can effectively detect smart contract vulnerabilities.  © 2022 IEEE.","Khan Z.A., Namin A.S., Ethereum Smart Contracts: Vulnerabilities and their Classifications, 2020 Ieee International Conference on Big Data (Big Data), (2020); Singh A., Parizi R.M., Zhang Q., Choo K.-K.R., Dehghantanha A., Blockchain smart contracts formalization: Approaches and challenges to address vulnerabilities[J], Comput Secur, 88, (2020); Jiang Y., Wu S., Yang H., Luo H., Chen Z., Yin S., Et al., Secure Data Transmission and Trustworthiness Judgement Approaches Against Cyber-Physical Attacks in an Integrated Data-Driven Framework, Ieee Transactions on Systems, Man, and Cybernetics: Systems, pp. 1-11, (2022); Luu L., Chu D.-H., Olickel H., Saxena P., Hobor A., Making Smart Contracts Smarter, 23rd Acm Conference on Computer and Communications Security (CCS), (2016); Eshghie M., Artho C., Gurov D., Dynamic Vulnerability Detection on Smart Contracts Using Machine Learning, Evaluation and Assessment in Software Engineering, (2021); Mi F., Wang Z., Zhao C., Guo J., Ahmed F., Khan L., VSCL: Automating Vulnerability Detection in Smart Contracts with Deep Learning, 2021 Ieee International Conference on Blockchain and Cryptocurrency (ICBC), (2021); Shakya S., Mukherjee A., Halder R., Maiti A., Chaturvedi A., SmartMixModel: Machine Learning-based Vulnerability Detection of Solidity Smart Contracts, 2022 Ieee International Conference on Blockchain (Blockchain), (2022); Cvitkovic M., Singh B., Anandkumar A., Open Vocabulary Learning on Source Code with a Graph-Structured Cache, Icml, (2019); Kipf T., Welling M., Semi-Supervised Classification with Graph Convolutional Networks, (2017); Yu Z., Cao R., Tang Q., Nie S., Huang J., Wu S., Order Matters: Semantic-Aware Neural Networks for Binary Code Similarity Detection, Aaai, (2020); Ashizawa N., Yanai N., Cruz J.P., Okamura S., Eth2Vec: Learning Contract-Wide Code Representations for Vulnerability Detection on Ethereum Smart Contracts, Proceedings of the 3rd Acm International Symposium on Blockchain and Secure Critical Infrastructure, pp. 47-59, (2021)",IEEE,"4th International Conference on Frontiers Technology of Information and Computer, ICFTIC 2022",2 December 2022 through 4 December 2022,"Virtual, Online",187555,English,Conference paper,Final,,Scopus,2-s2.0-85152192949,218
Miao H.; Bao H.; Tang Z.; Li W.; Wang W.; Chen H.; Liu F.; Sun Y.,"Miao, Han (58743102200); Bao, Huaifeng (57226382103); Tang, Zixian (57226382361); Li, Wenhao (57226380132); Wang, Wen (56032175000); Chen, Huashan (57201909530); Liu, Feng (57161192700); Sun, Yanhui (58743204900)",58743102200; 57226382103; 57226382361; 57226380132; 56032175000; 57201909530; 57161192700; 58743204900,AST2Vec: A Robust Neural Code Representation for Malicious PowerShell Detection,2023,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),14299 LNCS,,,207,224,17,0,10.1007/978-3-031-45933-7_13,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178514641&doi=10.1007%2f978-3-031-45933-7_13&partnerID=40&md5=4494d55ff52abdbd18f1100ae2f6fd97,"In recent years, PowerShell has become a commonly used carrier to wage cyber attacks. As a script, PowerShell is easy to obfuscate to evade detection. Thus, they are difficult to detect directly using traditional anti-virus software. Existing advanced detection methods generally recover obfuscated scripts before detection. However, most deobfuscation tools can not achieve precise recovery on obfuscated scripts due to emerging obfuscation techniques. To solve the problem, we propose a robust neural code representation method, namely AST2Vec, to detect malicious PowerShell without de-obfuscating scripts. 6 Abstract Syntax Tree (AST) recovery-related statement nodes are defined to identify obfuscated subtrees. Then AST2Vec splits the large AST of entire PowerShell scripts into a set of small subtrees rooted by these 6 types of nodes and performs tree-based neural embeddings on all extracted subtrees by capturing lexical and syntactical knowledge of statement nodes. Based on the sequence of statement vectors, a bidirectional recursive neural network (Bi-RNN) is modeled to leverage the context of statements and finally produce vector representation of scripts. We evaluate the proposed method for malicious PowerShell detection through extensive experiments. Experimental results indicate that our model outperforms the state-of-the-art approaches. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Fang Y., Zhou X., Huang C., Effective method for detecting malicious PowerShell scripts based on hybrid features, Neurocomputing, 448, pp. 30-39, (2021); Hendler D., Kels S., Rubin A., Detecting malicious PowerShell commands using deep neural networks, Proceedings of the 2018 on Asia Conference on Computer and Communications Security, (2018); Chai H., Ying L., Duan H., Zha D., Invoke-deobfuscation: AST-based and semantics-preserving deobfuscation for PowerShell scripts, 52Nd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pp. 295-306, (2022); Li Z., Chen Q.A., Xiong C., Chen Y., Zhu T., Yang H., Effective and lightweight deobfuscation and semantic-aware attack detection for PowerShell scripts, Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, (2019); Blake A., David M., Identifying encrypted malware traffic with contextual flow data, Proceedings of the 2016 ACM Workshop on Artificial Intelligence and Security, Aisec 2016, Pp. 35–46, (2016); Hendler D., Kels S., Rubin A., AMSI-based detection of malicious PowerShell code using contextual embeddings, Proceedings of the 15Th ACM Asia Conference on Computer and Communications Security, (2019); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings of the 41St International Conference on Software Engineering, pp. 783-794, (2019); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional Neural Networks over Tree Structures for Programming Language Processing, (2015); Mikolov T., Karafiat M., Burget L., Cernock J., Khudanpur S., Recurrent neural network based language model, Interspeech, Conference of the International Speech Communication Association, Makuhari, Chiba, Japan, September, (2015); Bohannon D., Invoke-Obfuscation-Powershell Obfuscator; Tang D., Qin B., Liu T., Document modeling with gated recurrent neural network for sentiment classification, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 1422-1432, (2015); Bahdanau D., Cho K., Bengio Y., Neural Machine Translation by Jointly Learning to Align and Translate. Arxiv Preprint Arxiv, 1409, (2014); Wei H.-H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proceedings of the 26Th International Joint Conference on Artificial Intelligence, pp. 3034-3040, (2017); Rusak G., Al-Dujaili A., O'Reilly U.M., AST-based deep learning for detecting malicious PowerShell, ACM CCS, (2018); Liu C., Xia B., Yu M., Liu Y., PSDEM: A feasible de-obfuscation method for malicious PowerShell detection, IEEE ISCC, (2018); Psdecode-Powershell Script for Deobfuscating Encoded Powershell Scripts; Malandrone G.M., Virdis G., Giacinto G., Maiorca D., Powerdecode: A Power-Shell Script Decoder Dedicated to Malware Analysis, (2021); Gao Y., Peng G., Yang X., PowerShell malicious code family classification based on deep learning, J. Wuhan Univ., 68, 1, pp. 8-16, (2022); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in Neural Information Processing Systems, pp. 3111-3119, (2013); Bohannon D., Holmes L., Revoke-Obfuscation: Powershell Obfuscation Detection Using Science, (2017); Ruaro N., Pagani F., Ortolani S., Kruegel C., Vigna G., SYMBEXCEL: Automated analysis and understanding of malicious excel 4.0 macros, 43Rd IEEE Symposium on Security and Privacy, SP 2022, San Francisco, CA, USA, 22–26 May 2022, Pp. 1066–1081. IEEE, (2022); Cozzi E., Graziano M., Fratantonio Y., Balzarotti D., Understanding Linux malware, 2018 IEEE Symposium on Security and Privacy (S&P), pp. 161-175, (2018)",,"5th International Conference on Science of Cyber Security, SciSec 2023",11 July 2023 through 14 July 2023,Melbourne,304579,English,Conference paper,Final,,Scopus,2-s2.0-85178514641,219
Rozi M.F.; Ban T.; Ozawa S.; Yamada A.; Takahashi T.; Kim S.; Inoue D.,"Rozi, Muhammad Fakhrur (58032726000); Ban, Tao (7202924921); Ozawa, Seiichi (7201436732); Yamada, Akira (58628590000); Takahashi, Takeshi (55805377000); Kim, Sangwook (57218209841); Inoue, Daisuke (57206203839)",58032726000; 7202924921; 7201436732; 58628590000; 55805377000; 57218209841; 57206203839,Detecting Malicious JavaScript Using Structure-Based Analysis of Graph Representation,2023,IEEE Access,11,,,102727,102745,18,1,10.1109/ACCESS.2023.3317266,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172989806&doi=10.1109%2fACCESS.2023.3317266&partnerID=40&md5=bbd56b60ec2e4b7191116403b187c21e,"Malicious JavaScript code in web applications poses a significant threat as cyber attackers exploit it to perform various malicious activities. Detecting these malicious scripts is challenging, given their diverse nature and the continuous evolution of attack techniques. Most approaches formulate this task as a static or sequential feature of the script, which is insufficient in terms of flexibility to various attack techniques and the ability to capture the script's semantic meaning. To address this issue, we propose an alternative approach that leverages JavaScript code's abstract syntax tree (AST) representation, focusing on distinctive syntactic structure features. The proposed approach uses graph neural networks to extract structural features from the AST graph while considering the attribute features of individual nodes, which uses neural message passing with neighborhood aggregation. The proposed method encodes both the local AST graph structure and attributes of the nodes. It enables capturing the source code's semantic meaning and exploits the signature structure in the AST representations. The proposed method consistently achieved high detection performance in extensive experiments on two different datasets, with accuracy scores of 99.4% and 96.92%. The obtained evaluation metrics demonstrate the effectiveness of our approach in accurately detecting malicious JavaScript code, with our proposed method successfully detecting more than 81% for various attack types and achieving an almost twofold performance improvement on JS-Droppers compared to the sequence-based approach. In addition, we observed that the AST graph structure represented the code's semantic meaning, exhibiting distinctive patterns and signatures that could be effectively captured using the proposed method.  © 2013 IEEE.","Likarish P., Jung E., Jo I., Obfuscated malicious JavaScript detection using classification techniques, Proc. 4th Int. Conf. Malicious Unwanted Softw. (MALWARE), pp. 47-54, (2009); Rhode M., Burnap P., Jones K., Early-stage malware prediction using recurrent neural networks, Comput. Secur., 77, pp. 578-594, (2018); Zhang X., Sun M., Wang J., Wang J., Malware detection based on opcode sequence and ResNet, Security With Intelligent Computing and Big-data Services (Advances in Intelligent Systems and Computing), 895, pp. 489-502, (2020); Fang Y., Huang C., Liu L., Xue M., Research on malicious JavaScript detection technology based on LSTM, IEEE Access, 6, pp. 59118-59125, (2018); Horwitz S., Identifying the semantic and textual differences between two versions of a program, Proc. ACM SIGPLAN Conf. Program. Lang. Design Implement., 25, 6, pp. 234-245, (1990); Ndichu S., Kim S., Ozawa S., Misu T., Makishima K., A machine learning approach to detection of JavaScript-based attacks using AST features and paragraph vectors, Appl. Soft Comput., 84, (2019); Fass A., Backes M., Stock B., JStap: A static pre-filter for malicious JavaScript detection, Proc. 35th Annu. Comput. Secur. Appl. Conf., pp. 257-269, (2019); Song X., Chen C., Cui B., Fu J., Malicious JavaScript detection based on bidirectional LSTM model, Appl. Sci., 10, 10, (2020); Huang Y., Li T., Zhang L., Li B., Liu X., JSContana: Malicious JavaScript detection using adaptable context analysis and key feature extraction, Comput. Secur., 104, (2021); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, (2016); Phung N.M., Mimura M., Detection of malicious JavaScript on an imbalanced dataset, Internet Things, 13, (2021); Le Q., Mikolov T., Distributed representations of sentences and documents, Proc. 31st Int. Conf. Int. Conf. Mach. Learn., pp. 1188-1196, (2014); Cristianini N., Ricci E., Support Vector Machines, (2008); Alex S., Rajkumar T.D., Spider bird swarm algorithm with deep belief network for malicious JavaScript detection, Comput. Secur., 107, (2021); Hinton G., Deep Belief Nets, pp. 267-269, (2010); Kennedy J., Particle Swarm Optimization, pp. 760-766; Abdullah Alqarni A., Alsharif N., Ahmad Khan N., Georgieva L., Pardade E., Alzahrani M.Y., MNN-XSS: Modular neural network based approach for XSS attack detection, Comput., Mater. Continua, 70, 2, pp. 4075-4085, (2022); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, (2013); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput., 9, 8, pp. 1735-1780, (1997); Liang H., Yang Y., Sun L., Jiang L., JSAC: A novel framework to detect malicious JavaScript via CNNs over AST and CFG, Proc. Int. Joint Conf. Neural Netw. (IJCNN), pp. 1-8, (2019); Roy D., Panda P., Roy K., Tree-CNN: A hierarchical deep convolutional neural network for incremental learning, Neural Netw., 121, pp. 148-160, (2020); Shen V.R.L., Wei C.-S., Juang T.T., JavaScript malware detection using a high-level fuzzy Petri net, Proc. Int. Conf. Mach. Learn. Cybern. (ICMLC), 2, pp. 511-514, (2018); Cardoso J., Valette R., Dubois D., Fuzzy Petri nets: An overview, IFAC Proc. Volumes, 29, 1, pp. 4866-4871, (1996); Alazab A., Khraisat A., Alazab M., Singh S., Detection of obfuscated malicious JavaScript code, Future Internet, 14, 8, (2022); He X., Xu L., Cha C., Malicious JavaScript code detection based on hybrid analysis, Proc. 25th Asia-Pacific Softw. Eng. Conf. (APSEC), pp. 365-374, (2018); Wang W.-H., Lv Y.-J., Chen H.-B., Fang Z.-L., A static malicious JavaScript detection using SVM, Proc. 2nd Int. Conf. Comput. Sci. Electron. Eng. (ICCSEE)., pp. 214-217, (2013); Kim Y., Convolutional neural networks for sentence classification, Proc. Conf. Empirical Methods Natural Lang. Process. (EMNLP), pp. 1746-1751, (2014); Fang Y., Huang C., Su Y., Qiu Y., Detecting malicious JavaScript code based on semantic analysis, Comput. Secur., 93, (2020); Huang Z., Xu W., Yu K., Bidirectional LSTM-CRF models for sequence tagging, (2015); Kam Ho T., Random decision forests, Proc. 3rd Int. Conf. Document Anal. Recognit., pp. 278-282, (1995); Fass A., Krawczyk R.P., Backes M., Stock B., JaSt: Fully syntactic detection of malicious (Obfuscated) JavaScript, Detection of Intrusions and Malware, and Vulnerability Assessment (Lecture Notes in Computer Science), 10885, (2018); Rozi M.F., Ban T., Ozawa S., Kim S., Takahashi T., Inoue D., JStrack: Enriching malicious JavaScript detection based on AST graph analysis and attention mechanism, Neural Information Processing, pp. 669-680, (2021); Fang Y., Huang C., Zeng M., Zhao Z., Huang C., JStrong: Malicious JavaScript detection based on code semantic representation and graph neural network, Comput. Secur., 118, (2022); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Trans. Program. Lang. Syst., 9, 3, pp. 319-349, (1987); Rozi M.F., Kim S., Ozawa S., Deep neural networks for malicious JavaScript detection using bytecode sequences, Proc. Int. Joint Conf. Neural Netw. (IJCNN), pp. 1-8, (2020); Johnson R., Zhang T., Deep pyramid convolutional neural networks for text categorization, Proc. 55th Annu. Meeting Assoc. Comput. Linguistics, pp. 562-570, (2017); Stokes J.W., Agrawal R., McDonald G., Hausknecht M., ScriptNet: Neural static analysis for malicious JavaScript detection, Proc. IEEE Mil. Commun. Conf. (MILCOM), pp. 1-8, (2019); Allen F.E., Control flow analysis, ACM SIGPLAN Notices, 5, 7, pp. 1-19, (1970); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proc. IEEE/ACM 41st Int. Conf. Softw. Eng. (ICSE), pp. 783-794, (2019); Rozi M.F., Ozawa S., Ban T., Kim S., Takahashi T., Inoue D., Understanding the influence of AST-JS for improving malicious webpage detection, Appl. Sci., 12, 24, (2022); Rozi M.F., Ban T., Kim S., Ozawa S., Takahashi T., Inoue D., Detecting malicious websites based on JavaScript content analysis, Proc. Comput. Secur. Symp., pp. 727-732, (2021); Canfora G., Mercaldo F., Visaggio C.A., Malicious JavaScript detection by features extraction, e-Inform. Softw. Eng. J., 8, 1, pp. 65-78, (2014); Xu W., Zhang F., Zhu S., The power of obfuscation techniques in malicious JavaScript code: A measurement study, Proc. 7th Int. Conf. Malicious Unwanted Softw., pp. 9-16, (2012); Feinstein B., Peck D., Caffeine monkey: Automated collection, detection and analysis of malicious JavaScript, (2007); Xu W., Zhang F., Zhu S., JStill: Mostly static detection of obfuscated malicious JavaScript code, Proc. 3rd ACM Conf. Data Appl. Secur. Privacy, pp. 117-128, (2013); Jones J., Abstract syntax tree implementation idioms, Proc. 10th Conf. Pattern Lang. Programs (PLoP), (2003); Han K., Hwang S.O., Lightweight detection method of obfuscated landing sites based on the AST structure and tokens, Appl. Sci., 10, 17, (2020); Fred Agarap A., Deep learning using rectified linear units (ReLU), (2018); Han J., Moraga C., The influence of the sigmoid function parameters on the speed of backpropagation learning, Proc. Int. Workshop Artif. Neural Netw., From Natural Artif. Neural Comput., pp. 195-201, (1995); Raychev V., Bielik P., Vechev M., Krause A., Learning programs from noisy data, ACM SIGPLAN Notices, 51, 1, pp. 761-774, (2016); Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2014); Zhou K., Dong Y., Wang K., Sun Lee W., Hooi B., Xu H., Feng J., Understanding and resolving performance degradation in graph convolutional networks, (2020); Hamilton W.L., Ying R., Leskovec J., Inductive representation learning on large graphs, Proc. 31st Int. Conf. Neural Inf. Process. Syst., pp. 1025-1035, (2017); Webb G.I., Naíve Bayes, pp. 713-714, (2010); Furnkranz J., Decision Tree, pp. 263-267, (2010); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, Proc. 6th Int. Conf. Learn. Represent., pp. 1-12, (2017); Xu K., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks?, (2019)",,,,,,English,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85172989806,220
Zhu J.; Yao Y.; Deng X.; Yong Y.; Wang Y.; Chen L.; Xue Z.; Zhao R.,"Zhu, Junmin (56136235600); Yao, Yizhao (58566013400); Deng, Xianwen (57559258400); Yong, Yaoguang (57223224652); Wang, Yanhao (57783152700); Chen, Libo (57559258500); Xue, Zhi (7203058560); Zhao, Ruijie (57203168276)",56136235600; 58566013400; 57559258400; 57223224652; 57783152700; 57559258500; 7203058560; 57203168276,SAWD: Structural-Aware Webshell Detection System with Control Flow Graph,2023,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",2023-July,,,351,356,5,0,10.18293/SEKE2023-205,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170088196&doi=10.18293%2fSEKE2023-205&partnerID=40&md5=17552b54f84adbc66130e38cb0079c34,"With the increasing prevalence of web servers, protecting them from cyber attacks has become a crucial task for online service providers. Webshells, which are backdoors to websites, are commonly used by hackers to gain unauthorized access to web servers. However, traditional methods for detecting webshells often fail to produce satisfactory results due to the use of obfuscation or encryption to conceal their characteristics. In recent years, webshell detection methods based on deep learning (DL) have received significant attention, but they struggle to preserve the syntax and semantic information contained in the source code. In this paper, we propose a structural-aware webshell detection system to address these problems, denoted as SAWD. Specifically, we first generate the control flow graph (CFG) with syntax and semantic information from the PHP source code. Then, we leverage CFG to build our graph representation, which consists of the adjacency matrix and keywords-based basic block features. Finally, based on our graph representation, we adopt convolutional neural networks (GCN) combined with graph pooling to detect webshells more efficiently. Experimental results demonstrate that our method outperforms state-of-the-art webshell detection systems on the collected dataset. © 2023 Knowledge Systems Institute Graduate School. All rights reserved.","Yang W., Sun B., Cui B., A webshell detection technology based on HTTP traffic analysis, 12th International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing, 773, pp. 336-342, (2018); Shi L., Fang Y., Webshell detection method research based on web log, Journal of Information Security Reserach, 2, 1, pp. 66-73, (2016); Neopi; Li T., Ren C., Fu Y., Xu J., Guo J., Chen X., Webshell detection based on the word attention mechanism, IEEE Access, 7, pp. 185140-185147, (2019); Zhao R., Yong S., Zhang H., Long J., Xue Z., Webshell file detection method based on tf-idf, Computer Science, 47, (2020); Kang W., Zhong S., Chen K., Lai J., Xu G., Rf-adacost: Webshell detection method that combines statistical features and opcode, Frontiers in Cyber Security, 1286, pp. 667-682, (2020); Li Y., Huang J., Ikusan A. A., Mitchell M., Zhang J., Dai R., ShellBreaker: Automatically detecting php-based malicious web shells, Comput. Secur, 87, (2019); Cheng B., Guo Y., Ren Y., Yang G., Xu G., Msdetector: A static PHP webshell detection system based on deep-learning, 16th International Symposium on Theoretical Aspects of Software Engineering, 13299, pp. 155-172, (2022); Reps T. W., Program analysis via graph reachability, Inf. Softw. Technol, 40, 11-12, pp. 701-726, (1998); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, IEEE Symposium on Security and Privacy, pp. 590-604, (2014); Backes M., Rieck K., Skoruppa M., Stock B., Yamaguchi F., Efficient and flexible discovery of PHP application vulnerabilities, IEEE European Symposium on Security and Privacy, pp. 334-349, (2017); Kipf T. N., Welling M., Semi-supervised classification with graph convolutional networks, 5th International Conference on Learning Representations, (2017); Bianchi F. M., Grattarola D., Alippi C., Mincut pooling in graph neural networks, CoRR, (2019); Wu Y., Song M., Li Y., Tian Y., Tong E., Niu W., Jia B., Huang H., Li Q., Liu J., Improving convolutional neural network-based webshell detection through reinforcement learning, 23rd International Conference on Information and Communications Security, 12918, pp. 368-383, (2021); Fang Y., Qiu Y., Liu L., Huang C., Detecting webshell based on random forest with fasttext, International Conference on Computing and Artificial Intelligence, pp. 52-56, (2018)",Knowledge Systems Institute; KSI Research Inc.,"35th International Conference on Software Engineering and Knowledge Engineering, SEKE 2023",1 July 2023 through 10 July 2023,"Hybrid, San Francisco",191784,English,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85170088196,221
Fang Y.; Huang C.; Zeng M.; Zhao Z.; Huang C.,"Fang, Yong (57026722800); Huang, Chaoyi (57580376500); Zeng, Minchuan (57578927400); Zhao, Zhiying (57579340900); Huang, Cheng (55511401300)",57026722800; 57580376500; 57578927400; 57579340900; 55511401300,JStrong: Malicious JavaScript detection based on code semantic representation and graph neural network,2022,Computers and Security,118,,102715,,,,13,10.1016/j.cose.2022.102715,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128369219&doi=10.1016%2fj.cose.2022.102715&partnerID=40&md5=4f6874e954626fa4d1fe9d83d50e7502,"Web development technology has experienced significant progress. The creation of JavaScript has highly enriched the interactive ability of the client. However, the attacker uses the dynamic characteristics of the JavaScript language to embed malicious code into web pages to achieve the purpose of smuggling, redirection, and so on. Traditional methods based on static feature detection are therefore difficult to detect malicious code after confusion, and the method based on dynamic analysis is inefficient. To meet these challenges, this paper proposes a static detection model JStrong based on graph neural network. The model first generates an abstract syntax tree from the JavaScript source code, and then adds data flow and control flow information into the program dependency graph. In addition, we embed the nodes and edges of the graph into the feature vector and fully learn the features of the whole graph through the graph neural network. We take advantage of a real-world dataset collected from the top website and GitHub to evaluate JStrong and compare it to the state-of-the-art method. Experimental results show that JStrong achieves near-perfect classification performance and is superior to the state-of-the-art method. © 2022 Elsevier Ltd","Andreasen E., Moller A., Determinacy in static analysis for jQuery, Proceedings of the 2014 ACM International Conference on Object Oriented Programming Systems Languages & Applications, pp. 17-31, (2014); Brown F., Narayan S., Wahby R.S., Engler D., Jhala R., Stefan D., Finding and preventing bugs in javascript bindings, 2017 IEEE Symposium on Security and Privacy (SP), pp. 559-578, (2017); Catal C., Gunduz H., Ozcan A., Malware detection based on graph attention networks for intelligent transportation systems, Electronics (Basel), 10, 20, (2021); Cheng X., Wang H., Hua J., Xu G., Sui Y., Deepwukong: statically detecting software vulnerabilities using deep graph neural network, ACM Transactions on Software Engineering and Methodology (TOSEM), 30, 3, pp. 1-33, (2021); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using rnn encoder-decoder for statistical machine translation, arXiv preprint arXiv:1406.1078, (2014); Curtsinger C., Livshits B., Zorn B.G., Seifert C., Zozzle: fast and precise in-browser JavaScript malware detection, USENIX Security Symposium, pp. 33-48, (2011); Eshkevari L., Mazinanian D., Rostami S., Tsantalis N., Jsdeodorant: Class-awareness for javascript programs, 2017 IEEE/ACM 39th International Conference on Software Engineering Companion (ICSE-C), pp. 71-74, (2017); Fang Y., Huang C., Su Y., Qiu Y., Detecting malicious javascript code based on semantic analysis, Computers & Security, 93, (2020); Fass A., Backes M., Stock B., Jstap: A static pre-filter for malicious javascript detection, Proceedings of the 35th Annual Computer Security Applications Conference, pp. 257-269, (2019); Fass A., Krawczyk R.P., Backes M., Stock B., Jast: Fully syntactic detection of malicious (obfuscated) javascript, International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, pp. 303-325, (2018); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Transactions on Programming Languages and Systems (TOPLAS), 9, 3, pp. 319-349, (1987); (2021); Gorji A., Abadi M., Detecting obfuscated javascript malware using sequences of internal function calls, Proceedings of the 2014 ACM Southeast Regional Conference, pp. 1-6, (2014); Hamilton W.L., Ying R., Leskovec J., Inductive representation learning on large graphs, Proceedings of the 31st International Conference on Neural Information Processing Systems, pp. 1025-1035, (2017); Hamilton W.L., Ying R., Leskovec J., Representation learning on graphs: methods and applications, CoRR, abs/1709.05584, (2017); Hedin D., Sabelfeld A., Web application security using jsflow, 2015 17th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC), pp. 16-19, (2015); Hidayat A., (2021); Huang Y., Li T., Zhang L., Li B., Liu X., Jscontana: malicious javascript detection using adaptable context analysis and key feature extraction, Computers & Security, 104, (2021); Kapravelos A., Shoshitaishvili Y., Cova M., Kruegel C., Vigna G., Revolver: An automated approach to the detection of evasive web-based malware, 22nd {USENIX} Security Symposium ({USENIX} Security 13), pp. 637-652, (2013); Kim H.-C., Choi Y.-H., Lee D.-H., Jssandbox: a framework for analyzing the behavior of malicious javascript code using internal function hooking, KSII Transactions on Internet and Information Systems (TIIS), 6, 2, pp. 766-783, (2012); Kim K., Kim I.L., Kim C.H., Kwon Y., Zheng Y., Zhang X., Xu D., J-force: forced execution on JavaScript, Proceedings of the 26th International Conference on World Wide Web, pp. 897-906, (2017); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24–26, 2017, Conference Track Proceedings, (2017); Le Pochat V., Van Goethem T., Tajalizadehkhoob S., Korczynski M., Joosen W., Tranco: a research-oriented top sites ranking hardened against manipulation, Proceedings of the 26th Annual Network and Distributed System Security Symposium, pp. 1-15, (2019); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, 4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2–4, 2016, Conference Track Proceedings, (2016); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: a framework for using deep learning to detect software vulnerabilities, IEEE Trans Dependable Secure Comput, (2021); Mikolov T., Sutskever I., Chen K., Corrado G., Dean J., Distributed representations of words and phrases and their compositionality, Proceedings of the 26th International Conference on Neural Information Processing Systems-Volume 2, pp. 3111-3119, (2013); Mining node.js vulnerabilities via object dependence graph and query, In: 31st USENIX Security Symposium (USENIX Security 22), (2022); Ndichu S., Ozawa S., Misu T., Okada K., A machine learning approach to malicious javascript detection using fixed length vector representation, 2018 International Joint Conference on Neural Networks (IJCNN), pp. 1-8, (2018); Petrak H., (2021); Seshagiri P., Vazhayil A., Sriram P., Ama: static code analysis of web page for the detection of malicious scripts, Procedia Comput Sci, 93, pp. 768-773, (2016); Song W., Huang Q., Huang J., Understanding javascript vulnerabilities in large real-world android applications, IEEE Trans Dependable Secure Comput, 17, 5, pp. 1063-1078, (2018); Tellenbach B., Paganoni S., Rennhard M., Detecting obfuscated javascripts from known and unknown obfuscators using machine learning, International Journal on Advances in Security, 9, 3-4, pp. 196-206, (2016); (2021); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30, - May 3, 2018, Conference Track Proceedings, (2018); (2021); Wang H., Ye G., Tang Z., Tan S.H., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans. Inf. Forensics Secur., 16, pp. 1943-1958, (2020); Wang J., Xue Y., Liu Y., Tan T.H., Jsdc: A hybrid approach for javascript malware detection and classification, Proceedings of the 10th ACM Symposium on Information, Computer and Communications Security, pp. 109-120, (2015); Wang M., Zheng D., Ye Z., Gan Q., Li M., Song X., Zhou J., Ma C., Yu L., Gai Y., Xiao T., He T., Karypis G., Li J., Zhang Z., Deep graph library: a graph-centric, highly-performant package for graph neural networks, arXiv preprint arXiv:1909.01315, (2019); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, pp. 590-604, (2014); Zhou J., Cui G., Hu S., Zhang Z., Yang C., Liu Z., Wang L., Li C., Sun M., Graph neural networks: a review of methods and applications, AI Open, 1, pp. 57-81, (2020); Zhou Y., Evans D., Understanding and monitoring embedded web scripts, 2015 IEEE Symposium on Security and Privacy, pp. 850-865, (2015); Zhou Y., Liu S., Siow J.K., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, NeurIPS, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85128369219,223
Renjith G.; Aji S.,"Renjith, G. (57290257400); Aji, S. (56769726700)",57290257400; 56769726700,Vulnerability Analysis and Detection Using Graph Neural Networks for Android Operating System,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13146 LNCS,,,57,72,15,0,10.1007/978-3-030-92571-0_4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122043434&doi=10.1007%2f978-3-030-92571-0_4&partnerID=40&md5=4572538ed90c4cfd6eb83138ffd7e4e1,"Android operating system approximately contains around 93 million lines of code, mainly consisting of C, C++ and Java languages. There is no strict software engineering life-cycle followed during Android software development, and hence the design flaws and vulnerabilities are largely reported. Rising security attacks targeting Android manifests the importance of early detection of vulnerabilities in Android operating system. The existing mechanisms either focus on Android Apps or short code differences of the Android framework, and hence they are less effective for Android operating system. In this work, we extracted all the officially reported publicly accessible Android Java vulnerabilities in application and framework layers from 2015 till June 2021. The extracted vulnerable and corresponding fixed (secure) code are then converted into the graphical form using different intermediate graph representations, and then graph features are extracted. Vectorization techniques are used for converting node features of the graph into numerical formats. A vulnerability detection mechanism based on Graph Neural Network is designed and achieved an F1-score of 0.92. To the best of our knowledge, this will be one of the first works for Android operating system source code vulnerability detection technique exploiting the potential of Graph Neural Networks. © 2021, Springer Nature Switzerland AG.","Namrud Z., Kpodjedo S., Talhi C., AndroVul: A repository for Android security vulnerabilities, Proceedings of the 29Th Annual International Conference on Computer Science and Software Engineering, pp. 64-71, (2019); Gao J., Li L., Kong P., Bissyande T.F., Klein J., Understanding the evolution of android app vulnerabilities, IEEE Trans. Reliab., pp. 212-230, (2019); Linares-Vasquez M., Bavota G., Escobar-Velasquez C., An empirical study on android-related vulnerabilities, IEEE/ACM 14Th International Conference on Mining Software Repositories (MSR), pp. 2-13, (2017); Wu D., Gao D., Cheng E.K., Cao Y., Jiang J., Deng R.H., Proceedings of the 2019 ACM Asia Conference on Computer and Communications Security, pp. 295-306, (2019); Ghaffarian S.M., Shahriari H.R., Neural software vulnerability analysis using rich intermediate graph representations of programs, Information Sciences, pp. 189-207, (2021); Bilgin Z., Ersoy M.A., Soykan E.U., Tomur E., Comak P., Karacay L., Vulnerability prediction from source code using machine learning, IEEE Access, 8, pp. 150672-150684, (2020); Li Y., Ma L., Shen L., Lv J., Zhang P., Open source software security vulnerability detection based on dynamic behavior features, Plos One, 14, 8, (2019); Li X., Wang L., Xin Y., Yang Y., Chen Y., Automated vulnerability detection in source code using minimum intermediate representation learning, Appl. Sci., 10, 5, (2020); Suneja S., Zheng Y., Zhuang Y., Laredo J., Morari A., Learning to Map Source Code to Software Vulnerability Using Code-As-A-Graph. Arxiv Preprint Arxiv, 2006, (2020); Iadarola G., Graph-Based Classification for Detecting Instances of Bug Patterns, (2018); Russell R., Et al., Automated vulnerability detection in source code using deep representation learning, 17Th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 757-762, (2018); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, IEEE Symposium on Security and Privacy, pp. 590-604, (2014); Google Android Security Bulletin, (2021); Liang H., Sun L., Wang M., Yang Y., Deep learning with customized abstract syntax tree for bug localization, IEEE Access, 7, pp. 116309-116320, (2019); The Code Property Graph, (2021); Schutze H., Manning C.D., Raghavan P., Introduction to Information Retrieval, (2008); Le Q., Mikolov T., Distributed representations of sentences and documents, International Conference on Machine Learning PMLR, pp. 1188-1196, (2014); Mikolov T., Sutskever I., Chen K., Corrado G., Dean J., Distributed representations of words and phrases and their compositionality, Proceedings of the 27Th Annual Conference on Neural Information Processing Systems (NIPS), pp. 3111-3119, (2013); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, Proceedings of the 6Th International Conference on Learning Representations (ICLR, (2018); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks. Arxiv Preprint Arxiv, 1609, (2016); Android Open Source Project (AOSP), (2021); Android Ransomware Spreading Amid COVID-19 Epidemic, (2021)",,"17th International Conference on Information Systems Security, ICISS 2021",16 December 2021 through 20 December 2021,Patna,270249,English,Conference paper,Final,,Scopus,2-s2.0-85122043434,227
Rozi M.F.; Ban T.; Ozawa S.; Kim S.; Takahashi T.; Inoue D.,"Rozi, Muhammad Fakhrur (58032726000); Ban, Tao (7202924921); Ozawa, Seiichi (7201436732); Kim, Sangwook (57218209841); Takahashi, Takeshi (55805377000); Inoue, Daisuke (57206203839)",58032726000; 7202924921; 7201436732; 57218209841; 55805377000; 57206203839,JStrack: Enriching Malicious JavaScript Detection Based on AST Graph Analysis and Attention Mechanism,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),13109 LNCS,,,669,680,11,5,10.1007/978-3-030-92270-2_57,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121913208&doi=10.1007%2f978-3-030-92270-2_57&partnerID=40&md5=f5447afcae093e424ec42d6ba4e49536,"Malicious JavaScript is one of the most common tools for attackers to exploit the vulnerability of web applications. It can carry potential risks such as spreading malware, phishing, or collecting sensitive information. Though there are numerous types of malicious JavaScript that are difficult to detect, generalizing the malicious script’s signature can help catch more complex JavaScripts that use obfuscation techniques. This paper aims at detecting malicious JavaScripts based on structure and attribute analysis of abstract syntax trees (ASTs) that capture the generalized semantic meaning of the source code. We apply a graph convolutional neural network (GCN) to process the AST features and get a graph representation via neural message passing with neighborhood aggregation. The attention layer enriches our method to track pertinent parts of scripts that may contain the signature of malicious intent. We comprehensively evaluate the performance of our proposed approach on a real-world dataset to detect malicious websites. The proposed method demonstrates promising performance in terms of detection accuracy and robustness against obfuscated samples. © 2021, Springer Nature Switzerland AG.","Belkin M., Niyogi P., Sindhwani V., Manifold regularization: A geometric framework for learning from labeled and unlabeled examples, J. Mach. Learn. Res., 7, pp. 2399-2434, (2006); Cova M., Kruegel C., Vigna G., Detection and analysis of drive-by-download attacks and malicious JavaScript code, Proceedings of the 19Th International Conference on World Wide Web, WWW 2010, pp. 281-290, (2010); Douligeris C., Mitrokotsa A., DDoS attacks and defense mechanisms: Classification and state-of-the-art, Comput. Netw., 44, 5, pp. 643-666, (2004); Fang Y., Huang C., Liu L., Xue M., Research on malicious JavaScript detection technology based on LSTM, IEEE Access, 6, pp. 59118-59125, (2018); Hamilton W.L., Graph representation learning, Synthesis Lectures on Artificial Intelligence and Machine Learning, 14, 3, pp. 1-159, (2020); Kamkar S., Phpwn: Attacking Sessions and Pseudo-Random Numbers in PHP, (2010); Ndichu S., Kim S., Ozawa S., Deobfuscation, unpacking, and decoding of obfuscated malicious JavaScript for machine learning models detection performance improvement, CAAI Trans. Intell. Technol., 5, pp. 184-192, (2020); Raychev V., Bielik P., Vechev M., Krause A., Learning programs from noisy data, SIGPLAN Not, 51, 1, pp. 761-774, (2016); Rozi M.F., Kim S., Ozawa S., Deep neural networks for malicious JavaScript detection using bytecode sequences, International Joint Conference on Neural Networks (IJCNN), pp. 1-8, (2020); Usage Statistics of Javascript as Client-Side Programming Language on Websites, (2021); Vaswani A., Et al., Attention is all you need, Proceedings of the 31St International Conference on Neural Information Processing Systems, NIPS 2017, pp. 6000-6010, (2017); Wassermann G., Su Z., Static detection of cross-site scripting vulnerabilities, 2008 ACM/IEEE 30Th International Conference on Software Engineering, pp. 171-180, (2008); Weston J., Ratle F., Collobert R., Deep learning via semi-supervised embedding, Proceedings of the 25Th International Conference on Machine Learning, ICML 2008, pp. 1168-1175, (2008); Zhou K., Et al., Understanding and Resolving Performance Degradation in Graph Convolutional Networks. Arxiv E-Prints Arxiv, 2006, (2020)",,"28th International Conference on Neural Information Processing, ICONIP 2021",8 December 2021 through 12 December 2021,"Virtual, Online",269629,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85121913208,229
Cao S.; Sun X.; Bo L.; Wu R.; Li B.; Wu X.; Tao C.; Zhang T.; Liu W.,"Cao, Sicong (57222584216); Sun, Xiaobing (24829988300); Bo, Lili (57204660270); Wu, Rongxin (55469414900); Li, Bin (56342840400); Wu, Xiaoxue (56650282600); Tao, Chuanqi (36086787600); Zhang, Tao (55547105895); Liu, Wei (56795881000)",57222584216; 24829988300; 57204660270; 55469414900; 56342840400; 56650282600; 36086787600; 55547105895; 56795881000,Learning to Detect Memory-related Vulnerabilities,2023,ACM Transactions on Software Engineering and Methodology,33,2,43,,,,2,10.1145/3624744,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183325353&doi=10.1145%2f3624744&partnerID=40&md5=ada411ab2849e459230c34255ab66df2,"Memory-related vulnerabilities can result in performance degradation or even program crashes, constituting severe threats to the security of modern software. Despite the promising results of deep learning (DL)-based vulnerability detectors, there exist three main limitations: (1) rich contextual program semantics related to vulnerabilities have not yet been fully modeled; (2) multi-granularity vulnerability features in hierarchical code structure are still hard to be captured; and (3) heterogeneous flow information is not well utilized. To address these limitations, in this article, we propose a novel DL-based approach, called MVD+, to detect memory-related vulnerabilities at the statement-level. Specifically, it conducts both intraprocedural and interprocedural analysis to model vulnerability features, and adopts a hierarchical representation learning strategy, which performs syntax-aware neural embedding within statements and captures structured context information across statements based on a novel Flow-Sensitive Graph Neural Networks, to learn both syntactic and semantic features of vulnerable code. To demonstrate the performance, we conducted extensive experiments against eight state-of-the-art DL-based approaches as well as five well-known static analyzers on our constructed dataset with 6,879 vulnerabilities in 12 popular C/C++ applications. The experimental results confirmed that MVD+ can significantly outperform current state-of-the-art baselines and make a great trade-off between effectiveness and efficiency.  © 2023 Copyright held by the owner/author(s).","Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, Proceedings of the 6th International Conference on Learning Representations (ICLR’18), (2018); Alon U., Yahav E., On the bottleneck of graph neural networks and its practical implications, Proceedings of the 9th International Conference on Learning Representations (ICLR’21), (2021); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proc. ACM Program. Lang., 3, (2019); Bian P., Liang B., Huang J., Shi W., Wang X., Zhang J., SinkFinder: Harvesting hundreds of unknown interesting function pairs with just one seed, Proceedings of the 28th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE’20), pp. 1621-1625, (2020); Bo L., Li Y., Sun X., Wu X., Li B., 2023, Frontiers Comput. Sci., 17, 3; Bo L., Zhu X., Sun X., Zhen N., Li B., Are similar bugs fixed with similar change operations? An empirical study, Chinese J. Electr., 30, 1, pp. 55-63, (2021); Bordes A., Usunier N., Garcia-Duran A., Weston J., Yakhnenko O., Translating embeddings for modeling multi-relational data, Proceedings of the 27th Annual Conference on Neural Information Processing Systems (NeurIPS’13), pp. 2787-2795, (2013); Bruening D., Zhao Q., Practical memory checking with Dr. Memory, Proceedings of the 9th International Symposium on Code Generation and Optimization (CGO’11), pp. 213-223, (2011); Bui N.D.Q., Yu Y., Jiang L., TreeCaps: Tree-based capsule networks for source code processing, Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI’21), pp. 30-38, (2021); Cai J., Li B., Zhang J., Sun X., Chen B., Combine sliced joint graph with graph neural networks for smart contract vulnerability detection, J. Syst. Softw., 195, (2023); Cao S., He B., Sun X., Ouyang Y., Zhang C., Wu X., Su T., Bo L., Li B., Ma C., Li J., Wei T., ODDFUZZ: Discovering Java deserialization vulnerabilities via structure-aware directed greybox fuzzing, Proceedings of the 44th IEEE Symposium on Security and Privacy (SP’23), (2023); Cao S., Sun X., Bo L., Wei Y., Li B., BGNN4VD: Constructing Bidirectional Graph Neural-network for Vulnerability Detection, Inf. Softw. Technol., 136, (2021); Cao S., Sun X., Bo L., Wu R., Li B., Tao C., MVD: Memory-related vulnerability detection based on flow-sensitive graph neural networks, Proceedings of the 44th IEEE/ACM International Conference on Software Engineering (ICSE’22), pp. 1456-1468, (2022); Cao S., Sun X., Wu X., Bo L., Li B., Wu R., Liu W., He B., Ouyang Y., Li J., Improving Java deserialization gadget chain mining via overriding-guided object generation, Proceedings of the 45th IEEE/ACM International Conference on Software Engineering (ICSE’23), (2023); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet?, IEEE Trans. Softw. Eng., 48, 9, pp. 3280-3296, (2022); Chawla N.V., Bowyer K.W., Hall L.O., Philip Kegelmeyer W., SMOTE: Synthetic minority over-sampling technique, J. Artif. Intell. Res., 16, pp. 321-357, (2002); Chen Z., Wang C., Yan J., Sui Y., Xue J., Runtime detection of memory errors with smart status, Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA’21), pp. 296-308, (2021); Cheng X., Sun X., Bo L., Wei Y., KVS: A tool for knowledge-driven vulnerability searching, Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE’22), pp. 1731-1735, (2022); Cheng X., Wang H., Hua J., Xu G., Sui Y., DeepWukong: Statically detecting software vulnerabilities using deep graph neural network, ACM Trans. Softw. Eng. Methodol., 30, 3, (2021); Cherem S., Princehouse L., Rugina R., Practical memory leak detection using guarded value-flow analysis, Proceedings of the 28th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI’07), pp. 480-491, (2007); Common Vulnerabilities and Exposures, (2022); Common Weakness Enumeration, (2022); (2022); (2022); Dam H.K., Tran T., Pham T., Ng S.W., Grundy J., Ghose A., Automatic feature learning for predicting vulnerable software components, IEEE Trans. Softw. Eng., 47, 1, pp. 67-85, (2021); Emamdoost N., Wu Q., Lu K., McCamant S., Detecting kernel memory leaks in specialized modules with ownership reasoning, Proceedings of the 28th Annual Network and Distributed System Security Symposium (NDSS’21), (2021); Fan G., Wu R., Shi Q., Xiao X., Zhou J., Zhang C., Smoke: Scalable path-sensitive memory leak detection for millions of lines of code, Proceedings of the 41st International Conference on Software Engineering (ICSE’19), pp. 72-82, (2019); Fan J., Li Y., Wang S., Nguyen T.N., 2020. A C/C++ code vulnerability dataset with code changes and CVE summaries, Proceedings of the 17th International Conference on Mining Software Repositories (MSR’20), pp. 508-512; Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020 (Findings of ACL, Vol. EMNLP 2020), pp. 1536-1547, (2020); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Trans. Program. Lang. Syst., 9, 3, pp. 319-349, (1987); Flawfinder, (2022); Fu M., Tantithamthavorn C., LineVul: A transformer-based line-level vulnerability prediction, Proceedings of the 19th IEEE/ACM International Conference on Mining Software Repositories (MSR’22), pp. 608-620, (2022); Gens D., Schmitt S., Davi L., Sadeghi A.-R., K-miner: Uncovering memory corruption in linux, Proceedings of the 25th Annual Network and Distributed System Security Symposium (NDSS’18), (2018); Heine D.L., Lam M.S., Static detection of leaks in polymorphic containers, Proceedings of the 28th International Conference on Software Engineering (ICSE’06), pp. 252-261, (2006); Henning J.L., SPEC CPU2000: Measuring CPU performance in the new millennium, Computer, 33, 7, pp. 28-35, (2000); Hin D., Kan A., Chen H., Babar M.A., LineVD: Statement-level vulnerability detection using graph neural networks, Proceedings of the 19th IEEE/ACM International Conference on Mining Software Repositories (MSR’22), pp. 596-607, (2022); Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P.T., On the naturalness of software, Proceedings of the 34th International Conference on Software Engineering (ICSE’12), pp. 837-847, (2012); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput, 9, 8, pp. 1735-1780, (1997); Imtiaz N., Williams L.A., Memory error detection in security testing, (2021); Infer, (2022); Jung C., Lee S., Raman E., Pande S., Automated memory leak detection for production use, Proceedings of the 36th International Conference on Software Engineering (ICSE’14), pp. 825-836, (2014); Kingma D.P., Ba J., Adam: A method for stochastic optimization, Proceedings of the 3rd International Conference on Learning Representations (ICLR’15), (2015); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, Proceedings of the 5th International Conference on Learning Representations (ICLR’17), (2017); Le Q.V., Mikolov T., Distributed representations of sentences and documents, Proceedings of the 31th International Conference on Machine Learning (ICML’14), 32, pp. 1188-1196, (2014); Li W., Cai H., Sui Y., Manz D., PCA: Memory leak detection using partial call-path analysis, Proceedings of the 28th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE’20), pp. 1621-1625, (2020); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, Proceedings of the 4th International Conference on Learning Representations (ICLR’16), (2016); Li Y., Wang S., Nguyen T.N., Vulnerability detection with fine-grained interpretations, Proceeding of the 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE’21), pp. 292-303, (2021); Li Z., Zou D., Xu S., Chen Z., Zhu Y., Jin H., VulDeeLocator: A deep learning-based fine-grained vulnerability detector, IEEE Trans. Depend. Secur. Comput., 19, 4, pp. 2821-2837, (2022); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., SySeVR: A framework for using deep learning to detect software vulnerabilities, IEEE Trans. Dependable Secur. Comput., 19, 4, pp. 2244-2258, (2022); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., VulDeePecker: A deep learning-based system for vulnerability detection, Proceedings of the 25th Annual Network and Distributed System Security Symposium (NDSS’18), (2018); Linux Kernel, (2022); Lipp S., Banescu S., Pretschner A., An empirical study on the effectiveness of static C code analyzers for vulnerability detection, Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA’22), pp. 544-555, (2022); Liu D., Wu Q., Ji S., Lu K., Liu Z., Chen J., He Q., Detecting missed security operations through differential checking of object-based similar paths, Proceedings of the 27th ACM SIGSAC Conference on Computer and Communications Security (CCS’21), pp. 1627-1644, (2021); Liu T., Curtsinger C., Berger E.D., DoubleTake: Fast and precise error detection via evidence-based dynamic analysis, Proceedings of the 38th International Conference on Software Engineering (ICSE’16), pp. 911-922, (2016); Lou Y., Zhu Q., Dong J., Li X., Sun Z., Hao D., Zhang L., Zhang L., Boosting coverage-based fault localization via graph-based representation learning, Proceedings of the 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE’21), pp. 664-676, (2021); Lu K., Pakki A., Wu Q., Detecting missing-check bugs via semantic- and context-aware criticalness and constraints inferences, Proceedings of the 28th USENIX Security Symposium (USENIX Security’19), pp. 1769-1786, (2019); Lyu Y., Fang Y., Zhang Y., Sun Q., Ma S., Bertino E., Lu K., Li J., Goshawk: Hunting memory corruptions via structure-aware and object-centric memory operation synopsis, Proceedings of the 43rd IEEE Symposium on Security and Privacy (SP’22), pp. 2096-2113, (2022); Mazuera-Rozo A., Mojica-Hanke A., Linares-Vasquez M., Bavota G., Shallow or deep? An empirical study on detecting vulnerabilities using deep learning, Proceedings of the 29th IEEE/ACM International Conference on Program Comprehension (ICPC’21), pp. 276-287, (2021); MemoryVul, (2022); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Proceedings of the 27th Annual Conference on Neural Information Processing Systems (NeurIPS’13), pp. 3111-3119, (2013); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI’16), pp. 1287-1293, (2016); Nethercote N., Seward J., Valgrind: A framework for heavyweight dynamic binary instrumentation, Proceedings of the 28th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI’07), pp. 89-100, (2007); Nong Y., Cai H., Ye P., Li L., Chen F., Evaluating and comparing memory error vulnerability detectors, Inf. Softw. Technol., 137, (2021); Noonan R.E., An algorithm for generating abstract syntax trees, Comput. Lang., 10, 3-4, pp. 225-236, (1985); Pennington J., Socher R., Manning C.D., Glove: Global vectors for word representation, Proceedings of the 26th Conference on Empirical Methods in Natural Language Processing (EMNLP’14), pp. 1532-1543, (2014); PyTorch, (2022); Rough Audit Tool for Security, (2022); Schlichtkrull M.S., Kipf T.N., Bloem P., van den Berg R., Titov I., Welling M., Modeling relational data with graph convolutional networks, (2017); Sennrich R., Haddow B., Birch A., Neural machine translation of rare words with subword units, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL’16), (2016); Serebryany K., Bruening D., Potapenko A., Vyukov D., AddressSanitizer: A fast address sanity checker, Proceedings of the 23rd USENIX Annual Technical Conference (USENIX ATC’12), pp. 309-318, (2012); Shi Q., Xiao X., Wu R., Zhou J., Fan G., Zhang C., Pinpoint: Fast and precise sparse value flow analysis for million lines of code, Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI’18), pp. 693-706, (2018); Sinha S., Harrold M.J., Rothermel G., System-dependence-graph-based slicing of programs with arbitrary interprocedural control flow, Proceedings of the 21st International Conference on Software Engineering (ICSE’99), pp. 432-441, (1999); Siow J.K., Liu S., Xie X., Meng G., Liu Y., Learning program semantics with code representations: An empirical study, Proceedings of the 29th IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER’22), pp. 554-565, (2022); Software Assurance Reference Dataset, (2022); Song Z., Wang J., Yang K., Wang J., HGIVul: Detecting inter-procedural vulnerabilities based on hypergraph convolution, Inf. Softw. Technol., 160, (2023); Soremekun E.O., Kirschner L., Bohme M., Zeller A., Locating faults with program slicing: An empirical analysis, Empir. Softw. Eng., 26, 3, (2021); Subhan F., Wu X., Bo L., Sun X., Rahman M., A deep learning-based approach for software vulnerability detection using code metrics, IET Softw, 16, 5, pp. 516-526, (2022); Sui Y., Ye D., Xue J., Static memory leak detection using full-sparse value-flow analysis, Proceedings of the 21st International Symposium on Software Testing and Analysis (ISSTA’12), pp. 254-264, (2012); Szekeres L., Payer M., Wei T., Song D., SoK: Eternal war in memory, Proceedings of the 34th IEEE Symposium on Security and Privacy (SP’13), pp. 48-62, (2013); Tai K.S., Socher R., Manning C.D., Improved semantic representations from tree-structured long short-term memory networks, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing (ACL’15), pp. 1556-1566, (2015); Tantithamthavorn C., Hassan A.E., Matsumoto K., The impact of class rebalancing techniques on the performance and interpretation of defect prediction models, IEEE Trans. Softw. Eng., 46, 11, pp. 1200-1219, (2020); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, Proceedings of the 6th International Conference on Learning Representations (ICLR’18), (2018); Wang H., Xie X., Li Y., Wen C., Li Y., Liu Y., Qin S., Chen H., Sui Y., Typestate-guided fuzzer for discovering use-after-free vulnerabilities, Proceedings of the 42nd International Conference on Software Engineering (ICSE’20), pp. 999-1010, (2020); Wang H., Ye G., Tang Z., Tan S.H., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans. Inf. Forensics Secur., 16, pp. 1943-1958, (2021); Wang W., MLEE: Effective detection of memory leaks on early-exit paths in OS kernels, Proceedings of 32nd USENIX Annual Technical Conference (USENIX ATC’21), pp. 31-45, (2021); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI’17), pp. 3034-3040, (2017); Wei Y., Sun X., Bo L., Cao S., Xia X., Li B., A comprehensive study on security bug characteristics, J. Softw. Evol. Process., 33, 10, (2021); Weiser M., Program slicing, IEEE Trans. Softw. Eng., 10, 4, pp. 352-357, (1984); Wen C., Wang H., Li Y., Qin S., Liu Y., Xu Z., Chen H., Xie X., Pu G., Liu T., MemLock: Memory usage guided fuzzing, Proceedings of the 42nd International Conference on Software Engineering (ICSE’20), pp. 765-777, (2020); Wen X.-C., Chen Y., Gao C., Zhang H., Zhang J.M., Liao Q., Vulnerability detection with graph simplification and enhanced graph representation learning, Proceedings of the 45th IEEE/ACM International Conference on Software Engineering (ICSE’23), (2023); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering (ASE’16), pp. 87-98, (2016); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A comprehensive survey on graph neural networks, IEEE Trans. Neural Netw. Learn. Syst., 32, 1, pp. 4-24, (2021); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, Proceedings of the 35th IEEE Symposium on Security and Privacy (SP’14), pp. 590-604, (2014); Yan G., Chen S., Bai Y., Li X., Can deep learning models learn the vulnerable patterns for vulnerability detection?, Proceedings of the 46th IEEE Annual Computers, Software, and Applications Conference (COMPSAC’22), pp. 904-913, (2022); Yu H., Lam W., Chen L., Li G., Xie T., Wang Q., Neural detection of semantic code clones via tree-based convolution, Proceedings of the 27th International Conference on Program Comprehension (ICPC’19), pp. 70-80, (2019); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings of the 41st International Conference on Software Engineering (ICSE’19), pp. 783-794, (2019); Zhao T., Zhang X., Wang S., GraphSMOTE: Imbalanced node classification on graphs with graph neural networks, Proceedings of the 14th ACM International Conference on Web Search and Data Mining (WSDM’21), pp. 833-841, (2021); Zhou T., Sun X., Xia X., Li B., Chen X., Improving defect prediction with deep forest, Inf. Softw. Technol., 114, pp. 204-216, (2019); Zhou Y., Liu S., Siow J.K., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Proceedings of the 33rd Annual Conference on Neural Information Processing Systems (NeurIPS’19), pp. 10197-10207, (2019); Zhou Z., Bo L., Wu X., Sun X., Zhang T., Li B., Zhang J., Cao S., SPVF: Security property assisted vulnerability fixing via attention-based models, Empir. Softw. Eng., 27, 7, (2022); Zou D., Wang S., Xu S., Li Z., Jin H., 2021. μVulDeePecker: A deep learning-based system for multiclass vulnerability detection, IEEE Trans. Depend. Secur. Comput., 18, 5, pp. 2224-2236",,,,,,English,Article,Final,,Scopus,2-s2.0-85183325353,231
Zeng C.; Zhou B.; Dong H.; Wu H.; Xie P.; Guan Z.,"Zeng, Ciling (57195722172); Zhou, Bo (58515913700); Dong, Huoyuan (58034281900); Wu, Haolin (58805832200); Xie, Peiyuan (58805802700); Guan, Zhitao (22634312300)",57195722172; 58515913700; 58034281900; 58805832200; 58805802700; 22634312300,A General Source Code Vulnerability Detection Method via Ensemble of Graph Neural Networks,2024,Communications in Computer and Information Science,1992,,,560,574,14,0,10.1007/978-981-99-9331-4_37,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181976167&doi=10.1007%2f978-981-99-9331-4_37&partnerID=40&md5=233bc7479f4f344bcafc23a298b5134f,"Deep neural networks have been recently utilized in source code vulnerability detection methods due to their automated feature learning capabilities. However, current deep vulnerability detection models heavily rely on fixed code static analysis tools, limiting their applicability to a single programming language. Furthermore, the existing models often fail to fully extract semantic features from the source code, leading to limited generalization capabilities. To address these challenges, this paper proposes a language-agnostic code vulnerability detection framework based on ensemble of graph neural networks. Our approach considers the source program as a linear token sequence and constructs an initial graph representation by capturing the co-occurrence relationships between tokens. The model’s hidden layers leverage a combination of graph convolutional module and gated graph neural networks to extract semantic features from vulnerable code. To adaptively learn the importance of each vulnerability feature, we introduce a self-attention layer after the hidden layer. Additionally, to enhance model stability and prevent overfitting, we incorporate residual connections and flooding regularization techniques. Experimental results on real-world vulnerability datasets demonstrate our approach surpasses previous SOTA approaches by a margin of over 2.37% in terms of detection accuracy. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2024.","Lin G., Wen S., Han Q., Zhang J., Xiang Y., Software vulnerability detection using deep neural networks: A survey, Proc. IEEE, 108, pp. 1825-1848, (2020); Engler D.R., Chen D.Y., Chou A., Bugs as deviant behavior: A general approach to inferring errors in systems code, Proceedings of the 18Th ACM Symposium on Operating System Principles, pp. 57-72, (2001); Russell R.L., Et al., Automated vulnerability detection in source code using deep representation learning, 17Th IEEE International Conference on Machine Learning and Applications, pp. 757-762, (2018); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet?, IEEE Trans. Software Eng., 48, 9, pp. 3280-3296, (2022); Huang H., Guo Y., Shi Q., Yao P., Wu R., Zhang C., BEACON: Directed greybox fuzzing with provable path pruning, 43Rd IEEE Symposium on Security and Privacy, pp. 36-50, (2022); Karim R., Tip F., Sochurkova A., Sen K., Platform-independent dynamic taint analysis for JavaScript, IEEE Trans. Softw. Eng., 46, 12, pp. 1364-1379, (2020); Shin Y., Meneely A., Williams L., Osborne J.A., Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities, IEEE Trans. Software Eng., 37, 6, pp. 772-787, (2011); Li Z., Et al., VulDeePecker: A deep learning-based system for vulnerability detection, 25Th Annual Network and Distributed System Security Symposium, (2018); Zou D., Wang S., Xu S., Li Z., Jin H., VulDeePecker: A deep learning-based system for multiclass vulnerability detection, IEEE Trans. Dependable Secure Comput., 18, 5, pp. 2224-2236, (2011); Wu Y., Zou D., Yang W., Xu D., Jin H., VuICNN: An image-inspired scalable vulnerability detection system, International Conference on Software Engineering, pp. 2365-2376, (2022); Lin G., Et al., Cross-project transfer representation learning for vulnerable function discovery, IEEE Trans. Industr. Inf., 14, 7, pp. 3289-3297, (2018); Nguyen D.Q., Nguyen T.D., Phung D.Q., Universal graph transformer selfattention networks, Companion of the Web Conference 2022, pp. 193-196, (2022); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, pp. 590-604, (2014); Nguyen V., Nguyen D.Q., Nguyen V., Le T., Tran Q.H., Phung D., ReGVD: Revisiting graph neural networks for vulnerability detection, 44Th IEEE/ACM International Conference on Software Engineering: Companion Proceedings, pp. 178-182, (2022); Ashish V., Et al., Attention is all you need, Conference on Neural Information Processing Systems, pp. 5998-6008, (2017); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, 5Th International Conference on Learning Representations, (2017); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, 4Th International Conference on Learning Representations, (2016); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, 2016 IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Lu S., Guo D., Ren S., Et al., CodeXGLUE: A machine learning benchmark dataset for code understanding and generation, Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1. Virtual, (2021); Kaur A., Kaur M., Analysis of code refactoring impact on software quality, MATEC Web of Conferences, (2016); Dong Z.M., Hu Q., Guo Y.J., Et al., MixCode: Enhancing code classification by mixup-based data augmentation, IEEE International Conference on Software Analysis, Evolution and Reengineering, pp. 379-390, (2023); Feng Z., Guo D., Duan N., Et al., CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Guo D., Ren S., Lu S., Et al., GraphCodeBERT: Pre-training code representations with data flow, 9Th International Conference on Learning Representations. Virtual Event, (2021); Xu K., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks?, 7Th International Conference on Learning Representations, (2019); Ishida T., Yamane I., Sakai T., Niu G., Sugiyama M., Do we need zero training loss after achieving zero training error?, Proceedings of the 37Th International Conference on Machine Learning, pp. 4604-4614, (2020); Zhou Y., Liu S., Siow J.K., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, Vancouver, BC, Canada, Pp. 10197– 10207, (2019)",,"6th International Conference on Frontiers in Cyber Security, FCS 2023",21 August 2023 through 23 August 2023,Chengdu,306399,English,Conference paper,Final,,Scopus,2-s2.0-85181976167,232
Chen N.; Sun Q.; Wang J.; Li X.; Gao M.,"Chen, Nuo (58443547300); Sun, Qiushi (57937339800); Wang, Jianing (57222532099); Li, Xiang (57218466858); Gao, Ming (7201511612)",58443547300; 57937339800; 57222532099; 57218466858; 7201511612,Pass-Tuning: Towards Structure-Aware Parameter-Efficient Tuning for Code Representation Learning,2023,Findings of the Association for Computational Linguistics: EMNLP 2023,,,,577,591,14,1,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183291258&partnerID=40&md5=130096fe208ad4c87992e14275cc752b,"Code pre-trained models (CodePTMs) have recently become the de-facto paradigm for various tasks in the domain of code intelligence. To achieve excellent performance, the widely used strategy is to fine-tune all the parameters of CodePTMs. However, as the model size increases along with the number of downstream tasks, this strategy becomes excessively expensive. There are also some prior works that utilize Parameter-Efficient Learning (PEL) methods for model tuning in natural language processing to mitigate similar problems, but applying them directly to CodePTMs fails to capture the inherent structural characteristics of codes. To address the problem, in this paper, we propose Pass-Tuning for structure-aware Parameter-Efficient code representation learning. Specifically, a plug-and-play graph neural network module that can learn from Abstract Syntax Tree (AST) is employed as a tunable prefix. On the one hand, Pass-Tuning can further exploit the structural information of source code. On the other hand, it could serve as a replacement for full fine-tuning. We evaluate our method on multiple tasks across eight programming languages, including code understanding and generation. These results demonstrate the effectiveness, robustness, and universality of our method. Our codes and resources are available at https://github.com/nchen909/Pass-Tuning. © 2023 Association for Computational Linguistics.","Abboud Ralph, Ceylan Ismail Ilkan, Grohe Martin, Lukasiewicz Thomas, The surprising power of graph neural networks with random node initialization, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21, pp. 2112-2118, (2021); Ahmad Wasi, Chakraborty Saikat, Ray Baishakhi, Chang Kai-Wei, Unified pre-training for program understanding and generation, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2655-2668, (2021); Allamanis Miltiadis, Sutton Charles, Mining source code repositories at massive scale using language modeling, 2013 10th Working Conference on Mining Software Repositories (MSR), pp. 207-216, (2013); Alon Uri, Levy Omer, Yahav Eran, code2seq: Generating sequences from structured representations of code, International Conference on Learning Representations, (2019); Ayupov Shamil, Chirkova Nadezhda, Parameter-efficient finetuning of transformers for source code, Efficient Natural Language and Speech Processing (ENLSP-II) workshop of the 36th Conference on Neural Information Processing Systems (NeurIPS 2022), (2022); Zaken Elad Ben, Goldberg Yoav, Ravfogel Shauli, BitFit: Simple parameter-efficient fine-tuning for transformer-based masked language-models, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pp. 1-9, (2022); Brown Tom, Mann Benjamin, Ryder Nick, Subbiah Melanie, Kaplan Jared D, Dhariwal Prafulla, Neelakantan Arvind, Shyam Pranav, Sastry Girish, Askell Amanda, Agarwal Sandhini, Herbert-Voss Ariel, Krueger Gretchen, Henighan Tom, Child Rewon, Ramesh Aditya, Ziegler Daniel, Wu Jeffrey, Winter Clemens, Hesse Chris, Chen Mark, Sigler Eric, Litwin Ma-teusz, Gray Scott, Chess Benjamin, Clark Jack, Berner Christopher, McCandlish Sam, Radford Alec, Sutskever Ilya, Amodei Dario, Language models are few-shot learners, Advances in Neural Information Processing Systems, 33, pp. 1877-1901, (2020); Buratti Luca, Pujar Saurabh, Bornea Mihaela, Mc-Carley Scott, Zheng Yunhui, Rossiello Gaetano, Morari Alessandro, Laredo Jim, Thost Veronika, Zhuang Yufan, Domeniconi Giacomo, Exploring software naturalness through neural language models, (2020); Chen Nuo, Sun Qiushi, Zhu Renyu, Li Xiang, Lu Xuesong, Gao Ming, CAT-probing: A metric-based approach to interpret how pre-trained models for programming language attend code structure, EMNLP 2022, (2022); Devlin Jacob, Chang Ming-Wei, Lee Kenton, Toutanova Kristina, BERT: Pre-training of deep bidirectional transformers for language understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 4171-4186, (2019); Ding Ning, Qin Yujia, Yang Guang, Wei Fuchao, Yang Zonghan, Su Yusheng, Hu Shengding, Chen Yulin, Chan Chi-Min, Chen Weize, Yi Jing, Zhao Weilin, Wang Xiaozhi, Liu Zhiyuan, Zheng Hai-Tao, Chen Jianfei, Liu Yang, Tang Jie, Li Juanzi, Sun Maosong, Parameter-efficient fine-tuning of large-scale pre-trained language models, Nature Machine Intelligence, 5, 3, pp. 220-235, (2023); Dong Li, Yang Nan, Wang Wenhui, Wei Furu, Liu Xi-aodong, Wang Yu, Gao Jianfeng, Zhou Ming, Hon Hsiao-Wuen, Unified language model pre-training for natural language understanding and generation, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, pp. 13042-13054, (2019); Feng Zhangyin, Guo Daya, Tang Duyu, Duan Nan, Feng Xi-aocheng, Gong Ming, Shou Linjun, Qin Bing, Liu Ting, Jiang Daxin, Zhou Ming, CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Guo Daya, Lu Shuai, Duan Nan, Wang Yanlin, Zhou Ming, Yin Jian, UniXcoder: Unified cross-modal pre-training for code representation, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 7212-7225, (2022); Guo Daya, Ren Shuo, Lu Shuai, Feng Zhangyin, Tang Duyu, LIU Shujie, Zhou Long, Duan Nan, Svyatkovskiy Alexey, Fu Shengyu, Tufano Michele, Deng Shao Kun, Clement Colin, Drain Dawn, Sundaresan Neel, Yin Jian, Jiang Daxin, Zhou Ming, GraphCodeBERT: Pre-training code representations with data flow, International Conference on Learning Representations, (2021); He Junxian, Zhou Chunting, Ma Xuezhe, Berg-Kirkpatrick Taylor, Neubig Graham, Towards a unified view of parameter-efficient transfer learning, International Conference on Learning Representations, (2022); Hindle Abram, Barr Earl T., Gabel Mark, Su Zhendong, Devanbu Premkumar T., On the naturalness of software, Commun. ACM, 59, 5, pp. 122-131, (2016); Houlsby Neil, Giurgiu Andrei, Jastrzebski Stanislaw, Morrone Bruna, De Laroussilhe Quentin, Gesmundo Andrea, Attariyan Mona, Gelly Sylvain, Parameter-efficient transfer learning for NLP, Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pp. 2790-2799, (2019); Hu Edward J, shen yelong, Wallis Phillip, Allen-Zhu Zeyuan, Li Yuanzhi, Wang Shean, Wang Lu, Chen Weizhu, LoRA: Low-rank adaptation of large language models, International Conference on Learning Representations, (2022); Husain Hamel, Wu Ho-Hsiang, Gazit Tiferet, Allamanis Miltiadis, Brockschmidt Marc, Code-searchnet challenge: Evaluating the state of semantic code search, (2019); Iyer Srinivasan, Konstas Ioannis, Cheung Alvin, Zettlemoyer Luke, Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2073-2083, (2016); Iyer Srinivasan, Konstas Ioannis, Cheung Alvin, Zettlemoyer Luke, Mapping language to code in programmatic context, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1643-1652, (2018); Kingma Diederik P., Ba Jimmy, Adam: A method for stochastic optimization, 3rd International Conference on Learning Representations, ICLR 2015, (2015); Kipf Thomas N., Welling Max, Semi-supervised classification with graph convolutional networks, International Conference on Learning Representations, (2017); Lester Brian, Al-Rfou Rami, Constant Noah, The power of scale for parameter-efficient prompt tuning, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 3045-3059, (2021); Lewis Mike, Liu Yinhan, Goyal Naman, Ghazvininejad Marjan, Mohamed Abdelrahman, Levy Omer, Stoyanov Veselin, Zettlemoyer Luke, BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 7871-7880, (2020); Li Xiang Lisa, Liang Percy, Prefix-tuning: Optimizing continuous prompts for generation, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 4582-4597, (2021); Lin Chin-Yew, Och Franz Josef, ORANGE: a method for evaluating automatic evaluation metrics for machine translation, COLING 2004: Proceedings of the 20th International Conference on Computational Linguistics, pp. 501-507, (2004); Liu Pengfei, Yuan Weizhe, Fu Jinlan, Jiang Zhengbao, Hayashi Hiroaki, Neubig Graham, Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing, CoRR, (2021); Liu Yinhan, Ott Myle, Goyal Naman, Du Jingfei, Joshi Mandar, Chen Danqi, Levy Omer, Lewis Mike, Zettlemoyer Luke, Stoyanov Veselin, RoBERTa: A robustly optimized BERT pretraining approach, (2019); Mahabadi Rabeeh Karimi, Henderson James, Ruder Sebastian, Compacter: Efficient low-rank hypercomplex adapter layers, Advances in Neural Information Processing Systems, (2021); Mou Lili, Li Ge, Zhang Lu, Wang Tao, Jin Zhi, Convolutional neural networks over tree structures for programming language processing, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, pp. 1287-1293, (2016); Nguyen Anh Tuan, Nguyen Tung Thanh, Nguyen Tien N, Divide-and-conquer approach for multi-phase statistical migration for source code (t), 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 585-596, (2015); Papineni Kishore, Roukos Salim, Ward Todd, Zhu Wei-Jing, Bleu: a method for automatic evaluation of machine translation, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Raffel Colin, Shazeer Noam, Roberts Adam, Lee Katherine, Narang Sharan, Matena Michael, Zhou Yanqi, Li Wei, Liu Peter J., Exploring the limits of transfer learning with a unified text-to-text transformer, Journal of Machine Learning Research, 21, 140, pp. 1-67, (2020); Raychev Veselin, Bielik Pavol, Vechev Martin, Probabilistic model for code with decision trees, ACM SIGPLAN Notices, pp. 731-747, (2016); Ren Shuo, Guo Daya, Lu Shuai, Zhou Long, Liu Shujie, Tang Duyu, Zhou Ming, Blanco Ambrosio, Ma Shuai, Codebleu: a method for automatic evaluation of code synthesis, (2020); Stephen Robertson, Steve Walker, Susan Jones, Micheline Hancock-Beaulieu, Mike Gatford, Okapi at trec, (1994); Sun Qiushi, Chen Nuo, Wang Jianing, Li Xiang, Gao Ming, Transcoder: Towards unified transferable code representation learning inspired by human skills, (2023); Svajlenko Jeffrey, Islam Judith F, Keivanloo Iman, Roy Chanchal K, Mia Mohammad Mamun, Towards a big data curated benchmark of inter-project code clones, 2014 IEEE International Conference on Software Maintenance and Evolution, pp. 476-480, (2014); Tufano Michele, Watson Cody, Bavota Gabriele, Di Penta Massimiliano, White Martin, Poshyvanyk Denys, An empirical study on learning bug-fixing patches in the wild via neural machine translation, ACM Transactions on Software Engineering and Methodology, 28, 4, (2019); Vaswani Ashish, Shazeer Noam, Parmar Niki, Uszkoreit Jakob, Jones Llion, Gomez Aidan N, Kaiser L ukasz, Polosukhin Illia, Attention is all you need, Advances in Neural Information Processing Systems, 30, (2017); Velickovic Petar, Cucurull Guillem, Casanova Arantxa, Romero Adriana, Lio Pietro, Bengio Yoshua, Graph attention networks, International Conference on Learning Representations, (2018); Wang Jianing, Sun Qiushi, Chen Nuo, Wang Chengyu, Huang Jun, Gao Ming, Li Xiang, Uncertainty-aware parameter-efficient self-training for semi-supervised language understanding, (2023); Wang Wenhan, Li Ge, Ma Bo, Xia Xin, Jin Zhi, Detecting code clones with graph neural network and flow-augmented abstract syntax tree, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 261-271, (2020); Wang Yue, Wang Weishi, Joty Shafiq, Hoi Steven C.H., CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 8696-8708, (2021); Yang Zhilin, Dai Zihang, Yang Yiming, Car-bonell Jaime, Salakhutdinov Russ R, Le Quoc V, XLNet: Generalized autoregressive pretraining for language understanding, Advances in Neural Information Processing Systems, 32, (2019); Zhou Yaqin, Liu Shangqing, Siow Jingkai, Du Xiaoning, Liu Yang, Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, 32, (2019); Zhu Renyu, Yuan Lei, Li Xiang, Gao Ming, Cai Wenyuan, A neural network architecture for program understanding inspired by human behaviors, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 5142-5153, (2022)",Apple; Colossal-AI; et al.; Google Research; GTCOM; King Salman Global Academy for Arabic Language,2023 Findings of the Association for Computational Linguistics: EMNLP 2023,6 December 2023 through 10 December 2023,Singapore,196127,English,Conference paper,Final,,Scopus,2-s2.0-85183291258,234
Wang R.; Xu Y.; Wu Y.,"Wang, Ruizhi (58817837300); Xu, Yanping (57190032201); Wu, Yifan (56093297500)",58817837300; 57190032201; 56093297500,Python Open-Source Code Traceability Model Based on Graph Neural Networks,2023,"2023 IEEE International Conference on Dependable, Autonomic and Secure Computing, International Conference on Pervasive Intelligence and Computing, International Conference on Cloud and Big Data Computing, International Conference on Cyber Science and Technology Congress, DASC/PiCom/CBDCom/CyberSciTech 2023",,,,806,813,7,0,10.1109/DASC/PiCom/CBDCom/Cy59711.2023.10361385,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182602964&doi=10.1109%2fDASC%2fPiCom%2fCBDCom%2fCy59711.2023.10361385&partnerID=40&md5=27f6abcf2cadb5d3996750d3f7c403bc,"When programmers write project code, they may copy or reference some open-source code, which may include defective code, causing vulnerabilities in the project. This causes a potential threat to the project and threatens the security of the software supply chain. Therefore, to protect the code security, the Python open-source code traceability model based on graph neural networks is proposed to calculate the similarity between the programmers' Python code and the Python open-source code. Firstly, each function in Python code is parsed into one Type Abstract Syntax Tree. Secondly, graph neural networks are used to calculate the function similarity between the two Type Abstract Syntax Trees of the original code and open-source code. Thirdly, the overall similarity of a Python project that consists of many functions is calculated based on the function similarity following the maximum retention principle. The experiment was conducted on three datasets: StudentWork, GitDown, and Obfuscated-GitDown. The experiment shows that the results calculated by our model are more reasonable, which places more emphasis on similarity in code structure than on code text. Taking the Pyobfuscate obfuscation scenario as an example, our model considering code structure gets similarity 18.12%39.54% higher than other methods that calculate similarity based on the code text.  © 2023 IEEE.","Du S., Lu T., Zhao L., Xu B., Guo X., Yang H., Towards an analysis of software supply chain risk management, Proceedings of the World Congress on Engineering and Computer Science, 1, (2013); Jing N., Liu Q., Sugumaran V., A blockchain-based code copyright management system, Information Processing & Management., 58, 3, (2021); Zhou J., Cui G., Hu S., Zhang Z., Yang C., Liu Z., Et al., Graph neural networks: A review of methods and applications, AI Open, pp. 57-81, (2020); Roy C.K., Cordy J.R., NICAD: Accurate detection of near-miss intentional clones using flexible pretty-printing and code normalization, 2008 16th iEEE International Conference On Program Comprehension. IEEE, (2008); Dangel A., Pelisse Pmd: copy/paste detector (cpd), (2017); Manaa E.M., Abdulameer G., Web documents similarity using k-shingle tokens and minhash technique, Journal of Engineering and Applied Sciences, 13, 6, pp. 499-1505, (2018); Al-Ssulami A.M., Azmi A.M., Mathkour H., Aboalsamh H., LsHASHq: A string matching algorithm exploiting longer q-gram shifting, Information Processing & Management, 59, 5, pp. 5241-5250, (2022); Mathew V.G., Cross-Language Code Similarity and Applications in Clone Detection and Code Search, pp. 1-17, (2022); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate tree-based detection of code clones, 29th International Conference on Software Engineering (ICSE'07), IEEE, pp. 96-105, (2007); Gao H., Zhang T., Chen S., Wang L., Yu F., FUSION: Measuring Binary Function Similarity with Code-Specific Embedding and Order-Sensitive GNN, Symmetry, 14, 12, (2022); Fu D., Xu Y., Yu H., Yang B., WASTK: A weighted abstract syntax tree kernel method for source code plagiarism detection, Scientific Programming, (2017); Bai Y., Ding H., Bian S., Chen T., Sun Y., Wang W., Simgnn: A neural network approach to fast graph similarity computation, Proceedings Of The Twelfth ACM International Conference On Web Search And Data Mining, pp. 384-392, (2019); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, pp. 2-12, (2016); Socher R., Chen D., Manning C.D., Ng A., Reasoning with neural tensor networks for knowledge base completion, Advances In Neural Information Processing Systems, 26, pp. 926-934, (2013); Pawlik M., Augsten N., Tree edit distance: Robust and memory-efficient, Information Systems, 56, pp. 157-173, (2016); Wang J., Dong Y., Measurement of text similarity: A survey, Information, 11, 9, (2020); Pyobfuscate: Python source code obfuscator, (2023)",,"2023 IEEE International Conference on Dependable, Autonomic and Secure Computing, 2023 International Conference on Pervasive Intelligence and Computing, 2023 International Conference on Cloud and Big Data Computing, 2023 International Conference on Cyber Science and Technology Congress, DASC/PiCom/CBDCom/CyberSciTech 2023",14 November 2023 through 17 November 2023,Abu Dhabi,195843,English,Conference paper,Final,,Scopus,2-s2.0-85182602964,235
Wen X.-C.; Gao C.; Ye J.; Li Y.; Tian Z.; Jia Y.; Wang X.,"Wen, Xin-Cheng (57226098194); Gao, Cuiyun (57189036288); Ye, Jiaxin (57485104000); Li, Yichen (57386920000); Tian, Zhihong (9636602700); Jia, Yan (34770316700); Wang, Xuan (57192625391)",57226098194; 57189036288; 57485104000; 57386920000; 9636602700; 34770316700; 57192625391,Meta-Path Based Attentional Graph Learning Model for Vulnerability Detection,2024,IEEE Transactions on Software Engineering,50,3,,360,375,15,0,10.1109/TSE.2023.3340267,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181565485&doi=10.1109%2fTSE.2023.3340267&partnerID=40&md5=9c9216204be8bcbf11c14281c7e7a27f,"In recent years, deep learning (DL)-based methods have been widely used in code vulnerability detection. The DL-based methods typically extract structural information from source code, e.g., code structure graph, and adopt neural networks such as Graph Neural Networks (GNNs) to learn the graph representations. However, these methods fail to consider the heterogeneous relations in the code structure graph, i.e., the heterogeneous relations mean that the different types of edges connect different types of nodes in the graph, which may obstruct the graph representation learning. Besides, these methods are limited in capturing long-range dependencies due to the deep levels in the code structure graph. In this paper, we propose a Meta-path based Attentional Graph learning model for code vulNErability deTection, called MAGNET. MAGNET constructs a multi-granularity meta-path graph for each code snippet, in which the heterogeneous relations are denoted as meta-paths to represent the structural information. A meta-path based hierarchical attentional graph neural network is also proposed to capture the relations between distant nodes in the graph. We evaluate MAGNET on three public datasets and the results show that MAGNET outperforms the best baseline method in terms of F1 score by 6.32%, 21.50%, and 25.40%, respectively. MAGNET also achieves the best performance among all the baseline methods in detecting Top-25 most dangerous Common Weakness Enumerations (CWEs), further demonstrating its effectiveness in vulnerability detection.  © 1976-2012 IEEE.","Ghaffarian S.M., Shahriari H.R., Software vulnerability analysis and discovery using machine-learning and data-mining techniques: A survey, ACM Comput. Surv., 50, 4, pp. 561-5636, (2017); Johnson A., Et al., Guide for Security-focused Configuration Management of Information Systems, (2011); Wei Y., Sun X., Bo L., Cao S., Xia X., Li B., A comprehensive study on security bug characteristics, J. Softw. Evol. Process., 33, 10, (2021); Tan Q., Wang X., Shi W., Tang J., Tian Z., An anonymity vulnerability in Tor, IEEE/ACM Trans. Netw., 30, 6, pp. 2574-2587, (2022); Priority One Report.; Neuhaus S., Zimmermann T., Holler C., Zeller A., Predicting vulnerable software components, Proc. ACM Conf. Comput. Commun. Secur. (CCS), pp. 529-540, (2007); Scandariato R., Walden J., Hovsepyan A., Joosen W., Predicting vulnerable software components via text mining, IEEE Trans. Softw. Eng., 40, 10, pp. 993-1006, (2014); Shin Y., Meneely A., Williams L.A., Osborne J.A., Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities, IEEE Trans. Softw. Eng., 37, 6, pp. 772-787, (2011); Wu Y., Zou D., Dou S., Yang W., Xu D., Jin H., VulCNN: An image-inspired scalable vulnerability detection system, Proc. 44th IEEE/ACM 44th Int. Conf. Softw. Eng. (ICSE), pp. 2365-2376, (2022); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., SySeVR: A framework for using deep learning to detect software vulnerabilities, IEEE Trans. Dependable Secure Comput., 19, 4, pp. 2244-2258, (2022); Hin D., Kan A., Chen H., Babar M.A., LineVD: Statementlevel vulnerability detection using graph neural networks, Proc. 19th Int. Conf. Mining Softw. Repositories (MSR), pp. 596-607, (2022); Fu M., Tantithamthavorn C., LineVul: A transformer-based linelevel vulnerability prediction, Proc. 19th Int. Conf. Mining Softw. Repositories (MSR), pp. 608-620, (2022); Zhou Y., Liu S., Siow J.K., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Proc. Adv. Neural Inf. Process. Syst. 32, Annu. Conf. Neural Inf. Process. Syst. (NeurIPS), pp. 10197-10207, (2019); Cao S., Sun X., Bo L., Wu R., Li B., Tao C., MVD: Memory-related vulnerability detection based on flow-sensitive graph neural networks, Proc. 44th Int. Conf. Softw. Eng. (ICSE), pp. 1456-1468, (2022); Wang H., Et al., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans. Inf. Forensics Security, 16, pp. 1943-1958, (2021); Li Z., Et al., VulDeePecker: A Deep Learning-based System for Vulnerability Detection, (2018); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet?, IEEE Trans. Softw. Eng., 48, 9, pp. 3280-3296, (2022); Li Y., Wang S., Nguyen T.N., Vulnerability detection with finegrained interpretations, Proc. 29th ACM Joint Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng. (ESEC/FSE), pp. 292-303, (2021); Siow J.K., Liu S., Xie X., Meng G., Liu Y., Learning program semantics with code representations: An empirical study, Proc. IEEE Int. Conf. Softw. Anal., Evol. Reeng. (SANER), pp. 554-565, (2022); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, Proc. IEEE Symp. Secur. Privacy (SP), pp. 590-604, (2014); Neamtiu I., Foster J.S., Hicks M., Understanding source code evolution using abstract syntax tree matching, ACM SIGSOFT Softw. Eng. Notes, 30, 4, pp. 1-5, (2005); Huo X., Li M., Zhou Z., Control flow graph embedding based on multi-instance decomposition for bug localization, Proc. 34th AAAI Conf. Artif. Intell. (AAAI), 32nd Innovative Appl. Artif. Intell. Conf. (IAAI), 10th AAAI Symp. Educ. Adv. Artif. Intell. (EAAI), pp. 4223-4230, (2020); Cummins C., Fisches Z.V., Ben-Nun T., Hoefler T., O'Boyle M.F.P., Leather H., ProGraML: A graph-based program representation for data flow analysis and compiler optimizations, Proc. 38th Int. Conf. Mach. Learn. (ICML), 139, pp. 2244-2253, (2021); Russell R.L., Et al., Automated vulnerability detection in source code using deep representation learning, Proc. 17th IEEE Int. Conf. Mach. Learn. Appl. (ICMLA), pp. 757-762, (2018); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, Proc. 5th Int. Conf. Learn. Representations (ICLR), (2017); Li Y., Tarlow D., Brockschmidt M., Zemel R.S., Gated graph sequence neural networks, Proc. 4th Int. Conf. Learn. Representations (ICLR), (2016); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph Attention Networks, (2017); Wang X., Et al., HELoC: Hierarchical contrastive learning of source code representation, Proc. 30th IEEE/ACM Int. Conf. Program Comprehension (ICPC), pp. 354-365, (2022); Min W., Rongcun W., Shujuan J., Source code vulnerability detection based on relational graph convolution network, J. Comput. Appl., 42, 6, (2022); Liu F., Cheng Z., Zhu L., Gao Z., Nie L., Interest-aware messagepassing GCN for recommendation, Proc. Web Conf. (WWW), pp. 1296-1305, (2021); Alon U., Yahav E., On the bottleneck of graph neural networks and its practical implications, Proc. 9th Int. Conf. Learn. Representations (ICLR), (2021); Guo D., Et al., GraphCodeBERT: Pre-training code representations with data flow, Proc. 9th Int. Conf. Learn. Representations (ICLR), (2021); Zhu D., Dai X., Chen J., Pre-train and learn: Preserving global information for graph neural networks, J. Comput. Sci. Technol., 36, 6, pp. 1420-1430, (2021); Li Q., Han Z., Wu X., Deeper insights into graph convolutional networks for semi-supervised learning, Proc. 32nd AAAI Conf. Artif. Intell. (AAAI), 30th Innovative Appl. Artif. Intell. (IAAI), 8th AAAI Symp. Educ. Adv. Artif. Intell. (EAAI), pp. 3538-3545, (2018); Xiong Y., Zhang Y., Kong X., Chen H., Zhu Y., Graphinception: Convolutional neural networks for collective classification in heterogeneous information networks, IEEE Trans. Knowl. Data Eng., 33, 5, pp. 1960-1972, (2021); Fan J., Li Y., Wang S., Nguyen T.N., A C/C++ code vulnerability dataset with code changes and CVE summaries, Proc.17th Int. Conf. Mining Softw. Repositories (MSR), Seoul, Republic of Korea, pp. 508-512, (2020); CWE-839: Numeric Range Comparison Without Minimum Check.; CWE-476: Null Pointer Dereference.; Church K.W., Word2vec, Nat. Lang. Eng., 23, 1, pp. 155-162, (2017); Rabin M.R.I., Bui N.D.Q., Wang K., Yu Y., Jiang L., Alipour M.A., On the generalizability of neural program models with respect to semantic-preserving program transformations, Inf. Softw. Technol., 135, (2021); Zhang H., Li Z., Li G., Ma L., Liu Y., Jin Z., Generating adversarial examples for holding robustness of source code processing models, Proc. 34th AAAI Conf. Artif. Intell. (AAAI), 32nd Innovative Appl. Artif. Intell. Conf. (IAAI), 10th AAAI Symp. Educ. Adv. Artif. Intell. (EAAI), pp. 1169-1176, (2020); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, Proc. 6th Int. Conf. Learn. Representations (ICLR), (2018); Wu Y., Et al., SCDetector: Software functional clone detection based on semantic tokens analysis, Proc. 35th IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 821-833, (2020); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, Proc. 27th IEEE Int. Conf. Softw. Anal., pp. 261-271, (2020); Hua W., Sui Y., Wan Y., Liu G., Xu G., FCCA: Hybrid code representation for functional clone detection using attention networks, IEEE Trans. Rel., 70, 1, pp. 304-318, (2021); Lu J., Yu X., Chen G., Cheng D., Characterizing the synchronizability of small-world dynamical networks, IEEE Trans. Circuits Syst. I, Reg. Papers, 51, 4, pp. 787-796, (2004); Sun Y., Han J., Yan X., Yu P.S., Wu T., PathSim: Meta path-based top-K similarity search in heterogeneous information networks, Proc. VLDB Endow., 4, 11, pp. 992-1003, (2011); Landin P.J., The mechanical evaluation of expressions, Comput. J., 6, 4, pp. 308-320, (1964); Wang C., Song Y., Li H., Zhang M., Han J., Unsupervised meta-path selection for text similarity measure based on heterogeneous information networks, Data Min. Knowl. Discovery, 32, 6, pp. 1735-1767, (2018); Ning W., Et al., Automatic meta-path discovery for effective graph-based recommendation, Proc. 31st ACM Int. Conf. Inf. Knowl. Manage., pp. 1563-1572, (2022); He K., Zhang X., Ren S., Sun J., Identity mappings in deep residual networks, Proc. Comput. Vision-14th Eur. Conf. (ECCV), Amsterdam, the Netherlands, 9908, pp. 630-645, (2016); Sun L., Chen Z., Wu Q.M.J., Zhao H., He W., Yan X., AMPNet: Average-and max-pool networks for salient object detection, IEEE Trans. Circuits Syst. Video Technol., 31, 11, pp. 4321-4333, (2021); Woo S., Park J., Lee J., Kweon I.S., CBAM: Convolutional block attention module, Proc. Comput. Vision-15th Eur. Conf. (ECCV), pp. 3-19, (2018); Bahdanau D., Cho K., Bengio Y., Neural machine translation by jointly learning to align and translate, Proc. 3rd Int. Conf. Learn. Representations (ICLR), (2015); De Boer P., Kroese D.P., Mannor S., Rubinstein R.Y., A tutorial on the cross-entropy method, Ann. Oper. Res., 134, 1, pp. 19-67, (2005); Paszke A., Et al., PyTorch: An imperative style, high-performance deep learning library, Proc. Adv. Neural Inf. Process. Syst. 32, Annu. Conf. Neural Inf. Process. Syst. (NeurIPS), pp. 8024-8035, (2019); Wang M., Et al., Deep graph library: Towards efficient and scalable deep learning on graphs, Proc. ICLR Workshop Representation Learn. Graphs Manifolds, (2019); Zhang Z., Improved adam optimizer for deep neural networks, Proc. 26th IEEE/ACM Int. Symp. Qual. Service (IWQoS), pp. 1-2, (2018); Dermaaten Laurens V., Geoffrey H., Visualizing data using t-SNE, J. Mach. Learn. Res., 9, 11, (2008); Mao C., Zhong Z., Yang J., Vondrick C., Ray B., Metric learning for adversarial robustness, Proc. Adv. Neural Inf. Process. Syst. 32, Annu. Conf. Neural Inf. Process. Syst. (NeurIPS), pp. 478-489, (2019); Common Weakness Enumeratio.; 2021 CWE Top 25 Most Dangerous Software Weaknesses.; CWE-119: Improper Restriction of Operations Within the Bounds of A Memory Buffer.; CWE-20: Improper Input Validation.; CWE-287: Improper Authentication.; Feng Z., Et al., CodeBERT: A pre-trained model for programming and natural languages, Proc. Findings Assoc. Comput. Linguistics (EMNLP), pp. 1536-1547, (2020); Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating sequences from structured representations of code, Proc. 7th Int. Conf. Learn. Representations (ICLR), (2019); Nguyen V., Le T., De Vel O.Y., Montague P., Grundy J., Phung D., Information-theoretic source code vulnerability highlighting, Proc. Int. Joint Conf. Neural Netw. (IJCNN), pp. 1-8, (2021); Kamiya T., Kusumoto S., Inoue K., CCFinder: A multilinguistic token-based code clone detection system for large scale source code, IEEE Trans. Softw. Eng., 28, 7, pp. 654-670, (2002); Kim Y., Convolutional neural networks for sentence classification, Proc. Conf. Empirical Methods Natural Lang. Process. (EMNLP), pp. 1746-1751, (2014); Tang D., Qin B., Liu T., Document modeling with gated recurrent neural network for sentiment classification, Proc. Conf. Empirical Methods Natural Lang. Process. (EMNLP), pp. 1422-1432, (2015); Graves A., Schmidhuber J., Framewise phoneme classification with bidirectional LSTM and other neural network architectures, Neural Netw., 18, 5-6, pp. 602-610, (2005); Cheng X., Et al., Static detection of control-flow-related vulnerabilities using graph embedding, Proc. 24th Int. Conf. Eng. Complex Comput. Syst. (ICECCS), pp. 41-50, (2019); Ding Y., Et al., VELVET: A novel ensemble learning approach to automatically locate vulnerable statements, Proc. IEEE Int. Conf. Softw. Anal., Evol. Reeng. (SANER), pp. 959-970, (2022); Li Y., Wang S., Nguyen T.N., Nguyen S.V., Improving bug detection via context-based code representation learning and attention-based neural networks, Proc. ACM Program. Lang., 3, pp. 1621-16230, (2019)",,,,,,English,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85181565485,236
Zhang Z.; Liu L.; Chang J.; Wang L.; Liao L.,"Zhang, Zaixing (58815359400); Liu, Liang (58815246500); Chang, Jianming (58815392300); Wang, Lulu (36663167700); Liao, Li (9733600600)",58815359400; 58815246500; 58815392300; 36663167700; 9733600600,Commit Classification via Diff-Code GCN based on System Dependency Graph,2023,"IEEE International Conference on Software Quality, Reliability and Security, QRS",,,,476,487,11,0,10.1109/QRS60937.2023.00053,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182520712&doi=10.1109%2fQRS60937.2023.00053&partnerID=40&md5=eaee00d90d1ca5c9b7f9598b67000bfb,"Commit Classification, an automated process of classifying Diff-Code based on their purpose, plays a crucial role in enhancing comprehension and the quality of software. Some previous studies only used commit messages or code metrics to represent diff-code but lacked code context structure characterization. Alternatively, other studies have used Abstract Syntax Trees (ASTs) tokens to represent diff-code but did not consider contextual information like data dependency and control dependency. In this paper, we propose a new commit classification model called Diff-Code GCN (Graph Convolutional Network). Specifically, we firstly build a more detailed system dependency graph (SDG) of the commit, and secondly use program slicing to search the impact scope of diff-code. Thirdly, we extract the scope as a Change Impact Graph (CIG). We utilize GCN to extract contextual information from CIG and combine it with syntactic changed information of ASTs to represent the commit. Finally, we classify the commit into three maintenance categories (corrective, perfective, and adaptive). We evaluate our model based on commonly used datasets and compare our model with popular commit classification approaches. The experiment result well shows that both in within-project and cross-project prediction tasks, our model performs better than baseline models.  © 2023 IEEE.","Wang T., Tao C., Guo H., Tang L., Semantic Feature Learning based on Double Sequences Structure for Software Defect Number Prediction, 2022 IEEE 22nd International Conference on Software Quality, Reliability and Security (QRS), pp. 157-166, (2022); Hoang T., Kang H.J., Lo D., Lawall J., CC2Vec: Distributed representations of code changes, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, (2020); Hnel S., Ericsson M., Lwe W., Wingkvist A., Importance and Aptitude of Source Code Density for Commit Classification into Maintenance Activities, International Conference on Software Quality, Reliability and Security; Liu Z., Xia X., Hassan A.E., Lo D., Xing Z., Wang X., Neural-machine-translation-based commit message generation: How far are we, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering; Lozoya R.C., Baumann A., Sabetta A., Bezzi M., Commit2Vec: Learning Distributed Representations of Code Changes, SN Computer Science, 2, 3, (2021); Jiang S., Armaly A., McMillan C., Automatically generating commit messages from diffs using neural machine translation, 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 135-146, (2017); Loyola P., Marrese-Taylor E., Matsuo Y., A Neural Architecture for Generating Natural Language Descriptions from Source Code Changes, (2017); Jiang S., Boosting Neural Commit Message Generation with Code Semantic Analysis, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 1280-1282, (2019); Nie L.Y., Gao C., Zhong Z., Lam W., Xu Z., CoreGen: Contextualized Code Representation Learning for Commit Message Generation, Neurocomputing, 459, (2021); Xu J., Wang F., Ai J.J.I.T.O.R., Defect Prediction With Semantics and Context Features of Codes Based on Graph Representation Learning, PP, 99, pp. 1-13, (2020); Dong J., Et al., FIRA: Fine-Grained Graph-Based Code Change Representation for Automated Commit Message Generation, Proceedings of the 44th IEEE/ACM International Conference on Software Engineering (ICSE), pp. 970-981, (2022); Wang H., Xia X., Lo D., He Q., Wang X., Grundy J., Context-aware Retrieval-based Deep Commit Message Generation, 30, 4; Ghadhab L., Jenhani I., Mkaouer M.W., Ben Messaoud M., Augmenting commit classification by using fine-grained source code changes and a pretrained deep neural language model, Information and Software Technology, 135, (2021); Hindle A., German D.M., Godfrey M.W., Holt R.C., Automatic classication of large changes into maintenance categories, 2009 IEEE 17th International Conference on Program Comprehension, pp. 30-39, (2009); Swanson B.E., The Dimensions of Maintenance, Proceedings of the 2nd International Conference on Software Engineering, (1976); Zafar S., Malik M.Z., Walia G.S., Towards Standardizing and Improving Classification of Bug-Fix Commits, 2019 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM), (2019); Levin S., Yehudai A., Using Temporal and Semantic Developer-Level Information to Predict Maintenance Activity Profiles, 2016 IEEE International Conference on Software Maintenance and Evolution (ICSME), (2016); Amor J.J., Robles G., Gonzalezbarahona J.M., Navarro A., Discriminating Development Activities in Versioning Systems: A Case Study, (2008); Purushothaman R.J.I.T.S.E., Towards understanding the rhetoric of small changes, 31, (2005); Devlin J., Chang M.W., Lee K., Toutanova K., BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, (2018); Blondel V.D., Guillaume J.L., Lambiotte R., Lefebvre E., Fast unfolding of communities in large networks, (2008); Mariano R.V.R., Viggiato M., Santos G.E.D., Brandao W.C., Feature changes in source code for commit classification into maintenance activities, IEEE International Conference on Machine Learning and Applications, (2019); Myers E.W.J.A., An O(ND) Difference Algorithm and Its Variations, 1, 1-4, pp. 251-266, (1986); Lulu W., Bixin L., Xianglong K.J.I., Technology S., Type slicing: An accurate object oriented slicing based on sub-statement level dependence graph-ScienceDirect, 127, (2020); Zhang M., Cui Z., Neumann M., Chen Y., An End-to-End Deep Learning Architecture for Graph Classification, Proceedings of the AAAI Conference on Artificial Intelligence, 32, 1, (2018); Kipf T.N., Welling M., Semi-Supervised Classification with Graph Convolutional Networks, (2016); Wang H., Zhuang W., Zhang X., Software Defect Prediction Based on Gated Hierarchical LSTMs, IEEE Transactions on Reliability, 70, 2, pp. 711-727, (2021); Gupta M., Serebrenik A., Jalote P., Improving Software Maintenance Using Process Mining and Predictive Analytics, 2017 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 681-686, (2017); Tip F., A survey of program slicing techniques. Centrum voor Wiskunde en Informatica Amsterdam, (1994); Weiser M.J.C.O.T.A., Programmers use slices when debugging, 25, 7, pp. 446-452, (1982); Binkley D.W., Gallagher K.B.J.A.I.C., Program Slicing, 43, 11, pp. 1-50, (1996); Weiser M.D., Program Slices: Formal, Psychological, and Practical Investigations of an Automatic Program Abstraction Method, (1979); Galindo C., Perez S., Silva J., Program Slicing Techniques with Support for Unconditional Jumps, International Conference on Formal Engineering Methods, pp. 123-139, (2022); Galindo C., Perez S., Silva J., Exceptionsensitive program slicing, Journal of Logical and Algebraic Methods in Programming, 130, (2023); Lulu W., Bixin L., Xianglong K., Statementlevel system dependence graph for program slicing in object-oriented programs, Information and Software Technology, 127, (2020); Nanda M.G., Agrawal H., Program slicing based on data dependence graph, Journal of Systems and Software, 80, 7, pp. 1103-1115, (2007); Qu Y., Et al., node2defect: Using network embedding to improve software defect prediction, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering; Mauczka A., Brosch F., Schanes C., Grechenig T., Dataset of developer-labeled commit messages, 2015 IEEE/ACM 12th Working Conference on Mining Software Repositories, pp. 490-493, (2015); Fluri B., Wursch M., Inzger M.P., Gall H.J.I.T.O.S.E., Change distilling: Tree differencing for finegrained source code change extraction, 33, 11, pp. 725-743, (2007); Tsantalis N., Mansouri M., Eshkevari L.M., Mazinanian D., Dig D., Accurate and efficient refactoring detection in commit history, Proceedings of the 40th international conference on software engineering, pp. 483-494, (2018); Liu S., Gao C., Chen S., Nie L.Y., Liu Y.J.I.T.O.S.E., ATOM: Commit message generation based on abstract syntax tree and hybrid ranking, 48, 5, pp. 1800-1817, (2020); Spadini D., Aniche M., Bacchelli A., Py-Driller: Python framework for mining software repositories, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering-ESEC/FSE 2018, pp. 908-911, (2018); Shervashidze N., Schweitzer P., Leeuwen E.J.V., Mehlhorn K., Borgwardt K.M., Weisfeilerlehman graph kernels, Journal of Machine Learning Research, 12, pp. 2539-2561, (2011); Meng N., Jiang Z., Zhong H., Classifying Code Commits with Convolutional Neural Networks, 2021 International Joint Conference on Neural Networks (IJCNN), pp. 1-8, (2021); Wang S., Wang X., Sun K., Jajodia S., Wang H., Li Q., GraphSPD: Graph-Based Security Patch Detection with Enriched Code Semantics, 2023 IEEE Symposium on Security and Privacy (SP), pp. 2409-2426, (2023)",,"23rd IEEE International Conference on Software Quality, Reliability, and Security, QRS 2023",22 October 2023 through 26 October 2023,Chiang Mai,195900,English,Conference paper,Final,,Scopus,2-s2.0-85182520712,237
Chen S.; Xu S.; Yao Y.; Xu F.,"Chen, Siyu (57921401800); Xu, Shengbin (57211750535); Yao, Yuan (57192069374); Xu, Feng (56401380100)",57921401800; 57211750535; 57192069374; 56401380100,Untangling Composite Commits by Attributed Graph Clustering,2022,ACM International Conference Proceeding Series,,,,117,126,9,1,10.1145/3545258.3545267,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139556972&doi=10.1145%2f3545258.3545267&partnerID=40&md5=243fc68212f7e1da0843bdafb29510f9,"During software development, it is considered to be a best practice if each commit represents one distinct concern, such as fixing a bug or adding a new feature. However, developers may not always follow this practice and sometimes tangle multiple concerns into a single composite commit. This makes automatic commit untangling a necessary task, and recent approaches mainly untangle commits via applying graph clustering on the code dependency graph. In this paper, we propose a new commit untangling approach, ComUnt, to decompose the composite commits into atomic ones. Different from existing approaches, ComUnt is built upon the observation that both the textual content of code statements and the dependencies between code statements contain useful semantic information so as to better comprehend the committed code changes. Based on this observation, ComUnt first constructs an attributed graph for each commit, where code statements and various code dependencies are modeled as nodes and edges, respectively, and the textual body of code statements are maintained as node attributes. It then conducts attributed graph clustering on the constructed graph. The used attributed graph clustering algorithm can simultaneously encode both graph structure and node attributes so as to better separate the code changes into clusters with distinct concerns. We evaluate our approach on nine C# projects, and the experimental result shows that ComUnt improves the state-of-the-art by 7.8% in terms of untangling accuracy, and meanwhile it is more than 6 times faster.  © 2022 Association for Computing Machinery.","Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, International Conference on Learning Representations, (2018); Barnett M., Bird C., Brunet J., Lahiri S.K., Helping developers help themselves: Automatic decomposition of code review changesets, 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, 1, pp. 134-144, (2015); Bo D., Wang X., Shi C., Zhu M., Lu E., Cui P., Structural deep clustering network, Proceedings of The Web Conference 2020, pp. 1400-1410, (2020); Brandes U., Gaertler M., Wagner D., Experiments on graph clustering algorithms, European Symposium on Algorithms, pp. 568-579, (2003); Carrasco J.J., Fain D.C., Lang K.J., Zhukov L., Clustering of Bipartite Advertiser-Keyword Graph, (2003); Dash S.K., Allamanis M., Barr E.T., Refinym: Using names to refine types, Proceedings of The 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on The Foundations of Software Engineering, pp. 107-117, (2018); Devlin J., Chang M.-W., Lee K., Toutanova K., BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, North American Chapter of The Association for Computational Linguistics: Human Language Technologies, pp. 4171-4186, (2019); Dias M., Bacchelli A., Gousios G., Cassou D., Ducasse S., Untangling fine-grained code changes, 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER), pp. 341-350, (2015); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Transactions on Programming Languages and Systems (TOPLAS), 9, 3, pp. 319-349, (1987); Flake G.W., Lawrence S., Coetzee F.M., Self-organization and identification of web communities, Computer, 35, 3, pp. 66-70, (2002); Frey B.J., Dueck D., Clustering by passing messages between data points, Science, 315, 5814, pp. 972-976, (2007); Gkantsidis C., Mihail M., Zegura E., Spectral analysis of Internet topologies, IEEE INFOCOM 2003. Twenty-Second Annual Joint Conference of The IEEE Computer and Communications Societies, 1, pp. 364-374, (2003); Guo B., Song M., Interactively decomposing composite changes to support code review and regression testing, 2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC), 1, pp. 118-127, (2017); Hartigan J.A., Wong M.A., Algorithm AS 136: A k-means clustering algorithm, Journal of The Royal Statistical Society. Series C (Applied Statistics), 28, 1, pp. 100-108, (1979); Herbold S., Trautsch A., Ledel B., Aghamohammadi A., Ghaleb T.A., Chahal K.K., Bossenmaier T., Nagaria B., Makedonski P., Ahmadabadi M.N., Et al., A Fine-Grained Data Set and Analysis of Tangling in Bug Fixing Commits, (2020); Herzig K., Just S., Zeller A., The impact of tangled code changes on defect prediction models, Empirical Software Engineering, 21, 2, pp. 303-336, (2016); Herzig K., Zeller A., The impact of tangled code changes, 2013 10th Working Conference on Mining Software Repositories (MSR), pp. 121-130, (2013); Hindle A., Barr E.T., Gabel M., Su Z., Devanbu P., On the naturalness of software, Commun. ACM, 59, 5, pp. 122-131, (2016); Kavi K.M., Buckles B.P., A formal definition of data flow graph models, IEEE Transactions on Computers, 35, 11, pp. 940-948, (1986); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, International Conference on Learning Representations, (2017); Kirinuki H., Higo Y., Hotta K., Kusumoto S., Splitting commits via past code changes, 2016 23rd Asia-Pacific Software Engineering Conference (APSEC), pp. 129-136, (2016); Malathi D., A novel method to find time complexity of an algorithm by using control flow graph, 2017 International Conference on Technical Advancements in Computers and Communications (ICTACC), pp. 66-68, (2017); Madhulatha T.S., An overview on clustering methods, IOSR Journal of Engineering, 2, (2012); Mihail M., Gkantsidis C., Saberi A., On The Semantics of Internet Topologies, (2002); Muylaert W., de Roover C., Untangling composite commits using program slicing, 2018 IEEE 18th International Working Conference on Source Code Analysis and Manipulation (SCAM), pp. 193-202, (2018); Nguyen A.T., Nguyen T.N., Graph-based statistical language model for code, 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, 1, pp. 858-868, (2015); Nguyen H.A., Nguyen A.T., Nguyen T.N., Filtering noise in mixed-purpose fixing commits to improve defect prediction and localization, 2013 IEEE 24th International Symposium on Software Reliability Engineering (ISSRE), pp. 138-147, (2013); Nguyen H.A., Nguyen T.N., Dig D., Nguyen S., Tran H., Hilton M., Graph-based mining of in-the-wild, fine-grained, semantic code change patterns, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 819-830, (2019); Dash S.K., Allamanis M., Barr E.T., Flexeme: Untangling commits using lexical flows, Proceedings of The 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on The Foundations of Software Engineering, pp. 63-74, (2020); Shen B., Zhang W., Kastner C., Zhao H., Wei Z., Liang G., Jin Z., SmartCommit: A graph-based interactive assistant for activity-oriented commits, Proceedings of The 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on The Foundations of Software Engineering, pp. 379-390, (2021); Shen B., Zhang W., Zhao H., Liang G., Jin Z., Wang Q., Intellimerge: A refactoring-aware software merging technique, Proceedings of The ACM on Programming Languages, 3, pp. 1-28, (2019); Sothornprapakorn S., Hayashi S., Saeki M., Visualizing a tangled change for supporting its decomposition and commit construction, 2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC), 1, pp. 74-79, (2018); Tao Y., Dang Y., Xie T., Zhang D., Kim S., How do software engineers understand code changes? An exploratory study in industry, Proceedings of The ACM SIGSOFT 20th International Symposium on The Foundations of Software Engineering, pp. 1-11, (2012); Tao Y., Kim S., Partitioning composite code changes to facilitate code review, 2015 IEEE/ACM 12th Working Conference on Mining Software Repositories, pp. 180-190, (2015); Tian F., Gao B., Cui Q., Chen E., Liu T.-Y., Learning deep representations for graph clustering, Proceedings of The AAAI Conference on Artificial Intelligence, 28, (2014); Wang C., Pan S., Hu R., Long G., Jiang J., Zhang C., Attributed graph clustering: A deep attentional embedding approach, Proceedings of The 28th International Joint Conference on Artificial Intelligence, pp. 3670-3676, (2019); Wang M., Lin Z., Zou Y., Xie B., CORA: Decomposing and describing tangled code changes for reviewer, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 1050-1061, (2019); Wang W., Zhang K., Li G., Jin Z., Learning to Represent Programs with Heterogeneous Graphs, (2021); Xu K., Hu W., Leskovec J., Jegelka S., How powerful are graph neural networks?, International Conference on Learning Representations, (2019); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, pp. 590-604, (2014); Yamashita S., Hayashi S., Saeki M., ChangeBeadsthreader: An interactive environment for tailoring automatically untangled changes, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 657-661, (2020); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 783-794, (2019); Zhang X., Liu H., Li Q., Wu X.-M., Attributed graph clustering via adaptive graph convolution, Proceedings of The 28th International Joint Conference on Artificial Intelligence, pp. 4327-4333, (2019); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in Neural Information Processing Systems, 32, 2019, (2019)",,"13th Asia-Pacific Symposium on Internetware, Internetware 2022",11 June 2022 through 12 June 2022,"Virtual, Online",182765,English,Conference paper,Final,,Scopus,2-s2.0-85139556972,238
Chourasia P.; Ramakrishnan G.; Apte V.; Kumar S.,"Chourasia, Pranshu (57773622700); Ramakrishnan, Ganesh (12140784800); Apte, Varsha (22833682700); Kumar, Suraj (57738863400)",57773622700; 12140784800; 22833682700; 57738863400,Algorithm Identification in Programming Assignments,2022,IEEE International Conference on Program Comprehension,2022-March,,,471,481,10,0,10.1145/3524610.3527914,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133208644&doi=10.1145%2f3524610.3527914&partnerID=40&md5=6a56c84be9f2726f6427bcd02ca3cbe6,"Current autograders of programming assignments are typically program output based; they fall short in many ways: e.g. they do not carry out subjective evaluations such as code quality, or whether the code has followed any instructor specified constraints; this is still done manually by teaching assistants. In this paper, we tackle a specific aspect of such evaluation: to verify whether a program implements a specific algorithm that the instructor specified. An algorithm, e.g. bubble sort, can be coded in myriad different ways, but a human can always understand the code and spot, say a bubble sort, vs. a selection sort. We develop and compare four approaches to do precisely this: given the source code of a program known to implement a certain functionality, identify the algorithm used, among a known set of algorithms. The approaches are based on code similarity, Support Vector Machine (SVM) with tree or graph kernels, and transformer neural architectures based only source code (CodeBERT), and the extension of this that includes code structure (GraphCodeBERT). Furthermore, we use a model for explainability (LIME) to generate insights into why certain programs get certain labels. Results based on our datasets of sorting, searching and shortest path codes, show that GraphCodeBERT, fine-tuned with scrambled source code, i.e., where identifiers are replaced consistently with arbitrary words, gives the best performance in algorithm identification, with accuracy of 96-99% depending on the functionality. Additionally, we add uncalled function source code elimination to our pre-processing pipeline of test programs, to improve the accuracy of classification of obfuscated source code.  © 2022 ACM.","Code Analysis, Joern Tool; Aizu Online Judge; Metacpan Making Graph Easy; Bubble sort; Insertion sort; Linear Search; Selection sort; Precision and Recall; Graph Kernel, GraKel repository; Open source CodeBERT model; Bubble sort; Insertion sort; Selection sort; CodeBERT and GraphCodeBERT; Tree Sitter; Towards Data Science. F1 Score; Tree Kernel; Chourasia P., Kumar S., Code and Dataset Repository for ICPC 2022, (2022); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., CodeBERT: A pre-trained model for programming and natural languages, (2020); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Kun Deng S., Clement C.B., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., GraphCodeBERT: Pre-training Code Representations with Data Flow, (2020); Kaleeswaran S., Santhiar A., Kanade A., Gulwani S., Semi-supervised verified feedback generation, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, (2016); Kim S., Zhao J., Tian Y., Chandra S., Code prediction by feeding trees to transformers, IEEE/ACM 43rd International Conference on Software Engineering (ICSE), (2021); Kriege N.M., Johansson F.D., Morris C., A survey on graph kernels, Applied Network Science, 5, 1, (2020); Li J., Wang Y., Lyu M.R., King I., Code completion with neural attention and pointer networks, (2017); Maletic J.I., Valluri N., Automatic software clustering via Latent Semantic Analysis, 14th IEEE International Conference on Automated Software Engineering (1999), pp. 251-254, (1999); Moschitti A., Making tree kernels practical for natural language learning, 11th conference of the European Chapter of the Association for Computational Linguistics, (2006); Ohashi H., Watanobe Y., Convolutional Neural Network for Classification of Source Codes, 2019 IEEE 13th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC), pp. 194-200, (2019); Parihar S., Dadachanji Z., Kumar Singh P., Das R., Karkare A., Bhattacharya A., Automatic grading and feedback using program repair for introductory programming courses, Proceedings of the 2017 ACM Conference on Innovation and Technology in Computer Science Education, (2017); Piech C., Huang J., Nguyen A., Phulsuksombati M., Sahami M., Guibas L., Learning program embeddings to propagate feedback on student code, International conference on machine Learning. PMLR, (2015); Raychev V., Vechev M., Yahav E., Code completion with statistical language models, Proc. of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation, (2014); Tulio Ribeiro M., Singh S., Guestrin C., Why should i trust you? Explaining the predictions of any classifier, Proc. of the 22nd ACM SIGKDD, (2016); Romanov V., Ivanov V., Succi G., Approaches for Representing Software as Graphs for Machine Learning Applications, 2020 International Computer Symposium (ICS), (2020); Schleimer S., Wilkerson D.S., Aiken A., Winnowing: local algorithms for document fingerprinting, Proc. of ACM SIGMOD, (2003); Shalaby M., Mehrez T., Mougy A., Abdulnasser K., Al-Safty A., Automatic Algorithm Recognition of Source-Code Using Machine Learning, pp. 170-177, (2017); Siglidis G., Nikolentzos G., Limnios S., Giatsidis C., Skianis K., Vazirgiannis M., GraKeL: A Graph Kernel Library in Python, J. Mach. Learn. Res., 21, (2020); Singh G., Srikant S., Aggarwal V., Question independent grading using machine learning: The case of computer program grading, Proc. of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, (2016); Srikant S., Aggarwal V., A system to grade computer programming skills using machine learning, Proc. of the 20th ACM SIGKDD, (2014); Taherkhani A., Recognizing Sorting Algorithms with the C4. 5 Decision Tree Classifier, 2010 IEEE 18th International Conference on Program Comprehension, pp. 72-75, (2010); Ugurel S., Krovetz R., Lee Giles C., Pennock D.M., Glover E.J., Zha H., What's the code? Automatic classification of source code archives, Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 632-638, (2002); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in neural information processing systems, pp. 5998-6008, (2017)",,"30th IEEE/ACM International Conference on Program Comprehension, ICPC 2022",16 May 2022 through 17 May 2022,Pittsburgh,180257,English,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85133208644,240
Al-Debagy O.; Martinek P.,"Al-Debagy, Omar (57212389126); Martinek, Péter (57207550423)",57212389126; 57207550423,Dependencies-based microservices decomposition method,2022,International Journal of Computers and Applications,44,9,,814,821,7,4,10.1080/1206212X.2021.1915444,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105020336&doi=10.1080%2f1206212X.2021.1915444&partnerID=40&md5=08cedd231472d717ede187789604a42e,"A microservices identification method was proposed by this research paper. The proposed method consists of two parts; the first part is representing the source code of the monolithic application as a class dependency graph. This graph represents the structure of the monolithic application and the relationships between the classes of the application. The second part of the method is a graph clustering algorithm to identify the microservices through analyzing the dependencies between the classes of the monolithic application and cluster classes with solid relationships to generate microservice candidates. The method was tested with 8 different applications and 11 clustering algorithms were examined to find the most accurate and efficient algorithm. The proposed method produced promising results when compared to other methods in the literature with 0.8 averaged F-Measure ‘F1’ score and 0.44 averaged NGM score. The F1 score shows that the proposed method has good accuracy in detecting microservices candidates. Newman Girvan Modularity metric ‘NGM’ score shows that the generated microservices candidates are properly structured and that there are well-defined relationships among the clustered classes of the generated microservices. © 2021 Informa UK Limited, trading as Taylor & Francis Group.","Microservices, Martinfowler.Com; Bentlemsan K., Bennouar D., Tamzalit D., Et al., A hybrid re-composition based on components and web services, Int J Comput Appl, 42, 5, pp. 449-462, (2018); Newman S., Building Microservices: Designing Fine-Grained Systems, (2015); Balalaie A., Heydarnoori A., Jamshidi P., Microservices architecture enables DevOps: migration to a cloud-native architecture, IEEE Softw, 33, 3, pp. 42-52, (2016); Shang K., Semantic service composition model based on cloud computing, Int J Comput Appl, 2020, pp. 1-7; Megargel A., Shankararaman V., Walker D.K., Migrating from monoliths to cloud-based microservices: A banking industry example, Software Engineering in the Era of Cloud Computing, pp. 85-108, (2020); Gysel M., Kolbener L., Giersche W., Et al., Service cutter: A systematic approach to service decomposition, Service-Oriented and Cloud Computing, 9846, pp. 185-200, (2016); Baresi L., Garriga M., de Renzis A., Microservices identification through interface analysis, Service-Oriented and Cloud Computing, 10465, pp. 19-33, (2017); Nunes L., Santos N., Rito Silva A., From a monolith to a microservices architecture: An approach based on transactional contexts, Software Architecture, pp. 37-52, (2019); Santos N.A.V., Silva A.R., A complexity metric for microservices architecture migration, 2020 IEEE International Conference on Software Architecture (ICSA); Salvador, Brazil, pp. 169-178, (2020); Saidani I., Ouni A., Mkaouer M.W., Et al., Towards automated microservices extraction using muti-objective evolutionary search, Service-Oriented Computing, pp. 58-63, (2019); Jin W., Liu T., Zheng Q., Et al., Functionality-oriented microservice extraction based on execution trace clustering, 2018 IEEE International conference on web services (ICWS), pp. 211-218, (2018); Jin W., Liu T., Cai Y., Et al., Service candidate identification from monolithic systems based on execution traces, IEEE Trans Softw Eng, 1, (2019); Selmadji A., Seriai A.-D., Bouziane H.L., Et al., Re-architecting OO software into microservices, Service-Oriented and Cloud computing, pp. 65-73, (2018); Rossetti G., Pappalardo L., Rinzivillo S., A novel approach to evaluate community detection algorithms on ground truth, Complex Networks VII, 644, pp. 133-144, (2016); Newman M.E.J., Girvan M., Finding and evaluating community structure in networks, Phys Rev E Stat Nonlin Soft Matter Phys, 69, 2, (2004); Fortunato S., Community detection in graphs, Phys Rep, 486, 3-5, pp. 75-174, (2010); Dietrich J., Yakovlev V., McCartin C., Et al., Cluster analysis of Java dependency graphs, Proceedings of the 4th ACM symposium on Software visuallization - SoftVis ‘08, Ammersee, Germany, (2008); Mancoridis S., Mitchell B.S., Chen Y., Et al., Bunch: a clustering tool for the recovery and maintenance of software system structures, Proceedings IEEE International Conference on Software Maintenance - 1999 (ICSM’99). “Software Maintenance for Business Change” (Cat. No.99CB36360), pp. 50-59, (1999); Zhong L.-H., Xu L., Ye M., Et al., An approach for software architecture refactoring based on clustering of extended component dependency graph, 2009 International Conference on Computational Intelligence and Software Engineering, pp. 1-4, (2009); Wang Y., Yu H., Zhu Z., Et al., Automatic software refactoring via weighted clustering in method-level networks, IEEE Trans Softw Eng, 44, 3, pp. 202-236, (2018); Raghavan U.N., Albert R., Kumara S., Near linear time algorithm to detect community structures in large-scale networks, Phys Rev E, 76, 3, (2007); Blondel V.D., Guillaume J.-L., Lambiotte R., Et al., Fast unfolding of communities in large networks, J. Stat. Mech Theory Exp, 2008, 10, (2008); Traag V.A., Waltman L., van Eck N.J., From Louvain to Leiden: Guaranteeing Well-Connected Communities. Sci Rep, 9, 1, (2019); Xie J., Szymanski B.K., Liu X., SLPA: Uncovering overlapping communities in social networks via a Speaker-Listener Interaction Dynamic Process, IEEE 11Th International Conference on Data Mining Workshops; 2011 Dec. P., pp. 344-349, (2011); Newman M.E.J., Finding community structure in networks using the eigenvectors of matrices, Phys Rev E, 74, 3, (2006); Girvan M., Newman M.E.J., Community structure in social and biological networks, Proc Natl Acad Sci U S A, 99, 12, pp. 7821-7826, (2002); Enright A.J., van Dongen S., Ouzounis C.A., An efficient algorithm for large-scale detection of protein families, Nucleic Acids Res, 30, 7, pp. 1575-1584, (2002); Reichardt J., Bornholdt S., Statistical mechanics of community detection, Phys Rev E, 74, 1, (2006); Pons P., Latapy M., Computing communities in large networks using random walks, Computer and Information Sciences - ISCIS 2005, pp. 284-293, (2005); Ustalov D., Panchenko A., Biemann C., Et al., Watset: local-global graph clustering with applications in sense and frame induction, Comput Linguist, 45, 3, pp. 423-479, (2019); Rossetti G., Milli L., Cazabet R., CDLIB: a python library to extract, compare and evaluate communities from complex networks, Appl Netw Sci, 4, 1, (2019); Richardson C., Microservices patterns: With examples in Java. 1st ed, Shelter Island (NY): Manning Publications, (2018)",,,,,,English,Article,Final,,Scopus,2-s2.0-85105020336,241
Pourasghar B.; Izadkhah H.; Isazadeh A.; Lotfi S.,"Pourasghar, Babak (57210314101); Izadkhah, Habib (48662310900); Isazadeh, Ayaz (25122239900); Lotfi, Shahriar (13607411800)",57210314101; 48662310900; 25122239900; 13607411800,A graph-based clustering algorithm for software systems modularization,2021,Information and Software Technology,133,,106469,,,,26,10.1016/j.infsof.2020.106469,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095748789&doi=10.1016%2fj.infsof.2020.106469&partnerID=40&md5=23bafc7abded00db06bb72f18870e788,"Context: Clustering algorithms, as a modularization technique, are used to modularize a program aiming to understand large software systems as well as software refactoring. These algorithms partition the source code of the software system into smaller and easy-to-manage modules (clusters). The resulting decomposition is called the software system structure (or software architecture). Due to the NP-hardness of the modularization problem, evolutionary clustering approaches such as the genetic algorithm have been used to solve this problem. These methods do not make much use of the information and knowledge available in the artifact dependency graph which is extracted from the source code. Objective: To overcome the limitations of the existing modularization techniques, this paper presents a new modularization technique named GMA (Graph-based Modularization Algorithm). Methods: In this paper, a new graph-based clustering algorithm is presented for software modularization. To this end, the depth of relationships is used to compute the similarity between artifacts, as well as seven new criteria are proposed to evaluate the quality of a modularization. The similarity presented in this paper enables the algorithm to use graph-theoretic information. Results: To demonstrate the applicability of the proposed algorithm, ten folders of Mozilla Firefox with different domains and functions, along with four other applications, are selected. The experimental results demonstrate that the proposed algorithm produces modularization closer to the human expert's decomposition (i.e., directory structure) than the other existing algorithms. Conclusion: The proposed algorithm is expected to help a software designer in the software reverse engineering process to extract easy-to-manage and understandable modules from source code. © 2020 Elsevier B.V.","Ducasse S., Pollet D., Software architecture reconstruction: A process-oriented taxonomy, IEEE Trans. Softw. Eng., 35, 4, pp. 573-591, (2009); Isazadeh A., Izadkhah H., Elgedawy I., Source Code Modularization: Theory and Techniques, (2017); Mitchell B.S., Mancoridis S., A Heuristic Search Approach to Solving the Software Clustering Problem, (2002); Wiggerts T.A., Using clustering algorithms in legacy systems remodularization, Proceedings of the Fourth Working Conference on Reverse Engineering, pp. 33-43, (1997); Andritsos P., Tzerpos V., Information-theoretic software clustering, IEEE Trans. Softw. Eng., 31, 2, pp. 150-165, (2005); Lutellier T., Chollak D., Garcia J., Tan L., Rayside D., Medvidovic N., Kroeger R., Comparing software architecture recovery techniques using accurate dependencies, 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, vol. 2, pp. 69-78, (2015); Lutellier T., Chollak D., Garcia J., Tan L., Rayside D., Medvidovic N., Kroeger R., Measuring the impact of code dependencies on software architecture recovery techniques, IEEE Trans. Softw. Eng., 44, 2, pp. 159-181, (2017); Garcia J., Krka I., Mattmann C., Medvidovic N., Obtaining ground-truth software architectures, Proceedings of the 2013 International Conference on Software Engineering, pp. 901-910, (2013); Jalali N.S., Izadkhah H., Lotfi S., Multi-objective search-based software modularization: structural and non-structural features, Soft Comput., 23, 21, pp. 11141-11165, (2019); Mitchell B.S., Mancoridis S., On the evaluation of the Bunch search-based software modularization algorithm, Soft Comput., 12, 1, pp. 77-93, (2008); Mitchell B., Mancoridis S., On the automatic modularization of software systems using the bunch tool, IEEE Trans. Softw. Eng., 32, 3, pp. 193-208, (2006); Beck F., Diehl S., On the impact of software evolution on software clustering, Empir. Softw. Eng., 18, 5, pp. 970-1004, (2013); Maqbool O., Babri H., Hierarchical clustering for software architecture recovery, IEEE Trans. Softw. Eng., 33, 11, pp. 759-780, (2007); Naseem R., Maqbool O., Muhammad S., Cooperative clustering for software modularization, J. Syst. Softw., 86, 8, pp. 2045-2062, (2013); Naseem R., Deris M.B.M., Maqbool O., Li J.-P., Shahzad S., Shah H., Improved binary similarity measures for software modularization, Front. Inf. Technol. Electron. Eng., 18, 8, pp. 1082-1107, (2017); Saeed M., Maqbool O., Babri H.A., Hassan S.Z., Sarwar S.M., Software clustering techniques and the use of combined algorithm, Seventh European Conference OnSoftware Maintenance and Reengineering, 2003. Proceedings, pp. 301-306, (2003); Rathee A., Chhabra J.K., Software remodularization by estimating structural and conceptual relations among classes and using hierarchical clustering, International Conference on Advanced Informatics for Computing Research, pp. 94-106, (2017); Naseem R., Deris M.M., Maqbool O., Shahzad S., Euclidean space based hierarchical clusterers combinations: an application to software clustering, Cluster Comput., pp. 1-25, (2017); Kong X., Li B., Wang L., Wu W., Directory-based dependency processing for software architecture recovery, IEEE Access, 6, pp. 52321-52335, (2018); Praditwong K., Harman M., Yao X., Software module clustering as a multi-objective search problem, IEEE Trans. Softw. Eng., 37, 2, pp. 264-282, (2011); Bishnoi M., Singh P., Modularizing software systems using PSO optimized hierarchical clustering, 2016 International Conference on Computational Techniques in Information and Communication Technologies, ICCTICT, pp. 659-664, (2016); Mahdavi K., A Clustering Genetic Algorithm for Software Modularisation with a Multiple Hill Climbing Approach, (2005); Izadkhah H., Elgedawy I., Isazadeh A., E-CDGM: An evolutionary call-dependency graph modularization approach for software systems, Cybern. Inf. Technol., 16, 3, pp. 70-90, (2016); Moncores M.C., Alvim A.C., Barros M.O., Large neighborhood search applied to the software module clustering problem, Comput. Oper. Res., 91, pp. 92-111, (2018); Huang J., Liu J., A similarity-based modularization quality measure for software module clustering problems, Inform. Sci., 342, pp. 96-110, (2016); Parsa S., Bushehrian O., Et al., A new encoding scheme and a framework to investigate genetic clustering algorithms, J. Res. Pract. Inf. Technol., 37, 1, (2005); Mamaghani A.S., Hajizadeh M., Software modularization using the modified firefly algorithm, 2014 8th. Malaysian Software Engineering Conference, MySEC, pp. 321-324, (2014); Huang J., Liu J., Yao X., A multi-agent evolutionary algorithm for software module clustering problems, Soft Comput., 21, 12, pp. 3415-3428, (2017); Jeet K., Dhir R., Software module clustering using hybrid socio-evolutionary algorithms, Int. J. Inf. Eng. Electron. Bus., 8, 4, (2016); Chhabra J.K., Et al., Harmony search based remodularization for object-oriented software systems, Comput. Lang. Syst. Struct., 47, pp. 153-169, (2017); Kumari A., Srinivas K., Hyper-heuristic approach for multi-objective software module clustering, J. Syst. Softw., 117, pp. 384-401, (2016); Tajgardan M., Izadkhah H., Lotfi S., Software systems clustering using estimation of distribution approach, J. Appl. Comput. Sci. Methods, 8, 2, pp. 99-113, (2016); Mamaghani A.S., Meybodi M.R., Clustering of software systems using new hybrid algorithms, 2009 Ninth IEEE International Conference on Computer and Information Technology, vol. 1, pp. 20-25, (2009); Prajapati A., Chhabra J.K., An efficient scheme for candidate solutions of search-based multi-objective software remodularization, International Conference on Human Interface and the Management of Information, pp. 296-307, (2016); Hwa J., Yoo S., Seo Y.-S., Bae D.-H., Search-based approaches for software module clustering based on multiple relationship factors, Int. J. Softw. Eng. Knowl. Eng., 27, 7, pp. 1033-1062, (2017); Ramirez A., Romero J.R., Ventura S., Interactive multi-objective evolutionary optimization of software architectures, Inform. Sci., 463, pp. 92-109, (2018); Hussain I., Khanum A., Abbasi A.Q., Javed M.Y., Et al., A novel approach for software architecture recovery using particle swarm optimization., Int. Arab J. Inf. Technol., 12, 1, pp. 32-41, (2015); Kargar M., Isazadeh A., Izadkhah H., Semantic-based software clustering using hill climbing, 2017 International Symposium on Computer Science and Software Engineering Conference, CSSE, pp. 55-60, (2017); Izadkhah H., Tajgardan M., Information theoretic objective function for genetic software clustering, 5th International Electronic Conference on Entropy and Its Applications, pp. 1-9, (2019); Chhabra J.K., Et al., Many-objective artificial bee colony algorithm for large-scale software module clustering problem, Soft Comput., 22, 19, pp. 6341-6361, (2018); Shokoufandeh A., Mancoridis S., Maycock M., Applying spectral methods to software clustering, Ninth Working Conference on Reverse Engineering, 2002. Proceedings, pp. 3-10, (2002); Mohammadi S., Izadkhah H., A new algorithm for software clustering considering the knowledge of dependency between artifacts in the source code, Inf. Softw. Technol., 105, pp. 252-256, (2019); Qiu D., Zhang Q., Fang S., Reconstructing software high-level architecture by clustering weighted directed class graph, Int. J. Softw. Eng. Knowl. Eng., 25, 4, pp. 701-726, (2015); Cormen T.H., Leiserson C.E., Rivest R., Stein C., Algorithmen-Eine Einführung, (2017); Rousseeuw P.J., Silhouettes: a graphical aid to the interpretation and validation of cluster analysis, J. Comput. Appl. Math., 20, pp. 53-65, (1987); Wen Z., Tzerpos V., An effectiveness measure for software clustering algorithms, Proceedings. 12th IEEE International Workshop on Program Comprehension, 2004, pp. 194-203, (2004); Sozer H., Evaluating the effectiveness of multi-level greedy modularity clustering for software architecture recovery, European Conference on Software Architecture, pp. 71-87, (2019); Kargar M., Isazadeh A., Izadkhah H., Multi-programming language software systems modularization, Comput. Electr. Eng., 80, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85095748789,242
Pârtachi P.-P.; Dash S.K.; Allamanis M.; Barr E.T.,"Pârtachi, Profir-Petru (57219626989); Dash, Santanu Kumar (57192250213); Allamanis, Miltiadis (39361040300); Barr, Earl T. (7005643860)",57219626989; 57192250213; 39361040300; 7005643860,Flexeme: Untangling commits using lexical flows,2020,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,,,63,74,11,9,10.1145/3368089.3409693,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097194961&doi=10.1145%2f3368089.3409693&partnerID=40&md5=3655a2d95887a2382e1a1056ae653ae3,"Today, most developers bundle changes into commits that they submit to a shared code repository. Tangled commits intermix distinct concerns, such as a bug fix and a new feature. They cause issues for developers, reviewers, and researchers alike: they restrict the usability of tools such as git bisect, make patch comprehension more difficult, and force researchers who mine software repositories to contend with noise. We present a novel data structure, the -NFG, a multiversion Program Dependency Graph augmented with name flows. A -NFG directly and simultaneously encodes different program versions, thereby capturing commits, and annotates data flow edges with the names/lexemes that flow across them. Our technique, Flexeme, builds a -NFG from commits, then applies Agglomerative Clustering using Graph Similarity to that -NFG to untangle its commits. At the untangling task on a C# corpus, our implementation, Heddle, improves the state-of-the-art on accuracy by 0.14, achieving 0.81, in a fraction of the time: Heddle is 32 times faster than the previous state-of-the-art. © 2020 ACM.","Alexandru C.V., Panichella S., Proksch S., Gall H.C., Redundancy-free analysis of multi-revision software artifacts, Empirical Software Engineering, 24, 1, pp. 332-380, (2019); Barnett M., Bird C., Brunet J., Lahiri S.K., Helping developers help themselves: Automatic decomposition of code review changesets, Proc.-Int. Conf. Softw. Eng, 2014, 1, pp. 134-144, (2015); Kumar Dash S., Allamanis M., Barr E.T., Refinym: Using names to refine types, Foundations of Software Engineering (FSE), (2018); Dias M., Bacchelli A., Gousios G., Cassou D., Ducasse S., Untangling fine-grained code changes, 2015 IEEE 22nd Int. Conf. Softw. Anal. Evol. Reengineering, SANER 2015-Proc. IEEE, pp. 341-350, (2015); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, Lect. Notes Comput. Sci. (Including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), 167, pp. 125-132, (1984); Herzig K., Just S., Zeller A., The impact of tangled code changes on defect prediction models, Empir. Softw. Eng., 21, 2, pp. 303-336, (2016); Herzig K., Zeller A., The impact of tangled code changes, IEEE Int. Work. Conf. Min. Softw. Repos., pp. 121-130, (2013); Hogg R.V., Tanis E.A., Zimmerman D.L., Probability and Statistical Inference, (2020); Irving R.W., Manlove D.F., The stable roommates problem with ties, J. Algorithms, 43, 1, pp. 85-105, (2002); Jones E., Oliphant T., Peterson P., Et al., SciPy: Open Source Scientific Tools for Python, (2001); Kawrykow D., Robillard M.P., Non-essential changes in version histories, Proceeding 33rd Int. Conf. Softw. Eng.-ICSE'11, (2011); Kim M., Notkin D., Program element matching for multiversion program analyses, Proceedings of the 2006 International Workshop on Mining Software Repositories, pp. 58-64, (2006); Kirinuki H., Higo Y., Hotta K., Kusumoto S., Hey! are you committing tangled changes?, Proc. 22nd Int. Conf. Progr. Compr. (ICPC 2014), pp. 262-265, (2014); Kirinuki H., Higo Y., Hotta K., Kusumoto S., Splitting commits via past code changes, Proc.-Asia-Pacific Softw. Eng. Conf. APSEC (2017), pp. 129-136, (2017); Kuhn H.W., The hungarian method for the assignment problem, Naval Research Logistics Quarterly, 2, 1-2, pp. 83-97; Le W., Pattison S.D., Patch verification via multiversion interprocedural control flow graphs, Proc. 36th Int. Conf. Softw. Eng.-ICSE, 2014, pp. 1047-1058, (2014); Li Y., Rubin J., Chechik M., Semantic slicing of software version histories, Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering, pp. 686-696, (2015); Li Y., Zhu C., Gligoric M., Rubin J., Chechik M., Precise semantic history slicing through dynamic delta refinement, Autom. Softw. Eng., 26, 4, pp. 757-793, (2019); Li Y., Zhu C., Rubin J., Chechik M., Semantic slicing of software version histories, IEEE Trans. Softw. Eng., 44, 2, pp. 182-201, (2018); Microsoft Rosyln; Murphy-Hill E., Parnin C., Black A.P., How we refactor, and how we know it, IEEE Trans. Softw. Eng., 38, 1, pp. 5-18, (2012); Nielsen J., Response times: The three important limits, Usability Engineering, (1993); De Roover, Muylaert W., Untangling Source Code Changes Using Program Slicing, (2017); Sebastian P., Harald P., Redundancy-free Analysis of Multi-revision Software Artifacts Redundancy-free Analysis of Multi-revision Software Artifacts, (2018); Shervashidze N., Schweitzer P., Van Leeuwen E.J., Mehlhorn K., Borgwardt K.M., Weisfeiler-lehman graph kernels, Journal of Machine Learning Research, 12, pp. 2539-2561, (2011); Siglidis G., Nikolentzos G., Limnios S., Giatsidis C., Skianis K., Vazirgiannis M., GraKeL: A Graph Kernel Library in Python, (2018); Tao Y., Dang Y., Xie T., Zhang D., Kim S., How do software engineers understand code changes?, Proc. ACM SIGSOFT 20th Int. Symp. Found. Softw. Eng.-FSE'12, (2012); Tip F., A Survey of Program Slicing Techniques, (1994); Vichy Vishwanathan N.S., Schraudolph N.N., Kondor R., Borgwardt K.M., Graph kernels, Journal of Machine Learning Research, 11, pp. 1201-1242, (2010); Yu. Weisfeiler B., Leman A.A., Reduction of A Graph to A Canonical Form and An Algebra Arising during This Reduction, (1968); Zimmermann T., Zeller A., Weissgerber P., Diehl S., Mining version histories to guide software changes, IEEE Transactions on Software Engineering, 31, 6, pp. 429-445, (2005)",ACM SIGSOFT,"28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2020",8 November 2020 through 13 November 2020,"Virtual, Online",164831,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85097194961,244
Höppner F.; Jahnke M.,"Höppner, Frank (6602185295); Jahnke, Maximilian (57216670799)",6602185295; 57216670799,Enriched Weisfeiler-Lehman Kernel for Improved Graph Clustering of Source Code,2020,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12080 LNCS,,,248,260,12,2,10.1007/978-3-030-44584-3_20,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084262556&doi=10.1007%2f978-3-030-44584-3_20&partnerID=40&md5=21eef57863f917b964b0b50d656747bf,"To perform cluster analysis on graphs we utilize graph kernels, Weisfeiler-Lehman kernel in particular, to transform graphs into a vector representation. Despite good results, these kernels have been criticized in the literature for high dimensionality and high sensitivity, so we propose an efficient subtree distance measure that is subsequently used to enrich the vector representations and enables more sensitive distance measurements. We demonstrate the usefulness in an application, where the graphs represent different source code snapshots, and a cluster analysis of these snapshots provides the lecturer an overview about the overall performance of a group of students. © 2020, The Author(s).","Bille P., A survey on tree edit distance and related problems, Theor. Comput. Sci., 337, pp. 217-239, (2005); Demaine E.D., Mozes S., Rossman B., Weimann O., An optimal decomposition algorithm for tree edit distance, International Colloquium on Automata, Languages, and Programming, pp. 146-157, (2007); Gao X., Xiao B., Tao D., Li X., A survey of graph edit distance, Pattern Anal. Appl., 13, 1, pp. 113-129, (2010); Munkres M., Algorithms for the assignment and transportation problems, J. Soc. Ind. Appl. Math., 5, 1, pp. 32-38, (1957); Narayanan A., Chandramohan M., Chen L., Liu Y., Saminathan S., Sub-graph2vec: Learning distributed representations of rooted sub-graphs from large graphs, Workshop on Mining and Learning with Graphs, (2016); Paassen B., Metric Learning for Structured Data, (2019); Ramon J., Gartner T., Expressivity versus efficiency of graph kernels, Proceedings of the First International Workshop on Mining Graphs, Trees and Sequences, pp. 65-74, (2003); Seeland M., Girschick T., Buchwald F., Kramer S., Online structural graph clustering using frequent subgraph mining, ECML PKDD 2010. LNCS (LNAI), 6323, pp. 213-228, (2010); Shervashidze N., Schweitzer P., van Leeuwen E.J., Mehlhorn K., Borgwardt K.M., Weisfeiler-lehman graph kernels, J. Mach. Learn. Res., 12, pp. 2539-2561, (2011); Shervashidze N., Vishwanathan S., Petri T.H., Mehlhorn K., Borgwardt K.M., Efficient graphlet kernels for large graph comparison, Proceedings of the International Conference on Artificial Intelligence and Statistics, (2009); Weisfeiler B., Lehman A., A reduction of a graph to a canonical form and an algebra arising during this reduction, Nauchno-Technicheskaya Informatsia, 2, 9, pp. 12-16, (1968)",,"18th International Conference on Intelligent Data Analysis, IDA 2020",27 April 2020 through 29 April 2020,Konstanz,239279,English,Conference paper,Final,All Open Access; Hybrid Gold Open Access,Scopus,2-s2.0-85084262556,245
Gu X.; Zhang H.; Kim S.,"Gu, Xiaodong (57188851712); Zhang, Hongyu (55685668500); Kim, Sunghun (12241083400)",57188851712; 55685668500; 12241083400,CodeKernel: A graph kernel based approach to the selection of API usage examples,2019,"Proceedings - 2019 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019",,,8952546,590,601,11,22,10.1109/ASE.2019.00061,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078952975&doi=10.1109%2fASE.2019.00061&partnerID=40&md5=85dbd8c1cccc076ea3a48f8a8e86118c,"Developers often want to find out how to use a certain API (e.g., FileReader.read in JDK library). API usage examples are very helpful in this regard. Over the years, many automated methods have been proposed to generate code examples by clustering and summarizing relevant code snippets extracted from a code corpus. These approaches simplify source code as method invocation sequences or feature vectors. Such simplifications only model partial aspects of the code and tend to yield inaccurate examples. We propose CodeKernel, a graph kernel based approach to the selection of API usage examples. Instead of approximating source code as method invocation sequences or feature vectors, CodeKernel represents source code as object usage graphs. Then, it clusters graphs by embedding them into a continuous space using a graph kernel. Finally, it outputs code examples by selecting a representative graph from each cluster using designed ranking metrics. Our empirical evaluation shows that CodeKernel selects more accurate code examples than the related work (MUSE and eXoaDocs). A user study involving 25 developers in a multinational company also confirms the usefulness of CodeKernel in selecting API usage examples. © 2019 IEEE.","Github Search; Harris S., Simian-Similarity Analyzer, (2003); Spectral Clusterer for WEKA; Stack Overflow; Allamanis M., Sutton C., Mining idioms from source code, Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 472-483, (2014); Bishop C.M., Pattern Recognition and Machine Learning, (2006); Borgwardt K.M., Kriegel H.-P., Shortest-path kernels on graphs, Data Mining, Fifth IEEE International Conference on, (2005); Borgwardt K.M., Ong C.S., Schonauer S., Vishwanathan S., Smola A.J., Kriegel H.-P., Protein function prediction via graph kernels, Bioinformatics, 21, pp. i47-i56, (2005); Bruch M., Monperrus M., Mezini M., Learning from examples to improve code completion systems, Proceedings of the the 7th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, pp. 213-222, (2009); Buse R.P., Weimer W., Synthesizing api usage examples, Software Engineering (ICSE) 2012 34th International Conference on, pp. 782-792, (2012); Cai C., Han L., Ji Z., Chen Y., Enzyme family classification by support vector machines, Proteins: Structure Function and Bioinformatics, 55, 1, pp. 66-76, (2004); Cai D., He X., Han J., Document clustering using locality preserving indexing, Knowledge and Data Engineering IEEE Transactions on, 17, 12, pp. 1624-1637, (2005); Fowkes J., Sutton C., Parameter-Free Probabilistic Api Mining at Github Scale, (2015); Gartner T., A survey of kernels for structured data, ACM SIGKDD Explorations Newsletter, 5, 1, pp. 49-58, (2003); Ghafari M., Rubinov K., Pourhashem M.M., K. Mining unit test cases to synthesize api usage examples, Journal of Software: Evolution and Process, 29, 12, (2017); Gu X., Zhang H., Kim S., Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE, pp. 933-944, (2018); Gu X., Zhang H., Zhang D., Kim S., Deep api learning, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 631-642, (2016); Han J., Moraga C., The influence of the sigmoid function parameters on the speed of backpropagation learning, From Natural to Artificial Neural Computation, pp. 195-201, (1995); Hummel B., Juergens E., Heinemann L., Conradt M., Index-based code clone detection: Incremental, distributed, scalable, Software Maintenance (ICSM) 2010 IEEE International Conference on, pp. 1-9, (2010); Keivanloo I., Rilling J., Zou Y., Spotting working code examples, Proceedings of the 36th International Conference on Software Engineering, pp. 664-675, (2014); Kim J., Lee S., Hwang S.-W., Kim S., Towards an intelligent code search engine, Twenty-Fourth AAAI Conference on Artificial Intelligence, (2010); Kim S., Zimmermann T., Nagappan N., Crash graphs: An aggregated view of multiple crashes to improve crash triage, Dependable Systems & Networks (DSN) 2011 IEEE/IFIP 41st International Conference on, pp. 486-493, (2011); Kuhn A., Ducasse S., Girba T., Semantic clustering: Identifying topics in source code, Information and Software Technology, 49, 3, pp. 230-243, (2007); Kulis B., Basu S., Dhillon I., Mooney R., Semi-supervised graph clustering: A kernel approach, Machine Learning, 74, 1, pp. 1-22, (2009); Lv F., Zhang H., Lou J., Wang S., Zhang D., Zhao J., Codehow: Effective code search based on api understanding and extended boolean model, Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering, ASE '15, pp. 260-270, (2015); Manning C.D., Raghavan P., Schutze H., Et al., Introduction to Information Retrieval Volume 1, (2008); McCallum A., Nigam K., Ungar L.H., Efficient clustering of high-dimensional data sets with application to reference matching, Proceedings of the Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 169-178, (2000); Moreno L., Bavota G., Di Penta M., Oliveto R., Marcus A., How can i use this method?, Proceedings of the 37th IEEE/ACM International Conference on Software Engineering (ICSE'15), (2015); Narayanan A., Meng G., Yang L., Liu J., Chen L., Contextual weisfeiler-lehman graph kernel for malware detection, 2016 International Joint Conference on Neural Networks (IJCNN, pp. 4701-4708, (2016); Nguyen A.T., Hilton M., Codoban M., Nguyen H.A., Mast L., Rademacher E., Nguyen T.N., Dig D., Api code recommendation using statistical learning from fine-grained changes, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 511-522, (2016); Nguyen A.T., Nguyen T.D., Phan H.D., Nguyen T.N., A deep neural network language model with contexts for source code, 2018 IEEE 25th International Conference on Software Analysis Evolution and Reengineering SANER, pp. 323-334, (2018); Nguyen A.T., Nguyen T.N., Graph-based statistical language model for code, Proceedings of the 37th IEEE/ACM International Conference on Software Engineering (ICSE'15), (2015); Nguyen A.T., Nguyen T.T., Nguyen H.A., Tamrawi A., Nguyen H.V., Al-Kofahi J., Nguyen T.N., Graph-based pattern-oriented, context-sensitive source code completion, Proceedings of the 34th International Conference on Software Engineering, pp. 69-79, (2012); Nguyen H.A., Nguyen T.T., Pham N.H., Al-Kofahi J.M., Nguyen T.N., Accurate and efficient structural characteristic feature extraction for clone detection, Fundamental Approaches to Software Engineering, pp. 440-455, (2009); Nguyen P., Di Rocco J., Ruscio D., Ochoa L., Degueule T., Di Penta M., Focus: A recommender system for mining api function calls and usage patterns, 41st ACM/IEEE International Conference on Software Engineering (ICSE), (2019); Nguyen T.T., Nguyen H.A., Pham N.H., Al-Kofahi J.M., Nguyen T.N., Graph-based mining of multiple object usage patterns, Proceedings of the the 7th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, pp. 383-392, (2009); Nguyen T.T., Pham H.V., Vu P.M., Nguyen T.T., Learning API Usages from Bytecode: A Statistical Approach, (2015); Niu H., Keivanloo I., Zou Y., Learning to rank code examples for code search engines, Empirical Software Engineering, 22, 1, pp. 259-291, (2017); Park H.-S., Jun C.-H., A simple and fast algorithm for k-medoids clustering, Expert Systems with Applications, 36, 2, pp. 3336-3341, (2009); Platt Autoalbum J.C., Clustering digital photographs using probabilistic model merging, Content-based Access of Image and Video Libraries 2000. Proceedings IEEE Workshop on, pp. 96-100, (2000); Rabiner L.R., Juang B.-H., An introduction to hidden markov models, ASSP Magazine, 3, 1, pp. 4-16, (1986); Ralaivola L., Swamidass S.J., Saigo H., Baldi P., Graph kernels for chemical informatics, Neural Networks, 18, 8, pp. 1093-1110, (2005); Rosa K.D., Shah R., Lin B., Gershman A., Frederking R., Topical clustering of tweets. Proceedings of the, ACM SIGIR: SWSM, (2011); Roy C.K., Cordy J.R., Koschke R., Comparison and evaluation of code clone detection techniques and tools: A qualitative approach, Science of Computer Programming, 74, 7, pp. 470-495, (2009); Shawe-Taylor J., Cristianini N., Kernel Methods for Pattern Analysis, (2004); Vishwanathan S.V.N., Schraudolph N.N., Kondor R., Borgwardt K.M., Graph kernels, The Journal of Machine Learning Research, 11, pp. 1201-1242, (2010); Wang J., Dang Y., Zhang H., Chen K., Xie T., Zhang D., Mining succinct and high-coverage api usage patterns from source code, Proceedings of the 10th Working Conference on Mining Software Repositories, pp. 319-328, (2013); Wu L., Du L., Liu B., Xu G., Ge Y., Fu Y., Li J., Zhou Y., Xiong H., Heterogeneous metric learning with content-based regulariza-tion for software artifact retrieval, Data Mining (ICDM) 2014 IEEE International Conference on, pp. 610-619, (2014); Xie T., Pei J., Mapo: Mining api usages from open source repositories, Proceedings of the 2006 International Workshop on Mining Software Repositories, pp. 54-57, (2006); Zhang D., Liu Y., Si L., Zhang J., Lawrence R.D., Multiple instance learning on structured data, Advances in Neural Information Processing Systems (NIPS, pp. 145-153, (2011); Zhang D.-Q., Lin C.-Y., Chang S.-F., Smith J.R., Semantic video clustering across sources using bipartite spectral clustering, Multimedia and Expo 2004. ICME'04. 2004 IEEE International Conference on Volume 1, pp. 117-120, (2004); Zhang H., Jain A., Khandelwal G., Kaushik C., Ge S., Hu W., Bing developer assistant: Improving developer productivity by recommending sample code, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, FSE 2016, pp. 956-961, (2016); Zhong H., Xie T., Zhang L., Pei J., Mei H., Mapo: Mining and recommending api usage patterns, ECOOP 2009-Object-Oriented Programming, pp. 318-343, (2009)",ACM SIGAI; Association for Computing Machinery (ACM); IEEE; IEEE Computer Society; IEEE Technical Council on Software Engineering (TCSE); Special Interest Group on Software Engineering (SIGSOFT),"34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019",10 November 2019 through 15 November 2019,San Diego,156781,English,Conference paper,Final,,Scopus,2-s2.0-85078952975,247
Siddik S.; Gias A.U.; Khaled S.M.,"Siddik, Saeed (56297475300); Gias, Alim Ul (35434840600); Khaled, Shah Mostafa (35435302100)",56297475300; 35434840600; 35435302100,Optimizing software design migration from structured programming to object oriented paradigm,2014,"2013 16th International Conference on Computer and Information Technology, ICCIT 2013",,,6997320,1,6,5,2,10.1109/ICCITechn.2014.6997320,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905036062&doi=10.1109%2fICCITechn.2014.6997320&partnerID=40&md5=d9270341cfe747f6a60e076323a6220e,"Several industries are using legacy softwares, developed with Structured Programming (SP) approach, that should be migrated to Object Oriented Paradigm (OOP) for ensuring better software quality parameters like modularity, manageability and extendability. Automating SP to OOP migration is pivotal as it could reduce time that take in the manual process. Given this potential benefit, the issue is yet to be addressed by researchers. This paper addresses the scenario by modeling this problem as a graph clustering problem where SP functions and function calls are vertices and edges respectively. The challenge evolving the problem is to find optimized clusters from graphs. To aid this problem, certain heuristic algorithms based on Monte Carlo and Greedy approaches are being developed. The proposed algorithms have been tested against a collection of real and synthetic data. The numerical results show that greedy algorithms are faster and produced better results than the average performance of Monte Carlo based approaches. © 2014 IEEE.","Chisolm K., Lisonbee J., The use of computer language compilers in legacy code migration, IEEE Systems Readiness Technology Conference (AUTOTESTCON'99)., pp. 137-145, (1999); Ryder B.G., Constructing the call graph of a program, Software Engineering, 3, pp. 216-226, (1979); Terashima Y., Gondow K., Static call graph generator for C++ using debugging information, 14th Asia-Pacific Software Engineering Conference (APSEC 2007), pp. 127-134, (2007); Hossain S., Zulkarnine A.T., Design structure of scientific software-a case study, 13th International DSM Conference, pp. 129-141, (2011); Chidamber S.R., Kemerer C.F., A metrics suite for object oriented design, IEEE Transactions on Software Engineering, 20, 6, pp. 476-493, (1994); Asagba P.O., Ogheneovo E., A comparative analysis of structured and object-oriented programming methods, Journal of Applied Sciences and Environmental Management, 11, 4, pp. 42-46, (2007); Wolsey L.A., Integer programming, IIE Transactions, 32, 273-285, pp. 2-58, (2000); Watts D.J., Strogatz S.H., Collective dynamics of smallworldnetworks, Nature, 393, 6684, pp. 440-442, (1998); Braha D., Bar-Yam Y., The statistical mechanics of complex product development: Empirical and analytical results, Management Science, 53, 7, pp. 1127-1145, (2007); Schaeffer S.E., Graph clustering, Computer Science Review, 1, 1, pp. 27-64, (2007); Sneed H.M., Nyary E., Extracting object-oriented specification from procedurally oriented programs, 2nd Working Conference on Reverse Engineering, pp. 217-226, (1995); Maqbool O., Babri H.A., Hierarchical clustering for software architecture recovery, IEEE Transactions on Software Engineering, 33, 11, pp. 759-780, (2007); Dineshkumar V., Deepika J., Code to design migration from structured to object oriented paradigm, International Journal of Information and Communication Technology Research, 1, (2011); Zhou Y., Cheng H., Yu J.X., Graph clustering based on structural/attribute similarities, VLDB Endowment, 2, 1, pp. 718-729, (2009); Aggarwal C.C., Wolf J.L., Yu P.S., Procopiuc C., Park J.S., Fast algorithms for projected clustering, ACM SIGMOD International Conference on Management of Data, Ser. SIGMOD, 99, pp. 61-72, (1999); Wu K.-L., Yang M.-S., Alternative c-means clustering algorithms, Pattern Recognition, 35, 10, pp. 2267-2278, (2002); Bezdek J.C., Pal N.R., Some new indexes of cluster validity,"" Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on, 28, 3, pp. 301-315, (1998); Dunn J.C., A fuzzy relative of the isodata process and its use in detection compact well-separated clusters, Journal of Cybernetics, 3, pp. 32-57, (1973)",,"2013 16th International Conference on Computer and Information Technology, ICCIT 2013",8 March 2014 through 10 March 2014,Khulna,109851,English,Conference paper,Final,,Scopus,2-s2.0-84905036062,248
Zhong L.-H.; Xu L.; Ye M.-S.; Zheng Y.; Xie B.,"Zhong, Lin-Hui (56265453500); Xu, Le (55732667000); Ye, Mao-Sheng (55416527500); Zheng, Yi (57198814614); Xie, Bing (7201872787)",56265453500; 55732667000; 55416527500; 57198814614; 7201872787,An approach for software architecture refactoring based on clustering of extended component dependency graph,2009,"Proceedings - 2009 International Conference on Computational Intelligence and Software Engineering, CiSE 2009",,,5362854,,,,2,10.1109/CISE.2009.5362854,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949700560&doi=10.1109%2fCISE.2009.5362854&partnerID=40&md5=7adc7879dea903a9d4b6ad1babc5c55e,"For improving the evolvability of software architecture, the paper proposes a software architecture refactoring strategy based on extended clustering of component dependency relation, which consists of logical relation and evolution relation among components. By using the graph clustering algorithm, the software architecture can be restructured according to the software quality of ""high cohesion and low coupling"" under the control of our refactoring algorithm. Moreover, an example is shown for explaining its usability.","Fowler M., Refactoring: Improving the Design of Existing Programs, (1999); Eriksson H.E., Penker M., Lyons B., Fado D., UML2 Toolkit, (2004); (2007); Philipps J., Rumpe B., Refinement of Information Flow Architectures, Proc. Int'l Conf. Formal Eng. Methods, (1997); Tzerpos V., Holt R.C., ACDC: An algorithm for comprehension driven clustering, Proceedings of the 7th Working Conference on Reverse Engineering, pp. 258-267, (2000); Mancoridis S., Mitchell B., Chen Y., Gansner E., Bunch: A clustering tool for the recovery and maintenance of software system structures, Proceedings of the 15th International Conference on Software Maintenance, pp. 50-59, (1999); Doval D., Mancoridis S., Mitchell B., Automatic clustering of software systems using a genetic algorithm, Proceedings of the International Conference on Software Technology and Engineering Practice, pp. 73-91, (1998)",IEEE Wuhan Section; Wuhan University; James Madison University; University of Wisconsin at La Crosse; Microsoft Research Asia,"2009 International Conference on Computational Intelligence and Software Engineering, CiSE 2009",11 December 2009 through 13 December 2009,Wuhan,79559,English,Conference paper,Final,,Scopus,2-s2.0-77949700560,251
Qiu D.; Zhang Q.; Fang S.,"Qiu, Dehong (56235709800); Zhang, Qifeng (57199110305); Fang, Shaohong (16678654200)",56235709800; 57199110305; 16678654200,Reconstructing Software High-Level Architecture by Clustering Weighted Directed Class Graph,2015,International Journal of Software Engineering and Knowledge Engineering,25,4,,701,726,25,8,10.1142/S0218194015500072,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941884483&doi=10.1142%2fS0218194015500072&partnerID=40&md5=ac56e15253d0402f32dac893408a22ad,"Software architecture reconstruction plays an important role in software reuse, evolution and maintenance. Clustering is a promising technique for software architecture reconstruction. However, the representation of software, which serves as clustering input, and the clustering algorithm need to be improved in real applications. The representation should contain appropriate and adequate information of software. Furthermore, the clustering algorithm should be adapted to the particular demands of software architecture reconstruction well. In this paper, we first extract Weighted Directed Class Graph (WDCG) to represent object-oriented software. WDCG is a structural and quantitative representation of software, which contains not only the static information of software source code but also the dynamic information of software execution. Then we propose a WDCG-based Clustering Algorithm (WDCG-CA) to reconstruct high-level software architecture. WDCG-CA makes full use of the structural and quantitative information of WDCG, and avoids wrong compositions and arbitrary partitions successfully in the process of reconstructing software architecture. We introduce four metrics to evaluate the performance of WDCG-CA. The results of the comparative experiments show that WDCG-CA outperforms the comparative approaches in most cases in terms of the four metrics. © 2015 World Scientific Publishing Company.","Eranki K., Community Software Architecture Definitions; Taylor R., Medvidovic N., Dashofy E., Software Architecture: Foundations, Theory, and Practice, (2009); Maqbool O., Babri H.A., Hierarchical clustering for software architecture recovery, IEEE Trans. on Software Engineering, 33, 7, pp. 759-780, (2007); Ducasse S., Pollet D., Software architecture reconstruction: A process - Oriented taxonomy, IEEE Trans. on Software Engineering, 35, 4, pp. 573-591, (2009); Garcia J., Ivkovic I., Medvidovic N., A comparative analysis of software architecture recovery techniques, Proc. 28th IEEE/ACM Int. Conf. Automated Software Engineering (ASE 2013), pp. 486-496, (2013); Kaufman L., Rousseeuw P.J., Finding Groups in Data: An Introduction to Cluster Analysis, (2005); Berkhin P., A survey of clustering data mining techniques, Grouping Multidimensional Data, pp. 25-71, (2006); Schaeffer S.E., Graph clustering, Computer Science Review, 1, 1, pp. 27-64, (2007); Wu J., Hassan A.E., Holt R.C., Comparison of clustering algorithms in the context of software evolution, Proc. 21st IEEE Int. Conf. on Software Maintenance (ICSM 2005), pp. 525-535, (2005); Zhang Q.F., Qiu D.H., Tian Q.B., Sun L., Object-oriented software architecture recovery using a new hybrid clustering algorithm, Proc. 7th Int. Conf. on Fuzzy Systems and Knowledge Discovery (FSKD 2010), pp. 2546-2550, (2010); Grygorash O., Zhou Y., Jorgensen Z., Minimum spanning tree based clustering algorithms, Proc. 18th IEEE Int. Conf. on Tools with Artificial Intelligence (ICTAI 2006), pp. 73-81, (2006); Saeed M., Maqbool O., Babri H.A., Sarwar S.M., Hassan S.Z., Software clustering techniques and the use of the combined algorithm, Proc. 7th European Conference on Software Maintenance and Reengineering (CSMR 2003), pp. 301-306, (2003); Maqbool O., Babri H.A., The weighted combined algorithm: A linkage algorithm for software clustering, Proc. 8th European Conference on Software Maintenance and Reengineering (CSMR 2004), pp. 15-24, (2004); Andritsos P., Tzerpos V., Information-theoretic software clustering, IEEE Trans. on Software Engineering, 31, 2, pp. 150-165, (2005); Naseem R., Maqbool O., Muhammad S., An improved similarity measure for binary features in software clustering, Proc. 2nd Int. Conf. on Computational Intelligence, Modelling and Simulation (CIMSim 2010), pp. 111-116; Naseem R., Maqbool O., Muhammad S., Improved similarity measures for software clustering, Proc. 15th European Conf. Software Maintenance and Reengineering (CSMR 2011), pp. 45-54, (2011); Mancoridis S., Mitchell B.S., Using automatic clustering to produce high-level system organizations of source code, Proc. 6th International Workshop on Program Comprehension (IWPC 1998), pp. 45-53, (1998); Mahdavi K., Harman M., Hierons R.M., A multiple hill climbing approach to software module clustering, Proc. 19th Int. Conf. on Software Maintenance (ICSM 2003), pp. 315-324, (2003); Dietrich J., Yakovlev V., McCartin C., Jenson G., Duchrow M., Cluster analysis of Java dependency graphs, Proc. 4th ACM Symposium on Software Visualization (Softvis 2008), pp. 91-94, (2008); Constantinou E., Kakarontzas G., Stamelos I., Towards open source software system architecture recovery using design metrics, Proc. 15th Panhellenic Conference on Informatics (PCI 2011), pp. 166-170, (2011); Muhammad S., Maqbool O., Abbasi A., Evaluating relationship categories for clustering object-oriented software systems, IET Software, 6, 3, pp. 260-274, (2012); Pourhaji Kazem A.A., Lotfi S., An evolutionary approach for partitioning weighted module dependency graphs, Proc. 4th Int. Conf. on Innovations in Information Technology (IIT 2007), pp. 252-256, (2007); Chiricota Y., Jourdan F., Melancon G., Software components capture using graph clustering, Proc. 11th IEEE Int. Workshop on Program Comprehension (IWPC 2003), pp. 217-226, (2003); Scanniello G., D'Amico A., D'Amico C., D'Amico T., Architectural layer recovery for software system understanding and evolution, Software Practice and Experience, 40, 6, pp. 897-916, (2010); Corazza A., Martino S.D., Maggio V., Scanniello G., Investigating the use of lexical information for software system clustering, Proc. 15th European Conference on Software Maintenance and Reengineering (CSMR 2011), pp. 35-44, (2011); Misra J., Annervaz K., Kaulgud V., Sengupta S., Titus G., Software clustering: Unifying syntactic and semantic features, Proc. 19th Working Conference on Reverse Engineering (WCRE 2012), pp. 113-122, (2012); Vasconcelos A., Werner C., Software architecture recovery based on dynamic analysis, Proc. 5th Argentine Symposium on Software Engineering (ASSE 2004), (2004); Callo Arias T.B., America P., Avgeriou P., A top-down approach to construct execution views of a large software-intensive system, Journal of Software: Evolution and Process, 25, 3, pp. 233-260, (2013); Vasconcelos A., Werner C., Evaluating reuse and program understanding in Arch-Mine architecture recovery approach, IET Software, 181, 13, pp. 2761-2786, (2011); Andreopoulos B., An A., Tzerpos V., Wang X., Clustering large software systems at multiple layers, Information and Software Technology, 49, 3, pp. 244-254, (2007); Patel C., Hamou-Lhadj A., Rilling J., Software clustering using dynamic analysis and static dependencies, Proc. 13th European Conf. Software Maintenance and Reengineering (CSMR 2009), pp. 27-36, (2009); Corazza A., Di Martino S., Maggio V., Moschitti A., Passerini A., Scanniello G., Silvestri F., Using machine learning and information retrieval techniques to improve software maintainability, Trustworthy Eternal Systems Via Evolving Software, Data and Knowledge, 379, pp. 117-134, (2013); Deiters C., Rausch A., Schindler M., Using spectral clustering to automate identifi-cation and optimization of component structures, Proc. 2nd International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering (RAISE 2013), pp. 14-20, (2013); Sora I., Glodean G., Gligor M., Software architecture reconstruction: An approach based on combining graph clustering and partitioning, Software: Practice and Experience, 40, pp. 259-264, (2010); Naseem R., Maqbool O., Muhammad S., Cooperative clustering for software modularization, Journal of Systems and Software, 86, 8, pp. 2045-2062, (2013); Kang S., Lee S., Lee D., A framework for tool-based software architecture reconstruction, International Journal of Software Engineering and Knowledge Engineering, 19, 2, pp. 283-305, (2009); Tzerpos V., Holt R.C., Mojo: A distance metric for software clustering, Proc. 6th Working Conference on Reverse Engineering (WCRE 1999), pp. 187-193, (1999); Tzerpos V., Holt R.C., On the stability of software clustering algorithms, Proc. 8th International Workshop on Program Comprehension (IWPC 2000), pp. 211-218, (2000); Bittencourt R.A., Serey Guerrero D.D., Comparison of graph clustering algorithms for recovering software architecture module views, Proc. 13th European Conference on Software Maintenance and Reengineering (CSMR 2009), pp. 251-254, (2009); Shtern M., Tzerpos V., On the comparability of software clustering algorithms, Proc. 18th IEEE Int. Conf. on Program Comprehension (ICPC 2010), pp. 64-67, (2010); Mahmoud A., Niu N., Evaluating software clustering algorithms in the context of program comprehension, Proc. 21st IEEE Int. Conf. on Program Comprehension (ICPC 2013), pp. 162-171, (2013); Queyroi F., Delest M., Fedou J.-M., Melancon G., Assessing the quality of multilevel graph clustering, Data Mining and Knowledge Discovery, 28, 1, pp. 1107-1128, (2014); Shtern M., Tzerpos V., Evaluating software clustering using multiple simulated authoritative decompositions, Proc. 27th IEEE Int. Conf. on Software Maintenance Software Maintenance (ICSM 2011), pp. 353-361, (2011); Eder J., Kappel G., Schrefl M., Coupling and Cohesion in Object-oriented Systems, (1994); Software architecture management for Java, .Net, C/C++ and anything with structure101; Xu X., Yuruk N., Feng Z., Schweiger T.A.J., SCAN: A structural clustering algorithm for networks, Proc. 13th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining (KDD 2007), pp. 824-833, (2007); Deursen A.V., Kuipers T., Identifying objects using cluster and concept analysis, Proc. 21st Int. Conf. on Software Engineering (ICSE 1999), pp. 246-255, (1999); Mitchell B.S., Mancoridis S., Comparing the decompositions produced by software clustering algorithms using similarity measurements, Proc. 17th Int. Conf. on Software Maintenance (ICSM 2001), pp. 744-753, (2001)",,,,,,English,Article,Final,,Scopus,2-s2.0-84941884483,252
Chirila C.-B.; Sora I.,"Chirila, Ciprian-Bogdan (27067559900); Sora, Ioana (8300792200)",27067559900; 8300792200,The Optimization of a Page Rank Based Key Classes Classifier using Simulated Annealing with ROC-AUC and Recall Metrics,2019,"SACI 2019 - IEEE 13th International Symposium on Applied Computational Intelligence and Informatics, Proceedings",,,9111601,21,26,5,3,10.1109/SACI46893.2019.9111601,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075065323&doi=10.1109%2fSACI46893.2019.9111601&partnerID=40&md5=1156fad3845e01b6654b7b6870f54408,"Nowadays, software projects from different industrial sectors tend to grow from tens of classes towards sizes of hundreds or even thousands of classes. Key classes or hotspots are the most important classes in a project. They represent the starting point for any maintenance operation. In this context key classes detection is an important software engineering task, especially in projects where documentation is poor or missing totally. In the state of the art there are several key classes classifiers based on different representations and algorithms. We focus on the empirical parameters of a classifier based on weighted graph representation of the source code combined with a Page Rank algorithm which give the best results compared to previous works results available online. The empirical parameters represent weights assigned to several relations between classes like: inheritance between two classes, interface implementation between a class and an interface etc. Initially the parameters were manually set, having empirical values. It is not known if other sets of values for the parameters will not give better diagnostic abilities to the classifier. To test the entire parameters state space is virtually impossible for 12 Java software projects and 15 parameters with values varying in the integer range. Using the Simulated Annealing optimization algorithm we start with the manually set values for the parameters and we optimize the objective functions based on ROC-AUC and Recall metrics. © 2019 IEEE.","Briand L.C., Daly J.W., Wust J.K., A unified framework for coupling measurement in object-oriented systems, IEEE Transactions on Software Engineering, 25, 1, pp. 91-121, (1999); Abreu F.B., Pereira G., Sousa P., A couplingguided cluster analysis approach to reengineer the modularity of objectoriented systems, Proceedings of the Fourth European Conference on Software Maintenance and Reengineering, pp. 13-22, (2000); Sora I., A PageRank based recommender system for identifying key classes in software systems, 2015 IEEE 10th Jubilee International Symposium on Applied Computational Intelligence and Informatics (SACI, pp. 495-500, (2015); Sora I., Glodean G., Gligor M., Software architecture reconstruction: An approach based on combining graph clustering and partitioning, 2010 International Joint Conference on Computational Cybernetics and Technical Informatics (ICCC-CONTI, pp. 259-264, (2010); Ding Y., Li B., He P., An improved approach to identifying key classes in weighted software network, Mathematical Problems in Engineering, 1-9, (2016); Do Nasimento Vale L., De Maia M.A., Keecle: Mining key architecturally relevant classes using dynamic analysis, 2015 IEEE International Conference on Software Maintenance and Evolution (ICSME, pp. 566-570, (2015); Kamran M., Azam F., Khanum A., Discovering core architecture classes to assist initial program comprehension, Proceedings of the 2012 International Conference on Information Technology and Software Engineering of Lecture Notes in Electrical Engineering, 211, pp. 3-10, (2013); Noda K., Kobayasi T., Atsumi N., Identifying core objects for trace summarization by analyzing reference relations and dynamic properties, IEICE Transactions on Information and Systems, E101-D, 7, pp. 1751-1765, (2018); Hafeez Osman M., Chaudron M., Van Der Putten P., An analysis of machine learning algorithms for condensing reverse engineered class diagrams, Proceedings of the 2013 IEEE International Conference on Software Maintenance, ICSM 13, pp. 140-149, (2013); Page L., Brin S., Motwani R., Winograd T., The PageRank Citation Ranking: Bringing Order to the Web. Technical Report 1999-66; Pan W., Song B., Li K., Zhang K., Identifying key classes in object-oriented software using generalized k-core decomposition, Future Generation Computer Systems, 81, pp. 188-202, (2018); Praijapat A., Kumar Chhabra J., Improving modular structure of software system using structural and lexical dependency, Information and Software Technology, 82, pp. 96-120, (2017); Reeves C.R., Modern Heuristic Techniques for Combinatorial Problems, (1992); Savic M., Ivanovic M., Radovanovic M., Analysis of high structural class coupling in object-oriented software systems, Computing, 99, 11, pp. 1055-1079, (2017); Savic M., Rakic G., Budimac Z., Ivanovic M., A language-independent approach to the extraction of dependencies between source code entities, Information and Software Technology, 56, 10, pp. 1268-1288, (2014); Sora I., Helping program comprehension of large software systems by identifying their most important classes, Evaluation of Novel Approaches to Software Engineering, pp. 122-140, (2016); Steidl D., Hummel B., Juergens E., Using network analysis for recommendation of central software classes, 2012 19th Working Conference on Reverse Engineering (WCRE, pp. 93-102; Thung F., Lo D., Hafeez Osman M., Chaudron V.M.R., Condensing class diagrams by analyzing design and network metrics using optimistic classification, Proceedings of the 22nd International Conference on Program Comprehension, ICPC 2014, pp. 110-121, (2014); Yang X., Lo D., Xia X., Sun J., Condensing class diagrams with minimal manual labeling cost, 2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC, 1, pp. 22-31; Zaidman A., Demeyer S., Automatic identification of key classes in a software system using webmining techniques, Journal of Software Maintenance and Evolution: Research and Practice, 20, 6, pp. 387-417, (2008)",,"13th IEEE International Symposium on Applied Computational Intelligence and Informatics, SACI 2019",29 May 2019 through 31 May 2019,Timisoara,160955,English,Conference paper,Final,,Scopus,2-s2.0-85075065323,254
Mirsky Y.; MacOn G.; Brown M.; Yagemann C.; Pruett M.; Downing E.; Mertoguno S.; Lee W.,"Mirsky, Yisroel (6506527584); MacOn, George (58686458400); Brown, Michael (57212081928); Yagemann, Carter (57191431030); Pruett, Matthew (57219764699); Downing, Evan (55481517000); Mertoguno, Sukarno (35611160600); Lee, Wenke (7407083525)",6506527584; 58686458400; 57212081928; 57191431030; 57219764699; 55481517000; 35611160600; 7407083525,VulChecker: Graph-based Vulnerability Localization in Source Code,2023,"32nd USENIX Security Symposium, USENIX Security 2023",9,,,6557,6574,17,4,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172385383&partnerID=40&md5=b65bb84e01429db78bbf2ec291d6097f,"In software development, it is critical to detect vulnerabilities in a project as early as possible. Although, deep learning has shown promise in this task, current state-of-the-art methods cannot classify and identify the line on which the vulnerability occurs. Instead, the developer is tasked with searching for an arbitrary bug in an entire function or even larger region of code. In this paper, we propose VulChecker: a tool that can precisely locate vulnerabilities in source code (down to the exact instruction) as well as classify their type (CWE). To accomplish this, we propose a new program representation, program slicing strategy, and the use of a message-passing graph neural network to utilize all of code's semantics and improve the reach between a vulnerability's root cause and manifestation points. We also propose a novel data augmentation strategy for cheaply creating strong datasets for vulnerability detection in the wild, using free synthetic samples available online.With this training strategy,VulCheckerwas able to identify 24 CVEs (10 from 2019&2020) in 19 projects taken from the wild, with nearly zero false positives compared to a commercial tool that could only detect 4. VulChecker also discovered an exploitable zero-day vulnerability, which has been reported to developers for responsible disclosure. © 2023 32nd USENIX Security Symposium, USENIX Security 2023. All rights reserved.","scikit-optimize: Sequential model-based optimization in python; Application security | cyberres, (2021); Clang static analyzer, (2021); coverity - google search, (2021); Flawfinder home page, (2021); Helix qac for c and c++ | perforce, (2021); Infer static analyzer | infer | infer, (2021); Arakelyan S., Arasteh S., Hauser C., Kline E., Galstyan A., Bin2vec: learning representations of binary executable programs for security tasks, Cybersecurity, 4, 1, pp. 1-14, (2021); Cao S., Sun X., Bo L., Wei Y., Li B., Bgnn4vd: Constructing bidirectional graph neural-network for vulnerability detection, Information and Software Technology, 136, (2021); Chakraborty A., Alam M., Dey V., Chattopadhyay A., Mukhopadhyay D., Adversarial attacks and defences: A survey, (2018); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet, IEEE Transactions on Software Engineering, (2021); Chaudhary A., Mittal H., Arora A., Anomaly detection using graph neural networks, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon). IEEE, pp. 346-350, (2019); Cheng X., Wang H., Hua J., Xu G., Sui Y., Deepwukong: Statically detecting software vulnerabilities using deep graph neural network, ACM Transactions on Software Engineering and Methodology (TOSEM), 30, 3, pp. 1-33, (2021); Cheng X., Wang H., Hua J., Zhang M., Xu G., Yi L., Sui Y., Static detection of control-flow-related vulnerabilities using graph embedding, 2019 24th International Conference on Engineering of Complex Computer Systems (ICECCS). IEEE, pp. 41-50, (2019); Dai H., Dai B., Song L., Discriminative embeddings of latent variable models for structured data, Proceedings of The 33rd International Conference on Machine Learning, ser. Proceedings of Machine Learning Research, 48, pp. 2702-2711, (2016); Ding S. H. H., Fung B. C. M., Charland P., Asm2vec: Boosting static representation robustness for binary clone search against code obfuscation and compiler optimization, 2019 IEEE Symposium on Security and Privacy (SP), pp. 472-489, (2019); Duan Y., Li X., Wang J., Yin H., Deepbindiff: Learning program-wide code representations for binary diffing, Network and Distributed System Security Symposium, (2020); Le Q., Mikolov T., Distributed representations of sentences and documents, International conference on machine learning. PMLR, pp. 1188-1196, (2014); Li X., Wang L., Xin Y., Yang Y., Chen andY., Automated vulnerability detection in source code using minimum intermediate representation learning, Applied Sciences, 10, 5, (2020); Li X., Wang L., Xin Y., Yang Y., Tang Q., Chen Y., Automated software vulnerability detection based on hybrid neural network, Applied Sciences, 11, 7, (2021); Li Z., Zou D., Xu S., Chen Z., Zhu Y., Jin H., Vuldeelocator: a deep learning-based fine-grained vulnerability detector, IEEE Transactions on Dependable and Secure Computing, (2021); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: A framework for using deep learning to detect software vulnerabilities, IEEE Transactions on Dependable and Secure Computing, (2021); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, (2018); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, (2013); Cve, (2021); Software assurance reference dataset; Rolnick D., Veit A., Belongie S., Shavit N., Deep learning is robust to massive label noise, (2017); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE international conference on machine learning and applications (ICMLA). IEEE, pp. 757-762, (2018); Spring T., Microsoft quietly patches another critical malware protection engine flaw | threatpost, (2021); Suneja S., Zheng Y., Zhuang Y., Laredo J., Morari A., Learning to map source code to software vulnerability using code-as-a-graph, (2020); Visalli N., Deng L., Al-Suwaida A., Brown Z., Joshi M., Wei B., Towards automated security vulnerability and software defect localization, 2019 IEEE 17th International Conference on Software Engineering Research, Management and Applications (SERA). IEEE, pp. 90-93, (2019); Wang H., Ye G., Tang Z., Tan S. H., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Transactions on Information Forensics and Security, 16, pp. 1943-1958, (2020); Wang T., Song C., Lee W., Diagnosis and emergency patch generation for integer overflow exploits, International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, pp. 255-275, (2014); White D. R., Borgatti S. P., Betweenness centrality measures for directed graphs, Social networks, 16, 4, pp. 335-346, (1994); Wu Y., Lu J., Zhang Y., Jin S., Vulnerability detection in c/c++ source code with graph representation learning, 2021 IEEE 11th Annual Computing and Communication Workshop and Conference (CCWC). IEEE, pp. 1519-1524, (2021); Xu X., Liu C., Feng Q., Yin H., Song L., Song D., Neural network-based graph embedding for cross-platform binary code similarity detection, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS '17, pp. 363-376, (2017); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy. IEEE, pp. 590-604, (2014); Zagane M., Abdi M. K., Alenezi M., Deep learning for software vulnerabilities detection using code metrics, IEEE Access, 8, pp. 74562-74570, (2020); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, (2019); Zou D., Wang S., Xu S., Li Z., Jin H., μvuldeepecker: A deep learning-based system for multiclass vulnerability detection, IEEE Transactions on Dependable and Secure Computing, (2019); Zou D., Hu Z., Wang Y., Jiang S., Sun Y., Gu Q., Layer-dependent importance sampling for training deep and large graph convolutional networks, Advances in neural information processing systems, 32, (2019)",et al.; Futurewei Technologies; Google; Meta; NSF; TikTok,"32nd USENIX Security Symposium, USENIX Security 2023",9 August 2023 through 11 August 2023,Anaheim,193590,English,Conference paper,Final,,Scopus,2-s2.0-85172385383,256
Viet Phan A.; Le Nguyen M.; Thu Bui L.,"Viet Phan, Anh (57202460791); Le Nguyen, Minh (57193118937); Thu Bui, Lam (56637835900)",57202460791; 57193118937; 56637835900,Convolutional neural networks over control flow graphs for software defect prediction,2017,"Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI",2017-November,,,45,52,7,103,10.1109/ICTAI.2017.00019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048483561&doi=10.1109%2fICTAI.2017.00019&partnerID=40&md5=707b5b2e13cd2bb78a670a75996004a4,"Existing defects in software components is unavoidable and leads to not only a waste of time and money but also many serious consequences. To build predictive models, previous studies focus on manually extracting features or using tree representations of programs, and exploiting different machine learning algorithms. However, the performance of the models is not high since the existing features and tree structures often fail to capture the semantics of programs. To explore deeply programs' semantics, this paper proposes to leverage precise graphs representing program execution flows, and deep neural networks for automatically learning defect features. Firstly, control flow graphs are constructed from the assembly instructions obtained by compiling source code; we thereafter apply multi-view multi-layer directed graph-based convolutional neural networks (DGCNNs) to learn semantic features. The experiments on four real-world datasets show that our method significantly outperforms the baselines including several other deep learning approaches. © 2017 IEEE.","Allen F.E., Control flow analysis, ACM Sigplan Notices, 5, pp. 1-19, (1970); Anderson B., Quist D., Neil J., Storlie C., Lane T., Graph-based malware detection using dynamic analysis, Journal in Computer Virology, 7, 4, pp. 247-258, (2011); Bruschi D., Martignoni L., Monga M., Detecting selfmutating malware using control-flow graph matching, International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, pp. 129-143, (2006); Catal C., Software fault prediction: A literature review and current trends, Expert Systems with Applications, 38, 4, pp. 4626-4636, (2011); Chae D., Ha J., Kim S., Kang B., Gyu Im E., Software plagiarism detection: A graph-based approach, Proceedings of the 22nd ACM International Conference on Conference on Information & Knowledge Management, pp. 1577-1580, (2013); Chidamber S.R., Kemerer C.F., A metrics suite for object oriented design, IEEE Transactions on Software Engineering, 20, 6, pp. 476-493, (1994); Fawcett T., An introduction to roc analysis, Pattern Recognition Letters, 27, 8, pp. 861-874, (2006); Howard Halstead M., Elements of Software Science, 7, (1977); Jones C., Strengths and weaknesses of software metrics, American PROGRAMMER, 10, pp. 44-49, (1997); Kikuchi H., Goto T., Wakatsuki M., Nishino T., A source code plagiarism detecting method using alignment with abstract syntax tree elements, Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD), 2014 15th IEEE/ACIS International Conference on, pp. 1-6, (2014); Ling C.X., Huang J., Zhang H., Auc: A statistically consistent and more discriminating measure than accuracy, IJCAI, 3, pp. 519-524, (2003); Louden K.C., Et al., Programming Languages: Principles and Practices, (2011); McCabe T.J., A complexity measure, IEEE Transactions on Software Engineering, 4, pp. 308-320, (1976); Menzies T., Greenwald J., Frank A., Data mining static code attributes to learn defect predictors, IEEE Transactions on Software Engineering, 33, (2007); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Thirtieth AAAI Conference on Artificial Intelligence, (2016); Anh Phan V., Phuong Chau N., Le Nguyen M., Exploiting tree structures for classifying programs by functionalities, Knowledge and Systems Engineering (KSE), 2016 Eighth International Conference on, pp. 85-90, (2016); Rodriguez D., Herraiz I., Harrison R., Dolado J., Riquelme J.C., Preliminary comparison of techniques for dealing with imbalance in software defect prediction, Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering, (2014); Socher R., Huang E.H., Pennington J., Ng A.Y., Manning C.D., Dynamic pooling and unfolding recursive autoencoders for paraphrase detection, NIPS, 24, pp. 801-809, (2011); Socher R., Pennington J., Huang E.H., Ng A.Y., Manning C.D., Semi-supervised recursive autoencoders for predicting sentiment distributions, Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 151-161, (2011); Socher R., Perelygin A., Wu J.Y., Chuang J., Manning C.D., Ng A.Y., Potts C., Et al., Recursive deep models for semantic compositionality over a sentiment treebank, Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 1631, (2013); Sokolova M., Lapalme G., A systematic analysis of performance measures for classification tasks, Information Processing & Management, 45, 4, pp. 427-437, (2009); Sun X., Zhongyang Y., Xin Z., Mao B., Xie L., Detecting code reuse in android applications using component-based control flow graph, IFIP International Information Security Conference, pp. 142-155, (2014); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, Proceedings of the 38th International Conference on Software Engineering, pp. 297-308, (2016); White M., Vendome C., Linares-Vasquez M., Poshyvanyk D., Toward deep learning software repositories, Mining Software Repositories (MSR) 2015 IEEE/ACM 12th Working Conference on, pp. 334-345, (2015)",IEEE Computer Society,"29th IEEE International Conference on Tools with Artificial Intelligence, ICTAI 2017",6 November 2017 through 8 November 2017,Boston,136944,English,Conference paper,Final,,Scopus,2-s2.0-85048483561,257
Zeng C.; Yu Y.; Li S.; Xia X.; Wang Z.; Geng M.; Bai L.; Dong W.; Liao X.,"Zeng, Chen (57210603252); Yu, Yue (55566298800); Li, Shanshan (55741045700); Xia, Xin (54586248800); Wang, Zhiming (57212532463); Geng, Mingyang (57204642410); Bai, Linxiao (57355120500); Dong, Wei (57190581192); Liao, Xiangke (57205084899)",57210603252; 55566298800; 55741045700; 54586248800; 57212532463; 57204642410; 57355120500; 57190581192; 57205084899,deGraphCS: Embedding Variable-based Flow Graph for Neural Code Search,2023,ACM Transactions on Software Engineering and Methodology,32,2,34,,,,12,10.1145/3546066,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153750091&doi=10.1145%2f3546066&partnerID=40&md5=bd8b4bfceb84f7efe993d499261fbcd2,"With the rapid increase of public code repositories, developers maintain a great desire to retrieve precise code snippets by using natural language. Despite existing deep learning-based approaches that provide end-to-end solutions (i.e., accept natural language as queries and show related code fragments), the performance of code search in the large-scale repositories is still low in accuracy because of the code representation (e.g., AST) and modeling (e.g., directly fusing features in the attention stage). In this paper, we propose a novel learnable deep Graph for Code Search (called deGraphCS) to transfer source code into variable-based flow graphs based on an intermediate representation technique, which can model code semantics more precisely than directly processing the code as text or using the syntax tree representation. Furthermore, we propose a graph optimization mechanism to refine the code representation and apply an improved gated graph neural network to model variable-based flow graphs. To evaluate the effectiveness of deGraphCS, we collect a large-scale dataset from GitHub containing 41,152 code snippets written in the C language and reproduce several typical deep code search methods for comparison. The experimental results show that deGraphCS can achieve state-of-the-art performance and accurately retrieve code snippets satisfying the needs of the users.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Bahdanau D., Cho K., Bengio Y., Neural machine translation by jointly learning to align and translate, (2014); Bajracharya S., Ngo T., Linstead E., Dou Y., Rigor P., Baldi P., Lopes C., Sourcerer: A search engine for open source code supporting structure-based search, Companion to the 21st ACM SIGPLAN Symposium on Object-oriented Programming Systems, Languages, and Applications, pp. 681-682, (2006); Ben-Nun T., Shoshana Jakobovits A., Hoefler T., Neural code comprehension: A learnable representation of code semantics, Advances in Neural Information Processing Systems 31, pp. 3585-3597, (2018); Brandt J., Dontcheva M., Weskamp M., Klemmer S.R., Example-centric programming: Integrating web search into the development environment, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 513-522, (2010); Cai L., Wang H., Huang Q., Xia X., Xing Z., Lo D., BIKER: A tool for Bi-information source based API method recommendation (ESEC/FSE 2019), (2019); Caldeira P.M., Sakamoto K., Washizaki H., Fukazawa Y., Shimada T., Improving syntactical clone detection methods through the use of an intermediate representation, 2020 IEEE 14th International Workshop on Software Clones (IWSC), pp. 8-14, (2020); Cambronero J., Li H., Kim S., Sen K., Chandra S., When deep learning met code search, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 964-974, (2019); Angus Campbell B., Treude C., NLP2Code: Code snippet content assist via natural language tasks, 2017 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 628-632, (2017); Chan W.-K., Cheng H., Lo D., Searching connected API subgraph via text phrases, Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering, pp. 1-11, (2012); Chen Q., Zhou M., A neural framework for retrieval and summarization of source code, 2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 826-831, (2018); Chen X., Liu C., Song D., Tree-to-tree neural networks for program translation, Advances in Neural Information Processing Systems, 31, pp. 2547-2557, (2018); Chung J., Gulcehre C., Cho K., Bengio Y., Empirical evaluation of gated recurrent neural networks on sequence modeling, CoRR, (2014); Cytron R., Ferrante J., Rosen B.K., Wegman M.N., Kenneth Zadeck F., Efficiently computing static single assignment form and the control dependence graph, ACM Trans. Program. Lang. Syst., 13, 4, pp. 451-490, (1991); Khanh Dam H., Tran T., Pham T., A deep language model for software code, (2016); DeFreez D., Thakur A.V., Rubio-Gonzalez C., Path-based function embedding and its application to specification mining, (2018); Devlin J., Chang M.-W., Lee K., Toutanova K., BERT: Pre-training of deep bidirectional transformers for language understanding, (2018); Dietrich T., Cleland-Huang J., Shin Y., Learning effective query transformations for enhanced requirements trace retrieval, 2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 586-591, (2013); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020 (Findings of ACL), pp. 1536-1547, (2020); Gu W., Li Z., Gao C., Wang C., Zhang H., Xu Z., Lyu M.R., CRaDLe: Deep code retrieval based on semantic dependency learning, Neural Networks, 141, pp. 385-394, (2021); Gu X., Zhang H., Kim S., Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE), pp. 933-944, (2018); Gu X., Zhang H., Zhang D., Kim S., Deep API learning, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 631-642, (2016); Haiduc S., Bavota G., Marcus A., Oliveto R., De Lucia A., Menzies T., Automatic query reformulations for text retrieval in software engineering, 2013 35th International Conference on Software Engineering (ICSE), pp. 842-851, (2013); Haldar R., Wu L., Xiong J., Hockenmaier J., A Multi-Perspective Architecture for Semantic Code Search, (2020); Henkel J., Lahiri S.K., Liblit B., Reps T., Code vectors: Understanding programs through embedded abstracted symbolic traces, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 163-174, (2018); Hill E., Pollock L., Vijay-Shanker K., Improving source code search with natural language phrasal representations of method signatures, 2011 26th IEEE/ACMInternational Conference on Automated Software Engineering (ASE 2011), pp. 524-527, (2011); Hill E., Roldan-Vega M., Alan Fails J., Mallet G., NL-based query refinement and contextualized code search results: A user study, 2014 Software Evolution Week-IEEE Conference on Software Maintenance, Reengineering, and Reverse Engineering (CSMR-WCRE), pp. 34-43, (2014); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); Holmes R., Cottrell R., Walker R.J., Denzinger J., The end-to-end use of source code examples: An exploratory study, 2009 IEEE International Conference on Software Maintenance, pp. 555-558, (2009); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, 2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC), pp. 200-20010, (2018); Huang Q., Xia X., Xing Z., Lo D., Wang X., API method recommendation without worrying about the task-API knowledge gap, 2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 293-304, (2018); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., CodeSearchNet challenge: Evaluating the state of semantic code search, CoRR, (2019); Husain H., Wu H.-H., How to create natural language semantic search for arbitrary objects with deep learning, Retrieved November, 5, (2018); Husain H., Wu H.-H., Towards natural language semantic code search, Retrieved November, 5, (2018); Keivanloo I., Rilling J., Zou Y., Spotting working code examples, Proceedings of the 36th International Conference on Software Engineering, pp. 664-675, (2014); Lattner C., Adve V., LLVM: A compilation framework for lifelong program analysis & transformation, International Symposium on Code Generation and Optimization, 2004. CGO 2004, pp. 75-86, (2004); Augusto Lazzarini Lemos O., Bajracharya S., Ossher J., Cesar Masiero P., Lopes C., A test-driven approach to code search and its application to the reuse of auxiliary functionality, Information and Software Technology, 53, 4, pp. 294-306, (2011); Lemos O.A.L., De Paula A.C., Zanichelli F.C., Lopes C.V., Thesaurus-based automatic query expansion for interface-driven code search, Proceedings of the 11th Working Conference on Mining Software Repositories, pp. 212-221, (2014); Augusto Lazzarini Lemos O., Krishna Bajracharya S., Ossher J., CodeGenie: A tool for test-driven source code search, Companion to the 22nd Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, pp. 917-918, (2007); Li X., Wang Z., Wang Q., Yan S., Xie T., Mei H., Relationship-aware code search for JavaScript frameworks, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 690-701, (2016); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, (2015); Li Z., Yu Y., Wang T., Yin G., Li S., Wang H., Are you still working on this? An empirical study on pull request abandonment, IEEE Transactions on Software Engineering, (2021); Li Z., Yu Y., Zhou M., Wang T., Yin G., Lan L., Wang H., Redundancy, context, and preference: An empirical study of duplicate pull requests in OSS projects, IEEE Transactions on Software Engineering, (2020); Loshchilov I., Hutter F., Fixing weight decay regularization in Adam, CoRR, (2017); Lu M., Sun X., Wang S., Lo D., Duan Y., Query expansion viaWordNet for effective code search, 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER), pp. 545-549, (2015); Lv F., Zhang H., Lou J.-G., Wang S., Zhang D., Zhao J., CodeHow: Effective code search based on API understanding and extended Boolean model (e), 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 260-270, (2015); McMillan C., Grechanik M., Poshyvanyk D., Fu C., Xie Q., Exemplar: A source code search engine for finding highly relevant applications, IEEE Transactions on Software Engineering, 38, 5, pp. 1069-1087, (2011); McMillan C., Grechanik M., Poshyvanyk D., Xie Q., Fu C., Portfolio: Finding relevant functions and their usage, Proceedings of the 33rd International Conference on Software Engineering, pp. 111-120, (2011); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, (2014); Mover S., Sankaranarayanan S., Braginton Pettee Olsen R., Evan Chang B.-Y., Mining framework usage graphs from app corpora, 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 277-289, (2018); Tuan Nguyen A., Anh Nguyen H., Thanh Nguyen T., Nguyen T.N., GraPacc: A graph-based pattern-oriented, context-sensitive code completion tool, 2012 34th International Conference on Software Engineering (ICSE), pp. 1407-1410, (2012); Anh Nguyen H., Thanh Nguyen T., Wilson G., Tuan Nguyen A., Kim M., Nguyen T.N., A graph-based approach to API usage adaptation, ACM SIGPLAN Notices, 45, 10, pp. 302-321, (2010); Thanh Nguyen T., Anh Nguyen H., Pham N.H., Al-Kofahi J.M., Nguyen T.N., Graph-based mining of multiple object usage patterns, Proceedings of the 7th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, pp. 383-392, (2009); Piech C., Huang J., Nguyen A., Phulsuksombati M., Sahami M., Guibas L., Learning program embeddings to propagate feedback on student code, (2015); Raychev V., Vechev M., Yahav E., Code completion with statistical language models, Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 419-428, (2014); Reiss S.P., Semantics-based code search, 2009 IEEE 31st International Conference on Software Engineering, pp. 243-253, (2009); Sachdev S., Li H., Luan S., Kim S., Sen K., Chandra S., Retrieval on source code: A neural code search, Proceedings of the 2nd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages, pp. 31-41, (2018); Schafer A., Amme W., Heinze T.S., Detection of similar functions through the use of dominator information, 2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C), pp. 206-211, (2020); Shuai J., Xu L., Liu C., Yan M., Xia X., Lei Y., Improving code search with co-attentive representation learning, 28th International Conference on Program Comprehension (ICPC), (2020); Stolee K.T., Finding suitable programs: Semantic search with incomplete and lightweight specifications, 2012 34th International Conference on Software Engineering (ICSE), pp. 1571-1574, (2012); Su F.-H., Bell J., Harvey K., Sethumadhavan S., Kaiser G., Jebara T., Code Relatives: Detecting similarly behaving software, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering (FSE 2016), pp. 702-714, (2016); Sui Y., Cheng X., Zhang G., Wang H., Flow2Vec: Value-flow-based precise code embedding, Proc.ACM Program. Lang., 4, (2020); Sheng Tai K., Socher R., Manning C.D., Improved semantic representations from treestructured long short-termmemory networks, CoRR, (2015); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, 2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR), pp. 542-553, (2018); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P., Multi-modal attention network learning for semantic source code retrieval, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 13-25, (2019); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Wang C., Nong Z., Gao C., Li Z., Zeng J., Xing Z., Liu Y., Enriching query semantics for code search with reinforcement learning, Neural Networks, 145, pp. 22-32, (2022); Wang S., Lo D., Jiang L., Active code search: Incorporating user feedback to improve code search relevance, Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering, pp. 677-682, (2014); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 261-271, (2020); Wang Y., Wang W., Joty S.R., Hoi S.C.H., CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, pp. 8696-8708, (2021); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, IJCAI, pp. 3034-3040, (2017); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, 2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 87-98, (2016)",,,,,,English,Article,Final,,Scopus,2-s2.0-85153750091,258
Ma Y.; Yu Y.; Li S.; Jia Z.; Ma J.; Xu R.; Dong W.; Liao X.,"Ma, Yingwei (58293644300); Yu, Yue (55566298800); Li, Shanshan (55741045700); Jia, Zhouyang (56733791600); Ma, Jun (56873512900); Xu, Rulin (57746593800); Dong, Wei (57190581192); Liao, Xiangke (57205084899)",58293644300; 55566298800; 55741045700; 56733791600; 56873512900; 57746593800; 57190581192; 57205084899,MulCS: Towards a Unified Deep Representation for Multilingual Code Search,2023,"Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",,,,120,131,11,5,10.1109/SANER56733.2023.00021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160560651&doi=10.1109%2fSANER56733.2023.00021&partnerID=40&md5=7891f2c53d03c2ddb212c471a64458da,"Code search aims to search for relevant code snippets through queries, which has become an essential requirement to assist programmers in software development. With the availability of large and rapidly growing source code repositories covering various languages, multilingual code search can leverage more training data to learn complementary information across languages. Contrastive learning can naturally understand the similarity between functionally equivalent code across different languages by narrowing the distance between objects with the same function while keeping dissimilar objects further apart. Some works exist addressing monolingual code search problems with contrastive learning, however, they mainly exploit every specific programming language's textual semantics or syntactic structures for code representation. Due to the high diversity of different languages in terms of syntax, format, and structure, these methods limit the performance of contrastive learning in multilingual training. To bridge this gap, we propose a unified semantic graph representation approach toward multilingual code search called MulCS. Specifically, we first design a general semantic graph construction strategy across different languages by Intermediate Representation (IR). Furthermore, we introduce the contrastive learning module integrated into a gated graph neural network (GGNN) to enhance query-multilingual code matching. The extensive experiments on three representative languages illustrate that our method outperforms state-of-the-art models by 10.7% to 77.5% in terms of MRR on average. © 2023 IEEE.","Keivanloo I., Rilling J., Zou Y., Spotting working code examples, Proceedings of the 36th International Conference on Software Engineering, pp. 664-675, (2014); Li X., Wang Z., Wang Q., Yan S., Xie T., Mei H., Relationshipaware code search for javascript frameworks, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 690-701, (2016); Lv F., Zhang H., Lou J.-G., Wang S., Zhang D., Zhao J., Codehow: Effective code search based on api understanding and extended boolean model (e), 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 260-270, (2015); Cambronero J., Li H., Kim S., Sen K., Chandra S., When deep learning met code search, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 964-974, (2019); Chen Q., Zhou M., A neural framework for retrieval and summarization of source code, 2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 826-831, (2018); DeFreez D., Thakur A.V., Rubio-Gonzalez C., Path-based function embedding and its application to specification mining, (2018); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P., Multimodal attention network learning for semantic source code retrieval, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 13-25, (2019); Gu X., Zhang H., Kim S., Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE), pp. 933-944, (2018); Shuai J., Xu L., Liu C., Yan M., Xia X., Lei Y., Improving code search with co-attentive representation learning, Proceedings of the 28th International Conference on Program Comprehension, pp. 196-207, (2020); Bissyande T.F., Thung F., Lo D., Jiang L., Reveillere L., Popularity, interoperability, and impact of programming languages in 100, 000 open source projects, Computer Software and Applications Conference (COMPSAC), 2013 IEEE 37th Annual, (2013); Prechelt L., An empirical comparison of seven programming languages, Computer, 33, 10, pp. 23-29, (2000); Bui N.D., Yu Y., Jiang L., Self-supervised contrastive learning for code retrieval and summarization via semantic-preserving transformations, Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 511-521, (2021); Huang J., Tang D., Shou L., Gong M., Xu K., Jiang D., Zhou M., Duan N., Cosqa: 20, 000+ web queries for code search and question answering, (2021); Jain P., Jain A., Zhang T., Abbeel P., Gonzalez J.E., Stoica I., Contrastive code representation learning, (2020); Li X., Gong Y., Shen Y., Qiu X., Zhang H., Yao B., Qi W., Jiang D., Chen W., Duan N., Coderetriever: Unimodal and bimodal contrastive learning, (2022); Sun Z., Li L., Liu Y., Du X., On the importance of building high-quality training datasets for neural code search, (2022); Kochhar P.S., Wijedasa D., Lo D., A large scale study of multiple programming languages and code quality, 2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER), 1, pp. 563-573, (2016); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, IJCAI, pp. 3034-3040, (2017); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 783-794, (2019); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., Codebert: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Wang X., Wang Y., Mi F., Zhou P., Wan Y., Liu X., Li L., Wu H., Liu J., Jiang X., Syncobert: Syntax-guided multi-modal contrastive pre-training for code representation, (2021); Ahmed T., Devanbu P., Multilingual training for software engineering, (2021); Zeng C., Yu Y., Li S., Xia X., Wang Z., Geng M., Xiao B., Dong W., Liao X., degraphcs: Embedding variable-based flow graph for neural code search, (2021); Gupta P., Mehrotra N., Purandare R., Jcoffee: Using compiler feedback to make partial code snippets compilable, 2020 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 810-813, (2020); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, (2015); Cho K., Van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using rnn encoder-decoder for statistical machine translation, (2014); Hochreiter S., Schmidhuber J., Long short-term memory, Neural computation, 9, 8, pp. 1735-1780, (1997); Bahdanau D., Cho K., Bengio Y., Neural machine translation by jointly learning to align and translate, (2014); He K., Fan H., Wu Y., Xie S., Girshick R., Momentum contrast for unsupervised visual representation learning, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 9729-9738, (2020); Van Oord Den A., Li Y., Vinyals O., Representation learning with contrastive predictive coding, (2018); Wu Z., Xiong Y., Yu S.X., Lin D., Unsupervised feature learning via non-parametric instance discrimination, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3733-3742, (2018); Wang Y., Wang W., Joty S.R., Hoi S.C.H., Codet5: Identifieraware unified pre-trained encoder-decoder models for code understanding and generation, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, pp. 8696-8708, (2021); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet challenge: Evaluating the state of semantic code search, (2019); Xu L., Yang H., Liu C., Shuai J., Yan M., Lei Y., Xu Z., Twostage attention-based model for code search with textual and structural features, 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 342-353, (2021); Loshchilov I., Hutter F., Fixing weight decay regularization in adam, (2018); Liu S., Xie X., Ma L., Siow J., Liu Y., Graphsearchnet: Enhancing gnns via capturing global dependency for semantic code search, (2021); Bajracharya S., Ngo T., Linstead E., Dou Y., Rigor P., Baldi P., Lopes C., Sourcerer: a search engine for open source code supporting structure-based search, Companion to the 21st ACM SIGPLAN symposium on Object-oriented programming systems, languages, and applications, pp. 681-682, (2006); Chan W.-K., Cheng H., Lo D., Searching connected api subgraph via text phrases, Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering, pp. 1-11, (2012); Holmes R., Cottrell R., Walker R.J., Denzinger J., The end-toend use of source code examples: An exploratory study, 2009 IEEE International Conference on Software Maintenance, pp. 555-558, (2009); Grechanik M., Fu C., Xie Q., McMillan C., Poshyvanyk D., Cumby C., A search engine for finding highly relevant applications, Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering, 1, pp. 475-484, (2010); McMillan C., Grechanik M., Poshyvanyk D., Xie Q., Fu C., Portfolio: finding relevant functions and their usage, Proceedings of the 33rd International Conference on Software Engineering, pp. 111-120, (2011); Gu X., Zhang H., Zhang D., Kim S., Deep api learning, Proceedings of the 2016 24th ACM SIGSOFT international symposium on foundations of software engineering, pp. 631-642, (2016); Henkel J., Lahiri S.K., Liblit B., Reps T., Code vectors: Understanding programs through embedded abstracted symbolic traces, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 163-174, (2018); Huang Q., Xia X., Xing Z., Lo D., Wang X., Api method recommendation without worrying about the task-api knowledge gap, 2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 293-304, (2018); Sachdev S., Li H., Luan S., Kim S., Sen K., Chandra S., Retrieval on source code: a neural code search, Proceedings of the 2nd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages, pp. 31-41, (2018); Wang D., Yu Y., Li S., Dong W., Wang J., Qing L., Mulcode: A multi-task learning approach for source code understanding, 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 48-59, (2021); Wang D., Jia Z., Li S., Yu Y., Xiong Y., Dong W., Liao X., Bridging pre-trained models and downstream tasks for source code understanding, Proceedings of the 44th International Conference on Software Engineering, pp. 287-298, (2022); Liu Y., Yang X., Zhou S., Liu X., Wang Z., Liang K., Tu W., Li L., Duan J., Chen C., Hard sample aware network for contrastive deep graph clustering, (2022); Peng D., Zheng S., Li Y., Ke G., He D., Liu T.-Y., How could neural networks understand programs?, International Conference on Machine Learning, pp. 8476-8486, (2021)",IEEE; IEEE Computer Society; Macau University of Science and Technology (MUST),"30th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",21 March 2023 through 24 March 2023,Macao,188717,English,Conference paper,Final,,Scopus,2-s2.0-85160560651,259
Chen Z.,"Chen, Zeng (57210603252)",57210603252,Semantic based Cross-Language Clone Related Bug Detection,2021,"Proceedings - 2021 2nd International Seminar on Artificial Intelligence, Networking and Information Technology, AINIT 2021",,,,494,499,5,1,10.1109/AINIT54228.2021.00101,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127493196&doi=10.1109%2fAINIT54228.2021.00101&partnerID=40&md5=6ced2448716044d6fed75c1d1331ad66,"Code clones are widespread in software since programmers always reuse code to reduce programming effort. As programming languages are continuing to evolve and morph, code clones also widely exist across different languages for platform compatibility and adoption. Although code clones can improve development efficiency, they are prone to introducing bugs. Existing code clone detection technologies, however, mainly focused on single programming language or syntactical features of code. The syntax of different programming language are diverse because of syntax sugar, and many cloning pairs are semantic related instead of syntactic similar, such as Type 4 clones. To bridge the gap between syntax and semantic, and detect clone-related bugs more accurately, we explore an IR (Intermediate Representation) based method to represent code semantic representation information of multiple language code. We utilize graph neural network to learn code semantic representation. Through the semantic representation, we can detect more cross-language clone related bugs across multiple language.  © 2021 IEEE.","Nafi K.W., Kar T.S., Roy B., Roy C.K., Schneider K.A., CLCDSA: Cross language code clone detection using syntactical features and API documentation, Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering, pp. 1026-1037, (2019); Jiang L., Su Z., Chiu E., Context-based detection of clone-related bugs, Proceedings of the the 6th Joint Meeting of the European Software Engineering Conference and the Acm Sigsoft Symposium on the Foundations of Software Engineering (ESEC-FSE '07), pp. 55-64, (2007); Koschke R., Bazrafshan S., Software-clone rates in open source programs written in C or C+, 2016 Ieee 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER), 3, pp. 1-7, (2016); Bissyande T.F., Thung F., Lo D., Jiang L., Reveillere L., Popularity, interoperability, and impact of programming languages in 100, 000 open source projects, 2013 Ieee 37th Annual Computer Software and Applications Conference, pp. 303-312, (2013); Chou A., Yang J., Chelf B., Hallem S., Engler D.R., An empirical study of operating system errors, Symposium on Operating Systems Principles, pp. 73-88, (2001); Perez D., Chiba S., Cross-language clone detection by learning over abstract syntax trees, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), pp. 518-528, (2019); Kraft N.A., Bonds B.W., Smith R.K., Cross-language clone detection, Proceedings of Seke, pp. 54-59, (2008); Li Z., Lu S., Myagmar S., Zhou Y., CP Miner: A tool for finding copy-paste and related bugs in operating system code, Proceedings of the 6th Conference on Symposium on Operating Systems Design & Implementation - Volume 6 (OSDI'04, (2004); Gao Z., Jayasundara V., Jiang L., Xia X., Lo D., Grundy J., Smart embed: A tool for clone and bug detection in smart contracts through structural code embedding, 2019 Ieee International Conference on Software Maintenance and Evolution (ICSME), pp. 394-397, (2019); Prechelt L., An empirical comparison of seven programming languages, Computer, 33, 10, pp. 23-29, (2000); Gupta P., Mehrotra N., Purandare R., J coffee: Using compiler feedback to make partial code snippets compilable, 2020 Ieee International Conference on Software Maintenance and Evolution (ICSME), pp. 810-813, (2020); Zeng C., Yu Y., Li S., Xia X., Wang Z., Geng M., Xiao B., Dong W., Liao X., DeGraphCS: Embedding Variable-based Flow Graph for Neural Code Search, (2021); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated Graph Sequence Neural Networks, (2015); Lachaux M.-A., Roziere B., Chanussot L., Lample G., Unsupervised Translation of Programming Languages, (2020); Li Y., Gu C., Dullien T., Vinyals O., Kohli P., Graph matching networks for learning the similarity of graph structured objects, International Conference on Machine Learning, pp. 3835-3845, (2019); Cho K., Merrienboer B.V., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning Phrase Representations Using Rnn Encoder-decoder for Statistical Machine Translation, (2014); Nafi K.W., Kar T.S., Roy B., Roy C.K., Schneider K.A., Clcdsa: Cross language code clone detection using syntactical features and api documentation, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 1026-1037, (2019); Wan Y., Shu J., Sui Y., Xu G., Zhao Z., Wu J., Yu P., Multimodal attention network learning for semantic source code retrieval, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 13-25, (2019); Mao X., Lei Y., Dai Z., Qi Y., Wang C., Slice-based statistical fault localization, Journal of Systems Software, 89, pp. 51-62, (2014); Zhou X., Wang H., Peng W., Ding B., Wang R., Solving Multi-scenario Cardinality Constrained Optimization Problems Via Multi-objective Evolutionary Algorithms, 62, 9, pp. 69-86, (2019)",,"2nd International Seminar on Artificial Intelligence, Networking and Information Technology, AINIT 2021",15 October 2021 through 17 October 2021,"Virtual, Shanghai",177613,English,Conference paper,Final,,Scopus,2-s2.0-85127493196,260
Lin G.; Zhang J.; Luo W.; Pan L.; Xiang Y.; De Vel O.; Montague P.,"Lin, Guanjun (57195557433); Zhang, Jun (57198771239); Luo, Wei (57218392471); Pan, Lei (55800992300); Xiang, Yang (57114147900); De Vel, Olivier (56429241700); Montague, Paul (7004572755)",57195557433; 57198771239; 57218392471; 55800992300; 57114147900; 56429241700; 7004572755,Cross-Project Transfer Representation Learning for Vulnerable Function Discovery,2018,IEEE Transactions on Industrial Informatics,14,7,,3289,3297,8,162,10.1109/TII.2018.2821768,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044759580&doi=10.1109%2fTII.2018.2821768&partnerID=40&md5=7b39cae920b250cce5566de38edd8f68,"Machine learning is now widely used to detect security vulnerabilities in the software, even before the software is released. But its potential is often severely compromised at the early stage of a software project when we face a shortage of high-quality training data and have to rely on overly generic hand-crafted features. This paper addresses this cold-start problem of machine learning, by learning rich features that generalize across similar projects. To reach an optimal balance between feature-richness and generalizability, we devise a data-driven method including the following innovative ideas. First, the code semantics are revealed through serialized abstract syntax trees (ASTs), with tokens encoded by Continuous Bag-of-Words neural embeddings. Next, the serialized ASTs are fed to a sequential deep learning classifier (Bi-LSTM) to obtain a representation indicative of software vulnerability. Finally, the neural representation obtained from existing software projects is then transferred to the new project to enable early vulnerability detection even with a small set of training labels. To validate this vulnerability detection approach, we manually labeled 457 vulnerable functions and collected 30 000+ nonvulnerable functions from six open-source projects. The empirical results confirmed that the trained model is capable of generating representations that are indicative of program vulnerability and is adaptable across multiple projects. Compared with the traditional code metrics, our transfer-learned representations are more effective for predicting vulnerable functions, both within a project and across multiple projects. © 2005-2012 IEEE.","Abadi M., Et al., Tensorflow: A system for large-scale machine learning, Operating Syst. Des. Implementation, 16, pp. 265-283, (2016); Cadar C., Et al., Klee: Unassisted and automatic generation of highcoverage tests for complex systems programs, Operating Syst. Des. Implementation, 8, pp. 209-224, (2008); Chollet F., Et al., Keras, (2015); Chowdhury I., Zulkernine M., Using complexity, coupling, and cohesion metrics as early indicators of vulnerabilities, J. Syst. Archit., 57, 3, pp. 294-313, (2011); Christopher P.R., Manning D., Schutze H., Introduction to Information Retrieval, (2009); Engler D., Chen D.Y., Hallem S., Chou A., Chelf B., Bugs as deviant behavior: A general approach to inferring errors in systems code, ACM SIGOPS Operating Syst. Rev., 35, 5, pp. 57-72, (2001); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput., 9, 8, pp. 1735-1780, (1997); Jang J., Agrawal A., Brumley D., Redebug: Finding unpatched code clones in entire OS distributions, Proc. 2012 IEEE Symp. Security Privacy, pp. 48-62, (2012); Kim S., Woo S., Lee H., Oh H., VUDDY: A scalable approach for vulnerable code clone discovery, Proc. 2017 IEEE Symp. Security Privacy, pp. 595-614, (2017); Li Z., Zou D., Xu S., Jin H., Qi H., Hu J., VulPecker: An automated vulnerability detection system based on code similarity analysis, Proc. 32nd Annu. Conf. Comp. Security Appl., pp. 201-213, (2016); Lin G., Zhang J., Luo W., Pan L., Xiang Y., POSTER: Vulnerability discovery with function representation learning from unlabeled projects, Proc. 2017 ACM SIGSAC Conf. Comput. Security, pp. 2539-2541, (2017); Meneely A., Williams L., Secure open source collaboration: An empirical study of Linus' law, Proc. 16th ACM Conf. Comput. Commun. Security, pp. 453-462, (2009); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, Proc. ICLR Workshop, (2013); Mikolov T., Karafiat M., Burget L., Cernocky J., Khudanpur S., Recurrent neural network based language model, Eleventh Annual Conference of the International Speech Communication Association, pp. 1045-1048, (2010); Moonen L., Generating robust parsers using island grammars, Proc. IEEE 8th Working Conf. Reverse Eng., pp. 13-22, (2001); Neuhaus S., Zimmermann T., Holler C., Zeller A., Predicting vulnerable software components, Proc. 14th Conf. Comput. Commun. Security, pp. 529-540, (2007); Newsome J., Song D., Dynamic taint analysis for automatic detection, analysis, and signature generation of exploits on commodity software, Proceedings of NDSS, (2005); Olah C., Understanding LSTM networks, GITHUB Blo, 27, (2015); Pedregosa F., Et al., Scikit-learn: Machine learning in Python, J. Mach. Learn. Res., 12, pp. 2825-2830, (2011); Perl H., Et al., VCCfinder: Finding potential vulnerabilities in opensource projects to assist code audits, Proc. 22nd ACM SIGSAC Conf. Comput. Commun. Security, pp. 426-437, (2015); Schuster M., Paliwal K.K., Bidirectional recurrent neural networks, IEEE Trans. Signal Process., 45, 11, pp. 2673-2681, (1997); Shin Y., Meneely A., Williams L., Osborne J.A., Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities, IEEE Trans. Softw. Eng., 37, 6, pp. 772-787, (2011); Sutton M., Greene A., Amini P., Fuzzing: Brute Force Vulnerability Discovery, (2007); Yamaguchi F., Lindner F., Rieck K., Vulnerability extrapolation: Assisted discovery of vulnerabilities usingmachine learning, Proceedings of the 5th USENIX Conference on Offensive Technologies, (2011); Yamaguchi F., Lottmann M., Rieck K., Generalized vulnerability extrapolation using abstract syntax trees, Proc. 28th Annu. Comp. Security Appl. Conf., pp. 359-368, (2012); Yamaguchi F., Wressnegger C., Gascon H., Rieck K., Chucky: Exposingmissing checks in source code for vulnerability discovery, Proc. 2013 ACM SIGSAC Comp. Commun. Security, pp. 499-510, (2013)",,,,,,English,Article,Final,,Scopus,2-s2.0-85044759580,261
Zhang C.; Xin Y.,"Zhang, Chunyong (57776483000); Xin, Yang (23479035200)",57776483000; 23479035200,VulGAI: vulnerability detection based on graphs and images,2023,Computers and Security,135,,103501,,,,2,10.1016/j.cose.2023.103501,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173161023&doi=10.1016%2fj.cose.2023.103501&partnerID=40&md5=9e57107e2986651d8ddcf8caabc908fc,"Deep learning models have been widely used in the field of vulnerability detection. Deep learning-based vulnerability detection methods can automatically learn code patterns. Some methods consider processing codes as text sequences to achieve scalable vulnerability detection. They leverage natural language processing models to extract code features. These methods do not consider the code's semantic structure and treat code slices as text. Vulnerability detection methods based on graph structures and graph neural networks are more accurate than text-based methods. However, these methods lack scalability in practice. Both graph generation and graph neural network training are all time-consuming. We propose a vulnerability detection method based on graphs and images (VulGAI). VulGAI choose the more reasonable node centrality to generate the image. It can preserve program details and distinguish node importance from different perspectives. In addition, we design a more efficient CNN model, which reduces computational overhead and improves detection performance (Time and Accuracy). We implement VulGAI and evaluate six methods (VulDePecker, SySeVR, Devign, VulCNN, mVulPreter, and VulGAI) on 40,657 functions. Experimental results show that VulGAI achieves higher Accuracy, TPR, and F1-Score than the others. In addition, we compare VulGAI and VulCNN on 30270 real-world functions. VulGAI outperforms VulCNN by 1.48 times in the number of TP. VulGAI is about 3.9 times faster than VulCNN in detection time. © 2023 Elsevier Ltd","Cao S., Sun X., Bo L., Wei Y., Li B., Bgnn4vd: constructing bidirectional graph neural-network for vulnerability detection, Inf. Softw. Technol., 136, (2021); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: are we there yet, IEEE Trans. Softw. Eng., (2021); Chattopadhay A., Sarkar A., Howlader P., Balasubramanian V.N., Grad-CAM++: generalized gradient-based visual explanations for deep convolutional networks, 2018 IEEE Winter Conference on Applications of Computer Vision, WACV, pp. 839-847, (2018); Chen H., Xue Y., Li Y., Chen B., Xie X., Wu X., Liu Y., Hawkeye: towards a desired directed grey-box fuzzer, Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pp. 2095-2108, (2018); Cheng X., Wang H., Hua J., Xu G., Sui Y., DeepWukong: statically detecting software vulnerabilities using deep graph neural network, ACM Trans. Softw. Eng. Methodol., 30, pp. 1-33, (2021); Cheng X., Zhang G., Wang H., Sui Y., Path-sensitive code embedding via contrastive learning for software vulnerability detection, Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 519-531, (2022); Fan Y., Wan C., Fu C., Han L., Xu H., VDoTR: vulnerability detection based on tensor representation of comprehensive code graphs, Comput. Secur., 130, (2023); Freeman L.C., Et al., Centrality in social networks: conceptual clarification, Social Network: Critical Concepts in Sociology, 1, pp. 238-263, (2002); Ghaffarian S.M., Shahriari H.R., Software vulnerability analysis and discovery using machine-learning and data-mining techniques: a survey, ACM Comput. Surv., 50, pp. 1-36, (2017); Grover A., Leskovec J., node2vec: scalable feature learning for networks, Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 855-864, (2016); Hanif H., Nasir M.H.N.M., Ab Razak M.F., Firdaus A., Anuar N.B., The rise of software vulnerability: taxonomy of software vulnerabilities detection and machine learning approaches, J. Netw. Comput. Appl., 179, (2021); Hin D., Kan A., Chen H., Babar M.A., LineVD: statement-level vulnerability detection using graph neural networks, Proceedings of the 19th International Conference on Mining Software Repositories, pp. 596-607, (2022); Katz L., A new status index derived from sociometric analysis, Psychometrika, 18, pp. 39-43, (1953); Kermarrec A.M., Le Merrer E., Sericola B., Tredan G., Second order centrality: distributed assessment of nodes criticity in complex networks, Comput. Commun., 34, pp. 619-628, (2011); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Commun. ACM, 60, pp. 84-90, (2017); Le Merrer E., Tredan G., Le Scouarnec N., Heuristical top-k: fast estimation of centralities in complex networks, Inf. Process. Lett., 114, pp. 432-436, (2014); Li M., Wu Y., Zhang B., Wen Y., ACGVD: vulnerability detection based on comprehensive graph via graph neural network with attention, Information and Communications Security: Proceedings of the 23rd International Conference, Part i, ICICS 2021, Chongqing, China, November 19–21, 2021, 23, pp. 243-259, (2021); Li Y., Tarlow D., Brockschmidt M., Zemel R., Gated graph sequence neural networks, (2015); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., SySeVR: a framework for using deep learning to detect software vulnerabilities, IEEE Trans. Dependable Secure Comput., (2021); Li Z., Zou D., Xu S., Jin H., Zhu Y., Zhang Y., Chen Z., Li D., VulDeeLocator: a deep learning-based system for detecting and locating software vulnerabilities, IEEE Trans. Dependable Secure Comput., (2021); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., VulDeePecker: a deep learning-based system for vulnerability detection, (2018); Lin G., Zhang J., Luo W., Pan L., De Vel O., Montague P., Xiang Y., Software vulnerability discovery via learning multi-domain knowledge bases, IEEE Trans. Dependable Secure Comput., 18, pp. 2469-2485, (2019); Lin G., Zhang J., Luo W., Pan L., Xiang Y., De Vel O., Montague P., Cross-project transfer representation learning for vulnerable function discovery, IEEE Trans. Ind. Inform., 14, pp. 3289-3297, (2018); Van der Maaten L., Hinton G., Visualizing data using t-SNE, J. Mach. Learn. Res., 9, (2008); Mao C., Zhong Z., Yang J., Vondrick C., Ray B., Metric learning for adversarial robustness, Adv. Neural Inf. Process. Syst., 32, (2019); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, (2013); Morris C., Ritzert M., Fey M., Hamilton W.L., Lenssen J.E., Rattan G., Grohe M., Weisfeiler and Leman go neural: higher-order graph neural networks, Proceedings of the AAAI Conference on Artificial Intelligence, pp. 4602-4609, (2019); Pagliardini M., Gupta P., Jaggi M., Unsupervised learning of sentence embeddings using compositional n-gram features, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pp. 528-540, (2018); Pennington J., Socher R., Manning C.D., Glove: global vectors for word representation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP, pp. 1532-1543, (2014); Perozzi B., Al-Rfou R., Skiena S., Deepwalk: online learning of social representations, Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 701-710, (2014); Rastegari M., Ordonez V., Redmon J., Farhadi A., XNOR-Net: imagenet classification using binary convolutional neural networks, Computer Vision–ECCV 2016: Proceedings of the 14th European Conference, Part IV, Amsterdam, the Netherlands, October 11–14, 2016, pp. 525-542, (2016); Ribeiro L.F., Saverese P.H., Figueiredo D.R., struc2vec: learning node representations from structural identity, Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 385-394, (2017); Selvaraju R.R., Cogswell M., Das A., Vedantam R., Parikh D., Batra D., Grad-CAM: visual explanations from deep networks via gradient-based localization, Proceedings of the IEEE International Conference on Computer Vision, pp. 618-626, (2017); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, (2017); Wang H., Ye G., Tang Z., Tan S.H., Huang S., Fang D., Feng Y., Bian L., Wang Z., Combining graph-based learning with automated data collection for code vulnerability detection, IEEE Trans. Inf. Forensics Secur., 16, pp. 1943-1958, (2020); Watson A., Ufuktepe E., Palaniappan K., Detecting software code vulnerabilities using 2d convolutional neural networks with program slicing feature maps, 2022 IEEE Applied Imagery Pattern Recognition Workshop, AIPR, pp. 1-9, (2022); Wu Y., Zou D., Dou S., Yang W., Xu D., Jin H., VulCNN: an image-inspired scalable vulnerability detection system, Proceedings of the 44th International Conference on Software Engineering, pp. 2365-2376, (2022); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy, pp. 590-604, (2014); Ye G., Tang Z., Wang H., Fang D., Fang J., Huang S., Wang Z., Deep program structure modeling through multi-relational graph-based learning, Proceedings of the ACM International Conference on Parallel Architectures and Compilation Techniques, pp. 111-123, (2020); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Adv. Neural Inf. Process. Syst., 32, (2019); Zou D., Hu Y., Li W., Wu Y., Zhao H., Jin H., mVulPreter: a multi-granularity vulnerability detection system with interpretations, IEEE Trans. Dependable Secure Comput., (2022); Zou D., Wang S., Xu S., Li Z., Jin H., μVulDeePecker: a deep learning-based system for multiclass vulnerability detection, IEEE Trans. Dependable Secure Comput., 18, pp. 2224-2236, (2019)",,,,,,English,Article,Final,,Scopus,2-s2.0-85173161023,262
Wu Y.; Zou D.; Dou S.; Yang W.; Xu D.; Jin H.,"Wu, Yueming (57202109788); Zou, Deqing (8935128200); Dou, Shihan (57221458503); Yang, Wei (55607069500); Xu, Duo (57783164500); Jin, Hai (56434989100)",57202109788; 8935128200; 57221458503; 55607069500; 57783164500; 56434989100,VulCNN: An Image-inspired Scalable Vulnerability Detection System,2022,Proceedings - International Conference on Software Engineering,2022-May,,,2365,2376,11,51,10.1145/3510003.3510229,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133506161&doi=10.1145%2f3510003.3510229&partnerID=40&md5=5067c6763020b702bf6f767155caf849,"Since deep learning (DL) can automatically learn features from source code, it has been widely used to detect source code vulnerability. To achieve scalable vulnerability scanning, some prior studies intend to process the source code directly by treating them as text. To achieve accurate vulnerability detection, other approaches consider distilling the program semantics into graph representations and using them to detect vulnerability. In practice, text-based techniques are scalable but not accurate due to the lack of program semantics. Graph-based methods are accurate but not scalable since graph analysis is typically time-consuming. In this paper, we aim to achieve both scalability and accuracy on scanning large-scale source code vulnerabilities. Inspired by existing DL-based image classification which has the ability to analyze millions of images accurately, we prefer to use these techniques to accomplish our purpose. Specifically, we propose a novel idea that can efficiently convert the source code of a function into an image while preserving the program details. We implement Vul-CNN and evaluate it on a dataset of 13,687 vulnerable functions and 26,970 non-vulnerable functions. Experimental results report that VulCNN can achieve better accuracy than eight state-of-the-art vul-nerability detectors (i.e., Checkmarx, FlawFinder, RATS, TokenCNN, VulDeePecker, SySeVR, VulDeeLocator, and Devign). As for scalability, VulCNN is about four times faster than VulDeePecker and SySeVR, about 15 times faster than VulDeeLocator, and about six times faster than Devign. Furthermore, we conduct a case study on more than 25 million lines of code and the result indicates that VulCNN can detect large-scale vulnerability. Through the scanning reports, we finally discover 73 vulnerabilities that are not reported in NVD. © 2022 ACM.","5 Key Takeaways from the 2020 Open Source Security and Risk Analysis Report, (2020); The Exactis Breach: 5 Things You Eed to Know, (2020); WarmaCry Ransomware Attack, (2020); Adjace';-cy Matrix, (2021); (2021); (2021); (2021); (2021); National Institute of Standards and Technology, (2021); National Vulnerability Database, (2021); Open-source Code Analysis Platform for CIC++ Based on Code Property Graphs, (2021); Rough Audit Tool for Security, (2021); (2021); Software Assurance Reference Dataset, (2021); Software for Complex Networks (Networkx), (2021); Tensors and Dynarruc Neural Networks III Python with Strong GPU Acceleration (PyTorch), (2021); (2021); Backes M., Kopf B., Rybalchenko A., Automatic discovery and quantification ofinformatioil leaks, Proceedings Ofthe 20091fff Symposium on Security and Privacy (S&P'09)., pp. 141-153, (2009); Bohme M., Pham V., Nguyen M., Roychoudhury A., Directed greybox fuzzing, Proceedings Ofthe 2017ACM SIGSAC Conference on Computer and Communications Security (CCS'I7)., pp. 2329-2344, (2017); Chattopadhay A., Sarkar A., Howlader P., Balasubrarnanian V.N., Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks, Proceedings of the 2018 IEEE Winter Conference on Applil:Ations of Computer Vision (WACV'I8)., pp. 839-847, (2018); Chen H., Xue Y., Li Y., Chen B., Xie X., Wu X., Yang L., Hawkeye: Towards a desired directed grey-box fuzzer, Proceedings Ofthe 2018ACM SIGSAC Conference on Computer and Communications Security (CCS'I8)., pp. 2095-2108, (2018); Cheng X., Wang H., Hua J., Xu G.Y., Deepwukong: Statically detecting software vulnerabilities using deep graph neural network, ACM Transactions on Software Engineering and Methodology, 30, 3, pp. 1-33, (2021); Dahl G.E., Sainath T.N., Hinton G.E., Improving deep neural networks for lvcsr using rectified linear units and dropout, Proceedings Ofthe 20131fff International Conference on Acoustics, Speech and Signal Processing (ICASSP'13)., pp. 8609-8613, (2013); Duan X., Wu J., Ji S., Rui Z., Luo T., Yang M., Wu Y., Vulsniper: Focus your attention to shoot fine-grained vulnerabilities, Proceedings of the 2019 International Joint Conference 011 Artificial Intelligence (ryCAI'I9)., pp. 4665-4671, (2019); Linton C.F., Centrality in social networks conceptual clarification, Social Networks, 1, 3, pp. 215-239, (1978); Guimera R., Mossa S., Turtschi A., Amaral Nunes L.A., The worldwide air transportation network: Anomalous centrality, community structure, and cities' global roles, Proceedings of the National Academy OfSciences, 102, 22, pp. 7794-7799, (2005); Jang J., Agrawal A., Brumley D., Redebug: Finding unpatched code clones in entire as distributions, Proceedings of the 2012 FEEE Symposium on SeClirity and Privacy (S&P'12)., pp. 48-62, (2012); Jeong H., Mason S.P., BarabiIsi A.L., Oltvai Z.N., Lethality and centrality in protein networks, Nature, 411, 6833, pp. 41-42, (2001); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate tree-based detection ofcode clones, Proceedings Ofthe 29th International Conference on Software Engineering (ICSE'07)., pp. 96-105, (2007); Kamiya T., Kusumoto S., Inoue K., Ccfinder: A multilinguistic token-based code clone detection system for large scale source code, IEEE Transactions on Software Engineering, 28, 7, pp. 654-670, (2002); Katz L., A new status index derived from sociometric analysis, Psychometrika, 18, 1, pp. 39-43, (1953); Kim S., Woo S., Lee H., Oh H., VUDDY: A scalable approach for vulnerable code clone discovery, Proceedings of the 2017 FEEE Symposium on Security and Privacy (S&P'I7), pp. 595-614, (2017); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, (2014); Krizhevsl A., Sutskever L., Hinton G.E., Lmagenet classification with deep convolutional neural networks, Proceedings of the 2012 Advances in Neural Biformatio'l Processing Systems (NIPS'I2)., pp. 1097-1105, (2012); LoCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, 7553, pp. 436-444, (2015); LeCun Y., Battou L., Bengio Y., Haffner P., Gradientbased learning applied to document recognition, IEEE, 86, 2, pp. 2278-2324, (1998); Li J., Ernst M.D., Cbcd: Cloned buggy code detector, Proceedings of the 34th International Conference on Software Engineering (ICSE'I2)., pp. 310-320, (2012); Li Z., Zou D., Xu S., Chen Z., Zhu Y., Jin H., Vuldeelocator: A deep learning-based fine-grained vulnerability detector, IEEE Transactions on Dependable and Secure Computing, pp. 1-17, (2021); Li Z., Zou D., Xu S., Jin H., Qi H., Hu J., Vulpecker: An automated vulnerability detection system based on code similarity analysis, Proceedings of the 32nd Annual Conference on Computer Security Applications (ACSAC'16)., pp. 201-213, (2016); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: A framework for using deep learning to detect software vulnerabilities, IEEE Transactions on Dependable and Secure Computing, pp. 1-15, (2021); Li Z., Zou D., Xu S., Ou X., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, Proceedings of the 2018 Network and Distributed System Security Symposium (NDSS'I8)., pp. 1-15, (2018); Lin G., Xiao W., Zhang J., Xiang Y., Deep learningbased vulnerable function detection: A benchmark, Proceedings Afthe 2019 International Conference on Information and Communications Security (ICICS'19)., pp. 219-232, (2019); Lin G., Zhang J., Luo W., Pan L., Xiang Y., Poster: Vulnerability discovery with function representation learning from unlabeled projects, Proceedings of the 2017 ACM SlGSAC Conference on Computer and Communications Security (CCS'17)., pp. 2539-2541, (2017); Neuhaus S., Zimmermann T., Holler C., Zeller A., Predicting vulnerable software components, Proceedings Ofthe 14th ACM Conference on Computer and Comnumications Security (CCS'07)., pp. 529-540, (2007); Pagliardini M., Gupta P., Jaggi M., Unsupervised Learning of Sentence Embeddings Using Compositional N-gram Features, (2017); Pham A.H., Thanh Guyen T., Anh Guyen H., Guyen T., Detection of recurring software vulnerabilities, Proceedings Afthe 2010 International Conference on Automated Software Engineering (ase'Lo)., pp. 447-456, (2010); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, Proceedings of the 2018 IEEE International Conference on Machine Learning and Applications (ICMLA'I8)., pp. 757-762, (2018); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., Sourcerercc: Scaling code clone detection to big-code, Proceedings Ofthe 38th International Confer~nce on Software Engineering (ICSE'16)., pp. 1157-1168, (2016); Selvaraju R.R., Cogswell M., Das A., Vedantam R., Parikh D., Batra D., Grad-cam: Visual explanations from deep networks via gradient-based localization, Proceedings of the 2017 IEEE Lnternational Conference 011 Computer Vision (ICCV'I7)., pp. 618-626, (2017); Shankar U., Talwar K., Foster J.S., Wagner D.A., Detecting format string vulnerabilities with type qualifiers, Proceedings of the 2001 USENIX Security Symposium (USENlX security'Oi)., pp. 201-220, (2001); Khin Shar L., Briand L.C., Beng Kuan Tan H., Web application vulnerability prediction using hybrid program analysis and machine learning, IEEE Transactions on Dependable and Secure Computing, 12, 6, pp. 688-707, (2014); Wu Y., Li X., Zou D., Yang W., Zhang X., Jin H., Malscan: Fast market-wide mobile malware scanning by social-network centrality analysis, Proceedings Ofthe 34th International Conference on Automated Software Engineering (ASE'I9)., pp. 139-150, (2019); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, Proceddings of the 20I4fEEE Symposium on Security Alld Privacy (S&P'I4)., pp. 590-604, (2014); Yamaguchi F., Lottmann M., Rieck K., Generalized vulnerability extrapolation using abstract syntax trees, Proceedings Ofthe 28th Annual Computer Security Applications COllference (ACSAC'I2)., pp. 359-368, (2012); Yamaguchi F., Maier A., Gascon H., Rieck K., Automatic inference of search patterns for taint-style vulnerabilities, Proceedings Ofthe 2015 IEEE Symposium on Security and Privacy (S&P'I5)., pp. 797-812, (2015); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Proceedings Ofthe 2019 Advances in Neural Information Processing Systems (NlPS'I9), pp. 10197-10207, (2019); Zou D., Wang S., Xu S., Li Z., Jin H., Flvuideepecker: A deep learning-based system for multiclass vulnerability detection, IEEE Transactions on Dependable and Secure Computing, 18, 5, pp. 1-13, (2019)",Association for Computing Machinery (ACM); IEEE Computer Society; IEEE Technical Council on Software Engineering (TCSE); Special Interest Group on Software Engineering (SIGSOFT),"44th ACM/IEEE International Conference on Software Engineering, ICSE 2022",22 May 2022 through 27 May 2022,Pittsburgh,180255,English,Conference paper,Final,,Scopus,2-s2.0-85133506161,263
Deng Z.; Xu L.; Liu C.; Yan M.; Xu Z.; Lei Y.,"Deng, Zhongyang (57841075500); Xu, Ling (56142146600); Liu, Chao (57191256904); Yan, Meng (56230838000); Xu, Zhou (57212062746); Lei, Yan (55541448200)",57841075500; 56142146600; 57191256904; 56230838000; 57212062746; 55541448200,Fine-grained Co-Attentive Representation Learning for Semantic Code Search,2022,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",,,,396,407,11,5,10.1109/SANER53432.2022.00055,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135793766&doi=10.1109%2fSANER53432.2022.00055&partnerID=40&md5=1795969acdea1df7b7ad47fcfce02acd,"Code search aims to find code snippets from large-scale code repositories based on the developer's query intent. A significant challenge for code search is the semantic gap between programming language and natural language. Recent works have indicated that deep learning (DL) techniques can perform well by automatically learning the relationships between query and code. Among these DL-based approaches, the state-of-the-art model is TabCS, a two-stage attention-based model for code search. However, TabCS still has two limitations: semantic loss and semantic confusion. TabCS breaks the structural information of code into token-level words of abstract syntax tree (AST), which loses the sequential semantics between words in programming statements, and it uses a co-attention mechanism to build the semantic correlation of code-query after fusing all features, which may confuse the correlations between individual code features and query. In this paper, we propose a code search model named FcarCS (Fine-grained Co-Attentive Representation Learning Model for Semantic Code Search). FcarCS extracts code textual features (i.e., method name, API sequence, and tokens) and structural features that introduce a statement-level code structure. Unlike TabCS, FcarCS splits AST into a series of subtrees corresponding to code statements and treats each subtree as a whole to preserve sequential semantics between words in code statements. FcarCS constructs a new fine-grained co-attention mechanism to learn interdependent representations for each code feature and query, respectively, instead of performing one co-attention process for the fused code features like TabCS. Generally, this mechanism leverages row/column-wise CNN to enable our model to focus on the strongly correlated local information between code feature and Query. We train and evaluate FcarCS on an open Java dataset with 475k and 10k code/query pairs, respectively. Experimental results show that FcarCS achieves an MRR of 0.613, outperforming three state-of-the-art models DeepCS, UNIF, and TabCS, by 117.38%, 16.76%, and 12.68%, respectively. We also performed a user study for each model with 50 real-world queries, and the results show that FcarCS returned code snippets that are more relevant than the baseline models.  © 2022 IEEE.","Brandt J., Guo P.J., Lewenstein J., Dontcheva M., Klemmer S.R., Two studies of opportunistic programming: Interleaving web foraging, learning, and writing code, Proceedings of the 27th International Conference on Hwnan Factors in Computing Systems, CHI 2009, (2009); Kevic K., Fritz T., Automatic search term identification for change tasks, Companion Proceedings of the 36th International Conference on Software Engineering, pp. 468-471, (2014); Robillard M.P., What makes apis hard to learn? answers from developers, IEEE software, 26, 6, pp. 27-34, (2009); McMillan C., Grechanik M., Poshyvanyk D., Xie Q., Fu C., Portfolio: finding relevant functions and their usage, Proceedings of the 33rd International Conference on Software Engineering, pp. 111-120, (2011); Reiss S.P., Semantics-based code search, 2009 IEEE 31st International Conference on Software Engineering. lEEE, pp. 243-253, (2009); Zhang F., Niu H., Keivanloo I., Zou Y., Expanding queries for code search using semantically related api class-names, IEEE Transactions on Software Engineering, 44, 11, pp. 1070-1082, (2017); Ling X., Wu L., Wang S., Pan G., Ma T., Xu F., Liu A.X., Wu C., Ji S., Deep graph matching and searching for semantic code retrieval, ACM Transactions on Knowledge Discovery from Data (TKDD), 15, 5, pp. 1-21, (2021); Bajracharya S., Ngo T., Linstead E., Dou Y., Rigor P., Baldi P., Lopes C., Sourcerer: A search engine for open source code supporting structure-based search, Companion to the 21st ACM SIGPLAN symposium on Object-oriented programming systems, languages, and applications, pp. 681-682, (2006); Lv F., Zhang H., Lou J.-G., Wang S., Zhang D., Zhao J., Codehow: Effective code search based on api understanding and extended boolean model (e), 2015 30th IEEElACM International Conference on Automated Software Engineering (ASE). lEEE, pp. 260-270, (2015); Hill E., Pollock L.L., Vijay-Shanker K., hnproving source code search with natural language phrasal representations of method signatures, IEEElACM International Conference on Automated Software Engineering, (2011); Sindhgatta R., Using an information retrieval system to retrieve source code samples, International Conference on Software Engineering, (2006); Lu M., Sun X., Wang S., Lo D., Duan Y., Query expansion via wordnet for effective code search, 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER), (2015); Gu X., Zhang H., Kim S., Deep code search, 2018 IEEElACM 40th International Conference on Software Engineering (ICSE). lEEE, pp. 933-944, (2018); Li W., Qin H., Yan S., Shen B., Chen Y., Learning code-query interaction for enhancing code searches, 2020 IEEE International Conference on Software Maintenance and Evolution (ICSME). IEEE, pp. 115-126, (2020); Shuai J., Xu L., Liu C., Yan M., Xia X., Lei Y., hnproving code search with co-attentive representation learning, Proceedings of the 28th International Conference on Program Comprehension, pp. 196-207, (2020); Xu L., Yang H., Liu C., Shuai J., Yan M., Lei Y., Xu Z., Twostage attention-based model for code search with textual and structural features, 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER). lEEE, pp. 342-353, (2021); Sundermeyer M., SchlUter R., Ney H., Lstru neural networks for language modeling, Thirteenth annual conference ofthe international speech communication association, (2012); Gardner M.W., Dorling S., Artificial neural networks (the multilayer perceptron)-a review of applications in the atmospheric sciences, Atmospheric environment, 32, 14-15, pp. 2627-2636, (1998); Cambronero J., Li H., Kim S., Sen K., Chandra S., When deep learning met code search, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 964-974, (2019); Joulin A., Grave E., Bojanowski P., Douze M., Jegou H., Mikov T., Fasttext. zip: Compressing text classification models, (2016); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, POPL, pp. 1-29, (2019); LeCun Y., Boser B., Denker J.S., Henderson D., Howard R.E., Hubbard W., Jackel L.D., Backpropagation applied to handwritten zip code recognition, Neural computation, 1, 4, pp. 541-551, (1989); Yu J., Lu Y., Zhang W., Qin Z., Liu Y., Hu Y., Learning cross-modal correlations by exploring inter-word semantics and stacked co-attention, Pattern Recognition Letters, 130, pp. 189-198, (2020); Nguyen D.-K., Okatani T., hnproved fusion of visual and language representations by dense symmetric co-attention for visual question answering, Proceedings ofthe IEEE Conference on Computer Vision and Pattern Recognition, pp. 6087-6096, (2018); Thy Y., Luu A.T., Hui S.C., Multi-pointer co-attention networks for recommendation, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 2309-2318, (2018); Li L., Dong R., Chen L., Context-aware co-attention neural network for service recommendations, 2019 IEEE 35th International Conference on Data Engineering Workshops (ICDEW). lEEE, pp. 201-208, (2019); Li B., Sun Z., Li Q., Wu Y., Hu A., Group-wise deep object cosegmentation with co-attention recurrent neural network, Proceedings of the IEEElCVF International Conference on Computer Vision, pp. 8519-8528, (2019); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation with hybrid lexical and syntactical information, Empirical Software Engineering, 25, 3, pp. 2179-2217, (2020); Wilcoxon F., Individual comparisons by ranking methods, Breakthroughs in statistics, pp. 196-202, (1992); Liu M., Yin H., Cross attention network for semantic segmentation, 2019 IEEE International Conference on Image Processing (ICIP). lEEE, pp. 2434-2438, (2019); Bai X., Text classification based on 1stm and attention, 2018 Thirteenth International Conference on Digital Information Management (ICDIM). lEEE, pp. 29-32, (2018); Xu K., Ba J., Kiros R., Cho K., Courville A., Salakhudinov R., Zemel R., Bengio Y., Show, attend and tell: Neural image caption generation with visual attention, International conference on machine learning. PMLR, pp. 2048-2057, (2015); Yin W., Kann K., Yu M., SchUtze H., Comparative study of coo and mn for natural language processing, (2017); Collobert R., Weston J., Bottou L., Karlen M., Kavukcuoglu K., Kuksa P., Natural language processing (almost) from scratch, Journal of machine learning research, 12, pp. 2493-2537, (2011); Frome A., Corrado G., Shlens J., Bengio S., Dean J., Ranzato M., Mikov T., Devise: A deep visual-semantic embedding model, (2013); Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2014); Yao Y., Rosasco L., Caponnetto A., On early stopping in gradient descent learning, Constructive Approximation, 26, 2, pp. 289-315, (2007); Cohen J., A coefficient of agreement for nominal scales, Educational and psychological measurement, 20, 1, pp. 37-46, (1960); Sim S.E., Gallardo-Valencia R.E., Finding source code on the web for remix and reuse, (2013); Bajracharya S.K., Lopes C.V., Analyzing and mining a code search engine usage log, Empirical Software Engineering, 17, 4, pp. 424-466, (2012); Haiduc S., Bavota G., Marcus A., Oliveto R., De Lucia A., Menzies T., Automatic query reformulations for text retrieval in software engineering, 2013 35th International Conference on Software Engineering (ICSE). lEEE, pp. 842-851, (2013); Hill E., Pollock L., Vijay-Shanker K., hnproving source code search with natural language phrasal representations of method signatures, 2011 26th IEEElACM International Conference on Automated Software Engineering (ASE 20ll). lEEE, pp. 524-527, (2011); Lu M., Sun X., Wang S., Lo D., Duan Y., Query expansion via wordnet for effective code search, 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER). lEEE, pp. 545-549, (2015); Leacock C., Chodorow M., Combining local context and wordnet similarity for word sense identification, WordNet: An electronic lexical database, 49, 2, pp. 265-283, (1998); Liu C., Xia X., Lo D., Liu Z., Hassan A.E., Li S., Codematcher: Searching code based on sequential semantics of important query words, ACM Transactions on Software Engineering and Methodology (TOSEM), 31, 1, pp. 1-37, (2021); Fang S., Tan Y.-S., Zhang T., Liu Y., Self-attention networks for code search, Information and Software Technology, 134, (2021); LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, 2019 IEEElACM 41st International Conference on Software Engineering (ICSE). IEEE, pp. 795-806, (2019); Zhang J., Wang X., Zhang H., Sun H., Liu X., Retrieval-based neural source code summarization, 2020 IEEElACM 42nd International Conference on Software Engineering (ICSE). IEEE, pp. 1385-1397, (2020); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEElACM 41st International Conference on Software Engineering (ICSE). IEEE, pp. 783-794, (2019); Bui N.D., Yu Y., Jiang L., Infercode: Self-supervised learning of code representations by predicting subtrees, 2021 IEEElACM 43rd International Conference on Software Engineering (ICSE). IEEE, pp. 1186-1197, (2021); Li Y., Improving bug detection and fixing via code representation learning, Proceedings of the ACMlIEEE 42nd International Conference on Software Engineering: CompanionProceedings, pp. 137-139, (2020); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Et al., Graphcodebert: Pre-training code representations with data flow, (2020); Neamtiu I., Foster J.S., Hicks M., Understanding source code evolution using abstract syntax tree matching, Proceedings of the 2005 international workshop on Mining software repositories, pp. 1-5, (2005); Zhang Y., Gao X., Bian C., Ma D., Cui B., Homologous detection based on text, token and abstract syntax tree comparison, 2010 IEEE International Conference on Information Theory and Information Security. IEEE, pp. 70-75, (2010); Biich L., Andrzejak A., Learning-based recursive aggregation of abstract syntax trees for code clone detection, 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, pp. 95-104, (2019); Luan S., Yang D., Barnaby C., Sen K., Chandra S., Aroma: Code recommendation via structural code search, Proceedings of the ACM on Programming Languages, 3, OOPSLA, pp. 1-28, (2019); Koyuncu A., Liu K., Bissyande T.F., Kim D., Monperrus M., Klein J., Le Traon Y., ifixr: Bug report driven program repair, Proceedings of the 2019 27th ACM joint meeting on european software engineering conference and symposium on the foundations of software engineering, pp. 314-325, (2019); Lin C., Ouyang Z., Zhuang J., Chen J., Li H., Wu R., Improving code summarization with block-wise abstract syntax tree splitting, (2021)",IEEE Computer Society,"29th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",15 March 2022 through 18 March 2022,"Virtual, Online",181173,English,Conference paper,Final,,Scopus,2-s2.0-85135793766,265
Xu L.; Yang H.; Liu C.; Shuai J.; Yan M.; Lei Y.; Xu Z.,"Xu, Ling (56142146600); Yang, Huanhuan (57223964217); Liu, Chao (57191256904); Shuai, Jianhang (57219260678); Yan, Meng (56230838000); Lei, Yan (55541448200); Xu, Zhou (57212062746)",56142146600; 57223964217; 57191256904; 57219260678; 56230838000; 55541448200; 57212062746,Two-Stage Attention-Based Model for Code Search with Textual and Structural Features,2021,"Proceedings - 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2021",,,9425924,342,353,11,34,10.1109/SANER50967.2021.00039,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106570287&doi=10.1109%2fSANER50967.2021.00039&partnerID=40&md5=a2919fe897a6c6adecf47a4796258956,"Searching and reusing existing code from a large scale codebase can largely improve developers' programming efficiency. To support code reuse, early code search models leverage information retrieval (IR) techniques to index a large-scale code corpus and return relevant code according to developers' search query. However, IR-based models fail to capture the semantics in code and query. To tackle this issue, developers applied deep learning (DL) techniques to code search models. However, these models either are too complex to determine an effective method efficiently or learning for semantic correlation between code and query inadequately.To bridge the semantic gap between code and query effectively and efficiently, we propose a code search model TabCS (Two-stage Attention-Based model for Code Search) in this study. TabCS extracts code and query information from the code textual features (i.e., method name, API sequence, and tokens), the code structural feature (i.e., abstract syntax tree), and the query feature (i.e., tokens). TabCS performs a two-stage attention net-work structure. The first stage leverages attention mechanisms to extract semantics from code and query considering their semantic gap. The second stage leverages a co-attention mechanism to capture their semantic correlation and learn better code/query representation. We evaluate the performance of TabCS on two existing large-scale datasets with 485k and 542k code snippets, respectively. Experimental results show that TabCS achieves an MRR of 0.57 on Hu et al.'s dataset, outperforming three state-of-the-art models CARLCS-CNN, DeepCS, and UNIF by 18%, 70%, 12%, respectively. Meanwhile, TabCS gains an MRR of 0.54 on Husain et al.'s, outperforming CARLCS-CNN, DeepCS, and UNIF by 32%, 76%, 29%, respectively. © 2021 IEEE.","Brandt J., Dontcheva M., Weskamp M., Klemmer S.R., Examplecentric programming: Integrating web search into the development environment, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 513-522, (2010); Chan W.-K., Cheng H., Lo D., Searching connected api subgraph via text phrases, Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering, Ser. FSE '12, pp. 101-1011, (2012); Haiduc S., Bavota G., Marcus A., Oliveto R., De Lucia A., Menzies T., Automatic query reformulations for text retrieval in software engineering, Proceedings of the 2013 International Conference on Software Engineering, pp. 842-851, (2013); Hill E., Vega M.R., Fails J.A., Mallet G., Nl-based query refinement and contextualized code search results: A user study, 2014 Software Evolution Week-IEEE Conference on Software Maintenance, Reengineering, and Reverse Engineering (CSMR-WCRE), pp. 34-43, (2014); Holmes R., Cottrell R., Walker R.J., Denzinger J., The end-toend use of source code examples: An exploratory study, 2009 IEEE International Conference on Software Maintenance. IEEE, pp. 555-558, (2009); Lu M., Sun X., Wang S., Lo D., Duan Y., Query expansion via wordnet for effective code search, 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering, SANER 2015-Proceedings, pp. 545-549, (2015); McMillan C., Grechanik M., Poshyvanyk D., Xie Q., Fu C., Portfolio: Finding Relevant Functions and Their Usage, 1, pp. 111-120, (2011); Sadowski C., Stolee K.T., Elbaum S., How developers search for code: A case study, Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering, Ser. ESEC/FSE 2015, pp. 191-201, (2015); Linstead E., Bajracharya S., Ngo T., Rigor P., Lopes C., Baldi P., Sourcerer: Mining and searching internet-scale software repositories, Data Mining and Knowledge Discovery, 18, 2, pp. 300-336, (2009); Lv F., Zhang H., Lou J., Wang S., Zhang D., Zhao J., Codehow: Effective Code Search Based on Api Understanding and Extended Boolean Model (E), pp. 260-270, (2015); McCandless M., Hatcher E., Gospodnetic O., Gospodnetic O., Lucene in Action. Manning Greenwich, 2, (2010); Salton G., Fox E.A., Wu H., Extended boolean information retrieval, Communications of the ACM, 26, 11, pp. 1022-1036, (1983); Gu X., Zhang H., Kim S., Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE). IEEE, pp. 933-944, (2018); Sundermeyer M., Schluter R., Ney H., Lstm neural networks for language modeling, Thirteenth Annual Conference of the International Speech Communication Association, (2012); Shuai J., Xu L., Liu C., Yan M., Xia X., Lei Y., Improving code search with co-attentive representation learning, 28th International Conference on Program Comprehension (ICPC), (2020); Cambronero J., Li H., Kim S., Sen K., Chandra S., When deep learning met code search, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 964-974, (2019); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation with hybrid lexical and syntactical information, Empirical Software Engineering, pp. 1-39, (2019); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet Challenge: Evaluating the State of Semantic Code Search, (2019); Gardner M.W., Artificial neural networks (the multilayer perceptron)-A review of applications in the atmospheric sciences, Atmospheric Environment, 32, (1998); Kingma D., Ba J., Adam: A method for stochastic optimization, Computer Science, (2014); Yao Y., Rosasco L., Caponnetto A., On early stopping in gradient descent learning, Constructive Approximation, 26, 2, pp. 289-315, (2007); Shuai J., Xu L., Liu C., Yan M., Xia X., Lei Y., Improving Code Search with Co-attentive Representation Learning.; Xiaodong G., Hongyu Z., Sunghun K., Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE), pp. 933-944, (2018); Wilcoxon F., Individual comparisons by ranking methods, Breakthroughs in Statistics, pp. 196-202, (1992); Yin W., Schutze H., Xiang B., Zhou B., Abcnn: Attention-based convolutional neural network for modeling sentence pairs, Transactions of the Association for Computational Linguistics, 4, pp. 259-272, (2016); Yin W., Kann K., Yu M., Schutze H., Comparative Study of Cnn and Rnn for Natural Language Processing, (2017); Yao X., Van Durme B., Clark P., Automatic coupling of answer extraction and information retrieval, Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pp. 159-165, (2013); Bahdanau D., Cho K., Bengio Y., Neural machine translation by jointly learning to align and translate, Computer Science, 1409, (2014); Arora M., How google search engine works, Electronics for You, (2013); Krugler K., Krugle Code Search Architecture, (2013); Muddu B.R., Asadullah A.M., Vinod J., Pooloth K.K., Structural Search of Source Code, (2012); Stylos J., Myers B.A., Mica: A web-search tool for finding api components and examples, 2006 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC 2006), (2006); Hoffmann R., Fogarty J., Weld D.S., Assieme: Finding and leveraging implicit references in a web search interface for programmers, Proceedings of the 20th Annual ACM Symposium on User Interface Software and Technology, pp. 13-22, (2007); Manjula D., Kulandaiyan S., Sudarshan S., Francis A., Geetha T.V., Semantics based information retrieval using conceptual indexing of documents, Intelligent Data Engineering Automated Learning, International Conference, (2003); Babashzadeh A., Huang J., Daoud M., Exploiting Semantics for Improving Clinical Information Retrieval, (2013); Graph A.S., Abstract Syntax Tree, (2015); Zhang Y., Gao X., Bian C., Ma D., Cui B., Homologous detection based on text, token and abstract syntax tree comparison, 2010 IEEE International Conference on Information Theory and Information Security, pp. 70-75, (2010); Buch L., Andrzejak A., Learning-based recursive aggregation of abstract syntax trees for code clone detection, 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 95-104, (2019); Luan S., Yang D., Barnaby C., Sen K., Chandra S., Aroma: Code recommendation via structural code search, Proceedings of the ACM on Programming Languages, (2019); Koyuncu A., Liu K., Bissyande T.F., Kim D., Traon Y.L., Ifixr: Bug Report Driven Program Repair, (2019); Neamtiu I.G., Foster J.S., Hicks M., Understanding source code evolution using abstract syntax tree matching, ACM SIGSOFT Software Engineering Notes, (2005); Wang B., Xu L., Yan M., Liu C., Liu L., Multi-dimension convolutional neural network for bug localization, IEEE Transactions on Services Computing, (2020); Zhang J., Wang X., Zhang H., Sun H., Liu X., Retrieval-based neural source code summarization, International ConferenceonSoftwareEngineering, (2020); Li X., Zhong X.J., The source code plagiarism detection using ast, 2010 International Symposium on Intelligence Information Processing and Trusted Computing, pp. 406-408, (2010); Wang X., Yuan X., Towards an ast-based approach to reverse engineering, 2006 Canadian Conference on Electrical and Computer Engineering, 2006, pp. 422-425; Parikh A.P., Tckstrm O., Das D., Uszkoreit J., A Decomposable Attention Model for Natural Language Inference, (2016); Liu Y., Sun C., Lin L., Wang X., Learning Natural Language Inference Using Bidirectional Lstm Model and Inner-attention, (2016); Gajbhiye A., Jaf S., Moubayed N.A., Bradley S., Mcgough A.S., Cam: A combined attention model for natural language inference, IEEE International Conference on Big Data, (2018); Liu M., Yin H., Cross attention network for semantic segmentation, 2019 IEEE International Conference on Image Processing (ICIP), pp. 2434-2438, (2019); Bai X., Text classification based on lstm and attention, 2018 Thirteenth International Conference on Digital Information Management (ICDIM), pp. 29-32, (2018); Yadav S., Rai A., Frequency and temporal convolutional attention for text-independent speaker recognition, ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 6794-6798, (2020); Ueda T., Okada M., Mori N., Hashimoto K., A method to estimate request sentences using lstm with self-attention mechanism, 2019 8th International Congress on Advanced Applied Informatics (IIAI-AAI), pp. 7-10, (2019); Rezaurrahman Chowdhury F.A., Wang Q., Moreno I.L., Wan L., Attention-based models for text-dependent speaker verification, 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 5359-5363, (2018); Jing Y., Yuhang L., Weifeng Z., Zengchang Q., Yanbing L., Yue H., Learning cross-modal correlations by exploring inter-word semantics and stacked co-attention, Pattern Recognition Letters, 167, (2018); Nguyen D.K., Okatani T., Improved fusion of visual and language representations by dense symmetric co-attention for visual question answering, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), (2018); Tay Y., Luu A.T., Hui S.C., Multi-pointer co-attention networks for recommendation, The 24th ACM SIGKDD International Conference, (2018); Li L., Dong R., Chen L., Context-aware co-attention neural network for service recommendations, 2019 IEEE 35th International Conference on Data Engineering Workshops (ICDEW), (2019); Li L., Dong R., Chen L., Context-aware co-attention neural network for service recommendations, 2019 IEEE 35th International Conference on Data Engineering Workshops (ICDEW), pp. 201-208, (2019); Li B., Sun Z., Li Q., Wu Y., Anqi H., Group-wise deep object co-segmentation with co-attention recurrent neural network, 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pp. 8518-8527, (2019); Zhang P., Zhu H., Xiong T., Yang Y., Co-attention network and lowrank bilinear pooling for aspect based sentiment analysis, ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 6725-6729, (2019); Nguyen D., Okatani T., Improved fusion of visual and language representations by dense symmetric co-attention for visual question answering, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 6087-6096, (2018); Ma H., Li Y., Ji X., Han J., Li Z., Mscoa: Multi-step co-attention model for multi-label classification, IEEE Access, 7, pp. 109635-109645, (2019)",IEEE Computer Society,"28th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2021",9 March 2021 through 12 March 2021,"Virtual, Honolulu",168914,English,Conference paper,Final,,Scopus,2-s2.0-85106570287,266
Yang S.; Gu X.; Shen B.,"Yang, Shouliang (57221476797); Gu, Xiaodong (57188851712); Shen, Beijun (23089553000)",57221476797; 57188851712; 23089553000,Self-Supervised Learning of Smart Contract Representations,2022,IEEE International Conference on Program Comprehension,2022-March,,,82,93,11,6,10.1145/3524610.3527894,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133158808&doi=10.1145%2f3524610.3527894&partnerID=40&md5=8ca8720f70660086fafd22863769106d,"Learning smart contract representations can greatly facilitate the development of smart contracts in many tasks such as bug detection and clone detection. Existing approaches for learning program representations are difficult to apply to smart contracts which have insufficient data and significant homogenization. To overcome these challenges, in this paper, we propose SRCL, a novel, self-supervised approach for learning smart contract representations. Unlike ex-isting supervised methods, which are tied on task-specific data labels, SRCL leverages large-scale unlabeled data by self-supervised learning of both local and global information of smart contracts. It automatically extracts structural sequences from abstract syntax trees (ASTs). Then, two discriminators are designed to guide the Transformer encoder to learn local and global semantic features of smart contracts. We evaluate SRCL on a dataset of 75,006 smart contracts collected from Etherscan. Experimental results show that SRCL considerably outperforms the state-of-the-art code represen-tation models on three downstream tasks.  © 2022 ACM.","Alon U., Brody S., Levy O., Yahav E., code2seq: Generating Sequences from Structured Representations of Code, 7th International Conference on Learning Representations (ICLR), (2019); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, pp. 1-29, (2019); Ashizawa N., Yanai N., Paul Cruz J., Okamura S., Eth2Vec: Learning Contract-Wide Code Representations for Vulnerability Detection on Ethereum Smart Contracts, Proceedings of the 3rd ACM International Symposium on Blockchain and Secure Critical Infrastructure (BSCI), pp. 47-59, (2021); Bahga A., Madisetti V.K., Blockchain platform for industrial internet of things, Journal of Software Engineering and Applications, 9, 10, pp. 533-546, (2016); Bojanowski P., Grave E., Joulin A., Mikolov T., Enriching Word Vectors with Subword Information, Trans. Assoc. Comput. Linguistics., 5, pp. 135-146, (2017); Bui Q.N.D., Yu Y., Jiang L., InferCode: Self-Supervised Learning of Code Representations by Predicting Subtrees, 43rd IEEE/ACM International Conference on Software Engineering (ICSE), pp. 1186-1197, (2021); Cai H., Chen H., Song Y., Zhang C., Zhao X., Yin D., Data Manipulation: Towards Effective Instance Learning for Neural Dialogue Generation via Learning to Augment and Reweight, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL), pp. 6334-6343, (2020); Chen X., Liao P., Zhang Y., Huang Y., Zheng Z., Understanding Code Reuse in Smart Contracts, 28th IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 470-479, (2021); Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), pp. 4171-4186, (2019); Ding M., Tang J., Zhang J., Semi-supervised Learning on Graphs with Generative Adversarial Nets, Proceedings of the 27th ACM International Conference on Information and Knowledge Management (CIKM), pp. 913-922, (2018); Feng S.Y., Gangal V., Wei J., Chandar S., Vosoughi S., Mitamura T., Hovy E., A Survey of Data Augmentation Approaches for NLP, Findings of the Association for Computational Linguistics (ACL-IJCNLP), pp. 968-988, (2021); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A Pre-Trained Model for Programming and Natural Languages, Findings of the Association for Computational Linguistics (EMNLP), pp. 1536-1547, (2020); Fukushima K., Neocognitron: A hierarchical neural network capable of visual pattern recognition, Neural Networks., 1, 2, pp. 119-130, (1988); Gao Z., Jiang L., Xia X., Lo D., Grundy J., Checking Smart Contracts With Structural Code Embedding, IEEE Transactions on Software Engineering., 47, 12, pp. 2874-2891, (2021); Gu X., Zhang H., Kim S., Deep code search, Proceedings of the 40th International Conference on Software Engineering (ICSE). ACM, pp. 933-944, (2018); Guo H., Mao Y., Zhang R., Augmenting Data with Mixup for Sentence Classification: An Empirical Study, (2019); He K., Zhang X., Ren S., Sun J., Deep Residual Learning for Image Recognition, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778, (2016); He N., Wu L., Wang H., Guo Y., Jiang X., Characterizing Code Clones in the Ethereum Smart Contract Ecosystem, 24th International Conference on Financial Cryptography and Data Security, pp. 654-675, (2020); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proceedings of the 26th Conference on Program Comprehension (ICPC). ACM, pp. 200-210, (2018); Huo X., Li M., Zhou Z., Learning Unified Features from Natural and Programming Languages for Locating Buggy Source Code, Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, (IJCAI), pp. 1606-1612, (2016); Jain P., Jain A., Zhang T., Abbeel P., Gonzalez J., Stoica I., Contrastive Code Representation Learning, Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 5954-5971, (2021); Jiang L., Misherghi G., Su Z., Glondu S., DECKARD: Scalable and Accurate Tree-Based Detection of Code Clones, 29th International Conference on Software Engineering (ICSE), pp. 96-105, (2007); Kanungo T., Mount D.M., Netanyahu N.S., Piatko C.D., Silverman R., Wu A.Y., An efficient k-means clustering algorithm: Analysis and implementation, IEEE transactions on pattern analysis and machine intelligence., 24, 7, pp. 881-892, (2002); Kim D., Tao Y., Kim S., Zeller A., Where should we fix this bug? a two-phase recommendation model, IEEE transactions on software Engineering., 39, 11, pp. 1597-1610, (2013); Kim S., Zhao J., Tian Y., Chandra S., Code Prediction by Feeding Trees to Transformers, 43rd IEEE/ACM International Conference on Software Engineering (ICSE), pp. 150-162, (2021); Kingma D.P., Dhariwal P., Glow: Generative Flow with Invertible 1x1 Convolutions, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems (NeurIPS), pp. 10236-10245, (2018); Kondo M., Ansaldi Oliva G., Ming Jiang Z., Hassan A.E., Mizuno O., Code cloning in smart contracts: a case study on verified contracts from the Ethereum blockchain platform, Empir. Softw. Eng., 25, 6, pp. 4617-4675, (2020); Kong L., De Masson D'Autume C., Yu L., Ling W., Dai Z., Yogatama D., A Mutual Information Maximization Perspective of Language Representation Learning, 8th International Conference on Learning Representations (ICLR, (2020); Lan Z., Chen M., Goodman S., Gimpel K., Sharma P., Soricut R., ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, 8th International Conference on Learning Representations (ICLR), (2020); Li W., Qin H., Yan S., Shen B., Chen Y., Learning Code-Query Interaction for Enhancing Code Searches, IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 115-126, (2020); Liebel L., Korner M., Auxiliary Tasks in Multi-task Learning, (2018); Lukins S.K., Kraft N.A., Etzkorn L.H., Bug localization using latent dirichlet allocation, Information and Software Technology., 52, 9, pp. 972-990, (2010); Lutz O., Chen H., Fereidooni H., Sendner C., Dmitrienko A., Sadeghi A., Koushanfar F., ESCORT: Ethereum Smart COntRacTs Vulnerability Detection using Deep Neural Network and Transfer Learning, (2021); Mi F., Wang Z., Zhao C., Guo J., Ahmed F., Khan L., VSCL: Automating Vulnerability Detection in Smart Contracts with Deep Learning, IEEE International Conference on Blockchain and Cryptocurrency (ICBC), pp. 1-9, (2021); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed Representations of Words and Phrases and their Compositionality, 27th Annual Conference on Neural Information Processing Systems (NIPS), pp. 3111-3119, (2013); Min J., Thomas McCoy R., Das D., Pitler E., Linzen T., Syntactic Data Augmentation Increases Robustness to Inference Heuristics, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, pp. 2339-2352, (2020); Nix R., Zhang J., Classification of Android apps and malware using deep neural networks, International Joint Conference on Neural Networks (IJCNN). IEEE, pp. 1871-1878, (2017); Radziwill N., Blockchain revolution: How the technology behind Bitcoin is changing money, business, and the world, The Quality Management Journal., 25, 1, pp. 64-65, (2018); Gul Sahin G., Steedman M., Data Augmentation via Dependency Tree Morphing for Low-Resource Languages, Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 5004-5009, (2018); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., SourcererCC: scaling code clone detection to big-code, Proceedings of the 38th International Conference on Software Engineering (ICSE). ACM, pp. 1157-1168, (2016); Santos J.M., Embrechts M.J., On the Use of the Adjusted Rand Index as a Metric for Evaluating Supervised Classification, 19th International Conference on Artificial Neural Networks (ICANN), pp. 175-184, (2009); Savelyev A., Contract law 2. 0: 'Smart'contracts as the beginning of the end of classic contract law, Information & communications technology law., 26, 2, pp. 116-134, (2017); Data Pricing. [EB/OL], (2022); Sennrich R., Haddow B., Birch A., Improving Neural Machine Translation Models with Monolingual Data, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL), (2016); Shi C., Xiang Y., Yu J., Gao L., Semantic Code Search for Smart Contracts, (2021); Swan M., Blockchain: Blueprint for a new economy, (2015); Szabo N., Formalizing and Securing Relationships on Public Networks, First Monday., 2, 9, (1997); Van Der Maaten L., Hinton G., Visualizing data using t-SNE, Journal of machine learning research., 9, 11, pp. 2579-2605, (2008); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is All you Need, Annual Conference on Neural Information Processing Systems, pp. 5998-6008, (2017); Wang H., Wang J., Wang J., Zhao M., Zhang W., Zhang F., Xie X., Guo M., GraphGAN: Graph Representation Learning With Generative Adversarial Nets, Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI), the 30th innovative Applications of Artificial Intelligence (IAAI), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI), pp. 2508-2515, (2018); Yang Wang W., Yang D., That's So Annoying!!!: A Lexical and Frame-Semantic Embedding Based Data Augmentation Approach to Automatic Categorization of Annoying Behaviors using #petpeeve Tweets, Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 2557-2563, (2015); Wei J.W., Zou K., EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks, Proceedings of the Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 6381-6387, (2019); Xiong W., Du J., Yang Wang W., Stoyanov V., Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language Model, 8th International Conference on Learning Representations (ICLR), (2020); Yang Z., Dai Z., Yang Y., Carbonell J.G., Salakhutdinov R., Le Q.V., XLNet: Generalized Autoregressive Pretraining for Language Understanding, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems (NeurIPS), pp. 5754-5764, (2019); Yang Z., Keung J., Yu X., Gu X., Wei Z., Ma X., Zhang M., A Multi-Modal Transformer-based Code Summarization Approach for Smart Contracts, 29th IEEE/ACM International Conference on Program Comprehension (ICPC), pp. 1-12, (2021); Zhang H., Cisse M., Dauphin Y.N., Lopez-Paz D., mixup: Beyond Empirical Risk Minimization, 6th International Conference on Learning Representations (ICLR), (2018); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings of the 41st International Conference on Software Engineering (ICSE). IEEE/ACM, pp. 783-794, (2019); Zhou S., Shen B., Zhong H., Lancer: Your Code Tell Me What You Need, 34th IEEE/ACMInternational Conference on Automated Software Engineering (ASE); Zhou T., Liu K., Li L., Liu Z., Klein J., Bissyande T.F., SmartGift: Learning to Generate Practical Inputs for Testing Smart Contracts, 2021 IEEE International Conference on Software Maintenance and Evolution (ICSME). IEEE, pp. 23-34, (2021)",,"30th IEEE/ACM International Conference on Program Comprehension, ICPC 2022",16 May 2022 through 17 May 2022,Pittsburgh,180257,English,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85133158808,267
Krasanakis E.; Symeonidis A.,"Krasanakis, Emmanouil (57209312190); Symeonidis, Andreas (7004087388)",57209312190; 7004087388,Fast Library Recommendation in Software Dependency Graphs with Symmetric Partially Absorbing Random Walks,2022,Future Internet,14,5,124,"","","",2,10.3390/fi14050124,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129358472&doi=10.3390%2ffi14050124&partnerID=40&md5=b0c1e797271729e90fce836dbd73bd5d,"To help developers discover libraries suited to their software projects, automated approaches often start from already employed libraries and recommend more based on co-occurrence patterns in other projects. The most accurate project–library recommendation systems employ Graph Neural Networks (GNNs) that learn latent node representations for link prediction. However, GNNs need to be retrained when dependency graphs are updated, for example, to recommend libraries for new projects, and are thus unwieldy for scalable deployment. To avoid retraining, we pro-pose that recommendations can instead be performed with graph filters; by analyzing dependency graph dynamics emulating human-driven library discovery, we identify low-pass filtering with memory as a promising direction and introduce a novel filter, called symmetric partially absorbing random walks, which infers rather than trains the parameters of filters with node-specific memory to guarantee low-pass filtering. Experiments on a dependency graph between Android projects and third-party libraries show that our approach makes recommendations with a quality and diversifica-tion loosely comparable to those state-of-the-art GNNs without computationally intensive retraining for new predictions. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Nerur S., Balijepally V., Theoretical reflections on agile development methodologies, Commun. ACM, 50, pp. 79-83, (2007); Miller F.P., Vandome A.F., McBrewster J., Apache Maven, (2010); Python Software Foundation; Raemaekers S., Van Deursen A., Visser J., The maven repository dataset of metrics, changes, and dependencies, Proceedings of the 2013 10th Working Conference on Mining Software Repositories (MSR), pp. 221-224, (2013); Li Z., Avgeriou P., Liang P., A systematic mapping study on technical debt and its management, J. Syst. Softw, 101, pp. 193-220, (2015); He X., Liao L., Zhang H., Nie L., Hu X., Chua T.S., Neural collaborative filtering, Proceedings of the 26th International Conference on World Wide Web, pp. 173-182, (2017); Barbosa E.A., Garcia A., Global-aware recommendations for repairing violations in exception handling, IEEE Trans. Softw. Eng, 44, pp. 855-873, (2017); Huang Q., Xia X., Xing Z., Lo D., Wang X., API method recommendation without worrying about the task-API knowledge gap, Proceedings of the 2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 293-304, (2018); Ichii M., Hayase Y., Yokomori R., Yamamoto T., Inoue K., Software component recommendation using collaborative filtering, Proceedings of the 2009 ICSE Workshop on Search-Driven Development-Users, Infrastructure, Tools and Evaluation, pp. 17-20, (2009); Thung F., Lo D., Lawall J., Automated library recommendation, Proceedings of the 2013 20th Working conference on reverse engineering (WCRE), pp. 182-191, (2013); Ouni A., Kula R.G., Kessentini M., Ishio T., German D.M., Inoue K., Search-based software library recommendation using multi-objective optimization, Inf. Softw. Technol, 83, pp. 55-75, (2017); Su X., Khoshgoftaar T.M., A survey of collaborative filtering techniques, Adv. Artif. Intell, 2009, (2009); He Q., Li B., Chen F., Grundy J., Xia X., Yang Y., Diversified third-party library prediction for mobile app development, IEEE Trans. Softw. Eng, 48, pp. 150-165, (2020); Bottou L., Large-scale machine learning with stochastic gradient descent, Proceedings of the COMPSTAT’2010: 19th International Conference on Computational Statistics, pp. 177-186, (2010); Li B., He Q., Chen F., Xia X., Li L., Grundy J., Yang Y., Embedding app-library graph for neural third party library recommendation, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 466-477, (2021); Yan D., Tang T., Xie W., Zhang Y., He Q., Session-based Social and Dependency-aware Software Recommendation, (2021); Ortega A., Frossard P., Kovacevic J., Moura J.M., Vandergheynst P., Graph signal processing: Overview, challenges, and applications, Proc. IEEE, 106, pp. 808-828, (2018); Krasanakis E., Papadopoulos S., Kompatsiaris I., Symeonidis A., pygrank: A Python Package for Graph Node Ranking, (2021); Page L., Brin S., Motwani R., Winograd T., The PageRank Citation Ranking: Bringing Order to the Web, (1999); Andersen R., Chung F., Lang K., Local graph partitioning using pagerank vectors, Proceedings of the 2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS’06), pp. 475-486, (2006); Bahmani B., Chowdhury A., Goel A., Fast incremental and personalized pagerank, (2010); Chung F., The heat kernel as the pagerank of a graph, Proc. Natl. Acad. Sci. USA, 104, pp. 19735-19740, (2007); Kloster K., Gleich D.F., Heat kernel based community detection, Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1386-1395, (2014); Wu Z., Pan S., Chen F., Long G., Zhang C., Philip S.Y., A comprehensive survey on graph neural networks, IEEE Trans. Neural Netw. Learn. Syst, 32, pp. 4-24, (2020); Zhang Z., Cui P., Zhu W., Deep learning on graphs: A survey, IEEE Trans. Knowl. Data Eng, 34, pp. 249-270, (2020); Wang X., He X., Wang M., Feng F., Chua T.S., Neural graph collaborative filtering, Proceedings of the 42nd international ACM SIGIR conference on Research and development in Information Retrieval, pp. 165-174, (2019); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, (2016); Agarap A.F., Deep learning using rectified linear units (relu), (2018); Hamilton W.L., Ying R., Leskovec J., Inductive representation learning on large graphs, Proceedings of the 31st International Conference on Neural Information Processing Systems, pp. 1025-1035, (2017); Klicpera J., Bojchevski A., Gunnemann S., Predict then propagate: Graph neural networks meet personalized pagerank, (2018); Chen M., Wei Z., Huang Z., Ding B., Li Y., Simple and deep graph convolutional networks, Proceedings of the International Conference on Machine Learning, pp. 1725-1735, (2020); Adamczyk P., Smith P.H., Johnson R.E., Hafiz M., Rest and web services: In theory and in practice, REST: From Research to Practice, pp. 35-57, (2011); Gunasekaran A., Agile manufacturing: A framework for research and development, Int. J. Prod. Econ, 62, pp. 87-105, (1999); Dong H., Chen J., Feng F., He X., Bi S., Ding Z., Cui P., On the equivalence of decoupled graph convolution network and label propagation, Proceedings of the Web Conference 2021, pp. 3651-3662; Yang F., Zhang H., Tao S., Hao S., Graph representation learning via simple jumping knowledge networks, Appl. Intell, pp. 1-19, (2022); Gleich D.F., Seshadhri C., Vertex neighborhoods, low conductance cuts, and good seeds for local community methods, Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 597-605, (2012); Tong H., Faloutsos C., Pan J.Y., Fast random walk with restart and its applications, Proceedings of the Sixth International Conference on Data Mining (ICDM’06), pp. 613-622, (2006); Wu X.M., Li Z., So A., Wright J., Chang S.F., Learning with partially absorbing random walks, Adv. Neural Inf. Process. Syst, 25, pp. 3077-3085, (2012); Krasanakis E., Papadopoulos S., Kompatsiaris I., Stopping personalized PageRank without an error tolerance parameter, Proceedings of the 2020 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), pp. 242-249, (2020); Wang J., Song G., Wu Y., Wang L., Streaming graph neural networks via continual learning, Proceedings of the 29th ACM International Conference on Information & Knowledge Management, pp. 1515-1524, (2020)","","","","","",English,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85129358472,269
Nadim M.; Mondal D.; Roy C.K.,"Nadim, Md (57516873600); Mondal, Debajyoti (36190110000); Roy, Chanchal K. (36176304400)",57516873600; 36190110000; 36176304400,Leveraging structural properties of source code graphs for just-in-time bug prediction,2022,Automated Software Engineering,29,1,27,"","","",10,10.1007/s10515-022-00326-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125647013&doi=10.1007%2fs10515-022-00326-0&partnerID=40&md5=e1bee7a7a259198ea08691007f2c1829,"The most common use of data visualization is to minimize the complexity for proper understanding. A graph is one of the most commonly used representations for understanding relational data. It produces a simplified representation of data that is challenging to comprehend if kept in a textual format. In this study, we propose a methodology to utilize the relational properties of source code in the form of a graph to identify Just-in-Time (JIT) bug prediction in software systems during different revisions of software evolution and maintenance. We presented a method to convert the source codes of commit patches to equivalent graph representations and named it Source Code Graph (SCG). To understand and compare multiple source code graphs, we extracted several structural properties of these.graphs, such as the density, number of cycles, nodes, edges, etc. We then utilized the attribute values of those SCGs to visualize and detect buggy software commits. We process more than 246 K software commits from 12 subject systems in this investigation. Our investigation on these 12 open-source software projects written in C++ and Java programming languages shows that if we combine the features from SCG with conventional features used in similar studies, we will get the increased performance of Machine Learning (ML) based buggy commit detection models. We also find the increase of F1 Scores in predicting buggy and non-buggy commits statistically significant using the Wilcoxon Signed Rank Test. Since SCG-based feature values represent the style or structural properties of source code updates or changes in the software system, it suggests the importance of careful maintenance of source code style or structure for keeping a software system bug-free. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Alexandru C.V., Proksch S., Behnamghader P., Gall H.C., Evo-clocks: Software evolution at a glance, 2019 Working Conference on Software Visualization (VISSOFT), pp. 12-22, (2019); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, International Conference on Learning Representations, (2018); Asaduzzaman M., Bullock M.C., Roy C.K., Schneider K.A., Bug introducing changes: a case study with android, 2012 9th IEEE Working Conference on Mining Software Repositories (MSR), pp. 116-119, (2012); Bavota G., de Carluccio B., de Lucia A., Di Penta M., Oliveto R., Strollo O., When does a refactoring induce bugs? An empirical study, Proceedings of the 2012 IEEE 12Th International Working Conference on Source Code Analysis and Manipulation, pp. 104-113, (2012); Baxter I., Yahin A., Moura L., Sant'Anna M., Bier L., Clone detection using abstract syntax trees, Proceedings. International Conference on Software Maintenance (Cat. No. 98CB36272), pp. 368-377, (1998); Bernardi M.L., Canfora G., Di Lucca G.A., Di Penta M., Distante D., Do developers introduce bugs when they do not communicate? the case of eclipse and mozilla, 2012 16th European Conference on Software Maintenance and Reengineering, pp. 139-148, (2012); Bondy J.A., Murty U.S.R., Graphs and Subgraphs, pp. 9-10, (1976); Borg M., Svensson O., Berg K., Hansson D., Szz unleashed: An open implementation of the szz algorithm - featuring example usage in a study of just-in-time bug prediction for the jenkins project, Proceedings of the 3Rd ACM SIGSOFT International Workshop on Machine Learning Techniques for Software Quality Evaluation - Maltesque 2019, (2019); Bulmer J., Pinchbeck A., Hui B., Visualizing code patterns in novice programmers, Proceedings of the 23Rd Western Canadian Conference on Computing Education, 18, (2018); Burch M., Vehlow C., Beck F., Diehl S., Weiskopf D., Parallel edge splatting for scalable dynamic graph visualization, IEEE Trans. Visualiz. Comp. Graphics, 17, 12, pp. 2344-2353, (2011); Canfora G., Ceccarelli M., Cerulo L., Di Penta M., How long does a bug survive? an empirical study, 2011 18th Working Conference on Reverse Engineering, pp. 191-200, (2011); Chevalier F., Auber D., Telea A., Structural analysis and visualization of c++ code evolution using syntax trees, Ninth International Workshop on Principles of Software Evolution: In: Conjunction with the 6Th ESEC/FSE Joint Meeting, Association for Computing Machinery, New York, NY, USA, IWPSE ’07, Pp. 90-97, (2007); Collofello J.S., Woodfield S.N., Evaluating the effectiveness of reliability-assurance techniques, J. Syst. Softw., 9, 3, pp. 191-195, (1989); Dhaya R., Kanthavel R., Comprehensively meld code clone identifier for replicated source code identification in diverse web browsers, J. Trends Comp. Sci. Smart Technol. (TCSST), 2, 2, pp. 109-119, (2020); Diehl S., Software Visualization: Visualizing the Structure, Behaviour, and Evolution of Software, (2007); Ell J., Identifying failure inducing developer pairs within developer networks, Proceedings of the 35Th International Conference on Software Engineering (ICSE’13), pp. 1471-1473, (2013); Eyolfson J., Tan L., Lam P., Do time of day and developer experience affect commit bugginess?, Proceedings of the 8Th Working Conference on Mining Software Repositories (MSR’11), pp. 153-162, (2011); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Trans. Program Lang. Syst., 9, 3, pp. 319-349, (1987); Classification: Precision and Recall | Machine Learning Crash Course, (2021); Gove R., Gragnostics: Fast, interpretable features for comparing graphs, 23Rd International Conference on Information Visualisation, pp. 201-209, (2019); Gu Z., Barr E.T., Hamilton D.J., Su Z., Has the bug really been fixed?, Proceedings of the 32Nd ACM/IEEE International Conference on Software Engineering - Volume 1, ACM, New York, NY, USA, ICSE ’10, Pp., pp. 55-64, (2010); Hamilton W.L., Ying R., Leskovec J., Representation learning on graphs: methods and applications, IEEE Data Eng Bull, 40, 3, pp. 52-74, (2017); Hindle A., German D.M., Holt R., What do large commits tell us? A taxonomical study of large commits, Proceedings of the 2008 International Working Conference on Mining Software Repositories, pp. 99-108, (2008); Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P., On the naturalness of software, Proceedings of the 34Th International Conference on Software Engineering, IEEE Press, ICSE ’12, Pp., pp. 837-847, (2012); Hinton G., Roweis S., Stochastic neighbor embedding, Adv. Neural Inf. Process. Syst., 15, pp. 833-840, (2003); Islam M.R., Zibran M.F., What changes in where? an empirical study of bug-fixing change patterns, SIGAPP Appl. Comput. Rev., 20, 4, pp. 18-34, (2021); Jajuga K., Walesiak M., Standardisation of data set under different measurement scales, Classification and Information Processing at the Turn of the Millennium. Studies in Classification, Data Analysis, and Knowledge Organization, pp. 105-111, (2000); Jones J.A., Harrold M.J., Stasko J., Visualization of test information to assist fault localization, Proceedings of the 24Th International Conference on Software Engineering, Association for Computing Machinery, New York, NY, USA, ICSE ’02, Pp, pp. 467-477, (2002); Jones K.S., Natural Language Processing: A Historical Review, pp. 3-16, (1994); Kamei Y., Shihab E., Adams B., Hassan A.E., Mockus A., Sinha A., Ubayashi N., A large-scale empirical study of just-in-time quality assurance, IEEE Trans. Softw. Eng., 39, 6, pp. 757-773, (2013); Kim S., Whitehead E.J., How long did it take to fix bugs?, Proceedings of the International Workshop on Mining Software Repositories (MSR’06), pp. 173-174, (2006); Kim S., Whitehead E.J., Zhang Y., Classifying software changes: clean or buggy?, IEEE Trans. Softw. Eng., 34, 2, pp. 181-196, (2008); Kim Y., Kim J., Jeon H., Kim Y.H., Song H., Kim B., Seo J., Githru: visual analytics for understanding software development history through git metadata analysis, IEEE Trans. Visualiz. Comp. Graphics., (2020); Kruiger J.F., Rauber P.E., Martins R.M., Kerren A., Kobourov S., Telea A.C., Graph layouts by t-sne, Comput. Graph. Forum, 36, 3, pp. 283-294, (2017); Llvm’s analysis and transform passes – llvm 13 documentation., (2019); Mikolov T., Sutskever I., Chen K., Corrado G., Dean J., Distributed representations of words and phrases and their compositionality, Proceedings of the 26Th International Conference on Neural Information Processing Systems - Volume, 2, pp. 3111-3119, (2013); Mockus V., Identifying reasons for software changes using historic databases, Proceedings 2000 International Conference on Software Maintenance, pp. 120-130, (2000); Mostafa N., Krintz C., Tracking performance across software revisions, Proceedings of the 7Th International Conference on Principles and Practice of Programming in Java, Association for Computing Machinery, New York, NY, USA, PPPJ ’09, pp. 162-171, (2009); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, AAAI Press, AAAI’16, pp. 1287-1293, (2016); Myers E.M., A precise inter-procedural data flow algorithm, Proceedings of the 8Th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, Association for Computing Machinery, New York, NY, USA, POPL ’81, Pp. 219-230, (1981); Nadim M., Investigating the Techniques to Detect and Reduce Bug Inducing Commits during Change Operations in Software Systems, (2020); Nam D., Lee Y.K., Medvidovic N., Eva: A tool for visualizing software architectural evolution, 2018 IEEE/ACM 40Th International Conference on Software Engineering: Companion (Icse-Companion), pp. 53-56, (2018); Nguyen A.T., Nguyen T.N., Graph-based statistical language model for code, Proceedings of the 37Th International Conference on Software Engineering - Volume, 1, pp. 858-868, (2015); Pradel M., Sen K., Deepbugs: A learning approach to name-based bug detection, Proc ACM Program Lang, 2, OOPSLA, (2018); Purushothaman R., Perry D., Toward understanding the rhetoric of small source code changes, IEEE Trans. Softw. Eng., 31, 6, pp. 511-526, (2005); Rajlich V., Software evolution and maintenance, Future Softw. Eng. Proc. Assoc. Comput. Mach. New York, NY, USA, FOSE, 2014, pp. 133-144, (2014); Ray B., Hellendoorn V., Godhane S., Tu Z., Bacchelli A., Devanbu P., On the ""naturalness"" of buggy code, Proceedings of the 38Th International Conference on Software Engineering, Association for Computing Machinery, New York, NY, USA, ICSE ’16, Pp., pp. 428-439, (2016); Reniers D., Voinea L., Ersoy O., Telea A., The solid* toolset for software visual analytics of program structure and metrics comprehension: from research prototype to product, Sci. Comput. Program, 79, pp. 224-240, (2014); Rosen C., Grawi B., Shihab E., Commit guru: Analytics and risk prediction of software commits, Proceedings of the 2015 10Th Joint Meeting on Foundations of Software Engineering, Association for Computing Machinery, New York, NY, USA, ESEC/FSE 2015, Pp. 966–969, (2015); Rosen C., Grawi B., Shihab E., Commit guru: Analytics and risk prediction of software commits, Proceedings of the 2015 10Th Joint Meeting on Foundations of Software Engineering, Association for Computing Machinery, New York, NY, USA, ESEC/FSE 2015, Pp., pp. 966-969, (2015); Rosner B., Glynn R.J., Lee M.L.T., The wilcoxon signed rank test for paired comparisons of clustered data, Biometrics, 62, 1, pp. 185-192, (2006); Sandoval Alcocer J.P., Bergel A., Ducasse S., Denker M., Performance evolution blueprint: Understanding the impact of software evolution on performance, 2013 First IEEE Working Conference on Software Visualization (VISSOFT), pp. 1-9, (2013); Sandoval J.P., Beck F., Bergel A., Performance evolution matrix: Visualizing performance variations along software versions, 2019 Working Conference on Software Visualization (VISSOFT), pp. 1-11, (2019); Shakya S., Smys S., Reliable automated software testing through hybrid optimization algorithm, J. Ubiquitous Comput. Commun. Technol. (UCCT)., pp. 126-135, (2020); Shivaji S., James Whitehead E., Akella R., Kim S., Reducing features to improve code change-based bug prediction, IEEE Trans. Softw. Eng., 39, 4, pp. 552-569, (2013); Sliwerski J., Zimmermann T., Zeller A., Hatari: Raising risk awareness, ACM SIGSOFT Softw. Eng. Notes, 30, 5, pp. 107-110, (2005); Sliwerski J., Zimmermann T., Zeller A., When do changes induce fixes?, ACM SIGSOFT Softw. Eng. Notes, 30, 4, pp. 1-5, (2005); Storey M., Bennett C., Bull R.I., German D.M., Remixing visualization to support collaboration in software maintenance, Frontiers of Software Maintenance, pp. 139-148, (2008); Student: The probable error of a mean, Biometrika, pp. 1-25, (1908); Tabassum S., Minku L.L., Feng D., Cabral G.G., Song L., An investigation of cross-project learning in online just-in-time software defect prediction, 2020 IEEE/ACM 42Nd International Conference on Software Engineering (ICSE), pp. 554-565, (2020); Tan M., Tan L., Dara S., Mayeux C., Online defect prediction for imbalanced data, In: Proceedings of the 37Th International Conference on Software Engineering - Volume, 2, pp. 99-108, (2015); Tomida Y., Higo Y., Matsumoto S., Kusumoto S., Visualizing code genealogy: How code is evolutionarily fixed in program repair?, Working Conference on Software Visualization (VISSOFT), pp. 23-27, (2019); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, Proceedings of the 15Th International Conference on Mining Software Repositories, 18, pp. 542-553, (2018); van Der Maaten L., Hinton G., Visualizing data using t-sne, J. Mach. Learn. Res., 9, 86, pp. 2579-2605, (2008); Vieira R., da Silva A., Rocha L., Gomes J., From reports to bug-fix commits: A 10 years dataset of bug-fixing activity from 55 apache’s open source projects, Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering, pp. 80-89; Voinea L., Telea A., van Wijk J.J., Cvsscan: Visualization of code evolution, Proceedings of the 2005 ACM Symposium on Software Visualization, pp. 47-56, (2005); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, Proceedings of the 38Th International Conference on Software Engineering, Association for Computing Machinery, New York, NY, USA, ICSE ’16, Pp. 297–308, (2016); Wen M., Wu R., Liu Y., Tian Y., Xie X., Cheung S.C., Su Z., Exploring and exploiting the correlations between bug-inducing and bug-fixing commits, Proceedings of the 27Th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE’19), pp. 326-337, (2019); Wilcoxon F., Individual comparisons by ranking methods, Biomet. Bull., 1, 6, pp. 80-83, (1945); Yang X., Lo D., Xia X., Zhang Y., Sun J., Deep learning for just-in-time defect prediction, Proceedings of the IEEE International Conference on Software Quality, Reliability and Security (QRS’15), pp. 17-26, (2015); Yin Z., Yuan D., Zhou Y., Pasupathy S., Bairavasundaram L., How do fixes become bugs?, Proceedings of the 19Th ACM SIGSOFT Symposium and the 13Th European Conference on Foundations of Software Engineering, ACM, New York, NY, USA, ESEC/FSE ’11, Pp., pp. 26-36, (2011); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu, X.:A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41St International Conference on Software Engineering (ICSE, pp. 783-794, (2019)","","","","","",English,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85125647013,270
Tian Z.; Zhang C.; Tian B.,"Tian, Zhenzhou (56258233500); Zhang, Cuiping (58099305000); Tian, Binhui (58099255100)",56258233500; 58099305000; 58099255100,Code Summarization Through Learning Linearized AST Paths with Transformer,2023,Lecture Notes on Data Engineering and Communications Technologies,153,"","",53,60,7,0,10.1007/978-3-031-20738-9_7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147852355&doi=10.1007%2f978-3-031-20738-9_7&partnerID=40&md5=220cea88b634670078d9d23b2a52a7f4,"The lack of code comments is common in software projects. This work proposes TFSum, which generates from a function’s source code a readable summary to describe its functionality, with a Transformer based model trained on sequences linearized from the function’s abstract syntax tree (AST). To ensure the quality of the generated summaries, TFSum firstly parses from the function’s source code an AST of semantic richness, as the raw representation of the function; but linearizes and pre-processes it into a set of normalized token sequences, for efficient and effective following semantic representation learning. On this basis, an encoder-decoder based generative model that adopts the Transformer architecture is designed and trained to automatically generate code comments. The experimental evaluations conducted on a public dataset show the superiority of TFSum over state-of-the-art neural code summarization methods, with the BLEU score reaching 46.84. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Xia X., Bao L., Lo D., Xing Z., Hassan A.E., Li S., Measuring program comprehension: A large-scale field study with professionals, IEEE Trans. Softw. Eng., 44, 10, pp. 951-976, (2017); Sridhara G., Hill E., Muppaneni D., Pollock L., Vijay-Shanker K., PrTowards automatically generating summary comments for java methods, Proceedings of the IEEE/ACM International Conference on Automated Software Engineering, pp. 43-52, (2010); McBurney P.W., McMillan C., Automatic documentation generation via source code summarization of method context, Proceedings of the 22Nd International Conference on Program Comprehension, pp. 279-290, (2014); McBurney P.W., McMillan C., Automatic source code summarization of context for java methods, IEEE Trans. Softw. Eng., 42, 2, pp. 103-119, (2015); Sridhara G., Pollock L., Vijay-Shanker K., Generating parameter comments and integrating with method summaries, 2011 IEEE 19Th International Conference on Program Comprehension, Pp. 71–80. IEEE, (2011); Eddy B.P., Robinson J.A., Kraft N.A., Carver J.C., Evaluating source code summarization techniques: Replication and expansion, 2013 21St International Conference on Program Comprehension (ICPC), pp. 13-22, (2013); Haiduc S., Aponte J., Moreno L., Marcus A., On the use of automated text summarization techniques for summarizing source code, 2010 17Th Working Conference on Reverse Engineering, pp. 35-44, (2010); Sutskever I., Vinyals O., Le Q.V., Sequence to sequence learning with neural networks, Adv. Neural Inf. Process. Syst., 27, (2014); Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., Summarizing Source Code with Transferred API Knowledge, (2018); Ahmad W.U., Chakraborty S., Ray B., Chang K.W., A Transformer-Based Approach for Source Code Summarization. Arxiv, 2005, (2020); Papineni K., Roukos S., Ward T., Zhu W.J., Bleu: A method for automatic evaluation of machine translation, Proceedings of the 40Th Annual Meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Denkowski M., Lavie A., Meteor universal: Language specific translation evaluation for any target language, Proceedings of the Ninth Workshop on Statistical Machine Translation, pp. 376-380, (2014); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54Th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2073-2083, (2016); Eriguchi A., Hashimoto K., Tsuruoka Y., Tree-To-Sequence Attentional Neural Machine Translation. Arxiv, 1603, (2016); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P., S.: Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33Rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, (2018); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, 2018 IEEE/ACM 26Th International Conference on Program Comprehension (ICPC), pp. 200-20010, (2018); Wei B., Li G., Xia X., Fu Z., Jin Z., Code generation as a dual task of code summarization, Adv. Neural Inf. Process. Syst., 32, (2019)","","","","","",English,Book chapter,Final,"",Scopus,2-s2.0-85147852355,271
LeClair A.; Haque S.; Wu L.; McMillan C.,"LeClair, Alexander (57189643544); Haque, Sakib (57219259190); Wu, Lingfei (56937260100); McMillan, Collin (35094348900)",57189643544; 57219259190; 56937260100; 35094348900,Improved code summarization via a graph neural network,2020,IEEE International Conference on Program Comprehension,"","","",184,195,11,193,10.1145/3387904.3389268,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091891388&doi=10.1145%2f3387904.3389268&partnerID=40&md5=ce69209bb60c6825fb0237b8e58ffa4f,"Automatic source code summarization is the task of generatingnatural language descriptions for source code. Automatic code summarization is a rapidly expanding research area, especially as thecommunity has taken greater advantage of advances in neural network and AI technologies. In general, source code summarizationtechniques use the source code as input and outputs a natural language description. Yet a strong consensus is developing that usingstructural information as input leads to improved performance. Thefirst approaches to use structural information flattened the AST intoa sequence. Recently, more complex approaches based on randomAST paths or graph neural networks have improved on the modelsusing flattened ASTs. However, the literature still does not describethe using a graph neural network together with source code sequence as separate inputs to a model. Therefore, in this paper, wepresent an approach that uses a graph-based neural architecturethat better matches the default structure of the AST to generatethese summaries. We evaluate our technique using a data set of2.1 million Java method-comment pairs and show improvementover four baseline techniques, two from the software engineeringliterature, and two from machine learning literature. © 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Abadi M., Agarwal A., Barham P., Brevdo E., Chen Z., Citro C., Corrado G.S., Davis A., Dean J., Devin M., Ghemawat S., Goodfellow I., Harp A., Irving G., Isard M., Jia Y., Jozefowicz R., Kaiser L., Kudlur M., Levenberg J., Mane D., Monga R., Moore S., Murray D., Olah C., Schuster M., Shlens J., Steiner B., Sutskever I., Talwar K., Tucker P., Vanhoucke V., Vasudevan V., Viegas F., Vinyals O., Warden P., Wattenberg M., Wicke M., Yu Y., Zheng X., TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems, (2015); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, International Conference on Learning Representations, (2018); Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating sequences from structured representations of code, International Conference on Learning Representations, (2019); Arras L., Horn F., Montavon G., Muller K.-R., Samek W., What is relevant in a text document?"": An inter-pretable machine learning approach, Plos. One, 12, 8, (2017); Bahdanau D., Cho K., Bengio Y., Neural Machine Translation by Jointly Learning to Align and Translate, (2014); Binkley D., Source code analysis: A road map, 2007 Future of Software Engineering, pp. 104-119, (2007); Chen H., Huang S., Chiang D., Chen J., Improved neural machine translation with a syntax-Aware encoder and decoder, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1936-1945, (2017); Chen Y., Wu L., Zaki M.J., Reinforcement learning based graph-to-sequence model for natural question generation, International Conference on Learning Representations (2020), (2020); Chollet F., Et al., Keras, (2015); Collard M.L., Decker M.J., Maletic J.I., Lightweight transformation and fact extraction with the srcml toolkit, Source Code Analysis and Manipulation (SCAM) 2011 11th Ieee International Working Conference on, pp. 173-184, (2011); Cornelissen B., Zaidman A., Van Deursen A., Moonen L., Koschke R., A systematic survey of program comprehension through dynamic analysis, Ieee Transactions on Software Engineering, 35, 5, pp. 684-702, (2009); De Souza S.C.B., Anquetil N., De Oliveira K.M., A study of the documentation essential to software maintenance, Proceedings of the 23rd Annual International Conference on Design of Communication: Documenting & Designing for Pervasive Information (SIGDOC '05), pp. 68-75, (2005); Doran D., Schulz S., Besold T.R., What does explainable ai really mean? A new conceptualization of perspectives, CoRR, (2017); Doshi-Velez F., Kim B., Towards A Rigorous Science of Inter-pretable Machine Learning, (2017); Eddy B.P., Robinson J.A., Kraft N.A., Carver J.C., Evaluating source code summarization techniques: Replication and expansion, Program Comprehension (ICPC) 2013 Ieee 21st International Conference on, pp. 13-22, (2013); Fernandes P., Allamanis M., Brockschmidt M., Structured neural summarization, CoRR, (2018); Forward A., Lethbridge T.C., The relevance of software documentation, tools and technologies: A survey, Proceedings of the 2002 Acm Symposium on Document Engineering (DocEng '02), pp. 26-33, (2002); Gu J., Lu Z., Li H., Li V.O.K., Incorporating copying mechanism in sequence-to-sequence learning, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), (2016); Haiduc S., Aponte J., Moreno L., Marcus A., On the use of automated text summarization techniques for summarizing source code, Reverse Engineering (WCRE) 2010 17th Working Conference on, pp. 35-44, (2010); Haiduc S., Marcus A., On the use of domain terms in source code, 16th Ieee International Conference on Program Comprehension (ICPC'08), pp. 113-122, (2008); Hellendoorn V.J., Devanbu P., Are deep neural networks the best choice for modeling source code?, Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, pp. 763-773, (2017); Howard M.J., Gupta S., Pollock L., Vijay-Shanker K., Automatically mining software-based, semantically-similar words from comment-code mappings, 2013 10th Working Conference on Mining Software Repositories (MSR)., pp. 377-386, (2013); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proceedings of the 26th International Conference on Program Comprehension, pp. 200-210, (2018); Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., Summarizing source code with transferred api knowledge, IJCAI., pp. 2269-2275, (2018); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Vol., 1, pp. 2073-2083, (2016); Kajko-Mattsson M., A survey of documentation practice within corrective maintenance, Empirical Softw. Engg., 10, 1, pp. 31-55, (2005); Kramer D., Api documentation from source code comments: A case study of javadoc, Proceedings of the 17th Annual International Conference on Computer Documentation, pp. 147-153, (1999); LeClair A., Eberhart Z., McMillan C., Adapting neural text clas-sifcation for improved software categorization, 2018 Ieee International Conference on Software Maintenance and Evolution (ICSME)., pp. 461-472, (2018); LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, Proceedings of the 41st International Conference on Software Engineering, pp. 795-806, (2019); LeClair A., McMillan C., Recommendations for datasets for source code summarization, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies 1 (Long and Short Papers)., pp. 3931-3937, (2019); Liang Y., Zhu K.Q., Automatic generation of text descriptive comments for code blocks, CoRR, (2018); Lin C.-Y., Rouge: A package for automatic evaluation of summaries, Text Summarization Branches out, (2004); Lopes C., Bajracharya S., Ossher J., Baldi P., Uci Source Code Data Sets, (2010); Loyola P., Marrese-Taylor E., Matsuo Y., A neural architecture for generating natural language descriptions from source code changes, Acl, (2017); Lu Y., Zhao Z., Li G., Jin Z., Learning to generate comments for api-based code snippets, Software Engineering and Methodology for Emerging Domains, pp. 3-14, (2019); McBurney P.W., Liu C., McMillan C., Automated feature discovery via sentence selection and source code summarization, Journal of Software: Evolution and Process, 28, 2, pp. 120-145, (2016); McBurney P.W., McMillan C., Automatic source code summarization of context for java methods, Ieee Transactions on Software Engineering, 42, 2, pp. 103-119, (2016); Miller T., Explanation in artifcial intelligence: Insights from the social sciences, Artifcial Intelligence, 267, pp. 1-38, (2019); Moreno L., Aponte J., On the analysis of human and automatic summaries of source code, Clei Electronic Journal, 15, 2, (2012); Moreno L., Aponte J., Sridhara G., Marcus A., Pollock L., Vijay-Shanker K., Automatic generation of natural language summaries for java classes, Program Comprehension (ICPC) 2013 Ieee 21st International Conference on, pp. 23-32, (2013); Nazar N., Hu Y., Jiang H., Summarizing software artifacts: A literature review, Journal of Computer Science and Technology, 31, 5, pp. 883-909, (2016); Ottenstein K.J., Ottenstein L.M., The program dependence graph in a software development environment, Acm Sigsoft Software Engineering Notes, 9, 3, pp. 177-184, (1984); Papineni K., Roukos S., Ward T., Zhu W.-J., Bleu: A method for automatic evaluation of machine translation, Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pp. 311-318, (2002); Rodeghero P., Liu C., McBurney P.W., McMillan C., An eye-tracking study of java programmers and application to source code summarization, Ieee Transactions on Software Engineering, 41, 11, pp. 1038-1054, (2015); Roehm T., Tiarks R., Koschke R., Maalej W., How do professional developers comprehend software?, Proceedings of the 2012 International Conference on Software Engineering (ICSE 2012), pp. 255-265, (2012); Roscher R., Bohn B., Duarte M.F., Garcke J., Explainable Machine Learning for Scientifc Insights and Discoveries, (2019); Samek W., Wiegand T., Muller K.-R., Explainable Artifcial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models, (2017); Shi L., Zhong H., Xie T., Li M., An empirical study on evolution of api documentation, Proceedings of the 14th International Conference on Fundamental Approaches to Software Engineering: Part of the Joint European Conferences on Theory and Practice of Software (FASE'11/ETAPS'11), pp. 416-431, (2011); Song X., Sun H., Wang X., Yan J., A survey of automatic generation of source code comments: Algorithms and techniques, Ieee Access, (2019); Sridhara G., Hill E., Muppaneni D., Pollock L., Vijay-Shanker K., Towards automatically generating summary comments for java methods, Proceedings of the IEEE/ACM International Conference on Automated Software Engineering, pp. 43-52, (2010); Sridhara G., Pollock L., Vijay-Shanker K., Automatically detecting and describing high level actions within methods, Proceedings of the 33rd International Conference on Software Engineering, pp. 101-110, (2011); Sutskever I., Martens J., Hinton G.E., Generating text with recurrent neural networks, Proceedings of the 28th International Conference on Machine Learning (ICML-11)., pp. 1017-1024, (2011); Sutskever I., Vinyals O., Le Q.V., Sequence to sequence learning with neural networks, Advances in Neural Information Processing Systems., pp. 3104-3112, (2014); Von Mayrhauser A., Marie Vans A., Program comprehension during software maintenance and evolution, Computer, 8, pp. 44-55, (1995); Von Rueden L., Mayer S., Garcke J., Bauckhage C., Schuecker J., Informed Machine Learning-Towards a Taxonomy of Explicit Integration of Knowledge into Machine Learning, (2019); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., Yu P.S., Improving automatic source code summarization via deep reinforcement learning, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering (ASE 2018), pp. 397-407, (2018); Wu Z., Pan S., Chen F., Long G., Zhang C., Yu P.S., A comprehensive survey on graph neural networks, CoRR, (2019); Xu K., Wu L., Wang Z., Feng Y., Witbrock M., Sheinin V., Graph2seq: Graph to Sequence Learning with Attention-Based Neural Networks, (2018); Xu K., Wu L., Wang Z., Yu M., Chen L., Sheinin V., Exploiting rich syntactic information for semantic parsing with graph-to-sequence model, Conference on Empirical Methods in Natural Language Processing, (2018)",ACM; ACM SIGSOFT; IEEE Computer Society; IEEE-CS TCSE; KIISE,"28th IEEE/ACM International Conference on Program Comprehension, ICPC 2020, collocated with the 42nd International Conference on Software Engineering, ICSE 2020",13 July 2020 through 15 July 2020,Seoul,162971,English,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85091891388,272