paper-id: 265
pdf-id: 256
graphs:
  ast:
    name: ast
    description: n/a
    artefacts:
      - name: source code
        details: method
    vertex-type: ast
    edge-type: ast
    vertex-features: n/a
    edge-features: n/a
    connectivity-features: n/a
    graph-features: n/a
    other-features: |-
      every statement in the tree as follows: e.g. MethodDeclaration(Modifier(protected))(sendMessage)...(body)
      This results in a sequence of such statements 
      
      method name (split up into sequence) is used as feature 
      
      sequence of APIs used in the method is used as feature
      
      bag of tokens used in the snippets is used as feature 
      
      code summary/query is used as feature
models:
  model:
    name: n/a
    architecture-attributes:
      - embedding layers for all features
      - for every sequence (statements, method name, apis, tokens, summary/query), apply soft-attention (mlp based) to every element (separately)
      - for every feature (statement, name, apis, tokens), multiply matrix with param matrix and summary matrix
      - perform cnn and use fnn/average pooling/softmax to compute attention scores; multiple with pre-matrix multiplication features
      - fuse features using soft-attention (mlp-based) weighted sum
      - cosine similarity with summary embedding
tasks:
  code-search:
    training-objective: Maximise similarity between related (code, summary) pairs, minimise similarity between unrelated (code, summary) pairs
    training-granularity: n/a
    working-objective: compute code snippet <-> query similarity
    working-granularity: n/a
    application: Code search
    supervision: supervised
combinations:
  - graph: ast
    model: model
    task: code-search
    comments:
comments: # list