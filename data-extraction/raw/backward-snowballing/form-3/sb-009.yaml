paper-id: sb-009
pdf-id: sb-012
graphs:
  split-ast:
    name: Split AST
    description: |-
      First, the CFG is computed.
      Then, the dominator tree of the CFG is computed.
      For every node with more than 2 outgoing edges, its outgoing edges are removed,
      leading to groups of separate nodes. For every group of nodes, its AST 
      subtree is computed. (alternative view: the AST is split up according to the graph described above)
    artefacts:
      - name: source code
        details: n/a
    vertex-type: ast
    edge-type: ast
    vertex-features: Node type and value (concatenated)
    edge-features: n/a
    connectivity-features: Not specified
    graph-features: n/a
    other-features: |-
      Source code is used as feature
models:
  model-1:
    name: n/a
    architecture-attributes:
      - Siamese network (input; two AST sub-trees belonging to the same code sample)
      - child-sum tree-LSTM
      - Take outputs of the two root nodes, concatenate, sigmoid
  model-2:
    name: n/a
    architecture-attributes:
      - Use pre-trained model-1 for graph encoding, apply average pooling over nodes
      - Source code embedded, combined with graph in FNN, positional encoding added
      - Transformer encoder
      - Transformer decoder
tasks:
  pre-training:
    training-objective: Given two sub-trees from the same code sample, predict which one comes first in the dominator tree
    training-granularity: n/a
    working-objective: n/a
    working-granularity: n/a
    application: model pre-training
    supervision: supervised
  code-summarization:
    training-objective: Given a code sample, generate a summary
    training-granularity: x to sequence
    working-objective: Given a code sample, generate a summary
    working-granularity: x to sequence
    application: code summarization
    supervision: supervised
combinations:
  - graph: split-ast
    model: model-1 + model-2
    task: pre-training + code-summarization
    comments:
comments: # list