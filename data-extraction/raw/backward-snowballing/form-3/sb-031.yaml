paper-id: sb-031
pdf-id: sb-042
graphs:
  ast:
    name: AST
    description: n/a
    artefacts:
      - name: source code
        details: pairs of source code for training
    vertex-type: ast
    edge-type: ast
    vertex-features: node type one hot
    edge-features: n/a
    connectivity-features: not specified
    graph-features: n/a
    other-features: n/a
models:
  model:
    name: n/a
    architecture-attributes:
      - encoder/decoder architecture
      - encoder Tree-LSTM
      - decoder; for node type, hidden state into FNN w/ as additional input an attention vector computed on the old ast and the node to be expanded;  for token, node type is fed into trainable embedding followed by LSTM
tasks:
  translation:
    training-objective: Given a program (in AST form), translate the program to a different AST (different language)
    training-granularity: tree to tree
    working-objective: Given a program (in AST form), translate the program to a different AST (different language)
    working-granularity: tree to tree
    application: Program translation
    supervision: supervised
combinations:
  - graph: ast
    model: model
    task: translation
    comments:
comments: # list