Authors,Title,Abstract,Document Type,Year,Link,Source title,Include/Exclude,Author 1 Re-tag,Author 2,Author 2 Re-tag
Hu Z.; Wang Y.; Ning H.; Wu D.; Nie F.,Mutual-Taught Deep Clustering,"Deep clustering seeks to group data into distinct clusters using deep learning techniques. Existing approaches of deep clustering can be broadly categorized into two groups: offline clustering based on unsupervised representation learning and online clustering based on unsupervised classification. While both groups have demonstrated impressive performance in deep clustering, no study has explored the integration of their respective strengths. To this end, we propose Mutual-Taught Deep Clustering (MTDC), which unifies unsupervised representation learning and unsupervised classification into a framework while realizing mutual promotion using a novel mutual-taught mechanism. Specifically, MTDC alternates between predicting pseudolabels in label space and estimating semantic similarity in feature space during training. Moreover, pseudolabels provide weakly-supervised information to enhance unsupervised representation learning, while semantic similarities function as structural priors that regularize unsupervised classification. Consequently, unsupervised classification and unsupervised representation learning can mutually benefit from one another. MTDC is decoupled from prevailing deep clustering methods. For the sake of clarity, we build upon a straightforward baseline in this paper. Despite its simplicity, we demonstrate that MTDC is exceedingly efficacious and consistently enhances the baseline results by substantial margins. For example, MTDC achieves 2.5%∼7.9% (NMI), 3.0%∼13.9% (ACC), and 3.1%∼16.7% (ARI) gains over the baseline on six widely used image datasets. Source code is available at:https://github.com/yichenwang231/MTDC. © 2023 Elsevier B.V.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174721430&doi=10.1016%2fj.knosys.2023.111100&partnerID=40&md5=26dc63ed5f49d8920bcc0d72f9d67cee,Knowledge-Based Systems,Exclude,,,
Hu C.; Li S.; Yang C.; Chen J.; Xiong Y.; Fan G.; Liu H.; Hong L.,ScaffoldGVAE: scaffold generation and hopping of drug molecules via a variational autoencoder based on multi-view graph neural networks,"In recent years, drug design has been revolutionized by the application of deep learning techniques, and molecule generation is a crucial aspect of this transformation. However, most of the current deep learning approaches do not explicitly consider and apply scaffold hopping strategy when performing molecular generation. In this work, we propose ScaffoldGVAE, a variational autoencoder based on multi-view graph neural networks, for scaffold generation and scaffold hopping of drug molecules. The model integrates several important components, such as node-central and edge-central message passing, side-chain embedding, and Gaussian mixture distribution of scaffolds. To assess the efficacy of our model, we conduct a comprehensive evaluation and comparison with baseline models based on seven general generative model evaluation metrics and four scaffold hopping generative model evaluation metrics. The results demonstrate that ScaffoldGVAE can explore the unseen chemical space and generate novel molecules distinct from known compounds. Especially, the scaffold hopped molecules generated by our model are validated by the evaluation of GraphDTA, LeDock, and MM/GBSA. The case study of generating inhibitors of LRRK2 for the treatment of PD further demonstrates the effectiveness of ScaffoldGVAE in generating novel compounds through scaffold hopping. This novel approach can also be applied to other protein targets of various diseases, thereby contributing to the future development of new drugs. Source codes and data are available at https://github.com/ecust-hc/ScaffoldGVAE . © 2023, Springer Nature Switzerland AG.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173741237&doi=10.1186%2fs13321-023-00766-0&partnerID=40&md5=6677809215ac91f74ddab1b389c8cdec,Journal of Cheminformatics,Exclude,,Exclude,
Liu Y.; Liang K.; Xia J.; Yang X.; Zhou S.; Liu M.; Liu X.; Li S.Z.,Reinforcement Graph Clustering with Unknown Cluster Number,"Deep graph clustering, which aims to group nodes into disjoint clusters by neural networks in an unsupervised manner, has attracted great attention in recent years. Although the performance has been largely improved, the excellent performance of the existing methods heavily relies on an accurately predefined cluster number, which is not always available in the real-world scenario. To enable the deep graph clustering algorithms to work without the guidance of the predefined cluster number, we propose a new deep graph clustering method termed Reinforcement Graph Clustering (RGC). In our proposed method, cluster number determination and unsupervised representation learning are unified into a uniform framework by the reinforcement learning mechanism. Concretely, the discriminative node representations are first learned with the contrastive pretext task. Then, to capture the clustering state accurately with both local and global information in the graph, both node and cluster states are considered. Subsequently, at each state, the qualities of different cluster numbers are evaluated by the quality network, and the greedy action is executed to determine the cluster number. In order to conduct feedback actions, the clustering-oriented reward function is proposed to enhance the cohesion of the same clusters and separate the different clusters. Extensive experiments demonstrate the effectiveness and efficiency of our proposed method. The source code of RGC is shared at https://github.com/yueliu1999/RGC and a collection (papers, codes and, datasets) of deep graph clustering is shared at https://github.com/yueliu1999/Awesome-Deep-Graph-Clustering on Github. © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179548806&doi=10.1145%2f3581783.3612155&partnerID=40&md5=4a19ee79caec60009650248174fdd65d,MM 2023 - Proceedings of the 31st ACM International Conference on Multimedia,Exclude,,,
Zhang S.; Jin P.; Lin Z.; Sun Y.; Zhang B.; Xia S.; Li Z.; Zhong Z.; Ma M.; Jin W.; Zhang D.; Zhu Z.; Pei D.,Robust Failure Diagnosis of Microservice System Through Multimodal Data,"Automatic failure diagnosis is crucial for large microservice systems. Currently, most failure diagnosis methods rely solely on single-modal data (i.e., using either metrics, logs, or traces). In this study, we conduct an empirical study using real-world failure cases to show that combining these sources of data (multimodal data) leads to a more accurate diagnosis. However, effectively representing these data and addressing imbalanced failures remain challenging. To tackle these issues, we propose DiagFusion, a robust failure diagnosis approach that uses multimodal data. It leverages embedding techniques and data augmentation to represent the multimodal data of service instances, combines deployment data and traces to build a dependency graph, and uses a graph neural network to localize the root cause instance and determine the failure type. Our evaluations using real-world datasets show that DiagFusion outperforms existing methods in terms of root cause instance localization (improving by 20.9% to 368%) and failure type determination (improving by 11.0% to 169%).  © 2008-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163552123&doi=10.1109%2fTSC.2023.3290018&partnerID=40&md5=62fca280c2498627bdfdb05971af34e3,IEEE Transactions on Services Computing,Exclude,,Exclude,
Snášel V.; Štěpnička M.; Ojha V.; Suganthan P.N.; Gao R.; Kong L.,Large-scale data classification based on the integrated fusion of fuzzy learning and graph neural network,"Deep learning and fuzzy models provide powerful and practical techniques for solving large-scale deep-learning tasks. The fusion technique on deep learning and fuzzy system are generally classified into ensemble and integrated modes and materializes in information fusion, model fusion, and feature fusion. In an ensemble-based fusion, the fuzzy model either acts as an activation function or is operated as a separate process aggregating/preprocessing the information. Some early attempts in the field have successfully fused deep neural networks and fuzzy modeling concepts in ensemble mode. However, no effective attempts were made to fuse fuzzy models as an integrated feature-level fusion learning with graph neural networks (GNNs). This is mainly due to two challenges related to this fusion: (1) the number of fuzzy rules grows exponentially with the number of features that causes computational inefficiency, and (2) the solution space created by this fusion of fuzzy rules becomes complex due to multiple regression relations between inputs and outputs. Additionally, a simple linear regression at the output space would not be sufficient to model deep learning tasks. Therefore, this paper addresses these challenges by proposing a feature-level fusion method to fuse deep learning and fuzzy modeling where the latter technique is for integrated feature learning, called fuzzy forest graph neural network (FuzzyGNN), which creates a fuzzy learning forest fusing the linear graph transformers for deep learning tasks. We conducted experiments on fourteen machine learning datasets to test and validate the efficiency of the proposed FuzzyGNN model. Compared to state-of-the-art methods, our algorithm achieves the best results on four out of five machine learning datasets. The source code will be available at https://github.com/lingping-fuzzy/, https://github.com/vojha-code and https://github.com/P-N-Suganthan. © 2023 The Authors",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174799199&doi=10.1016%2fj.inffus.2023.102067&partnerID=40&md5=31e23360570fff11e796ede0d23109cc,Information Fusion,Exclude,,Exclude,
Shi Y.; Wang B.; Yu Y.; Tang X.; Huang C.; Dong J.,Robust anomaly detection for multivariate time series through temporal GCNs and attention-based VAE,"Anomaly detection on multivariate time series (MTS) is of great importance in both data mining research and industrial applications. While a handful of anomaly detection models are developed for MTS data, most of them either ignore the potential correlations between different variables or overlook the different importance of variables at each time period in MTS, which leads to poor accuracy in anomaly detection. In this paper, we propose a novel unsupervised MUltivariate Time series ANomaly deTection framework (MUTANT), which simultaneously models the correlations between variables and the importance of variables at each time period. Specifically, we construct a feature graph for variables in each time window and perform graph convolutional network (GCN) to learn embeddings for all variables, which effectively captures the time-varying correlations between variables in MTS. Then, we propose an attention-based reconstruction model to learn robust latent representations to capture normal patterns of MTS by modeling the importance of variables based on time dependencies along with time dimension. Our evaluation experiments are conducted on four real-life datasets from different industrial domains. Experimental results show that MUTANT significantly outperforms state-of-the-art MTS anomaly detection methods, achieving an average anomaly detection F1-score higher than 0.96. The source code is available at https://github.com/Coac-syf/MUTANT. © 2023 Elsevier B.V.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163554843&doi=10.1016%2fj.knosys.2023.110725&partnerID=40&md5=1d0ed301a5876b7b5a8a24b839284442,Knowledge-Based Systems,Exclude,,Exclude,
Zhang W.; Wu Q.M.J.; Zhao W.G.W.; Deng H.; Yang Y.,Hierarchical One-Class Model With Subnetwork for Representation Learning and Outlier Detection,"The multilayer one-class classification (OCC) frameworks have gained great traction in research on anomaly and outlier detection. However, most multilayer OCC algorithms suffer from loosely connected feature coding, affecting the ability of generated latent space to properly generate a highly discriminative representation between object classes. To alleviate this deficiency, two novel OCC frameworks, namely: 1) OCC structure using the subnetwork neural network (OC-SNN) and 2) maximum correntropy-based OC-SNN (MCOC-SNN), are proposed in this article. The novelties of this article are as follows: 1) the subnetwork is used to build the discriminative latent space; 2) the proposed models are one-step learning networks, instead of stacking feature learning blocks and final classification layer to recognize the input pattern; 3) unlike existing works which utilize mean square error (MSE) to learn low-dimensional features, the MCOC-SNN uses maximum correntropy criterion (MCC) for discriminative feature encoding; and 4) a brand-new OCC dataset, called CO-Mask, is built for this research. Experimental results on the visual classification domain with a varying number of training samples from 6131 to 513 061 demonstrate that the proposed OC-SNN and MCOC-SNN achieve superior performance compared to the existing multilayer OCC models. For reproducibility, the source codes are available at https://github.com/W1AE/OCC.  © 2013 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129352878&doi=10.1109%2fTCYB.2022.3166349&partnerID=40&md5=b44ca70756082aa923f883d3a4ead943,IEEE Transactions on Cybernetics,Exclude,,,
Sun S.; Liu D.; Dong J.; Qu X.; Gao J.; Yang X.; Wang X.; Wang M.,Unified Multi-modal Unsupervised Representation Learning for Skeleton-based Action Understanding,"Unsupervised pre-training has shown great success in skeleton-based action understanding recently. Existing works typically train separate modality-specific models (i.e., joint, bone, and motion), then integrate the multi-modal information for action understanding by a late-fusion strategy. Although these approaches have achieved significant performance, they suffer from the complex yet redundant multi-stream model designs, each of which is also limited to the fixed input skeleton modality. To alleviate these issues, in this paper, we propose a Unified Multimodal Unsupervised Representation Learning framework, called UmURL, which exploits an efficient early-fusion strategy to jointly encode the multi-modal features in a single-stream manner. Specifically, instead of designing separate modality-specific optimization processes for uni-modal unsupervised learning, we feed different modality inputs into the same stream with an early-fusion strategy to learn their multi-modal features for reducing model complexity. To ensure that the fused multi-modal features do not exhibit modality bias, i.e., being dominated by a certain modality input, we further propose both intra- and inter-modal consistency learning to guarantee that the multi-modal features contain the complete semantics of each modal via feature decomposition and distinct alignment. In this manner, our framework is able to learn the unified representations of uni-modal or multi-modal skeleton input, which is flexible to different kinds of modality input for robust action understanding in practical cases. Extensive experiments conducted on three large-scale datasets, i.e., NTU-60, NTU-120, and PKU-MMD II, demonstrate that UmURL is highly efficient, possessing the approximate complexity with the uni-modal methods, while achieving new state-of-the-art performance across various downstream task scenarios in skeleton-based action representation learning. Our source code is available at https://github.com/HuiGuanLab/UmURL. © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179553595&doi=10.1145%2f3581783.3612449&partnerID=40&md5=4ba2887e918fc1064ce9be967a7d12d7,MM 2023 - Proceedings of the 31st ACM International Conference on Multimedia,Exclude,,,
Sui J.; Chen J.; Chen Y.; Iwamori N.; Sun J.,Identification of plant vacuole proteins by using graph neural network and contact maps,"Plant vacuoles are essential organelles in the growth and development of plants, and accurate identification of their proteins is crucial for understanding their biological properties. In this study, we developed a novel model called GraphIdn for the identification of plant vacuole proteins. The model uses SeqVec, a deep representation learning model, to initialize the amino acid sequence. We utilized the AlphaFold2 algorithm to obtain the structural information of corresponding plant vacuole proteins, and then fed the calculated contact maps into a graph convolutional neural network. GraphIdn achieved accuracy values of 88.51% and 89.93% in independent testing and fivefold cross-validation, respectively, outperforming previous state-of-the-art predictors. As far as we know, this is the first model to use predicted protein topology structure graphs to identify plant vacuole proteins. Furthermore, we assessed the effectiveness and generalization capability of our GraphIdn model by applying it to identify and locate peroxisomal proteins, which yielded promising outcomes. The source code and datasets can be accessed at https://github.com/SJNNNN/GraphIdn . © 2023, BioMed Central Ltd., part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171862085&doi=10.1186%2fs12859-023-05475-x&partnerID=40&md5=81ee853f734136f08d72a356c0139850,BMC Bioinformatics,Exclude,,,
Guo H.; Zhou Z.; Zhao D.; Gaaloul W.,EGNN: Energy-efficient anomaly detection for IoT multivariate time series data using graph neural network,"Anomaly detection has been widely applied in Internet of Things (IoT) to guarantee the health of IoT applications. Current studies on anomaly detection focus mainly on measurement design and discovery methods on the cloud, which, however, are associated with issues of computational heaviness and capacity limitation when applied at the network edge. Thus, it becomes important to ensure that the detection is not only accurate but also energy-efficient. To fill this gap, this paper proposes an accurate and Energy-efficient Graph Neural Network based anomaly detection method (EGNN) for IoT multivariate time series data. Specifically, correlations between sensory data upon different IoT devices, which are rarely considered in the literature, are explored through a developed Subgraph Generation Algorithm (SGA) based on graph structure learning. As a result, a dependency graph with multiple subgraphs and their corresponding centres is generated. Thereafter, to reduce anomaly-irrelevant sensory data transmitted in the network, only sensory data upon subgraph centres are utilized for anomaly detection by a computational-light approach, i.e., a multi-layer perceptron based forecasting method. Once an anomaly is detected, sensory data of whole subgraph data are adopted for obtaining accurate anomaly results, by a graph attention based forecasting method. This GNN-based anomaly detection strategy with Mode Switching (GMS) can greatly reduce anomaly-irrelevant data transmission, especially when anomalies occur infrequently. To validate the effectiveness of our mechanism, extensive experiments are conducted upon real-world IoT multivariate time series datasets, and comparison results demonstrate that our technique outperforms the state-of-the-art counterparts in terms of accuracy and energy-efficiency. © 2023 Elsevier B.V.",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173188295&doi=10.1016%2fj.future.2023.09.028&partnerID=40&md5=0c47b5bcbdd9713b6cdd727855f4f198,Future Generation Computer Systems,Exclude,,,
Fan H.; Wang R.; Huang X.; Zhang F.; Li Z.; Su S.,Deep joint adversarial learning for anomaly detection on attribute networks,"Attribute network anomaly detection has attracted growing interest in recent years, which aims to separate the points whose behavior is clearly different from others. The complex interactions between the network structure and node attributes result in difficulty in detecting anomalous nodes on attribute networks. To alleviate the above mentioned issue, in this paper, we design a deep joint adversarial learning representation framework (JAANE) for attribute network anomaly detection, by capturing the consistency and complementarity between network structure and node attributes. Specifically, JAANE utilizes a weight-sharing encoder to learn the attribute embedding and structure embedding in a shared latent space. Then, the feature fusion module fuses the learned attribute embedding and structure embedding into the fused node embedding to capture the consistency and complementarity between them. Finally, the fused node embedding is regularized via adversarial learning, and the anomaly nodes outside the regularized hypersphere space can be effectively detected. The experiment results on the real-world datasets indicate that the proposed JAANE performs better than other state-of-the-art, which demonstrates the effectiveness of the proposed method. The source code and data are released in https://haoyfan.github.io/. © 2023 Elsevier Inc.",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176264000&doi=10.1016%2fj.ins.2023.119840&partnerID=40&md5=0aadcd6600b427298408eea3d9132ccc,Information Sciences,Exclude,,Exclude,
Li C.; Fu J.; Yan Y.; Zhao Z.; Zeng Q.,Higher order heterogeneous graph neural network based on node attribute enhancement,"Heterogeneous graph neural networks (HGNNs) have garnered significant attention owing to their ability to capture attribute information from heterogeneous graphs (HGs). However, practical scenarios involving HGs often suffer from missing node attributes. Furthermore, most existing HGNNs have limitations in exploiting node attributes. Specifically, they cannot entirely capture the attributes of higher order neighbors or only use the higher order homogeneous neighbors, thus disregarding the attributes of heterogeneous neighbors. To address these problems, we propose a higher order heterogeneous graph neural network based on heterogeneous node attribute enhancement (HOAE). We first design an attribute-completion strategy using an advanced transformer based self-attention mechanism to fill in the missing attributes. After that, we propose a simple and efficient attribute enhancement strategy based on heterogeneous attributes, empowering HOAE to fully learn the attributes of heterogeneous neighbors. Additionally, meta-path is incorporated to construct a higher order neighbor-based network, enabling effective learning of higher order attributes. Experimental results on three real world datasets demonstrate that HOAE significantly outperforms state-of-the-art methods. The source code of this work is available at https://github.com/FredJDean/HOAE. © 2023 Elsevier Ltd",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175571913&doi=10.1016%2fj.eswa.2023.122404&partnerID=40&md5=07be645deb6435f4234460c7c1cb672b,Expert Systems with Applications,Exclude,,,
Ye J.; Wei Y.; Wen X.-C.; Ma C.; Huang Z.; Liu K.; Shan H.,Emo-DNA: Emotion Decoupling and Alignment Learning for Cross-Corpus Speech Emotion Recognition,"Cross-corpus speech emotion recognition (SER) seeks to generalize the ability of inferring speech emotion from a well-labeled corpus to an unlabeled one, which is a rather challenging task due to the significant discrepancy between two corpora. Existing methods, typically based on unsupervised domain adaptation (UDA), struggle to learn corpus-invariant features by global distribution alignment, but unfortunately, the resulting features are mixed with corpus-specific features or not class-discriminative. To tackle these challenges, we propose a novel Emotion Decoupling aNd Alignment learning framework (EMO-DNA) for cross-corpus SER, a novel UDA method to learn emotion-relevant corpus-invariant features. The novelties of EMO-DNA are two-fold: contrastive emotion decoupling and dual-level emotion alignment. On one hand, our contrastive emotion decoupling achieves decoupling learning via a contrastive decoupling loss to strengthen the separability of emotion-relevant features from corpus-specific ones. On the other hand, our dual-level emotion alignment introduces an adaptive threshold pseudo-labeling to select confident target samples for class-level alignment, and performs corpus-level alignment to jointly guide model for learning class-discriminative corpus-invariant features across corpora. Extensive experimental results demonstrate the superior performance of EMO-DNA over the state-of-the-art methods in several cross-corpus scenarios. Source code is available at https://github.com/Jiaxin-Ye/Emo-DNA. © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179546767&doi=10.1145%2f3581783.3611704&partnerID=40&md5=bd0e286c31c9d133f18e3a81847432c1,MM 2023 - Proceedings of the 31st ACM International Conference on Multimedia,Exclude,,Exclude,
Ou W.; Ding S.H.H.; Tian Y.; Song L.,SCS-Gan: Learning Functionality-Agnostic Stylometric Representations for Source Code Authorship Verification,"In recent years, the number of anonymous script-based fileless malware attacks and software copyright disputes has increased rapidly. In the literature, automated Code Authorship Analysis (CAA) techniques have been proposed to reduce the manual effort in identifying those attacks and issues. Most CAA techniques aim to solve the task of Authorship Attribution (AA), i.e., identifying the actual author of a source code fragment from a given set of candidate authors. However, in many real-world scenarios, investigators do not have a predefined set of authors containing the actual author at the time of investigation, i.e., contradicting AA's assumption. Additionally, existing AA techniques ignore the influence of code functionality when identifying the authorship, which leads to biased matching simply based on code functionality. Different from AA, the task of (extreme) Authorship Verification (AV) is to decide if two texts were written by the same person or not. AV techniques do not need a predefined author set and thus could be applied in more code authorship-related applications than AA. To our knowledge, there is no previous work attempting to solve the AV problem for the source code. To fill the gap, we propose a novel adversarial neural network, namely SCS-Gan, that can learn a stylometric representation of code for automated AV. With the multi-head attention mechanism, SCS-Gan focuses on the code parts that are most informative regarding personal styles and generates functionality-agnostic stylometric representations through adversarial training. We benchmark SCS-Gan and two state-of-the-art code representation models on four out-of-sample datasets collected from a real-world programming competition. Our experiment results show that SCS-Gan outperforms the baselines on all four out-of-sample datasets.  © IEEE 1976-2012.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130812596&doi=10.1109%2fTSE.2022.3177228&partnerID=40&md5=2bd3b051420a8f0607a0bcb3b9489a81,IEEE Transactions on Software Engineering,Include,,,
do Rosario V.M.; da Silva A.F.; Zanella A.F.; Napoli O.O.; Borin E.,Fast selection of compiler optimizations using performance prediction with graph neural networks,"Tuning application performance on modern computing infrastructures involves choices in a vast design space as modern computing architectures can have several complex structures impacting performance. Moreover, different applications use these structures in different ways, leading to a challenging performance function. Consequently, it is hard for compilers or experts to find optimal compilation parameters for an application that maximizes such performance function. One approach to tackle this problem is to evaluate many possible optimization plans and select the best among them. However, executing an application to measure its performance for every plan can be very expensive. To tackle this problem, previous work has investigated the use of Machine Learning techniques to predict the performance of the applications without executing them quickly. In this work, we evaluate the use of graph neural networks (GNN) to make fast predictions without executing the application to guide the selection of good optimization sequences. We propose a GNN architecture to make such predictions. We train and test it using 30 thousand different compilation plans applied to 300 different applications, using ARM64 and LLVM IR code representations as input. Our results indicate that the control and data flow graph can then learn features from the control and data flow graph to outperform nongraph-aware Machine Learning models. Our GNN architecture achieved 91% accuracy in our dataset compared to 79% when using a nongraph-aware architecture–taking only 16ms to predict a given input. If the application been optimized took an average of 10 s to execute, and we evaluated 1000 optimization sequences, it would take almost 9 h to assess all pairs, but only 16 s with our GNN. © 2022 John Wiley & Sons Ltd.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126280581&doi=10.1002%2fcpe.6869&partnerID=40&md5=f8fab966abd61e95953dbe4237b61fb7,Concurrency and Computation: Practice and Experience,Include,,,
Mi Q.; Zhan Y.; Weng H.; Bao Q.; Cui L.; Ma W.,A graph-based code representation method to improve code readability classification,"Context: Code readability is crucial for developers since it is closely related to code maintenance and affects developers’ work efficiency. Code readability classification refers to the source code being classified as pre-defined certain levels according to its readability. So far, many code readability classification models have been proposed in existing studies, including deep learning networks that have achieved relatively high accuracy and good performance. Objective: However, in terms of representation, these methods lack effective preservation of the syntactic and semantic structure of the source code. To extract these features, we propose a graph-based code representation method. Method: Firstly, the source code is parsed into a graph containing its abstract syntax tree (AST) combined with control and data flow edges to reserve the semantic structural information and then we convert the graph nodes’ source code and type information into vectors. Finally, we train our graph neural networks model composing Graph Convolutional Network (GCN), DMoNPooling, and K-dimensional Graph Neural Networks (k-GNNs) layers to extract these features from the program graph. Result: We evaluate our approach to the task of code readability classification using a Java dataset provided by Scalabrino et al. (2016). The results show that our method achieves 72.5% and 88% in three-class and two-class classification accuracy, respectively. Conclusion: We are the first to introduce graph-based representation into code readability classification. Our method outperforms state-of-the-art readability models, which suggests that the graph-based code representation method is effective in extracting syntactic and semantic information from source code, and ultimately improves code readability classification. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160003449&doi=10.1007%2fs10664-023-10319-6&partnerID=40&md5=123f5324dfc79038a0d3244e8c791cab,Empirical Software Engineering,Include,,Include,
Dong Y.; Wang S.; Ma J.; Liu N.; Li J.,Interpreting Unfairness in Graph Neural Networks via Training Node Attribution,"Graph Neural Networks (GNNs) have emerged as the leading paradigm for solving graph analytical problems in various real-world applications. Nevertheless, GNNs could potentially render biased predictions towards certain demographic subgroups. Understanding how the bias in predictions arises is critical, as it guides the design of GNN debiasing mechanisms. However, most existing works overwhelmingly focus on GNN debiasing, but fall short on explaining how such bias is induced. In this paper, we study a novel problem of interpreting GNN unfairness through attributing it to the influence of training nodes. Specifically, we propose a novel strategy named Probabilistic Distribution Disparity (PDD) to measure the bias exhibited in GNNs, and develop an algorithm to efficiently estimate the influence of each training node on such bias. We verify the validity of PDD and the effectiveness of influence estimation through experiments on real-world datasets. Finally, we also demonstrate how the proposed framework could be used for debiasing GNNs. Open-source code can be found at https://github.com/yushundong/BIND. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146321881&partnerID=40&md5=193adf8a1498f438c4a32e44e5b25269,"Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",Exclude,,,
Yoon K.; Kim K.; Moon J.; Park C.,Unbiased Heterogeneous Scene Graph Generation with Relation-Aware Message Passing Neural Network,"Recent scene graph generation (SGG) frameworks have focused on learning complex relationships among multiple objects in an image. Thanks to the nature of the message passing neural network (MPNN) that models high-order interactions between objects and their neighboring objects, they are dominant representation learning modules for SGG. However, existing MPNN-based frameworks assume the scene graph as a homogeneous graph, which restricts the contextawareness of visual relations between objects. That is, they overlook the fact that the relations tend to be highly dependent on the objects with which the relations are associated. In this paper, we propose an unbiased heterogeneous scene graph generation (HetSGG) framework that captures relation-aware context using message passing neural networks. We devise a novel message passing layer, called relation-aware message passing neural network (RMP), that aggregates the contextual information of an image considering the predicate type between objects. Our extensive evaluations demonstrate that HetSGG outperforms state-of-the-art methods, especially outperforming on tail predicate classes. The source code for HetSGG is available at https://github. com/KanghoonYoon/hetsgg-torch.  Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167971037&partnerID=40&md5=e5a5a02b80a47cf310f6758f9eebc3a9,"Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",Exclude,,,
Liu L.; Yang Z.; Li G.; Wang K.; Chen T.; Lin L.,Aerial Images Meet Crowdsourced Trajectories: A New Approach to Robust Road Extraction,"Land remote-sensing analysis is a crucial research in earth science. In this work, we focus on a challenging task of land analysis, i.e., automatic extraction of traffic roads from remote-sensing data, which has widespread applications in urban development and expansion estimation. Nevertheless, conventional methods either only utilized the limited information of aerial images, or simply fused multimodal information (e.g., vehicle trajectories), thus cannot well recognize unconstrained roads. To facilitate this problem, we introduce a novel neural network framework termed cross-modal message propagation network (CMMPNet), which fully benefits the complementary different modal data (i.e., aerial images and crowdsourced trajectories). Specifically, CMMPNet is composed of two deep autoencoders for modality-specific representation learning and a tailor-designed dual enhancement module for cross-modal representation refinement. In particular, the complementary information of each modality is comprehensively extracted and dynamically propagated to enhance the representation of another modality. Extensive experiments on three real-world benchmarks demonstrate the effectiveness of our CMMPNet for robust road extraction benefiting from blending different modal data, either using image and trajectory data or image and light detection and ranging (LiDAR) data. From the experimental results, we observe that the proposed approach outperforms current state-of-the-art methods by large margins. Our source code is resealed on the project page http://lingboliu.com/multimodal_road_extraction.html. © 2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124088570&doi=10.1109%2fTNNLS.2022.3141821&partnerID=40&md5=8f0d0185880d6c09a3c871859c719b4c,IEEE Transactions on Neural Networks and Learning Systems,Exclude,,Exclude,
Asadi M.; Swamy V.; Frej J.; Vignoud J.; Marras M.; Käser T.,Ripple: Concept-Based Interpretation for Raw Time Series Models in Education,"Time series is the most prevalent form of input data for educational prediction tasks. The vast majority of research using time series data focuses on hand-crafted features, designed by experts for predictive performance and interpretability. However, extracting these features is labor-intensive for humans and computers. In this paper, we propose an approach that utilizes irregular multivariate time series modeling with graph neural networks to achieve comparable or better accuracy with raw time series clickstreams in comparison to handcrafted features. Furthermore, we extend concept activation vectors for interpretability in raw time series models. We analyze these advances in the education domain, addressing the task of early student performance prediction for downstream targeted interventions and instructional support. Our experimental analysis on 23 MOOCs with millions of combined interactions over six behavioral dimensions show that models designed with our approach can (i) beat state-of-the-art educational time series baselines with no feature extraction and (ii) provide interpretable insights for personalized interventions. Source code: https://github.com/epfl-ml4ed/ripple/. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165559781&partnerID=40&md5=877d19dc369a811deebaf9f3ed418850,"Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",Exclude,,Exclude,
Tam D.S.H.; Liu Y.; Xu H.; Xie S.; Lau W.C.,PERT-GNN: Latency Prediction for Microservice-based Cloud-Native Applications via Graph Neural Networks,"Cloud-native applications using microservice architectures are rapidly replacing traditional monolithic applications. To meet end-to-end QoS guarantees and enhance user experience, each component microservice must be provisioned with sufficient resources to handle incoming API calls. Accurately predicting the latency of microservices-based applications is critical for optimizing resource allocation, which turns out to be extremely challenging due to the complex dependencies between microservices and the inherent stochasticity. To tackle this problem, various predictors have been designed based on the Microservice Call Graph. However, Microservice Call Graphs do not take into account the API-specific information, cannot capture important temporal dependencies, and cannot scale to large-scale applications. In this paper, we propose PERT-GNN, a generic graph neural network based framework to predict the end-to-end latency for microservice applications. PERT-GNN characterizes the interactions or dependency of component microservices observed from prior execution traces of the application using the Program Evaluation and Review Technique (PERT). We then construct a graph neural network based on the generated PERT Graphs, and formulate the latency prediction task as a supervised graph regression problem using the graph transformer method. PERT-GNN can capture the complex temporal causality of different microservice traces, thereby producing more accurate latency predictions for various applications. Evaluations based on datasets generated from common benchmarks and large-scale Alibaba microservice traces show that PERT-GNN can outperform other models by a large margin. In particular, PERT-GNN is able to predict the latency of microservice applications with less than 12% mean absolute percentage error.  © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171364400&doi=10.1145%2f3580305.3599465&partnerID=40&md5=9bd0da39263358013adaa5b493881bd7,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Exclude,,,
Wang X.; Dong Y.; Jin D.; Li Y.; Wang L.; Dang J.,Augmenting Affective Dependency Graph via Iterative Incongruity Graph Learning for Sarcasm Detection,"Recently, progress has been made towards improving automatic sarcasm detection in computer science. Among existing models, manually constructing static graphs for texts and then using graph neural networks (GNNs) is one of the most effective approaches for drawing long-range incongruity patterns. However, the manually constructed graph structure might be prone to errors (e.g., noisy or incomplete) and not optimal for the sarcasm detection task. Errors produced during the graph construction step cannot be remedied and may accrue to the following stages, resulting in poor performance. To surmount the above limitations, we explore a novel Iterative Augmenting Affective Graph and Dependency Graph (IAAD) framework to jointly and iteratively learn the incongruity graph structure. IAAD can alternatively update the incongruity graph structure and node representation until the learning graph structure is optimal for the metrics of sarcasm detection. More concretely, we begin with deriving an affective and a dependency graph for each instance, then an iterative incongruity graph learning module is employed to augment affective and dependency graphs for obtaining the optimal inconsistent semantic graph with the goal of optimizing the graph for the sarcasm detection task. Extensive experiments on three datasets demonstrate that the proposed model outperforms state-of-the-art baselines for sarcasm detection with significant margins. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167866325&partnerID=40&md5=50e994a8665cc44b48421a06c2d230a0,"Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",Exclude,,,
Wang C.-Y.; Yeh I.-H.; Liao H.-Y.M.,You Only Learn One Representation: Unified Network for Multiple Tasks,"People “understand” the world via vision, hearing, tactile, and also the past experience. Human experience can be learned through normal learning (we call it explicit knowledge), or subconsciously (we call it implicit knowledge). These experiences learned through normal learning or subconsciously will be encoded and stored in the brain. Using these abundant experience, as a huge database, human beings can effectively process data, even they were unseen beforehand. In this paper, we propose a unified network to encode implicit knowledge and explicit knowledge together, just like the human brain can learn knowledge from normal learning as well as subconsciousness learning. The unified network can generate a unified representation to simultaneously serve various tasks. We can perform kernel space alignment, prediction refinement, and multi-task learning in a convolutional neural network. The results demonstrate that when implicit knowledge is introduced into the neural network, it benefits the performance of all tasks. We further analyze the implicit representation learnt from the proposed unified network, and it shows great capability on catching the physical meaning of different tasks. The source code of this work is at: https://github.com/WongKinYiu/yolor. © 2023 Institute of Information Science. All rights reserved.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160528774&doi=10.6688%2fJISE.202305_39%283%29.0015&partnerID=40&md5=1b096d6f801c63de222014d41cc74416,Journal of Information Science and Engineering,Exclude,,,
Yin J.; Shen J.; Gao X.; Crandall D.J.; Yang R.,Graph Neural Network and Spatiotemporal Transformer Attention for 3D Video Object Detection From Point Clouds,"Previous works for LiDAR-based 3D object detection mainly focus on the single-frame paradigm. In this paper, we propose to detect 3D objects by exploiting temporal information in multiple frames, i.e., point cloud videos. We empirically categorize the temporal information into short-term and long-term patterns. To encode the short-term data, we present a Grid Message Passing Network (GMPNet), which considers each grid (i.e., the grouped points) as a node and constructs a k k-NN graph with the neighbor grids. To update features for a grid, GMPNet iteratively collects information from its neighbors, thus mining the motion cues in grids from nearby frames. To further aggregate long-term frames, we propose an Attentive Spatiotemporal Transformer GRU (AST-GRU), which contains a Spatial Transformer Attention (STA) module and a Temporal Transformer Attention (TTA) module. STA and TTA enhance the vanilla GRU to focus on small objects and better align moving objects. Our overall framework supports both online and offline video object detection in point clouds. We implement our algorithm based on prevalent anchor-based and anchor-free detectors. Evaluation results on the challenging nuScenes benchmark show superior performance of our method, achieving first on the leaderboard (at the time of paper submission) without any 'bells and whistles.' Our source code is available at https://github.com/shenjianbing/GMP3D.  © 1979-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164223698&doi=10.1109%2fTPAMI.2021.3125981&partnerID=40&md5=169467f521c2fc27d675c1d2ea094f9f,IEEE Transactions on Pattern Analysis and Machine Intelligence,Exclude,,,
Cui B.; Ma K.; Li L.; Zhang W.; Ji K.; Chen Z.; Abraham A.,Intra-graph and Inter-graph joint information propagation network with third-order text graph tensor for fake news detection,"Although the Internet and social media provide people with a range of opportunities and benefits in a variety of ways, the proliferation of fake news has negatively affected society and individuals. Many efforts have been invested to detect the fake news. However, to learn the representation of fake news by context information, it has brought many challenges for fake news detection due to the feature sparsity and ineffectively capturing the non-consecutive and long-range context. In this paper, we have proposed Intra-graph and Inter-graph Joint Information Propagation Network (abbreviated as IIJIPN) with Third-order Text Graph Tensor for fake news detection. Specifically, data augmentation is firstly utilized to solve the data imbalance and strengthen the small corpus. In the stage of feature extraction, Third-order Text Graph Tensor with sequential, syntactic, and semantic features is proposed to describe contextual information at different language properties. After constructing the text graphs for each text feature, Intra-graph and Inter-graph Joint Information Propagation is used for encoding the text: intra-graph information propagation is performed in each graph to realize homogeneous information interaction, and high-order homogeneous information interaction in each graph can be achieved by stacking propagation layer; inter-graph information propagation is performed among text graphs to realize heterogeneous information interaction by connecting the nodes across the graphs. Finally, news representations are generated by attention mechanism consisting of graph-level attention and node-level attention mechanism, and then news representations are fed into a fake news classifier. The experimental results on four public datasets indicate that our model has outperformed state-of-the-art methods. Our source code is available at https://github.com/cuibenkuan/IIJIPN. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148077946&doi=10.1007%2fs10489-023-04455-1&partnerID=40&md5=108274c98e6d336874e31168e6c60bac,Applied Intelligence,Exclude,,,
Pian W.; Peng H.; Tang X.; Sun T.; Tian H.; Habib A.; Klein J.; Bissyandé T.F.,MetaTPTrans: A Meta Learning Approach for Multilingual Code Representation Learning,"Representation learning of source code is essential for applying machine learning to software engineering tasks. Learning code representation from a multilingual source code dataset has been shown to be more effective than learning from single-language datasets separately, since more training data from multilingual dataset improves the model’s ability to extract language-agnostic information from source code. However, existing multilingual training overlooks the language-specific information which is crucial for modeling source code across different programming languages, while only focusing on learning a unified model with shared parameters among different languages for language-agnostic information modeling. To address this problem, we propose MetaTPTrans, a meta learning approach for multilingual code representation learning. MetaTPTrans generates different parameters for the feature extractor according to the specific programming language type of the input code snippet, enabling the model to learn both language-agnostic and language-specific information with dynamic parameters in the feature extractor. We conduct experiments on the code summarization and code completion tasks to verify the effectiveness of our approach. The results demonstrate the superiority of our approach with significant improvements on state-of-the-art baselines. p g . Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167864360&partnerID=40&md5=1daa985a31f853e55cc239b7c4f9cdc2,"Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",Include,,Include,
Qin G.; Song L.; Yu Y.; Huang C.; Jia W.; Cao Y.; Dong J.,Graph Structure Learning on User Mobility Data for Social Relationship Inference,"With the prevalence of smart mobile devices and location-based services, uncovering social relationships from human mobility data is of great value in real-world spatio-temporal applications ranging from friend recommendation, advertisement targeting to transportation scheduling. While a handful of sophisticated graph embedding techniques are developed for social relationship inference, they are significantly limited to the sparse and noisy nature of user mobility data, as they all ignore the essential problem of the existence of a large amount of noisy data unrelated to social activities in such mobility data. In this work, we present Social Relationship Inference Network (SRINet), a novel Graph Neural Network (GNN) framework, to improve inference performance by learning to remove noisy data. Specifically, we first construct a multiplex user meeting graph to model the spatial-temporal interactions among users in different semantic contexts. Our proposed SRINet tactfully combines the representation learning ability of Graph Convolutional Networks (GCNs) with the power of removing noisy edges of graph structure learning, which can learn effective user embeddings on the multiplex user meeting graph in a semi-supervised manner. Extensive experiments on three real-world datasets demonstrate the superiority of SRINet against state-of-the-art techniques in inferring social relationships from user mobility data. The source code of our method is available at https://github.com/qinguangming1999/SRINet. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167870009&partnerID=40&md5=6528809e071c8700d25f7fb5a7bef6ab,"Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",Exclude,,,
Dutta A.; Alcaraz J.; Tehranijamsaz A.; Cesar E.; Sikora A.; Jannesari A.,Performance Optimization using Multimodal Modeling and Heterogeneous GNN,"Growing heterogeneity and configurability in HPC architectures has made auto-tuning applications and runtime parameters on these systems very complex. Users are presented with a multitude of options to configure parameters. In addition to application specific solutions, a common approach is to use general purpose search strategies, which often might not identify the best configurations or their time to convergence is a significant barrier. There is, thus, a need for a general purpose and efficient tuning approach that can be easily scaled and adapted to various tuning tasks. We propose a technique for tuning parallel code regions that is general enough to be adapted to multiple tasks. In this paper, we analyze IR-based programming models to make task-specific performance optimizations. To this end, we propose the Multimodal Graph Neural Network and Autoencoder (MGA) tuner, a multimodal deep learning based approach that adapts Heterogeneous Graph Neural Networks and Denoising Autoencoders for modeling IR-based code representations that serve as separate modalities. This approach is used as part of our pipeline to model a syntax, semantics, and structure-aware IR-based code representation for tuning parallel code regions/kernels. We extensively experiment on OpenMP and OpenCL code regions/kernels obtained from PolyBench, Rodinia, STREAM, DataRaceBench, AMD SDK, NPB, NVIDIA SDK, Parboil, SHOC, LULESH, XSBench, RSBench, miniFE, miniAMR, and Quicksilver benchmarks and applications. We apply our multimodal learning techniques to the tasks of (i) optimizing the number of threads, scheduling policy and chunk size in OpenMP loops and, (ii) identifying the best device for heterogeneous device mapping of OpenCL kernels. Our experiments show that this multimodal learning based approach outperforms the state-of-the-art in almost all experiments.  © 2023 Owner/Author.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169596772&doi=10.1145%2f3588195.3592984&partnerID=40&md5=8541d5da24bd5e4f2d9ac83d29a5b658,HPDC 2023 - Proceedings of the 32nd International Symposium on High-Performance Parallel and Distributed Computing,Include,Exclude,Exclude,
Li X.; Guo R.; Lu J.; Chen T.; Qian X.,Causality-Driven Graph Neural Network for Early Diagnosis of Pancreatic Cancer in Non-Contrast Computerized Tomography,"Pancreatic cancer is the emperor of all cancer maladies, mainly because there are no characteristic symptoms in the early stages, resulting in the absence of effective screening and early diagnosis methods in clinical practice. Non-contrast computerized tomography (CT) is widely used in routine check-ups and clinical examinations. Therefore, based on the accessibility of non-contrast CT, an automated early diagnosismethod for pancreatic cancer is proposed. Among this, we develop a novel causalitydriven graph neural network to solve the challenges of stability and generalization of early diagnosis, that is, the proposed method achieves stable performance for datasets from different hospitals, which highlights its clinical significance. Specifically, a multiple-instance-learning framework is designed to extract fine-grained pancreatic tumor features. Afterwards, to ensure the integrity and stability of the tumor features, we construct an adaptivemetric graph neural network that effectively encodes prior relationships of spatial proximity and feature similarity for multiple instances, and hence adaptively fuses the tumor features. Besides, a causal contrastivemechanism is developed to decouple the causality-driven and non-causal components of the discriminative features, suppress the non-causal ones, and hence improve the model stability and generalization. Extensive experiments demonstrated that the proposed method achieved the promising early diagnosis performance, and its stability and generalizability were independently verified on amulti-center dataset. Thus, the proposed method provides a valuable clinical tool for the early diagnosis of pancreatic cancer. Our source codes will be released at https://github.com/SJTUBME-QianLab/ CGNN-PC-Early-Diagnosis.  © 1982-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147220078&doi=10.1109%2fTMI.2023.3236162&partnerID=40&md5=5e477410807fe4728822d3d27bb3f063,IEEE Transactions on Medical Imaging,Exclude,,,
Ding Z.; Li H.; Shang W.; Chen T.-H.P.,Towards Learning Generalizable Code Embeddings Using Task-agnostic Graph Convolutional Networks,"Code embeddings have seen increasing applications in software engineering (SE) research and practice recently. Despite the advances in embedding techniques applied in SE research, one of the main challenges is their generalizability. A recent study finds that code embeddings may not be readily leveraged for the downstream tasks that the embeddings are not particularly trained for. Therefore, in this article, we propose GraphCodeVec, which represents the source code as graphs and leverages the Graph Convolutional Networks to learn more generalizable code embeddings in a task-agnostic manner. The edges in the graph representation are automatically constructed from the paths in the abstract syntax trees, and the nodes from the tokens in the source code. To evaluate the effectiveness of GraphCodeVec , we consider three downstream benchmark tasks (i.e., code comment generation, code authorship identification, and code clones detection) that are used in a prior benchmarking of code embeddings and add three new downstream tasks (i.e., source code classification, logging statements prediction, and software defect prediction), resulting in a total of six downstream tasks that are considered in our evaluation. For each downstream task, we apply the embeddings learned by GraphCodeVec and the embeddings learned from four baseline approaches and compare their respective performance. We find that GraphCodeVec outperforms all the baselines in five out of the six downstream tasks, and its performance is relatively stable across different tasks and datasets. In addition, we perform ablation experiments to understand the impacts of the training context (i.e., the graph context extracted from the abstract syntax trees) and the training model (i.e., the Graph Convolutional Networks) on the effectiveness of the generated embeddings. The results show that both the graph context and the Graph Convolutional Networks can benefit GraphCodeVec in producing high-quality embeddings for the downstream tasks, while the improvement by Graph Convolutional Networks is more robust across different downstream tasks and datasets. Our findings suggest that future research and practice may consider using graph-based deep learning methods to capture the structural information of the source code for SE tasks.  © 2023 Association for Computing Machinery.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153731394&doi=10.1145%2f3542944&partnerID=40&md5=5579536a2ca56d11845228acae273057,ACM Transactions on Software Engineering and Methodology,Include,,,
Li G.; Muller M.; Qian G.; Delgadillo I.C.; Abualshour A.; Thabet A.; Ghanem B.,DeepGCNs: Making GCNs Go as Deep as CNNs,"Convolutional neural networks (CNNs) have been very successful at solving a variety of computer vision tasks such as object classification and detection, semantic segmentation, activity understanding, to name just a few. One key enabling factor for their great performance has been the ability to train very deep networks. Despite their huge success in many tasks, CNNs do not work well with non-euclidean data, which is prevalent in many real-world applications. Graph Convolutional Networks (GCNs) offer an alternative that allows for non-Eucledian data input to a neural network. While GCNs already achieve encouraging results, they are currently limited to architectures with a relatively small number of layers, primarily due to vanishing gradients during training. This work transfers concepts such as residual/dense connections and dilated convolutions from CNNs to GCNs in order to successfully train very deep GCNs. We show the benefit of using deep GCNs (with as many as 112 layers) experimentally across various datasets and tasks. Specifically, we achieve very promising performance in part segmentation and semantic segmentation on point clouds and in node classification of protein functions across biological protein-protein interaction (PPI) graphs. We believe that the insights in this work will open avenues for future research on GCNs and their application to further tasks not explored in this paper. The source code for this work is available at https://github.com/lightaime/deep_gcns_torch and https://github.com/lightaime/deep_gcns for PyTorch and TensorFlow implementations respectively.  © 1979-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104604591&doi=10.1109%2fTPAMI.2021.3074057&partnerID=40&md5=3c456beac87d0e2239559826f29e4d00,IEEE Transactions on Pattern Analysis and Machine Intelligence,Exclude,,,
Salahian N.; Tab F.A.; Seyedi S.A.; Chavoshinejad J.,Deep Autoencoder-like NMF with Contrastive Regularization and Feature Relationship Preservation,"Nonnegative Matrix Factorization is a data analysis method to discover parts-based, linear representations of data. It has been successfully used in a great variety of applications. Deep Nonnegative Matrix Factorization (deep NMF) was recently established to cope with the extraction of hierarchical latent feature representation, and it has been demonstrated to achieve outstanding results in unsupervised representation learning. However, defining a suitable regularization for the deep models is a key challenge, and the existing Deep NMF approaches lack a well-suited regularization. In this paper, we propose the Deep Autoencoder-like NMF with Contrastive Regularization and Feature Relationship preservation (DANMF-CRFR) to address the above problem. Inspired by contrastive learning, this deep model is able to learn discriminative and instructive deep features while adequately enforcing the local and global structures of the data to its decoder and encoder components. Meanwhile, DANMF-CRFR also imposes feature correlations on the basis matrices during feature learning to improve part-based learning capabilities. Multiplicative updating rules and convergence guarantees are also provided. Extensive experimental results demonstrate the advantages of the proposed model. The source code for reproducing our results can be found at https://github.com/NavidSalahian/DANMF_CRFR. © 2022 Elsevier Ltd",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142439701&doi=10.1016%2fj.eswa.2022.119051&partnerID=40&md5=4956c0f1f8cb0bf4d16532b2343c029e,Expert Systems with Applications,Exclude,,,
Zhang Z.; Lei Y.; Mao X.; Yan M.; Xia X.; Lo D.,Context-Aware Neural Fault Localization,"Numerous fault localization techniques identify suspicious statements potentially responsible for program failures by discovering the statistical correlation between test results (i.e., failing or passing) and the executions of the different statements of a program (i.e., covered or not covered). They rarely incorporate a failure context into their suspiciousness evaluation despite the fact that a failure context showing how a failure is produced is useful for analyzing and locating faults. Since a failure context usually contains the transitive relationships among the statements of causing a failure, its relationship complexity becomes one major obstacle for the context incorporation in suspiciousness evaluation of fault localization. To overcome the obstacle, our insight is that leveraging the promising learning ability may be a candidate solution to learn a feasible model for incorporating a failure context into fault localization. Thus, we propose a context-aware neural fault localization approach (CAN). Specifically, CAN represents the failure context by constructing a program dependency graph, which shows how a set of statements interact with each other (i.e., data and control dependencies) to cause a failure. Then, CAN utilizes graph neural networks to analyze and incorporate the context (e.g., the dependencies among the statements) into suspiciousness evaluation. Our empirical results on the 12 large-sized programs show that CAN achieves promising results (e.g., 29.23% faults are ranked within top 5), and it significantly improves the state-of-the-art baselines with a substantial margin.  © 1976-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161081310&doi=10.1109%2fTSE.2023.3279125&partnerID=40&md5=0d45c583f7c58af9023ec05c2b6ae585,IEEE Transactions on Software Engineering,Include,,,
Sriramulu A.; Fourrier N.; Bergmeir C.,Adaptive dependency learning graph neural networks,"Graph Neural Networks (GNN) have recently gained popularity in the forecasting domain due to their ability to model complex spatial and temporal patterns in tasks such as traffic forecasting and region-based demand forecasting. Most of these methods require a predefined graph as input, whereas in real-life multivariate time series problems, a well-predefined dependency graph rarely exists. This requirement makes it harder for GNNs to be utilised widely for multivariate forecasting problems in other domains such as retail or energy. In this paper, we propose a hybrid approach combining neural networks and statistical structure learning models to self-learn the dependencies and construct a dynamically changing dependency graph from multivariate data aiming to enable the use of GNNs for multivariate forecasting even when a well-defined graph does not exist. The statistical structure modeling in conjunction with neural networks provides a well-principled and efficient approach by bringing in causal semantics to determine dependencies among the series. Finally, we demonstrate significantly improved performance using our proposed approach on real-world benchmark datasets without a pre-defined dependency graph. © 2023 Elsevier Inc.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146595559&doi=10.1016%2fj.ins.2022.12.086&partnerID=40&md5=7dc4e3cb8c0e80c95e1b64e1cebe3174,Information Sciences,Exclude,,,
Chhipa P.C.; Chopra M.; Mengi G.; Gupta V.; Upadhyay R.; Chippa M.S.; De K.; Saini R.; Uchida S.; Liwicki M.,Functional Knowledge Transfer with Self-supervised Representation Learning,"This work investigates the unexplored usability of self-supervised representation learning in the direction of functional knowledge transfer. In this work, functional knowledge transfer is achieved by joint optimization of self-supervised learning pseudo task and supervised learning task, improving supervised learning task performance. Recent progress in self-supervised learning uses a large volume of data, which becomes a constraint for its applications on small-scale datasets. This work shares a simple yet effective joint training framework that reinforces human-supervised task learning by learning self-supervised representations just-in-time and vice versa. Experiments on three public datasets from different visual domains, Intel Image, CIFAR, and APTOS, reveal a consistent track of performance improvements on classification tasks during joint optimization. Qualitative analysis also supports the robustness of learnt representations. Source code and trained models are available on GitHub1 © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180766253&doi=10.1109%2fICIP49359.2023.10222142&partnerID=40&md5=102148252be25a13c0682bccc50f8bd9,"Proceedings - International Conference on Image Processing, ICIP",Exclude,,,
Shen C.; Zhang J.; Liang X.; Hao Z.; Li K.; Wang F.; Wang Z.; Lian C.,Forensic Histopathological Recognition via a Context-Aware MIL Network Powered by Self-supervised Contrastive Learning,"Forensic pathology is critical in analyzing death manner and time from the microscopic aspect to assist in the establishment of reliable factual bases for criminal investigation. In practice, even the manual differentiation between different postmortem organ tissues is challenging and relies on expertise, considering that changes like putrefaction and autolysis could significantly change typical histopathological appearance. Developing AI-based computational pathology techniques to assist forensic pathologists is practically meaningful, which requires reliable discriminative representation learning to capture tissues’ fine-grained postmortem patterns. To this end, we propose a framework called FPath, in which a dedicated self-supervised contrastive learning strategy and a context-aware multiple-instance learning (MIL) block are designed to learn discriminative representations from postmortem histopathological images acquired at varying magnification scales. Our self-supervised learning step leverages multiple complementary contrastive losses and regularization terms to train a double-tier backbone for fine-grained and informative patch/instance embedding. Thereafter, the context-aware MIL adaptively distills from the local instances a holistic bag/image-level representation for the recognition task. On a large-scale database of 19, 607 experimental rat postmortem images and 3, 378 real-world human decedent images, our FPath led to state-of-the-art accuracy and promising cross-domain generalization in recognizing seven different postmortem tissues. The source code will be released on https://github.com/ladderlab-xjtu/forensic_pathology. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174722536&doi=10.1007%2f978-3-031-43987-2_51&partnerID=40&md5=3f1c637183ce251a4a27601e9e60b4ea,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,Exclude,
Dong Z.; Hu Q.; Zhang Z.; Zhao J.,On the Effectiveness of Graph Data Augmentation for Source Code Learning,"The methodology that uses deep learning to solve software engineering tasks, such as bug detection, is known as source code learning. Due to the graph nature of source code, graph learning, empowered by graph neural networks (GNNs), has been increasingly adopted for source code learning. Like other deep learning contexts, source code learning also relies on massive high-quality training data, and the shortage of such data has become the main performance bottleneck. In practice, data augmentation is often used as a countermeasure to mitigate this issue, by synthesizing additional training data based on existing ones. However, most existing practice of data augmentation in source code learning limits simple code refactoring methods and is not sufficiently effective. In this work, in light of the graph nature of source code, we propose to apply the data augmentation methods used for graph-structured data in graph learning to the tasks of source code learning, and we conduct a comprehensive empirical study to evaluate whether such new ways of data augmentation are more effective than the existing simple code refactoring methods. Specifically, we evaluate 4 critical software engineering tasks and 7 neural network architectures to assess the effectiveness of 5 data augmentation methods. Experimental results identify that, compared to other methods, Manifold-Mixup can greatly improve the accuracy of the trained models for source code learning.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179522132&doi=10.1109%2fDSA59317.2023.00124&partnerID=40&md5=86fc4890726e94127df716a7a57d61d1,"Proceedings - 2023 10th International Conference on Dependable Systems and Their Applications, DSA 2023",Include,,,
Pan W.; Ming H.; Kim D.-K.; Yang Z.,Pride: Prioritizing Documentation Effort Based on a PageRank-Like Algorithm and Simple Filtering Rules,"Code documentation can be helpful in many software quality assurance tasks. However, due to resource constraints (e.g., time, human resources, and budget), programmers often cannot document their work completely and timely. In the literature, two approaches (one is supervised and the other is unsupervised) have been proposed to prioritize documentation effort to ensure the most important classes to be documented first. However, both of them contain several limitations. The supervised approach overly relies on a difficult-to-obtain labeled data set and has high computation cost. The unsupervised one depends on a graph representation of the software structure, which is inaccurate since it neglects many important couplings between classes. In this paper, we propose an improved approach, named Pride, to prioritize documentation effort. First, Pride uses a weighted directed class coupling network to precisely describe classes and their couplings. Second, we propose a PageRank-like algorithm to quantify the importance of classes in the whole class coupling network. Third, we use a set of software metrics to quantify source code complexity and further propose a simple but easy-to-operate filtering rule. Fourth, we sort all the classes according to their importance in descending order and use the filtering rule to filter out unimportant classes. Finally, a threshold kk is utilized, and the top-kk% ranked classes are the identified important classes to be documented first. Empirical results on a set of nine software systems show that, according to the average ranking of the Friedman test, Pride is superior to the existing approaches in the whole data set.  © 2022 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129670613&doi=10.1109%2fTSE.2022.3171469&partnerID=40&md5=346cf30e57b601387a769a9b0f781a8d,IEEE Transactions on Software Engineering,Include,,,
Yuan B.; Xu L.,DoreBer: Document-Level Relation Extraction Method Based on BernNet,"Document-level relation extraction (RE) task aims to predict predefined relation types of every entity pair in a given document. Compared with the sentence-level counterpart, document-level relation extraction task requires reasoning in a more complex environment, where exist much longer text and much larger amount of entities, making it a more challenging task. However, previous methods suffers from over-smoothing problem when the count of GNN layers is high enough, leading high frequency signals on graph could not pass through filter, and then resulting in an insufficient approximation of the real function and finally causing a defective performance in tasks. To solve this problem, we propose a novel model, called DoreBer, for document-level RE task, which can obtain a higher quality of graph representation. Specifically, DoreBer performs estimation of filter over the normalized Laplacian spectrum of a graph by leveraging an order-K Bernstein polynomial approximation, and designs its spectral property by setting the coefficients of the Bernstein basis. Therefore, DoreBer can alleviate the over-smoothing problem to enhance learning ability of model. In addition, DoreBer has a higher interpretability for learned parameters of graph filter. We evaluate DoreBer on the DocRED public document-level RE dataset. Online experimental results demonstrate that DoreBer achieves significant performance improvements (2.72 and 2.76 higher on Ign F-1 and F-1 respectively), over the previous state-of-The-Art on sequence-based method baseline. DoreBer reveals the potential of BernNet method in document-level relation extraction tasks and sheds light on a path to learn potential representation in high-dimensional data.The source code of this paper can be obtained from https://github.com/factor77/DoreBer/.  © 2013 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179581947&doi=10.1109%2fACCESS.2023.3337871&partnerID=40&md5=7582c8057b2e8e6462792bd95e7ea4fa,IEEE Access,Exclude,,,
Deangeli D.; Iarussi E.; Princich J.P.; Bendersky M.; Larrabide I.; Orlando J.I.,Learning Normal Asymmetry Representations for Homologous Brain Structures,"Although normal homologous brain structures are approximately symmetrical by definition, they also have shape differences due to e.g. natural ageing. On the other hand, neurodegenerative conditions induce their own changes in this asymmetry, making them more pronounced or altering their location. Identifying when these alterations are due to a pathological deterioration is still challenging. Current clinical tools rely either on subjective evaluations, basic volume measurements or disease-specific deep learning models. This paper introduces a novel method to learn normal asymmetry patterns in homologous brain structures based on anomaly detection and representation learning. Our framework uses a Siamese architecture to map 3D segmentations of left and right hemispherical sides of a brain structure to a normal asymmetry embedding space, learned using a support vector data description objective. Being trained using healthy samples only, it can quantify deviations-from-normal-asymmetry patterns in unseen samples by measuring the distance of their embeddings to the center of the learned normal space. We demonstrate in public and in-house sets that our method can accurately characterize normal asymmetries and detect pathological alterations due to Alzheimer’s disease and hippocampal sclerosis, even though no diseased cases were accessed for training. Our source code is available at https://github.com/duiliod/DeepNORHA. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174742775&doi=10.1007%2f978-3-031-43993-3_8&partnerID=40&md5=078d42445fe55743302e024a8243d54b,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Cheng H.; Li Q.; Cui Z.; Liu S.; Pan L.,Dynamic Communications Network Linking Prediction by Disseminating Event Embedding,"Communication networks represent communication between entities like social networks and microservice call graphs of microservice systems. Link prediction is useful in various communication network service systems such as predicting the relation between two services. Continuous-time dynamic graph (CTDG) is one form of representing temporal information in communication networks that treats them as a set of events occurring over time. Dynamic graph embedding for CTDG handles these events and disseminates event information to other nodes to get node embedding. Though dynamic graph embedding is suitable for making link prediction in communication networks, graph embedding for CTDG faces challenges such as how to model the event information dissemination process including information decaying over distance and influence of time information. To cope with this issue, we propose a CTDG-based dynamic graph embedding framework for dynamic communication networks link prediction called CTDGNN (Continuous-Time Dynamic Graph Neural Networks). In particular, we propose a self-adaptive information dissemination strategy based on node importance to update node embedding by disseminating event information. Finally, extensive numerical experiments on three real-world communication network datasets validate the effectiveness of our proposed model compared to other related methods. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173797699&doi=10.1109%2fICWS60048.2023.00020&partnerID=40&md5=4ae5abe277aab8625e710668beaa9c9e,"Proceedings - 2023 IEEE International Conference on Web Services, ICWS 2023",Exclude,,Include,Exclude
Chen L.; Jia D.; Gao H.; Wu F.; Zhao J.,SkaNet: Split Kernel Attention Network,"Recently, convolutional neural networks (CNNs) and vision transformers (ViTs) have shown impressive results in the area of light-weight models for edge devices. However, the dominant CNNs and ViTs architectures rely heavily on a structured grid or sequence representation of images, which can result in inflexible handling of complex or irregular objects within them. In this paper, we propose SkaNet, an innovative, high-performance hybrid architecture that synergistically integrates the benefits of both CNNs and ViTs, and further enhances these advantages by graph representation learning. Specifically in SkaNet, we introduce a novel linear attention named split kernel attention (SKA) that exploits graph convolution to capture global semantic information and facilitate flexible recognition of irregular objects, splits input tensors into multiple channel groups adaptively, and fuses aforementioned modules into linear attention to efficiently aggregate contextual information. Extensive experiments demonstrate that SkaNet outperforms popular light-weight CNN and ViT-based models on common vision tasks and datasets. For classification on ImageNet-1k, SkaNet-S, with 5.5M parameters, achieves an impressive top-1 accuracy of 79.5%, surpassing MobileViT-S with an absolute gain of 1.1%. Furthermore, SkaNet-S exhibits superior performance in semantic segmentation on PASCAL VOC 2012 and object detection on COCO 2017. Our source code is available on GitHub at: https://github.com/charryglomc/skanet. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174611454&doi=10.1007%2f978-3-031-44192-9_37&partnerID=40&md5=ec1f5c6616717376bbfc36c821cce9a2,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,Exclude,
Cassagne J.; Merlo E.; Branco P.; Jourdan G.-V.; Onut I.-V.,Unsupervised Graph Neural Networks for Source Code Similarity Detection,"In this paper, we propose a novel unsupervised approach for code similarity and clone detection that is based on Graph Neural Networks. We propose a hybrid approach to detect similarities within source code, using centroid distances and a Graph Auto-Encoder that uses a raw abstract syntax trees as input. When compared to RTVNN [33], the state-of-the-art unsupervised approach for code similarity and clone detection, our method improves significantly training and inference time efficiency, while preserving or improving precision. In our experiments, our algorithm is on average 77 times faster during training and 21 times faster during inference. This shows that using Graph Auto-Encoders in the domain of source code similarity analysis is the better option in an industrial context or in a production environment. We illustrate this by using our approach to compute source code similarity within a large dataset of phishing kits written in PHP provided by our industry partner. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174316921&doi=10.1007%2f978-3-031-45275-8_36&partnerID=40&md5=aee61debb36b07fa4fc6b014d2bd824f,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,,
Wu Z.; Shu X.; Yan S.; Lu Z.,FGCVQA: Fine-Grained Cross-Attention for Medical VQA,"The application of Visual Question Answering (VQA) in the medical field has significantly impacted traditional medical research methods. A mature medical visual question answering system can greatly help the patients' diagnosis. The Visual Question Answering Model in the generic domain is not compelling enough for the feature alignment in medical image and text semantics because of the complex diversity of clinical problems and the difficulties in multi-modal reasoning. To solve these, we propose a model called FGCVQA. It is essential to consider the semantic alignment of the medical images and the language features. Specifically, We use the Cross-Modality Encoder to learn the semantic representation of medical images and texts. It improves the reasoning ability of multi-modal by considering the fine-grained property. The experimental results show that FGCVQA outperforms all previous dataset VQA-RAD methods for radiology images. FGCVQA effectively answers medical visual questions and can help doctors to make better clinical analyses and diagnoses. The source codes can be available at https://github.com/wwzziheng/FGCVQA. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180759527&doi=10.1109%2fICIP49359.2023.10222540&partnerID=40&md5=ee74e5d6a1136074bfefceb555ac5e12,"Proceedings - International Conference on Image Processing, ICIP",Exclude,,,
Zou J.; Shao M.; Xia S.,Graphrpe: Relative Position Encoding Graph Transformer for 3d Human Pose Estimation,"The graph neural network has been playing increasingly important roles in 2D-3D lifting based single-frame human pose estimation. However, it still suffers from inferior modeling of local and global associations between 2D nodes. To this end, we introduce two relative position encoding approaches and propose a novel graph-transformer structure ""GraphRPE.""The model consists of two components: graph relative position encoding (GRPE) and universal relative position encoding (URPE). GRPE embeds graph structure prior information into the attention map to correct the self-attention weights and prompt appropriate interactions between 2D nodes, both locally and globally. On the other hand, URPE introduces the Toeplitz matrix to address the limited representation capability of the transformer. In addition, we investigate several graph edge types and their impacts on the results. Extensive experimental results demonstrate that our proposed method achieves SOTA performance on the Human3.6M dataset. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180770947&doi=10.1109%2fICIP49359.2023.10222124&partnerID=40&md5=e23b44933f4b485b10e3ea2144f573b2,"Proceedings - International Conference on Image Processing, ICIP",Exclude,,,
Karl F.; Scherp A.,Transformers are Short-Text Classifiers,"Short text classification is a crucial and challenging aspect of Natural Language Processing. For this reason, there are numerous highly specialized short text classifiers. A variety of approaches have been employed in short text classifiers such as convolutional and recurrent networks. Also many short text classifier based on graph neural networks have emerged in the last years. However, in recent short text research, State of the Art (SOTA) methods for traditional text classification, particularly the pure use of Transformers, have been unexploited. In this work, we examine the performance of a variety of short text classifiers as well as the top performing traditional text classifier on benchmark datasets. We further investigate the effects on two new real-world short text datasets in an effort to address the issue of becoming overly dependent on benchmark datasets with a limited number of characteristics. The datasets are motivated from a real-world use case on classifying goods and services for tax auditing. NICE is a classification system for goods and services that divides them into 45 classes and is based on the Nice Classification of the World Intellectual Property Organization. The Short Texts Of Products and Services (STOPS) dataset is based on Amazon product descriptions and Yelp business entries. Our experiments unambiguously demonstrate that Transformers achieve SOTA accuracy on short text classification tasks, raising the question of whether specialized short text techniques are necessary. The NICE dataset showed to be particularly challenging and makes a good benchmark for future advancements. A preprint can be also found on arXiv [14]. Source code is available here: https://github.com/FKarl/short-text-classification. © 2023, IFIP International Federation for Information Processing.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172272152&doi=10.1007%2f978-3-031-40837-3_7&partnerID=40&md5=97662963f3b747720c5c0d1963edefd4,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Liu J.; Zeng J.; Wang X.; Liang Z.,Learning Graph-based Code Representations for Source-level Functional Similarity Detection,"Detecting code functional similarity forms the basis of various software engineering tasks. However, the detection is challenging as functionally similar code fragments can be implemented differently, e.g., with irrelevant syntax. Recent studies incorporate program dependencies as semantics to identify syntactically different yet semantically similar programs, but they often focus only on local neighborhoods (e.g., one-hop dependencies), limiting the expressiveness of program semantics in modeling functionalities. In this paper, we present Tailor that explicitly exploits deep graph-structured code features for functional similarity detection. Given source-level programs, Tailor first represents them into code property graphs (CPGs) - which combine abstract syntax trees, control flow graphs, and data flow graphs - to collectively reason about program syntax and semantics. Then, Tailor learns representations of CPGs by applying a CPG-based neural network (CPGNN) to iteratively propagate information on them. It improves over prior work on code representation learning through a new graph neural network (GNN) tailored to CPG structures instead of the off-the-shelf GNNs used previously. We systematically evaluate Tailor on C and Java programs using two public benchmarks. Experimental results show that Tailor outperforms the state-of-the-art approaches, achieving 99.8% and 99.9% F-scores in code clone detection and 98.3% accuracy in source code classification. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171745038&doi=10.1109%2fICSE48619.2023.00040&partnerID=40&md5=53a3e46dcfc8d8ebf0487b07fc1986f7,Proceedings - International Conference on Software Engineering,Include,,,
Yang B.; Jiang H.; Pan H.; Xiao J.,VectorFloorSeg: Two-Stream Graph Attention Network for Vectorized Roughcast Floorplan Segmentation,"Vector graphics (VG) are ubiquitous in industrial designs. In this paper, we address semantic segmentation of a typical VG, i.e., roughcast floorplans with bare wall structures, whose output can be directly used for further applications like interior furnishing and room space modeling. Previous semantic segmentation works mostly process well-decorated floorplans in raster images and usually yield aliased boundaries and outlier fragments in segmented rooms, due to pixel-level segmentation that ignores the regular elements (e.g. line segments) in vector floor-plans. To overcome these issues, we propose to fully utilize the regular elements in vector floorplans for more integral segmentation. Our pipeline predicts room segmentation from vector floorplans by dually classifying line segments as room boundaries, and regions partitioned by line segments as room segments. To fully exploit the structural relationships between lines and regions, we use two-stream graph neural networks to process the line segments and partitioned regions respectively, and devise a novel modulated graph attention layer to fuse the heterogeneous information from one stream to the other. Extensive experiments show that by directly operating on vector floorplans, we outper-form image-based methods in both mIoU and mAcc. In addition, we propose a new metric that captures room integrity and boundary regularity, which confirms that our method produces much more regular segmentations. Source code is available at https://github.com/DrZiji/VecFloorSeg. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173929729&doi=10.1109%2fCVPR52729.2023.00137&partnerID=40&md5=ae432373b944b2992c187c470c9aa9fa,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,Exclude,,,
Mohi Ud Din A.; Qureshi S.; Iqbal J.,GNN Approach for Software Reliability,"Software defect prediction is used in the program maintenance process to find potential flaws in order to increase software reliability. A useful procedure that guarantees that the time and expense of software testing can be cut is the prediction of problematic software modules prior to testing. However, the majority of existing models either neglect a source codes tree structure or simply pay attention to a tiny portion of it; thus they do not fully exploit a source code. An abstract syntax tree (AST) of the source code for a software module contains information about the nodes and edges, and Graph Neural Networks (GNNs) evaluate this information to determine whether the module is defective or not. © 2024 Taylor & Francis Group, LLC.",Book chapter,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179209956&doi=10.1201%2f9781032624983-1&partnerID=40&md5=fee77a2e436fe69567fcd5b3485f248a,System Reliability and Security: Techniques and Methodologies,Include,,Include,
Das D.; Mathews N.S.; Mathai A.; Tamilselvam S.; Sedamaki K.; Chimalakonda S.; Kumar A.,COMEX: A Tool for Generating Customized Source Code Representations,"Learning effective representations of source code is critical for any Machine Learning for Software Engineering (ML4SE) system. Inspired by natural language processing, large language models (LLMs) like Codex and CodeGen treat code as generic sequences of text and are trained on huge corpora of code data, achieving state of the art performance on several software engineering (SE) tasks. However, valid source code, unlike natural language, follows a strict structure and pattern governed by the underlying grammar of the programming language. Current LLMs do not exploit this property of the source code as they treat code like a sequence of tokens and overlook key structural and semantic properties of code that can be extracted from code-views like the Control Flow Graph (CFG), Data Flow Graph (DFG), Abstract Syntax Tree (AST), etc. Unfortunately, the process of generating and integrating code-views for every programming language is cumbersome and time consuming. To overcome this barrier, we propose our tool COMEX - a framework that allows researchers and developers to create and combine multiple code-views which can be used by machine learning (ML) models for various SE tasks. Some salient features of our tool are: (i) it works directly on source code (which need not be compilable), (ii) it currently supports Java and C#, (iii) it can analyze both method-level snippets and program-level snippets by using both intra-procedural and inter-procedural analysis, and (iv) it is easily extendable to other languages as it is built on tree-sitter - a widely used incremental parser that supports over 40 languages. We believe this easy-to-use code-view generation and customization tool will give impetus to research in source code representation learning methods and ML4SE. The source code and demonstration of our tool can be found at https://github.com/IBM/tree-sitter-codeviews and https://youtu.be/GER6U87FVbU, respectively.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178994775&doi=10.1109%2fASE56229.2023.00010&partnerID=40&md5=1a70ee5b1443473ceb8605a0a5bd21b9,"Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023",Include,,,
Shu Y.; Van Den Hengel A.; Liu L.,Learning Common Rationale to Improve Self-Supervised Representation for Fine-Grained Visual Recognition Problems,"Self-supervised learning (SSL) strategies have demonstrated remarkable performance in various recognition tasks. However, both our preliminary investigation and recent studies suggest that they may be less effective in learning representations for fine-grained visual recognition (FGVR) since many features helpful for optimizing SSL objectives are not suitable for characterizing the subtle differences in FGVR. To overcome this issue, we propose learning an additional screening mechanism to identify discriminative clues commonly seen across instances and classes, dubbed as common rationales in this paper. Intuitively, common rationales tend to correspond to the discriminative patterns from the key parts of foreground objects. We show that a common rationale detector can be learned by simply exploiting the GradCAM induced from the SSL objective without using any pre-trained object parts or saliency detectors, making it seamlessly to be integrated with the existing SSL process. Specifically, we fit the GradCAM with a branch with limited fitting capacity, which allows the branch to capture the common rationales and discard the less common discriminative patterns. At the test stage, the branch generates a set of spatial weights to selectively aggregate features representing an instance. Extensive experimental results on four visual tasks demonstrate that the proposed method can lead to a significant improvement in different evaluation settings.11The source code will be publicly available at:https://github.com/GANPerf/LCR © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173679892&doi=10.1109%2fCVPR52729.2023.01096&partnerID=40&md5=7431850b7c5e8ce647590501d8e77bcf,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,Exclude,,,
Guo J.; Sun M.; Zhao X.; Shi C.; Su H.; Guo Y.; Pu X.,General Graph Neural Network-Based Model To Accurately Predict Cocrystal Density and Insight from Data Quality and Feature Representation,"Cocrystal engineering as an effective way to modify solid-state properties has inspired great interest from diverse material fields while cocrystal density is an important property closely correlated with the material function. In order to accurately predict the cocrystal density, we develop a graph neural network (GNN)-based deep learning framework by considering three key factors of machine learning (data quality, feature presentation, and model architecture). The result shows that different stoichiometric ratios of molecules in cocrystals can significantly influence the prediction performances, highlighting the importance of data quality. In addition, the feature complementary is not suitable for augmenting the molecular graph representation in the cocrystal density prediction, suggesting that the complementary strategy needs to consider whether extra features can sufficiently supplement the lacked information in the original representation. Based on these results, 4144 cocrystals with 1:1 stoichiometry ratio are selected as the dataset, supplemented by the data augmentation of exchanging a pair of coformers. The molecular graph is determined to learn feature representation to train the GNN-based model. Global attention is introduced to further optimize the feature space and identify important atoms to realize the interpretability of the model. Benefited from the advantages, our model significantly outperforms three competitive models and exhibits high prediction accuracy for unseen cocrystals, showcasing its robustness and generality. Overall, our work not only provides a general cocrystal density prediction tool for experimental investigations but also provides useful guidelines for the machine learning application. All source codes are freely available at https://github.com/Xiao-Gua00/CCPGraph. © 2023 American Chemical Society.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147531596&doi=10.1021%2facs.jcim.2c01538&partnerID=40&md5=f5b28713ea52a1e9a14beba69cfbc1dd,Journal of Chemical Information and Modeling,Exclude,,,
He X.; Hooi B.; Laurent T.; Perold A.; LeCun Y.; Bresson X.,A Generalization of ViT/MLP-Mixer to Graphs,"Graph Neural Networks (GNNs) have shown great potential in the field of graph representation learning. Standard GNNs define a local message-passing mechanism which propagates information over the whole graph domain by stacking multiple layers. This paradigm suffers from two major limitations, over-squashing and poor long-range dependencies, that can be solved using global attention but significantly increases the computational cost to quadratic complexity. In this work, we propose an alternative approach to overcome these structural limitations by leveraging the ViT/MLP-Mixer architectures introduced in computer vision. We introduce a new class of GNNs, called Graph ViT/MLP-Mixer, that holds three key properties. First, they capture long-range dependency and mitigate the issue of oversquashing as demonstrated on Long Range Graph Benchmark and TreeNeighbourMatch datasets. Second, they offer better speed and memory efficiency with a complexity linear to the number of nodes and edges, surpassing the related Graph Transformer and expressive GNN models. Third, they show high expressivity in terms of graph isomorphism as they can distinguish at least 3-WL non-isomorphic graphs. We test our architecture on 4 simulated datasets and 7 real-world benchmarks, and show highly competitive results on all of them. The source code is available for reproducibility at: https://github.com/XiaoxinHe/Graph-ViT-MLPMixer. © 2023 Proceedings of Machine Learning Research. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172669958&partnerID=40&md5=209a6ef35d4bbe9b028f1ab61e06ad1b,Proceedings of Machine Learning Research,Exclude,,,
Nguyen Q.V.; Pham H.Q.; Tran D.Q.; Nguyen T.K.-B.; Nguyen N.H.,MAT: Effective Link Prediction via Mutual Attention Transformer,"The Data Science and Advanced Analytics (DSAA) 2023 competition [1] focuses on proposing link prediction methods to solve challenges about network-like data structure, such as network reconstruction, network development, etc., from articles on Wikipedia. In this challenge, our 'UIT Dark Cow' team proposes the Mutual Attention Transformer (MAT) method to predict if there is a link between two Wikipedia pages. Our method achieved the 5th and 4th position on the leaderboard for the public and private tests, respectively. Our source code is publicly available for the ease of experimental re-implementation at the following link: https://github.com/minhquan6203/source-code-dsaa-2023. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178999144&doi=10.1109%2fDSAA60987.2023.10302519&partnerID=40&md5=2ac1a9c50fabb64b41e3fd2932f11145,"2023 IEEE 10th International Conference on Data Science and Advanced Analytics, DSAA 2023 - Proceedings",Exclude,,Exclude,
Zhang J.; Wu N.; Yang C.,NExtGCN: Modeling Node Importance of Graph Convolution Network by Neighbor Excitation for Recommendation,"To alleviate information overload, the recommender system is pushing personalized contents to users and improving the efficiency of information distribution. Graph Convolution Networks (GCNs), which can better gather structured information and becomes a new state-of-the-art for collaborative filtering. Many current works on GCNs tend to be easier to train and have better generalization ability like LightGCN. However, they care less about the importance of nodes. In this work, we propose a new model named NExtGCN (Neighbor Exci tation Graph Convolutional Network), which models the node importance of GCN by neighbor excitation. The NExtGCN can learn the importance of nodes via the global and local excitation layer which is inspired by the Squeeze-Excitation network. Furthermore, we propose a neighbor excitation layer that can fully utilize graph structure and make this model practical to large-scale datasets. Extensive experimental results on four real-world datasets have shown the effectiveness and robustness of the proposed model. Especially on the Amazon-Books dataset, our NExtGCN has improved by 10.95%, 49.36%, and 26.8% in Recall@20, MRR@20, and NDCG@20 compared to LightGCN. We also provide source code (https://github.com/clemaph/NExtGCN.git ) to reproduce the experimental results (This job is supported by Postgraduate Research & Practice Innovation Program of Jiangsu Province, the item number is KYCX22_3071). © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174685194&doi=10.1007%2f978-3-031-39821-6_26&partnerID=40&md5=dd6ff421931ec1f5afa24fb9c61edca0,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,Exclude,
Zheng Z.; Guo C.; Chen J.; Li J.,Graph Neural Network-Based Representation Learning for Medical Time Series,"The ability to analyze and predict medical time series data is crucial for enhancing healthcare decision-making and improving patient outcomes. Currently, the algorithms used for classification and prediction of medical time series data are limited in their capabilities and may not be reliable enough to meet the demands of practical applications. The purpose of this paper is to promote the representation learning of complex data primarily comprised of medical time series, in order to facilitate various downstream tasks. Under the framework of graph neural networks (GNN), we present indegree regularized neural message passing to reflect the dependencies between different sequences. Our approach also leverages representation learning to convert multivariate time series (MTS) and static features into nodes of GNN. Moreover, we propose a dynamic loss function to encourage the consistent learning of sensor dependency graphs across models. Based on these proposals, our method can effectively capture not only the temporal dependencies among variables, but also the multidimensional dependencies among MTS and static features. We classify time series on two medical challenge and a human activity datasets. The results show that our approach can significantly improve downstream task performance across various metrics. Code is available at https://github.com/Zzzoptimus/GICG. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174619250&doi=10.1007%2f978-3-031-44223-0_16&partnerID=40&md5=6543363ac73af2051e6f1f1d8ae41128,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,Exclude,
Liu Y.; Liang K.; Xia J.; Zhou S.; Yang X.; Liu X.; Li S.Z.,Dink-Net: Neural Clustering on Large Graphs,"Deep graph clustering, which aims to group the nodes of a graph into disjoint clusters with deep neural networks, has achieved promising progress in recent years. However, the existing methods fail to scale to the large graph with million nodes. To solve this problem, a scalable deep graph clustering method (Dink-Net) is proposed with the idea of dilation and shrink. Firstly, by discriminating nodes, whether being corrupted by augmentations, representations are learned in a self-supervised manner. Meanwhile, the cluster centers are initialized as learnable neural parameters. Subsequently, the clustering distribution is optimized by minimizing the proposed cluster dilation loss and cluster shrink loss in an adversarial manner. By these settings, we unify the two-step clustering, i.e., representation learning and clustering optimization, into an end-to-end framework, guiding the network to learn clustering-friendly features. Besides, Dink-Net scales well to large graphs since the designed loss functions adopt the mini-batch data to optimize the clustering distribution even without performance drops. Both experimental results and theoretical analyses demonstrate the superiority of our method. Compared to the runner-up, Dink-Net achieves 9.62% NMI improvement on the ogbn-papers100M dataset with 111 million nodes and 1.6 billion edges. The source code is released: Dink-NetI. Besides, a collection (papers, codes, and datasets) of deep graph clustering is shared on GitHubII © 2023 Proceedings of Machine Learning Research. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174395382&partnerID=40&md5=d844d53c438235661ffb2d33b856d537,Proceedings of Machine Learning Research,Exclude,,Exclude,
Tran A.H.; Nguyen T.M.; Luu S.T.,A Text-based Approach For Link Prediction on Wikipedia Articles,"This paper present our work in the DSAA 2023 Challenge about Link Prediction for Wikipedia Articles. We use traditional machine learning models with POS tags (part-of-speech tags) features extracted from text to train the classification model for predicting whether two nodes has the link. Then, we use these tags to test on various machine learning models. We obtained the results by F1 score at 0.99999 and got 7{th} place in the competition. Our source code is publicly available at this link: https://github.com/Tam1032/DSAA2023-Challenge-Link-prediction-DS-UIT_SAT. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179009904&doi=10.1109%2fDSAA60987.2023.10302627&partnerID=40&md5=43aebd0a69ae953d9cad4d38b27834ea,"2023 IEEE 10th International Conference on Data Science and Advanced Analytics, DSAA 2023 - Proceedings",Exclude,,Exclude,
Feng Q.; Shao Z.; Wang Z.,Boundary-aware small object detection with attention and interaction,"Object detection is a critical technology for the intelligent analytical processing of images captured by drones. The objects usually come in various scales and can be extremely small. Existing detection methods are inherently based on pyramid hierarchy architectures to extract multi-scale features and provide better feature representation for small objects. Nevertheless, they inevitably dilute the representation of details in low-level features during top-down feature fusion and are totally unconcerned with whether the fused feature fits the objects of specific scales within a layer. Moreover, the pyramid can only implicitly fuse the spatial context, which makes the fused features cannot receive fine spatial location information for object localization. In this work, we propose an effective boundary-aware network with attention refinement and spatial interaction to tackle the above challenges. Specifically, we first present a highly effective yet simple boundary-aware detection head (BAH), which directly guides representation learning of object structure semantics in the prediction layer to preserve object-related boundary semantics. Additionally, the attentional feature parallel fusion (AFPF) module offers multi-scale feature encoding capability in a parallel triple fusion fashion and adaptively selects features appropriate for objects of certain scales. Furthermore, we design a spatial interactive module (SIM) to preserve fine spatial detail through cross-spatial feature association. Extensive experiments prove that the proposed network significantly outperforms the state-of-the-art methods, in which we achieve 33.1 mAP and 56.5 AP50 on the VisDrone benchmark, 63.4 mAP and 94 AP50 on the NWPU VHR-10 benchmark. The source code will be released. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176347595&doi=10.1007%2fs00371-023-03144-x&partnerID=40&md5=f499b9119db71d05db0314e9be606610,Visual Computer,Exclude,,Exclude,
Romanov V.; Dlamini G.; Valeev A.; Ivanov V.,Leveraging Transformer and Graph Neural Networks for Variable Misuse Detection,"Understanding source code is a central part of finding and fixing software defects in software development. In many cases software defects caused by an incorrect usage of variables in program code. Over the years researchers have developed data-driven approaches to detect variable misuse. Most of modern existing approaches are based on the transformer architecture, trained on millions of buggy and correct code snippets to learn the task of variable detection. In this paper, we evaluate an alternative, a graph neural network (GNN) architectures, for variable misuse detection. Popular benchmark dataset, which is a collection functions written in Python programming language, is used to train the models presented in this paper. We compare the GNN models with the transformer-based model called CodeBERT. Copyright © 2023 by SCITEPRESS - Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0)",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160532580&doi=10.5220%2f0011997300003464&partnerID=40&md5=a925c3ada0ee8038d91da293179dc5b6,"International Conference on Evaluation of Novel Approaches to Software Engineering, ENASE - Proceedings",Include,,,
Nashid N.; Sintaha M.; Mesbah A.,Embedding Context as Code Dependencies for Neural Program Repair,"Deep learning-based program repair has received significant attention from the research community lately. Most existing techniques treat source code as a sequence of tokens or abstract syntax trees. Consequently, they cannot incorporate semantic contextual information pertaining to a buggy line of code and its fix. In this work, we propose a program repair technique called GLANCE that combines static program analysis with graph-to-sequence learning for capturing contextual information. To represent contextual information, we introduce a graph representation that can encode information about the buggy code and its repair ingredients by embedding control and data flow information. We employ a fine-grained graphical code representation, which explicitly describes code change context and embeds semantic relationships between code elements. GLANCE leverages a graph neural network and a sequence-based decoder to learn from this semantic code representation. We evaluated our work against six state-of-the-art techniques, and our results show that GLANCE fixes 52% more bugs than the best performing technique.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161949341&doi=10.1109%2fICST57152.2023.00018&partnerID=40&md5=c0ba7521813481c648b352b9f7768f43,"Proceedings - 2023 IEEE 16th International Conference on Software Testing, Verification and Validation, ICST 2023",Include,,Include,
D'Inca M.; Beyan C.; Niewiadomski R.; Barattin S.; Sebe N.,Unleashing the Transferability Power of Unsupervised Pre-Training for Emotion Recognition in Masked and Unmasked Facial Images,"Facial expressions are an essential part of nonverbal communication and major indicators of human emotions. Effective automatic Facial Emotion Recognition (FER) systems can facilitate comprehension of an individual's intention, and prospective behaviors in Human-Computer and Human-Robot Interaction. However, FER faces an enduring challenge, commonly encountered in real-life, of partial occlusions caused by objects such as sunglasses and hands. With the onset of the COVID-19 pandemic, facial masks become a major obstruction for FER systems. The utilization of facial masks exacerbates the occlusion issue since these cover a significant portion of a person's face, including the highly informative mouth area from which positive and negative emotions can be differentiated. Conversely, the efficacy of FER is largely contingent upon the supervised learning paradigm, which necessitates costly and laborious data annotation. Our study centers on utilizing the reconstruction capability of a Convolutional Residual Autoencoder to differentiate between positive and negative emotions. The proposed approach employs unsupervised feature learning and takes as inputs facial images of individuals with masks and without masks. Our study puts particular emphasis on the transferability of the proposed approach to different domains in comparison to current state-of-the-art fully supervised methods. The comprehensive experimental evaluation demonstrates the superior transferability of the proposed approach, highlighting the effectiveness of the unsupervised feature learning pipeline. Despite outperforming more complex methods in some scenarios, the proposed approach is characterized by relatively low computational expense. The source code of the proposed approach, along with the facial images created for this study, are accessible in HERE. © 2013 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168742167&doi=10.1109%2fACCESS.2023.3308047&partnerID=40&md5=a2d0b210547c0921cfbf6b82f6935ca0,IEEE Access,Exclude,,,
Sun J.; Ji L.; Zhu J.,Shared Coupling-bridge Scheme for Weakly Supervised Local Feature Learning,"Local feature learning is believed to be of important significance in classic vision tasks such as visual localization, image matching and 3D reconstruction. Limited by training samples, weakly-supervised strategy has become one of widely-concerned effective schemes for local feature learning. Currently, it still has some weaknesses needing further improvement, mainly including the discrimination power of extracted local descriptors, the localization accuracy of detected keypoints, and the efficiency of weakly-supervised local feature learning. Focusing on promoting the performance of sparse local feature learning with camera pose supervision, this paper pertinently proposes a Shared Coupling-bridge scheme with four light-weight yet effective improvements for weakly-supervised local feature (SCFeat) learning. It mainly contains: (i) the <italic>Feature-Fusion-ResUNet Backbone</italic> (F2R-Backbone) for local descriptors learning, (ii) a shared coupling-bridge normalization to improve the decoupling training of description network and detection network,(iii) an improved detection network with peakiness measurement to detect keypoints and iv) a new reward factor of fundamental matrix error to further optimize feature detection training. Extensive experiments prove that our SCFeat scheme is effective and has wide task adaptability. It could often obtain a state-of-the-art performance on classic image matching and visual localization. Even in terms of 3D reconstruction, it could still achieve competitive results. Our source codes are available at <uri>https://github.com/sunjiayuanro/SCFeat.git</uri> IEEE",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160265775&doi=10.1109%2fTMM.2023.3278172&partnerID=40&md5=6708e525ea7d07fb11355d0ba99da2e9,IEEE Transactions on Multimedia,Exclude,,,
Gu H.; Su L.; Zhang W.; Ran C.,Attention is Needed for RF Fingerprinting,"Radio Frequency (RF) fingerprinting is a novel solution for identifying a unique radio from a large pool of devices by analyzing the subtle characteristics that are inherent in the radio waveform. Deep convolutional neural networks have been widely used to handle the RF fingerprinting task because of their exceptional capacity for representation learning. However, there are still challenges in employing deep convolutional neural networks, such as how to enable the model learn more robust and discriminative RF fingerprints. This paper aims to explore new model architectures to learn robust RF fingerprints. Hence we proposes a novel Dual Attention Convolution module that simultaneously learns channel attention and spatial attention to tune the RF fingerprints, enhancing the convolutional layers' potential for representation learning. Our proposed module is lightweight and plug-and-play. A number of convolutional neural networks can be equipped with our module, which enables them to extract robust and discriminative RF fingerprints. Our approach has been extensively tested through experimental trials, and the results have demonstrated its effectiveness. It is shown that the performance of convolutional neural networks on RF fingerprinting can be improved 1.5% on average, and DAConv-ResNet50 which combined ResNet50 and our Dual Attention Convolution module can achieve 95.6% recognition accuracy on 10 USRP X310. Our source code is available at https://github.com/zhangweifeng1218/Adaptive_RF_Fingerprinting.  © 2013 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168277536&doi=10.1109%2fACCESS.2023.3305533&partnerID=40&md5=4ea887a598c5f448f4cfc1a38fb0aadc,IEEE Access,Exclude,,,
Sedmidubsky J.; Carrara F.; Amato G.,SegmentCodeList: Unsupervised Representation Learning for Human Skeleton Data Retrieval,"Recent progress in pose-estimation methods enables the extraction of sufficiently-precise 3D human skeleton data from ordinary videos, which offers great opportunities for a wide range of applications. However, such spatio-temporal data are typically extracted in the form of a continuous skeleton sequence without any information about semantic segmentation or annotation. To make the extracted data reusable for further processing, there is a need to access them based on their content. In this paper, we introduce a universal retrieval approach that compares any two skeleton sequences based on temporal order and similarities of their underlying segments. The similarity of segments is determined by their content-preserving low-dimensional code representation that is learned using the Variational AutoEncoder principle in an unsupervised way. The quality of the proposed representation is validated in retrieval and classification scenarios; our proposal outperforms the state-of-the-art approaches in effectiveness and reaches speed-ups up to 64x on common skeleton sequence datasets. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151002327&doi=10.1007%2f978-3-031-28238-6_8&partnerID=40&md5=0cd28c6db9f2712f95e83d14a35f6bad,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Zhang J.; Yang C.,IcaGCN: Model Intents via Coactivated Graph Convolution Network for Recommendation,"In this era of information overload, to better provide personalized content services to users, recommendation systems have greatly improved the efficiency of information distribution. Graph Convolution Network(GCN), which is one of the representative works of graph structure aggregation processing, works by node convolution with the help of the Laplacian matrix of the graph and weighted combination of neighbor node information according to the outgoing and incoming degrees of neighbor nodes to obtain the representation of the current node. However, the mainstream GCN models nowadays do not take into account data augmentation of metadata and the fact that each node plays different roles with different importance and weights, thus making the recommendation performance limited. To better solve the above problems, we propose the IcaGCN model, which can perform data augmentation and calculate node weights in modules, and is a convenient plug-and-play method. Finally, extensive experimental results on four real-world datasets have shown the effectiveness and robustness of the proposed model. Especially on the Amazon-Book dataset, our IcaGCN has improved by 6.32%, 42.29%, and 12.38% in Recall@20, MRR@20, and NDCG@20, respectively, compared to other existing state-of-the-art models. We also provide source code and data to reproduce the experimental results available at https://github.com/PersonZ1223/IcaGCN.git  © 2013 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153798464&doi=10.1109%2fACCESS.2023.3268616&partnerID=40&md5=0eeed5b27b6261a5754eb5dcff7853e4,IEEE Access,Exclude,,,
Xu M.; Yuan X.; Miret S.; Tang J.,ProtST: Multi-Modality Learning of Protein Sequences and Biomedical Texts,"Current protein language models (PLMs) learn protein representations mainly based on their sequences, thereby well capturing co-evolutionary information, but they are unable to explicitly acquire protein functions, which is the end goal of protein representation learning. Fortunately, for many proteins, their textual property descriptions are available, where their various functions are also described. Motivated by this fact, we first build the ProtDescribe dataset to augment protein sequences with text descriptions of their functions and other important properties. Based on this dataset, we propose the ProtST framework to enhance Protein Sequence pre-training and understanding by biomedical Texts. During pre-training, we design three types of tasks, i.e., unimodal mask prediction, multimodal representation alignment and multimodal mask prediction, to enhance a PLM with protein property information with different granularities and, at the same time, preserve the PLM's original representation power. On downstream tasks, ProtST enables both supervised learning and zero-shot prediction. We verify the superiority of ProtST-induced PLMs over previous ones on diverse representation learning benchmarks. Under the zero-shot setting, we show the effectiveness of ProtST on zero-shot protein classification, and ProtST also enables functional protein retrieval from a large-scale database without any function annotation. Source code and model weights are available at https://github.com/DeepGraphLearning/ProtST. © 2023 Proceedings of Machine Learning Research. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150962055&partnerID=40&md5=508426a5aade2667ce37b3dc5ed8c699,Proceedings of Machine Learning Research,Exclude,,,
Wang W.; Zhang K.; Li G.; Liu S.; Li A.; Jin Z.; Liu Y.,Learning Program Representations with a Tree-Structured Transformer,"Learning vector representations for programs is a critical step in applying deep learning techniques for program understanding tasks. Various neural network models are proposed to learn from tree-structured program representations, e.g., abstract syntax tree (AST) and concrete syntax tree (CST). However, most neural architectures either fail to capture long-range dependencies which are ubiquitous in programs, or cannot learn effective representations for syntax tree nodes, making them incapable of performing the node-level prediction tasks, e.g., bug localization. In this paper, we propose Tree-Transformer, a novel recursive tree-structured neural network to learn the vector representations for source codes. We propose a multi-head attention mechanism to model the dependency between siblings and parent-children node pairs. Moreover, we propose a bi-directional propagation strategy to allow node information passing in two directions, bottom-up and top-down along trees. In this way, Tree-Transformer can learn the information of the node features as well as the global contextual information. The extensive experimental results show that our Tree-Transformer significantly outperforms the existing tree-based and graph-based program representation learning approaches in both the tree-level and node-level prediction tasks. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160553032&doi=10.1109%2fSANER56733.2023.00032&partnerID=40&md5=026c96d9f2a353f6e064483c12951584,"Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",Include,,,
Gu X.; Lou R.; Sun L.; Li S.,PAGE: A Position-Aware Graph-Based Model for Emotion Cause Entailment in Conversation,"Conversational Causal Emotion Entailment (C2E2) is a task that aims at recognizing the causes corresponding to a target emotion in a conversation. The order of utterances in the conversation affects the causal inference. However, most current position encoding strategies ignore the order relation among utterances and speakers. To address the issue, we devise a novel position-Aware graph to encode the entire conversation, fully modeling causal relations among utterances. The comprehensive experiments show that our method consistently achieves state-of-The-Art performance on two challenging test sets, proving the effectiveness of our model. Our source code is available on Github1. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168743621&doi=10.1109%2fICASSP49357.2023.10096909&partnerID=40&md5=129ad5110f0b80c3055ee62f13523240,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",Exclude,,,
Miao H.; Chen J.; Lin Y.; Xu M.; Han Y.; Gao J.,JG2Time: A Learned Time Estimator for Join Operators Based on Heterogeneous Join-Graphs,"The join operator is one of the key operators in RDBMS, and estimating its evaluation time is a fundamental task in query optimization, scheduling, etc. However, it is hard to make a precise estimation, which is not only related with the physical join implementations (hash, sort, loop) but also with the corresponding parameters, like the size of the data, the number of partitions, the number of threads in a modern hash join. Existing works rely on the time complexity analysis but yield rough results, or employ machine learning techniques to build a predictive model but require many training instances. In this paper, we propose a method, named JG2Time, to estimate the running time using the join-graphs constructed from the source codes. Specifically, we construct a heterogonous join-graph by annotating parameter nodes to a call-graph generated by running time analysis tools, and propose ReGAT, a heterogonous graph neural network, to fully capture the edge weights (the number of function calls) in the join-graph. The embeddings learned from ReGAT can be used to predict the running time. In addition, we optimize JG2Time with a multi-task model that also predicts the times of function calls, and an unsupervised code learning method to enhance its generalization. The experimental results illustrate the effectiveness of JG2Time and its optimization strategies. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161709753&doi=10.1007%2f978-3-031-30637-2_9&partnerID=40&md5=b31b9bb5e996d9f599b4c20c25abe3bb,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,Include,
Zhou P.; Wu Z.; Zeng X.; Wen G.; Ma J.; Zhu X.,Totally Dynamic Hypergraph Neural Network,"Recent dynamic hypergraph neural networks (DHGNNs) are designed to adaptively optimize the hypergraph structure to avoid the dependence on the initial hypergraph structure, thus capturing more hidden information for representation learning. However, most existing DHGNNs cannot adjust the hyperedge number and thus fail to fully explore the underlying hypergraph structure. This paper proposes a new method, namely, totally hypergraph neural network (TDHNN), to adjust the hyperedge number for optimizing the hypergraph structure. Specifically, the proposed method first captures hyperedge feature distribution to obtain dynamical hyperedge features rather than fixed ones, by conducting the sampling from the learned distribution. The hypergraph is then constructed based on the attention coefficients of both sampled hyperedges and nodes. The node features are dynamically updated by designing a simple hypergraph convolution algorithm. Experimental results on real datasets demonstrate the effectiveness of the proposed method, compared to SOTA methods. The source code can be accessed via https://github.com/HHW-zhou/TDHNN. © 2023 International Joint Conferences on Artificial Intelligence. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170388436&partnerID=40&md5=563a12a495787d31a663112f93538eb4,IJCAI International Joint Conference on Artificial Intelligence,Exclude,,Exclude,
Schwertmann L.; Ravi M.P.K.; de Melo G.,Model-Agnostic Bias Measurement in Link Prediction,"Link prediction models based on factual knowledge graphs are commonly used in applications such as search and question answering. However, work investigating social bias in these models has been limited. Previous work focused on knowledge graph embeddings, so more recent classes of models achieving superior results by fine-tuning Transformers have not yet been investigated. We therefore present a model-agnostic approach for bias measurement leveraging fairness metrics to compare bias in knowledge graph embedding-based predictions (KG only) with models that use pre-trained, Transformer-based language models (KG+LM). We further create a dataset to measure gender bias in occupation predictions and assess whether the KG+LM models are more or less biased than KG only models. We find that gender bias tends to be higher for the KG+LM models and analyze potential connections to the accuracy of the models and the data bias inherent in our dataset. Finally, we discuss limitations and ethical considerations of our work. The repository containing the source code and the data set is publicly available at https://github.com/lena-schwert/comparing-bias-in-KG-models. © 2023 Association for Computational Linguistics.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159850556&partnerID=40&md5=2d89a5635d899b46d4a9a9f9baafac09,"EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Findings of EACL 2023",Exclude,,Exclude,
Hoffmann M.; Galke L.; Scherp A.,Open-World Lifelong Graph Learning,"We study the problem of lifelong graph learning in an open-world scenario, where a model needs to deal with new tasks and potentially unknown classes. We utilize Out-of-Distribution (OOD) detection methods to recognize new classes and adapt existing non-graph OOD detection methods to graph data. Crucially, we suggest performing new class detection by combining OOD detection methods with information aggregated from the graph neighborhood. Most OOD detection methods avoid determining a crisp threshold for deciding whether a vertex is OOD. To tackle this problem, we propose a Weakly-supervised Relevance Feedback (Open-WRF) method, which decreases the sensitivity to thresholds in OOD detection. We evaluate our approach on six benchmark datasets. Our results show that the proposed neighborhood aggregation method for OOD scores outperforms existing methods independent of the underlying graph neural network. Furthermore, we demonstrate that our Open-WRF method is more robust to threshold selection and analyze the influence of graph neighborhood on OOD detection. The aggregation and threshold methods are compatible with arbitrary graph neural networks and OOD detection methods, making our approach versatile and applicable to many real-world applications. The source code is available at https://github.com/Bobowner/Open-World-LGL. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169576646&doi=10.1109%2fIJCNN54540.2023.10191071&partnerID=40&md5=b27c022c3fe2e8feb5db18a6011cdc70,Proceedings of the International Joint Conference on Neural Networks,Exclude,,,
Zeng N.; Cao H.,An Improved LSTM Model for Correcting Grammatical Errors in English Text,"In English teaching, grammar teaching is still an indispensable part. Teachers pay more attention to the correction of written form than oral form in grammar teaching so that students can see their mistakes intuitively and clearly. Whether from the perspective of teachers or students, the correction of grammatical errors and good learning results are inseparable. At present, the public grammar error correction corpus is too small and the quality is uneven, which makes the parameters of the grammar error correction model can not be fully trained. The performance of the model is also a bottleneck. Graph neural network-based model for grammar error detection is studied. The errors in the text data are detected. Neural network modeling is adopted as the basic structure of the model. In addition to predicting the correct label of each word in the sentence, an auxiliary task of predicting the context word of the word is introduced to further improve the detection performance of the model. Furthermore, the graph neural network with a gating mechanism is adopted to model the dependency syntax tree of the statement, which provides important information features for error detection and effectively improves the performance of model checking. Finally, good results in English grammar error detection and test data sets are achieved. As one of the core technologies in online education and other fields, the research of grammar error correction has great research and application value. © 2023 SPIE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163397017&doi=10.1117%2f12.2679046&partnerID=40&md5=7bf0b9945bedc9a7e4047a66bccf8108,Proceedings of SPIE - The International Society for Optical Engineering,Exclude,,,
Chen T.; Shen Y.; Chen X.; Zhang L.; Zhao S.,MPEG: A Multi-Perspective Enhanced Graph Attention Network for Causal Emotion Entailment in Conversations,"Emotion causes constitute a pivotal component in the comprehension of emotional conversations. Recently, a new task named Causal Emotion Entailment (CEE) has been proposed to identify the causal utterances for the target emotional utterance in a conversation. Although researchers have achieved some progress in solving this problem, they failed to adequately incorporate speaker characteristics and overlooked the effects of temporal relations in conversation structures. To fill such a research gap to some extent, we propose a novel causal emotion entailment framework, namely MPEG (Multi-Perspective Enhanced Graph attention network). The training of MPEG consists of three stages. Firstly, we utilize a speaker-aware pre-trained model and two attention mechanisms to obtain the utterance representations that incorporate local contexts as well as the speaker and emotional information. Then, these representations are fed into a graph attention network to model the conversation structures and emotional dynamics from both local and global perspectives. Finally, a fully-connected network is implemented to predict the relationships between emotional utterances and causal utterances. Experimental results show that MPEG achieves state-of-the-art performance. The source code is available at <uri>https://github.com/slptongji/MPEG</uri>. IEEE",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171572422&doi=10.1109%2fTAFFC.2023.3315752&partnerID=40&md5=193f2d14faf9baa4bca70276c4829bdd,IEEE Transactions on Affective Computing,Exclude,,,
Sukur N.; Milošević N.; Pracner D.; Budimac Z.,Automated program improvement with reinforcement learning and graph neural networks,"Automated software transformations and the process of automated program repair and improvement are an important aspect of modern software engineering practices. In this paper, we describe a system which uses a graph-based deep learning model that can be trained to automatically transform and improve computer programs. By operating on language-agnostic, universal graph-like structures easily extractable from source code files (abstract syntax trees), the deep learning agent learns which transformations should be effectively applied to various structures recognized in the source code in order to improve it. By defining a metric which we want to improve and introducing an optimization task—a reinforcement learning setting, an agent learns to automatically apply a chain of transformations to the program, drastically improving it. While similar program improvement processes exist, they exclusively use exhaustive search algorithms to try all the possible code transformations which is a long process susceptible to local optimum issues. Our solution aims to model and embed structural knowledge about the programs being transformed which greatly helps the agent to choose best possible code transformations to apply. Elements of the approach we present in this paper are further applicable not just to automatic software improvement tasks, but also to other code-related tasks. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160861647&doi=10.1007%2fs00500-023-08559-1&partnerID=40&md5=8f31b665e0a0762d68a81c3d84e68699,Soft Computing,Include,,,
Hua Y.; Shi R.; Wang P.; Ge S.,Learning Patch-Channel Correspondence for Interpretable Face Forgery Detection,"Beyond high accuracy, good interpretability is very critical to deploy a face forgery detection model for visual content analysis. In this paper, we propose learning patch-channel correspondence to facilitate interpretable face forgery detection. Patch-channel correspondence aims to transform the latent features of a facial image into multi-channel interpretable features where each channel mainly encoders a corresponding facial patch. Towards this end, our approach embeds a feature reorganization layer into a deep neural network and simultaneously optimizes classification task and correspondence task via alternate optimization. The correspondence task accepts multiple zero-padding facial patch images and represents them into channel-aware interpretable representations. The task is solved by step-wisely learning channel-wise decorrelation and patch-channel alignment. Channel-wise decorrelation decouples latent features for class-specific discriminative channels to reduce feature complexity and channel correlation, while patch-channel alignment then models the pairwise correspondence between feature channels and facial patches. In this way, the learned model can automatically discover corresponding salient features associated to potential forgery regions during inference, providing discriminative localization of visualized evidences for face forgery detection while maintaining high detection accuracy. Extensive experiments on popular benchmarks clearly demonstrate the effectiveness of the proposed approach in interpreting face forgery detection without sacrificing accuracy. The source code is available at https://github.com/Jae35/IFFD.  © 1992-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149383758&doi=10.1109%2fTIP.2023.3246793&partnerID=40&md5=7acf267b9f0e28362f65d451776f82e3,IEEE Transactions on Image Processing,Exclude,,Exclude,
Chen C.; Peng X.; Xing Z.; Sun J.; Wang X.; Zhao Y.; Zhao W.,Holistic Combination of Structural and Textual Code Information for Context Based API Recommendation,"Context based API recommendation is an important way to help developers find the needed APIs effectively and efficiently. For effective API recommendation, we need not only a joint view of both structural and textual code information, but also a holistic view of correlated API usage in control and data flow graph as a whole. Unfortunately, existing API recommendation methods exploit structural or textual code information separately. In this work, we propose a novel API recommendation approach called APIRec-CST (API Recommendation by Combining Structural and Textual code information). APIRec-CST is a deep learning model that combines the API usage with the text information in the source code based on an API Context Graph Network and a Code Token Network that simultaneously learn structural and textual features for API recommendation. We apply APIRec-CST to train a model for JDK library based on 1,914 open-source Java projects and evaluate the accuracy and MRR (Mean Reciprocal Rank) of API recommendation with another 6 open-source projects. The results show that our approach achieves respectively a top-1, top-5, top-10 accuracy and MRR of 60.3, 81.5, 87.7 and 69.4 percent, and significantly outperforms an existing graph-based statistical approach and a tree-based deep learning approach for API recommendation. A further analysis shows that textual code information makes sense and improves the accuracy and MRR. The sensitivity analysis shows that the top-k accuracy and MRR of APIRec-CST are insensitive to the number of APIs to be recommended in a hole. We also conduct a user study in which two groups of students are asked to finish 6 programming tasks with or without our APIRec-CST plugin. The results show that APIRec-CST can help the students to finish the tasks faster and more accurately and the feedback on the usability is overwhelmingly positive. © 1976-2012 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104636235&doi=10.1109%2fTSE.2021.3074309&partnerID=40&md5=673fd9afacf9ce76e19fed9b164bd0b9,IEEE Transactions on Software Engineering,Include,,Include,
Alon Y.; David C.,Using graph neural networks for program termination,"Termination analyses investigate the termination behavior of programs, intending to detect nontermination, which is known to cause a variety of program bugs (e.g. hanging programs, denial-of-service vulnerabilities). Beyond formal approaches, various attempts have been made to estimate the termination behavior of programs using neural networks. However, the majority of these approaches continue to rely on formal methods to provide strong soundness guarantees and consequently suffer from similar limitations. In this paper, we move away from formal methods and embrace the stochastic nature of machine learning models. Instead of aiming for rigorous guarantees that can be interpreted by solvers, our objective is to provide an estimation of a program's termination behavior and of the likely reason for nontermination (when applicable) that a programmer can use for debugging purposes. Compared to previous approaches using neural networks for program termination, we also take advantage of the graph representation of programs by employing Graph Neural Networks. To further assist programmers in understanding and debugging nontermination bugs, we adapt the notions of attention and semantic segmentation, previously used for other application domains, to programs. Overall, we designed and implemented classifiers for program termination based on Graph Convolutional Networks and Graph Attention Networks, as well as a semantic segmentation Graph Neural Network that localizes AST nodes likely to cause nontermination. We also illustrated how the information provided by semantic segmentation can be combined with program slicing to further aid debugging.  © 2022 Owner/Author.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143064932&doi=10.1145%2f3540250.3549095&partnerID=40&md5=9156908b690ba90af862a39222ba7ecb,ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,Include,,,
Dharma K.C.; Morrison C.T.; Walls B.,Texture Generation Using a Graph Generative Adversarial Network and Differentiable Rendering,"Novel photo-realistic texture synthesis is an important task for generating novel scenes, including asset generation for 3D simulations. However, to date, these methods predominantly generate textured objects in 2D space. If we rely on 2D object generation, then we need to make a computationally expensive forward pass each time we change the camera viewpoint or lighting. Recent work that can generate textures in 3D requires 3D component segmentation that is expensive to acquire. In this work, we present a novel conditional generative architecture that we call a graph generative adversarial network (GGAN) that can generate textures in 3D by learning object component information in an unsupervised way. In this framework, we do not need an expensive forward pass whenever the camera viewpoint or lighting changes, and we do not need expensive 3D part information for training, yet the model can generalize to unseen 3D meshes and generate appropriate novel 3D textures. We compare this approach against state-of-the-art texture generation methods and demonstrate that the GGAN obtains significantly better texture generation quality (according to Fréchet inception distance). We release our model source code as open source (https://github.com/ml4ai/ggan ). © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147995861&doi=10.1007%2f978-3-031-25825-1_28&partnerID=40&md5=b11c4ec9734ae1abfecbe765bc07621c,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Wu H.; Liu G.,Split-merge-excitation: a robust channel-wise feature attention mechanism applied to MDNet tracking,"Object tracking is a fundamental problem of computer vision. Although being studied for decades, the single object tracking problem has not been completely solved, since there exist various challenges in the real physical world, such as object deformation, complex background and imperfect imaging, which make tracking difficult. For these challenges, we design a robust feature extraction network. Specifically, we propose a novel channel-wise feature attention mechanism, which is integrated into the pipeline of a well-known convolutional neural network based visual tracking algorithm. It is crucial to represent the object robustly. Due to the representative feature, the tracking performance is improved. In experiments, we test the proposed tracking algorithm in OTB100, VOT2018, VOT2020 and VOT-TIR datasets. Compared to the baseline algorithm, our proposed algorithm obtains consistent performance improvement for different benchmarks with absolute increase of tracking success score in OTB100 up to 0.6, and absolute increase of EAO up to 0.022, 0.007, and 0.008 in VOT2018, VOT2020, VOT-TIR2015 respectively. The source codes are publicly available. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132626928&doi=10.1007%2fs11042-022-12752-z&partnerID=40&md5=4599bdec3c2f3975de85653efad1324a,Multimedia Tools and Applications,Exclude,,,
Zhang B.; Xiao J.; Jiao J.; Wei Y.; Zhao Y.,Affinity Attention Graph Neural Network for Weakly Supervised Semantic Segmentation,"Weakly supervised semantic segmentation is receiving great attention due to its low human annotation cost. In this paper, we aim to tackle bounding box supervised semantic segmentation, i.e., training accurate semantic segmentation models using bounding box annotations as supervision. To this end, we propose affinity attention graph neural network (A2GNN). Following previous practices, we first generate pseudo semantic-aware seeds, which are then formed into semantic graphs based on our newly proposed affinity Convolutional Neural Network (CNN). Then the built graphs are input to our A2GNN, in which an affinity attention layer is designed to acquire the short- and long- distance information from soft graph edges to accurately propagate semantic labels from the confident seeds to the unlabeled pixels. However, to guarantee the precision of the seeds, we only adopt a limited number of confident pixel seed labels for A2GNN, which may lead to insufficient supervision for training. To alleviate this issue, we further introduce a new loss function and a consistency-checking mechanism to leverage the bounding box constraint, so that more reliable guidance can be included for the model optimization. Experiments show that our approach achieves new state-of-the-art performances on Pascal VOC 2012 datasets (val: 76.5 percent, test: 75.2 percent). More importantly, our approach can be readily applied to bounding box supervised instance segmentation task or other weakly supervised semantic segmentation tasks, with state-of-the-art or comparable performance among almot all weakly supervised tasks on PASCAL VOC or COCO dataset. Our source code will be available at https://github.com/zbf1991/A2GNN.  © 1979-2012 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107194391&doi=10.1109%2fTPAMI.2021.3083269&partnerID=40&md5=f0631c776f4807c962cce2c9420fdeee,IEEE Transactions on Pattern Analysis and Machine Intelligence,Exclude,,Exclude,
Liu J.; Zeng J.; Wang X.; Ji K.; Liang Z.,TeLL: Log level suggestions via modeling multi-level code block information,"Developers insert logging statements into source code to monitor system execution, which forms the basis for software debugging and maintenance. For distinguishing diverse runtime information, each software log is assigned with a separate verbosity level (e.g., trace and error). However, choosing an appropriate verbosity level is a challenging and error-prone task due to the lack of specifications for log level usages. Prior solutions aim to suggest log levels based on the code block in which a logging statement resides (i.e., intra-block features). Such suggestions, however, do not consider information from surrounding blocks (i.e., inter-block features), which also plays an important role in revealing logging characteristics. To address this issue, we combine multiple levels of code block information (i.e., intra-block and inter-block features) into a joint graph structure called Flow of Abstract Syntax Tree (FAST). To explicitly exploit multi-level block features, we design a new neural architecture, Hierarchical Block Graph Network (HBGN), on the FAST. In particular, it leverages graph neural networks to encode both the intra-block and inter-block features into code block representations and guide log level suggestions. We implement a prototype system, TeLL, and evaluate its effectiveness on nine large-scale software systems. Experimental results showcase TeLL's advantage in predicting log levels over the state-of-the-art approaches.  © 2022 Owner/Author.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136803982&doi=10.1145%2f3533767.3534379&partnerID=40&md5=2e89b0ce740145a39cccfbfc5c613c53,ISSTA 2022 - Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis,Include,,,
Ye J.-X.; Wen X.-C.; Wang X.-Z.; Xu Y.; Luo Y.; Wu C.-L.; Chen L.-Y.; Liu K.-H.,GM-TCNet: Gated Multi-scale Temporal Convolutional Network using Emotion Causality for Speech Emotion Recognition,"In human-computer interaction, Speech Emotion Recognition (SER) plays an essential role in understanding the user's intent and improving the interactive experience. While similar sentimental speeches own diverse speaker characteristics but share common antecedents and consequences, an essential challenge for SER is how to produce robust and discriminative representations through causality between speech emotions. In this paper, we propose a Gated Multi-scale Temporal Convolutional Network (GM-TCNet) to construct a novel emotional causality repre- sentation learning component with a multi-scale receptive field. GM-TCNet deploys a novel emotional causality representation learning component to capture the dynamics of emotion across the time domain, constructed with dilated causal convolutions layer and gating mechanism. Besides, it utilizes skip connection fusing high-level fea- tures from different Gated Convolution Blocks (GCB) to capture abundant and subtle emotion changes in human speech. GM-TCNet first uses a single type of feature, Mel-Frequency Cepstral Coefficients (MFCC), as inputs and then passes them through the Gated Temporal Convolutional Module (GTCM) to generate the high-level fea- tures. Finally, the features are fed to the emotion classifier to accomplish the SER task. The experimental results show that our model maintains the highest performance in most cases, with +0.90% to +18.50% and +0.55% to +20.15% average relative improvement on the weighted average recall and unweighted average recall compared to state-of-the-art techniques. The source code is available at: https://github.com/Jiaxin-Ye/GM-TCNet for SER. © 2022",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139868003&doi=10.1016%2fj.specom.2022.07.005&partnerID=40&md5=b2270e7d89c6f48640652e7a40dc0e53,Speech Communication,Exclude,,,
Cao Y.; Liang R.; Chen K.; Hu P.,Boosting Neural Networks to Decompile Optimized Binaries,"Decompilation aims to transform a low-level program language (LPL) (eg., binary file) into its functionally-equivalent high-level program language (HPL) (e.g., C/C++). It is a core technology in software security, especially in vulnerability discovery and malware analysis. In recent years, with the successful application of neural machine translation (NMT) models in natural language processing (NLP), researchers have tried to build neural decompilers by borrowing the idea of NMT. They formulate the decompilation process as a translation problem between LPL and HPL, aiming to reduce the human cost required to develop decompilation tools and improve their generalizability. However, state-of-the-art learning-based decompilers do not cope well with compiler-optimized binaries. Since real-world binaries are mostly compiler-optimized, decompilers that do not consider optimized binaries have limited practical significance. In this paper, we propose a novel learning-based approach named NeurDP, that targets compiler-optimized binaries. NeurDP uses a graph neural network (GNN) model to convert LPL to an intermediate representation (IR), which bridges the gap between source code and optimized binary. We also design an Optimized Translation Unit (OTU) to split functions into smaller code fragments for better translation performance. Evaluation results on datasets containing various types of statements show that NeurDP can decompile optimized binaries with 45.21% higher accuracy than state-of-the-art neural decompilation frameworks.  © 2022 Owner/Author.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144089223&doi=10.1145%2f3564625.3567998&partnerID=40&md5=c1fb648ed6fbae83b6263f0e67f9780b,ACM International Conference Proceeding Series,Exclude,,,
Guan W.; Jiao F.; Song X.; Wen H.; Yeh C.-H.; Chang X.,Personalized Fashion Compatibility Modeling via Metapath-guided Heterogeneous Graph Learning,"Fashion Compatibility Modeling (FCM) is a new yet challenging task, which aims to automatically access the matching degree among a set of complementary items. Most of existing methods evaluate the fashion compatibility from the common perspective, but overlook the user's personal preference. Inspired by this, a few pioneers study the Personalized Fashion Compatibility Modeling (PFCM). Despite their significance, these PFCM methods mainly concentrate on the user and item entities, as well as their interactions, but ignore the attribute entities, which contain rich semantics. To address this problem, we propose to fully explore the related entities and their relations involved in PFCM to boost the PFCM performance. This is, however, non-trivial due to the heterogeneous contents of different entities, embeddings for new users, and various high-order relations. Towards these ends, we present a novel metapath-guided personalized fashion compatibility modeling, dubbed as MG-PFCM. In particular, we creatively build a heterogeneous graph to unify the three types of entities (i.e., users, items, and attributes) and their relations (i.e., user-item interactions, item-item matching relations, and item-attribute association relations). Thereafter, we design a multi-modal content-oriented user embedding module to learn user representations by inheriting the contents of their interacted items. Meanwhile, we define the user-oriented and item-oriented metapaths, and perform the metapath-guided heterogeneous graph learning to enhance the user and item embeddings. In addition, we introduce the contrastive regularization to improve the model performance. We conduct extensive experiments on the real-world benchmark dataset, which verifies the superiority of our proposed scheme over several cutting-edge baselines. As a byproduct, we have released our source codes to benefit other researchers. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135093930&doi=10.1145%2f3477495.3532038&partnerID=40&md5=ed6a9fcea29811de37b76cbc9b288eac,SIGIR 2022 - Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval,Exclude,,,
Dong Y.; Wang S.; Wang Y.; Derr T.; Li J.,On Structural Explanation of Bias in Graph Neural Networks,"Graph Neural Networks (GNNs) have shown satisfying performance in various graph analytical problems. Hence, they have become the de facto solution in a variety of decision-making scenarios. However, GNNs could yield biased results against certain demographic subgroups. Some recent works have empirically shown that the biased structure of the input network is a significant source of bias for GNNs. Nevertheless, no studies have systematically scrutinized which part of the input network structure leads to biased predictions for any given node. The low transparency on how the structure of the input network influences the bias in GNN outcome largely limits the safe adoption of GNNs in various decision-critical scenarios. In this paper, we study a novel research problem of structural explanation of bias in GNNs. Specifically, we propose a novel post-hoc explanation framework to identify two edge sets that can maximally account for the exhibited bias and maximally contribute to the fairness level of the GNN prediction for any given node, respectively. Such explanations not only provide a comprehensive understanding of bias/fairness of GNN predictions but also have practical significance in building an effective yet fair GNN model. Extensive experiments on real-world datasets validate the effectiveness of the proposed framework towards delivering effective structural explanations for the bias of GNNs. Open-source code can be found at https://github.com/yushundong/REFEREE.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132151669&doi=10.1145%2f3534678.3539319&partnerID=40&md5=a2fd6acb05f7e6827cb3a6e039ad512d,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Exclude,,Exclude,
Li L.; Liu Y.,Mapping Modern JVM Language Code to Analysis-Friendly Graphs: A Study with Kotlin,"Kotlin is a modern JVM language, gaining adoption rapidly and becoming Android official programming language. With its wide usage, the need for code analysis of Kotlin is increasing. Exposing code semantics explicitly with a properly structured format is the first step in code analysis and the construction of such representation is the foundation for downstream tasks. Recently, graph-based approaches became a promising way of encoding source code semantics. However, this work mainly focuses on representation learning with limited interpretability and shallow domain knowledge. The known evolvements of code semantics in new-generation programming languages have been overlooked. How to establish an effective mapping between naturally concise Kotlin source code with graph-based representation needs to be studied by analyzing known language features. Moreover, the feasibility of enhancing the mapping with code semantics automatically learned from the program needs to be explored. In this paper, we first propose a first-sight, rule-based mapping method, using composite representation with AST, CFG, DFG and language features. To examine the possibility of exposing code semantics in the mapped graph, we use Latent Semantic Indexing-based source code summarization to learn more features of each method, and then enrich the attributes of the corresponding node in the graph. We evaluate these mapping strategies with comparative experiments by simulating a code search solution as a downstream task. The experiment result shows that the graph-based method with built-in language features outperforms the text-based way without introducing greater complexity. Comparative experiments also prove that adding code semantics to the graph benefits the capacity of downstream tasks. When exploring the whole mapping process, our study explicitly revealed the practical barriers to extracting and exposing the hidden semantics from Kotlin source code, which may help enlighten source code representations for other modern languages.  © 2022 World Scientific Publishing Company.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144497191&doi=10.1142%2fS0218194022500735&partnerID=40&md5=552d52eb6536340eec206e9b7c0a31ab,International Journal of Software Engineering and Knowledge Engineering,Exclude,,,
Nie L.; Liu L.; Wu Z.; Kang W.,Unconstrained face sketch synthesis via perception-adaptive network and a new benchmark,"Face sketch generation has attracted much attention in the field of visual computing. However, existing methods either are limited to constrained conditions or heavily rely on various preprocessing steps to deal with in-the-wild cases. In this paper, we argue that accurately perceiving facial region and facial components is crucial for unconstrained sketch synthesis. To this end, we propose a novel Perception-Adaptive Network (PANet), which can generate high-quality face sketches under unconstrained conditions in an end-to-end scheme. Specifically, our PANet is composed of: i) a Fully Convolutional Encoder for hierarchical feature extraction, ii) a Face-Adaptive Perceiving Decoder for extracting potential facial region and handling face variations, and iii) a Component-Adaptive Perceiving Module for facial component aware feature representation learning. To facilitate further researches of unconstrained face sketch synthesis, we introduce a new benchmark termed WildSketch, which contains 800 pairs of face photo-sketch with large variations in pose, expression, ethnic origin, background, and illumination. Extensive experiments demonstrate that the proposed method is capable of achieving state-of-the-art performance under both constrained and unconstrained conditions. Our source codes and the WildSketch benchmark are resealed on the project page http://lingboliu.com/unconstrained_face_sketch.html. © 2022",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129045271&doi=10.1016%2fj.neucom.2022.04.077&partnerID=40&md5=123fd3ecc58f3165b45a57aab9460a60,Neurocomputing,Exclude,,,
Chen C.; Chen X.; Morehead A.; Wu T.; Cheng J.,3D-equivariant graph neural networks for protein model quality assessment,"MOTIVATION: Quality assessment (QA) of predicted protein tertiary structure models plays an important role in ranking and using them. With the recent development of deep learning end-to-end protein structure prediction techniques for generating highly confident tertiary structures for most proteins, it is important to explore corresponding QA strategies to evaluate and select the structural models predicted by them since these models have better quality and different properties than the models predicted by traditional tertiary structure prediction methods. RESULTS: We develop EnQA, a novel graph-based 3D-equivariant neural network method that is equivariant to rotation and translation of 3D objects to estimate the accuracy of protein structural models by leveraging the structural features acquired from the state-of-the-art tertiary structure prediction method-AlphaFold2. We train and test the method on both traditional model datasets (e.g. the datasets of the Critical Assessment of Techniques for Protein Structure Prediction) and a new dataset of high-quality structural models predicted only by AlphaFold2 for the proteins whose experimental structures were released recently. Our approach achieves state-of-the-art performance on protein structural models predicted by both traditional protein structure prediction methods and the latest end-to-end deep learning method-AlphaFold2. It performs even better than the model QA scores provided by AlphaFold2 itself. The results illustrate that the 3D-equivariant graph neural network is a promising approach to the evaluation of protein structural models. Integrating AlphaFold2 features with other complementary sequence and structural features is important for improving protein model QA. AVAILABILITY AND IMPLEMENTATION: The source code is available at https://github.com/BioinfoMachineLearning/EnQA. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online. © The Author(s) 2023. Published by Oxford University Press.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147094507&doi=10.1093%2fbioinformatics%2fbtad030&partnerID=40&md5=b76351ec01c6bf3bb2158419a26c1691,"Bioinformatics (Oxford, England)",Exclude,,Exclude,
Chen Z.; Rezayi S.; Li S.,"More Knowledge, Less Bias: Unbiasing Scene Graph Generation with Explicit Ontological Adjustment","Scene graph generation (SGG) models seek to detect relationships between objects in a given image. One challenge in this area is the biased distribution of predicates in the dataset and the semantic space. Recent works incorporating knowledge graphs with scene graphs prove effective in improving recall for the tail predicate classes. Moreover, many recent SGG approaches with promising results explicitly redistribute the predicates in both the training process and in the prediction step. To incorporate external knowledge, we construct a commonsense knowledge graph by integrating ConceptNet and Wikidata. To explicitly unbias SGG with knowledge in the reasoning process, we propose a novel framework, Explicit Ontological Adjustment (EOA), to adjust the graph model predictions with knowledge priors. We use the edge matrix from the commonsense knowledge graph as a module in the graph neural network model to refine the relationship detection process. This module proves effective in alleviating the long-tail distribution of predicates. When combined, we show that these modules achieve state-of-the-art performance on the Visual Genome dataset in most cases. The source code is available at https://github.com/zhanwenchen/eoa. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149020592&doi=10.1109%2fWACV56688.2023.00401&partnerID=40&md5=b65f8170f36c21c0cf694b5d5a5e93b3,"Proceedings - 2023 IEEE Winter Conference on Applications of Computer Vision, WACV 2023",Exclude,,Exclude,
Qian Y.; Zhang Y.; Wen Q.; Ye Y.; Zhang C.,Rep2Vec: Repository Embedding via Heterogeneous Graph Adversarial Contrastive Learning,"Driven by the exponential increase of software and the advent of the pull-based development system Git, a large amount of open-source software has emerged on various social coding platforms. GitHub, as the largest platform, not only attracts developers and researchers to contribute legitimate software and research-related source code but has also become a popular platform for an increasing number of cybercriminals to perform continuous cyberattacks. Hence, some tools have been developed to learn representations of repositories on GitHub for various related applications (e.g., malicious repository detection) recently. However, most of them merely focus on code content while ignoring the rich relational data among repositories. In addition, they usually require a mass of resources to obtain sufficient labeled data for model training while ignoring the usefully handy unlabeled data. To this end, we propose a novel model Rep2Vec which integrates the code content, the structural relations, and the unlabeled data to learn the repository representations. First, to comprehensively model the repository data, we build a repository heterogeneous graph (Rep-HG) which is encoded by a graph neural network. Afterwards, to fully exploit unlabeled data in Rep-HG, we introduce adversarial attacks to generate more challenging contrastive pairs for the contrastive learning module to train the encoder in node view and meta-path view simultaneously. To alleviate the workload of the encoder against attacks, we further design a dual-stream contrastive learning module that integrates contrastive learning on adversarial graph and original graph together. Finally, the pre-trained encoder is fine-tuned to the downstream task, and further enhanced by a knowledge distillation module. Extensive experiments on the collected dataset from GitHub demonstrate the effectiveness of Rep2Vec in comparison with state-of-the-art methods for multiple repository tasks.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137142998&doi=10.1145%2f3534678.3539324&partnerID=40&md5=c3c7c70d0cdcdb6b01b1b244a0b4d5a9,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Include,,,
Hovenga V.; Kalita J.; Oluwadare O.,HiC-GNN: A generalizable model for 3D chromosome reconstruction using graph convolutional neural networks,"Chromosome conformation capture (3 C) is a method of measuring chromosome topology in terms of loci interaction. The Hi-C method is a derivative of 3 C that allows for genome-wide quantification of chromosome interaction. From such interaction data, it is possible to infer the three-dimensional (3D) structure of the underlying chromosome. In this paper, we developed a novel method, HiC-GNN, for predicting the 3D structures of chromosomes from Hi-C data. HiC-GNN is unique from other methods for chromosome structure prediction in that the models learned by HiC-GNN can be generalized to data that is distinct from the training data. This aspect of HiC-GNN allows models that were trained on one Hi-C contact map to be used for inference on entirely different maps. To the authors’ knowledge, this generalizing capability is not present in any existing methods. HiC-GNN uses a node embedding algorithm and a graph neural network to predict the 3D coordinates of each genomic loci from the corresponding Hi-C contact data. Unlike other methods, our algorithm allows for the storage of pre-trained parameters, thus enabling prediction on data that is entirely different from the training data. We show that our method can accurately generalize a single model across Hi-C resolutions, multiple restriction enzymes, and multiple cell populations while maintaining reconstruction accuracy across three Hi-C datasets. Our algorithm outperforms the state-of-the-art methods in accuracy of prediction and runtime and introduces a novel method for 3D structure prediction from Hi-C data. All our source codes and data are available at https://github.com/OluwadareLab/HiC-GNN. © 2023 The Authors",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146233275&doi=10.1016%2fj.csbj.2022.12.051&partnerID=40&md5=d5548ec79c0dbbc130ccf98878faf50e,Computational and Structural Biotechnology Journal,Exclude,,,
Chrysos G.G.; Moschoglou S.; Bouritsas G.; Deng J.; Panagakis Y.; Zafeiriou S.,Deep Polynomial Neural Networks,"Deep convolutional neural networks (DCNNs) are currently the method of choice both for generative, as well as for discriminative learning in computer vision and machine learning. The success of DCNNs can be attributed to the careful selection of their building blocks (e.g., residual blocks, rectifiers, sophisticated normalization schemes, to mention but a few). In this paper, we propose Π-Nets, a new class of function approximators based on polynomial expansions. Π-Nets are polynomial neural networks, i.e., the output is a high-order polynomial of the input. The unknown parameters, which are naturally represented by high-order tensors, are estimated through a collective tensor factorization with factors sharing. We introduce three tensor decompositions that significantly reduce the number of parameters and show how they can be efficiently implemented by hierarchical neural networks. We empirically demonstrate that Π-Nets are very expressive and they even produce good results without the use of non-linear activation functions in a large battery of tasks and signals, i.e., images, graphs, and audio. When used in conjunction with activation functions, Π-Nets produce state-of-the-art results in three challenging tasks, i.e., image generation, face verification and 3D mesh representation learning. The source code is available at https://github.com/grigorisg9gr/polynomial_nets.  © 1979-2012 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100853802&doi=10.1109%2fTPAMI.2021.3058891&partnerID=40&md5=85454660a13bece0b61549bab3ca0d33,IEEE Transactions on Pattern Analysis and Machine Intelligence,Exclude,,Exclude,
Chinery L.; Wahome N.; Moal I.; Deane C.M.,Paragraph-antibody paratope prediction using graph neural networks with minimal feature vectors,"SUMMARY: The development of new vaccines and antibody therapeutics typically takes several years and requires over $1bn in investment. Accurate knowledge of the paratope (antibody binding site) can speed up and reduce the cost of this process by improving our understanding of antibody-antigen binding. We present Paragraph, a structure-based paratope prediction tool that outperforms current state-of-the-art tools using simpler feature vectors and no antigen information. AVAILABILITY AND IMPLEMENTATION: Source code is freely available at www.github.com/oxpig/Paragraph. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online. © The Author(s) 2022. Published by Oxford University Press.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145425840&doi=10.1093%2fbioinformatics%2fbtac732&partnerID=40&md5=b759fdd0895cac8f6bd1bfe163558282,"Bioinformatics (Oxford, England)",Exclude,,,
Kim H.; Park M.; Lee I.; Nam H.,"BayeshERG: a robust, reliable and interpretable deep learning model for predicting hERG channel blockers","Unintended inhibition of the human ether-à-go-go-related gene (hERG) ion channel by small molecules leads to severe cardiotoxicity. Thus, hERG channel blockage is a significant concern in the development of new drugs. Several computational models have been developed to predict hERG channel blockage, including deep learning models; however, they lack robustness, reliability and interpretability. Here, we developed a graph-based Bayesian deep learning model for hERG channel blocker prediction, named BayeshERG, which has robust predictive power, high reliability and high resolution of interpretability. First, we applied transfer learning with 300 000 large data in initial pre-training to increase the predictive performance. Second, we implemented a Bayesian neural network with Monte Carlo dropout to calibrate the uncertainty of the prediction. Third, we utilized global multihead attentive pooling to augment the high resolution of structural interpretability for the hERG channel blockers and nonblockers. We conducted both internal and external validations for stringent evaluation; in particular, we benchmarked most of the publicly available hERG channel blocker prediction models. We showed that our proposed model outperformed predictive performance and uncertainty calibration performance. Furthermore, we found that our model learned to focus on the essential substructures of hERG channel blockers via an attention mechanism. Finally, we validated the prediction results of our model by conducting in vitro experiments and confirmed its high validity. In summary, BayeshERG could serve as a versatile tool for discovering hERG channel blockers and helping maximize the possibility of successful drug discovery. The data and source code are available at our GitHub repository (https://github.com/GIST-CSBL/BayeshERG).  © 2022 The Author(s). Published by Oxford University Press. All rights reserved.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134721122&doi=10.1093%2fbib%2fbbac211&partnerID=40&md5=15e61acb427ddf9a673a052240d50781,Briefings in Bioinformatics,Exclude,,,
Somashekar G.; Dutt A.; Vaddavalli R.; Varanasi S.B.; Gandhi A.,B-Meg: Bottlenecked-microservices extraction using graph neural networks,"The microservices architecture enables independent development and maintenance of application components through its fine-grained and modular design. This has enabled rapid adoption of microservices architecture to build latency-sensitive online applications. In such online applications, it is critical to detect and mitigate sources of performance degradation (bottlenecks). However, the modular design of microservices architecture leads to a large graph of interacting microservices whose influence on each other is non-trivial. In this preliminary work, we explore the effectiveness of Graph Neural Network models in detecting bottlenecks. Preliminary analysis shows that our framework, B-MEG, produces promising results, especially for applications with complex call graphs. B-MEG shows up to 15% and 14% improvements in accuracy and precision, respectively, and close to 10× increase in recall for detecting bottlenecks compared to the technique used in existing work for bottleneck detection in microservices.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136030379&doi=10.1145%2f3491204.3527494&partnerID=40&md5=a4a3c4a45e2a915b9b593acdfe0b956d,ICPE 2022 - Companion of the 2022 ACM/SPEC International Conference on Performance Engineering,Include,,,
Zhao K.; Liu J.; Xu Z.; Liu X.; Xue L.; Xie Z.; Zhou Y.; Wang X.,Graph4Web: A relation-aware graph attention network for web service classification,"Software reuse is a popular way to utilize existing software components to ensure the quality of newly developed software in service-oriented architecture. However, how to find a suitable web service from existing repositories to meet requirements is still an open issue. Among others, web service classification is one of the most essential and effective means for web service recommendation. Previous studies have concerned this problem, but a critical issue, i.e., the semantic and syntactic information for the web service, is often ignored. To address such an issue, in this work, we propose Graph4Web, which uses a relation-aware graph attention network for web service classification. Specifically, we first parse the web service description sequence into the dependency graph and initialize the embedding vector of each node in the graph by tuning the pre-trained BERT model. We further propose a relation-aware graph attention layer to learn and update the node embedding vector by aggregating the information of neighborhood nodes and the distinct types of relationships between nodes. In addition, we introduce the self-attention mechanism to acquire the high-level global representation for web service classification. Various experiments demonstrate that Graph4Web has better classification performance compared with seven baseline methods with three indicators. © 2022 Elsevier Inc.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129456347&doi=10.1016%2fj.jss.2022.111324&partnerID=40&md5=d1ee3c4d7db360934c312053a0be1dee,Journal of Systems and Software,Include,,,
Zhuang Y.; Zhang Z.; Liu D.,Towards high-quality CGRA mapping with graph neural networks and reinforcement learning,"Coarse-Grained Reconfigurable Architectures (CGRA) is a promising solution to accelerate domain applications due to its good combination of energy-efficiency and flexibility. Loops, as computationintensive parts of applications, are often mapped onto CGRA and modulo scheduling is commonly used to improve the execution performance. However, the actual performance using modulo scheduling is highly dependent on the mapping ability of the Data Dependency Graph (DDG) extracted from a loop. As existing approaches usually separate routing exploration of multi-cycle dependence from mapping for fast compilation, they may easily suffer from poor mapping quality. In this paper, we integrate the routing explorations into the mapping process and make it have more opportunities to find a globally optimized solution. Meanwhile, with a reduced resource graph defined, the searching space of the new mapping problem is not greatly increased. To efficiently solve the problem, we introduce graph neural network based reinforcement learning to predict a placement distribution over different resource nodes for all operations in a DDG. Using the routing connectivity as the reward signal, we optimize the parameters of neural network to find a valid mapping solution with a policy gradient method. Without much engineering and heuristic designing, our approach achieves 1.57× mapping quality, as compared to the state-of-the-art heuristic.  © 2022 Association for Computing Machinery.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145653777&doi=10.1145%2f3508352.3549458&partnerID=40&md5=cf15c34e89b2c44ab681e01d0c442e19,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",Exclude,,,
Tang C.; Hu C.; Sun J.; Wang S.-H.; Zhang Y.-D.,NSCGCN: A novel deep GCN model to diagnosis COVID-19,"Aim: Corona Virus Disease 2019 (COVID-19) was a lung disease with high mortality and was highly contagious. Early diagnosis of COVID-19 and distinguishing it from pneumonia was beneficial for subsequent treatment. Objectives: Recently, Graph Convolutional Network (GCN) has driven a significant contribution to disease diagnosis. However, limited by the nature of the graph convolution algorithm, deep GCN has an over-smoothing problem. Most of the current GCN models are shallow neural networks, which do not exceed five layers. Furthermore, the objective of this study is to develop a novel deep GCN model based on the DenseGCN and the pre-trained model of deep Convolutional Neural Network (CNN) to complete the diagnosis of chest X-ray (CXR) images. Methods: We apply the pre-trained model of deep CNN to perform feature extraction on the data to complete the extraction of pixel-level features in the image. And then, to extract the potential relationship between the obtained features, we propose Neighbourhood Feature Reconstruction Algorithm to reconstruct them into graph-structured data. Finally, we design a deep GCN model that exploits the graph-structured data to diagnose COVID-19 effectively. In the deep GCN model, we propose a Node-Self Convolution Algorithm (NSC) based on feature fusion to construct a deep GCN model called NSCGCN (Node-Self Convolution Graph Convolutional Network). Results: Experiments were carried out on the Computed Tomography (CT) and CXR datasets. The results on the CT dataset confirmed that: compared with the six state-of-the-art (SOTA) shallow GCN models, the accuracy and sensitivity of the proposed NSCGCN had improve 8% as sensitivity (Sen.) = 87.50%, F1 score = 97.37%, precision (Pre.) = 89.10%, accuracy (Acc.) = 97.50%, area under the ROC curve (AUC) = 97.09%. Moreover, the results on the CXR dataset confirmed that: compared with the fourteen SOTA GCN models, sixteen SOTA CNN transfer learning models and eight SOTA COVID-19 diagnosis methods on the COVID-19 dataset. Our proposed method had best performances as Sen. = 96.45%, F1 score = 96.45%, Pre. = 96.61%, Acc. = 96.45%, AUC = 99.22%. Conclusion: Our proposed NSCGCN model is effective and performed better than the thirty-eight SOTA methods. Thus, the proposed NSC could help build deep GCN models. Our proposed COVID-19 diagnosis method based on the NSCGCN model could help radiologists detect pneumonia from CXR images and distinguish COVID-19 from Ordinary Pneumonia (OPN). The source code of this work will be publicly available at https://github.com/TangChaosheng/NSCGCN. © 2022 The Authors",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139835126&doi=10.1016%2fj.compbiomed.2022.106151&partnerID=40&md5=36571fd78028d4c7fe05cc3901d63ebb,Computers in Biology and Medicine,Exclude,,Exclude,
Tang Y.; Yan J.,GraphQNTK: Quantum Neural Tangent Kernel for Graph Data,"Graph Neural Networks (GNNs) and Graph Kernels (GKs) are two fundamental tools used to analyze graph-structured data. Efforts have been recently made in developing a composite graph learning architecture combining the expressive power of GNNs and the transparent trainability of GKs. However, learning efficiency on these models should be carefully considered as the huge computation overhead. Besides, their convolutional methods are often straightforward and introduce severe loss of graph structure information. In this paper, we design a novel quantum graph learning model to characterize the structural information while using quantum parallelism to improve computing efficiency. Specifically, a quantum algorithm is proposed to approximately estimate the neural tangent kernel of the underlying graph neural network where a multi-head quantum attention mechanism is introduced to properly incorporate semantic similarity information of nodes into the model. We empirically show that our method achieves competitive performance on several graph classification benchmarks, and theoretical analysis is provided to demonstrate the superiority of our quantum algorithm. Source code is available at https://github.com/abel1231/graphQNTK. © 2022 Neural information processing systems foundation. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152374390&partnerID=40&md5=e2b854a1510214bff5a83d4db441ceff,Advances in Neural Information Processing Systems,Exclude,,,
Lee N.; Lee J.; Park C.,Augmentation-Free Self-Supervised Learning on Graphs,"Inspired by the recent success of self-supervised methods applied on images, self-supervised learning on graph structured data has seen rapid growth especially centered on augmentation-based contrastive methods. However, we argue that without carefully designed augmentation techniques, augmentations on graphs may behave arbitrarily in that the underlying semantics of graphs can drastically change. As a consequence, the performance of existing augmentation-based methods is highly dependent on the choice of augmentation scheme, i.e., hyperparameters associated with augmentations. In this paper, we propose a novel augmentation-free self-supervised learning framework for graphs, named AFGRL. Specifically, we generate an alternative view of a graph by discovering nodes that share the local structural information and the global semantics with the graph. Extensive experiments towards various node-level tasks, i.e., node classification, clustering, and similarity search on various real-world datasets demonstrate the superiority of AFGRL. The source code for AFGRL is available at https://github.com/Namkyeong/AFGRL. © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147697223&partnerID=40&md5=7eba50dd402dca5e679b4aa99d10666e,"Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022",Exclude,,,
Qin M.; Zhang Z.; Zhou X.,Disentangled representation learning GANs for generalized and stable font fusion network,"Automatic generation of calligraphy fonts has attracted broad attention of researchers. However, previous font generation research mainly focused on the known font style imitation based on image to image translation. For poor interpretability, it is hard for deep learning to create new fonts with various font styles and features according to human understanding. To address this issue, the font fusion network based on generative adversarial networks (GANs) and disentangled representation learning is proposed in this paper to generate brand new fonts. It separates font into two understandable disentangled features: stroke style and skeleton shape. According to personal preferences, various new fonts with multiple styles can be generated by fusing the stroke style and skeleton shape of different fonts. First, this task improves the interpretability of deep learning, and is more challenging than simply imitating font styles. Second, considering the robustness of the network, a fuzzy supervised learning skill is proposed to enhance the stability of the fusion of two fonts with considerable discrepancy. Finally, instead of retraining, the authors' trained model can be quickly transferred to other font fusion samples. It improves the efficiency of the model. Qualitative and quantitative results demonstrate that the proposed method is capable of efficiently and stably generating the new font images with multiple styles. The source code and the implementation details of our model are available at https://github.com/Qinmengxi/Fontfusion. © 2021 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116555170&doi=10.1049%2fipr2.12355&partnerID=40&md5=134ffed5d67321b0dde8a34f2f343328,IET Image Processing,Exclude,,,
Boukhtouta A.; Madi T.; Pourzandi M.; Hyame Alameddine A.,Cloud Native Applications Profiling using a Graph Neural Networks Approach,"The convergence of Telecommunication and industry operational networks towards cloud native applications has enabled the idea to integrate protection layers to harden security posture and management of cloud native based deployments. In this paper, we propose a data-driven approach to support detection of anomalies in cloud native application based on a graph neural network. The essence of the profiling relies on capturing interactions between different perspectives in cloud native applications through a network dependency graph and transforming it to a computational graph neural network. The latter is used to profile different deployed assets like micro-service types, workloads' namespaces, worker machines, management and orchestration machines as well as clusters. As a first phase of the profiling, we consider a fine-grained profiling on microservice types with an emphasis on network traffic indicators. These indicators are collected on distributed Kubernetes (K8S) deployment premises. Experimental results shows good trade-off in terms of accuracy and recall with respect to micro-service types profiling (around 96%). In addition, we used predictions entropy scores to infer anomalies in testing data. These scores allow to segregate between benign and anomalous graphs, where we identified 19 out of 23 anomalies. Moreover, by using entropy scores, we can conduct a root cause analysis to infer problematic micro-services.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150299535&doi=10.1109%2fFNWF55208.2022.00046&partnerID=40&md5=35ccde9af84a68a5ce4a32ae1e277032,"Proceedings - 2022 IEEE Future Networks World Forum, FNWF 2022",Exclude,,,
Ding K.; Li J.; Chawla N.; Liu H.,Graph minimally-supervised learning,"Graphs are widely used for abstracting complex systems of interacting objects, such as social networks, knowledge graphs, and traffic networks, as well as for modeling molecules, manifolds, and source code. To model such graph-structured data, graph learning, in particular deep graph learning with graph neural networks, has drawn much attention in both academic and industrial communities lately. Prevailing graph learning methods usually rely on learning from ""big'' data, requiring a large amount of labeled data for model training. However, it is common that graphs are associated with ""small'' labeled data as data annotation and labeling on graphs is always time and resource-consuming. Therefore, it is imperative to investigate graph learning with minimal human supervision for the low-resource settings where limited or even no labeled data is available. In this tutorial, we will focus on the state-of-the-art techniques of Graph Minimally-supervised Learning, in particular a series of weakly-supervised learning, few-shot learning, and self-supervised learning methods on graph-structured data as well as their real-world applications. The objectives of this tutorial are to: (1) formally categorize the problems in graph minimally-supervised learning and discuss the challenges under different learning scenarios; (2) comprehensively review the existing and recent advances of graph minimally-supervised learning; and (3) elucidate open questions and future research directions. This tutorial introduces major topics within minimally-supervised learning and offers a guide to a new frontier of graph learning. We believe this tutorial is beneficial to researchers and practitioners, allowing them to collaborate on graph learning. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125776501&doi=10.1145%2f3488560.3501390&partnerID=40&md5=0504a8bdd440e1741df816ad267d3d24,WSDM 2022 - Proceedings of the 15th ACM International Conference on Web Search and Data Mining,Exclude,,,
Baby B.; Chasmai M.; Banerjee T.; Suri A.; Banerjee S.; Arora C.,REPRESENTATION LEARNING USING RANK LOSS FOR ROBUST NEUROSURGICAL SKILLS EVALUATION,"Surgical simulators provide hands-on training and learning of the necessary psychomotor skills. Automated skill evaluation of the trainee doctors based on the video of a task being performed by them is an important key step for the optimal utilization of such simulators. However, current skill evaluation techniques require accurate tracking information of the instruments which restricts their applicability to robot assisted surgeries only. In this paper, we propose a novel neural network architecture that can perform skill evaluation using video data alone (and no tracking information). Given the small dataset available for training such a system, the network trained using ℓ2 regression loss easily overfits the training data. We propose a novel rank loss to help learn robust representation, leading to 5% improvement for skill score prediction on the benchmark JIGSAWS dataset. To demonstrate the applicability of our method on non-robotic surgeries, we contribute a new neuro-endoscopic technical skills (NETS) training dataset comprising of 100 short videos of 12 subjects. Our method achieved 27% improvement over the state of the art on the NETS dataset. Project page with source code, and data is available at nets-iitd.github.io/nets-v1. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146693979&doi=10.1109%2fICIP46576.2022.9897932&partnerID=40&md5=2fca7346d409d5152a58ab98a80268c1,"Proceedings - International Conference on Image Processing, ICIP",Exclude,,Exclude,
Sun Y.; Lei L.; Tan X.; Guan D.; Wu J.; Kuang G.,Structured graph based image regression for unsupervised multimodal change detection,"Change detection for multimodal remote sensing images is an important and challenging research topic with a wide range of applications in disaster assessment and environmental monitoring. To address the problem that heterogeneous images cannot be directly compared due to different imaging mechanisms, we propose an unsupervised image regression method based on the inherent structure consistency between heterogeneous images, which learns a structured graph and computes the regression image by graph projection. Firstly, the proposed method uses the self-expression property to preserve the global structure of image and uses the adaptive neighbor approach to capture the local structure of image in the graph learning process. Then, with the learned graph, two types of structure constraints are introduced into the regression model: one corresponds to the global self-expression constraint and the other corresponds to the local similarity constraint, which can be further implemented by using graph or hypergraph Laplacian based regularization. Finally, a Markov segmentation model is designed to calculate the binary change map, which combines the change information and spatial information to improve the detection accuracy. Experiments conducted on six real data sets show the effectiveness of the proposed method by comparing with five state-of-the-art algorithms, achieving 2.4%, 5.5% and 4.1% improvements in accuracy, Kappa coefficient, and F1 score respectively. Source code of the proposed method will be made available at https://github.com/yulisun/GIR-MRF. © 2022 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123030472&doi=10.1016%2fj.isprsjprs.2022.01.004&partnerID=40&md5=e9be55b978ab8687a7091c53cc61d274,ISPRS Journal of Photogrammetry and Remote Sensing,Exclude,,,
Jiang D.; Sun H.; Wang J.; Hsieh C.-Y.; Li Y.; Wu Z.; Cao D.; Wu J.; Hou T.,Out-of-the-box deep learning prediction of quantum-mechanical partial charges by graph representation and transfer learning,"Accurate prediction of atomic partial charges with high-level quantum mechanics (QM) methods suffers from high computational cost. Numerous feature-engineered machine learning (ML)-based predictors with favorable computability and reliability have been developed as alternatives. However, extensive expertise effort was needed for feature engineering of atom chemical environment, which may consequently introduce domain bias. In this study, SuperAtomicCharge, a data-driven deep graph learning framework, was proposed to predict three important types of partial charges (i.e. RESP, DDEC4 and DDEC78) derived from high-level QM calculations based on the structures of molecules. SuperAtomicCharge was designed to simultaneously exploit the 2D and 3D structural information of molecules, which was proved to be an effective way to improve the prediction accuracy of the model. Moreover, a simple transfer learning strategy and a multitask learning strategy based on self-supervised descriptors were also employed to further improve the prediction accuracy of the proposed model. Compared with the latest baselines, including one GNN-based predictor and two ML-based predictors, SuperAtomicCharge showed better performance on all the three external test sets and had better usability and portability. Furthermore, the QM partial charges of new molecules predicted by SuperAtomicCharge can be efficiently used in drug design applications such as structure-based virtual screening, where the predicted RESP and DDEC4 charges of new molecules showed more robust scoring and screening power than the commonly used partial charges. Finally, two tools including an online server (http://cadd.zju.edu.cn/deepchargepredictor) and the source code command lines (https://github.com/zjujdj/SuperAtomicCharge) were developed for the easy access of the SuperAtomicCharge services.  © 2022 The Author(s) 2022. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127551450&doi=10.1093%2fbib%2fbbab597&partnerID=40&md5=70c7bb9ab34304daa91e0a54bc5baef1,Briefings in Bioinformatics,Exclude,,,
Kupke C.; Marti J.; Venema Y.,Succinct Graph Representations of µ-Calculus Formulas,"Many algorithmic results on the modal mu-calculus use representations of formulas such as alternating tree automata or hierarchical equation systems. At closer inspection, these results are not always optimal, since the exact relation between the formula and its representation is not clearly understood. In particular, there has been confusion about the definition of the fundamental notion of the size of a mu-calculus formula. We propose the notion of a parity formula as a natural way of representing a mu-calculus formula, and as a yardstick for measuring its complexity. We discuss the close connection of this concept with alternating tree automata, hierarchical equation systems and parity games. We show that well-known size measures for mu-calculus formulas correspond to a parity formula representation of the formula using its syntax tree, subformula graph or closure graph, respectively. Building on work by Bruse, Friedmann & Lange we argue that for optimal complexity results one needs to work with the closure graph, and thus define the size of a formula in terms of its Fischer-Ladner closure. As a new observation, we show that the common assumption of a formula being clean, that is, with every variable bound in at most one subformula, incurs an exponential blow-up of the size of the closure. To realise the optimal upper complexity bound of model checking for all formulas, our main result is to provide a construction of a parity formula that (a) is based on the closure graph of a given formula, (b) preserves the alternation-depth but (c) does not assume the input formula to be clean. © Clemens Kupke, Johannes Marti, and Yde Venema.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124241076&doi=10.4230%2fLIPIcs.CSL.2022.29&partnerID=40&md5=6e4083cacfa35fdd5d815f46b19a9dfb,"Leibniz International Proceedings in Informatics, LIPIcs",Exclude,,,
Ardimento P.; Aversano L.; Bernardi M.L.; Cimitile M.,Design patterns mining using neural sub-graph matching,"Design Patterns detection in Object-Oriented software systems is essential for effectively supporting program comprehension and re-engineering tasks. It helps to recover, from source code, the developers' design decisions and trade-offs that could be not up-to-date or even not documented. Several approaches to mine design patterns from source code have been defined in the last twelve years and they are all based on the analysis of object-oriented systems components, their relationships, and behaviors to identify the roles played in the patterns. Both static and dynamic approaches need to perform matching between data captured from the system with the design patterns specification that encodes the structure and the behavior of the micro-architectural solution. The matching process, in principle, can be formulated as a sub-graph matching problem that is NP-complete. This problem has been addressed in the literature using heuristics designed to produce good solutions in an acceptable time, but the task is still expensive with a significant trade-off between accuracy and performance. This work proposes the adoption of a neural-based approach that exploits graph neural networks to perform detection using a more efficient sub-graph matching step outperforming existing heuristics proposed for this task. The pattern detection approach has been assessed on several open-source systems widely used to perform design pattern detection obtaining very good results for both detection performances and efficiency. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130388510&doi=10.1145%2f3477314.3507073&partnerID=40&md5=b0ba92c528295442e80c974754fde807,Proceedings of the ACM Symposium on Applied Computing,Include,,Include,
Mc Millan C.,Graph Neural Networks in Software Mining,"Software Mining encompasses a broad range of tasks involving software, such as finding the location of a bug in the source code of a program, generating natural language descriptions of software behavior, and detecting when two programs do basically the same thing. Software tends to have an extremely well-defined structure, due to the linguistic confines of source code and the need for programmers to maintain readability and compatibility when working on large teams. A tradition of graph-based representations of software has therefore proliferated. Meanwhile, advances in software repository maintenance have recently helped create very large datasets of source code. The result is fertile ground for Graph Neural Network representations of software to facilitate a plethora of software mining tasks. This chapter will provide a brief history of these representations, describe typical software mining tasks that benefit from GNNs, demonstrate one of these tasks in detail, and explain the benefits that GNNs can provide. Caveats and recommendations will also be discussed. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022.",Book chapter,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162675009&doi=10.1007%2f978-981-16-6054-2_23&partnerID=40&md5=fa7720b5c0d4c419ddbe988f2993ebf3,"Graph Neural Networks: Foundations, Frontiers, and Applications",Include,Exclude,Exclude,
Shi K.; Li J.; Liu Y.; Chang Y.; Li X.,BSDG: Anomaly Detection of Microservice Trace Based on Dual Graph Convolutional Neural Network,"Microservice architecture has been widely used by more and more developers in recent years. Accurate anomaly detection is crucial for system maintenance. Trace data can reflect the microservice dependency relationship and response time, which has been adopted for microservice anomaly detection now. However, due to the lack of unification modeling framework of response time and call path, the performance of anomaly detection degrades, and difficult to adapt to downstream tasks. To address the above issues, we propose BSDG, a trace anomaly detection method based on a dual graph convolutional neural network (dualGCN). First, BSDG extracts the microservice call dependencies, combing the learnable node attributes generated by Bi-directional Long Short-Term Memory(BiLSTM) to build an attribute dependency graph combined response time and call path. Then, a self-attention mapping graph is constructed and we use a dualGCN with mutual attention to generate effective feature embedding representation. Finally, BSDG adopts a multilayer perceptron with a new classification loss function to train the model in an end-to-end way for anomaly detection. The experimental results on public benchmarks show that the proposed BDSG outperforms baseline methods. We also conduct experiments on our constructed microservice trace dataset to validate the robustness of BSDG. Experiments show that the BSDG outperforms existing methods in microservice trace anomaly detection. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145008040&doi=10.1007%2f978-3-031-20984-0_12&partnerID=40&md5=339202f3b288ebf497cb6f3cb2113bb1,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Chen R.; Ren J.; Wang L.; Pu Y.; Yang K.; Wu W.,MicroEGRCL: An Edge-Attention-Based Graph Neural Network Approach for Root Cause Localization in Microservice Systems,"Microservices architecture has become the latest trend in building modern applications due to its flexibility, scalability, and agility. However, due to the complex interdependencies between microservices, an anomaly in any one service in a microservice system has the potential to propagate along service dependencies and affect multiple services. Therefore, accurate and efficient root cause localization is a significant challenge for current microservice system operation and maintenance. Focusing on this challenge and leveraging the dynamically constructed service call graph, we propose MicroEGRCL, a root cause localization approach based on graph neural networks with an attention mechanism that includes edge feature enhancement. We conducted an experimental evaluation by injecting various types of service anomalies into two microservice benchmarks running in a Kubernetes cluster. The experimental results demonstrate that MicroEGRCL can achieve an average top1 localization accuracy of 87%, exceeding the state-of-the-art baseline approaches. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145006548&doi=10.1007%2f978-3-031-20984-0_18&partnerID=40&md5=fb2ea18d71e0db63e7ba246d38daae2e,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Yang C.-W.; Phung T.H.; Shuai H.-H.; Cheng W.-H.,Mask or Non-Mask? Robust Face Mask Detector via Triplet-Consistency Representation Learning,"In the absence of vaccines or medicines to stop COVID-19, one of the effective methods to slow the spread of the coronavirus and reduce the overloading of healthcare is to wear a face mask. Nevertheless, to mandate the use of face masks or coverings in public areas, additional human resources are required, which is tedious and attention-intensive. To automate the monitoring process, one of the promising solutions is to leverage existing object detection models to detect the faces with or without masks. As such, security officers do not have to stare at the monitoring devices or crowds, and only have to deal with the alerts triggered by the detection of faces without masks. Existing object detection models usually focus on designing the CNN-based network architectures for extracting discriminative features. However, the size of training datasets of face mask detection is small, while the difference between faces with and without masks is subtle. Therefore, in this article, we propose a face mask detection framework that uses the context attention module to enable the effective attention of the feed-forward convolution neural network by adapting their attention maps' feature refinement. Moreover, we further propose an anchor-free detector with Triplet-Consistency Representation Learning by integrating the consistency loss and the triplet loss to deal with the small-scale training data and the similarity between masks and occlusions. Extensive experimental results show that our method outperforms the other state-of-the-art methods. The source code is released as a public download to improve public health at https://github.com/wei-1006/MaskFaceDetection.  © 2022 Association for Computing Machinery.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127452998&doi=10.1145%2f3472623&partnerID=40&md5=9cb38d8c2712d3ad39b17bf689c6680a,"ACM Transactions on Multimedia Computing, Communications and Applications",Exclude,,,
Wang X.; Chen S.; He Y.; Wang M.; Gan Q.; Yan J.,CEP3: Community Event Prediction with Neural Point Process on Graph,"Many real-world applications can be formulated as event forecasting on Continuous Time Dynamic Graphs (CTDGs) where the occurrence of a timed event between two entities is represented as an edge along with its occurrence timestamp. However, many previous works handle the problem in compromised settings, either formulating it as a link prediction task on the graph given the event time, or a time prediction problem for which event will happen next. In this paper, we propose a novel model combining Graph Neural Networks and Marked Temporal Point Process (MTPP) that jointly forecasts multiple link events and their timestamps on communities over a CTDG. Moreover, to scale our model to large graphs, we factorize the joint event prediction problem into three easier conditional probability modeling problems. To evaluate the effectiveness of our model and the rationale behind such a decomposition, we establish a set of benchmarks and evaluation metrics. The experimental results demonstrate the superiority of our model in terms of both accuracy and training efficiency. All the source codes and datasets are available in a GitHub repository. © 2022 Proceedings of Machine Learning Research. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164538001&partnerID=40&md5=11241d0a552cacfc209047b304441f2b,Proceedings of Machine Learning Research,Exclude,,Exclude,
Xia C.; Feng S.-H.; Xia Y.; Pan X.; Shen H.-B.,Fast protein structure comparison through effective representation learning with contrastive graph neural networks,"Protein structure alignment algorithms are often time-consuming, resulting in challenges for large-scale protein structure similarity-based retrieval. There is an urgent need for more efficient structure comparison approaches as the number of protein structures increases rapidly. In this paper, we propose an effective graph-based protein structure representation learning method, GraSR, for fast and accurate structure comparison. In GraSR, a graph is constructed based on the intra-residue distance derived from the tertiary structure. Then, deep graph neural networks (GNNs) with a short-cut connection learn graph representations of the tertiary structures under a contrastive learning framework. To further improve GraSR, a novel dynamic training data partition strategy and length-scaling cosine distance are introduced. We objectively evaluate our method GraSR on SCOPe v2.07 and a new released independent test set from PDB database with a designed comprehensive performance metric. Compared with other state-of-the-art methods, GraSR achieves about 7%-10% improvement on two benchmark datasets. GraSR is also much faster than alignment-based methods. We dig into the model and observe that the superiority of GraSR is mainly brought by the learned discriminative residue-level and global descriptors. The web-server and source code of GraSR are freely available at www.csbio.sjtu.edu.cn/bioinf/GraSR/ for academic use. Copyright: © 2022 Xia et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128146502&doi=10.1371%2fjournal.pcbi.1009986&partnerID=40&md5=dcbde7d85f22fa3bc57f906e3c000cf6,PLoS Computational Biology,Exclude,,Exclude,
Jiang Y.; Zhou B.; Zhao X.; Zou J.; Xie F.; Li L.,Domain-adaptive Graph based on Post-hoc Explanation for Cross-domain Hate Speech Detection,"Hate speech detection is hampered by the scarcity and topical and lexical biases of annotated data, leading to poor generalization. It is imperative to devise a cross-domain approach to solve this problem. The ability to learn transferable knowledge is critical for cross-domain hate speech detection. In this work, We propose a domain-adaptive dependency graph method based on post-hoc explanation (DPDG). We extract post-hoc explanations from fine-tuned BERT classifiers as the importance score for hate representation. Based on these, we construct in-domain graph and cross-domain graph to better learn in-domain hate representation and adapt to the target domain respectively. Finally, we use interactive GCN blocks to interactively and adaptively learn and adjust the domain adaptive graph representation. The results of cross-domain experiments on multiple domains show that our proposed model outperforms competitive baselines in cross-domain hate speech detection. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156161575&doi=10.1109%2fICTAI56018.2022.00192&partnerID=40&md5=202bd35982ccc846ddf7c50bd3de4b89,"Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI",Exclude,,Exclude,
Xiao D.; Hang D.; Ai L.; Li S.; Liang H.,Path context augmented statement and network for learning programs,"Applying machine learning techniques in program analysis has attracted much attention. Recent research efforts in detecting code clones and classifying code have shown that neural models based on abstract syntax trees (ASTs) can better represent source code than other approaches. However, existing AST-based approaches do not take into account contextual information of a program, like statement context. To address this issue, we propose a novel approach path context to capture the context of statements, and a path context augmented network (PCAN) to learn a program. We evaluate PCAN on code clone detection, source code classification, and method naming. The results show that compared to state-of-the-art approaches, PCAN performs the best on code clone detection and has comparable performance on code classification and method naming. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122668648&doi=10.1007%2fs10664-021-10098-y&partnerID=40&md5=50bf30a064322a3cb94a24b84246e28c,Empirical Software Engineering,Include,,Include,
Qian Y.; Zhang C.; Zhang Y.; Wen Q.; Ye Y.; Zhang C.,Co-Modality Graph Contrastive Learning for Imbalanced Node Classification,"Graph contrastive learning (GCL), leveraging graph augmentations to convert graphs into different views and further train graph neural networks (GNNs), has achieved considerable success on graph benchmark datasets. Yet, there are still some gaps in directly applying existing GCL methods to real-world data. First, handcrafted graph augmentations require trials and errors, but still can not yield consistent performance on multiple tasks. Second, most real-world graph data present class-imbalanced distribution but existing GCL methods are not immune to data imbalance. Therefore, this work proposes to explicitly tackle these challenges, via a principled framework called Co-Modality Graph Contrastive Learning (CM-GCL) to automatically generate contrastive pairs and further learn balanced representation over unlabeled data. Specifically, we design inter-modality GCL to automatically generate contrastive pairs (e.g., node-text) based on rich node content. Inspired by the fact that minority samples can be “forgotten” by pruning deep neural networks, we naturally extend network pruning to our GCL framework for mining minority nodes. Based on this, we co-train two pruned encoders (e.g., GNN and text encoder) in different modalities by pushing the corresponding node-text pairs together and the irrelevant node-text pairs away. Meanwhile, we propose intra-modality GCL by co-training non-pruned GNN and pruned GNN, to ensure node embeddings with similar attribute features stay closed. Last, we fine-tune the GNN encoder on downstream class-imbalanced node classification tasks. Extensive experiments demonstrate that our model significantly outperforms state-of-the-art baseline models and learns more balanced representations on real-world graphs. Our source code is available at https://github.com/graphprojects/CM-GCL. © 2022 Neural information processing systems foundation. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153757604&partnerID=40&md5=fee5301ade8f5f896fb420d5e0bc2758,Advances in Neural Information Processing Systems,Exclude,,Exclude,
Wan X.; Wu X.; Wang D.; Tan X.; Liu X.; Fu Z.; Jiang H.; Zheng M.; Li X.,An inductive graph neural network model for compound–protein interaction prediction based on a homogeneous graph,"Identifying the potential compound–protein interactions (CPIs) plays an essential role in drug development. The computational approaches for CPI prediction can reduce time and costs of experimental methods and have benefited from the continuously improved graph representation learning. However, most of the network-based methods use heterogeneous graphs, which is challenging due to their complex structures and heterogeneous attributes. Therefore, in this work, we transformed the compound–protein heterogeneous graph to a homogeneous graph by integrating the ligand-based protein representations and overall similarity associations. We then proposed an Inductive Graph AggrEgator-based framework, named CPI-IGAE, for CPI prediction. CPI-IGAE learns the low-dimensional representations of compounds and proteins from the homogeneous graph in an end-to-end manner. The results show that CPI-IGAE performs better than some state-of-the-art methods. Further ablation study and visualization of embeddings reveal the advantages of the model architecture and its role in feature extraction, and some of the top ranked CPIs by CPI-IGAE have been validated by a review of recent literature. The data and source codes are available at https://github.com/wanxiaozhe/CPI-IGAE. © The Author(s) 2022. Published by Oxford University Press. All rights reserved.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130765885&doi=10.1093%2fbib%2fbbac073&partnerID=40&md5=74a349ecae98174928355f51f5163bc9,Briefings in Bioinformatics,Exclude,,,
Zhao Z.; Yang B.; Li G.; Liu H.; Jin Z.,Precise Learning of Source Code Contextual Semantics via Hierarchical Dependence Structure and Graph Attention Networks,"Deep learning is being used extensively in a variety of software engineering tasks, e.g., program classification and defect prediction. Although the technique eliminates the required process of feature engineering, the construction of source code model significantly affects the performance on those tasks. Most recent works was mainly focused on complementing AST-based source code models by introducing contextual dependencies extracted from CFG. However, all of them pay little attention to the representation of basic blocks, which are the basis of contextual dependencies. In this paper, we integrated AST and CFG and proposed a novel source code model embedded with hierarchical dependencies. Based on that, we also designed a neural network that depends on the graph attention mechanism. Specifically, we introduced the syntactic structural of the basic block, i.e., its corresponding AST, in source code model to provide sufficient information and fill the gap. We have evaluated this model on three practical software engineering tasks and compared it with other state-of-the-art methods. The results show that our model can significantly improve the performance. For example, compared to the best performing baseline, our model reduces the scale of parameters by 50% and achieves 4% improvement on accuracy on program classification task. © 2021 Elsevier Inc.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118759414&doi=10.1016%2fj.jss.2021.111108&partnerID=40&md5=b2e6deb1d8c0668848a5d5f83bc18516,Journal of Systems and Software,Include,,Include,
Shi N.; Xu J.; Wurster S.W.; Guo H.; Woodring J.; Van Roekel L.P.; Shen H.-W.,GNN-Surrogate: A Hierarchical and Adaptive Graph Neural Network for Parameter Space Exploration of Unstructured-Mesh Ocean Simulations,"We propose GNN-Surrogate, a graph neural network-based surrogate model to explore the parameter space of ocean climate simulations. Parameter space exploration is important for domain scientists to understand the influence of input parameters (e.g., wind stress) on the simulation output (e.g., temperature). The exploration requires scientists to exhaust the complicated parameter space by running a batch of computationally expensive simulations. Our approach improves the efficiency of parameter space exploration with a surrogate model that predicts the simulation outputs accurately and efficiently. Specifically, GNN-Surrogate predicts the output field with given simulation parameters so scientists can explore the simulation parameter space with visualizations from user-specified visual mappings. Moreover, our graph-based techniques are designed for unstructured meshes, making the exploration of simulation outputs on irregular grids efficient. For efficient training, we generate hierarchical graphs and use adaptive resolutions. We give quantitative and qualitative evaluations on the MPAS-Ocean simulation to demonstrate the effectiveness and efficiency of GNN-Surrogate. Source code is publicly available at http://github.com/trainsn/GNN-Surrogate. © 2022 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128310637&doi=10.1109%2fTVCG.2022.3165345&partnerID=40&md5=6c6f33080deb2f6a4c1f843a5d8c2b00,IEEE Transactions on Visualization and Computer Graphics,Exclude,,Exclude,
Romanov V.; Ivanov V.,Prediction of Types in Python with Pre-Trained Graph Neural Networks,"The application of Graph Neural Networks for pre-Training models for source code is not well studied. We experimented with pre-Training a Graph Neural Network model for Python on tasks of Name Prediction and Edge Prediction. Then, we used pre-Trained weights to initialize a model for variable type prediction. Our preliminary results suggest that pre-Training on these tasks brings neither improvements in type prediction performance nor training dynamics. Possible ways to fix this are discussed in the concluding section of the paper. Additionally, we performed an ablation study to see whether type prediction is overreliant on some parts of the graph. Results suggest, that type prediction model does not significantly rely on obvious shortcuts and could be a useful proxy for evaluating pre-Trained graph embeddings.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146265787&doi=10.1109%2fIVMEM57067.2022.9983956&partnerID=40&md5=6d2dc784677e91f5f7fdf1c6e5a298f4,"Proceedings - 2022 Ivannikov Memorial Workshop, IVMEM 2022",Include,,Include,
Wang Y.; Hu Y.; Zhang J.,Panini-Net: GAN Prior Based Degradation-Aware Feature Interpolation for Face Restoration,"Emerging high-quality face restoration (FR) methods often utilize pre-trained GAN models (i.e., StyleGAN2) as GAN Prior. However, these methods usually struggle to balance realness and fidelity when facing various degradation levels. Besides, there is still a noticeable visual quality gap compared with pre-trained GAN models. In this paper, we propose a novel GAN Prior based degradation-aware feature interpolation network, dubbed Panini-Net, for FR tasks by explicitly learning the abstract representations to distinguish various degradations. Specifically, an unsupervised degradation representation learning (UDRL) strategy is first developed to extract degradation representations (DR) of the input degraded images. Then, a degradation-aware feature interpolation (DAFI) module is proposed to dynamically fuse the two types of informative features (i.e., features from input images and features from GAN Prior) with flexible adaption to various degradations based on DR. Ablation studies reveal the working mechanism of DAFI and its potential for editable FR. Extensive experiments demonstrate that our Panini-Net achieves state-of-the-art performance for multi-degradation face restoration and face super-resolution. The source code is available at https://github.com/jianzhangcs/panini. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147320915&partnerID=40&md5=a28552c8392c5e1a59870c1ee80f44a0,"Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022",Exclude,,,
Nguyen H.H.; Nguyen N.-M.; Xie C.; Ahmadi Z.; Kudendo D.; Doan T.-N.; Jiang L.,MANDO: Multi-Level Heterogeneous Graph Embeddings for Fine-Grained Detection of Smart Contract Vulnerabilities,"Learning heterogeneous graphs consisting of different types of nodes and edges enhances the results of homogeneous graph techniques. An interesting example of such graphs is control-flow graphs representing possible software code execution flows. As such graphs represent more semantic information of code, developing techniques and tools for such graphs can be highly beneficial for detecting vulnerabilities in software for its reliability. However, existing heterogeneous graph techniques are still insufficient in handling complex graphs where the number of different types of nodes and edges is large and variable. This paper concentrates on the Ethereum smart contracts as a sample of software codes represented by heterogeneous contract graphs built upon both control-flow graphs and call graphs containing different types of nodes and links. We propose MANDO, a new heterogeneous graph representation to learn such heterogeneous contract graphs' structures. MANDO extracts customized meta-paths, which compose relational connections between different types of nodes and their neighbors. Moreover, it develops a multi-metapath heterogeneous graph attention network to learn multi-level embeddings of different types of nodes and their metapaths in the heterogeneous contract graphs, which can capture the code semantics of smart contracts more accurately and facilitate both fine-grained line-level and coarse-grained contract-level vulnerability detection. Our extensive evaluation of large smart contract datasets shows that MANDO improves the vulnerability detection results of other techniques at the coarse-grained contract level. More importantly, it is the first learning-based approach capable of identifying vulnerabilities at the fine-grained line-level, and significantly improves the traditional code analysis-based vulnerability detection approaches by 11.35% to 70.81% in terms of F1-score. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143075291&doi=10.1109%2fDSAA54385.2022.10032337&partnerID=40&md5=a50173fabedbf7977331fc2f6d90f0d3,"Proceedings - 2022 IEEE 9th International Conference on Data Science and Advanced Analytics, DSAA 2022",Include,,Include,
Niu G.; Li B.; Zhang Y.; Pu S.,Perform Like an Engine: A Closed-Loop Neural-Symbolic Learning Framework for Knowledge Graph Inference,"Knowledge graph (KG) inference aims to address the natural incompleteness of KGs, including rule learning-based and KG embedding (KGE) models. However, the rule learning-based models suffer from low efficiency and generalization while KGE models lack interpretability. To address these challenges, we propose a novel and effective closed-loop neural-symbolic learning framework EngineKG via incorporating our developed KGE and rule learning modules. KGE module exploits symbolic rules and paths to enhance the semantic association between entities and relations for improving KG embeddings and interpretability. A novel rule pruning mechanism is proposed in the rule learning module by leveraging paths as initial candidate rules and employing KG embeddings together with concepts for extracting more high-quality rules. Experimental results on four real-world datasets show that our model outperforms the relevant baselines on link prediction tasks, demonstrating the superiority of our KG inference model in a neural-symbolic learning fashion. The source code and datasets of this paper are available at https://github.com/ngl567/EngineKG. © 2022 Proceedings - International Conference on Computational Linguistics, COLING. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165768747&partnerID=40&md5=40468d7e31ff8e7bd1799a12837c65d6,"Proceedings - International Conference on Computational Linguistics, COLING",Exclude,,,
Li Z.; Wu Q.; Nie F.; Yan J.,GraphDE: A Generative Framework for Debiased Learning and Out-of-Distribution Detection on Graphs,"Despite the remarkable success of graph neural networks (GNNs) for graph representation learning, they are generally built on the (unreliable) i.i.d. assumption across training and testing data. However, real-world graph data are universally comprised of outliers in training set and out-of-distribution (OOD) testing samples from unseen domains, which solicits effective models for i) debiased learning and ii) OOD detection, towards general trustworthy purpose. In this paper, we first mathematically formulate the two challenging problems for graph data and take an initiative on tackling them under a unified probabilistic model. Specifically, we model the graph generative process to characterize the distribution shifts of graph data together with an additionally introduced latent environment variable as an indicator. We then define a variational distribution, i.e., a recognition model, to infer the environment during training of GNN. By instantiating the generative models as two-component mixtures, we derive a tractable learning objective and theoretically justify that the model can i) automatically identify and down-weight outliers in the training procedure, and ii) induce an effective OOD detector simultaneously. Experiments on diverse datasets with different types of OOD data prove that our model consistently outperforms strong baselines for both debiasing and OOD detection tasks. The source code has been made publicly available at https://github.com/Emiyalzn/GraphDE. © 2022 Neural information processing systems foundation. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147954179&partnerID=40&md5=85e7bb945c6950dbf2b68182a0af6fc3,Advances in Neural Information Processing Systems,Exclude,,Exclude,
Meraz M.; Ansari M.A.; Javed M.; Chakraborty P.,DC-GNN: drop channel graph neural network for object classification and part segmentation in the point cloud,"In the recent years, the problem of 3D shape analysis in the point cloud is considered as one of the challenging research topics in the field of computer vision. The major issues here are effective representation of the 3D information, meaningful feature extraction and subsequent task of classification. In this research paper, a deep learning-based network called Drop Channel Graph Neural Network (DC-GNN) is proposed for object classification and part segmentation. The DC-GNN model employs the idea of k-NN-based drop channel with hierarchical feature selection approach at each layer for dynamic graph construction, and further, with the help of Multi-Layer Perceptron Networks accomplishes the task of object classification. The same DC-GNN model is extended to carry out part segmentation in the point cloud data using the ShapeNet-Part benchmark dataset. The proposed network reports the state-of-the-art classification accuracy of 93.64% with ModelNet-40 dataset (Source-Code-https://github.com/merazlab/DC-GNN). © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128669314&doi=10.1007%2fs13735-022-00236-7&partnerID=40&md5=9359a9b2a69258599ba5706320612a8f,International Journal of Multimedia Information Retrieval,Exclude,,,
Jia S.; Chen B.; Li D.; Wang S.,No-reference Image Quality Assessment via Non-local Dependency Modeling,"In this paper, we propose a no-reference image quality assessment method based on non-local features learned by a graph neural network (GNN). The proposed quality assessment framework is rooted in the view that the human visual system perceives image quality with long-dependency constructed among different regions, inspiring us to explore the non-local interactions in quality prediction. Instead of relying on convolutional neural network (CNN) based quality assessment methods that primarily focus on local field features, the GNN aiming for non-local quality perception facilitates modeling such long-dependency. In particular, we first adopt superpixel segmentation for the graph nodes construction. Subsequently, a spatial attention module is proposed to integrate the long- and short-range dependencies among the nodes of the whole image. The learned non-local features are finally combined with the local features extracted by the pre-trained CNN, achieving superior performance to the features utilized individually. Experimental results on intra-dataset and cross-dataset settings verify our proposed method's effectiveness and advanced generalization capability. Source codes are publicly accessible at https://github.com/SuperBruceJia/NLNet-IQA for scientific reproducible research. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143599165&doi=10.1109%2fMMSP55362.2022.9950035&partnerID=40&md5=703012e89a8755cdb1d42f35c79cd371,"2022 IEEE 24th International Workshop on Multimedia Signal Processing, MMSP 2022",Exclude,,Exclude,
Sun Y.; Liang B.; Bao J.; Yang M.; Xu R.,Probing Structural Knowledge from Pre-trained Language Model for Argumentation Relation Classification,"Extracting fine-grained structural information between argumentation component (AC) pairs is essential for argumentation relation classification (ARC). However, most previous studies attempt to model the relationship between AC pairs using AC level similarity or semantically relevant features. They ignore the complex interaction between AC pairs and cannot effectively reason the argumentation relation deeply. Therefore, in this paper, we propose a novel dual prior graph neural network (DPGNN) to jointly explore the probing knowledge derived from pre-trained language models (PLMs) and the syntactical information for comprehensively modeling the relationship between AC pairs. Specifically, we construct a probing graph by using probing knowledge derived from PLMs to recognize and align the relational information within and across the argumentation components. In addition, we propose a mutual dependency graph for the AC pair to reason the fine-grained syntactic structural information, in which the syntactical correlation between words is set by the dependency information within AC and the mutual attention mechanism across ACs. The knowledge learned from the probing graph and the dependency graph are combined to comprehensively capture the aligned relationships of AC pairs for improving the results of ARC. Experimental results on three public datasets show that DPGNN outperforms the state-of-the-art baselines by a noticeable margin. © 2022 Association for Computational Linguistics.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149833526&partnerID=40&md5=4c4fbd5afd9ebf1d3c2eece76d678eed,Findings of the Association for Computational Linguistics: EMNLP 2022,Exclude,,,
Bertrand S.; Favier P.-A.; André J.-M.,Building an Operable Graph Representation of a Java Program as a Basis for Automatic Software Maintainability Analysis,"As a part of a research project concerning software maintainability assessment in collaboration with the development team, we were interested in the frequent use of metrics as predictors. Many metrics exist, often with opaque and arguable implementations. We claim metrics mix the assessment of presentation, structure and model. In order to focus on true detectable maintainability defects, we computed metrics solely based on the structure of the program. Our approach was to parse the source code of Java programs as a graph, and to compute metrics in a declarative query language. To this end, we developed Javanalyser and implemented 34 metrics using Spoon to parse Java programs and Neo4j as graph database. We will show that the program graph constitutes a steady basis to compute metrics and conduct future machine-learning studies to assess maintainability. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132386334&doi=10.1145%2f3530019.3534081&partnerID=40&md5=fbedb840e41a1c49920c441c3cb2a38e,ACM International Conference Proceeding Series,Include,,Include,
Keetha N.V.; Wang C.; Qiu Y.; Xu K.; Scherer S.,AirObject: A Temporally Evolving Graph Embedding for Object Identification,"Object encoding and identification are vital for robotic tasks such as autonomous exploration, semantic scene understanding, and relocalization. Previous approaches have attempted to either track objects or generate descriptors for object identification. However, such systems are limited to a 'fixed' partial object representation from a single viewpoint. In a robot exploration setup, there is a requirement for a temporally 'evolving' global object representation built as the robot observes the object from multiple viewpoints. Furthermore, given the vast distribution of unknown novel objects in the real world, the object identification process must be class-agnostic. In this context, we propose a novel temporal 3D object encoding approach, dubbed AirObject, to obtain global keypoint graph-based embeddings of objects. Specifically, the global 3D object embeddings are generated using a temporal convolutional network across structural information of multiple frames obtained from a graph attention-based encoding method. We demonstrate that AirObject achieves the state-of-the-art performance for video object identification and is robust to severe occlusion, perceptual aliasing, viewpoint shift, deformation, and scale transform, outperforming the state-of-the-art single-frame and sequential descriptors. To the best of our knowledge, AirObject is one of the first temporal object encoding methods. Source code is available at https://github.com/Nik-v9/AirObject. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143057401&doi=10.1109%2fCVPR52688.2022.00822&partnerID=40&md5=c64a2d5e5c6fce9d8d86eefb6fef77c1,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,Exclude,,,
Huong T.T.; Ha D.T.; Tran H.T.T.; Viet N.D.; Tien B.D.; Thanh N.H.; Thang T.C.; Nam P.N.,An Effective Foveated 360° Image Assessment Based on Graph Convolution Network,"Virtual reality (VR) has been adopted in various fields such as entertainment, education, healthcare, and the military, due to its ability to provide an immersive experience to users. However, 360° images, one of the main components in VR systems, have bulky sizes and thus require effective transmitting and rendering solutions. One of the potential solutions is to use foveated technologies, that take advantage of the foveation feature of the human eyes. Foveated technologies can significantly reduce the data required for transmission and computation complexity in rendering. However, understanding the impact of foveated 360° images on human quality perception is still limited. This paper addresses the above problems by proposing an accurate machine-learning-based quality assessment model for foveated 360° images. The proposed model is proven to outperform the three cutting-edge machine-learning-based models, which apply deep learning techniques and 25 traditional-metric-based models (or analytical-function-based-models), which utilize analytical functions. It is also expected that our model helps to evaluate and improve 360° content streaming and rendering solutions to further reduce data sizes while ensuring user experience. Also, this model could be used as a building block to construct quality assessment methods for 360° videos, that are reserved for our future work. The source code is available at https://github.com/telagment/FoVGCN.  © 2013 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137926849&doi=10.1109%2fACCESS.2022.3204766&partnerID=40&md5=fd7652c33340f8697493799fee257604,IEEE Access,Exclude,,,
Liu K.; Chen K.; Jia K.,Convolutional Fine-Grained Classification with Self-Supervised Target Relation Regularization,"Fine-grained visual classification can be addressed by deep representation learning under supervision of manually pre-defined targets (e.g., one-hot or the Hadamard codes). Such target coding schemes are less flexible to model inter-class correlation and are sensitive to sparse and imbalanced data distribution as well. In light of this, this paper introduces a novel target coding scheme - dynamic target relation graphs (DTRG), which, as an auxiliary feature regularization, is a self-generated structural output to be mapped from input images. Specifically, online computation of class-level feature centers is designed to generate cross-category distance in the representation space, which can thus be depicted by a dynamic graph in a non-parametric manner. Explicitly minimizing intra-class feature variations anchored on those class-level centers can encourage learning of discriminative features. Moreover, owing to exploiting inter-class dependency, the proposed target graphs can alleviate data sparsity and imbalanceness in representation learning. Inspired by recent success of the mixup style data augmentation, this paper introduces randomness into soft construction of dynamic target relation graphs to further explore relation diversity of target classes. Experimental results can demonstrate the effectiveness of our method on a number of diverse benchmarks of multiple visual classification, especially achieving the state-of-the-art performance on three popular fine-grained object benchmarks and superior robustness against sparse and imbalanced data. Source codes are made publicly available at https://github.com/AkonLau/DTRG. © 1992-2012 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136867614&doi=10.1109%2fTIP.2022.3197931&partnerID=40&md5=135d83174408452d8892df849b098e4d,IEEE Transactions on Image Processing,Exclude,,,
Ma W.; Zhao M.; Soremekun E.; Hu Q.; Zhang J.M.; Papadakis M.; Cordy M.; Xie X.; Le Traon Y.,GraphCode2Vec: Generic Code Embedding via Lexical and Program Dependence Analyses,"Code embedding is a keystone in the application of machine learning on several Software Engineering (SE) tasks. To effectively support a plethora of SE tasks, the embedding needs to capture program syntax and semantics in a way that is generic. To this end, we propose the first self-supervised pre-training approach (called Graphcode2vec) which produces task-agnostic embedding of lexical and program dependence features. Graphcode2vec achieves this via a synergistic combination of code analysis and Graph Neural Networks. Graphcode2vec is generic, it allows pre-training, and it is applicable to several SE downstream tasks. We evaluate the effectiveness of Graphcode2vec on four (4) tasks (method name prediction, solution classification, mutation testing and overfitted patch classification), and compare it with four (4) similarly generic code embedding baselines (Code2Seq, Code2Vec, CodeBERT, Graph-CodeBERT) and seven (7) task-specific, learning-based methods. In particular, Graphcode2vec is more effective than both generic and task-specific learning-based baselines. It is also complementary and comparable to GraphCodeBERT (a larger and more complex model). We also demonstrate through a probing and ablation study that Graphcode2vec learns lexical and program dependence features and that self-supervised pre-training improves effectiveness. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134018448&doi=10.1145%2f3524842.3528456&partnerID=40&md5=8de7aa869994647081c414a65aa27259,"Proceedings - 2022 Mining Software Repositories Conference, MSR 2022",Include,,,
Qin Z.; Liu Y.; Ji P.; Kim D.; Wang L.; McKay R.I.; Anwar S.; Gedeon T.,Fusing Higher-Order Features in Graph Neural Networks for Skeleton-Based Action Recognition,"Skeleton sequences are lightweight and compact and thus are ideal candidates for action recognition on edge devices. Recent skeleton-based action recognition methods extract features from 3-D joint coordinates as spatial&#x2013;temporal cues, using these representations in a graph neural network for feature fusion to boost recognition performance. The use of first-and second-order features, that is, joint and bone representations, has led to high accuracy. Nonetheless, many models are still confused by actions that have similar motion trajectories. To address these issues, we propose fusing higher-order features in the form of angular encoding (AGE) into modern architectures to robustly capture the relationships between joints and body parts. This simple fusion with popular spatial&#x2013;temporal graph neural networks achieves new state-of-the-art accuracy in two large benchmarks, including NTU60 and NTU120, while employing fewer parameters and reduced run time. Our source code is publicly available at: https://github.com/ZhenyueQin/Angular-Skeleton-Encoding. Author",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139396548&doi=10.1109%2fTNNLS.2022.3201518&partnerID=40&md5=8a81d9338d3e20230209b50b9df9a003,IEEE Transactions on Neural Networks and Learning Systems,Exclude,,,
He D.; Xie L.,A cross-level information transmission network for hierarchical omics data integration and phenotype prediction from a new genotype,"Motivation: An unsolved fundamental problem in biology is to predict phenotypes from a new genotype under environmental perturbations. The emergence of multiple omics data provides new opportunities but imposes great challenges in the predictive modeling of genotype-phenotype associations. Firstly, the high-dimensionality of genomics data and the lack of coherent labeled data often make the existing supervised learning techniques less successful. Secondly, it is challenging to integrate heterogeneous omics data from different resources. Finally, few works have explicitly modeled the information transmission from DNA to phenotype, which involves multiple intermediate molecular types. Higher-level features (e.g. gene expression) usually have stronger discriminative and interpretable power than lower-level features (e.g. somatic mutation). Results: We propose a novel Cross-LEvel Information Transmission (CLEIT) network framework to address the above issues. CLEIT aims to represent the asymmetrical multi-level organization of the biological system by integrating multiple incoherent omics data and to improve the prediction power of low-level features. CLEIT first learns the latent representation of the high-level domain then uses it as ground-truth embedding to improve the representation learning of the low-level domain in the form of contrastive loss. Besides, CLEIT can leverage the unlabeled heterogeneous omics data to improve the generalizability of the predictive model. We demonstrate the effectiveness and significant performance boost of CLEIT in predicting anti-cancer drug sensitivity from somatic mutations via the assistance of gene expressions when compared with state-of-the-art methods. CLEIT provides a general framework to model information transmissions and integrate multi-modal data in a multi-level system. Availabilityand implementation: The source code is freely available at https://github.com/XieResearchGroup/CLEIT. © 2021 The Author(s). Published by Oxford University Press.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137694980&doi=10.1093%2fbioinformatics%2fbtab580&partnerID=40&md5=57f6339d3ce7bcd8b0731841d7ae9733,Bioinformatics,Exclude,,,
Li L.; Liu Y.,Mapping Modern JVM Language Code to Analysis-friendly Graphs: A Pilot Study with Kotlin,"Kotlin is a modern JVM language, gaining adoption rapidly and becoming Android official programming language. With its widely usage, the need for code analysis of Kotlin is increasing. Exposing code semantics explicitly with a properly structured format is the first step in code analysis and the construction of such representation is the foundation for downstream tasks. Recently, graph-based approaches become a promising way for encoding source code semantics. However, current works mainly focus on representation learning with limited interpretability and shallow domain knowledge. The known evolvements of code semantics in new-generation programming languages have been overlooked. How to establish an effective mapping between naturally concise Kotlin source code with graph-based representation needs to be studied by analyzing known language features. In this paper, we propose a first-sight, rule-based mapping method, using composite representation with AST, CFG, DFG, and language features. We evaluate mapping strategies with ablation experiments by simulating a code search solution as a downstream task. Our graph-based method with built-in language features outperforms the text-based way without introducing greater complexity. By addressing the practical barriers to extracting and exposing the hidden semantics from Kotlin source code, our study also helps enlighten source code representations for other modern languages. © 2022 Knowledge Systems Institute Graduate School. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137168841&doi=10.18293%2fSEKE2022-079&partnerID=40&md5=82c2ad807f6b37bcfbf7e7432c07c6df,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",Exclude,,,
Zeng P.; Zhang H.; Gao L.; Song J.; Shen H.T.,Video Question Answering With Prior Knowledge and Object-Sensitive Learning,"Video Question Answering (VideoQA), which explores spatial-temporal visual information of videos given a linguistic query, has received unprecedented attention over recent years. One of the main challenges lies in locating relevant visual and linguistic information, and therefore various attention-based approaches are proposed. Despite the impressive progress, two aspects are not fully explored by current methods to get proper attention. Firstly, prior knowledge, which in the human cognitive process plays an important role in assisting the reasoning process of VideoQA, is not fully utilized. Secondly, structured visual information (e.g., object) instead of the raw video is underestimated. To address the above two issues, we propose a Prior Knowledge and Object-sensitive Learning (PKOL) by exploring the effect of prior knowledge and learning object-sensitive representations to boost the VideoQA task. Specifically, we first propose a Prior Knowledge Exploring (PKE) module that aims to acquire and integrate prior knowledge into a question feature for feature enriching, where an information retriever is constructed to retrieve related sentences as prior knowledge from the massive corpus. In addition, we propose an Object-sensitive Representation Learning (ORL) module to generate object-sensitive features by interacting object-level features with frame and clip-level features. Our proposed PKOL achieves consistent improvements on three competitive benchmarks (i.e., MSVD-QA, MSRVTT-QA, and TGIF-QA) and gains state-of-the-art performance. The source code is available at https://github.com/zchoi/PKOL.  © 1992-2012 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137893017&doi=10.1109%2fTIP.2022.3205212&partnerID=40&md5=87d2bac8fdcac97eed11f65f910b6573,IEEE Transactions on Image Processing,Exclude,,,
Mokhtari M.; Tsang T.; Abolmaesumi P.; Liao R.,EchoGNN: Explainable Ejection Fraction Estimation with Graph Neural Networks,"Ejection fraction (EF) is a key indicator of cardiac function, allowing identification of patients prone to heart dysfunctions such as heart failure. EF is estimated from cardiac ultrasound videos known as echocardiograms (echo) by manually tracing the left ventricle and estimating its volume on certain frames. These estimations exhibit high inter-observer variability due to the manual process and varying video quality. Such sources of inaccuracy and the need for rapid assessment necessitate reliable and explainable machine learning techniques. In this work, we introduce EchoGNN, a model based on graph neural networks (GNNs) to estimate EF from echo videos. Our model first infers a latent echo-graph from the frames of one or multiple echo cine series. It then estimates weights over nodes and edges of this graph, indicating the importance of individual frames that aid EF estimation. A GNN regressor uses this weighted graph to predict EF. We show, qualitatively and quantitatively, that the learned graph weights provide explainability through identification of critical frames for EF estimation, which can be used to determine when human intervention is required. On EchoNet-Dynamic public EF dataset, EchoGNN achieves EF prediction performance that is on par with state of the art and provides explainability, which is crucial given the high inter-observer variability inherent in this task. Our source code is publicly available at: https://github.com/MasoudMo/echognn. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139004792&doi=10.1007%2f978-3-031-16440-8_35&partnerID=40&md5=d4c445c8988de8a6618de5f466e8a23c,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Liu Q.; Li Z.; Li X.; Wu J.; Yuan S.,Graph Convolution-Based Deep Reinforcement Learning for Multi-Agent Decision-Making in Interactive Traffic Scenarios,"A reliable multi-agent decision-making system is highly demanded for safe and efficient operations of connected and autonomous vehicles (CAVs). In order to represent the mutual effects between vehicles and model the dynamic traffic environments, this research proposes an integrated and open-source framework to realize different Graph Reinforcement Learning (GRL) methods for better decision-making in interactive driving scenarios. Firstly, an interactive driving scenario on the highway with two ramps is constructed. The vehicles in this scenario are modeled by graph representation, and features are extracted via Graph Neural Network (GNN). Secondly, several GRL approaches are implemented and compared in detail. Finally, The simulation in the SUMO platform is carried out to evaluate the performance of different G RL approaches. Results are analyzed from multiple perspectives to compare the performance of different G RL methods in intelligent transportation scenarios. Experiments show that the implementation of GNN can well model the interactions between vehicles, and the proposed framework can improve the overall performance of multi-agent decision-making. The source code of our work can be found at https://github.com/Jacklinkk/TorchGRL.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141846528&doi=10.1109%2fITSC55140.2022.9922001&partnerID=40&md5=1f91bd49f256c51a77cee5819d87a5bc,"IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC",Exclude,,,
Zhu X.; Song J.; Gao L.; Zheng F.; Shen H.T.,Unified Multivariate Gaussian Mixture for Efficient Neural Image Compression,"Modeling latent variables with priors and hyperpriors is an essential problem in variational image compression. Formally, trade-off between rate and distortion is handled well if priors and hyperpriors precisely describe latent variables. Current practices only adopt univariate priors and process each variable individually. However, we find inter-correlations and intra-correlations exist when observing latent variables in a vectorized perspective. These findings reveal visual redundancies to improve rate-distortion performance and parallel processing ability to speed up compression. This encourages us to propose a novel vectorized prior. Specifically, a multivariate Gaussian mixture is proposed with means and covariances to be estimated. Then, a novel probabilistic vector quantization is utilized to effectively approximate means, and remaining covariances are further induced to a unified mixture and solved by cascaded estimation without context models involved. Furthermore, code books involved in quantization are extended to multi-codebooks for complexity reduction, which formulates an efficient compression procedure. Extensive experiments on benchmark datasets against state-of-the-art indicate our model has better rate-distortion performance and an impressive 3.18x compression speed up, giving us the ability to perform real-time, high-quality variational image compression in practice. Our source code is publicly available at https://github.com/xiaosu-zhu/McQuic. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140387874&doi=10.1109%2fCVPR52688.2022.01709&partnerID=40&md5=661c4e869e5d0343122f2d1bae4c3dd0,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,Exclude,,Exclude,
Guan W.; Wen H.; Song X.; Wang C.; Yeh C.-H.; Chang X.; Nie L.,Partially Supervised Compatibility Modeling,"Fashion Compatibility Modeling (FCM), which aims to automatically evaluate whether a given set of fashion items makes a compatible outfit, has attracted increasing research attention. Recent studies have demonstrated the benefits of conducting the item representation disentanglement towards FCM. Although these efforts have achieved prominent progress, they still perform unsatisfactorily, as they mainly investigate the visual content of fashion items, while overlooking the semantic attributes of items (e.g., color and pattern), which could largely boost the model performance and interpretability. To address this issue, we propose to comprehensively explore the visual content and attributes of fashion items towards FCM. This problem is non-trivial considering the following challenges: a) how to utilize the irregular attribute labels of items to partially supervise the attribute-level representation learning of fashion items; b) how to ensure the intact disentanglement of attribute-level representations; and c) how to effectively sew the multiple granulairites (i.e, coarse-grained item-level and fine-grained attribute-level) information to enable performance improvement and interpretability. To address these challenges, in this work, we present a partially supervised outfit compatibility modeling scheme (PS-OCM). In particular, we first devise a partially supervised attribute-level embedding learning component to disentangle the fine-grained attribute embeddings from the entire visual feature of each item. We then introduce a disentangled completeness regularizer to prevent the information loss during disentanglement. Thereafter, we design a hierarchical graph convolutional network, which seamlessly integrates the attribute- and item-level compatibility modeling, and enables the explainable compatibility reasoning. Extensive experiments on the real-world dataset demonstrate that our PS-OCM significantly outperforms the state-of-the-art baselines. We have released our source codes and well-trained models to benefit other researchers (https://site2750.wixsite.com/ps-ocm).  © 1992-2012 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134246843&doi=10.1109%2fTIP.2022.3187290&partnerID=40&md5=2c1c5b7f933cf0d212d333ab23475990,IEEE Transactions on Image Processing,Exclude,,,
Xia F.; Wu G.; Zhao G.; Li X.,SimCGE: Simple Contrastive Learning of Graph Embeddings for Cross-Version Binary Code Similarity Detection,"Binary code similarity detection (BCSD) has many applications in computer security, whose task is to detect the similarity of two binary functions without having access to the source code. Recently deep learning methods have shown better efficiency, accuracy, and potential in BCSD. Most of them reduce losses by the Siamese network, and they ignore some shortcomings of the Siamese network. In this paper, we introduce the idea of contrastive learning into graph neural networks and experimentally demonstrate that the way of training graph models by contrastive learning is significantly better than Siamese. In addition, we found that Principal Neighbourhood Aggregation for Graph Nets (PNA) has the best ability to extract structural information of control flow graph (CFG) among various graph neural networks. © 2022, Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137050801&doi=10.1007%2f978-3-031-15777-6_25&partnerID=40&md5=813853ad201f49311aef5f7935a271ae,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Yang X.; Wang Y.; Chen K.; Xu Y.; Tian Y.,Fine-Grained Object Classification via Self-Supervised Pose Alignment,"Semantic patterns offine-grained objects are determined by subtle appearance difference of local parts, which thus inspires a number of part-based methods. However, due to uncontrollable object poses in images, distinctive de-tails carried by local regions can be spatially distributed or even self-occluded, leading to a large variation on ob-ject representation. For discounting pose variations, this paper proposes to learn a novel graph based object rep-resentation to reveal a global configuration of local parts for self-supervised pose alignment across classes, which is employed as an auxiliary feature regularization on a deep representation learning network. Moreover, a coarse-to-fine supervision together with the proposed pose-insensitive constraint on shallow-to-deep sub-networks encourages discriminative features in a curriculum learning manner. We evaluate our method on three popular fine-grained ob-ject classification benchmarks, consistently achieving the state-of-the-art performance. Source codes are available at https://github.com/yangxhll/P2P-Net. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136045266&doi=10.1109%2fCVPR52688.2022.00725&partnerID=40&md5=d31435b5ccc049d4022a0db37f446a5b,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,Exclude,,,
Han R.; Yan H.; Li J.; Wang S.; Feng W.; Wang S.,Panoramic Human Activity Recognition,"To obtain a more comprehensive activity understanding for a crowded scene, in this paper, we propose a new problem of panoramic human activity recognition (PAR), which aims to simultaneously achieve the recognition of individual actions, social group activities, and global activities. This is a challenging yet practical problem in real-world applications. To track this problem, we develop a novel hierarchical graph neural network to progressively represent and model the multi-granular human activities and mutual social relations for a crowd of people. We further build a benchmark to evaluate the proposed method and other related methods. Experimental results verify the rationality of the proposed PAR problem, the effectiveness of our method and the usefulness of the benchmark. We have released the source code and benchmark to the public for promoting the study on this problem. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142687709&doi=10.1007%2f978-3-031-19772-7_15&partnerID=40&md5=9f34baf9a25ae6ef7d4ed388d9a503b8,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Chen Y.; Zhao L.; Yuan J.; Tian Y.; Xia Z.; Geng S.; Han L.; Metaxas D.N.,Hierarchically Self-supervised Transformer for Human Skeleton Representation Learning,"Despite the success of fully-supervised human skeleton sequence modeling, utilizing self-supervised pre-training for skeleton sequence representation learning has been an active field because acquiring task-specific skeleton annotations at large scales is difficult. Recent studies focus on learning video-level temporal and discriminative information using contrastive learning, but overlook the hierarchical spatial-temporal nature of human skeletons. Different from such superficial supervision at the video level, we propose a self-supervised hierarchical pre-training scheme incorporated into a hierarchical Transformer-based skeleton sequence encoder (Hi-TRS), to explicitly capture spatial, short-term, and long-term temporal dependencies at frame, clip, and video levels, respectively. To evaluate the proposed self-supervised pre-training scheme with Hi-TRS, we conduct extensive experiments covering three skeleton-based downstream tasks including action recognition, action detection, and motion prediction. Under both supervised and semi-supervised evaluation protocols, our method achieves the state-of-the-art performance. Additionally, we demonstrate that the prior knowledge learned by our model in the pre-training stage has strong transfer capability for different downstream tasks. The source code can be found at https://github.com/yuxiaochen1103/Hi-TRS. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142754906&doi=10.1007%2f978-3-031-19809-0_11&partnerID=40&md5=9b67ac700f0ac340a5719463ff697b2f,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,Exclude,
Zhang G.; Davoodnia V.; Etemad A.,PARSE: Pairwise Alignment of Representations in Semi-Supervised EEG Learning for Emotion Recognition,"We propose pairwise alignment of representations for semi-supervised Electroencephalogram (EEG) learning (PARSE), a novel semi-supervised architecture for learning reliable EEG representations for emotion recognition. To reduce the potential distribution mismatch between large amounts of unlabeled data and a limited number of labeled data, PARSE uses pairwise representation alignment. First, our model performs data augmentation followed by label guessing for large amounts of original and augmented unlabeled data. The model is then followed by sharpening the guessed labels and convex combinations of the unlabeled and labeled data. Finally, it performs representation alignment and emotion classification. To rigorously test our model, we compare PARSE to several state-of-the-art semi-supervised approaches, which we implement and adapt for EEG learning. We perform these experiments on four public EEG-based emotion recognition datasets, SEED, SEED-IV, SEED-V and AMIGOS (valence and arousal). The experiments show that our proposed framework achieves the overall best results with varying amounts of limited labeled samples in SEED, SEED-IV and AMIGOS (valence), while approaching the overall best result (reaching the second-best) in SEED-V and AMIGOS (arousal). The analysis shows that our pairwise representation alignment considerably improves the performance by performing the distribution alignment between unlabeled and labeled data, especially when only 1 sample per class is labeled. The source code of our article is publicly available at https://github.com/guangyizhangbci/PARSE. © 2010-2012 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139412290&doi=10.1109%2fTAFFC.2022.3210441&partnerID=40&md5=27e4209038f2505ad11dd32ef2e64340,IEEE Transactions on Affective Computing,Exclude,,,
Chen L.; Mahmud Q.I.; Jannesari A.,Multi-View Learning for Parallelism Discovery of Sequential Programs,"Identifying suitable parallelizable regions in sequential programs is a crucial task for performance optimizations. Traditional methods like static and dynamic analysis have flaws like insufficient accuracy or high overhead runtime. Recent studies are more interested in applying machine learning techniques to this topic. The crux of parallelism discovery with machine learning is to generate meaningful code representations. One promising route is to exploit the dependence graph through Graph Neural Networks (GNNS). In this paper, a novel multi-view framework is proposed to automatically detect potential parallelism opportunities. Sequential programs are first repre-sented by program execution graphs encompassing both semantic and structural information. Then two independent views are defined: namely, a structural pattern view and a node feature view. In the structural view, local graph structural patterns are captured via random anonymous walks and then fed into a Graph Convolutional Network (GCN). The node features, both dynamic and static, are fed into another GCN in the node feature view. In addition, a multi-view model is designed to unify the node features and the structural features for parallelism detection. Our approach achieves comparable state-of-the-art performance on parallel region classification with an accuracy up to 92.6 % when evaluated with popular parallel eomputing benchmarks.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136219915&doi=10.1109%2fIPDPSW55747.2022.00059&partnerID=40&md5=6f94bd8f8d492eb08d74666640f78b95,"Proceedings - 2022 IEEE 36th International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2022",Include,,,
Wang X.; Wang Y.; Wan Y.; Wang J.; Zhou P.; Li L.; Wu H.; Liu J.,CODE-MVP: Learning to Represent Source Code from Multiple Views with Contrastive Pre-Training,"Recent years have witnessed increasing interest in code representation learning, which aims to represent the semantics of source code into distributed vectors. Currently, various works have been proposed to represent the complex semantics of source code from different views, including plain text, Abstract Syntax Tree (AST), and several kinds of code graphs (e.g., Control/Data Flow Graph). However, most of them only consider a single view of source code independently, ignoring the correspondences among different views. In this paper, we propose to integrate different views with the naturallanguage description of source code into a unified framework with Multi-View contrastive Pre-training, and name our model as CODEMVP. Specifically, we first extract multiple code views using compiler tools, and learn the complementary information among them under a contrastive learning framework. Inspired by the type checking in compilation, we also design a fine-grained type inference objective in the pre-training. Experiments on three downstream tasks over five datasets demonstrate the superiority of CODE-MVP when compared with several state-of-the-art baselines. For example, we achieve 2.4/2.3/1.1 gain in terms of MRR/MAP/Accuracy metrics on natural language code retrieval, code similarity, and code defect detection tasks, respectively. © Findings of the Association for Computational Linguistics: NAACL 2022 - Findings.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135499146&partnerID=40&md5=ce9546da3091cf7f7fac3b2be289837c,Findings of the Association for Computational Linguistics: NAACL 2022 - Findings,Exclude,,,
Duran F.S.; Beyaz A.; Rekik I.,Dual-HINet: Dual Hierarchical Integration Network of Multigraphs for Connectional Brain Template Learning,"A connectional brain template (CBT) is a normalized representation of a population of brain multigraphs, where two anatomical regions of interests (ROIs) are connected by multiple edges. Each edge captures a particular type of interaction between pairs of ROIs (e.g., structural/functional). Learning a well-centered and representative CBT of a particular brain multigraph population (e.g., healthy or atypical) is a means of modeling complex and varying ROI interactions in a holistic manner. Existing methods generate CBTs by locally integrating heterogeneous multi-edge attributes (e.g., weights and features). However, such methods are agnostic to brain network modularity as they ignore the hierarchical structure of neural interactions. Furthermore, they only perform node-level integration at the individual level without learning the multigraph representation at the group level in a layer-wise manner. To address these limitations, we propose Dual Hierarchical Integration Network (Dual-HINet) for connectional brain template estimation, which simultaneously learns the node-level and cluster-level integration processes using a dual graph neural network architecture. We also propose a novel loss objective to jointly learn the clustering assignment across different edge types and the centered CBT representation of the population multigraphs. Our Dual-HINet significantly outperforms state-of-the-art methods for learning CBTs on a large-scale multigraph connectomic datasets. Our source code can be found at https://github.com/basiralab/Dual-HINet. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138823554&doi=10.1007%2f978-3-031-16431-6_29&partnerID=40&md5=da2cd7c3d3e82813584b2abe3287e024,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,Exclude,
Zhang W.; Yang Y.; Wu Q.M.J.; Wang T.; Zhang H.,Multimodal Moore&#x2013;Penrose Inverse-Based Recomputation Framework for Big Data Analysis,"Most multilayer Moore&#x2013;Penrose inverse (MPI)-based neural networks, such as deep random vector functional link (RVFL), are structured with two separate stages: unsupervised feature encoding and supervised pattern classification. Once the unsupervised learning is finished, the latent encoding is fixed without supervised fine-tuning. However, in complex tasks such as handling the ImageNet dataset, there are often many more clues that can be directly encoded, while unsupervised learning, by definition, cannot know exactly what is useful for a certain task. There is a need to retrain the latent space representations in the supervised pattern classification stage to learn some clues that unsupervised learning has not yet been learned. In particular, the residual error in the output layer is pulled back to each hidden layer, and the parameters of the hidden layers are recalculated with MPI for more robust representations. In this article, a recomputation-based multilayer network using Moore&#x2013;Penrose inverse (RML-MP) is developed. A sparse RML-MP (SRML-MP) model to boost the performance of RML-MP is then proposed. The experimental results with varying training samples (from 3k to 1.8 million) show that the proposed models provide higher Top-1 testing accuracy than most representation learning algorithms. For reproducibility, the source codes are available at https://github.com/W1AE/Retraining. IEEE",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141500937&doi=10.1109%2fTNNLS.2022.3211149&partnerID=40&md5=2459fbcb9eff2cf1c71f3cd80b77a2f7,IEEE Transactions on Neural Networks and Learning Systems,Exclude,,,
Samoaa H.P.; Longa A.; Mohamad M.; Chehreghani M.H.; Leitner P.,TEP-GNN: Accurate Execution Time Prediction of Functional Tests Using Graph Neural Networks,"Predicting the performance of production code prior to actual execution is known to be highly challenging. In this paper, we propose a predictive model, dubbed TEP-GNN, which demonstrates that high-accuracy performance prediction is possible for the special case of predicting unit test execution times. TEP-GNN uses FA-ASTs, or flow-augmented ASTs, as a graph-based code representation approach, and predicts test execution times using a powerful graph neural network (GNN) deep learning model. We evaluate TEP-GNN using four real-life Java open source programs, based on 922 test files mined from the projects’ public repositories. We find that our approach achieves a high Pearson correlation of 0.789, considerable outperforming a baseline deep learning model. Our work demonstrates that FA-ASTs and GNNs are a feasible approach for predicting absolute performance values, and serves as an important intermediary step towards being able to predict the performance of arbitrary code prior to execution. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142682048&doi=10.1007%2f978-3-031-21388-5_32&partnerID=40&md5=135963edc383a2020c19681c88c0d89f,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,,
Pala F.; Rekik I.,Predicting Brain Multigraph Population from a Single Graph Template for Boosting One-Shot Classification,"A central challenge in training one-shot learning models is the limited representativeness of the available shots of the data space. Particularly in the field of network neuroscience where the brain is represented as a graph, such models may lead to low performance when classifying brain states (e.g., typical vs. autistic). To cope with this, most of the existing works involve a data augmentation step to increase the size of the training set, its diversity and representativeness. Though effective, such augmentation methods are limited to generating samples with the same size as the input shots (e.g., generating brain connectivity matrices from a single shot matrix). To the best of our knowledge, the problem of generating brain multigraphs capturing multiple types of connectivity between pairs of nodes (i.e., anatomical regions) from a single brain graph remains unsolved. In this paper, we unprecedentedly propose a hybrid graph neural network (GNN) architecture, namely Multigraph Generator Network or briefly MultigraphGNet, comprising two subnetworks: (1) a many-to-one GNN which integrates an input population of brain multigraphs into a single template graph, namely a connectional brain temple (CBT), and (2) a reverse one-to-many U-Net network which takes the learned CBT in each training step and outputs the reconstructed input multigraph population. Both networks are trained in an end-to-end way using a cyclic loss. Experimental results demonstrate that our MultigraphGNet boosts the performance of an independent classifier when trained on the augmented brain multigraphs in comparison with training on a single CBT from each class. We hope that our framework can shed some light on the future research of multigraph augmentation from a single graph. Our MultigraphGNet source code is available at https://github.com/basiralab/MultigraphGNet. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140473699&doi=10.1007%2f978-3-031-16919-9_18&partnerID=40&md5=4075b31739609c9cc2a7c2d16c8ff15a,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Zhu R.; Yuan L.; Li X.; Gao M.; Cai W.,A Neural Network Architecture for Program Understanding Inspired by Human Behaviors,"Program understanding is a fundamental task in program language processing. Despite the success, existing works fail to take human behaviors as reference in understanding programs. In this paper, we consider human behaviors and propose the PGNN-EK model that consists of two main components. On the one hand, inspired by the “divide-and-conquer” reading behaviors of humans, we present a partitioning-based graph neural network model PGNN on the upgraded AST of codes. On the other hand, to characterize human behaviors of resorting to other resources to help code comprehension, we transform raw codes with external knowledge and apply pre-training techniques for information extraction. Finally, we combine the two embeddings generated from the two components to output code embeddings. We conduct extensive experiments to show the superior performance of PGNN-EK on the code summarization and code clone detection tasks. In particular, to show the generalization ability of our model, we release a new dataset that is more challenging for code clone detection and could advance the development of the community. Our codes and data are publicly available at https://github.com/RecklessRonan/PGNN-EK. © 2022 Association for Computational Linguistics.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140398484&partnerID=40&md5=9020473919331f9676604d8e85374f6c,Proceedings of the Annual Meeting of the Association for Computational Linguistics,Include,,,
Dai L.; Liu Y.; Ma J.; Wei L.; Lai T.; Yang C.; Chen R.,MS2DG-Net: Progressive Correspondence Learning via Multiple Sparse Semantics Dynamic Graph,"Establishing superior-quality correspondences in an image pair is pivotal to many subsequent computer vision tasks. Using Euclidean distance between correspondences to find neighbors and extract local information is a common strategy in previous works. However, most such works ignore similar sparse semantics information between two given images and cannot capture local topology among correspondences well. Therefore, to deal with the above problems, Multiple Sparse Semantics Dynamic Graph Network (MS2 DG-Net) is proposed, in this paper, to predict probabilities of correspondences as inliers and recover camera poses. MS2 DG-Net dynamically builds sparse semantics graphs based on sparse semantics similarity between two given images, to capture local topology among correspondences, while maintaining permutation-equivariant. Extensive experiments prove that MS2 DG-Net outperforms state-of-the-art methods in outlier removal and camera pose estimation tasks on the public datasets with heavy outliers. Source code:https://github.com/changcaiyang/MS2DG-Net © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140200937&doi=10.1109%2fCVPR52688.2022.00877&partnerID=40&md5=6e812c8d1bb862b6333b0074965d0dae,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,Exclude,,,
Xue Y.; Guo J.; Zhang L.; Song H.,Message Passing Graph Neural Networks for Software Security Vulnerability Detection,"With the booming development of deep learning and machine learning, the use of neural networks for software source code security vulnerability detection has become a hot pot in the field of software security. As a data structure, graphs can adequately represent the complex syntactic information, semantic information, and dependencies in software source code. In this paper, we propose the MPGVD model based on the idea of text classification in natural language processing. The model uses BERT for source code pre-training, transforms graphs into corresponding feature vectors, uses MPNN (Message Passing Neural Networks) based on graph neural networks in the feature extraction phase, and finally outputs the detection results. Our proposed MPGVD, compared with other existing vulnerability detection models on the same dataset CodeXGLUE, obtain the highest detection accuracy of 64.34%.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142506108&doi=10.1109%2fICCNEA57056.2022.00041&partnerID=40&md5=b9f59e156dd72ddaaacc337da4ce9342,"Proceedings - 2022 International Conference on Computer Network, Electronic and Automation, ICCNEA 2022",Include,,,
Nguyen H.V.; Zheng J.; Inomata A.; Uehara T.,Code Aggregate Graph: Effective Representation for Graph Neural Networks to Detect Vulnerable Code,"Deep learning, especially graph neural networks (GNNs), provides efficient, fast, and automated methods to detect vulnerable code. However, the accuracy could be improved as previous studies were limited by existing code representations. Additionally, the diversity of embedding techniques and GNN models can make selecting the appropriate method challenging. Herein we propose Code Aggregate Graph (CAG) to improve vulnerability detection efficiency. CAG combines the principles of different code analyses such as abstract syntax tree, control flow graph, and program dependence graph with dominator and post-dominator trees. This extensive representation empowers deep graph networks for enhanced classification. We also implement different data encoding methods and neural networks to provide a multidimensional view of the system performance. Specifically, three word embedding approaches and three deep GNNs are utilized to build classifiers. Then CAG is evaluated using two datasets: a real-world open-source dataset and the software assurance reference dataset. CAG is also compared with seven state-of-the-art methods and six classic representations. CAG shows the best performance. Compared to previous studies, CAG has an increased accuracy (5.4%) and F1-score (5.1%). Additionally, experiments confirm that encoding has a positive impact on accuracy (4-6%) but the network type does not. The study should contribute to a meaningful benchmark for future research on code representations, data encoding, and GNNs.  © 2013 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140708573&doi=10.1109%2fACCESS.2022.3216395&partnerID=40&md5=1a5ef9149269d7bcb295558d4263f64a,IEEE Access,Include,,Include,
Li L.; Wang S.; Liu X.; Zhu E.; Shen L.; Li K.; Li K.,Local Sample-Weighted Multiple Kernel Clustering With Consensus Discriminative Graph,"Multiple kernel clustering (MKC) is committed to achieving optimal information fusion from a set of base kernels. Constructing precise and local kernel matrices is proven to be of vital significance in applications since the unreliable distant&#x2013;distance similarity estimation would degrade clustering performance. Although existing localized MKC algorithms exhibit improved performance compared with globally designed competitors, most of them widely adopt the KNN mechanism to localize kernel matrix by accounting for <inline-formula> <tex-math notation=""LaTeX"">$\tau$</tex-math> </inline-formula>-nearest neighbors. However, such a coarse manner follows an unreasonable strategy that the ranking importance of different neighbors is equal, which is impractical in applications. To alleviate such problems, this article proposes a novel local sample-weighted MKC (LSWMKC) model. We first construct a consensus discriminative affinity graph in kernel space, revealing the latent local structures. Furthermore, an optimal neighborhood kernel for the learned affinity graph is output with naturally sparse property and clear block diagonal structure. Moreover, LSWMKC implicitly optimizes adaptive weights on different neighbors with corresponding samples. Experimental results demonstrate that our LSWMKC possesses better local manifold representation and outperforms existing kernel or graph-based clustering algorithms. The source code of LSWMKC can be publicly accessed from https://github.com/liliangnudt/LSWMKC. IEEE",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134006347&doi=10.1109%2fTNNLS.2022.3184970&partnerID=40&md5=0a486908e1339c18b4e8bebf743ec601,IEEE Transactions on Neural Networks and Learning Systems,Exclude,,,
Chen Y.; Zhang Q.; Guan Z.; Zhao Y.; Chen W.,GEMvis: a visual analysis method for the comparison and refinement of graph embedding models,"Graph embedding, which constructs vector representation of nodes in a network, has shown effectiveness in many graph analysis tasks, such as node classification, node clustering, and link prediction. However, due to the complexity of graph embedding models (GEMs) and their nontransparency of hyperparameters, evaluation and comparison of embedding results in retaining the original graph features, and consequently, the selection of suitable GEMs according to graph analysis tasks are challenging for people. In this paper, we present a visual analysis method, GEMvis, to support the evaluation and comparison of GEMs from the original graph, node metric, and embedding result spaces. The method also supports the online refining of GEM by tuning the parameters in its three components (graph sampling method, neural network structure, and loss function). A series of metrics, R_node metrics, for measuring GEMs’ ability to preserve specific node metrics, such as R_degree and R_closeness, is also proposed to support quantitative evaluation and comparison of GEMs’ ability to preserve original graph features. Finally, three case studies and expert feedback illustrate the effectiveness of GEMvis. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132134649&doi=10.1007%2fs00371-022-02548-5&partnerID=40&md5=ad07a7ca47190a612b4ab1411cde4640,Visual Computer,Exclude,,,
Peng X.; Li Y.; Tsang I.W.; Zhu H.; Lv J.; Zhou J.T.,XAI beyond Classification: Interpretable Neural Clustering,"In this paper, we study two challenging problems in explainable AI (XAI) and data clustering. The first is how to directly design a neural network with inherent interpretability, rather than giving post-hoc explanations of a black-box model. The second is implementing discrete k-means with a differentiable neural network that embraces the advantages of parallel computing, online clustering, and clustering-favorable representation learning. To address these two challenges, we design a novel neural network, which is a differentiable reformulation of the vanilla k-means, called inTerpretable nEuraL cLustering (TELL). Our contributions are threefold. First, to the best of our knowledge, most existing XAI works focus on supervised learning paradigms. This work is one of the few XAI studies on unsupervised learning, in particular, data clustering. Second, TELL is an interpretable, or the so-called intrinsically explainable and transparent model. In contrast, most existing XAI studies resort to various means for understanding a black-box model with post-hoc explanations. Third, from the view of data clustering, TELL possesses many properties highly desired by k-means, including but not limited to online clustering, plug-and-play module, parallel computing, and provable convergence. Extensive experiments show that our method achieves superior performance comparing with 14 clustering approaches on three challenging data sets. The source code could be accessed at www.pengxi.me. ©2022 Xi Peng, Yunfan Li, Ivor W. Tsang, Hongyuan Zhu, Jiancheng Lv, and Joey Tianyi Zhou.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124157707&partnerID=40&md5=4dd19a37c71f2217ac7ec44fd1ab69fc,Journal of Machine Learning Research,Exclude,,,
Hao X.; Liu Y.; Xie R.; Ge K.; Tang L.; Zhang X.; Lin L.,Adversarial Feature Translation for Multi-domain Recommendation,"Real-world super platforms such as Google and WeChat usually have different recommendation scenarios to provide heterogeneous items for users' diverse demands. Multi-domain recommendation (MDR) is proposed to improve all recommendation domains simultaneously, where the key point is to capture informative domain-specific features from all domains. To address this problem, we propose a novel Adversarial feature translation (AFT) model for MDR, which learns the feature translations between different domains under a generative adversarial network framework. Precisely, in the multi-domain generator, we propose a domain-specific masked encoder to highlight inter-domain feature interactions, and then aggregate these features via a transformer and a domain-specific attention. In the multi-domain discriminator, we explicitly model the relationships between item, domain and users' general/domain-specific representations with a two-step feature translation inspired by the knowledge representation learning. In experiments, we evaluate AFT on a public and an industrial MDR datasets and achieve significant improvements. We also conduct an online evaluation on a real-world MDR system. We further give detailed ablation tests and model analyses to verify the effectiveness of different components. Currently, we have deployed AFT on WeChat Top Stories. The source code is in https://github.com/xiaobocser/AFT. © 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114955220&doi=10.1145%2f3447548.3467176&partnerID=40&md5=7c750cc25d4fa768e31e4ec6e049b648,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Exclude,,,
Liu Z.; Xia X.; Lo D.; Xing Z.; Hassan A.E.; Li S.,Which variables should i log?,"Developers usually depend on inserting logging statements into the source code to collect system runtime information. Such logged information is valuable for software maintenance. A logging statement usually prints one or more variables to record vital system status. However, due to the lack of rigorous logging guidance and the requirement of domain-specific knowledge, it is not easy for developers to make proper decisions about which variables to log. To address this need, in this work, we propose an approach to recommend logging variables for developers during development by learning from existing logging statements. Different from other prediction tasks in software engineering, this task has two challenges: 1) Dynamic labels - different logging statements have different sets of accessible variables, which means in this task, the set of possible labels of each sample is not the same. 2) Out-of-vocabulary words - identifiers' names are not limited to natural language words and the test set usually contains a number of program tokens which are out of the vocabulary built from the training set and cannot be appropriately mapped to word embeddings. To deal with the first challenge, we convert this task into a representation learning problem instead of a multi-label classification problem. Given a code snippet which lacks a logging statement, our approach first leverages a neural network with an RNN (recurrent neural network) layer and a self-attention layer to learn the proper representation of each program token, and then predicts whether each token should be logged through a unified binary classifier based on the learned representation. To handle the second challenge, we propose a novel method to map program tokens into word embeddings by making use of the pre-trained word embeddings of natural language tokens. We evaluate our approach on 9 large and high-quality Java projects. Our evaluation results show that the average MAP of our approach is over 0.84, outperforming random guess and an information-retrieval-based method by large margins.  © 1976-2012 IEEE.",Review,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115222248&doi=10.1109%2fTSE.2019.2941943&partnerID=40&md5=db49f1d6ab7d0ab12b6f6bcff3bd027b,IEEE Transactions on Software Engineering,Exclude,,,
Suarez I.; Buenaposada J.M.; Baumela L.,Revisiting Binary Local Image Description for Resource Limited Devices,"The advent of a panoply of resource limited devices opens up new challenges in the design of computer vision algorithms with a clear compromise between accuracy and computational requirements. In this letter we present new binary image descriptors that emerge from the application of triplet ranking loss, hard negative mining and anchor swapping to traditional features based on pixel differences and image gradients. These descriptors, BAD (Box Average Difference) and HashSIFT, establish new operating points in the state-of-the-art's accuracy vs. resources trade-off curve. In our experiments we evaluate the accuracy, execution time and energy consumption of the proposed descriptors. We show that BAD bears the fastest descriptor implementation in the literature while HashSIFT approaches in accuracy that of the top deep learning-based descriptors, being computationally more efficient. We have made the source code public1.  © 2016 IEEE.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113870990&doi=10.1109%2fLRA.2021.3107024&partnerID=40&md5=53ea47ee8e81fb712e1695e67b851777,IEEE Robotics and Automation Letters,Exclude,,,
Mihelic S.A.; Sikora W.A.; Hassan A.M.; Williamson M.R.; Jones T.A.; Dunn A.K.,"Segmentation-Less, automated, vascular vectorization","Recent advances in two-photon fluorescence microscopy (2PM) have allowed large scale imaging and analysis of blood vessel networks in living mice. However, extracting network graphs and vector representations for the dense capillary bed remains a bottleneck in many applications. Vascular vectorization is algorithmically difficult because blood vessels have many shapes and sizes, the samples are often unevenly illuminated, and large image volumes are required to achieve good statistical power. State-of-the-art, three-dimensional, vascular vectorization approaches often require a segmented (binary) image, relying on manual or supervised-machine annotation. Therefore, voxel-by-voxel image segmentation is biased by the human annotator or trainer. Furthermore, segmented images oftentimes require remedial morphological filtering before skeletonization or vectorization. To address these limitations, we present a vectorization method to extract vascular objects directly from unsegmented images without the need for machine learning or training. The Segmentation-Less, Automated, Vascular Vectorization (SLAVV) source code in MATLAB is openly available on GitHub. This novel method uses simple models of vascular anatomy, efficient linear filtering, and vector extraction algorithms to remove the image segmentation requirement, replacing it with manual or automated vector classification. Semi-automated SLAVV is demonstrated on three in vivo 2PM image volumes of microvascular networks (capillaries, arterioles and venules) in the mouse cortex. Vectorization performance is proven robust to the choice of plasma- or endothelial-labeled contrast, and processing costs are shown to scale with input image volume. Fully-automated SLAVV performance is evaluated on simulated 2PM images of varying quality all based on the large (1.4×0.9×0.6 mm3 and 1.6×108 voxel) input image. Vascular statistics of interest (e.g. volume fraction, surface area density) calculated from automatically vectorized images show greater robustness to image quality than those calculated from intensity-thresholded images. Copyright: © 2021 Mihelic et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116754944&doi=10.1371%2fjournal.pcbi.1009451&partnerID=40&md5=2da3b0bdc7752779c6fcad52f9e3c0b6,PLoS Computational Biology,Exclude,,Exclude,
Zhao E.; Yan R.; Li K.; Li L.; Xing J.,Learning to Play Hard Exploration Games Using Graph-Guided Self-Navigation,"This work considers the problem of deep reinforcement learning (RL) with long time dependencies and sparse rewards, as are found in many hard exploration games. A graph-based representation is proposed to allow an agent to perform self-navigation for environmental exploration. The graph representation not only effectively models the environment structure, but also efficiently traces the agent state changes and the corresponding actions. By encouraging the agent to earn a new influence-based curiosity reward for new game observations, the whole exploration task is divided into sub-tasks, which are effectively solved using a unified deep RL model. Experimental evaluations on hard exploration Atari Games demonstrate the effectiveness of the proposed method. The source code and learned models will be released to facilitate further studies on this problem. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116402699&doi=10.1109%2fIJCNN52387.2021.9534251&partnerID=40&md5=a57e073b35e8866dc39e596310a1c256,Proceedings of the International Joint Conference on Neural Networks,Exclude,,,
Dai D.; Dong C.; Xu S.; Yan Q.; Li Z.; Zhang C.; Luo N.,Ms RED: A novel multi-scale residual encoding and decoding network for skin lesion segmentation,"Computer-Aided Diagnosis (CAD) for dermatological diseases offers one of the most notable showcases where deep learning technologies display their impressive performance in acquiring and surpassing human experts. In such the CAD process, a critical step is concerned with segmenting skin lesions from dermoscopic images. Despite remarkable successes attained by recent deep learning efforts, much improvement is still anticipated to tackle challenging cases, e.g., segmenting lesions that are irregularly shaped, bearing low contrast, or possessing blurry boundaries. To address such inadequacies, this study proposes a novel Multi-scale Residual Encoding and Decoding network (Ms RED) for skin lesion segmentation, which is able to accurately and reliably segment a variety of lesions with efficiency. Specifically, a multi-scale residual encoding fusion module (MsR-EFM) is employed in an encoder, and a multi-scale residual decoding fusion module (MsR-DFM) is applied in a decoder to fuse multi-scale features adaptively. In addition, to enhance the representation learning capability of the newly proposed pipeline, we propose a novel multi-resolution, multi-channel feature fusion module (M2F2), which replaces conventional convolutional layers in encoder and decoder networks. Furthermore, we introduce a novel pooling module (Soft-pool) to medical image segmentation for the first time, retaining more helpful information when down-sampling and getting better segmentation performance. To validate the effectiveness and advantages of the proposed network, we compare it with several state-of-the-art methods on ISIC 2016, 2017, 2018, and PH2. Experimental results consistently demonstrate that the proposed Ms RED attains significantly superior segmentation performance across five popularly used evaluation criteria. Last but not least, the new model utilizes much fewer model parameters than its peer approaches, leading to a greatly reduced number of labeled samples required for model training, which in turn produces a substantially faster converging training process than its peers. The source code is available at https://github.com/duweidai/Ms-RED. © 2021 Elsevier B.V.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119193292&doi=10.1016%2fj.media.2021.102293&partnerID=40&md5=d6ca8ce5d39488f3cc3d35fc2917cbb7,Medical Image Analysis,Exclude,,,
Jiang J.; Lai S.; Jin L.; Zhu Y.,DsDTW: Local Representation Learning With Deep soft-DTW for Dynamic Signature Verification,"Dynamic time warping (DTW) is a popular technique for sequence alignment, and is the de facto standard for dynamic signature verification. In this paper, we go a significant step further to enhance DTW with the capability of deep representation learning, and propose an end-to-end trainable Deep soft-DTW (DsDTW) model for dynamic signature verification. Specifically, we design a convolutional recurrent adaptive network (CRAN) to process dynamic signatures, and utilize it to provide robust and discriminative local representations as inputs for DTW. As DTW is not fully differentiable with regard to its inputs, we introduce its smoothed formulation, soft-DTW, and incorporate the soft-DTW distances of signature pairs into the loss function for optimization. Because soft-DTW is differentiable, the proposed DsDTW is end-to-end trainable, and achieves an elegant integration of CRAN deep learning model and traditional DTW mechanism. Our method achieves state-of-the-art performance on several public benchmarks, and has won first place in the ICDAR 2021 competition for online signature verification. Source codes of DsDTW is available at https://github.com/KAKAFEI123/DsDTW.  © 2005-2012 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131758518&doi=10.1109%2fTIFS.2022.3180219&partnerID=40&md5=7ef045b276f5eb090e2055d2d6fc90e8,IEEE Transactions on Information Forensics and Security,Exclude,,,
Petukhov M.; Gudauskayte E.; Kaliyev A.; Oskin M.; Ivanov D.; Wang Q.,Method Name Prediction for Automatically Generated Unit Tests,"Writing intuitively understandable method names is an important aspect of good programming practice. The method names have to summarize the codes' behavior such that software engineers would easily understand their purpose. Modern automatic testing tools are able to generate potentially unlimited number of unit tests for a project under test. However, these tests suffers from unintelligible unit test names as it is quite difficult to understand what each test triggers and checks. This inspired us to adapt the state-of-the-art method name prediction approaches for automatically generated unit tests. We have developed a graph extraction pipeline with prediction models based on Graph Neural Networks (GNNs). Extracted graphs contain information about the structure of unit tests and their called functions. The experiment results have shown that the proposed work outperforms other models with precision = 0.48, recall = 0.42 and F1 = 0.45 results. The dataset and source codes are released for wide public access.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130020877&doi=10.1109%2fICCQ53703.2022.9763112&partnerID=40&md5=ed0fff791e84806977f36e384166f1e4,ICCQ 2022 - Proceedings of the 2nd International Conference on Code Quality,Include,,Include,
Wang X.; Wang S.; Liang Y.; Gu L.; Lei Z.,RVFace: Reliable Vector Guided Softmax Loss for Face Recognition,"Face recognition has witnessed significant progress with the advances of deep convolutional neural networks (CNNs), and the central task of which is how to improve the feature discrimination. To this end, several margin-based (e.g., angular, additive and additive angular margins) softmax loss functions have been proposed to increase the feature margin between different classes. However, despite great achievements have been made, they mainly suffer from four issues: 1) They are based on the assumption of well-cleaned training sets, without considering the consequence of noisy labels inherently existing in most of face recognition datasets; 2) They ignore the importance of informative (e.g., semi-hard) features mining for discriminative learning; 3) They encourage the feature margin only from the perspective of ground truth class, without realizing the discriminability from other non-ground truth classes; and 4) They set the feature margin between different classes to be same and fixed, which may not adapt the situation of unbalanced data in different classes very well. To cope with these issues, this paper develops a novel loss function, which explicitly estimates the noisy labels to drop them and adaptively emphasizes the semi-hard feature vectors from the remaining reliable ones to guide the discriminative feature learning. Thus we can address all the above issues and achieve more discriminative features for face recognition. To the best of our knowledge, this is the first attempt to inherit the advantages of feature-based noisy labels detection, feature mining and feature margin into a unified loss function. Extensive experimental results on a variety of face recognition benchmarks have demonstrated the effectiveness of our method over state-of-the-art alternatives. Our source code is available at http://www.cbsr.ia.ac.cn/users/xiaobowang/. © 1992-2012 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125696426&doi=10.1109%2fTIP.2022.3154293&partnerID=40&md5=ea790b4d1bdab4c136a89a6e6a950382,IEEE Transactions on Image Processing,Exclude,,,
Zhang C.; Nie F.; Wang Z.; Wang R.; Li X.,Fast local representation learning via adaptive anchor graph for image retrieval,"Linear Discriminant Analysis (LDA) is one of most important methods in dimensionality reduction domain, which is limited with Gaussian assumption. Because of the complexity of real data, data often presents non-Gaussian distribution that points in same class can be divided into several sub-clusters and center point is not enough to describe the distribution of data. In order to solve non-Gaussian data, LDA-based methods consider local structure information through measuring each pairwise distance of full connection graph. However, the strategy of establishing fully-connected graph is at expense of high computational complexity and limits it practical and industrial applications. We propose a Fast Local Representation Learning (FLRL) method which leverages anchor points to establish anchor-based graph and uses similarity matrix to depict the relationships of each pairwise connections. Notably, to avoid the affect of noises and redundant features in original space, anchor points and similarity matrix are updated alternately in subspace that local structure of data will be more precise to learn. Extensive pattern classification and image retrieval experiments on several synthetic datasets, well-known datasets and deep features datasets demonstrate the advantages of our method over the state-of-the-art methods. Our source code available on: https://github.com/superzcy/FLRL. © 2021",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113454719&doi=10.1016%2fj.ins.2021.07.088&partnerID=40&md5=b737acc947e76d7285784911053d8f87,Information Sciences,Exclude,,Exclude,
Pham P.; Nguyen L.T.T.; Vo B.; Yun U.,Bot2Vec: A general approach of intra-community oriented representation learning for bot detection in different types of social networks,"Recently, due to the rapid growth of online social networks (OSNs) such as Facebook, Twitter, Weibo, etc. the number of machine accounts/social bots that mimic human users has increased. Along with the development of artificial intelligence (AI), social bots are designed to become smarter and more sophisticated in their efforts at replicating the normal behaviors of human accounts. Constructing reliable and effective bot detection mechanisms is this considered crucial to keep OSNs clean and safe for users. Despite the rapid development of social bot detection platforms, recent state-of-the-art systems still encounter challenges which are related to the model's generalization (and whether it can be adaptable for multiple types of OSNs) as well as the great efforts needed for feature engineering. In this paper, we propose a novel approach of applying network representation learning (NRL) to bot/spammer detection, called Bot2Vec. Our proposed Bot2Vec model is designed to automatically preserve both local neighborhood relations and the intra-community structure of user nodes while learning the representation of given OSNs, without using any extra features based on the user's profile. By applying the intra-community random walk strategy, Bot2Vec promises to achieve better user node embedding outputs than recent state-of-the-art network embedding baselines for bot detection tasks. Extensive experiments on two different types of real-word social networks (Twitter and Tagged) demonstrate the effectiveness of our proposed model. The source code for implementing the Bot2Vec model is available at: https://github.com/phamtheanhphu/bot2vec © 2021 Elsevier Ltd",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103499630&doi=10.1016%2fj.is.2021.101771&partnerID=40&md5=adf5468371679fcdae6fd61dbbdd62ea,Information Systems,Exclude,,Exclude,
Rahman M.K.; Sujon M.H.; Azad A.,Scalable force-directed graph representation learning and visualization,"A graph embedding algorithm embeds a graph into a low-dimensional space such that the embedding preserves the inherent properties of the graph. While graph embedding is fundamentally related to graph visualization, prior work did not exploit this connection explicitly. We develop Force2Vec that uses force-directed graph layout models in a graph embedding setting with an aim to excel in both machine learning (ML) and visualization tasks. We make Force2Vec highly parallel by mapping its core computations to linear algebra and utilizing multiple levels of parallelism available in modern processors. The resultant algorithm is an order of magnitude faster than existing methods (43× faster than DeepWalk, on average) and can generate embeddings from graphs with billions of edges in a few hours. In comparison to existing methods, Force2Vec is better in graph visualization and performs comparably or better in ML tasks such as link prediction, node classification, and clustering. Source code is available at https://github.com/HipGraph/Force2Vec.This paper is an extension of a conference paper by Rahman et al. (in: 20th IEEE international conference on data mining, IEEE ICDM, 2020b) published in IEEE ICDM 2020. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121666477&doi=10.1007%2fs10115-021-01634-9&partnerID=40&md5=77308fa7b26d9bb296e7002eb68154a8,Knowledge and Information Systems,Exclude,,,
Zheng N.; Song X.; Niu Q.; Dong X.; Zhan Y.; Nie L.,Collocation and Try-on Network: Whether an Outfit is Compatible,"Whether an outfit is compatible? Using machine learning methods to assess an outfit's compatibility, namely, fashion compatibility modeling (FCM), has recently become a popular yet challenging topic. However, current FCM studies still perform far from satisfactory, because they only consider the collocation compatibility modeling, while neglecting the natural human habits that people generally evaluate outfit compatibility from both the collocation (discrete assess) and the try-on (unified assess) perspectives. In light of the above analysis, we propose a Collocation and Try-On Network (CTO-Net) for FCM, combining both the collocation and try-on compatibilities. In particular, for the collocation perspective, we devise a disentangled graph learning scheme, where the collocation compatibility is disentangled into multiple fine-grained compatibilities between items; regarding the try-on perspective, we propose an integrated distillation learning scheme to unify all item information in the whole outfit to evaluate the compatibility based on the latent try-on representation. To further enhance the collocation and try-on compatibilities, we exploit the mutual learning strategy to obtain a more comprehensive judgment. Extensive experiments on the real-world dataset demonstrate that our CTO-Net significantly outperforms the state-of-the-art methods. In particular, compared with the competitive counterparts, our proposed CTO-Net significantly improves AUC accuracy from 83.2% to 87.8% and MRR from 15.4% to 21.8%. We have released our source codes and trained models to benefit other researchers.1 © 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119347334&doi=10.1145%2f3474085.3475691&partnerID=40&md5=ca097f26b785fbaf8913ad895eeae0d1,MM 2021 - Proceedings of the 29th ACM International Conference on Multimedia,Exclude,,Exclude,
Dong Y.; Kang J.; Tong H.; Li J.,Individual Fairness for Graph Neural Networks: A Ranking based Approach,"Recent years have witnessed the pivotal role of Graph Neural Networks (GNNs) in various high-stake decision-making scenarios due to their superior learning capability. Close on the heels of the successful adoption of GNNs in different application domains has been the increasing societal concern that conventional GNNs often do not have fairness considerations. Although some research progress has been made to improve the fairness of GNNs, these works mainly focus on the notion of group fairness regarding different subgroups defined by a protected attribute such as gender, age, and race. Beyond that, it is also essential to study the GNN fairness at a much finer granularity (i.e., at the node level) to ensure that GNNs render similar prediction results for similar individuals to achieve the notion of individual fairness. Toward this goal, in this paper, we make an initial investigation to enhance the individual fairness of GNNs and propose a novel ranking based framework - -REDRESS. Specifically, we refine the notion of individual fairness from a ranking perspective, and formulate the ranking based individual fairness promotion problem. This naturally addresses the issue of Lipschitz constant specification and distance calibration resulted from the Lipschitz condition in the conventional individual fairness definition. Our proposed framework REDRESS encapsulates the GNN model utility maximization and the ranking-based individual fairness promotion in a joint framework to enable end-to-end training. It is noteworthy mentioning that REDRESS is a plug-and-play framework and can be easily generalized to any prevalent GNN architectures. Extensive experiments on multiple real-world graphs demonstrate the superiority of REDRESS in achieving a good balance between model utility maximization and individual fairness promotion. Our open source code can be found here: https://github.com/yushundong/REDRESS. © 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114944463&doi=10.1145%2f3447548.3467266&partnerID=40&md5=a596a6ece0e6ae6483939999ace9cb2a,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Exclude,,Exclude,
Shen Z.-A.; Luo T.; Zhou Y.-K.; Yu H.; Du P.-F.,Npi-gnn: Predicting ncrna-protein interactions with deep graph neural networks,"Noncoding RNAs (ncRNAs) play crucial roles in many biological processes. Experimental methods for identifying ncRNA-protein interactions (NPIs) are always costly and time-consuming. Many computational approaches have been developed as alternative ways. In this work, we collected five benchmarking datasets for predicting NPIs. Based on these datasets, we evaluated and compared the prediction performances of existing machine-learning based methods. Graph neural network (GNN) is a recently developed deep learning algorithm for link predictions on complex networks, which has never been applied in predicting NPIs. We constructed a GNN-based method, which is called Noncoding RNA-Protein Interaction prediction using Graph Neural Networks (NPI-GNN), to predict NPIs. The NPI-GNN method achieved comparable performance with state-of-The-Art methods in a 5-fold cross-validation. In addition, it is capable of predicting novel interactions based on network information and sequence information. We also found that insufficient sequence information does not affect the NPI-GNN prediction performance much, which makes NPI-GNN more robust than other methods. As far as we can tell, NPI-GNN is the first end-To-end GNN predictor for predicting NPIs. All benchmarking datasets in this work and all source codes of the NPI-GNN method have been deposited with documents in a GitHub repo (https://github.com/AshuiRUA/NPI-GNN).  © 2021 The Author(s) 2021. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113850036&doi=10.1093%2fbib%2fbbab051&partnerID=40&md5=40ba97ed5b0690a7a208b7c1f6a50d07,Briefings in Bioinformatics,Exclude,,,
Lai V.D.; Nguyen M.V.; Nguyen T.H.; Dernoncourt F.,Graph Learning Regularization and Transfer Learning for Few-Shot Event Detection,"We address the poor generalization of few-shot learning models for event detection (ED) using transfer learning and representation regularization. In particular, we propose to transfer knowledge from open-domain word sense disambiguation into few-shot learning models for ED to improve their generalization to new event types. We also propose a novel training signal derived from dependency graphs to regularize the representation learning for ED. Moreover, we evaluate few-shot learning models for ED with a large-scale human-annotated ED dataset to obtain more reliable insights for this problem. Our comprehensive experiments demonstrate that the proposed model outperforms state-of-the-art baseline models in the few-shot learning and supervised learning settings for ED. Code and data splits are available at https://github.com/laiviet/ed-fsl. © 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111632172&doi=10.1145%2f3404835.3463054&partnerID=40&md5=c8bfbe4b800678547eff9d3781cc031e,SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval,Exclude,,Exclude,
Ferdowsi S.; Borissov N.; Knafou J.; Amini P.; Teodoro D.,Classification of hierarchical text using geometric deep learning: the case of clinical trials corpus,"We consider the hierarchical representation of documents as graphs and use geometric deep learning to classify them into different categories. While graph neural networks can efficiently handle the variable structure of hierarchical documents using the permutation invariant message passing operations, we show that we can gain extra performance improvements using our proposed selective graph pooling operation that arises from the fact that some parts of the hierarchy are invariable across different documents. We applied our model to classify clinical trial (CT) protocols into completed and terminated categories. We use bag-of-words based, as well as pre-trained transformer-based embeddings to featurize the graph nodes, achieving f1-scores ' 0.85 on a publicly available large scale CT registry of around 360K protocols. We further demonstrate how the selective pooling can add insights into the CT termination status prediction. We make the source code and dataset splits accessible. © 2021 Association for Computational Linguistics",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127437273&partnerID=40&md5=979a97333e000d8f1a49752fefa14969,"EMNLP 2021 - 2021 Conference on Empirical Methods in Natural Language Processing, Proceedings",Exclude,,,
Liang B.; Fu Y.; Gui L.; Yang M.; Du J.; He Y.; Xu R.,Target-adaptive graph for cross-target stance detection,"Target plays an essential role in stance detection of an opinionated review/claim, since the stance expressed in the text often depends on the target. In practice, we need to deal with targets unseen in the annotated training data. As such, detecting stance for an unknown or unseen target is an important research problem. This paper presents a novel approach that automatically identifies and adapts the target-dependent and target-independent roles that a word plays with respect to a specific target in stance expressions, so as to achieve cross-target stance detection. More concretely, we explore a novel solution of constructing heterogeneous target-adaptive pragmatics dependency graphs (TPDG) for each sentence towards a given target. An in-target graph is constructed to produce inherent pragmatics dependencies of words for a distinct target. In addition, another cross-target graph is constructed to develop the versatility of words across all targets for boosting the learning of dominant word-level stance expressions available to an unknown target. A novel graph-aware model with interactive Graphical Convolutional Network (GCN) blocks is developed to derive the target-adaptive graph representation of the context for stance detection. The experimental results on a number of benchmark datasets show that our proposed model outperforms state-of-the-art methods in cross-target stance detection.  Â© 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107965243&doi=10.1145%2f3442381.3449790&partnerID=40&md5=e5f78b3d026071f7874190c0b61eb333,"The Web Conference 2021 - Proceedings of the World Wide Web Conference, WWW 2021",Exclude,,Exclude,
Zhu Y.; Xu X.; Shen F.; Ji Y.; Gao L.; Shen H.T.,PoseGTAC: Graph Transformer Encoder-Decoder with Atrous Convolution for 3D Human Pose Estimation,"Graph neural networks (GNNs) have been widely used in the 3D human pose estimation task, since the pose representation of a human body can be naturally modeled by the graph structure. Generally, most of the existing GNN-based models utilize the restricted receptive fields of filters and single-scale information, while neglecting the valuable multi-scale contextual information. To tackle this issue, we propose a novel model named Graph Transformer Encoder-Decoder with Atrous Convolution (PoseGTAC), to effectively extract multi-scale context and long-range information. Specifically, our PoseGTAC model has two key components: Graph Atrous Convolution (GAC) and Graph Transformer Layer (GTL), which are respectively for the extraction of local multi-scale and global long-range information. They are combined and stacked in an encoder-decoder structure, where graph pooling and unpooling are adopted for the interaction of multi-scale information from local to global aspect (e.g., part-scale and body-scale). Extensive experiments on the Human3.6M and MPI-INF-3DHP datasets demonstrate that the proposed PoseGTAC model achieves state-of-the-art performance. © 2021 International Joint Conferences on Artificial Intelligence. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125493982&partnerID=40&md5=0a69e98a04ad6dc6334ff779983a46d9,IJCAI International Joint Conference on Artificial Intelligence,Exclude,,Exclude,
Yang J.; Liu Z.; Xiao S.; Li C.; Lian D.; Agrawal S.; Singh A.; Sun G.; Xie X.,GraphFormers: GNN-nested Transformers for Representation Learning on Textual Graph,"The representation learning on textual graph is to generate low-dimensional embeddings for the nodes based on the individual textual features and the neighbourhood information. Recent breakthroughs on pretrained language models and graph neural networks push forward the development of corresponding techniques. The existing works mainly rely on the cascaded model architecture: the textual features of nodes are independently encoded by language models at first; the textual embeddings are aggregated by graph neural networks afterwards. However, the above architecture is limited due to the independent modeling of textual features. In this work, we propose GraphFormers, where layerwise GNN components are nested alongside the transformer blocks of language models. With the proposed architecture, the text encoding and the graph aggregation are fused into an iterative workflow, making each node's semantic accurately comprehended from the global perspective. In addition, a progressive learning strategy is introduced, where the model is successively trained on manipulated data and original data to reinforce its capability of integrating information on graph. Extensive evaluations are conducted on three large-scale benchmark datasets, where GraphFormers outperform the SOTA baselines with comparable running efficiency. The source code is released at https://github.com/microsoft/GraphFormers. © 2021 Neural information processing systems foundation. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130911254&partnerID=40&md5=a85ee375fb996f485a6271234eb51bdc,Advances in Neural Information Processing Systems,Exclude,,,
Liang Y.; Li H.; Guo B.; Yu Z.; Zheng X.; Samtani S.; Zeng D.D.,Fusion of heterogeneous attention mechanisms in multi-view convolutional neural network for text classification,"The rapid proliferation of user generated content has given rise to large volumes of text corpora. Increasingly, scholars, researchers, and organizations employ text classification to mine novel insights for high-impact applications. Despite their prevalence, conventional text classification methods rely on labor-intensive feature engineering efforts that are task specific, omit long-term relationships, and are not suitable for the rapidly evolving domains. While an increasing body of deep learning and attention mechanism literature aim to address these issues, extant methods often represent text as a single view and omit multiple sets of features at varying levels of granularity. Recognizing that these issues often result in performance degradations, we propose a novel Spatial View Attention Convolutional Neural Network (SVA-CNN). SVA-CNN leverages an innovative and carefully designed set of multi-view representation learning, a combination of heterogeneous attention mechanisms and CNN-based operations to automatically extract and weight multiple granularities and fine-grained representations. Rigorously evaluating SVA-CNN against prevailing text classification methods on five large-scale benchmark datasets indicates its ability to outperform extant deep learning-based classification methods in both performance and training time for document classification, sentiment analysis, and thematic identification applications. To facilitate model reproducibility and extensions, SVA-CNN's source code is also available via GitHub. © 2020 Elsevier Inc.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093960486&doi=10.1016%2fj.ins.2020.10.021&partnerID=40&md5=dc80c79805540851d1b9a9087c4d268b,Information Sciences,Exclude,,,
Omori T.; Maruyama K.; Ohnishi A.,Lightweight operation history graph for traceability on program elements,"History data of edit operations are more beneficial than those stored in version control systems since they provide detailed information on how source code was changed. Meanwhile, a large number of recorded edit operations discourage developers and researchers from roughly understanding the changes. To assist with this task, it is desirable that they easily obtain traceability links for changed program elements over two source code snapshots before and after a code change. In this paper, we propose a graph representation called Operation History Graph (OHG), which presents code change information with such traceability links that are inferred from the history of edit operations. An OHG instance is generated by parsing any source code snapshot restored by edit histories and combining resultant abstract syntax trees (ASTs) into a single graph structure. To improve the performance of building graph instances, we avoided simply maintaining every program element. Any program element presenting the inner-structure of methods and non-changed elements are omitted. In addition, we adopted a lightweight static analysis for type name resolving to reduce required memory resource in the analysis while the accuracy of name resolving is preserved. Moreover, we assign a specific ID to each node and edge in the graph instance so that a part of the graph data can be separately stored and loaded on demand. These decisions make it feasible to build, manipulate, and store the graph with limited computer resources. To demonstrate the usefulness of the proposed operation history graph and verify whether detected traceability links are sufficient to reveal actual changes of program elements, we implemented tools to generate and manipulate OHG instances. The evaluation on graph generation performance shows that our tool can reduce the required computer resource as compared to another tool authors previously proposed. Moreover, the evaluation on traceability shows that OHG provides traceability links with sufficient accuracy as compared to the baseline approach using GumTree. © 2021 The Institute of Electronics, Information and Communication Engineers",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102028598&doi=10.1587%2ftransinf.2020EDP7129&partnerID=40&md5=00ab61f0ef6c4b7d90ddb4637513e645,IEICE Transactions on Information and Systems,Exclude,,,
Wang T.; Liu S.; Tian Y.; Li K.; Yang M.-H.,Video Matting via Consistency-Regularized Graph Neural Networks,"Learning temporally consistent foreground opacity from videos, i.e., video matting, has drawn great attention due to the blossoming of video conferencing. Previous approaches are built on top of image matting models, which fail in maintaining the temporal coherence when being adapted to videos. They either utilize the optical flow to smooth frame-wise prediction, where the performance is dependent on the selected optical flow model; or naively combine feature maps from multiple frames, which does not model well the correspondence of pixels in adjacent frames. In this paper, we propose to enhance the temporal coherence by Consistency-Regularized Graph Neural Networks (CRGNN) with the aid of a synthesized video matting dataset. CRGNN utilizes Graph Neural Networks (GNN) to relate adjacent frames such that pixels or regions that are incorrectly predicted in one frame can be corrected by leveraging information from its neighboring frames. To generalize our model from synthesized videos to real-world videos, we propose a consistency regularization technique to enforce the consistency on the alpha and foreground when blending them with different backgrounds. To evaluate the efficacy of CRGNN, we further collect a real-world dataset with annotated alpha mattes. Compared with state-of-the-art methods that require hand-crafted trimaps or backgrounds for modeling training, CRGNN generates favorably results with the help of unlabeled real training dataset. The source code and datasets are available at https://github.com/TiantianWang/VideoMattingCRGNN.git. © 2021 IEEE",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127753602&doi=10.1109%2fICCV48922.2021.00486&partnerID=40&md5=70e6c91b3e4db024ec4b1401d17fb310,Proceedings of the IEEE International Conference on Computer Vision,Exclude,,Exclude,
Chen Z.; Zhang T.; Peng X.,A Novel API Recommendation Approach By Using Graph Attention Network,"Although the use of APIs (Application Programming Interfaces) in software program development can effectively improve development efficiency, developers still need to spend more time in finding suitable APIs. To improve the overall development efficiency, many API recommendation approaches have been proposed. However, they could not make good use of the information in the source code, especially for the structural information. The PDG (Program Dependence Graph) of source code can contain both syntactic and structural information, which can be great representations of the source code. Based on the PDG, we propose a new approach, called JARST (Java API Recommendation combining Structural with Textual code information), which recommends the appropriate APIs by analyzing the structure information and text information of the source code. The JARST approach uses a graph neural network to learn source code structure information of PDG and uses a multi-modal approach to learn the text information in the source code. Finally, we combine the structural and textual information of the source code to implement API recommendations. We collect 625 open source Java projects from Github as our experimental objects. The experimental results show that JARST can provide accurate APIs to help software developers facilitate development activities. Moreover, it performs better than the cutting-edge studies including APIRes-CST and APIREC with higher top-k accuracy values. In detail, the improvement achieves up to 35.3%. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146199902&doi=10.1109%2fQRS54544.2021.00082&partnerID=40&md5=cef4668a79de071a6550072240aef8be,"IEEE International Conference on Software Quality, Reliability and Security, QRS",Include,,,
Jain P.; Jain A.; Zhang T.; Abbeel P.; Gonzalez J.E.; Stoica I.,Contrastive Code Representation Learning,"Recent work learns contextual representations of source code by reconstructing tokens from their context. For downstream semantic understanding tasks like code clone detection, these representations should ideally capture program functionality. However, we show that the popular reconstruction-based RoBERTa model is sensitive to source code edits, even when the edits preserve semantics. We propose ContraCode: a contrastive pre-training task that learns code functionality, not form. ContraCode pre-trains a neural network to identify functionally similar variants of a program among many non-equivalent distractors. We scalably generate these variants using an automated source-to-source compiler as a form of data augmentation. Contrastive pretraining outperforms RoBERTa on an adversarial code clone detection benchmark by 39% AUROC. Surprisingly, improved adversarial robustness translates to better accuracy over natural code; ContraCode improves summarization and TypeScript type inference accuracy by 2 to 13 percentage points over competitive baselines. All source is available at https://github.com/parasj/contracode. © 2021 Association for Computational Linguistics",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123338103&partnerID=40&md5=c4c75db6d4500c1998722ed2b782410a,"EMNLP 2021 - 2021 Conference on Empirical Methods in Natural Language Processing, Proceedings",Include,,,
Lin J.; Lee G.H.,Learning Spatial Context with Graph Neural Network for Multi-Person Pose Grouping,"Bottom-up approaches for image-based multi-person pose estimation consist of two stages: (1) keypoint detection and (2) grouping of the detected keypoints to form person instances. Current grouping approaches rely on learned embedding from only visual features that completely ignore the spatial configuration of human poses. In this work, we formulate the grouping task as a graph partitioning problem, where we learn the affinity matrix with a Graph Neural Network (GNN). More specifically, we design a Geometry-aware Association GNN that utilizes spatial information of the keypoints and learns local affinity from the global context. The learned geometry-based affinity is further fused with appearance-based affinity to achieve robust keypoint association. Spectral clustering is used to partition the graph for the formation of the pose instances. Experimental results on two benchmark datasets show that our proposed method outperforms existing appearance-only grouping frameworks, which shows the effectiveness of utilizing spatial context for robust grouping. Source code is available at: https://github.com/jiahaoLjh/PoseGrouping. © 2021 IEEE",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125464543&doi=10.1109%2fICRA48506.2021.9561960&partnerID=40&md5=3d8e6ef1db09b051d945c471adae5886,Proceedings - IEEE International Conference on Robotics and Automation,Exclude,,Exclude,
Li K.; Luo G.; Ye Y.; Li W.; Ji S.; Cai Z.,Adversarial Privacy-Preserving Graph Embedding against Inference Attack,"Recently, the surge in popularity of the Internet of Things (IoT), mobile devices, social media, etc., has opened up a large source for graph data. Graph embedding has been proved extremely useful to learn low-dimensional feature representations from graph-structured data. These feature representations can be used for a variety of prediction tasks from node classification to link prediction. However, the existing graph embedding methods do not consider users' privacy to prevent inference attacks. That is, adversaries can infer users' sensitive information by analyzing node representations learned from graph embedding algorithms. In this article, we propose adversarial privacy graph embedding (APGE), a graph adversarial training framework that integrates the disentangling and purging mechanisms to remove users' private information from learned node representations. The proposed method preserves the structural information and utility attributes of a graph while concealing users' private attributes from inference attacks. Extensive experiments on real-world graph data sets demonstrate the superior performance of APGE compared to the state-of-the-arts. Our source code can be found at https://github.com/KaiyangLi1992/Privacy-Preserving-Social-Network-Embedding.  © 2014 IEEE.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098792453&doi=10.1109%2fJIOT.2020.3036583&partnerID=40&md5=ed62b27c28eec21c63c3f58ead59378c,IEEE Internet of Things Journal,Exclude,,,
Wang G.; Gu R.; Liu Z.; Hu W.; Song M.; Hwang J.-N.,Track without Appearance: Learn Box and Tracklet Embedding with Local and Global Motion Patterns for Vehicle Tracking,"Vehicle tracking is an essential task in the multi-object tracking (MOT) field. A distinct characteristic in vehicle tracking is that the trajectories of vehicles are fairly smooth in both the world coordinate and the image coordinate. Hence, models that capture motion consistencies are of high necessity. However, tracking with the standalone motion-based trackers is quite challenging because targets could get lost easily due to limited information, detection error and occlusion. Leveraging appearance information to assist object re-identification could resolve this challenge to some extent. However, doing so requires extra computation while appearance information is sensitive to occlusion as well. In this paper, we try to explore the significance of motion patterns for vehicle tracking without appearance information. We propose a novel approach that tackles the association issue for long-term tracking with the exclusive fully-exploited motion information. We address the tracklet embedding issue with the proposed reconstruct-to-embed strategy based on deep graph convolutional neural networks (GCN). Comprehensive experiments on the KITTI-car tracking dataset and UA-Detrac dataset show that the proposed method, though without appearance information, could achieve competitive performance with the state-of-the-art (SOTA) trackers. The source code will be available at https://github.com/GaoangW/LGMTracker. © 2021 IEEE",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126220230&doi=10.1109%2fICCV48922.2021.00973&partnerID=40&md5=c18a32675a8d05892024a8a4e2e7cb06,Proceedings of the IEEE International Conference on Computer Vision,Exclude,,Exclude,
Paaßen B.; McBroom J.; Jeffries B.; Yacef K.; Koprinska I.,Mapping Python Programs to Vectors using Recursive Neural Encodings,"Educational data mining involves the application of data mining techniques to student activity. However, in the context of computer programming, many data mining techniques can not be applied because they require vector-shaped input, whereas computer programs have the form of syntax trees. In this paper, we present ast2vec, a neural network that maps Python syntax trees to vectors and back, thereby enabling about a hundred data mining techniques that were previously not applicable. Ast2vec has been trained on almost half a million programs of novice programmers and is designed to be applied across learning tasks without re-training, meaning that users can apply it without any need for deep learning. We demonstrate the generality of ast2vec in three settings. First, we provide example analyses using ast2vec on a classroom-sized dataset, involving two novel techniques, namely progress-variance projection for visualization and a dynamical systems analysis for prediction. In these examples, we also explain how ast2vec can be utilized for educational decisions. Second, we consider the ability of ast2vec to recover the original syntax tree from its vector representation on the training data and two other large-scale programming datasets. Finally, we evaluate the predictive capability of a linear dynamical system on top of ast2vec, obtaining similar results to techniques that work directly on syntax trees while being much faster (constant- instead of linear-time processing). We hope ast2vec can augment the educational data mining toolkit by making analyses of computer programs easier, richer, and more efficient. © 2021. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132630551&doi=10.5281%2fzenodo.5634224&partnerID=40&md5=7aa89301e2e8d1ae526fd13f58e9cd3f,Journal of Educational Data Mining,Include,,,
Shen B.; Zhang W.; Yu A.; Shi Y.; Zhao H.; Jin Z.,SoManyConflicts: Resolve Many Merge Conflicts Interactively and Systematically,"Code merging plays an important role in collaborative software development. However, it is often tedious and error-prone for developers to manually resolve merge conflicts, especially when there are many conflicts after merging long-lived branches or parallel versions. In this paper, we present SoManyConflicts, a language-agnostic approach to help developers resolve merge conflicts systematically, by utilizing their interrelations (e.g., dependency, similarity, etc.). SoManyConflicts employs a graph representation to model these interrelations and provides 3 major features: 1) cluster and order related conflict based on the graph connectivity; 2) suggest related conflicts of one focused conflict based on the topological sorting, 3) suggest resolution strategies for unresolved conflicts based already resolved ones. We have implemented SoManyConflicts as a Visual Studio Code extension that supports multiple languages (Java, JavaScript, and TypeScript, etc.), which is briefly introduced in the video: https://youtu.be/asWhj1KTU. The source code is publicly available at: https://github.com/Symbolk/somanyconflicts.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125477165&doi=10.1109%2fASE51524.2021.9678937&partnerID=40&md5=a36cb0fef278e9cbf23cd2720558d864,"Proceedings - 2021 36th IEEE/ACM International Conference on Automated Software Engineering, ASE 2021",Exclude,,Include,
Mou C.; Zhang J.; Wu Z.,Dynamic Attentive Graph Learning for Image Restoration,"Non-local self-similarity in natural images has been verified to be an effective prior for image restoration. However, most existing deep non-local methods assign a fixed number of neighbors for each query item, neglecting the dynamics of non-local correlations. Moreover, the non-local correlations are usually based on pixels, prone to be biased due to image degradation. To rectify these weaknesses, in this paper, we propose a dynamic attentive graph learning model (DAGL) to explore the dynamic non-local property on patch level for image restoration. Specifically, we propose an improved graph model to perform patch-wise graph convolution with a dynamic and adaptive number of neighbors for each node. In this way, image content can adaptively balance over-smooth and over-sharp artifacts through the number of its connected neighbors, and the patch-wise non-local correlations can enhance the message passing process. Experimental results on various image restoration tasks: synthetic image denoising, real image denoising, image demosaicing, and compression artifact reduction show that our DAGL can produce state-of-the-art results with superior accuracy and visual quality. The source code is available at https://github.com/jianzhangcs/DAGL. © 2021 IEEE",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123396877&doi=10.1109%2fICCV48922.2021.00429&partnerID=40&md5=d015b04d9dea02c4870c083fff12657a,Proceedings of the IEEE International Conference on Computer Vision,Exclude,,,
Zhang H.; Zhan T.; Basu S.; Davidson I.,A framework for deep constrained clustering,"The area of constrained clustering has been extensively explored by researchers and used by practitioners. Constrained clustering formulations exist for popular algorithms such as k-means, mixture models, and spectral clustering but have several limitations. A fundamental strength of deep learning is its flexibility, and here we explore a deep learning framework for constrained clustering and in particular explore how it can extend the field of constrained clustering. We show that our framework can not only handle standard together/apart constraints (without the well documented negative effects reported earlier) generated from labeled side information but more complex constraints generated from new types of side information such as continuous values and high-level domain knowledge. Furthermore, we propose an efficient training paradigm that is generally applicable to these four types of constraints. We validate the effectiveness of our approach by empirical results on both image and text datasets. We also study the robustness of our framework when learning with noisy constraints and show how different components of our framework contribute to the final performance. Our source code is available at: http://github.com/blueocean92. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100032167&doi=10.1007%2fs10618-020-00734-4&partnerID=40&md5=524db5b822e63bd4e599eb727d2c31ae,Data Mining and Knowledge Discovery,Exclude,,,
Garg S.; Vankadari M.; Milford M.,SeqMatchNet: Contrastive Learning with Sequence Matching for Place Recognition & Relocalization,"Visual Place Recognition (VPR) for mobile robot global relocalization is a well-studied problem, where contrastive learning based representation training methods have led to state-of-the-art performance. However, these methods are mainly designed for single image based VPR, where sequential information, which is ubiquitous in robotics, is only used as a post-processing step for filtering single image match scores, but is never used to guide the representation learning process itself. In this work, for the first time, we bridge the gap between single image representation learning and sequence matching through SeqMatchNet which transforms the single image descriptors such that they become more responsive to the sequence matching metric. We propose a novel triplet loss formulation where the distance metric is based on sequence matching, that is, the aggregation of temporal order-based Euclidean distances computed using single images. We use the same metric for mining negatives online during the training which helps the optimization process by selecting appropriate positives and harder negatives. To overcome the computational overhead of sequence matching for negative mining, we propose a 2D convolution based formulation of sequence matching for efficiently aggregating distances within a distance matrix computed using single images. We show that our proposed method achieves consistent gains in performance as demonstrated on four benchmark datasets. Source code available at https://github.com/oravus/SeqMatchNet. © 2021 Proceedings of Machine Learning Research. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171758542&partnerID=40&md5=2dda941d6bf8f314957cd203db3d2e0c,Proceedings of Machine Learning Research,Exclude,,Exclude,
Ivanov V.; Romanov V.; Succi G.,Predicting Type Annotations for Python using Embeddings from Graph Neural Networks,"An intelligent tool for type annotations in Python would increase the productivity of developers. Python is a dynamic programming language, and predicting types using static analysis is difficult. Existing techniques for type prediction use deep learning models originated in the area of Natural Language Processing. These models depend on the quality of embeddings for source code tokens. We compared approaches for pre-training embeddings for source code. Specifically, we compared FastText embeddings to embeddings trained with Graph Neural Networks (GNN). Our experiments showed that GNN embeddings outperformed FastText embeddings on the task of type prediction. Moreover, they seem to encode complementary information since the prediction quality increases when both types of embeddings are used. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137946240&partnerID=40&md5=ab98f6d51366117e312176dbdc39bd0f,"International Conference on Enterprise Information Systems, ICEIS - Proceedings",Include,,Include,
Farruque N.; Goebel R.; Zaiane O.R.; Sivapalan S.,Explainable Zero-Shot Modelling of Clinical Depression Symptoms from Text,"We focus on exploring various approaches of Zero-Shot Learning (ZSL) and their explainability for a challenging yet important supervised learning task, notorious for training data scarcity, i.e. Depression Symptoms Detection (DSD) from text. We start with a comprehensive synthesis of different components of our ZSL modelling and analysis of our ground truth samples and Depression symptom clues curation process with the help of a practicing Clinician. We next analyze the accuracy of various state-of-the-art ZSL models and their potential enhancements for our task. Further, we sketch a framework for the use of ZSL for hierarchical text-based explanation mechanism, which we call, Syntax Tree-Guided Semantic Explanation (STEP). Finally, we summarize experiments from which we conclude that we can use ZSL models and achieve reasonable accuracy and explainability, measured by a proposed Explainability Index (EI). This work is, to our knowledge, the first work to exhaustively explore the efficacy of ZSL models for DSD task, both in terms of accuracy and explainability. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125841149&doi=10.1109%2fICMLA52953.2021.00237&partnerID=40&md5=83f225e007a5cb09f2eeff98545c7551,"Proceedings - 20th IEEE International Conference on Machine Learning and Applications, ICMLA 2021",Exclude,,,
Wu Z.; Jain P.; Wright M.A.; Mirhoseini A.; Gonzalez J.E.; Stoica I.,Representing Long-Range Context for Graph Neural Networks with Global Attention,"Graph neural networks are powerful architectures for structured datasets. However, current methods struggle to represent long-range dependencies. Scaling the depth or width of GNNs is insufficient to broaden receptive fields as larger GNNs encounter optimization instabilities such as vanishing gradients and representation oversmoothing, while pooling-based approaches have yet to become as universally useful as in computer vision. In this work, we propose the use of Transformer-based self-attention to learn long-range pairwise relationships, with a novel “readout” mechanism to obtain a global graph embedding. Inspired by recent computer vision results that find position-invariant attention performant in learning long-range relationships, our method, which we call GraphTrans, applies a permutation-invariant Transformer module after a standard GNN module. This simple architecture leads to state-of-the-art results on several graph classification tasks, outperforming methods that explicitly encode graph structure. Our results suggest that purely-learning-based approaches without graph structure may be suitable for learning high-level, long-range relationships on graphs. Code for GraphTrans is available at https://github.com/ucbrise/graphtrans. © 2021 Neural information processing systems foundation. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131637028&partnerID=40&md5=6aa2fef13065131a1312db72e24fc629,Advances in Neural Information Processing Systems,Exclude,,Exclude,
Ramadan T.; Islam T.Z.; Phelps C.; Pinnow N.; Thiagarajan J.J.,Comparative Code Structure Analysis using Deep Learning for Performance Prediction,"Performance analysis has always been an afterthought during the application development process, focusing on application correctness first. The learning curve of the existing static and dynamic analysis tools are steep, which requires understanding low-level details to interpret the findings for actionable optimizations. Additionally, application performance is a function of a number of unknowns stemming from the application-, runtime-, and interactions between the OS and underlying hardware, making it difficult to model using any deep learning technique, especially without a large labeled dataset. In this paper, we address both of these problems by presenting a large corpus of a labeled dataset for the community and take a comparative analysis approach to mitigate all unknowns except their source code differences between different correct implementations of the same problem. We put the power of deep learning to the test for automatically extracting information from the hierarchical structure of abstract syntax trees to represent source code. This paper aims to assess the feasibility of using purely static information (e.g., abstract syntax tree or AST) of applications to predict performance change based on the change in code structure. This research will enable performance-aware application development since every version of the application will continue to contribute to the corpora, which will enhance the performance of the model. We evaluate several deep learning-based representation learning techniques for source code. Our results show that tree-based Long Short-Term Memory (LSTM) models can leverage source code's hierarchical structure to discover latent representations. Specifically, LSTM-based predictive models built using a single problem and a combination of multiple problems can correctly predict if a source code will perform better or worse up to 84% and 73% of the time, respectively.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105381706&doi=10.1109%2fISPASS51385.2021.00032&partnerID=40&md5=63fe68357a1b32bc8ca94c6f9bdb3311,"Proceedings - 2021 IEEE International Symposium on Performance Analysis of Systems and Software, ISPASS 2021",Include,,,
Gurugubelli S.; Chepuri S.P.,Learning Multi-layer Graphs and a Common Representation for Clustering,"In this paper, we focus on graph learning from multi-view data of shared entities for spectral clustering. We can explain interactions between the entities in multi-view data using a multi-layer graph with a common vertex set, which represents the shared entities. The edges of different layers capture the relationships of the entities. Assuming a smoothness data model, we jointly estimate the graph Laplacian matrices of the individual graph layers and low-dimensional embedding of the common vertex set. We constrain the rank of the graph Laplacian matrices to obtain multi-component graph layers for clustering. The low-dimensional node embeddings, common to all the views, assimilate the complementary information present in the views. We propose an efficient solver based on alternating minimization to solve the proposed multi-layer multi-component graph learning problem. Numerical experiments on synthetic and real datasets demonstrate that the proposed algorithm outperforms state-of-the-art multi-view clustering techniques. © 2021 European Signal Processing Conference. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117754861&doi=10.23919%2fEUSIPCO54536.2021.9615920&partnerID=40&md5=0b195741d226a3b0d8eba26fcd9bc9a6,European Signal Processing Conference,Exclude,,Exclude,
Yu S.-Y.; Chhetri S.R.; Canedo A.; Goyal P.; Al Faruque M.A.,Pykg2vec: A python library for knowledge graph embedding,"Pykg2vec is a Python library for learning the representations of the entities and relations in knowledge graphs. Pykg2vec's exible and modular software architecture currently imple-ments 25 state-of-the-art knowledge graph embedding algorithms, and is designed to easily incorporate new algorithms. The goal of pykg2vec is to provide a practical and educational platform to accelerate research in knowledge graph representation learning. Pykg2vec is built on top of PyTorch and Python's multiprocessing framework and provides modules for batch generation, Bayesian hyperparameter optimization, evaluation of KGE tasks, em-bedding, and result visualization. Pykg2vec is released under the MIT License and is also available in the Python Package Index (PyPI). The source code of pykg2vec is available at http://github.com/Sujit-O/pykg2vecy. © 2021 Microtome Publishing. All rights reserved.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105881704&partnerID=40&md5=4f8ef2c092a9b250077652f2bdde449b,Journal of Machine Learning Research,Exclude,,Exclude,
Agarap A.F.; Azcarraga A.P.,Improving k-Means Clustering Performance with Disentangled Internal Representations,"Deep clustering algorithms combine representation learning and clustering by jointly optimizing a clustering loss and a non-clustering loss. In such methods, a deep neural network is used for representation learning together with a clustering network. Instead of following this framework to improve clustering performance, we propose a simpler approach of optimizing the entanglement of the learned latent code representation of an autoencoder. We define entanglement as how close pairs of points from the same class or structure are, relative to pairs of points from different classes or structures. To measure the entanglement of data points, we use the soft nearest neighbor loss, and expand it by introducing an annealing temperature factor. Using our proposed approach, the test clustering accuracy was 96.2% on the MNIST dataset, 85.6% on the Fashion-MNIST dataset, and 79.2% on the EMNIST Balanced dataset, outperforming our baseline models. © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093828193&doi=10.1109%2fIJCNN48605.2020.9207192&partnerID=40&md5=525aa14dd5f1d39daf6770e653aeab32,Proceedings of the International Joint Conference on Neural Networks,Exclude,,,
Romanov V.,Evaluating importance of edge types when using graph neural network for predicting return types of Python functions,"The static prediction of types for dynamic programming languages is a challenging and important problem. Some success for Python was demonstrated by analyzing docstrings, still, a large portion of code comes without thorough documentation. To target this problem in this work we attempt to predict return type annotations for Python functions by looking at function usage patterns. We analyzed a collection of Python packages and created a graph that captures global relationships between source code elements such as imports, calls, and definitions. Moreover, we train embeddings for functions and evaluate how the performance of predicting return types is affected by removing one of the relationship types from the dataset.  © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097709365&doi=10.1145%2f3426430.3428135&partnerID=40&md5=aaec256bd65fc3a29df25994889df992,"SPLASH Companion 2020 - Companion Proceedings of the 2020 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity",Include,,Include,
She Y.; Tang S.; Zhang Q.,Indirect Gaussian Graph Learning beyond Gaussianity,"This paper studies how to capture dependency graph structures from real data that may not be multivariate Gaussian. Starting from marginal loss functions not necessarily derived from probability distributions, we utilize an additive over-parametrization with shrinkage to incorporate variable dependencies into the criterion. An iterative Gaussian graph learning algorithm is proposed with ease in implementation. Statistical analysis shows that the estimators achieve satisfactory accuracy with the error measured in terms of a proper Bregman divergence. Real-life examples in different settings are given to demonstrate the efficacy of the proposed methodology. © 2013 IEEE.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060280628&doi=10.1109%2fTNSE.2019.2893383&partnerID=40&md5=5865b37140326b53970f67215983e566,IEEE Transactions on Network Science and Engineering,Exclude,,,
Cui L.; Seo H.; Tabar M.; Ma F.; Wang S.; Lee D.,DETERRENT: Knowledge Guided Graph Attention Network for Detecting Healthcare Misinformation,"To provide accurate and explainable misinformation detection, it is often useful to take an auxiliary source (e.g., social context and knowledge base) into consideration. Existing methods use social contexts such as users' engagements as complementary information to improve detection performance and derive explanations. However, due to the lack of sufficient professional knowledge, users seldom respond to healthcare information, which makes these methods less applicable. In this work, to address these shortcomings, we propose a novel knowledge guided graph attention network for detecting health misinformation better. Our proposal, named as DETERRENT, leverages on the additional information from medical knowledge graph by propagating information along with the network, incorporates a Medical Knowledge Graph and an Article-Entity Bipartite Graph, and propagates the node embeddings through Knowledge Paths. In addition, an attention mechanism is applied to calculate the importance of entities to each article, and the knowledge guided article embeddings are used for misinformation detection. DETERRENT addresses the limitation on social contexts in the healthcare domain and is capable of providing useful explanations for the results of detection. Empirical validation using two real-world datasets demonstrated the effectiveness of DETERRENT. Comparing with the best results of eight competing methods, in terms of F1 Score, DETERRENT outperforms all methods by at least 4.78% on the diabetes dataset and 12.79% on cancer dataset. We release the source code of DETERRENT at: https://github.com/cuilimeng/DETERRENT. © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090425194&doi=10.1145%2f3394486.3403092&partnerID=40&md5=aa451a65473a7d1f2f73940820a77483,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Exclude,,,
Fan R.; Wang H.; Wang Y.; Liu M.; Pitas I.,Graph Attention Layer Evolves Semantic Segmentation for Road Pothole Detection: A Benchmark and Algorithms,"Existing road pothole detection approaches can be classified as computer vision-based or machine learning-based. The former approaches typically employ 2D image analysis/ understanding or 3D point cloud modeling and segmentation algorithms to detect (i.e., recognize and localize) road potholes from vision sensor data, e.g., RGB images and/or depth/disparity images. The latter approaches generally address road pothole detection using convolutional neural networks (CNNs) in an end-to-end manner. However, road potholes are not necessarily ubiquitous and it is challenging to prepare a large well-annotated dataset for CNN training. In this regard, while computer vision-based methods were the mainstream research trend in the past decade, machine learning-based methods were merely discussed. Recently, we published the first stereo vision-based road pothole detection dataset and a novel disparity transformation algorithm, whereby the damaged and undamaged road areas can be highly distinguished. However, there are no benchmarks currently available for state-of-the-art (SoTA) CNNs trained using either disparity images or transformed disparity images. Therefore, in this paper, we first discuss the SoTA CNNs designed for semantic segmentation and evaluate their performance for road pothole detection with extensive experiments. Additionally, inspired by graph neural network (GNN), we propose a novel CNN layer, referred to as graph attention layer (GAL), which can be easily deployed in any existing CNN to optimize image feature representations for semantic segmentation. Our experiments compare GAL-DeepLabv3+, our best-performing implementation, with nine SoTA CNNs on three modalities of training data: RGB images, disparity images, and transformed disparity images. The experimental results suggest that our proposed GAL-DeepLabv3+ achieves the best overall pothole detection accuracy on all training data modalities. The source code, dataset, and benchmark are publicly available at mias.group/GAL-Pothole-Detection.  © 1992-2012 IEEE.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115798280&doi=10.1109%2fTIP.2021.3112316&partnerID=40&md5=b55d02cbc67f80debedc4597b5b4b31d,IEEE Transactions on Image Processing,Exclude,,Exclude,
Wang W.; Li G.; Shen S.; Xia X.; Jin Z.,Modular Tree Network for Source Code Representation Learning,"Learning representation for source code is a foundation of many program analysis tasks. In recent years, neural networks have already shown success in this area, but most existing models did not make full use of the unique structural information of programs. Although abstract syntax tree (AST)-based neural models can handle the tree structure in the source code, they cannot capture the richness of different types of substructure in programs. In this article, we propose a modular tree network that dynamically composes different neural network units into tree structures based on the input AST. Different from previous tree-structural neural network models, a modular tree network can capture the semantic differences between types of AST substructures. We evaluate our model on two tasks: program classification and code clone detection. Our model achieves the best performance compared with state-of-the-art approaches in both tasks, showing the advantage of leveraging more elaborate structure information of the source code.  © 2020 ACM.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092714268&doi=10.1145%2f3409331&partnerID=40&md5=d905cdf7f3fff0be2096f74ffa0ca9ba,ACM Transactions on Software Engineering and Methodology,Include,,,
Mizanur Rahman S.; Bayer J.; Dengel A.,Graph-Based Object Detection Enhancement for Symbolic Engineering Drawings,"The identification of graphic symbols and interconnections is a primary task in the digitization of symbolic engineering diagram images like circuit diagrams. Recent approaches propose the use of Convolutional Neural Networks to the identification of symbols in engineering diagrams. Although recall and precision from CNN based object recognition algorithms are high, false negatives result in some input symbols being missed or misclassified. The missed symbols induce errors in the circuit level features of the extracted circuit, which can be identified using graph level analysis. In this work, a custom annotated printed circuit image set, which is made publicly available in conjunction with the source code of the experiments of this paper, is used to fine-tune a Faster RCNN network to recognise component symbols and blob detection to identify inter-connections between symbols to generate a graph representation of the extracted circuit components. The graph structure is then analysed using graph convolutional neural networks and node degree comparison to identify graph anomalies potentially resulting from false negatives from the object recognition module. Anomaly predictions are then used to identify image regions with potential missed symbols, which are subject to image transforms and re-input to the Faster RCNN, which results in a significant improvement in component recall, which increases to 91% on the test set. The general tools used by the analysis pipeline can also be applied to other Engineering Diagrams with the availability of similar datasets. © 2021, Springer Nature Switzerland AG.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115289435&doi=10.1007%2f978-3-030-86198-8_6&partnerID=40&md5=fd4d14ded12b29d1ee8031d9e7dd22c0,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Ye G.; Tang Z.; Wang H.; Fang D.; Fang J.; Huang S.; Wang Z.,Deep program structure modeling through multi-relational graph-based learning,"Deep learning is emerging as a promising technique for buildingpredictive models to support code-related tasks like performanceoptimization and code vulnerability detection. One of the criticalaspects of building a successful predictive model is having theright representation to characterize the model input for the giventask. Existing approaches in the area typically treat the programstructure as a sequential sequence but fail to capitalize on the richsemantics of data and control flow information, for which graphsare a proven representation structure.We present Poem1, a novel framework that automatically learnsuseful code representations from graph-based program structures.At the core of Poem is a graph neural network (GNN) that is specially designed for capturing the syntax and semantic informationfrom the program abstract syntax tree and the control and dataflow graph. As a departure from existing GNN-based code modeling techniques, our network simultaneously learns over multiplerelations of a program graph. This capability enables the learningframework to distinguish and reason about the diverse code relationships, be it a data or a control flow or any other relationshipsthat may be important for the downstream processing task.We apply Poem to four representative tasks that require a strongability to reason about the program structure: heterogeneous devicemapping, parallel thread coarsening, loop vectorization and codevulnerability detection. We evaluate Poem on programs written inOpenCL, C, Java and Swift, and compare it against nine learningbased methods. Experimental results show that Poem consistentlyoutperforms all competing methods across evaluation settings.  © 2020 Association for Computing Machinery.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094208858&doi=10.1145%2f3410463.3414670&partnerID=40&md5=7e53d7f68569e46dadc23171ed2dae04,"Parallel Architectures and Compilation Techniques - Conference Proceedings, PACT",Include,,,
Richter C.; Hüllermeier E.; Jakobs M.-C.; Wehrheim H.,Algorithm selection for software validation based on graph kernels,"Algorithm selection is the task of choosing an algorithm from a given set of candidate algorithms when faced with a particular problem instance. Algorithm selection via machine learning (ML) has recently been successfully applied for various problem classes, including computationally hard problems such as SAT. In this paper, we study algorithm selection for software validation, i.e., the task of choosing a software validation tool for a given validation instance. A validation instance consists of a program plus properties to be checked on it. The application of machine learning techniques to this task first of all requires an appropriate representation of software. To this end,we propose a dedicated kernel function, which compares two programs in terms of their similarity, thus making the algorithm selection task amenable to kernel-based machine learning methods. Our kernel operates on a graph representation of source code mixing elements of control-flow and program-dependence graphs with abstract syntax trees.Thus, given two such representations as input, the kernel function yields a real-valued score that can be interpreted as a degree of similarity. We experimentally evaluate our kernel in two learning scenarios, namely a classification and a ranking problem: (1) selecting between a verification and a testing tool for bug finding (i.e., property violation), and (2) ranking several verification tools,from presumably best to worst, for property proving. The evaluation, which is based on data sets from the annual software verification competition SV-COMP, demonstrates our kernel to generalize well and to achieve rather high prediction accuracy, both for the classification and the ranking task. © 2020, The Author(s).",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083878337&doi=10.1007%2fs10515-020-00270-x&partnerID=40&md5=cf9df51fce68c365deb53d95201ca5b3,Automated Software Engineering,Include,,Include,
Breit A.; Ott S.; Agibetov A.; Samwald M.,OpenBioLink: A benchmarking framework for large-scale biomedical link prediction,"Recently, novel machine-learning algorithms have shown potential for predicting undiscovered links in biomedical knowledge networks. However, dedicated benchmarks for measuring algorithmic progress have not yet emerged. With OpenBioLink, we introduce a large-scale, high-quality and highly challenging biomedical link prediction benchmark to transparently and reproducibly evaluate such algorithms. Furthermore, we present preliminary baseline evaluation results. Availability and implementation: Source code and data are openly available at https://github.com/OpenBioLink/OpenBioLink.  © 2020 The Author(s). Published by Oxford University Press. All rights reserved.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087532321&doi=10.1093%2fbioinformatics%2fbtaa274&partnerID=40&md5=7de18505fe5301d30612131cbd9b862a,Bioinformatics,Exclude,,Exclude,
Luo F.; Wang X.; Wu Q.; Liang J.; Qiu X.; Bao Z.,HQADeepHelper: A Deep Learning System for Healthcare Question Answering,"It is challenging to generate high quality answers for healthcare queries in online platforms. Recent studies proposed deep models for healthcare question answering (HQA) tasks. However, these models have not been thoroughly compared, and they were only tested on self-created datasets. This paper demonstrates a novel system, denoted by HQADeepHelper, to facilitate the learning and practicing of deep models for HQA. We have implemented a wide spectrum of state-of-the-art deep models for HQA retrieval. Users can upload self-collected HQA datasets and knowledge graphs, and do simple configurations by selecting datasets, knowledge graphs, neural network models, and evaluation metrics. Based on user's configuration specified, the system can automatically train and test the model, conduct extensive experimental evaluation of the models selected, and report comprehensive findings. The reports provide new insights about the strengths and weaknesses of deep models that can guide practitioners to select appropriate models for various scenarios. Moreover, users can download the datasets, knowledge graphs, experimental reports and source codes of neural network models for their own practice and evaluations further. © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091706616&doi=10.1145%2f3366424.3383539&partnerID=40&md5=c851a097180241b2d5821a4959995338,"The Web Conference 2020 - Companion of the World Wide Web Conference, WWW 2020",Exclude,,Exclude,
Fatima N.; Rueda L.,iSOM-GSN: An integrative approach for transforming multi-omic data into gene similarity networks via self-organizing maps,"Motivation: One of the main challenges in applying graph convolutional neural networks (CNNs) on gene-interaction data is the lack of understanding of the vector space to which they belong, and also the inherent difficulties involved in representing those interactions on a significantly lower dimension, viz Euclidean spaces. The challenge becomes more prevalent when dealing with various types of heterogeneous data. We introduce a systematic, generalized method, called iSOM-GSN, used to transform 'multi-omic' data with higher dimensions onto a 2D grid. Afterwards, we apply a CNN to predict disease states of various types. Based on the idea of Kohonen's self-organizing map, we generate a 2D grid for each sample for a given set of genes that represent a gene similarity network. Results: We have tested the model to predict breast and prostate cancer using gene expression, DNA methylation and copy number alteration. Prediction accuracies in the 94-98% range were obtained for tumor stages of breast cancer and calculated Gleason scores of prostate cancer with just 14 input genes for both cases. The scheme not only outputs nearly perfect classification accuracy, but also provides an enhanced scheme for representation learning, visualization, dimensionality reduction and interpretation of multi-omic data. Availability and implementation: The source code and sample data are available via a Github project at https://github.com/NaziaFatima/iSOM_GSN. © The Author(s) 2020. Published by Oxford University Press. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091808806&doi=10.1093%2fbioinformatics%2fbtaa500&partnerID=40&md5=d740da4943e45da8eb264853f2361987,Bioinformatics,Exclude,,,
Yu J.; Zhu Z.; Wang Y.; Zhang W.; Hu Y.; Tan J.,Cross-modal knowledge reasoning for knowledge-based visual question answering,"Knowledge-based Visual Question Answering (KVQA) requires external knowledge beyond the visible content to answer questions about an image. This ability is challenging but indispensable to achieve general VQA. One limitation of existing KVQA solutions is that they jointly embed all kinds of information without fine-grained selection, which introduces unexpected noises for reasoning the correct answer. How to capture the question-oriented and information-complementary evidence remains a key challenge to solve the problem. Inspired by the human cognition theory, in this paper, we depict an image by multiple knowledge graphs from the visual, semantic and factual views. Thereinto, the visual graph and semantic graph are regarded as image-conditioned instantiation of the factual graph. On top of these new representations, we re-formulate Knowledge-based Visual Question Answering as a recurrent reasoning process for obtaining complementary evidence from multimodal information. To this end, we decompose the model into a series of memory-based reasoning steps, each performed by a Graph-based Read, Update, and Control (GRUC) module that conducts parallel reasoning over both visual and semantic information. By stacking the modules multiple times, our model performs transitive reasoning and obtains question-oriented concept representations under the constrain of different modalities. Finally, we perform graph neural networks to infer the global-optimal answer by jointly considering all the concepts. We achieve a new state-of-the-art performance on three popular benchmark datasets, including FVQA, Visual7W-KB and OK-VQA, and demonstrate the effectiveness and interpretability of our model with extensive experiments. The source code is available at: https://github.com/astro-zihao/gruc © 2020 Elsevier Ltd",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088900055&doi=10.1016%2fj.patcog.2020.107563&partnerID=40&md5=d776421df9d958604707143250eb3efe,Pattern Recognition,Exclude,,,
Rodrigues G.E.D.P.; Braga A.M.; Dahab R.,Using Graph Embeddings and Machine Learning to Detect Cryptography Misuse in Source Code,"Cryptography is an essential aspect of software development. Nevertheless, software developers have limited knowledge of cryptography primitives, and support tools are limited. In this work, we present a comparison between graph embedding techniques, node2vec and Bag of Graphs, as embedding generators of source code graph representations. We combined these techniques with machine learning models in order to detect cryptography misuses in source codes. We show that Bag of Graphs outperforms node2vec in this task; also, both techniques outperform previously evaluated tools. © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102530771&doi=10.1109%2fICMLA51294.2020.00171&partnerID=40&md5=25e315d337ac391c396b4291e7741021,"Proceedings - 19th IEEE International Conference on Machine Learning and Applications, ICMLA 2020",Include,,,
Xiao D.; Li Y.-K.; Zhang H.; Sun Y.; Tian H.; Wu H.; Wang H.,ERNIE-Gram: Pre-Training with Explicitly N-Gram Masked Language Modeling for Natural Language Understanding,"Coarse-grained linguistic information, such as named entities or phrases, facilitates adequately representation learning in pre-training. Previous works mainly focus on extending the objective of BERT’s Masked Language Modeling (MLM) from masking individual tokens to contiguous sequences of n tokens. We argue that such contiguously masking method neglects to model the intra-dependencies and inter-relation of coarse-grained linguistic information. As an alternative, we propose ERNIE-Gram, an explicitly n-gram masking method to enhance the integration of coarse-grained information into pre-training. In ERNIE-Gram, n-grams are masked and predicted directly using explicit n-gram identities rather than contiguous sequences of n tokens. Furthermore, ERNIE-Gram employs a generator model to sample plausible n-gram identities as optional n-gram masks and predict them in both coarse-grained and fine-grained manners to enable comprehensive n-gram prediction and relation modeling. We pre-train ERNIE-Gram on English and Chinese text corpora and fine-tune on 19 downstream tasks. Experimental results show that ERNIE-Gram outperforms previous pre-training models like XLNet and RoBERTa by a large margin, and achieves comparable results with state-of-the-art methods. The source codes and pre-trained models have been released at https://github.com/PaddlePaddle/ERNIE. © 2021 Association for Computational Linguistics.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118985265&partnerID=40&md5=04073fdf6e8f0f8d69c70a4209fc5717,"NAACL-HLT 2021 - 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference",Exclude,,Exclude,
Wang Y.; Wang K.; Gao F.; Wang L.,Learning semantic program embeddings with graph interval neural network,"Learning distributed representations of source code has been a challenging task for machine learning models. Earlier works treated programs as text so that natural language methods can be readily applied. Unfortunately, such approaches do not capitalize on the rich structural information possessed by source code. Of late, Graph Neural Network (GNN) was proposed to learn embeddings of programs from their graph representations. Due to the homogeneous (i.e. do not take advantage of the program-specific graph characteristics) and expensive (i.e. require heavy information exchange among nodes in the graph) message-passing procedure, GNN can suffer from precision issues, especially when dealing with programs rendered into large graphs. In this paper, we present a new graph neural architecture, called Graph Interval Neural Network (GINN), to tackle the weaknesses of the existing GNN. Unlike the standard GNN, GINN generalizes from a curated graph representation obtained through an abstraction method designed to aid models to learn. In particular, GINN focuses exclusively on intervals (generally manifested in looping construct) for mining the feature representation of a program, furthermore, GINN operates on a hierarchy of intervals for scaling the learning to large graphs. We evaluate GINN for two popular downstream applications: variable misuse prediction and method name prediction. Results show in both cases GINN outperforms the state-of-the-art models by a comfortable margin. We have also created a neural bug detector based on GINN to catch null pointer deference bugs in Java code. While learning from the same 9,000 methods extracted from 64 projects, GINN-based bug detector significantly outperforms GNN-based bug detector on 13 unseen test projects. Next, we deploy our trained GINN-based bug detector and Facebook Infer, arguably the state-of-the-art static analysis tool, to scan the codebase of 20 highly starred projects on GitHub. Through our manual inspection, we confirm 38 bugs out of 102 warnings raised by GINN-based bug detector compared to 34 bugs out of 129 warnings for Facebook Infer. We have reported 38 bugs GINN caught to developers, among which 11 have been fixed and 12 have been confirmed (fix pending). GINN has shown to be a general, powerful deep neural network for learning precise, semantic program embeddings. © 2020 Owner/Author.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097576154&doi=10.1145%2f3428205&partnerID=40&md5=e25d55bad2a851b1147a5f865acc5153,Proceedings of the ACM on Programming Languages,Include,,Include,
Wang D.; Dong W.; Li S.,A multi-Task representation learning approach for source code,"Representation learning has shown impressive results for a multitude of tasks in software engineering. However, most researches still focus on a single problem. As a result, the learned representations cannot be applied to other problems and lack generalizability and interpretability. In this paper, we propose a Multi-Task learning approach for representation learning across multiple downstream tasks of software engineering. From the perspective of generalization, we build a shared sequence encoder with a pretrained BERT for the token sequence and a structure encoder with a Tree-LSTM for the abstract syntax tree of code. From the perspective of interpretability, we integrate attention mechanism to focus on different representations and set learnable parameters to adjust the relationship between tasks. We also present the early results of our model. The learning process analysis shows our model has a significant improvement over strong baselines.  © 2020 Owner/Author.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096999195&doi=10.1145%2f3416506.3423575&partnerID=40&md5=90838a9e9cff8ebedea3fa270f9fc249,"RL+SE and PL 2020 - Proceedings of the 1st ACM SIGSOFT International Workshop on Representation Learning for Software Engineering and Program Languages, Co-located with ESEC/FSE 2020",Include,,Include,
Chiou M.-J.; Liu Z.; Yin Y.; Liu A.-A.; Zimmermann R.,Zero-Shot Multi-View Indoor Localization via Graph Location Networks,"Indoor localization is a fundamental problem in location-based applications. Current approaches to this problem typically rely on Radio Frequency technology, which requires not only supporting infrastructures but human efforts to measure and calibrate the signal. Moreover, data collection for all locations is indispensable in existing methods, which in turn hinders their large-scale deployment. In this paper, we propose a novel neural network based architecture Graph Location Networks (GLN) to perform infrastructure-free, multi-view image based indoor localization. GLN makes location predictions based on robust location representations extracted from images through message-passing networks. Furthermore, we introduce a novel zero-shot indoor localization setting and tackle it by extending the proposed GLN to a dedicated zero-shot version, which exploits a novel mechanism Map2Vec to train location-aware embeddings and make predictions on novel unseen locations. Our extensive experiments show that the proposed approach outperforms state-of-the-art methods in the standard setting, and achieves promising accuracy even in the zero-shot setting where data for half of the locations are not available. The source code and datasets are publicly available. © 2020 Owner/Author.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106714030&doi=10.1145%2f3394171.3413856&partnerID=40&md5=a25e2651ffc090c701c75907ab82ceca,MM 2020 - Proceedings of the 28th ACM International Conference on Multimedia,Exclude,,,
Wang J.; Liang S.; He D.; Wang Y.; Wu Y.; Zhang Y.,A Sequential Graph Convolutional Network with Frequency-domain Complex Network of EEG Signals for Epilepsy Detection,"Automatic epilepsy seizure detection based on electroencephalography (EEG) signals has been a hot topic in the bioinformatics community. Recently, graph representations named complex networks have been increasingly utilized to characterize EEG signals. However, existing time-domain complex networks often suffer from undesired intra-class variance due to phase shift. Addressing this problem, we propose to obtain complex network representations in frequency domain where perfect data alignment can be achieved. The transformation to frequency domain highlights the urgency to retain sequential information in the signals. To this end, we propose to further extract features from the complex network representation using a novel deep model called Sequential Graph Convolutional Network (SGCN). Specifically, we incorporate state-of-the-art graph neural network (GNN) architecture with a novel sequential convolution operation which is key to preserving sequential information. Extensive experiments demonstrate the effectiveness and interpretability of our method. Our source code is available at https://github.com/JL-Wang-source-code/SGCN-for-epilepsy-detection. © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100357380&doi=10.1109%2fBIBM49941.2020.9313232&partnerID=40&md5=a8b208302096ce17c36b07a420db03a8,"Proceedings - 2020 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2020",Exclude,,,
Sadeghi A.; Shahini X.; Schmitz M.; Lehmann J.,BenchEmbedd: A FAIR benchmarking tool for knowledge graph embeddings,"Knowledge graph embedding models have been studied comprehensively recently. However, these studies lack an evaluation system that compares their efficiency in a reproducible manner that follows the FAIR principles. In this study, we extend the general HOBBIT benchmarking platform to evaluate the efficiency of embedding models with such criteria. The demo benchmark, source code of this study, and installation and usage guide are openly available in https://github.com/mlwinde/BenchEmbed. In this paper, we explain the structure of this Benchmarking tool and demonstrate the usage of the benchmarking system for the knowledge graph embedding models. © 2021 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114700496&partnerID=40&md5=9865e6b6534f28329af3087cc8c9ea27,CEUR Workshop Proceedings,Exclude,,,
Huang Z.; Liu Q.; Gao W.; Wu J.; Yin Y.; Wang H.; Chen E.,Neural Mathematical Solver with Enhanced Formula Structure,"Automatically answering mathematical problems is a challenging task since it requires not only the ability of linguistic understanding but also mathematical comprehension. Existing studies usually explore solutions on the elementary math word problems that aim to understand the questions described in natural language narratives, which are not capable of solving more general problems containing structural formulas. To this end, in this paper, we propose a novel Neural Mathematical Solver (NMS) with enhanced formula structures. Specifically, we first frame the formulas in a certain problem as a TeX dependency graph to preserve formula-enriched structures. Then, we design a formula graph network (FGN) to capture its mathematical relations. Next, we develop a novel architecture with two GRU models, connecting tokens from both word space and formula space together, to learn the linguistic semantics for the answers. Extensive experiments on a large-scale dataset demonstrate that NMS not only achieves better answer prediction but also visualizes reasonable mathematical representations of problems. © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090169309&doi=10.1145%2f3397271.3401227&partnerID=40&md5=bee277f44fc3ac34e23d68b83b3d29b2,SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval,Exclude,,,
Mazo C.; Bernal J.; Trujillo M.; Alegre E.,Transfer learning for classification of cardiovascular tissues in histological images,"Background and Objective: Automatic classification of healthy tissues and organs based on histology images is an open problem, mainly due to the lack of automated tools. Solutions in this regard have potential in educational medicine and medical practices. Some preliminary advances have been made using image processing techniques and classical supervised learning. Due to the breakthrough performance of deep learning in various areas, we present an approach to recognise and classify, automatically, fundamental tissues and organs using Convolutional Neural Networks (CNN). Methods: We adapt four popular CNNs architectures – ResNet, VGG19, VGG16 and Inception – to this problem through transfer learning. The resulting models are evaluated at three stages. Firstly, all the transferred networks are compared to each other. Secondly, the best resulting fine-tuned model is compared to an ad-hoc 2D multi-path model to outline the importance of transfer learning. Thirdly, the same model is evaluated against the state-of-the-art method, a cascade SVM using LBP-based descriptors, to contrast a traditional machine learning approach and a representation learning one. The evaluation task consists of separating six classes accurately: smooth muscle of the elastic artery, smooth muscle of the large vein, smooth muscle of the muscular artery, cardiac muscle, loose connective tissue, and light regions. The different networks are tuned on 6000 blocks of 100 × 100 pixels and tested on 7500. Results: Our proposal yields F-score values between 0.717 and 0.928. The highest and lowest performances are for cardiac muscle and smooth muscle of the large vein, respectively. The main issue leading to limited classification scores for the latter class is its similarity with the elastic artery. However, this confusion is evidenced during manual annotation as well. Our algorithm reached improvements in F-score between 0.080 and 0.220 compared to the state-of-the-art machine learning approach. Conclusions: We conclude that it is possible to classify healthy cardiovascular tissues and organs automatically using CNNs and that deep learning holds great promise to improve tissue and organs classification. We left our training and test sets, models and source code publicly available to the research community. © 2018 Elsevier B.V.",Article,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051947652&doi=10.1016%2fj.cmpb.2018.08.006&partnerID=40&md5=1905d14052eab2e6b0e023c23df3f33f,Computer Methods and Programs in Biomedicine,Exclude,,Exclude,
Ermolov A.; Sebe N.,Latent world models for intrinsically motivated exploration,"In this work we consider partially observable environments with sparse rewards. We present a self-supervised representation learning method for image-based observations, which arranges embeddings respecting temporal distance of observations. This representation is empirically robust to stochasticity and suitable for novelty detection from the error of a predictive forward model. We consider episodic and life-long uncertainties to guide the exploration. We propose to estimate the missing information about the environment with the world model, which operates in the learned latent space. As a motivation of the method, we analyse the exploration problem in a tabular Partially Observable Labyrinth. We demonstrate the method on image-based hard exploration environments from the Atari benchmark and report significant improvement with respect to prior work. The source code of the method and all the experiments is available at https://github.com/htdt/lwm. © 2020 Neural information processing systems foundation. All rights reserved.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108442662&partnerID=40&md5=61ce82f5935ec2b133ead1aaea14df27,Advances in Neural Information Processing Systems,Exclude,,,
Yang Y.; Chen X.; Sun J.,Improve Language Modeling for Code Completion Through Learning General Token Repetition of Source Code with Optimized Memory,"In last few years, applying language model to source code is the state-of-the-art method for solving the problem of code completion. However, compared with natural language, code has more obvious repetition characteristics. For example, a variable can be used many times in the following code. Variables in source code have a high chance to be repetitive. Cloned code and templates, also have the property of token repetition. Capturing the token repetition of source code is important. In different projects, variables or types are usually named differently. This means that a model trained in a finite data set will encounter a lot of unseen variables or types in another data set. How to model the semantics of the unseen data and how to predict the unseen data based on the patterns of token repetition are two challenges in code completion. Hence, in this paper, token repetition is modelled as a graph, we propose a novel REP model which is based on deep neural graph network to learn the code toke repetition. The REP model is to identify the edge connections of a graph to recognize the token repetition. For predicting the token repetition of token n, the information of all the previous tokens needs to be considered. We use memory neural network (MNN) to model the semantics of each distinct token to make the framework of REP model more targeted. The experiments indicate that the REP model performs better than LSTM model. Compared with Attention-Pointer network, we also discover that the attention mechanism does not work in all situations. The proposed REP model could achieve similar or slightly better prediction accuracy compared to Attention-Pointer network and consume less training time. We also find other attention mechanism which could further improve the prediction accuracy. © 2019 World Scientific Publishing Company.",Article,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079343262&doi=10.1142%2fS0218194019400229&partnerID=40&md5=8b11cc3a02416e82d9dad92c1e2d2da7,International Journal of Software Engineering and Knowledge Engineering,Include,,,
Oza P.; Patel V.M.,One-Class Convolutional Neural Network,"We present a novel convolutional neural network (CNN) based approach for one-class classification. The idea is to use a zero centered Gaussian noise in the latent space as the pseudo-negative class and train the network using the cross-entropy loss to learn a good representation as well as the decision boundary for the given class. A key feature of the proposed approach is that any pre-trained CNN can be used as the base network for one-class classification. The proposed one-class CNN is evaluated on the UMDAA-02 Face, Abnormality-1001, and FounderType-200 datasets. These datasets are related to a variety of one-class application problems such as user authentication, abnormality detection, and novelty detection. Extensive experiments demonstrate that the proposed method achieves significant improvements over the recent state-of-the-art methods. The source code is available at: github.com/otkupjnoz/oc-cnn. © 2018 IEEE.",Article,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059031943&doi=10.1109%2fLSP.2018.2889273&partnerID=40&md5=68e23934e5d53b5933d6cc52a2f6e0ca,IEEE Signal Processing Letters,Exclude,,,
Jiang H.; Turki T.; Wang J.T.L.,DLGraph: Malware Detection Using Deep Learning and Graph Embedding,"In this paper we present a new approach, named DLGraph, for malware detection using deep learning and graph embedding. DLGraph employs two stacked denoising autoencoders (SDAs) for representation learning, taking into consideration computer programs' function-call graphs and Windows application programming interface (API) calls. Given a program, we first use a graph embedding technique that maps the program's function-call graph to a vector in a low-dimensional feature space. One SDA in our deep learning model is used to learn a latent representation of the embedded vector of the function-call graph. The other SDA in our model is used to learn a latent representation of the given program's Windows API calls. The two learned latent representations are then merged to form a combined feature vector. Finally, we use softmax regression to classify the combined feature vector for predicting whether the given program is malware or not. Experimental results based on different datasets demonstrate the effectiveness of the proposed approach and its superiority over a related method. © 2018 IEEE.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062236259&doi=10.1109%2fICMLA.2018.00168&partnerID=40&md5=2e15619144de0a633600d6581c88efb6,"Proceedings - 17th IEEE International Conference on Machine Learning and Applications, ICMLA 2018",Include,,,
Yu Z.; Zheng W.; Wang J.; Tang Q.; Nie S.; Wu S.,CodeCMR: Cross-modal retrieval for function-level binary source code matching,"Binary source code matching, especially on function-level, has a critical role in the field of computer security. Given binary code only, finding the corresponding source code improves the accuracy and efficiency in reverse engineering. Given source code only, related binary code retrieval contributes to known vulnerabilities confirmation. However, due to the vast difference between source and binary code, few studies have investigated binary source code matching. Previously published studies focus on code literals extraction such as strings and integers, then utilize traditional matching algorithms such as the Hungarian algorithm for code matching. Nevertheless, these methods have limitations on function-level, because they ignore the potential semantic features of code and a lot of code lacks sufficient code literals. Also, these methods indicate a need for expert experience for useful feature identification and feature engineering, which is time-consuming. This paper proposes an end-to-end cross-modal retrieval network for binary source code matching, which achieves higher accuracy and requires less expert experience. We adopt Deep Pyramid Convolutional Neural Network (DPCNN) for source code feature extraction and Graph Neural Network (GNN) for binary code feature extraction. We also exploit neural network-based models to capture code literals, including strings and integers. Furthermore, we implement ""norm weighted sampling"" for negative sampling. We evaluate our model on two datasets, where it outperforms other methods significantly. © 2020 Neural information processing systems foundation. All rights reserved.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108431416&partnerID=40&md5=29534bfabcb9e792e4fc115ce77f3aae,Advances in Neural Information Processing Systems,Exclude,,Exclude,
Dominguez M.; Dhamdhere R.; Petkar A.; Jain S.; Sah S.; Ptucha R.,General-Purpose Deep Point Cloud Feature Extractor,"Depth sensors used in autonomous driving and gaming systems often report back 3D point clouds. The lack of structure from these sensors does not allow these systems to take advantage of recent advances in convolutional neural networks which are dependent upon traditional filtering and pooling operations. Analogous to image based convolutional architectures, recently introduced graph based architectures afford similar filtering and pooling operations on arbitrary graphs. We adopt these graph based methods to 3D point clouds to introduce a generic vector representation of 3D graphs, we call graph 3D (G3D). We believe we are the first to use large scale transfer learning on 3D point cloud data and demonstrate the discriminant power of our salient latent representation of 3D point clouds on unforeseen test sets. By using our G3D network (G3DNet) as a feature extractor, and then pairing G3D feature vectors with a standard classifier, we achieve the best accuracy on ModelNet10 (93.1%) and ModelNet 40 (91.7%) for a graph network, and comparable performance on the Sydney Urban Objects dataset to other methods. This general-purpose feature extractor can be used as an off-the-shelf component in other 3D scene understanding or object tracking works. © 2018 IEEE.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050982954&doi=10.1109%2fWACV.2018.00218&partnerID=40&md5=6f2cc64997e6e45288eb4d826aaa8682,"Proceedings - 2018 IEEE Winter Conference on Applications of Computer Vision, WACV 2018",Exclude,,Exclude,
Lian D.; Zheng K.; Cao L.; Zheng V.W.; Tsang I.W.; Ge Y.; Xie X.,High-order proximity preserving information network hashing,"Information network embedding is an effective way for efficient graph analytics. However, it still faces with computational challenges in problems such as link prediction and node recommendation, particularly with increasing scale of networks. Hashing is a promising approach for accelerating these problems by orders of magnitude. However, no prior studies have been focused on seeking binary codes for information networks to preserve high-order proximity. Since matrix factorization (MF) unifies and outperforms several well-known embedding methods with high-order proximity preserved, we propose a MF-based Information Network Hashing (INH-MF) algorithm, to learn binary codes which can preserve high-order proximity. We also suggest Hamming subspace learning, which only updates partial binary codes each time, to scale up INH-MF. We finally evaluate INH-MF on four real-world information network datasets with respect to the tasks of node classification and node recommendation. The results demonstrate that INH-MF can perform significantly better than competing learning to hash baselines in both tasks, and surprisingly outperforms network embedding methods, including DeepWalk, LINE and NetMF, in the task of node recommendation. The source code of INH-MF is available online1                          © 2018 Association for Computing Machinery.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051461356&doi=10.1145%2f3219819.3220034&partnerID=40&md5=2dc159dc8f93859bde443f18728e2533,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Exclude,,Exclude,
Yang K.; Deng J.,Strongly incremental constituency parsing with graph neural networks,"Parsing sentences into syntax trees can benefit downstream applications in NLP. Transition-based parsers build trees by executing actions in a state transition system. They are computationally efficient, and can leverage machine learning to predict actions based on partial trees. However, existing transition-based parsers are predominantly based on the shift-reduce transition system, which does not align with how humans are known to parse sentences. Psycholinguistic research suggests that human parsing is strongly incremental—humans grow a single parse tree by adding exactly one token at each step. In this paper, we propose a novel transition system called attach-juxtapose. It is strongly incremental; it represents a partial sentence using a single tree; each action adds exactly one token into the partial tree. Based on our transition system, we develop a strongly incremental parser. At each step, it encodes the partial tree using a graph neural network and predicts an action. We evaluate our parser on Penn Treebank (PTB) and Chinese Treebank (CTB). On PTB, it outperforms existing parsers trained with only constituency trees; and it performs on par with state-of-the-art parsers that use dependency trees as additional training data. On CTB, our parser establishes a new state of the art. Code is available at https://github.com/princeton-vl/ attach-juxtapose-parser. © 2020 Neural information processing systems foundation. All rights reserved.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106645417&partnerID=40&md5=b82075de70e50c73df25ee91b7f65943,Advances in Neural Information Processing Systems,Exclude,,,
Ranjan E.; Sanyal S.; Talukdar P.,ASAP: Adaptive structure aware pooling for learning hierarchical graph representations,"Graph Neural Networks (GNN) have been shown to work effectively for modeling graph structured data to solve tasks such as node classification, link prediction and graph classification. There has been some recent progress in defining the notion of pooling in graphs whereby the model tries to generate a graph level representation by downsampling and summarizing the information present in the nodes. Existing pooling methods either fail to effectively capture the graph substructure or do not easily scale to large graphs. In this work, we propose ASAP (Adaptive Structure Aware Pooling), a sparse and differentiable pooling method that addresses the limitations of previous graph pooling architectures. ASAP utilizes a novel self-attention network along with a modified GNN formulation to capture the importance of each node in a given graph. It also learns a sparse soft cluster assignment for nodes at each layer to effectively pool the subgraphs to form the pooled graph. Through extensive experiments on multiple datasets and theoretical analysis, we motivate our choice of the components used in ASAP. Our experimental results show that combining existing GNN architectures with ASAP leads to state-of-the-art results on multiple graph classification benchmarks. ASAP has an average improvement of 4%, compared to current sparse hierarchical state-of-the-art method. We make the source code of ASAP available to encourage reproducible research 1 Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094803028&partnerID=40&md5=b65efa89f2898bba3998e03c738c3639,AAAI 2020 - 34th AAAI Conference on Artificial Intelligence,Exclude,,,
Wu J.; Xu J.; Meng X.,Reliable compilation optimization selection based on gate graph neural network,"For different programs or applications, it is necessary to select the appropriate compilation optimization pass or subsequence for the program. To solve this problem, machine learning is widely used as an efficient technology. However, the most important problem in using machine learning is the extraction of program features. How to ensure the integrity and effectiveness of program information is the key to the problem. In addition, when compiling and optimizing the selection problem, the measurement indicators are often program performance, code size, etc. There is not much research on program reliability which needs the longest measurement time and the most complicated measurement methods. This paper proposes a GGNN-based compilation optimization pass selection model. We extend the deep neural network based on GGNN, and build a learning model which learns heuristics for program reliability. The experiment was performed under the clang compilation framework. The alternative compilation optimization pass adopts the C language standard compilation optimization passes. Compared with the traditional machine learning method, our model improves the average accuracy by 5% ~ 11% in the optimization pass selection for program reliability. At the same time, experiments show that our model has strong scalability. © 2020 Knowledge Systems Institute Graduate School. All rights reserved.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090509881&doi=10.18293%2fSEKE2020-029&partnerID=40&md5=7860e382705bab81132ff0ba3e601a3f,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",Include,,Include,
Barham R.; Sharieh A.; Sleit A.,Multi-moth flame optimization for solving the link prediction problem in complex networks,"Providing a solution for the link prediction problem attracts several computer science fields and becomes a popular challenge in researches. This challenge is presented by introducing several approaches keen to provide the most precise prediction quality within a short period of time. The difficulty of the link prediction problem comes from the sparse nature of most complex networks such as social networks. This paper presents a parallel metaheuristic framework which is based on moth-flame optimization (MFO), clustering and pre-processed datasets to solve the link prediction problem. This framework is implemented and tested on a high-performance computing cluster and carried out on large and complex networks from different fields such as social, citation, biological, and information and publication networks. This framework is called Parallel MFO for Link Prediction (PMFO-LP). PMFO-LP is composed of data preprocessing stage and prediction stage. Dataset division with stratified sampling, feature extraction, data under-sampling, and feature selection are performed in the data preprocessing stage. In the prediction stage, the MFO based on clustering is used as the prediction optimizer. The PMFO-LP provides a solution to the link prediction problem with more accurate prediction results within a reasonable amount of time. Experimental results show that PMFO-LP algorithm outperforms other well-regarded algorithms in terms of error rate, the area under curve and speedup. Note that the source code of the PMFO-LP algorithm is available at https://github.com/RehamBarham/PMFO_MPI.cpp. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.",Article,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068143786&doi=10.1007%2fs12065-019-00257-y&partnerID=40&md5=75e778d7511d2898929865d514fd613a,Evolutionary Intelligence,Exclude,,,
Wei J.; Goyal M.; Durrett G.; Dillig I.,LAMBDANET: PROBABILISTIC TYPE INFERENCE USING GRAPH NEURAL NETWORKS,"As gradual typing becomes increasingly popular in languages like Python and TypeScript, there is a growing need to infer type annotations automatically. While type annotations help with tasks like code completion and static error catching, these annotations cannot be fully determined by compilers and are tedious to annotate by hand. This paper proposes a probabilistic type inference scheme for TypeScript based on a graph neural network. Our approach first uses lightweight source code analysis to generate a program abstraction called a type dependency graph, which links type variables with logical constraints as well as name and usage information. Given this program abstraction, we then use a graph neural network to propagate information between related type variables and eventually make type predictions. Our neural architecture can predict both standard types, like number or string, as well as user-defined types that have not been encountered during training. Our experimental results show that our approach outperforms prior work in this space by 14% (absolute) on library types, while having the ability to make type predictions that are out of scope for existing techniques. © 2020 8th International Conference on Learning Representations, ICLR 2020. All rights reserved.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136028933&partnerID=40&md5=def38a1ee95a887c65c0df9dc70d4a25,"8th International Conference on Learning Representations, ICLR 2020",Include,,,
Fey M.; Lenssen J.E.; Morris C.; Masci J.; Kriege N.M.,DEEP GRAPH MATCHING CONSENSUS,"This work presents a two-stage neural architecture for learning and refining structural correspondences between graphs. First, we use localized node embeddings computed by a graph neural network to obtain an initial ranking of soft correspondences between nodes. Secondly, we employ synchronous message passing networks to iteratively re-rank the soft correspondences to reach a matching consensus in local neighborhoods between graphs. We show, theoretically and empirically, that our message passing scheme computes a well-founded measure of consensus for corresponding neighborhoods, which is then used to guide the iterative re-ranking process. Our purely local and sparsity-aware architecture scales well to large, real-world inputs while still being able to recover global correspondences consistently. We demonstrate the practical effectiveness of our method on real-world tasks from the fields of computer vision and entity alignment between knowledge graphs, on which we improve upon the current state-of-the-art. Our source code is available under https://github.com/rusty1s/deep-graph-matching-consensus. © 2020 8th International Conference on Learning Representations, ICLR 2020. All rights reserved.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150652939&partnerID=40&md5=41ef9087ac1d8f842f1e69d9a351485b,"8th International Conference on Learning Representations, ICLR 2020",Exclude,,,
Chirila C.-B.; Sora I.,The Optimization of a Page Rank Based Key Classes Classifier using Simulated Annealing with ROC-AUC and Recall Metrics,"Nowadays, software projects from different industrial sectors tend to grow from tens of classes towards sizes of hundreds or even thousands of classes. Key classes or hotspots are the most important classes in a project. They represent the starting point for any maintenance operation. In this context key classes detection is an important software engineering task, especially in projects where documentation is poor or missing totally. In the state of the art there are several key classes classifiers based on different representations and algorithms. We focus on the empirical parameters of a classifier based on weighted graph representation of the source code combined with a Page Rank algorithm which give the best results compared to previous works results available online. The empirical parameters represent weights assigned to several relations between classes like: inheritance between two classes, interface implementation between a class and an interface etc. Initially the parameters were manually set, having empirical values. It is not known if other sets of values for the parameters will not give better diagnostic abilities to the classifier. To test the entire parameters state space is virtually impossible for 12 Java software projects and 15 parameters with values varying in the integer range. Using the Simulated Annealing optimization algorithm we start with the manually set values for the parameters and we optimize the objective functions based on ROC-AUC and Recall metrics. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075065323&doi=10.1109%2fSACI46893.2019.9111601&partnerID=40&md5=1156fad3845e01b6654b7b6870f54408,"SACI 2019 - IEEE 13th International Symposium on Applied Computational Intelligence and Informatics, Proceedings",Include,,,
Gutiérrez-Cárdenas J.; Quintana-Cruz H.; Mego-Fernandez D.; Diaz-Baskakov S.,Heuristics applied to mutation testing in an impure functional programming language,"The task of elaborating accurate test suites for program testing can be an extensive computational work. Mutation testing is not immune to the problem of being a computational and time-consuming task so that it has found relief in the use of heuristic techniques. The use of Genetic Algorithms in mutation testing has proved to be useful for probing test suites, but it has mainly been enclosed only in the field of imperative programming paradigms. Therefore, we decided to test the feasibility of using Genetic Algorithms for performing mutation testing in functional programming environments. We tested our proposal by making a graph representations of four different functional programs and applied a Genetic Algorithm to generate a population of mutant programs. We found that it is possible to obtain a set of mutants that could find flaws in test suites in functional programming languages. Additionally, we encountered that when a source code increases its number of instructions it was simpler for a genetic algorithm to find a mutant that can avoid all of the test cases. © 2019 International Journal of Advanced Computer Science and Applications.",Article,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070527479&doi=10.14569%2fijacsa.2019.0100670&partnerID=40&md5=75493f304015a8f92c08cf2534f7e761,International Journal of Advanced Computer Science and Applications,Include,,,
He X.; Peng Y.; Xie L.,A new benchmark and approach for fine-grained cross-media retrieval,"Cross-media retrieval is to return the results of various media types corresponding to the query of any media type. Existing researches generally focus on coarse-grained cross-media retrieval. When users submit an image of “Slaty-backed Gull” as a query, coarse-grained cross-media retrieval treats it as “Bird”, so that users can only get the results of “Bird”, which may include other bird species with similar appearance (image and video), descriptions (text) or sounds (audio), such as “Herring Gull”. Such coarse-grained cross-media retrieval is not consistent with human lifestyle, where we generally have the fine-grained requirement of returning the exactly relevant results of “Slaty-backed Gull” instead of “Herring Gull”. However, few researches focus on fine-grained cross-media retrieval, which is a highly challenging and practical task. Therefore, in this paper, we first construct a new benchmark for fine-grained cross-media retrieval, which consists of 200 fine-grained subcategories of the “Bird”, and contains 4 media types, including image, text, video and audio. To the best of our knowledge, it is the first benchmark with 4 media types for fine-grained cross-media retrieval. Then, we propose a uniform deep model, namely FGCrossNet, which simultaneously learns 4 types of media without discriminative treatments. We jointly consider three constraints for better common representation learning: classification constraint ensures the learning of discriminative features for fine-grained subcategories, center constraint ensures the compactness characteristic of the features of the same subcategory, and ranking constraint ensures the sparsity characteristic of the features of different subcategories. Extensive experiments verify the usefulness of the new benchmark and the effectiveness of our FGCrossNet. The new benchmark and the source code of FGCrossNet will be made available at https://github.com/PKU-ICST-MIPL/FGCrossNet_ACMMM2019. © 2019 Association for Computing Machinery.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074820015&doi=10.1145%2f3343031.3350974&partnerID=40&md5=ac473451fc8b8dc1b94e3f14acf196ae,MM 2019 - Proceedings of the 27th ACM International Conference on Multimedia,Exclude,,Exclude,
Fey M.; Lenssen J.E.; Weichert F.; Muller H.,SplineCNN: Fast Geometric Deep Learning with Continuous B-Spline Kernels,"We present Spline-based Convolutional Neural Networks (SplineCNNs), a variant of deep neural networks for irregular structured and geometric input, e.g., graphs or meshes. Our main contribution is a novel convolution operator based on B-splines, that makes the computation time independent from the kernel size due to the local support property of the B-spline basis functions. As a result, we obtain a generalization of the traditional CNN convolution operator by using continuous kernel functions parametrized by a fixed number of trainable weights. In contrast to related approaches that filter in the spectral domain, the proposed method aggregates features purely in the spatial domain. In addition, SplineCNN allows entire end-to-end training of deep architectures, using only the geometric structure as input, instead of handcrafted feature descriptors. For validation, we apply our method on tasks from the fields of image graph classification, shape correspondence and graph node classification, and show that it outperforms or pars state-of-the-art approaches while being significantly faster and having favorable properties like domain-independence. Our source code is available on GitHub1. © 2018 IEEE.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059068412&doi=10.1109%2fCVPR.2018.00097&partnerID=40&md5=f5a332dc6f9faa53adb006da270ea4ef,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,Exclude,,Exclude,
Anand G.; Nayak R.,Unsupervised Visual Time-Series Representation Learning and Clustering,"Time-series data is generated ubiquitously from Internet-of-Things (IoT) infrastructure, connected and wearable devices, remote sensing, autonomous driving research and, audio-video communications, in enormous volumes. This paper investigates the potential of unsupervised representation learning for these time-series. In this paper, we use a novel data transformation along with novel unsupervised learning regime to transfer the learning from other domains to time-series where the former have extensive models heavily trained on very large labelled datasets. We conduct extensive experiments to demonstrate the potential of the proposed approach through time-series clustering. Source code available at https://github.com/technophyte/LDVR. © 2020, Springer Nature Switzerland AG.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097108043&doi=10.1007%2f978-3-030-63823-8_94&partnerID=40&md5=4665dc653da31fa8ab9d26e0e9db9f25,Communications in Computer and Information Science,Exclude,,,
Brauckmann A.; Goens A.; Ertel S.; Castrillon J.,Compiler-based graph representations for deep learning models of code,"In natural language processing, novel methods in deep learning, like recurrent neural networks (RNNs) on sequences of words, have been very successful. In contrast to natural languages, programming languages usually have a well-defined structure. With this structure compilers can reason about programs, using graphs such as abstract syntax trees (ASTs) or control-data flow graphs (CDFGs). In this paper, we argue that we should use these graph structures instead of sequences for learning compiler optimization tasks. To this end, we use graph neural networks (GNNs) for learning predictive compiler tasks on two representations based on ASTs and CDFGs. Experiments show that this improves upon the state-of-the-art in the task of heterogeneous OpenCL mapping, while providing orders of magnitude faster inference times, crucial for compiler optimizations. When testing on benchmark suites not included for training, our AST-based model significantly outperforms the state-of-the-art by over 12 percentage points in terms of accuracy. It is the only one to perform clearly better than a random mapping. On the task of predicting thread coarsening factors, we show that all of the methods fail to produce an overall speedup. © 2020 Association for Computing Machinery.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082029510&doi=10.1145%2f3377555.3377894&partnerID=40&md5=2b6ac90a73bc967e9ed2e3c34a9e86df,CC 2020 - Proceedings of the 29th International Conference on Compiler Construction,Include,,Include,
Hirohara M.; Saito Y.; Koda Y.; Sato K.; Sakakibara Y.,Convolutional neural network based on SMILES representation of compounds for detecting chemical motif,"Background: Previous studies have suggested deep learning to be a highly effective approach for screening lead compounds for new drugs. Several deep learning models have been developed by addressing the use of various kinds of fingerprints and graph convolution architectures. However, these methods are either advantageous or disadvantageous depending on whether they (1) can distinguish structural differences including chirality of compounds, and (2) can automatically discover effective features. Results: We developed another deep learning model for compound classification. In this method, we constructed a distributed representation of compounds based on the SMILES notation, which linearly represents a compound structure, and applied the SMILES-based representation to a convolutional neural network (CNN). The use of SMILES allows us to process all types of compounds while incorporating a broad range of structure information, and representation learning by CNN automatically acquires a low-dimensional representation of input features. In a benchmark experiment using the TOX 21 dataset, our method outperformed conventional fingerprint methods, and performed comparably against the winning model of the TOX 21 Challenge. Multivariate analysis confirmed that the chemical space consisting of the features learned by SMILES-based representation learning adequately expressed a richer feature space that enabled the accurate discrimination of compounds. Using motif detection with the learned filters, not only important known structures (motifs) such as protein-binding sites but also structures of unknown functional groups were detected. Conclusions: The source code of our SMILES-based convolutional neural network software in the deep learning framework Chainer is available at http://www.dna.bio.keio.ac.jp/smiles/ , and the dataset used for performance evaluation in this work is available at the same URL. © 2018 The Author(s).",Article,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059287866&doi=10.1186%2fs12859-018-2523-5&partnerID=40&md5=53d9571b41ce39bb40ab2e9249e2e7e3,BMC Bioinformatics,Exclude,,,
Jopek K.; Paszyński M.; Paszyńska A.; Hassan M.A.; Pingali K.,"Hypergraph grammar-based, multi-thread, multi-frontal direct solver scheduled in parallel GALOIS environment","In this paper, we analyze two-dimensional grids with point and edge singulari- ties in order to develop an efficient parallel hypergraph grammar-based multi- frontal direct solver algorithm. We express these grids by a hypergraph. For these meshes, we define a sequence of hypergraph grammar productions ex- pressing the construction of frontal matrices, eliminating fully assembled nodes, merging the resulting Schur complements, and repeating the process of elim- ination and merging until a single frontal matrix remains. The dependency relationship between hypergraph grammar productions is analyzed, and a de- pendency graph is plotted (which is equivalent to the elimination tree of a multi- frontal solver algorithm). We utilize a classical multi-frontal solver algorithm; the hypergraph grammar productions allow us to construct an efficient elimi- nation tree based on the graph representation of the computational mesh (not the global matrix itself). The hypergraph grammar productions are assigned to nodes on a dependency graph, and they are implemented as tasks in the GALOIS parallel environment and scheduled according to the developed de- pendency graph over the shared memory parallel machine. We show that our hypergraph grammar-based solver outperforms the parallel MUMPS solver. © 2019 AGH University of Science and Technology Press.",Article,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064050598&doi=10.7494%2fcsci.2019.20.1.3010&partnerID=40&md5=dc3c8ae9586dcebd1bc78108004aac9a,Computer Science,Exclude,,,
Lin J.; Lee G.H.,HDNet: Human Depth Estimation for Multi-person Camera-Space Localization,"Current works on multi-person 3D pose estimation mainly focus on the estimation of the 3D joint locations relative to the root joint and ignore the absolute locations of each pose. In this paper, we propose the Human Depth Estimation Network (HDNet), an end-to-end framework for absolute root joint localization in the camera coordinate space. Our HDNet first estimates the 2D human pose with heatmaps of the joints. These estimated heatmaps serve as attention masks for pooling features from image regions corresponding to the target person. A skeleton-based Graph Neural Network (GNN) is utilized to propagate features among joints. We formulate the target depth regression as a bin index estimation problem, which can be transformed with a soft-argmax operation from the classification output of our HDNet. We evaluate our HDNet on the root joint localization and root-relative 3D pose estimation tasks with two benchmark datasets, i.e., Human3.6M and MuPoTS-3D. The experimental results show that we outperform the previous state-of-the-art consistently under multiple evaluation metrics. Our source code is available at: https://github.com/jiahaoLjh/HumanDepth. © 2020, Springer Nature Switzerland AG.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097821042&doi=10.1007%2f978-3-030-58523-5_37&partnerID=40&md5=1d5fefac8e28b77c516795553ba6d889,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Chi C.; Zhang S.; Xing J.; Lei Z.; Li S.Z.; Zou X.,PedHunter: Occlusion robust pedestrian detector in crowded scenes,"Pedestrian detection in crowded scenes is a challenging problem, because occlusion happens frequently among different pedestrians. In this paper, we propose an effective and efficient detection network to hunt pedestrians in crowd scenes. The proposed method, namely PedHunter, introduces strong occlusion handling ability to existing region-based detection networks without bringing extra computations in the inference stage. Specifically, we design a mask-guided module to leverage the head information to enhance the feature representation learning of the backbone network. Moreover, we develop a strict classification criterion by improving the quality of positive samples during training to eliminate common false positives of pedestrian detection in crowded scenes. Besides, we present an occlusion-simulated data augmentation to enrich the pattern and quantity of occlusion samples to improve the occlusion robustness. As a consequent, we achieve state-of-the-art results on three pedestrian detection datasets including CityPersons, Caltech-USA and CrowdHuman. To facilitate further studies on the occluded pedestrian detection in surveillance scenes, we release a new pedestrian dataset, called SUR-PED, with a total of over 162k highquality manually labeled instances in 10k images. The proposed dataset, source codes and trained models are available at https://github.com/ChiCheng123/PedHunter. © AAAI 2020 - 34th AAAI Conference on Artificial Intelligence. All Rights Reserved.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104629205&partnerID=40&md5=b336dba05da0431940aa779144de5d2c,AAAI 2020 - 34th AAAI Conference on Artificial Intelligence,Exclude,,,
Mitrović S.; De Weerdt J.,Churn modeling with probabilistic meta paths-based representation learning,"Finding structural and efficient ways of leveraging available data is not an easy task, especially when dealing with network data, as is the case in telco churn prediction. Several previous works have made advancements in this direction both from the perspective of churn prediction, by proposing augmented call graph architectures, and from the perspective of graph featurization, by proposing different graph representation learning methods, frequently exploiting random walks. However, both graph augmentation as well as representation learning-based featurization face drawbacks. In this work, we first shift the focus from a homogeneous to a heterogeneous perspective, by defining different probabilistic meta paths on augmented call graphs. Secondly, we focus on solutions for the usually significant number of random walks that graph representation learning methods require. To this end, we propose a sampling method for random walks based on a combination of most suitable random walk generation strategies, which we determine with the help of corresponding Markov models. In our experimental evaluation, we demonstrate the benefits of probabilistic meta path-based walk generation in terms of predictive power. In addition, this paper provides promising insights regarding the interplay of the type of meta path and the predictive outcome, as well as the potential of sampling random walks based on the meta path structure in order to alleviate the computational requirements of representation learning by reducing typically sizable required data input. © 2019",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067422579&doi=10.1016%2fj.ipm.2019.06.001&partnerID=40&md5=8de63763ab07024a05db36a738f08fba,Information Processing and Management,Exclude,,Exclude,
Yang Y.; Fu Z.; Iftekhar A.; Cui X.,A Semantic Aware Meta-path Model for Heterogeneous Network Representation Learning,"Heterogeneous graph representation learning is to learn effective representations for nodes or (sub)graphs, which preserve node attributes and structural information. However, it is challenging to design a representation learning method for heterogeneous information networks (HINs) due to their diversity. Most of the existing HIN-oriented learning methods define a series of meta-paths. Then, they aggregate the representations learned from different meta-paths in the same hidden space. These methods do not consider semantic differences of different meta-paths, which leads to semantic confusion. And further affects the effectiveness of the learned representation. Given these issues, we introduce a Semantic Aware HIN Representation learning Network (SAHRN), which takes into account the semantics of different meta-paths. We mitigate the problem of semantic confusion by projecting nodes&#x2019; features into different hidden spaces separately according to different meta-paths. To further expand the scope of aggregation and enrich the aggregated information, we also design various variants of our model by adding layer aggregation. Extensive experiments on three standard HIN datasets show that SAHRN achieves consistent improvements compared to state-of-the-art graph representation learning methods. The experiments and analyses on each component of the model show the effectiveness of the proposed method. The source code is available on https://github.com/pingpingand/SAHRN. CCBYNCND",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097945445&doi=10.1109%2fACCESS.2020.3043269&partnerID=40&md5=abfe0d0ab0d3a71872672bf5da99c43c,IEEE Access,Exclude,,,
Takesue Y.; Mashima Y.; Takeuchi K.,Analysis and Visualization of Patterns in Answers to Programming Problems,"It is not an easy task for teachers to make students' answers for programming exercises. In scoring such a student program, the teacher needs to evaluate not only the degree of program achievement but also which way the program achieve the requirements. In order to solve such problems, we propose a supporting method to evaluate the program using 'prog2vec', which is software that converts a program into its feature vector representation. Specifically, our method estimates whether a programming problem needs certain ways to achieve its purpose or not. The input of the method is a set of the programs that are made as answer for the problem. If the method estimates that specific ways are needed to achieve the given problem, it also visualizes these programing ways in structural graph representation. In this way, our proposed method helps teachers that have a lot of and various answers for a programming problem to define evaluation criteria for those answers. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080898612&doi=10.1109%2fIIAI-AAI.2019.00213&partnerID=40&md5=92bf16e1b0b4ede6627f6e51509299f3,"Proceedings - 2019 8th International Congress on Advanced Applied Informatics, IIAI-AAI 2019",Include,,,
Sanakoyeu A.; Tschernezki V.; Buchler U.; Ommer B.,Divide and conquer the embedding space for metric learning,"Learning the embedding space, where semantically similar objects are located close together and dissimilar objects far apart, is a cornerstone of many computer vision applications. Existing approaches usually learn a single metric in the embedding space for all available data points, which may have a very complex non-uniform distribution with different notions of similarity between objects, e.g. appearance, shape, color or semantic meaning. Approaches for learning a single distance metric often struggle to encode all different types of relationships and do not generalize well. In this work, we propose a novel easy-to-implement divide and conquer approach for deep metric learning, which significantly improves the state-of-the-art performance of metric learning. Our approach utilizes the embedding space more efficiently by jointly splitting the embedding space and data into K smaller sub-problems. It divides both, the data and the embedding space into K subsets and learns K separate distance metrics in the non-overlapping subspaces of the embedding space, defined by groups of neurons in the embedding layer of the neural network. The proposed approach increases the convergence speed and improves generalization since the complexity of each sub-problem is reduced compared to the original one. We show that our approach outperforms the state-of-the-art by a large margin in retrieval, clustering and re-identification tasks on CUB200-2011, CARS196, Stanford Online Products, In-shop Clothes and PKU VehicleID datasets. Source code: https://bit.ly/dcesml. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078784287&doi=10.1109%2fCVPR.2019.00056&partnerID=40&md5=7d0301985e75f8503d6db7625e349e5b,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,Exclude,,Exclude,
Straka M.; Straková J.,Úfal MRPipE at MRP 2019: Udpipe goes semantic in the meaning representation parsing shared task,"We present a system description of our contribution to the CoNLL 2019 shared task, Cross-Framework Meaning Representation Parsing (MRP 2019). The proposed architecture is our first attempt towards a semantic parsing extension of the UDPipe 2.0, a lemmatization, POS tagging and dependency parsing pipeline. For the MRP 2019, which features five formally and linguistically different approaches to meaning representation (DM, PSD, EDS, UCCA and AMR), we propose a uniform, language and framework agnostic graph-to-graph neural network architecture. Without any knowledge about the graph structure, and specifically without any linguistically or framework motivated features, our system implicitly models the meaning representation graphs. After fixing a human error (we used earlier incorrect version of provided test set analyses), our submission would score third in the competition evaluation. The source code of our system is available at https://github.com/ufal/mrpipe-conll2019. © 2019 Association for Computational Linguistics",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084361903&doi=10.18653%2fv1%2fK19-2012&partnerID=40&md5=18b67ed0475467e849dae33a5e5f528e,"CoNLL 2019 - SIGNLL Conference on Computational Natural Language Learning, Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning",Exclude,,,
Zheng T.; Chen W.-J.; Tsang I.; Yao X.,Rectified Encoder Network for High-Dimensional Imbalanced Learning,"Many existing works have studied the learning on imbalanced data, however, it is still very challenging to handle high-dimensional imbalanced data. One key challenge of learning on imbalanced data is that most learning models usually have a bias towards the majority and its performance will deteriorate in the presence of underrepresented data and severe class distribution skews. One solution is to synthesize the minority data to balance the class distribution, but it may lead to more overlapping, especially in the high-dimensional setting. To alleviate the above challenges, in this paper, we present a novel Rectified Encoder Network (REN) for high-dimensional imbalanced learning tasks. The main contribution is that: (1) To deal with high-dimensionality, REN encodes high-dimensional imbalanced data into low dimensional latent codes as a latent representation. (2) To obtain a discriminative representation, we introduce a Rectifier to match the latent codes with our proposed Predefined Codes, which disentangles the overlapping among classes. (3) During rectification, in the Predefined Latent Distribution, we can efficiently identify and generate informative samples to maintain the balance of class distribution, so that the minority classes will not be neglected. The experimental results on several high-dimensional and image imbalanced data sets indicate that our REN obtains good representation code for classification and visualize the reason why REN gets better performance in high-dimensional imbalanced learning. © 2019, Springer Nature Switzerland AG.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072866437&doi=10.1007%2f978-3-030-29911-8_53&partnerID=40&md5=584fe3ca0519a5a28f3b5d1cd4c292c0,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Chen L.; Ye W.; Zhang S.,Capturing Source Code Semantics via Tree-based Convolution over API-enhanced AST,"When deep learning meets big code, a key question is how to efficiently learn a distributed representation for source code that can capture its semantics effectively. We propose to use tree-based convolution over API-enhanced AST. To demonstrate the effectiveness of our approach, we apply it to detect semantic clones-code fragments with similar semantics but dissimilar syntax. Experiment results show that our approach outperforms an existing state-of-the-art approach that uses tree-based LSTM, with an increase of 0.39 and 0.12 in F1-score on OJClone and BigCloneBench respectively. We further propose architectures that incorporate our approach for code search and code summarization. © 2019 Association for Computing Machinery.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066012156&doi=10.1145%2f3310273.3321560&partnerID=40&md5=f82f46e1227a2748179f7d71d5072443,"ACM International Conference on Computing Frontiers 2019, CF 2019 - Proceedings",Include,,,
Azcona D.; Hsiao I.-H.; Arora P.; Smeaton A.,User2Code2vec: Embeddings for profiling students based on distributional representations of source code,"In this work, we propose a new methodology to profile individual students of computer science based on their programming design using a technique called embeddings. We investigate different approaches to analyze user source code submissions in the Python language. We compare the performances of different source code vectorization techniques to predict the correctness of a code submission. In addition, we propose a new mechanism to represent students based on their code submissions for a given set of laboratory tasks on a particular course. This way, we can make deeper recommendations for programming solutions and pathways to support student learning and progression in computer programming modules effectively at a Higher Education Institution. Recent work using Deep Learning tends to work better when more and more data is provided. However, in Learning Analytics, the number of students in a course is an unavoidable limit. Thus we cannot simply generate more data as is done in other domains such as FinTech or Social Network Analysis. Our findings indicate there is a need to learn and develop better mechanisms to extract and learn effective data features from students so as to analyze the students' progression and performance effectively. © 2019 Association for Computing Machinery.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062775545&doi=10.1145%2f3303772.3303813&partnerID=40&md5=57afdeb344c75f39f57c3e0cf6dd2c24,ACM International Conference Proceeding Series,Include,,Include,
Gong K.; Liang X.; Li Y.; Chen Y.; Yang M.; Lin L.,Instance-Level Human Parsing via Part Grouping Network,"Instance-level human parsing towards real-world human analysis scenarios is still under-explored due to the absence of sufficient data resources and technical difficulty in parsing multiple instances in a single pass. Several related works all follow the “parsing-by-detection” pipeline that heavily relies on separately trained detection models to localize instances and then performs human parsing for each instance sequentially. Nonetheless, two discrepant optimization targets of detection and parsing lead to suboptimal representation learning and error accumulation for final results. In this work, we make the first attempt to explore a detection-free Part Grouping Network (PGN) for efficiently parsing multiple people in an image in a single pass. Our PGN reformulates instance-level human parsing as two twinned sub-tasks that can be jointly learned and mutually refined via a unified network: (1) semantic part segmentation for assigning each pixel as a human part (e.g., face, arms); (2) instance-aware edge detection to group semantic parts into distinct person instances. Thus the shared intermediate representation would be endowed with capabilities in both characterizing fine-grained parts and inferring instance belongings of each part. Finally, a simple instance partition process is employed to get final results during inference. We conducted experiments on PASCAL-Person-Part dataset and our PGN outperforms all state-of-the-art methods. Furthermore, we show its superiority on a newly collected multi-person parsing dataset (CIHP) including 38,280 diverse images, which is the largest dataset so far and can facilitate more advanced human analysis. The CIHP benchmark and our source code are available at http://sysu-hcp.net/lip/. © 2018, Springer Nature Switzerland AG.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055434354&doi=10.1007%2f978-3-030-01225-0_47&partnerID=40&md5=173fff08dc5310ffb12108ee2d156c4b,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Zheng R.; Chen J.; Qiu X.,"Same representation, different attentions: Shareable sentence representation learning from multiple tasks","Distributed representation plays an important role in deep learning based natural language processing. However, the representation of a sentence often varies in different tasks, which is usually learned from scratch and suffers from the limited amounts of training data. In this paper, we claim that a good sentence representation should be invariant and can benefit the various subsequent tasks. To achieve this purpose, we propose a new scheme of information sharing for multi-task learning. More specifically, all tasks share the same sentence representation and each task can select the task-specific information from the shared sentence representation with attention mechanisms. The query vector of each task's attention could be either static parameters or generated dynamically. We conduct extensive experiments on 16 different text classification tasks, which demonstrate the benefits of our architecture. Source codes of this paper are available on Github. © 2018 International Joint Conferences on Artificial Intelligence.All right reserved.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055686767&doi=10.24963%2fijcai.2018%2f642&partnerID=40&md5=20ad1cbcb36decdc7246b9fd3a2510f0,IJCAI International Joint Conference on Artificial Intelligence,Exclude,,,
Liu J.; Fang C.; Ansari N.,Request Dependency Graph: A Model for Web Usage Mining in Large-Scale Web of Things,"In the Web of Things (WoT) environment, Web traffic logs contain valuable information of how people interact with smart devices and Web servers. Mining the wealth of information available in the Web access logs has theoretical and practical significance for many important applications like network optimization and security management. The first critical step of the mining task is modeling the relationships among HyperText Transfer Protocol (HTTP) requests for accessing Web objects to investigate the behavior of Web clients. In this paper, we introduce the request dependency graph (RDG), a graph representation of the relationships among HTTP requests. Conceptually, a directed link from A to B in the graph means that the accessing of Web object B is caused by the accessing of A, i.e., B depends on A. We propose a methodology to establish such a graph by mining the temporal and causal information among aggregated HTTP requests. To demonstrate the value and effectiveness of the proposed model, we design and implement an algorithm for primary requests identification, which is a critical task of Web usage mining, based on the RDG. Evaluation results from a large-scale real-world Web access log shows that the RDG is a useful tool for Web usage mining. © 2015 IEEE.",Article,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982952604&doi=10.1109%2fJIOT.2015.2452964&partnerID=40&md5=d12ca01d1fa11f67e6246f0ee3e53fff,IEEE Internet of Things Journal,Exclude,,,
Eichinger F.; Oßner C.; Böhm K.,Scalable software-defect localisation by hierarchical mining of dynamic call graphs,"The localisation of defects in computer programmes is essential in software engineering and is important in domain-specific data mining. Existing techniques which build on call-graph mining localise defects well, but do not scale for large software projects. This paper presents a hierarchical approach with good scalability characteristics. It makes use of novel call-graph representations, frequent subgraph mining and feature selection. It first analyses call graphs of a coarse granularity, before it zooms-in into more fine-grained graphs. We evaluate our approach with defects in the Mozilla Rhino project: In our setup, it narrows down the code a developer has to examine to about 6% only. Copyright © SIAM.",Conference paper,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880082474&doi=10.1137%2f1.9781611972818.62&partnerID=40&md5=cca17dad8543a430daf12caba33ab8be,"Proceedings of the 11th SIAM International Conference on Data Mining, SDM 2011",Include,,,
Schuster S.; Nivre J.; Manning C.D.,Sentences with gapping: Parsing and reconstructing elided predicates,"Sentences with gapping, such as Paul likes coffee and Mary tea, lack an overt predicate to indicate the relation between two or more arguments. Surface syntax representations of such sentences are often produced poorly by parsers, and even if correct, not well suited to downstream natural language understanding tasks such as relation extraction that are typically designed to extract information from sentences with canonical clause structure. In this paper, we present two methods for parsing to a Universal Dependencies graph representation that explicitly encodes the elided material with additional nodes and edges. We find that both methods can reconstruct elided material from dependency trees with high accuracy when the parser correctly predicts the existence of a gap. We further demonstrate that one of our methods can be applied to other languages based on a case study on Swedish. © 2018 The Association for Computational Linguistics.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083490965&partnerID=40&md5=0ee02a1b35a97c795e81fe2158110a07,NAACL HLT 2018 - 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference,Exclude,,,
Abdulsahib A.K.; Kamaruddin S.S.,Graph based text representation for document clustering,"Advances in digital technology and the World Wide Web has led to the increase of digital documents that are used for various purposes such as publishing and digital library. This phenomenon raises awareness for the requirement of effective techniques that can help during the search and retrieval of text. One of the most needed tasks is clustering, which categorizes documents automatically into meaningful groups. Clustering is an important task in data mining and machine learning. The accuracy of clustering depends tightly on the selection of the text representation method. Traditional methods of text representation model documents as bags of words using term-frequency index document frequency (TFIDF). This method ignores the relationship and meanings of words in the document. As a result the sparsity and semantic problem that is prevalent in textual document are not resolved. In this study, the problem of sparsity and semantic is reduced by proposing a graph based text representation method, namely dependency graph with the aim of improving the accuracy of document clustering. The dependency graph representation scheme is created through an accumulation of syntactic and semantic analysis. A sample of 20 news groups, dataset was used in this study. The text documents undergo pre-processing and syntactic parsing in order to identify the sentence structure. Then the semantic of words are modeled using dependency graph. The produced dependency graph is then used in the process of cluster analysis. K-means clustering technique was used in this study. The dependency graph based clustering result were compared with the popular text representation method, i.e. TFIDF and Ontology based text representation. The result shows that the dependency graph outperforms both TFIDF and Ontology based text representation. The findings proved that the proposed text representation method leads to more accurate document clustering results. © 2005 - 2015 JATIT & LLS. All rights reserved.",Article,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930694414&partnerID=40&md5=5c7f0059c26594915cdf9360315173c7,Journal of Theoretical and Applied Information Technology,Exclude,,,
Cserép M.; Krupp D.,Component visualization methods for large legacy software in C/C++,"Software development in C and C++ is widely used in the various industries including Information Technology, Telecommunication and Transportation since the 80-ies. Over this four decade, companies have built up a huge software legacy. In many cases these programs, implementing complex features (such as OS kernels, databases) become inherently complicated and consist of millions lines of code. During the many years long development, not only the size of the software increases, but a large number (i.e. hundreds) of programmers get involved. Mainly due to these two factors the maintenance of software becomes more and more time consuming and costly. To attack the above mentioned complexity issue, companies apply various source code cross-referencers to help in the navigation and visualization of the legacy code. In this article we present a visualization methodology that helps programmers to understand the functional dependencies of artifacts in the C++ code in the form similar to UML component diagrams. Our novel graph representation reveals relations between binaries, C/C++ implementation files and headers. Our technique is non-intrusive. It does not require any modification of the source code or any additional documentation markup. It solely relies on the compiler generated Abstract Syntax Tree and the build information to analyze the legacy software. © 2015, Eszterhazy Karoly College. All rights reserved.",Article,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930692508&partnerID=40&md5=81b955aac9a116ba911f4fe893ee0459,Annales Mathematicae et Informaticae,Exclude,,,
Xia X.; Lo D.; Wang X.; Zhou B.,Build system analysis with link prediction,"Compilation is an important step in building working software system. To compile large systems, typically build systems, such as make, are used. In this paper, we investigate a new research problem for build configuration file (e.g., Makefile) analysis: how to predict missed dependencies in a build configuration file. We refer to this problem as dependency mining. Based on a Makefile, we build a dependency graph capturing various relationships defined in the Makefile. By representing a Makefile as a dependency graph, we map the dependency mining problem to a link prediction problem, and leverage 9 state-of-the-art link prediction algorithms to solve it. We collected Makefiles from 7 open source projects to evaluate the effectiveness of the algorithms. Copyright 2014 ACM.",Conference paper,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905650920&doi=10.1145%2f2554850.2555134&partnerID=40&md5=05ed5d20675511553cdb8c6e229847e7,Proceedings of the ACM Symposium on Applied Computing,Include,,Include,
Zhang W.; Chen G.; Kandemir M.; Karakoy M.,Interprocedural optimizations for improving data cache performance of array-intensive embedded applications,"As datasets processed by embedded processors increase in size and complexity, the management of higher levels of memory hierarchy (e.g., caches) is becoming an important issue. A major limitation of most of the cache locality optimization techniques proposed by previous research is that they handle a single procedure at a time. This prevents compilers from capturing the data access interactions between procedures and may result in poor performance. In this paper, we look at loop and data transformations from a different angle and use them in an interprocedural optimization framework. Employing the call graph representation of a given application, the proposed technique visits each node of this graph twice and uses loop and data transformations in a systematic way for optimizing array layouts whole program wide. Our experimental results show that this interprocedural locality optimization strategy is much more effective than the previous locality-based techniques that handle each procedure in isolation.",Conference paper,2003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041633587&doi=10.1145%2f776050.776054&partnerID=40&md5=2ecbe3dc39153957fd0910f7b9aac929,Proceedings - Design Automation Conference,Exclude,,Exclude,
Hassan M.; Coulet A.; Toussaint Y.,Learning subgraph patterns from text for extracting disease-symptom relationships,"To some extent, texts can be represented in the form of graphs, such as dependency graphs in which nodes represent words and edges represent grammatical dependencies between words. Graph representation of texts is an interesting alternative to string representation because it provides an additional level of abstraction over the syntax that is sometime easier to compute. In this paper, we study the use of graph mining methods on texts represented as dependency graphs, for extracting relationships between pairs of annotated entities. We propose a three step approach that includes (1) the transformation of texts in a collection of dependency graphs; (2) the selection of frequent subgraphs, named hereafter patterns, on the basis of positive sentences; and (3) the extraction of relationships by searching for occurrences of patterns in novel sentences. Our method has been experimented by extracting disease-symptom relationships from a corpus of 51,292 PubMed abstracts (428,491 sentences) related to 50 rare diseases. The extraction of correct disease-symptom relationships has been evaluated on 565 sentences, showing a precision of 0.91 and a recall of 0.49 (F-Meaure is 0.63). These preliminary experiments show the feasibility of extracting good quality relationships using frequent subgraph mining. Copyright © by the paper's authors.",Conference paper,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920917637&partnerID=40&md5=7536e5a01384521e3ecfa02ddd5b14cf,CEUR Workshop Proceedings,Exclude,,,
Ali O.; Zappella G.; De Bie T.; Cristianini N.,An empirical comparison of label prediction algorithms on automatically inferred networks,"The task of predicting the label of a network node, based on the labels of the remaining nodes, is an area of growing interest in machine learning, as various types of data are naturally represented as nodes in a graph. As an increasing number of methods and approaches are proposed to solve this task, the problem of comparing their performance becomes of key importance. In this paper we present an extensive experimental comparison of 15 different methods, on 15 different labelled-networks, as well as releasing all datasets and source code. In addition, we release a further set of networks that were not used in this study (as not all benchmarked methods could manage very large datasets). Besides the release of data, protocols and algorithms, the key contribution of this study is that in each of the 225 combinations we tested, the best performance-both in accuracy and running time-was achieved by the same algorithm: Online Majority Vote. This is also one of the simplest methods to implement.",Conference paper,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862215638&partnerID=40&md5=c065f66d6c00ede8c19dd3dc1673c1ac,ICPRAM 2012 - Proceedings of the 1st International Conference on Pattern Recognition Applications and Methods,Exclude,,,
Tu C.; Zhang W.; Liu Z.; Sun M.,Max-Margin DeepWalk: Discriminative learning of network representation,"DeepWalk is a typical representation learning method that learns low-dimensional representations for vertices in social networks. Similar to other network representation learning (NRL) models, it encodes the network structure into vertex representations and is learnt in unsupervised form. However, the learnt representations usually lack the ability of discrimination when applied to machine learning tasks, such as vertex classification. In this paper, we overcome this challenge by proposing a novel semi-supervised model, max-margin Deep- Walk (MMDW). MMDW is a unified NRL framework that jointly optimizes the max-margin classifier and the aimed social representation learning model. Influenced by the max-margin classifier, the learnt representations not only contain the network structure, but also have the characteristic of discrimination. The visualizations of learnt representations indicate that our model is more discriminative than unsupervised ones, and the experimental results on vertex classification demonstrate that our method achieves a significant improvement than other state-of-the-art methods. The source code can be obtained from https://github. com/thunlp/MMDW.",Conference paper,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006086124&partnerID=40&md5=cde77e09dd68dad1076b1689148b9e8d,IJCAI International Joint Conference on Artificial Intelligence,Exclude,,,
Danielsen L.E.,On the classification of self-dual additive codes over GF(9),"Additive codes over GF(9) that are self-dual with respect to the Hermitian trace inner product have previously been classified up to length 8. In this paper, all codes of length 9 and 10 are classified, using a new algorithm that combines two graph representations of codes. First, the search space is reduced by the fact that every self-dual additive code can be mapped to a weighted graph. Then a different graph is described that transforms the problem of code equivalence into a problem of graph isomorphism. © 2010 IEEE.",Conference paper,2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955699937&doi=10.1109%2fISIT.2010.5513658&partnerID=40&md5=38a3fd7449ba08ad93ca8916c1090d81,IEEE International Symposium on Information Theory - Proceedings,Exclude,,,
He H.; Wu L.; Yang X.; Yan H.; Gao Z.; Feng Y.; Townsend G.,Dual Long Short-Term Memory Networks for Sub-Character Representation Learning,"Characters have commonly been regarded as the minimal processing unit in Natural Language Processing (NLP). But many non-latin languages have hieroglyphic writing systems, involving a big alphabet with thousands or millions of characters. Each character is composed of even smaller parts, which are often ignored by the previous work. In this paper, we propose a novel architecture employing two stacked Long Short-Term Memory Networks (LSTMs) to learn sub-character level representation and capture deeper level of semantic meanings. To build a concrete study and substantiate the efficiency of our neural architecture, we take Chinese Word Segmentation as a research case example. Among those languages, Chinese is a typical case, for which every character contains several components called radicals. Our networks employ a shared radical level embedding to solve both Simplified and Traditional Chinese Word Segmentation, without extra Traditional to Simplified Chinese conversion, in such a highly end-to-end way the word segmentation can be significantly simplified compared to the previous work. Radical level embeddings can also capture deeper semantic meaning below character level and improve the system performance of learning. By tying radical and character embeddings together, the parameter count is reduced whereas semantic knowledge is shared and transferred between two levels, boosting the performance largely. On 3 out of 4 Bakeoff 2005 datasets, our method surpassed state-of-the-art results by up to 0.4%. Our results are reproducible; source codes and corpora are available on GitHub (https://github.com/hankcs/sub-character-cws). © 2018, Springer International Publishing AG, part of Springer Nature.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045833408&doi=10.1007%2f978-3-319-77028-4_55&partnerID=40&md5=535932fce4708e6dc0951406a3cfa7a2,Advances in Intelligent Systems and Computing,Exclude,,,
Robillard M.P.,A representation for describing and analyzing concerns in source code,[No abstract available],Conference paper,2002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036036573&doi=10.1145%2f581469.581470&partnerID=40&md5=fbe4e86628282bc7466866ad92c60174,Proceedings - International Conference on Software Engineering,Exclude,,Exclude,
Zhiyuli A.; Liang X.; Xu Z.,Learning distributed representations for large-scale dynamic social networks,"Learning distributed representations of symbolic data were introduced by Hinton[1], and first developed in modeling networks for learning the node vectors by Perozzi et al (2014). In this work, we proposed Dnps, a novel nodes embedding approach for acquiring distributed representations of large-scale dynamic social networks. Dnps is suitable for many types of social networks: dynamic/static, directed/undirected, and weighted/unweighted. Recently, several works of nodes embedding were proposed. However, they were designed for static networks, such as language networks. To address this problem, first, we develop a damping based positive sampling (DpS) algorithm to learn the hierarchical structure of social networks. Then, we devise a local search based DpS algorithm to obtain incremental information of network evolution. Finally, we show Dnps's potentials on future link prediction task for three real-life large-scale dynamic social networks. The results show that Dnps consistently outperforms all baseline methods and exhibits an improvement of 12%, 6%, 4% on Digg, Flickr and YouTube over the second-highest level, respectively. Moreover, Dnps is also scalable. For example, Dnps can speed up the training process in 2 ∼ 36 times compared with benchmarks on Flickr network. The source codes of the project is available online1. © 2017 IEEE.",Conference paper,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034019839&doi=10.1109%2fINFOCOM.2017.8057104&partnerID=40&md5=77b976d765bd10d3c019a53d394e3b07,Proceedings - IEEE INFOCOM,Exclude,,Exclude,
Buykx L.; Petrie H.,Recipe sub-goals and graphs: An evaluation by cooks,"Following recipes can be difficult for cooks. Many recipes use technical culinary language and condense their instructions into brief sentences, cooks may also get lost in long paragraphs as they jump around the recipe to find tasks to perform in parallel. Multimedia content has been shown to increase the confidence of cooks but few comparative evaluations have been reported. In this study we evaluated the effect of adding pictures of interim goal states to a plain text recipe and the effect of presenting recipe steps in a dependency graph representation. Initial results indicate that cooks value pictures of interim goals states to compare their ingredients against, and prefer a graph representation of a recipe because it supports the cook's non-linear path through recipe instructions. © 2012 ACM.",Conference paper,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870512348&doi=10.1145%2f2390776.2390789&partnerID=40&md5=c0e752f77ec177ccfa30ca745a43ee64,"CEA 2012 - Proceedings of the 2012 ACM Workshop on Multimedia for Cooking and Eating Activities, Co-located with ACM Multimedia 2012",Exclude,,Exclude,
De Smedt T.; Daelemans W.,Pattern for python,"Pattern is a package for Python 2.4+ with functionality for web mining (Google + Twitter + Wikipedia, web spider, HTML DOM parser), natural language processing (tagger/chunker, n-gram search, sentiment analysis, WordNet), machine learning (vector space model, k-means clustering, Naive Bayes + k-NN + SVM classifiers) and network analysis (graph centrality and visualization). It is well documented and bundled with 30+ examples and 350+ unit tests. The source code is licensed under BSD and available from http://www.clips.ua.ac.be/pages/ pattern.© 2012 Tom De Smedt and Walter Daelemans.",Article,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864960770&partnerID=40&md5=4af186e762ad866833d814661cb8264f,Journal of Machine Learning Research,Exclude,,Exclude,
Czech M.; Hüllermeier E.; Jakobs M.-C.; Wehrheim H.,Predicting rankings of software verification tools,"Today, software verification tools have reached the maturity to be used for large scale programs. Different tools perform differently well on varying code. A software developer is hence faced with the problem of choosing a tool appropriate for her program at hand. A ranking of tools on programs could facilitate the choice. Such rankings can, however, so far only be obtained by running all considered tools on the program. In this paper, we present a machine learning approach to predicting rankings of tools on programs. The method builds upon so-called label ranking algorithms, which we complement with appropriate kernels providing a similarity measure for programs. Our kernels employ a graph representation for software source code that mixes elements of control flow and program dependence graphs with abstract syntax trees. Using data sets from the software verification competition SV-COMP, we demonstrate our rank prediction technique to generalize well and achieve a rather high predictive accuracy (rank correlation > 0.6). © 2017 Copyright held by the owner/author(s).",Conference paper,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052882315&doi=10.1145%2f3121257.3121262&partnerID=40&md5=18b8a9acd060494963e86062f6f2ed90,"SWAN 2017 - Proceedings of the 3rd ACM SIGSOFT International Workshop on Software Analytics, Co-located with FSE 2017",Include,,,
Ahmad I.; Karlapalem K.; Kwok Y.-K.; So S.-K.,Evolutionary algorithms for allocating data in distributed database systems,"A major cost in executing queries in a distributed database system is the data transfer cost incurred in transferring relations (fragments) accessed by a query from different sites to the site where the query is initiated. The objective of a data allocation algorithm is to determine an assignment of fragments at different sites so as to minimize the total data transfer cost incurred in executing a set of queries. This is equivalent to minimizing the average query execution time, which is of primary importance in a wide class of distributed conventional as well as multimedia database systems. The data allocation problem, however, is NP-complete, and thus requires fast heuristics to generate efficient solutions. Furthermore, the optimal allocation of database objects highly depends on the query execution strategy employed by a distributed database system, and the given query execution strategy usually assumes an allocation of the fragments. We develop a site-independent fragment dependency graph representation to model the dependencies among the fragments accessed by a query, and use it to formulate and tackle data allocation problems for distributed database systems based on query-site and move-small query execution strategies. We have designed and evaluated evolutionary algorithms for data allocation for distributed database systems.",Article,2002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036162986&doi=10.1023%2fA%3a1013324605452&partnerID=40&md5=86c8d61466a43287f566259f591802c3,Distributed and Parallel Databases,Exclude,,,
Loyola P.; Matsuo Y.,Learning graph representations for defect prediction,"We propose to study the impact of the representation of the data in defect prediction models. For this study, we focus on the use of developer activity data, from which we structure dependency graphs. Then, instead of manually generating features, such as network metrics, we propose a model inspired in recent advances in Representation Learning which are able to automatically learn representations from graph data. These new representations are compared against manually crafted features for defect prediction in real world software projects. © 2017 IEEE.",Conference paper,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026781427&doi=10.1109%2fICSE-C.2017.68&partnerID=40&md5=5cf4f2e227d3a6f76fe196552721c144,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",Include,,Include,
Chouhan N.; Dutta M.; Singh M.,A code analysis base regression test selection technique for D Programming language,"D is a new programming language. This is an object-oriented, imperative, multi-paradigm system programming language. Regression testing on D programming language still untouched by researchers. Our research attempts to bridge this gap by introducing a techniques to revalidate D programs. A framework is proposed which automates both the regression test selection and regression testing processes for D programming language. As part of this approach, special consideration is given to the analysis of the source code of D language. In our approach system dependence graph representation will be used for regression test selection for analyzing and comparing the code changes of original and modified program. First we construct a system dependence graph of the original program from the source code. When some modification is executed in a program, the constructed graph is updated to reflect the changes. Our approach in addition to capturing control and data dependencies represents the dependencies arising from object-relations. The test cases that exercise the affected model elements in the program model are selected for regression testing. Empirical studies carried out by us show that our technique selects on an average of 26.36. % more fault-revealing test cases compared to a UML based technique while incurring about 37.34% increase in regression test suite size. © 2014 IEEE.",Conference paper,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927739950&doi=10.1109%2fCICN.2014.232&partnerID=40&md5=3d1d18f8439a5a2a8a99cb8f03d7f0ff,"Proceedings - 2014 6th International Conference on Computational Intelligence and Communication Networks, CICN 2014",Exclude,,,
Janowczyk A.; Madabhushi A.,Deep learning for digital pathology image analysis: A comprehensive tutorial with selected use cases,"Background: Deep learning (DL) is a representation learning approach ideally suited for image analysis challenges in digital pathology (DP). The variety of image analysis tasks in the context of DP includes detection and counting (e.g., mitotic events), segmentation (e.g., nuclei), and tissue classification (e.g., cancerous vs. non-cancerous). Unfortunately, issues with slide preparation, variations in staining and scanning across sites, and vendor platforms, as well as biological variance, such as the presentation of different grades of disease, make these image analysis tasks particularly challenging. Traditional approaches, wherein domain-specific cues are manually identified and developed into task-specific handcrafted features, can require extensive tuning to accommodate these variances. However, DL takes a more domain agnostic approach combining both feature discovery and implementation to maximally discriminate between the classes of interest. While DL approaches have performed well in a few DP related image analysis tasks, such as detection and tissue classification, the currently available open source tools and tutorials do not provide guidance on challenges such as (a) selecting appropriate magnification, (b) managing errors in annotations in the training (or learning) dataset, and (c) identifying a suitable training set containing information rich exemplars. These foundational concepts, which are needed to successfully translate the DL paradigm to DP tasks, are non-trivial for (i) DL experts with minimal digital histology experience, and (ii) DP and image processing experts with minimal DL experience, to derive on their own, thus meriting a dedicated tutorial. Aims: This paper investigates these concepts through seven unique DP tasks as use cases to elucidate techniques needed to produce comparable, and in many cases, superior to results from the state-of-the-art hand-crafted feature-based classification approaches. Results : Specifically, in this tutorial on DL for DP image analysis, we show how an open source framework (Caffe), with a singular network architecture, can be used to address: (a) nuclei segmentation (F-score of 0.83 across 12,000 nuclei), (b) epithelium segmentation (F-score of 0.84 across 1735 regions), (c) tubule segmentation (F-score of 0.83 from 795 tubules), (d) lymphocyte detection (F-score of 0.90 across 3064 lymphocytes), (e) mitosis detection (F-score of 0.53 across 550 mitotic events), (f) invasive ductal carcinoma detection (F-score of 0.7648 on 50 k testing patches), and (g) lymphoma classification (classification accuracy of 0.97 across 374 images). Conclusion: This paper represents the largest comprehensive study of DL approaches in DP to date, with over 1200 DP images used during evaluation. The supplemental online material that accompanies this paper consists of step-by-step instructions for the usage of the supplied source code, trained models, and input data. © 2016 Journal of Pathology Informatics | Published by Wolters Kluwer -Medknow.",Article,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009238256&doi=10.4103%2f2153-3539.186902&partnerID=40&md5=1b2fa6a54ec22277c5f5f14e9fdfe6e3,Journal of Pathology Informatics,Exclude,,,
Adolphs P.; Xu F.; Li H.; Uszkoreit H.,Dependency graphs as a generic interface between parsers and relation extraction rule learning,"In this paper, we propose to use dependency graphs rather than trees as the interface between a parser and the rule acquisition module of a relation extraction (RE) system. Dependency graphs are much more expressive than trees and can easily be adapted to the output representations of various parsers, in particular those with richer semantics. Our approach is built on top of an existing minimally supervised machine learning system for relation extraction. We extend its original tree-based interface to a graph-based representation. In our experiments, we make use of two different dependency parsers and a deep HPSG parser. As expected, switching to a graph representation for the parsers outputting dependency trees does not have any impact on the RE results. But using the graph-based representation for the extraction with deep HPSG analyses improves both recall and f-score of the RE and enables the system to extract more relation instances of higher arity. Furthermore, we also compare the performance among these parsers with respect to their contribution to the RE task. In general, the robust dependency parsers are good in recall. However, the fine-grained deep syntactic parsing wins when it comes to precision. © 2011 Springer-Verlag.",Conference paper,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053944128&doi=10.1007%2f978-3-642-24455-1_5&partnerID=40&md5=654cb32846aa4fed61b9a32ab20ab932,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,Include,
Kountouris Apostolos A.; Wolinski Christophe,Hierarchical Conditional Dependency Graphs for mutual exclusiveness identification,"Identifying operation mutual exclusiveness is important in order to improve the quality of high-level synthesis results, by reducing either the required number of control steps or the needed hardware resources by conditional resource sharing. To this end we propose the Hierarchical Conditional Dependency Graph representation and an algorithm for identification of mutually exclusive operations. A hierarchical control organization permits to minimize the number of pair-wise exclusiveness tests during the identification process. Using graph transformations and reasoning on arithmetic inequalities, the proposed approach can produce results independent of description styles and identify more mutually exclusive operation pairs than previous approaches.",Conference paper,1999,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032713340&doi=10.1109%2ficvd.1999.745139&partnerID=40&md5=99d5c823bdad8938e184c34c1bacec7f,Proceedings of the IEEE International Conference on VLSI Design,Exclude,,Include,Exclude
Zhou B.; Xia X.; Lo D.; Wang X.,Build predictor: More accurate missed dependency prediction in build configuration files,"Software build system (e.g., Make) plays an important role in compiling human-readable source code into an executable program. One feature of build system such as make-based system is that it would use a build configuration file (e.g., Make file) to record the dependencies among different target and source code files. However, sometimes important dependencies would be missed in a build configuration file, which would cause additional debugging effort to fix it. In this paper, we propose a novel algorithm named Build Predictor to mine the missed dependncies. We first analyze dependencies in a build configuration file (e.g., Make file), and establish a dependency graph which captures various dependencies in the build configuration file. Next, considering that a build configuration file is constructed based on the source code dependency relationship, we establish a code dependency graph (code graph). Build Predictor is a composite model, which combines both dependency graph and code graph, to achieve a high prediction performance. We collected 7 build configuration files from various open source projects, which are Zlib, putty, vim, Apache Portable Runtime (APR), memcached, nginx, and Tengine, to evaluate the effectiveness of our algorithm. The experiment results show that compared with the state-of-the-art link prediction algorithms used by Xia et al., our Build Predictor achieves the best performance in predicting the missed dependencies. © 2014 IEEE.",Conference paper,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928640876&doi=10.1109%2fCOMPSAC.2014.12&partnerID=40&md5=a3241e7a46466f48c08d33704bc5e9dd,Proceedings - International Computer Software and Applications Conference,Include,,,
Khan G.N.; Jin M.,A new graph structure for hardware-software partitioning of heterogeneous systems,"We present a new graph representation, DADGP (Directed Acyclic Data dependency Graph with Precedence) that extends the well-known Directed Acyclic Graph (DAG) structure. DADGP is suitable for partitioning heterogeneous systems due to its data and precedence dependency features of processes. The partitioning technique described in this paper exposes parallelism among tasks and minimizes the overall system execution time. DADGP-based system partitioning method starts with a single CPU software solution, finds the longest delay path in the DADGP structure and tries to map its nodes to dedicated hardware to minimize the execution time of target system. Exposing parallelism simplifies the partitioning process and reduces the overall system cost.",Conference paper,2004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4944256878&partnerID=40&md5=87baa2b13be7cd503fb54a02f1e8c46b,Canadian Conference on Electrical and Computer Engineering,Exclude,,Include,Exclude
Erdweg S.; Van Der Storm T.; Dai Y.,Capture-avoiding and hygienic program transformations,"Program transformations in terms of abstract syntax trees compromise referential integrity by introducing variable capture. Variable capture occurs when in the generated program a variable declaration accidentally shadows the intended target of a variable reference. Existing transformation systems either do not guarantee the avoidance of variable capture or impair the implementation of transformations. We present an algorithm called name-fix that automatically eliminates variable capture from a generated program by systematically renaming variables. name-fix is guided by a graph representation of the binding structure of a program, and requires name-resolution algorithms for the source language and the target language of a transformation. name-fix is generic and works for arbitrary transformations in any transformation system that supports origin tracking for names. We verify the correctness of name-fix and identify an interesting class of transformations for which name-fix provides hygiene. We demonstrate the applicability of name-fix for implementing capture-avoiding substitution, inlining, lambda lifting, and compilers for two domain-specific languages. © 2014 Springer-Verlag.",Conference paper,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905384138&doi=10.1007%2f978-3-662-44202-9_20&partnerID=40&md5=aae09a39bb070b96fc6ace9385388d56,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Lin Zen Yong; Liu P.,Structural attribute feature code representation and recognition of multifont printed Chinese characters,"In this paper, a new structural representation fuzzy matching scheme are proposed for multifont printed Chinese character recognition. A Chinese character is decomposed into eight stroke types. A complete structural attribute feature codes among different types of strokes are defined and extracted, which consist of weak and strong primary codes and secondary codes. Weak and strong primary feature codes depict the global and local spatial relationships among different types of strokes respectively, and they are used for a detailed match. A fuzzy matching scheme is used for detailed match between an input character and candidate characters. An experiment on 3755 Chinese characters used daily in multifonts and multisizes shows that our method is robust and can achieve high recognition accuracy.",Article,2001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035273382&doi=10.1142%2fS0218001401000885&partnerID=40&md5=3d6799ae7f6ff0e67e33f6bbcfacf9db,International Journal of Pattern Recognition and Artificial Intelligence,Exclude,,,
Kountouris A.A.; Wolinski C.,Hierarchical conditional dependency graphs for conditional resource sharing,"Conditional resource sharing has been identified as a possibility for optimizing high-level synthesis results. We propose a hierarchical conditional dependency graph representation that permits to treat conditional resource sharing in a generic fashion depending on the specific context, i.e. functional units, storage elements and interconnects. Resource usage conditions are represented in a control hierarchy of BDD trees that permits efficient reasoning on condition exclusiveness. These ideas are illustrated by a scheduling example. © 1998 IEEE.",Conference paper,1998,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969549930&doi=10.1109%2fEURMIC.1998.711816&partnerID=40&md5=c06fe03ff39538c254ed04532449e978,"Proceedings - 24th EUROMICRO Conference, EURMIC 1998",Exclude,,,
Yang J.; Parikh D.; Batra D.,Joint unsupervised learning of deep representations and image clusters,"In this paper, we propose a recurrent framework for joint unsupervised learning of deep representations and image clusters. In our framework, successive operations in a clustering algorithm are expressed as steps in a recurrent process, stacked on top of representations output by a Convolutional Neural Network (CNN). During training, image clusters and representations are updated jointly: image clustering is conducted in the forward pass, while representation learning in the backward pass. Our key idea behind this framework is that good representations are beneficial to image clustering and clustering results provide supervisory signals to representation learning. By integrating two processes into a single model with a unified weighted triplet loss function and optimizing it end-to-end, we can obtain not only more powerful representations, but also more precise image clusters. Extensive experiments show that our method outperforms the state of-the-art on image clustering across a variety of image datasets. Moreover, the learned representations generalize well when transferred to other tasks. The source code can be downloaded from https://github.com/jwyang/joint-unsupervised-learning. © 2016 IEEE.",Conference paper,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986281587&doi=10.1109%2fCVPR.2016.556&partnerID=40&md5=752347779a519e3036933678959315b5,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,Exclude,,,
Jeong Y.; Song H.O.,Efficient end-to-end learning for quantizable representations,"Embedding representation learning via neural networks is at the core foundation of modern similarity based search. While much effort has been put in developing algorithms for learning binary hamming code representations for search efficiency,: this still requires a linear scan of the entire dataset per each query and trades off the search accuracy through binarization. To this end, we consider the problem of directly learning a quantizable embedding representation and the sparse binary hash code end-to-end which can be used to construct an efficient hash table not only providing significant search reduction in the number of data but also achieving the state of the art search accuracy outperforming previous state of the art deep metric; learning methods. We also show that finding the optimal sparse binary hash code in a mini-batch can be computed exactly in polynomial time by solving a minimum cost flow problem. Our results on Cifar-100 and on ImageNet dataseis show the state of the art search accuracy in precision@k and NMI metrics while providing up to 98× and 478× search speedup respectively over exhaustive linear search. The source code is available at https://github.com/maestrojeong/Deep-Hash-Table-ICML18. © 2018 by authors.All right reserved.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057252480&partnerID=40&md5=813fcc6791e156da7862ccad308badeb,"35th International Conference on Machine Learning, ICML 2018",Exclude,,,
Jin M.; Khan G.N.,Heterogeneous Hardware-Software System partitioning using Extended Directed Acyclic Graph,"In this paper, we present a system partitioning technique in which the input system specification is based on C++ language. The proposed technique processes data and precedence dependencies simultaneously in one graph representation DADGP, which is an extension of Directed Acyclic Graph (DAG). The DADGP (Directed Acyclic Data dependency Graph with Precedence) based partitioning technique minimizes the communication overhead as well as overall system execution time under real-time deadline. It also tries to minimize the cost of target system in terms of hardware area. © PDCS 2003. All rights reserved.",Conference paper,2003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745658976&partnerID=40&md5=fded6c3cb9abac419b18734f60b93b30,"16th ISCA International Conference on Parallel and Distributed Computing Systems 2003, PDCS 2003",Exclude,,Exclude,
Dai Q.; Li Q.; Tang J.; Wang D.,Adversarial network embedding,"Learning low-dimensional representations of networks has proved effective in a variety of tasks such as node classification, link prediction and network visualization. Existing methods can effectively encode different structural properties into the representations, such as neighborhood connectivity patterns, global structural role similarities and other high-order proximities. However, except for objectives to capture network structural properties, most of them suffer from lack of additional constraints for enhancing the robustness of representations. In this paper, we aim to exploit the strengths of generative adversarial networks in capturing latent features, and investigate its contribution in learning stable and robust graph representations. Specifically, we propose an Adversarial Network Embedding (ANE) framework, which leverages the adversarial learning principle to regularize the representation learning. It consists of two components, i.e., a structure preserving component and an adversarial learning component. The former component aims to capture network structural properties, while the latter contributes to learning robust representations by matching the posterior distribution of the latent representations to given priors. As shown by the empirical results, our method is competitive with or superior to state-of-the-art approaches on benchmark network embedding tasks. The source code will be available online. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059745687&partnerID=40&md5=0baf71b8a68d6134aec20ee09dee26aa,"32nd AAAI Conference on Artificial Intelligence, AAAI 2018",Exclude,,,
Brabec M.; Bednárek D.,Procedural code representation in a flow graph,"Modern scientific computing often combines extensive calculation with complex structure of data; however, the programming methodologies and languages of high-performance computing significantly differ from those of databases. This impedance mismatch leads many projects to the use of either primitive (like JSON) or overly general (like distributed file systems) methods of data access, ignoring the decades of development in database technology. In this paper, we investigate the possibility to represent procedural code fragments using a network of operators similar to query plans used in relational database systems. Such a unified representation forms the necessary step towards an integrated computational-database platform. We propose a flow graph representation that allows us to analyze, transform and optimize applications more efficiently and without additional data. Along with the graph, we designed an algorithm that transforms a procedural code into the graph.",Conference paper,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930345749&partnerID=40&md5=e62ff2b6762587be889779d4c7b3f702,CEUR Workshop Proceedings,Exclude,,,
Pan S.; Wu J.; Zhu X.; Zhang C.,Graph ensemble boosting for imbalanced noisy graph stream classification,"Many applications involve stream data with structural dependency, graph representations, and continuously increasing volumes. For these applications, it is very common that their class distributions are imbalanced with minority (or positive) samples being only a small portion of the population, which imposes significant challenges for learning models to accurately identify minority samples. This problem is further complicated with the presence of noise, because they are similar to minority samples and any treatment for the class imbalance may falsely focus on the noise and result in deterioration of accuracy. In this paper, we propose a classification model to tackle imbalanced graph streams with noise. Our method, graph ensemble boosting, employs an ensemble-based framework to partition graph stream into chunks each containing a number of noisy graphs with imbalanced class distributions. For each individual chunk, we propose a boosting algorithm to combine discriminative subgraph pattern selection and model learning as a unified framework for graph classification. To tackle concept drifting in graph streams, an instance level weighting mechanism is used to dynamically adjust the instance weight, through which the boosting framework can emphasize on difficult graph samples. The classifiers built from different graph chunks form an ensemble for graph stream classification. Experiments on real-life imbalanced graph streams demonstrate clear benefits of our boosting design for handling imbalanced noisy graph stream. © 2014 IEEE.",Article,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027917439&doi=10.1109%2fTCYB.2014.2341031&partnerID=40&md5=21ac676244d083dd336fd6bf10db608b,IEEE Transactions on Cybernetics,Exclude,,,
Yang C.; Liu Z.; Zhao D.; Sun M.; Chang E.Y.,Network representation learning with rich text information,"Representation learning has shown its effectiveness in many tasks such as image classification and text mining. Network representation learning aims at learning distributed vector representation for each vertex in a network, which is also increasingly recognized as an important aspect for network analysis. Most network representation learning methods investigate network structures for learning. In reality, network vertices contain rich information (such as text), which cannot be well applied with algorithmic frameworks of typical representation learning methods. By proving that DeepWalk, a state-of-the-art network representation method, is actually equivalent to matrix factorization (MF), we propose text-associated DeepWalk (TADW). TADW incorporates text features of vertices into network representation learning under the framework of matrix factorization. We evaluate our method and various baseline methods by applying them to the task of multi-class classification of vertices. The experimental results show that, our method outperforms other baselines on all three datasets, especially when networks are noisy and training ratio is small. The source code of this paper can be obtained from https://github.com/albertyang33/TADW.",Conference paper,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949803524&partnerID=40&md5=898562d7fe9279d117dd8ab39c5fe6f1,IJCAI International Joint Conference on Artificial Intelligence,Exclude,,,
Robillard M.P.; Murphy G.C.,Concern graphs: Finding and describing concerns using structural program dependencies,"Many maintenance tasks address concerns, or features, that are not well modularized in the source code comprising a system. Existing approaches available to help software developers locate and manage scattered concerns use a representation based on lines of source code, complicating the analysis of the concerns. In this paper, we introduce the Concern Graph representation that abstracts the implementation details of a concern and makes explicit the relationships between different parts of the concern. The abstraction used in a Concern Graph has been designed to allow an obvious and inexpensive mapping back to the corresponding source code. To investigate the practical tradeoffs related to this approach, we have built the Feature Exploration and Analysis tool (FEAT) that allows a developer to manipulate a concern representation extracted from a Java system, and to analyze the relationships of that concern to the code base. We have used this tool to find and describe concerns related to software change tasks. We have performed case studies to evaluate the feasibility, usability, and scalability of the approach. Our results indicate that Concern Graphs can be used to document a concern for change, that developers unfamiliar with Concern Graphs can use them effectively, and that the underlying technology scales to industrial-sized programs.",Conference paper,2002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036039909&partnerID=40&md5=b63d1cd16d2cec7aff6ec8e11e30a22c,Proceedings - International Conference on Software Engineering,Exclude,,,
Mou L.; Jin Z.,TBCNN for programs’ abstract syntax trees,"In this chapter, we will apply the tree-based convolutional neural network (TBCNN) to the source code of programming languages, which we call programming language processing. In fact, programming language processing is a hot research topic in the field of software engineering; it has also aroused growing interest in the artificial intelligence community. A distinct characteristic of a program is that it contains rich, explicit, and complicated structural information, necessitating more intensive modeling of structures. In this chapter, we propose a TBCNN variant for programming language processing, where a convolution kernel is designed for programs’ abstract syntax trees. We show the effectiveness of TBCNN in two different program analysis tasks: classifying programs according to functionality, and detecting code snippets of certain patterns. TBCNN outperforms baseline methods, including several neural models for NLP. © The Author(s) 2018.",Book chapter,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054339226&doi=10.1007%2f978-981-13-1870-2_4&partnerID=40&md5=858f1f7aa4f4b9b1ed647cf8356a3192,SpringerBriefs in Computer Science,Include,,,
Bershadsky A.; Evseeva J.; Bozhday A.; Gudkov A.; Mkrtchian V.,Variability modeling in the automated system for authoring intelligent adaptive applications on the basis of three-dimensional graphics,"Development of adaptive applications with an extended life cycle is one of the most promising trends in the software engineering industry. The world of modern interactive applications on the basis of three-dimensional graphics (learning applications, virtual simulators, computer games, simulation environments, etc.) is not exception. Designing interactive programs one should take into account both the variability of the user and the variability of the environment. Such a program should not be interrupted because of updating the software. The intelligent adaptive applications should be based on such models that would allow them to monitor the processes of variability and to adapt to them without having to recompile the source code. The main objectives of the work are: 1) to provide an overview of existing techniques for modeling software variability and self-adaptation; 2) to consider problems of extending the life cycle of software; 3) to offer techniques for modeling variability to design adaptive applications with support of 3D-graphics. © Springer International Publishing Switzerland 2015.",Conference paper,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951830759&doi=10.1007%2f978-3-319-23766-4_12&partnerID=40&md5=dda8148223ed7a946ce6cdba31f7de88,Communications in Computer and Information Science,Exclude,,,
Katkoori Srinivas; Roy Jay; Vemuri Ranga,Hierarchical register optimization algorithm for behavioral synthesis,"In this work, we address the problem of register optimization that arises during high-level synthesis from hierarchical behavioral specifications containing a hierarchy of modules such as procedures, functions etc. Register optimization (or register sharing) is the process of grouping carriers in the specification such that each group can be safely assigned to a hardware register. Global register optimization by in-line expansion involves flattening the module hierarchy and using a heuristic register optimization procedure on the flattened description. Although in-line expansion leads to near-optimal number of registers, it is time consuming due to the large number of carrier compatibility relationships that must be considered. We present an efficient register optimization algorithm which achieves nearly the same effect of in-line expansion without actually in-line expanding at the specification level. It differs from other techniques as it employs a hierarchical optimization phase which exploits the properties of the module call graph and the information gathered during local carrier life-cycle analysis of each module. Experimental results on a number of examples show that the proposed algorithm produces nearly the same number of registers as in-line expansion based global optimization and is faster by a factor ranging from 1.5 to 18.3.",Conference paper,1996,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029697589&partnerID=40&md5=ec4538c8a0afa68849da39216fe7922b,Proceedings of the IEEE International Conference on VLSI Design,Exclude,,,
Karlapalem K.; Pun N.M.,Query-driven data allocation algorithms for distributed database systems,"The objective of a data allocation algorithm is to locate the fragments at different sites so as to minimize the total data transfer cost incurred in executing a set of queries. We develop a site-independent fragment dependency graph representation to model the dependencies among the fragments accessed by a query, and use it to formulate and solve data allocation problems for distributed database systems based on (query-site and move-small) query execution strategies. We show that an optimal solution can be achieved when the query-site query execution strategy is employed, and for the move-small query execution strategy we performed experimental evaluation about the effectiveness of a hill-climbing heuristic algorithm in achieving a near-optimal solution. © Springer-Verlag Berlin Heidelberg 1997.",Conference paper,1997,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947763011&doi=10.1007%2fbfb0022044&partnerID=40&md5=f1da1a82bf94497995e2835a7f107ac0,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Robillard P.N.; Simoneau M.,Iconic control graph representation,"This paper presents a new representation of control flow graphs which is readable and concise, keeping all pertinent information as it appears in the source code. The iconic control graph provides an exact transformation of the source code. It is a basis for control flow visualization, unstructuredness identification, path crossing and path computation. The representation is programming‐language independent. The iconic control flow construction is automated. Copyright © 1993 John Wiley & Sons, Ltd",Article,1993,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027543768&doi=10.1002%2fspe.4380230206&partnerID=40&md5=429d19d8aeaaa69b4ca01014fa040f33,Software: Practice and Experience,Exclude,,,
Boatto L.; Consorti V.; Del Buono M.; Eramo V.; Esposito A.; Melcarne F.; Meucci M.; Morelli A.; Mosciatti M.; Spirito A.; Tucci M.,Detection and Separation of symbols connected to graphics in line drawings,"Separation of symbols from graphics is a typical problem that arises in applications for automatic data capture and automatic document recognition. In this paper we present a new technique for the detection and separation of symbols connected to graphics in line drawings. Our approach is based on a special image representation, that we call graph representation. The graph representation is especially convenient for line-like images, since it decomposes the line structure into ""edges"" and ""nodes"", that formalize the intuitive notions of ""line"" and ""crossingpoint between lines"". In this way, well-known algorithms in the graph theory can be used. The graph is searched for characteristic sub-graphs, revealing the presence of symbols or noisy objects overlapping lines. Each symbol candidate is accurately processed, in order to make the area of its connection to lines as regular as possible. Actually, two different algorithms have been designed to perform this task: one for symbols crossing lines and the other for symbols only touching lines. Both of them are rotation invariant. The algorithms described in this paper are currently implemented in a system for the automatic interpretation of Italian Land Register maps. However, they are based upon a quite general methodology, that can be easily applied to other kinds of line drawings, as well as to documents and forms. © 1992 Institute of Electrical and Electronics Engineers Inc. All rights reserved.",Conference paper,1992,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855596254&doi=10.1109%2fICPR.1992.201837&partnerID=40&md5=ce1b4d970eb5f34316e9834d9b0e045a,Proceedings - International Conference on Pattern Recognition,Exclude,,,
Kountouris Apostolos A.,Safe and efficient elimination of infeasible execution paths in WCET estimation,"Reasoning about the timing properties of a program is indispensable in the development of time critical systems where failure to meet deadlines can result in loss of life or material. To this end having tools to calculate safe and tight Worst Case Execution Time (WCET) bounds can be very valuable. In most of the approaches to date a lot of pessimism is attributed to the fact that many paths that are infeasible are not excluded from the WCET computations. To remedy this, user annotations to the source code were proposed and used. Unfortunately, there is no guarantee that these annotations are always correct. This fact renders such a manual approach unacceptable in the case of R/T systems where safety is an absolute priority. In this paper another approach for the safe elimination of infeasible execution paths is presented. This method is based on the R/T programming language SIGNAL and its internal Dynamic Graph representation.",Conference paper,1996,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030378261&partnerID=40&md5=8224ed7b1c2ee77be33bb7dfaee20322,Proceedings of the International Workshop on Real-Time Computing Systems and Applications/RTCSA,Exclude,,Include,Exclude
Kwok Y.-K.; Karlapalem K.; Ahmad I.; Pun N.M.,Design and evaluation of data allocation algorithms for distributed multimedia database systems,"A major cost in retrieving multimedia data from multiple sites is the cost incurred in transferring multimedia data objects (MDO's) from different sites to the site where the query is initiated. The objective of a data allocation algorithm is to locate the MDO's at different sites so as to minimize the total data transfer cost incurred in executing a given set of queries. There is a mutual dependency between data allocation and query execution strategies in that the optimal allocation of MDO's depends on the query execution strategy employed by a distributed multimedia system while the query execution strategy optimizes a query based on this allocation. In this paper, we fix the query execution strategy and develop a site-independent MDO dependency graph representation to model the dependencies among the MDO's accessed by a query. Given the MDO dependency graphs as well as the set of multimedia database sites, data transfer costs between the sites, the allocation limit on the number of MDO's that can be allocated at a site, and the query execution frequencies from the sites, an allocation scheme is generated. We formulate the data allocation problem as an optimization problem. We solve this problem with a number of techniques that broadly belong to three classes: max-flow min-cut, state-space search, and graph partitioning heuristics. The max-flow min-cut technique formulates the data allocation problem as a network-flow problem, and uses a hill-climbing approach to try to find the optimal solution. For the state-space search approach, the problem is solved using a best-first search algorithm. The graph partitioning approach uses two clustering heuristics, the agglomerative clustering and divisive clustering. We evaluate and compare these approaches, and assess their cost-performance trade-offs. All algorithms are also compared with optimal solutions obtained through exhaustive search. Conclusions are also made on the suitability of these approaches to different scenarios.",Review,1996,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030244802&doi=10.1109%2f49.536483&partnerID=40&md5=8d2fb9eed9ee095b9c0d91e9488fe456,IEEE Journal on Selected Areas in Communications,Exclude,,,
Paulisch F.N.; Tichy W.F.,Edge: An extendible graph editor,"EDGE is an editor kernel for the direct and visual manipulation of graphs. The kernel can be adapted quickly to diverse applications based on graphs, such as PERT chart editing, directory browsing, call graph display, logic circuit simulation or configuration visualization. EDGE provides potential solutions to the following general problems faced by any graph editor. (1) Automatic graph layout: how can application‐specific layout requirements, individual preferences, and layout stability be integrated with automatic layout algorithms? EDGE solves this problem with a novel algorithm that is based on layout constraints. (2) Graph abstraction: how can users deal with large graphs containing hundreds of nodes and edges, and thousands of edge crossings? EDGE can reduce the apparent complexity with subgraph abstractions and a novel clustering technique called edge concentration. (3) Adaptability: how should the editor kernel be structured to be adaptable to various applications? EDGE uses a special graph representation language for specifying visual appearance and the inheritance mechanism of C++ to achieve extendibility. (4) Persistence of graphs: how can the graph structures produced by the editor be kept in long‐term storage, especially if the node and edge data structures have been extended for a particular application? Our approach uses a standardized, external format for graphs and handles extensions with program generator technology: the I/O routines for reading and writing extended node and edge data structures are produced automatically from the declarations of these data structures. This paper describes EDGE and presents details of the above solutions. Copyright © 1990 John Wiley & Sons, Ltd",Article,1990,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025448297&doi=10.1002%2fspe.4380201307&partnerID=40&md5=0cb18c6f5c062d66f59882e5890a314e,Software: Practice and Experience,Exclude,,,
Yuan K.; Liu G.; Wu J.; Xiong H.,Semantic and Structural View Fusion Modeling for Social Recommendation,"Existing studies have shown that user-item interaction data and social relation data can be jointly used for enhancing the performance of social recommendation. However, limited research has a focus on investigating how to deeply exploit different views of social interaction structures and rating behavior differences for further improving social recommendation. To this end, in this paper, we propose to integrate information from both semantic and structural views for social recommendation. Specifically, we first design a collective intelligence-based strategy to reveal high-quality implicit relations for both users and items. Then, by reformulating all available nodes and relations as a heterogeneous graph, we define multiple semantic metapaths to capture diverse preferences for comprehensive user and item representations. While various metapaths enlarge the representation capacity of users and items, they also introduce noise and irrelevant information. We recall that, for the user-item interaction graph, different structure sizes (e.g., local and global structures) provide diverse and complementary information for recommendation. Motivated by this, we propose a semantic and structural view fusion framework for social recommendation (S4Rec), which consists of a deep graph model and a wide attentive SVD (Singular Value Decomposition) model for rating prediction by taking the local and global structure as input and aggregating messages along the predefined metapaths. Finally, the two predicted results are adaptively fused to achieve the final both accurate and stable prediction. In addition, we treat the user's rating behavior difference as the relative position difference problem in the embedding space, and model it with TransH to improve the generalization ability of the main rating model. Extensive experiments on three open datasets demonstrate the superiority of our framework compared with state-of-the-art methods. Particularly, our model outperforms other baselines under different sparsity conditions, further validating the effectiveness on cold-start users. We release the source code at https://github.com/lcwy220/Social-Recommendation. © 1989-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146237430&doi=10.1109%2fTKDE.2022.3230972&partnerID=40&md5=e6f72d2f41a08506ac1105b369e2f192,IEEE Transactions on Knowledge and Data Engineering,Exclude,,,
Liang Y.; Song Q.; Zhao Z.; Zhou H.; Gong M.,BA-GNN: Behavior-aware graph neural network for session-based recommendation,"Session-based recommendation is a popular research topic that aims to predict users’ next possible interactive item by exploiting anonymous sessions. The existing studies mainly focus on making predictions by considering users’ single interactive behavior. Some recent efforts have been made to exploit multiple interactive behaviors, but they generally ignore the influences of different interactive behaviors and the noise in interactive sequences. To address these problems, we propose a behavior-aware graph neural network for session-based recommendation. First, different interactive sequences are modeled as directed graphs. Thus, the item representations are learned via graph neural networks. Then, a sparse self-attention module is designed to remove the noise in behavior sequences. Finally, the representations of different behavior sequences are aggregated with the gating mechanism to obtain the session representations. Experimental results on two public datasets show that our proposed method outperforms all competitive baselines. The source code is available at the website of GitHub. © 2023, Higher Education Press.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148441209&doi=10.1007%2fs11704-022-2324-x&partnerID=40&md5=d0d26c6c1d5d2614a539017a37af2578,Frontiers of Computer Science,Exclude,,Exclude,
Chen B.; Peng W.; Wu M.; Zheng B.; Zhu S.,Neural-Symbolic Recommendation with Graph-Enhanced Information,"The recommendation task is not only a problem of inductive statistics from data but also a cognitive task that requires reasoning ability. The most advanced graph neural networks have been widely used in recommendation systems because they can capture implicit structured information from graph-structured data. However, like most neural network algorithms, they only learn matching patterns from a perception perspective. Some researchers use user behavior for logic reasoning to achieve recommendation prediction from the perspective of cognitive reasoning, but this kind of reasoning is a local one and ignores implicit information on a global scale. In this work, we combine the advantages of graph neural networks and propositional logic operations to construct a neuro-symbolic recommendation model with both global implicit reasoning ability and local explicit logic reasoning ability. We first build an item-item graph based on the principle of adjacent interaction and use graph neural networks to capture implicit information in global data. Then we transform user behavior into propositional logic expressions to achieve recommendations from the perspective of cognitive reasoning. Extensive experiments on five public datasets show that our proposed model outperforms several state-of-the-art methods, source code is avaliable at [ https://github.com/hanzo2020/GNNLR ]. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177828945&doi=10.1007%2f978-981-99-8067-3_31&partnerID=40&md5=c7751b58cb395cb0ac07852846fcfd93,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Hao P.; Qian Z.; Wang S.; Bai C.,Community aware graph embedding learning for item recommendation,"Due to the heterogeneity of a large amount of real-world data, meta-paths are widely used in recommendation. Such recommendation methods can represent composite relationships between entities, but cannot explore reliable relations between nodes and influence among meta-paths. For solving this problem, a Community Aware Graph Embedding Learning method for Item Recommendation(CAEIRec) is proposed. By adaptively constructing communities for nodes in the graph of entities, the correlations of nodes are embedded in graph learning from the aspect of community structure. Semantic information of users and items are jointly learnt in the embedding. Finally, the embeddings of users and items are fed to extend matrix factorization for getting the top recommendations. A series of comprehensive experiments are conducted on two different public datasets. The empirical results show that CAEIRec is an encouraging recommendation method by the comarison with the state-of-the-art methods. Source code of CAEIRec is available at https://github.com/a545187002/CAEIRec-tensorflow . © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178946592&doi=10.1007%2fs11280-023-01224-5&partnerID=40&md5=f097f14ebf2d46463ad24f1d5ed4abd6,World Wide Web,Exclude,,,
Li C.; Xia L.; Ren X.; Ye Y.; Xu Y.; Huang C.,Graph Transformer for Recommendation,"This paper presents a novel approach to representation learning in recommender systems by integrating generative self-supervised learning with graph transformer architecture. We highlight the importance of high-quality data augmentation with relevant self-supervised pretext tasks for improving performance. Towards this end, we propose a new approach that automates the self-supervision augmentation process through a rationale-aware generative SSL that distills informative user-item interaction patterns. The proposed recommender with Graph TransFormer (GFormer) that offers parameterized collaborative rationale discovery for selective augmentation while preserving global-aware user-item relationships. In GFormer, we allow the rationale-aware SSL to inspire graph collaborative filtering with task-adaptive invariant rationalization in graph transformer. The experimental results reveal that our GFormer has the capability to consistently improve the performance over baselines on different datasets. Several in-depth experiments further investigate the invariant rationale-aware augmentation from various aspects. The source code for this work is publicly available at: https://github.com/HKUDS/GFormer. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167676757&doi=10.1145%2f3539618.3591723&partnerID=40&md5=f9a1ea86fa939a3240cf6e73ba4effb9,SIGIR 2023 - Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,Exclude,,,
Wang X.; Fukumoto F.; Cui J.; Suzuki Y.; Li J.; Yu D.,EEDN: Enhanced Encoder-Decoder Network with Local and Global Context Learning for POI Recommendation,"The point-of-interest (POI) recommendation predicts users' destinations, which might be of interest to users and has attracted considerable attention as one of the major applications in location-based social networks (LBSNs). Recent work on graph-based neural networks (GNN) or matrix factorization-based (MF) approaches has resulted in better representations of users and POIs to forecast users' latent preferences. However, they still suffer from the implicit feedback and cold-start problems of check-in data, as they cannot capture both local and global graph-based relations among users (or POIs) simultaneously, and the cold-start neighbors are not handled properly during graph convolution in GNN. In this paper, we propose an enhanced encoder-decoder network (EEDN) to exploit rich latent features between users, POIs, and interactions between users and POIs for POI recommendation. The encoder of EEDN utilizes a hybrid hypergraph convolution to enhance the aggregation ability of each graph convolution step and learns to derive more robust cold-start-aware user representations. In contrast, the decoder mines local and global interactions by both graph- and sequential-based patterns for modeling implicit feedback, especially to alleviate exposure bias. Extensive experiments in three public real-world datasets demonstrate that EEDN outperforms state-of-the-art methods. Our source codes and data are released at https://github.com/WangXFng/EEDN. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168698787&doi=10.1145%2f3539618.3591678&partnerID=40&md5=bea9d071640bd7ca1730d1aa891269f3,SIGIR 2023 - Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,Exclude,,,
Dai J.; Yuan W.; Bao C.; Zhang Z.,DAS-GNN: Denoising autoencoder integrated with self-supervised learning in graph neural network-based recommendations,"To enhance the recommendation performance, session-based recommendations typically model based on graph neural networks (GNN). These models use the most recently clicked item as the user’s short-term interest, as well as the query vector in the attention mechanism. Based on it, the attention score is calculated with the remaining items to obtain the user’s long-term interest. However, the obtained representation of long-term interest is one-sided. Furthermore, unlike other recommendation technology, such as collaborative filtering that includes the user’s entire history information, the session-based recommendation is more vulnerable to data sparsity. Existing models primarily make predictions based on observable user-item interactions and ignore items not interacted with by users. To address the aforementioned issues, we propose the denoising autoencoder integrated with self-supervised learning (SSL) in graph neural networks (DAS-GNN). In DAS-GNN, the query extraction module based on denoising autoencoder can mine multiple user interests and assist long-term interest to express user needs more comprehensively. We propose an effective way of dividing positive and negative samples in the SSL module and use adaptive thresholds to mine negative hard samples, thereby improving training efficiency and alleviating data sparsity. Extensive experiments demonstrate that the proposed DAS-GNN outperforms state-of-the-art models on four benchmarks. The source code is available at: https://github.com/daijiuqian/DAS-GNN. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145029584&doi=10.1007%2fs10489-022-04399-y&partnerID=40&md5=b4bcf33a8dc7a8215a859e2c733839f0,Applied Intelligence,Exclude,,,
Quan Y.; Ding J.; Gao C.; Yi L.; Jin D.; Li Y.,Robust Preference-Guided Denoising for Graph based Social Recommendation,"Graph Neural Network (GNN) based social recommendation models improve the prediction accuracy of user preference by leveraging GNN in exploiting preference similarity contained in social relations. However, in terms of both effectiveness and efficiency of recommendation, a large portion of social relations can be redundant or even noisy, e.g., it is quite normal that friends share no preference in a certain domain. Existing models do not fully solve this problem of relation redundancy and noise, as they directly characterize social influence over the full social network. In this paper, we instead propose to improve graph based social recommendation by only retaining the informative social relations to ensure an efficient and effective influence diffusion, i.e., graph denoising. Our designed denoising method is preference-guided to model social relation confidence and benefits user preference learning in return by providing a denoised but more informative social graph for recommendation models. Moreover, to avoid interference of noisy social relations, it designs a self-correcting curriculum learning module and an adaptive denoising strategy, both favoring highly-confident samples. Experimental results on three public datasets demonstrate its consistent capability of improving three state-of-the-art social recommendation models by robustly removing 10-40% of original relations. We release the source code at https://github.com/tsinghua-fib-lab/Graph-Denoising-SocialRec. © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159349648&doi=10.1145%2f3543507.3583374&partnerID=40&md5=48b170727b76a23864ed24a4ad285c54,"ACM Web Conference 2023 - Proceedings of the World Wide Web Conference, WWW 2023",Exclude,,Exclude,
Jin Y.; Bai Y.; Zhu Y.; Sun Y.; Wang W.,Code Recommendation for Open Source Software Developers,"Open Source Software (OSS) is forming the spines of technology infrastructures, attracting millions of talents to contribute. Notably, it is challenging and critical to consider both the developers' interests and the semantic features of the project code to recommend appropriate development tasks to OSS developers. In this paper, we formulate the novel problem of code recommendation, whose purpose is to predict the future contribution behaviors of developers given their interaction history, the semantic features of source code, and the hierarchical file structures of projects. We introduce CODER, a novel graph-based CODE Recommendation framework for open source software developers, which accounts for the complex interactions among multiple parties within the system. CODER jointly models microscopic user-code interactions and macroscopic user-project interactions via a heterogeneous graph and further bridges the two levels of information through aggregation on file-structure graphs that reflect the project hierarchy. Moreover, to overcome the lack of reliable benchmarks, we construct three large-scale datasets to facilitate future research in this direction. Extensive experiments show that our CODER framework achieves superior performance under various experimental settings, including intra-project, cross-project, and cold-start recommendation. © 2023 Owner/Author.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159264141&doi=10.1145%2f3543507.3583503&partnerID=40&md5=32b2da1f0f6ea3e64ea2d6f6b9e24913,"ACM Web Conference 2023 - Proceedings of the World Wide Web Conference, WWW 2023",Include,,,
Chen M.; Huang C.; Xia L.; Wei W.; Xu Y.; Luo R.,Heterogeneous Graph Contrastive Learning for Recommendation,"Graph Neural Networks (GNNs) have become powerful tools in modeling graph-structured data in recommender systems. However, real-life recommendation scenarios usually involve heterogeneous relationships (e.g., social-aware user influence, knowledge-aware item dependency) which contains fruitful information to enhance the user preference learning. In this paper, we study the problem of heterogeneous graph-enhanced relational learning for recommendation. Recently, contrastive self-supervised learning has become successful in recommendation. In light of this, we propose a <u>H</u>eterogeneous <u>G</u>raph <u>C</u>ontrastive <u>L</u>earning (HGCL), which is able to incorporate heterogeneous relational semantics into the user-item interaction modeling with contrastive learning-enhanced knowledge transfer across different views. However, the influence of heterogeneous side information on interactions may vary by users and items. To move this idea forward, we enhance our heterogeneous graph contrastive learning with meta networks to allow the personalized knowledge transformer with adaptive contrastive augmentation. The experimental results on three real-world datasets demonstrate the superiority of HGCL over state-of-the-art recommendation methods. Through ablation study, key components in HGCL method are validated to benefit the recommendation performance improvement. The source code of the model implementation is available at the link https://github.com/HKUDS/HGCL. © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148981686&doi=10.1145%2f3539597.3570484&partnerID=40&md5=5605fd3996880fbc51911b902d1bfbba,WSDM 2023 - Proceedings of the 16th ACM International Conference on Web Search and Data Mining,Exclude,,,
Han Y.; Huang E.W.; Zheng W.; Rao N.; Wang Z.; Subbian K.,Search Behavior Prediction: A Hypergraph Perspective,"At E-Commerce stores such as Amazon, eBay, and Taobao, the shopping items and the query words that customers use to search for the items form a bipartite graph that captures search behavior. Such a query-item graph can be used to forecast search trends or improve search results. For example, generating query-item associations, which is equivalent to predicting links in the bipartite graph, can yield recommendations that can customize and improve the user search experience. Although the bipartite shopping graphs are straightforward to model search behavior, they suffer from two challenges: 1) The majority of items are sporadically searched and hence have noisy/sparse query associations, leading to a long-tail distribution. 2) Infrequent queries are more likely to link to popular items, leading to another hurdle known as disassortative mixing. To address these two challenges, we go beyond the bipartite graph to take a hypergraph perspective, introducing a new paradigm that leverages <u>auxiliary</u> information from anonymized customer engagement sessions to assist the <u>main task</u> of query-item link prediction. This auxiliary information is available at web scale in the form of search logs. We treat all items appearing in the same customer session as a single hyperedge. The hypothesis is that items in a customer session are unified by a common shopping interest. With these hyperedges, we augment the original bipartite graph into a new hypergraph. We develop a Dual-Channel Attention-Based Hypergraph Neural Network (DCAH), which synergizes information from two potentially noisy sources (original query-item edges and item-item hyperedges). In this way, items on the tail are better connected due to the extra hyperedges, thereby enhancing their link prediction performance. We further integrate DCAH with self-supervised graph pre-training and/or DropEdge training, both of which effectively alleviate disassortative mixing. Extensive experiments on three proprietary E-Commerce datasets show that DCAH yields significant improvements of up to 24.6% in mean reciprocal rank (MRR) and 48.3% in recall compared to GNN-based baselines. Our source code is available at https://github.com/amazon-science/dual-channel-hypergraph-neural-network. © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149642358&doi=10.1145%2f3539597.3570403&partnerID=40&md5=f31f7cfb87b141b711565cdb64d907e8,WSDM 2023 - Proceedings of the 16th ACM International Conference on Web Search and Data Mining,Exclude,,Exclude,
Jendal T.E.; Lissandrini M.; Dolog P.; Hose K.,GInRec: A Gated Architecture for Inductive Recommendation using Knowledge Graphs,"We have witnessed increasing interest in exploiting KGs to integrate contextual knowledge in recommender systems in addition to user-item interactions, e.g., ratings. Yet, most methods are transductive, i.e., they represent instances seen during training as low-dimensionality vectors but cannot do so for unseen instances. Hence, they require heavy retraining every time new items or users are added. Conversely, inductive methods promise to solve these issues. KGs enhance inductive recommendation by offering information on item-entity relationships, whereas existing inductive methods rely purely on interactions, which makes recommendations for users with few interactions sub-optimal and even impossible for new items. In this work, we investigate the actual ability of inductive methods exploiting both the structure and the data represented by KGs. Hence, we propose GInRec, a state-of-the-art method that uses a graph neural network with relation-specific gates and a KG to provide better recommendations for new users and items than related inductive methods. As a result, we re-evaluate state-of-the-art methods, identify better evaluation protocols, highlight unwarranted conclusions from previous proposals, and showcase a novel, stronger architecture for this task. The source code is available at: https://github.com/theisjendal/kars2023-recommendation-framework. © 2023 Copyright for this paper by its authors.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179001927&partnerID=40&md5=b9423dfccc300bd56617e7ae905e4a4a,CEUR Workshop Proceedings,Exclude,,,
Xia L.; Shao Y.; Huang C.; Xu Y.; Xu H.; Pei J.,Disentangled Graph Social Recommendation,"Social recommender systems have drawn a lot of attention in many online web services, because of the incorporation of social information between users in improving recommendation results. Despite the significant progress made by existing solutions, we argue that current methods fall short in two limitations: (1) Existing social-aware recommendation models only consider collaborative similarity between items, how to incorporate item-wise semantic relatedness is less explored in current recommendation paradigms. (2) Current social recommender systems neglect the entanglement of the latent factors over heterogeneous relations (e.g., social connections, user-item interactions). Learning the disentangled representations with relation heterogeneity poses great challenge for social recommendation. In this work, we design a Disentangled Graph Neural Network (DGNN) with the integration of latent memory units, which empowers DGNN to maintain factorized representations for heterogeneous types of user and item connections. Additionally, we devise new memory-augmented message propagation and aggregation schemes under the graph neural architecture, allowing us to recursively distill semantic relatedness into the representations of users and items in a fully automatic manner. Extensive experiments on three benchmark datasets verify the effectiveness of our model by achieving great improvement over state-of-the-art recommendation techniques. The source code is publicly available at: https://github.com/HKUDS/DGNN.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167660322&doi=10.1109%2fICDE55515.2023.00180&partnerID=40&md5=f2e1f0077e76493343b917cd3bbd4bd4,Proceedings - International Conference on Data Engineering,Exclude,,,
Zhai S.; Liu B.; Yang D.; Xiao Y.,Group Buying Recommendation Model Based on Multi-task Learning,"In recent years, group buying has become one popular kind of online shopping activities, thanks to its larger sales and lower unit price. Unfortunately, seldom research focuses on the recommendations specifically for group buying by now. Although some recommendation models have been proposed for group recommendation, they can not be directly used to achieve the real-world group buying recommendation, due to the essential difference between group recommendation and group buying recommendation. In this paper, we first formalize the task of group buying recommendation into two sub-tasks. Then, based on our insights into the correlations and interactions between the two sub-tasks, we propose a novel recommendation model for group buying, namely MGBR, which is built mainly with a multi-task learning module. To improve recommendation performance further, we devise some collaborative expert networks and adjusted gates in the multi-task learning module, to promote the information interaction between the two sub-tasks. Furthermore, we propose two auxiliary losses corresponding to the two sub-tasks, to refine the representation learning in our model. Our extensive experiments not only demonstrate that the augmented representations learned in our model result in better performance than previous recommendation models, but also justify the impacts of the specially designed components in our model. To reproduce our model's recommendation results conveniently, we have provided our model's source code and dataset on https://github.com/DeqingYang/MGBR.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167719396&doi=10.1109%2fICDE55515.2023.00080&partnerID=40&md5=3036f6028988c47816081d238ddfc09d,Proceedings - International Conference on Data Engineering,Exclude,,,
Yeh C.-Y.; Chen H.-W.; Yang D.-N.; Lee W.-C.; Yu P.S.; Chen M.-S.,Planning Data Poisoning Attacks on Heterogeneous Recommender Systems in a Multiplayer Setting,"Data poisoning attacks against recommender systems (RecSys) often assume a single seller as the adversary. However, in reality, there are usually multiple sellers attempting to promote their items through RecSys manipulation. To obtain the best data poisoning plan, it is important for an attacker to anticipate and withstand the actions of his opponents. This work studies the problem of Multiplayer Comprehensive Attack (MCA) from the perspective of the attacker, considering the subsequent attacks by his opponents. In MCA, we target the Heterogeneous RecSys, where user-item interaction records, user social network, and item correlation graph are used for recommendations. To tackle MCA, we present the Multilevel Stackelberg Optimization over Progressive Differentiable Surrogate (MSOPDS). The Multilevel Stackelberg Optimization (MSO) method is used to form the optimum strategies by solving the Stackelberg game equilibrium between the attacker and his opponents, while the Progressive Differentiable Surrogate (PDS) addresses technical challenges in deriving gradients for candidate poisoning actions. Experiments on Heterogeneous RecSys trained with public datasets show that MSOPDS outperforms all examined prior works by up to 10.6% in average predicted ratings and up to 11.4% in HitRate@3 for an item targeted by an attacker facing one opponent. Source code provided in https://github.com/jimmy-academia/MSOPDS.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167698247&doi=10.1109%2fICDE55515.2023.00193&partnerID=40&md5=a9dfc23f6f4bf88cc4d2349684c8a75e,Proceedings - International Conference on Data Engineering,Exclude,,Exclude,
Wu C.; Wang C.; Xu J.; Fang Z.; Gu T.; Wang C.; Song Y.; Zheng K.; Wang X.; Zhou G.,Instant Representation Learning for Recommendation over Large Dynamic Graphs,"Recommender systems are able to learn user preferences based on user and item representations via their historical behaviors. To improve representation learning, recent recommendation models start leveraging information from various behavior types exhibited by users. In real-world scenarios, the user behavioral graph is not only multiplex but also dynamic, i.e., the graph evolves rapidly over time, with various types of nodes and edges added or deleted, which causes the Neighborhood Disturbance. Nevertheless, most existing methods neglect such streaming dynamics and thus need to be retrained once the graph has significantly evolved, making them unsuitable in the online learning environment. Furthermore, the Neighborhood Disturbance existing in dynamic graphs deteriorates the performance of neighbor-aggregation based graph models. To this end, we propose SUPA, a novel graph neural network for dynamic multiplex heterogeneous graphs. Compared to neighbor-aggregation architecture, SUPA develops a sample-update-propagate architecture to alleviate neighborhood disturbance. Specifically, for each new edge, SUPA samples an influenced subgraph, updates the representations of the two interactive nodes, and propagates the interaction information to the sampled subgraph. Furthermore, to train SUPA incrementally online, we propose InsLearn, an efficient workflow for single-pass training of large dynamic graphs. Extensive experimental results on six real-world datasets show that SUPA has a good generalization ability and is superior to sixteen state-of-the-art baseline methods. The source code is available at https://github.com/shatter15/SUPA.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167684296&doi=10.1109%2fICDE55515.2023.00014&partnerID=40&md5=10bef1f710f60dade02a19374b5897fd,Proceedings - International Conference on Data Engineering,Exclude,,,
Xie Y.; Zhou P.; Kim S.,Decoupled Side Information Fusion for Sequential Recommendation,"Side information fusion for sequential recommendation (SR) aims to effectively leverage various side information to enhance the performance of next-item prediction. Most state-of-the-art methods build on self-attention networks and focus on exploring various solutions to integrate the item embedding and side information embeddings before the attention layer. However, our analysis shows that the early integration of various types of embeddings limits the expressiveness of attention matrices due to a rank bottleneck and constrains the flexibility of gradients. Also, it involves mixed correlations among the different heterogeneous information resources, which brings extra disturbance to attention calculation. Motivated by this, we propose Decoupled Side Information Fusion for Sequential Recommendation (DIF-SR), which moves the side information from the input to the attention layer and decouples the attention calculation of various side information and item representation. We theoretically and empirically show that the proposed solution allows higher-rank attention matrices and flexible gradients to enhance the modeling capacity of side information fusion. Also, auxiliary attribute predictors are proposed to further activate the beneficial interaction between side information and item representation learning. Extensive experiments on four real-world datasets demonstrate that our proposed solution stably outperforms state-of-the-art SR models. Further studies show that our proposed solution can be readily incorporated into current attention-based SR models and significantly boost performance. Our source code is available at https: //github.com/AIM-SE/DIF-SR. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135048515&doi=10.1145%2f3477495.3531963&partnerID=40&md5=03f7259c5913547cd1578f9f996cfd18,SIGIR 2022 - Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval,Exclude,,,
Cui L.; Lee D.,KETCH: Knowledge Graph Enhanced Thread Recommendation in Healthcare Forums,"Health thread recommendation methods aim to suggest the most relevant existing threads for a user. Most of the existing methods tend to rely on modeling the post contents to retrieve relevant answers. However, some posts written by users with different clinical conditions can be lexically similar, as unrelated diseases (e.g., Angina and Osteoporosis) may have the same symptoms (e.g., back pain), yet irrelevant threads to a user. Therefore, it is critical to not only consider the connections between users and threads, but also the descriptions of users' symptoms and clinical conditions. In this paper, towards this problem of thread recommendation in online healthcare forums, we propose a knowledge graph enhanced Threads Recommendation (KETCH) model, which leverages graph neural networks to model the interactions among users and threads, and learn their representations. In our model, the users, threads and posts are three types of nodes in a graph, linked through their associations. KETCH uses the message passing strategy by aggregating information along with the network. In addition, we introduce a knowledge-enhanced attention mechanism to capture the latent conditions and symptoms. We also apply the method to the task of predicting the side effects of drugs, to show that KETCH has the potential to complement the medical knowledge graph. Comparing with the best results of seven competing methods, in terms of MRR, KETCH outperforms all methods by at least 0.125 on the MedHelp dataset, 0.048 on the Patient dataset and 0.092 on HealthBoards dataset, respectively. We release the source code of KETCH at: https: //github.com/cuilimeng/KETCH. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135022900&doi=10.1145%2f3477495.3532008&partnerID=40&md5=474a1851eed4d2eaac3ae6239c8d6dad,SIGIR 2022 - Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval,Exclude,,,
Xie R.; Liu Q.; Liu S.; Zhang Z.; Cui P.; Zhang B.; Lin L.,Improving Accuracy and Diversity in Matching of Recommendation With Diversified Preference Network,"Real-world recommendation systems need to deal with millions of item candidates. Therefore, most practical large-scale recommendation systems usually contain two modules. The matching module aims to efficiently retrieve hundreds of high-quality items from large corpora, while the ranking module aims to generate specific ranks for these items. Recommendation diversity is an essential factor that strongly impacts user experience. There are lots of efforts that have explored recommendation diversity in ranking, while the matching module should take more responsibility for diversity. In this article, we propose a novel Heterogeneous graph neural network framework for diversified recommendation (GraphDR) in matching to improve both recommendation accuracy and diversity. Specifically, GraphDR builds a huge heterogeneous preference network to record different types of user preferences, and conducts a field-level heterogeneous graph attention network for node aggregation. We conduct a neighbor-similarity based loss with a multi-channel matching to improve both accuracy and diversity. In experiments, we conduct extensive online and offline evaluations on a real-world recommendation system with various accuracy and diversity metrics and achieve significant improvements. GraphDR has been deployed on a well-known recommendation system named WeChat Top Stories, which affects millions of users. The source code will be released in https://github.com/lqfarmer/GraphDR.  © 2015 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134342833&doi=10.1109%2fTBDATA.2021.3103263&partnerID=40&md5=8d225265f947976a3ed7a100aaee69f7,IEEE Transactions on Big Data,Exclude,,,
Chang Y.; Shu L.; Du E.; Chen C.; Zhang Z.; Zheng Z.; Huang Y.; Xing X.,GraphRR: A multiplex Graph based Reciprocal friend Recommender system with applications on online gaming service,"Reciprocal Recommender Systems (RRSs) are recommender systems specifically designed for people-to-people recommendation tasks, e.g., online gaming, dating, and recruitment services. They are fundamentally different from the conventional user–item recommendations. In RRSs, user interactions are usually directional, i.e., they are initiated by one side and not necessarily reciprocated by the other side. In the meanwhile, abundant multiplex user interactions, e.g., Friend Request and Send Message, are collated by the online services and can be represented into a large-scale multiplex user interaction graph. Despite the substantial progress of Graph Neural Networks (GNNs) on capturing users’ multiplex interactions, naive GNNs are insufficient to capture the additional information implied from the directions of interactions, as they are usually not designed to preserve the asymmetric proximities between users. In the paper, we present a novel Graph neural network for Reciprocal Recommendation (GraphRR) to utilize the multiplex user interactions. Specifically, three ego graphs are augmented based on the directions of interactions for each user to capture his preference, attraction and similarity in a finer granularity. Then the multiplexity-aware GNN modules are further applied to measure the contributions of different interaction types. Extensive experiments are conducted in the datasets of the real-world large-scale online games from NetEase Games, a leading game provider for worldwide users. The experimental results demonstrate the superiority of GraphRR over baseline methods and provide empirical evidence for the benefits of the proposed ego graph augmentation. The source code is also available online for reproductivity1. © 2022 Elsevier B.V.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132889793&doi=10.1016%2fj.knosys.2022.109187&partnerID=40&md5=7169521e78106ef23d24763b22309290,Knowledge-Based Systems,Exclude,,Exclude,
Cai Y.; Li J.,Rethinking transition relationship between co-occurring items in graph neural networks for session-based recommendation,"Session-based recommendation aims to recommend items based on anonymous behavior sequences. A session is generally modeled as a sequential structure or graph structure to extract its session-level representation. However, directly modeling a session as a sequence ignores the co-occurrence relationship between pairwise items, and current graph-based methods do not consider information transition directions sufficiently when calculating the similarity of co-occurring items. In this paper, we propose a novel approach, dubbed Item Transition Relationship Graph Neural Networks (ITR-GNN), to model different transition relationships between co-occurring items in an effective way, for better extracting user intents of current sessions. In ITR-GNN, session sequences are modeled as directed unweighted graphs, and two different transition relationships between a pair of co-occurring items are distinguished by two different concatenations of their latent vectors, according to the direction of the edge between them. In addition, we notice that the data used for session-based recommendation contain many noisy labels, degrading recommendation effects. Thereby, we introduce a label distillation strategy to learn improved soft labels and replace potential noisy labels through a teacher–student network. Experimental results on three benchmark datasets demonstrate that the ITR-GNN outperforms state-of-the-art methods. Source code is available at https://github.com/cyq002/ITR-GNN. © 2022 Elsevier B.V.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133900159&doi=10.1016%2fj.asoc.2022.109231&partnerID=40&md5=c302452565e7769aff53330a50a2b42f,Applied Soft Computing,Exclude,,,
Xie R.; Liu Q.; Wang L.; Liu S.; Zhang B.; Lin L.,Contrastive Cross-domain Recommendation in Matching,"Cross-domain recommendation (CDR) aims to provide better recommendation results in the target domain with the help of the source domain, which is widely used and explored in real-world systems. However, CDR in the matching (i.e., candidate generation) module struggles with the data sparsity and popularity bias issues in both representation learning and knowledge transfer. In this work, we propose a novel Contrastive Cross-Domain Recommendation (CCDR) framework for CDR in matching. Specifically, we build a huge diversified preference network to capture multiple information reflecting user diverse interests, and design an intra-domain contrastive learning (intra-CL) and three inter-domain contrastive learning (inter-CL) tasks for better representation learning and knowledge transfer. The intra-CL enables more effective and balanced training inside the target domain via a graph augmentation, while the inter-CL builds different types of cross-domain interactions from user, taxonomy, and neighbor aspects. In experiments, CCDR achieves significant improvements on both offline and online evaluations in a real-world system. Currently, we have deployed our CCDR on WeChat Top Stories, affecting plenty of users. The source code is in https://github.com/lqfarmer/CCDR.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134416984&doi=10.1145%2f3534678.3539125&partnerID=40&md5=a4dc98d863a049ac4d8f09038afff805,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Exclude,,,
Xia L.; Huang C.; Zhang C.,Self-Supervised Hypergraph Transformer for Recommender Systems,"Graph Neural Networks (GNNs) have been shown as promising solutions for collaborative filtering (CF) with the modeling of user-item interaction graphs. The key idea of existing GNN-based recommender systems is to recursively perform the message passing along the user-item interaction edge for refining the encoded embeddings. Despite their effectiveness, however, most of the current recommendation models rely on sufficient and high-quality training data, such that the learned representations can well capture accurate user preference. User behavior data in many practical recommendation scenarios is often noisy and exhibits skewed distribution, which may result in suboptimal representation performance in GNN-based models. In this paper, we propose SHT, a novel Self-Supervised Hypergraph Transformer framework (SHT) which augments user representations by exploring the global collaborative relationships in an explicit way. Specifically, we first empower the graph neural CF paradigm to maintain global collaborative effects among users and items with a hypergraph transformer network. With the distilled global context, a cross-view generative self-supervised learning component is proposed for data augmentation over the user-item interaction graph, so as to enhance the robustness of recommender systems. Extensive experiments demonstrate that SHT can significantly improve the performance over various state-of-the-art baselines. Further ablation studies show the superior representation ability of our SHT recommendation framework in alleviating the data sparsity and noise issues. The source code and evaluation datasets are available at: https://github.com/akaxlh/SHT.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137147152&doi=10.1145%2f3534678.3539473&partnerID=40&md5=66af79c750fafec74ce26263efefb783,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Exclude,,,
Li H.; Li L.; Xv G.; Lin C.; Li K.; Jiang B.,SPEX: A Generic Framework for Enhancing Neural Social Recommendation,"Social Recommender Systems (SRS) have attracted considerable attention since its accompanying service, social networks, helps increase user satisfaction and provides auxiliary information to improve recommendations. However, most existing SRS focus on social influence and ignore another essential social phenomenon, i.e., social homophily. Social homophily, which is the premise of social influence, indicates that people tend to build social relations with similar people and form influence propagation paths. In this article, we propose a generic framework Social PathExplorer (SPEX) to enhance neural SRS. SPEX treats the neural recommendation model as a black box and improves the quality of recommendations by modeling the social recommendation task, the formation of social homophily, and their mutual effect in the manner of multi-task learning. We design a Graph Neural Network based component for influence propagation path prediction to help SPEX capture the rich information conveyed by the formation of social homophily. We further propose an uncertainty based task balancing method to set appropriate task weights for the recommendation task and the path prediction task during the joint optimization. Extensive experiments have validated that SPEX can be easily plugged into various state-of-the-art neural recommendation models and help improve their performance. The source code of our work is available at: https://github.com/XMUDM/SPEX.  © 2021 Association for Computing Machinery.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124087343&doi=10.1145%2f3473338&partnerID=40&md5=d44a3632a8151fb764f4f55495152cc1,ACM Transactions on Information Systems,Exclude,,,
Quan V.H.; Ngan L.H.; Duc L.M.; Linh N.T.N.; Quynh-Le H.,EfficientRec: An Unlimited User Scale Recommendation System Based on Clustering and User’s Interaction Embedding Profile,"Recommendation systems are highly interested in technology companies nowadays. The businesses are constantly growing users and products, causing the number of users and items to continuously increase over time, to very large numbers. Traditional recommendation algorithms with complexity dependent on the number of users and items make them difficult to adapt to the industrial environment. In this paper, we introduce a new method applying graph neural networks with a contrastive learning framework in extracting user preferences. We incorporate a soft clustering architecture that significantly reduces the computational cost of the inference process. Experiments show that the model is able to learn user preferences with low computational cost in both training and prediction phases. At the same time, the model gives a very good accuracy. We call this architecture EfficientRec (Our source code available at: https://github.com/quanvu0996/EfficientRec ) with the implication of model compactness and the ability to scale to unlimited users and products. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144237644&doi=10.1007%2f978-981-19-8234-7_53&partnerID=40&md5=a19cff3e1a8cbe384219e86a7e3f6370,Communications in Computer and Information Science,Exclude,,Exclude,
Saito Y.; Sugiyama K.,Job Recommendation Based on Multiple Behaviors and Explicit Preferences,"A lot of job openings have been released online, which makes job recommendation more and more important. Recently, users often enter their preferences into job search websites to receive some job recommendations that they hope to apply for. To achieve this goal, the following two types of data are available: (1) auxiliary behavior data such as viewing job postings, bookmarking them and (2) explicit preference data such as conditions for a job that each user desires. Some researchers propose job recommendation by addressing either of them. However, they have not focused on simultaneously addressing both (1) and (2) so far. Given this point, we propose a method for job recommendation that employs auxiliary behavior data and each user's explicit preference data simultaneously. Additionally, our proposed method addresses multiple behavior overlaps and refines the latent representations. Experimental results on our dataset constructed from an actual job search website show that our proposed model outperforms several state-of-the-arts as measured by MRR and nDCG. Our source code has been released1.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158846039&doi=10.1109%2fWI-IAT55865.2022.00011&partnerID=40&md5=b791c8c17b4f4fa61799fd8f5bbe9c1c,"Proceedings - 2022 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology, WI-IAT 2022",Exclude,,Exclude,
Ye Z.; Feng Z.; Xiao J.; Gao Y.; Fan G.; Zhang H.; Chen S.,Heterogeneous Graph Neural Network-Based Software Developer Recommendation,"In software maintenance, it is critical for project managers to assign software issues to the appropriate developers. However, finding suitable developers is challenging due to the general sparsity and the long-tail of developer-issue interactions. In this paper, we propose a novel Heterogeneous Graph Neural Network-based method for Developer Recommendation (called HGDR), in which text information embedding and self-supervised learning (SSL) are incorporated. Specifically, to alleviate the sparsity of developer-issue interactions, we unify developer-issue interactions, developer-source code file interactions and issue-source code file relations into a heterogeneous graph, and we embed text descriptions to graph nodes as information supplements. In addition, to mitigate the long-tail influence, e.g., recommendation bias, the proficiency weight suppression link supplementation is proposed to complement the tail developers by adjusting proficiency weights. Finally, to fully utilize rich structural information of heterogeneous graph, we use the joint learning of metapath-guided heterogeneous graph neural network and SSL to learn the embedding representation. Extensive comparison experiments on three real-world datasets show that HGDR outperforms the state-of-the-art methods by 6.02% to 44.27% on recommended metric. The experimental results also demonstrate the efficacy of HGDR in the sparse and long-tail scenario. Our code is available at https://github.com/1qweasdzxc/HGDR. © 2022, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149873121&doi=10.1007%2f978-3-031-24383-7_24&partnerID=40&md5=ecf48c7bba6e98f18bb9a9e0c0705a55,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",Include,,,
Krasanakis E.; Symeonidis A.,Fast Library Recommendation in Software Dependency Graphs with Symmetric Partially Absorbing Random Walks,"To help developers discover libraries suited to their software projects, automated approaches often start from already employed libraries and recommend more based on co-occurrence patterns in other projects. The most accurate project–library recommendation systems employ Graph Neural Networks (GNNs) that learn latent node representations for link prediction. However, GNNs need to be retrained when dependency graphs are updated, for example, to recommend libraries for new projects, and are thus unwieldy for scalable deployment. To avoid retraining, we pro-pose that recommendations can instead be performed with graph filters; by analyzing dependency graph dynamics emulating human-driven library discovery, we identify low-pass filtering with memory as a promising direction and introduce a novel filter, called symmetric partially absorbing random walks, which infers rather than trains the parameters of filters with node-specific memory to guarantee low-pass filtering. Experiments on a dependency graph between Android projects and third-party libraries show that our approach makes recommendations with a quality and diversifica-tion loosely comparable to those state-of-the-art GNNs without computationally intensive retraining for new predictions. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129358472&doi=10.3390%2ffi14050124&partnerID=40&md5=b0c1e797271729e90fce836dbd73bd5d,Future Internet,Include,,Include,
Feng L.; Cai Y.; Wei E.; Li J.,Graph neural networks with global noise filtering for session-based recommendation,"Session-based recommendation leverages anonymous sessions to predict which item a user is most likely to click on next. While previous approaches capture items-transition patterns within current session and neighbor sessions, they do not accurately filter out noise within session or widen the range of feasible data in a more reasonable way. In a current session, the user may accidentally click on an unrelated item, resulting in the fact that, the users’ primary intents from neighbor sessions, may mismatch the current session. Thereby, we propose a new framework, dubbed Graph Neural Networks with Global Noise Filtering for Session-based Recommendation (GNN-GNF), aiming to filter noisy data and exploit items-transition patterns in a more comprehensive and reasonable manner. In simple terms, GNN-GNF contains two parts: data preprocessing and model learning. In data preprocesing, an item-level filter module is used to obtain the main intent of user and a session-level filter module is designed to filter the sessions unrelated to the target session intent by means of edge matching. In model learning, we consider both local-level interest obtained by an aggregation of the items representing the main intent of user within a session, and global-level interest deduced from a global graph. We take two kinds of neighbor aggregations, summation and interactive aggregation, respectively, to iteratively derive the representation of the central node in the global graph. Finally, GNN-GNF concatenates the local and global preference to characterize the current session, towards better recommendation prediction. Experiments on two datasets demonstrate that GNN-GNF can achieve competitive results. The source code is available at: https://github.com/Fenglixia/GNF. © 2021 Elsevier B.V.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120987214&doi=10.1016%2fj.neucom.2021.11.068&partnerID=40&md5=b87a2c9e642d192394e1147bf95911f6,Neurocomputing,Exclude,,,
Tran T.T.; Snasel V.,Improvement Graph Convolution Collaborative Filtering with Weighted Addition Input,"Graph Neural Networks have been extensively applied in the field of machine learning to find features of graphs, and recommendation systems are no exception. The ratings of users on considered items can be represented by graphs which are input for many efficient models to find out the characteristics of the users and the items. From these insights, relevant items are recommended to users. However, user’s decisions on the items have varying degrees of effects on different users, and this information should be learned so as not to be lost in the process of information mining. In this publication, we propose to build an additional graph showing the recommended weight of an item to a target user to improve the accuracy of GNN models. Although the users’ friendships were not recorded, their correlation was still evident through the commonalities in consumption behavior. We build a model WiGCN (Weighted input GCN) to describe and experiment on well-known datasets. Conclusions will be stated after comparing our results with state-of-the-art such as GCMC, NGCF and LightGCN. The source code is also included (https://github.com/trantin84/WiGCN ). © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145233729&doi=10.1007%2f978-3-031-21743-2_51&partnerID=40&md5=e8217786da45c5c3070ecade28d4c150,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Dai S.; Yu Y.; Fan H.; Dong J.,Spatio-Temporal Representation Learning with Social Tie for Personalized POI Recommendation,"Recommending a limited number of Point-of-Interests (POIs) a user will visit next has become increasingly important to both users and POI holders for Location-Based Social Networks (LBSNs). However, POI recommendation is a challenging task since complex sequential patterns and rich contexts are contained in extremely sparse user check-in data. Recent studies show that embedding techniques effectively incorporate POI contextual information to alleviate the data sparsity issue, and Recurrent Neural Network (RNN) has been successfully employed for sequential prediction. Nevertheless, existing POI recommendation approaches are still limited in capturing user personalized preference due to separate embedding learning or network modeling. To this end, we propose a novel unified spatio-temporal neural network framework, named PPR, which leverages users’ check-in records and social ties to recommend personalized POIs for querying users by joint embedding and sequential modeling. Specifically, PPR first learns user and POI representations by joint modeling User-POI relation, sequential patterns, geographical influence, and social ties in a heterogeneous graph and then models user personalized sequential patterns using the designed spatio-temporal neural network based on LSTM model for the personalized POI recommendation. Furthermore, we extend PPR to an end-to-end recommendation model by jointly learning node representations and modeling user personalized sequential preference. Extensive experiments on three real-world datasets demonstrate that our model significantly outperforms state-of-the-art baselines for successive POI recommendation in terms of Accuracy, Precision, Recall and NDCG. The source code is available at: https://www.anonymous.4open.science/r/DSE-1BEC. © 2022, The Author(s).",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123929844&doi=10.1007%2fs41019-022-00180-w&partnerID=40&md5=fc6724411f439bcb501373282ce17413,Data Science and Engineering,Exclude,,Exclude,
Xia L.; Xu Y.; Huang C.; Dai P.; Bo L.,Graph Meta Network for Multi-Behavior Recommendation,"Modern recommender systems often embed users and items into low-dimensional latent representations, based on their observed interactions. In practical recommendation scenarios, users often exhibit various intents which drive them to interact with items with multiple behavior types (e.g., click, tag-as-favorite, purchase). However, the diversity of user behaviors is ignored in most of existing approaches, which makes them difficult to capture heterogeneous relational structures across different types of interactive behaviors. Exploring multi-typed behavior patterns is of great importance to recommendation systems, yet is very challenging because of two aspects: i) The complex dependencies across different types of user-item interactions; ii) Diversity of such multi-behavior patterns may vary by users due to their personalized preference. To tackle the above challenges, we propose a Multi-Behavior recommendation framework with Graph Meta Network to incorporate the multi-behavior pattern modeling into a meta-learning paradigm. Our developed MB-GMN empowers the user-item interaction learning with the capability of uncovering type-dependent behavior representations, which automatically distills the behavior heterogeneity and interaction diversity for recommendations. Extensive experiments on three real-world datasets show the effectiveness of MB-GMN by significantly boosting the recommendation performance as compared to various state-of-the-art baselines. The source code is available at https://github.com/akaxlh/MB-GMN. © 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111625621&doi=10.1145%2f3404835.3462972&partnerID=40&md5=3cb28cdfa2a033d8ffe2bdf221fa8fc0,SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval,Exclude,,Exclude,
Xiao F.; Li L.; Xu W.; Zhao J.; Yang X.; Lang J.; Wang H.,DMBGN: Deep Multi-Behavior Graph Networks for Voucher Redemption Rate Prediction,"In E-commerce, vouchers are important marketing tools to enhance users' engagement and boost sales and revenue. The likelihood that a user redeems a voucher is a key factor in voucher distribution decision. User-item Click-Through-Rate (CTR) models are often applied to predict the user-voucher redemption rate. However, the voucher scenario involves more complicated relations among users, items and vouchers. The users' historical behavior in a voucher collection activity reflects users' voucher usage patterns, which is nevertheless overlooked by the CTR-based solutions. In this paper, we propose a Deep Multi-behavior Graph Networks (DMBGN) to shed light on this field for the voucher redemption rate prediction. The complex structural user-voucher-item relationships are captured by a User-Behavior Voucher Graph (UVG). User behavior happening both before and after voucher collection is taken into consideration, and a high-level representation is extracted by Higher-order Graph Neural Networks. On top of a sequence of UVGs, an attention network is built which can help to learn users' long-term voucher redemption preference. Extensive experiments on three large-scale production datasets demonstrate the proposed DMBGN model is effective, with 10% to 16% relative AUC improvement over Deep Neural Networks (DNN), and 2% to 4% AUC improvement over Deep Interest Network (DIN). Source code and a sample dataset are made publicly available to facilitate future research. © 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114943296&doi=10.1145%2f3447548.3467191&partnerID=40&md5=41b35efc85c47d9a90a5a105a1876c80,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Exclude,,,
Zhang Q.; Wang S.; Lu W.; Feng C.; Peng X.; Wang Q.,Rethinking Adjacent Dependency in Session-Based Recommendations,"Session-based recommendations (SBRs) recommend the next item for an anonymous user by modeling the dependencies between items in a session. Benefiting from the superiority of graph neural networks (GNN) in learning complex dependencies, GNN-based SBRs have become the main stream of SBRs in recent years. Most GNN-based SBRs are based on a strong assumption of adjacent dependency, which means any two adjacent items in a session are necessarily dependent here. However, based on our observation, the adjacency does not necessarily indicate dependency due to the uncertainty and complexity of user behaviours. Therefore, the aforementioned assumption does not always hold in the real-world cases and thus easily leads to two deficiencies: (1) the introduction of false dependencies between items which are adjacent in a session but are not really dependent, and (2) the missing of true dependencies between items which are not adjacent but are actually dependent. Such deficiencies significantly downgrade accurate dependency learning and thus reduce the recommendation performance. Aiming to address these deficiencies, we propose a novel review-refined inter-item graph neural network (RI-GNN), which utilizes the topic information extracted from items’ reviews to refine dependencies between items. Experiments on two public real-world datasets demonstrate that RI-GNN outperforms the state-of-the-art methods (The implementation is available at https://github.com/Nishikata97/RI-GNN. ). © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130255483&doi=10.1007%2f978-3-031-05981-0_24&partnerID=40&md5=7fee9d145efe34e3c374b44a3b09582e,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Xia L.; Huang C.; Xu Y.; Xu H.; Li X.; Zhang W.,Collaborative Reflection-Augmented Autoencoder Network for Recommender Systems,"As the deep learning techniques have expanded to real-world recommendation tasks, many deep neural network based Collaborative Filtering (CF) models have been developed to project user-item interactions into latent feature space, based on various neural architectures, such as multi-layer perceptron, autoencoder, and graph neural networks. However, the majority of existing collaborative filtering systems are not well designed to handle missing data. Particularly, in order to inject the negative signals in the training phase, these solutions largely rely on negative sampling from unobserved user-item interactions and simply treating them as negative instances, which brings the recommendation performance degradation. To address the issues, we develop a Collaborative Reflection-Augmented Autoencoder Network (CRANet), that is capable of exploring transferable knowledge from observed and unobserved user-item interactions. The network architecture of CRANet is formed of an integrative structure with a reflective receptor network and an information fusion autoencoder module, which endows our recommendation framework with the ability of encoding implicit user's pairwise preference on both interacted and non-interacted items. Additionally, a parametric regularization-based tied-weight scheme is designed to perform robust joint training of the two-stage CRANetmodel. We finally experimentally validate CRANeton four diverse benchmark datasets corresponding to two recommendation tasks, to show that debiasing the negative signals of user-item interactions improves the performance as compared to various state-of-The-Art recommendation techniques. Our source code is available at https://github.com/akaxlh/CRANet. © 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123927255&doi=10.1145%2f3467023&partnerID=40&md5=b592d04b1400a0bea9fa5109309a8dcf,ACM Transactions on Information Systems,Exclude,,Exclude,
Salha-Galvan G.; Hennequin R.; Chapus B.; Tran V.-A.; Vazirgiannis M.,Cold start similar artists ranking with gravity-inspired graph autoencoders,"On an artist's profile page, music streaming services frequently recommend a ranked list of ""similar artists""that fans also liked. However, implementing such a feature is challenging for new artists, for which usage data on the service (e.g. streams or likes) is not yet available. In this paper, we model this cold start similar artists ranking problem as a link prediction task in a directed and attributed graph, connecting artists to their top-k most similar neighbors and incorporating side musical information. Then, we leverage a graph autoencoder architecture to learn node embedding representations from this graph, and to automatically rank the top-k most similar neighbors of new artists using a gravity-inspired mechanism. We empirically show the flexibility and the effectiveness of our framework, by addressing a real-world cold start similar artists ranking problem on a global music streaming service. Along with this paper, we also publicly release our source code and the industrial data from our experiments.  © 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115607253&doi=10.1145%2f3460231.3474252&partnerID=40&md5=7ea7cf798d8eff87ff16065f165aac93,RecSys 2021 - 15th ACM Conference on Recommender Systems,Exclude,,Exclude,
Gharibshah Z.; Zhu X.,User Response Prediction in Online Advertising,"Online advertising, as a vast market, has gained significant attention in various platforms ranging from search engines, third-party websites, social media, and mobile apps. The prosperity of online campaigns is a challenge in online marketing and is usually evaluated by user response through different metrics, such as clicks on advertisement (ad) creatives, subscriptions to products, purchases of items, or explicit user feedback through online surveys. Recent years have witnessed a significant increase in the number of studies using computational approaches, including machine learning methods, for user response prediction. However, existing literature mainly focuses on algorithmic-driven designs to solve specific challenges, and no comprehensive review exists to answer many important questions. What are the parties involved in the online digital advertising eco-systems? What type of data are available for user response prediction? How do we predict user response in a reliable and/or transparent way? In this survey, we provide a comprehensive review of user response prediction in online advertising and related recommender applications. Our essential goal is to provide a thorough understanding of online advertising platforms, stakeholders, data availability, and typical ways of user response prediction. We propose a taxonomy to categorize state-of-The-Art user response prediction methods, primarily focusing on the current progress of machine learning methods used in different online platforms. In addition, we also review applications of user response prediction, benchmark datasets, and open source codes in the field. © 2021 ACM.",Review,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108122066&doi=10.1145%2f3446662&partnerID=40&md5=1385c3e33917d4f67e9e7bd1810d3396,ACM Computing Surveys,Exclude,,,
Wu L.; Chen L.; Shao P.; Hong R.; Wang X.; Wang M.,Learning fair representations for recommendation: A graph-based perspective,"As a key application of artificial intelligence, recommender systems are among the most pervasive computer aided systems to help users find potential items of interests. Recently, researchers paid considerable attention to fairness issues for artificial intelligence applications. Most of these approaches assumed independence of instances, and designed sophisticated models to eliminate the sensitive information to facilitate fairness. However, recommender systems differ greatly from these approaches as users and items naturally form a user-item bipartite graph, and are collaboratively correlated in the graph structure. In this paper, we propose a novel graph based technique for ensuring fairness of any recommendation models. Here, the fairness requirements refer to not exposing sensitive feature set in the user modeling process. Specifically, given the original embeddings from any recommendation models, we learn a composition of filters that transform each user's and each item's original embeddings into a filtered embedding space based on the sensitive feature set. For each user, this transformation is achieved under the adversarial learning of a user-centric graph, in order to obfuscate each sensitive feature between both the filtered user embedding and the sub graph structures of this user. Finally, extensive experimental results clearly show the effectiveness of our proposed model for fair recommendation. We publish the source code at https://github.com/newlei/FairGo.  Â© 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106588797&doi=10.1145%2f3442381.3450015&partnerID=40&md5=b7c97fa3ffc664efd7f71fd1997b80ce,"The Web Conference 2021 - Proceedings of the World Wide Web Conference, WWW 2021",Exclude,,,
Zhang H.; Liang L.; Wang D.,Object Interaction Recommendation with Multi-Modal Attention-based Hierarchical Graph Neural Network,"Object interaction recommendation from Internet of Things (IoT) is a crucial basis for IoT related applications. While many efforts are devoted to suggesting object for interaction, the majority of models rigidly infer relationships from human social network, overlook the neighbor information in their own object social network and the correlation of multiple heterogeneous features, and ignore multi-scale structure of the network. To tackle the above challenges, this work focuses on object social network, formulates object interaction recommendation as multi-modals object ranking, and proposes Multi-Modal Attention-based Hierarchical Graph Neural Network (MM-AHGNN), that describes object with multiple knowledge of actions and pairwise interaction feature, encodes heterogeneous actions with multi-modal encoder, integrates neighbor information and fuses correlative multi-modal feature by intra-modal hybrid-attention graph convolution and inter-modal transformer encoder, and employs multi-modal multi-scale encoder to integrate multi-level information, for suggesting object interaction more flexibly. With extensive experiments on real-world datasets, we prove that MMAHGNN achieves better recommendation results (improve 3-4% HR@3 and 4-5% NDCG@3) than the most advanced baseline. To our knowledge, our MM-AHGNN is the first research in GNN design for object interaction recommendation. Source codes are available at: https://github.com/gaosaroma/MM-AHGNN. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125328181&doi=10.1109%2fBigData52589.2021.9671426&partnerID=40&md5=e7a2557f46db999b0b122ce2984422d4,"Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",Exclude,,,
Xia L.; Huang C.; Xu Y.; Dai P.; Lu M.; Bo L.,Multi-behavior enhanced recommendation with cross-interaction collaborative relation modeling,"Many previous studies aim to augment collaborative filtering with deep neural network techniques, so as to achieve better recommendation performance. However, most existing deep learning-based recommender systems are designed for modeling singular type of user-item interaction behavior, which can hardly distill the heterogeneous relations between user and item. In practical recommendation scenarios, there exist multi-typed user behaviors, such as browse and purchase. Due to the overlook of user's multi-behavioral patterns over different items, existing recommendation methods are insufficient to capture heterogeneous collaborative signals from user multi-behavior data. Inspired by the strength of graph neural networks for structured data modeling, this work proposes a Graph Neural Multi-Behavior Enhanced Recommendation (GNMR) framework which explicitly models the dependencies between different types of user-item interactions under a graph-based message passing architecture. GNMR devises a relation aggregation network to model interaction heterogeneity, and recursively performs embedding propagation between neighboring nodes over the user-item interaction graph. Experiments on real-world recommendation datasets show that our GNMR consistently outperforms state-of-the-art methods. The source code is available at https://github.com/akaxlh/GNMR. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112867032&doi=10.1109%2fICDE51399.2021.00179&partnerID=40&md5=e92526a0c8a6633e386468966c41fc64,Proceedings - International Conference on Data Engineering,Exclude,,,
Ferguson M.; Devlin S.; Kudenko D.; Walker J.A.,Player Style Clustering without Game Variables,"Player clustering when applied to the field of video games has several potential applications. For example, the evaluation of the composition of a player base or the generation of AI agents with identified playing styles. These agents can then be used for either the testing of new game content or used directly to enhance a player's gaming experience. Most current player clustering techniques focus on the use of internal game variables. This raises two main issues: (1) the availability of game variables, as source code access is required to log them and hence limits the data sources that can be used, and (2) the choice of game variables can introduce unintended bias in the types of play style extracted. In this work, a hybrid unsupervised frame encoder and a 'reference-based' clustering algorithm are both proposed and combined to allow clustering from raw game play videos. It is shown that the proposed methods are most beneficial when the types of play styles are unknown. © 2020 Owner/Author.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092328198&doi=10.1145%2f3402942.3402960&partnerID=40&md5=51ef1476b739ff11c5e217b30c4494e7,ACM International Conference Proceeding Series,Exclude,,,
Huang R.; Han C.; Cui L.,Joint Graph Contextualized Network for Sequential Recommendation,"Sequential recommendation aims to suggest items to users based on sequential dependencies. Graph neural networks (GNNs) are recently proposed to capture transitions of items by treating session sequences as graph-structured data. However, existing graph construction approaches mainly focus on the directional dependency of items and ignore benefits of feature aggregation from undirectional relationship. In this paper, we innovatively propose a joint graph contextualized network (JGCN) for sequential recommendation, which constructs both the directed graphs and undirected graphs to jointly capture current interests and global preferences. Specifically, we introduce gate graph neural networks and model the combined embedding of weighted position and node information from directed graphs for capturing current interests. Besides, to learn global preferences, we propose a graph collaborative attention network with correlation-based similarity of items from undirected graphs. Finally, a feed-forward layer with the residual connection is applied to synthetically obtain accurate transitions of items. Extensive experiments conducted on three datasets show that JGCN outperforms state-of-the-art methods. © 2021, Springer Nature Switzerland AG.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115671790&doi=10.1007%2f978-3-030-86365-4_8&partnerID=40&md5=df6e4b4f3adc72e604711c2448329768,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,Exclude,
Dai S.; Yu Y.; Fan H.; Dong J.,Personalized POI Recommendation: Spatio-Temporal Representation Learning with Social Tie,"Recommending a limited number of Point-of-Interests (POIs) a user will visit next has become increasingly important to both users and POI holders for Location-Based Social Networks (LBSNs). However, POI recommendation is a challenging task since complex sequential patterns and rich contexts are contained in extremely sparse user check-in data. Recent studies show that embedding techniques effectively incorporate POI contextual information to alleviate the data sparsity issue, and Recurrent Neural Network (RNN) has been successfully employed for sequential prediction. Nevertheless, existing POI recommendation approaches are still limited in capturing user personalized preference due to separate embedding learning or network modeling. To this end, we propose a novel unified spatio-temporal neural network framework, named PPR, which leverages users’ check-in records and social ties to recommend personalized POIs for querying users by joint embedding and sequential modeling. Specifically, PPR first learns user and POI representations by joint modeling User-POI relation, sequential patterns, geographical influence, and social ties in a heterogeneous graph, and then models user personalized sequential patterns using the designed spatio-temporal neural network based on LSTM model for the personalized POI recommendation. Extensive experiments on three real-world datasets demonstrate that our model significantly outperforms state-of-the-art baselines for successive POI recommendation in terms of Accuracy, Precision, Recall and NDCG. The source code is available at: https://github.com/dsj96/PPR-master. © 2021, Springer Nature Switzerland AG.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104760809&doi=10.1007%2f978-3-030-73194-6_37&partnerID=40&md5=a17060388ae9a488a1b1cf7c215357b3,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Tang J.; Du X.; He X.; Yuan F.; Tian Q.; Chua T.-S.,Adversarial Training towards Robust Multimedia Recommender System,"With the prevalence of multimedia content on the Web, developing recommender solutions that can effectively leverage the rich signal in multimedia data is in urgent need. Owing to the success of deep neural networks in representation learning, recent advances on multimedia recommendation has largely focused on exploring deep learning methods to improve the recommendation accuracy. To date, however, there has been little effort to investigate the robustness of multimedia representation and its impact on the performance of multimedia recommendation. In this paper, we shed light on the robustness of multimedia recommender system. Using the state-of-the-art recommendation framework and deep image features, we demonstrate that the overall system is not robust, such that a small (but purposeful) perturbation on the input image will severely decrease the recommendation accuracy. This implies the possible weakness of multimedia recommender system in predicting user preference, and more importantly, the potential of improvement by enhancing its robustness. To this end, we propose a novel solution named Adversarial Multimedia Recommendation (AMR), which can lead to a more robust multimedia recommender model by using adversarial learning. The idea is to train the model to defend an adversary, which adds perturbations to the target image with the purpose of decreasing the model's accuracy. We conduct experiments on two representative multimedia recommendation tasks, namely, image recommendation and visually-aware product recommendation. Extensive results verify the positive effect of adversarial learning and demonstrate the effectiveness of our AMR method. Source codes are available in https://github.com/duxy-me/AMR. © 2020 IEEE.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082819347&doi=10.1109%2fTKDE.2019.2893638&partnerID=40&md5=0192161e51e4f307d17dc97cb7230c46,IEEE Transactions on Knowledge and Data Engineering,Exclude,,Exclude,
Huang C.; Xu H.; Xu Y.; Dai P.; Xia L.; Lu M.; Bo L.; Xing H.; Lai X.; Ye Y.,Knowledge-aware Coupled Graph Neural Network for Social Recommendation,"Social recommendation task aims to predict users’ preferences over items with the incorporation of social connections among users, so as to alleviate the sparse issue of collaborative filtering. While many recent efforts show the effectiveness of neural network-based social recommender systems, several important challenges have not been well addressed yet: (i) The majority of models only consider users’ social connections, while ignoring the inter-dependent knowledge across items; (ii) Most of existing solutions are designed for singular type of user-item interactions, making them infeasible to capture the interaction heterogeneity; (iii) The dynamic nature of user-item interactions has been less explored in many social-aware recommendation techniques. To tackle the above challenges, this work proposes a Knowledge-aware Coupled Graph Neural Network (KCGN) that jointly injects the inter-dependent knowledge across items and users into the recommendation framework. KCGN enables the high-order user- and item-wise relation encoding by exploiting the mutual information for global graph structure awareness. Additionally, we further augment KCGN with the capability of capturing dynamic multi-typed user-item interactive patterns. Experimental studies on real-world datasets show the effectiveness of our method against many strong baselines in a variety of settings. Source codes are available at: https://github.com/xhcdream/KCGN. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111671349&partnerID=40&md5=33f5d04e71852220974791ca305ddc0c,"35th AAAI Conference on Artificial Intelligence, AAAI 2021",Exclude,,Exclude,
Cafeo B.B.P.; Hunsen C.; Garcia A.; Apel S.; Lee J.,Segregating feature interfaces to support software product line maintenance,"Although software product lines are widely used in practice, their maintenance is challenging. Features as units of behaviour can be heavily scattered across the source code of a product line, hindering modular reasoning. To alleviate this problem, feature interfaces aim at enhancing modular reasoning about features. However, considering all members of a feature interface is often cumbersome, especially due to the large number of members arising in practice. To address this problem, we present an approach to group members of a feature interface based on their mutual dependencies. We argue that often only a subset of all interface members is relevant to a maintenance task. Therefore, we propose a graph representation that is able to capture the collaboration between members and apply a clustering algorithm to it to group highly-related members and segregate non-related members. On a set of ten versions of a real-world product line, we evaluate the effectiveness of our approach, by comparing the two types of feature interfaces (segregated vs. original interfaces) with co-change information from the version-control system. We found a potential reduction of 62% of the interface members to be considered during maintenance. © 2016 ACM.",Conference paper,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971290689&doi=10.1145%2f2889443.2889451&partnerID=40&md5=1cf13ed01d8251f3343e626ac429b69f,MODULARITY 2016 - Proceedings of the 15th International Conference on Modularity,Exclude,,,
Yerramreddy S.; Mordahl A.; Koc U.; Wei S.; Foster J.S.; Carpuat M.; Porter A.A.,An empirical assessment of machine learning approaches for triaging reports of static analysis tools,"Despite their ability to detect critical bugs in software, static analysis tools’ high false positive rates are a key barrier to their adoption in real-world settings. To improve the usability of these tools, researchers have recently begun to apply machine learning techniques to classify and filter incorrect analysis reports. Although initial results have been promising, the long-term potential and best practices for this line of research are unclear due to the lack of detailed, large-scale empirical evaluation. To partially address this knowledge gap, we present a comparative empirical study of three machine learning techniques—traditional models, recurrent neural networks (RNNs), and graph neural networks (GNNs)—for classifying correct and incorrect results in three static analysis tools—FindSecBugs, CBMC, and JBMC—using multiple datasets. These tools represent different techniques of static analysis, namely taint analysis and model-checking. We also introduce and evaluate new data preparation routines for RNNs and node representations for GNNs. We find that overall classification accuracy reaches a high of 80%–99% for different datasets and application scenarios. We observe that data preparation routines have a positive impact on classification accuracy, with an improvement of up to 5% for RNNs and 16% for GNNs. Overall, our results suggest that neural networks (RNNs or GNNs) that learn over a program’s source code outperform traditional models, although interesting tradeoffs are present among all techniques. Our observations provide insight into the future research needed to speed the adoption of machine learning approaches for static analysis tools in practice. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146111753&doi=10.1007%2fs10664-022-10253-z&partnerID=40&md5=aca50e2d5282663af0b1c5a20fba98c0,Empirical Software Engineering,Include,,,
Tommasel A.; Diaz-Pace J.A.,Identifying emerging smells in software designs based on predicting package dependencies,"Software systems naturally evolve, and this evolution often brings design problems that contribute to system degradation. Architectural smells are typical symptoms of such problems, and several of these smells are related to undesired dependencies among packages. The early detection of smells is essential for software engineers to plan ahead for maintenance or refactoring efforts. Although tools for identifying smells exist, they detect the smells once they already exist in the source code when their undesired dependencies are already created. In this work, we explore a forward-looking approach for identifying smells that can emerge in the next system version based on inferring package dependencies that are likely to appear in the system. Our approach takes the current design structure of the system as a network, along with information from previous versions, and applies link prediction techniques from the field of social network analysis. In particular, we consider a group of smells known as instability smells (cyclic dependency, hub-like dependency, and unstable dependency), which fit well with the link prediction model. The approach includes a feedback mechanism to progressively reduce false positives in predictions. An evaluation based on six open-source projects showed that, under certain considerations, the proposed approach can satisfactorily predict missing dependencies and smell configurations thereof. The feedback mechanism led to improvements of up to three times the initial precision values. Furthermore, we have developed a tool for practitioners to apply the approach in their projects. © 2022 Elsevier Ltd",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135130833&doi=10.1016%2fj.engappai.2022.105209&partnerID=40&md5=dfeac6767cd0654f1ee0925e2fe7c8ef,Engineering Applications of Artificial Intelligence,Include,,,
Li Y.,Improving Bug Detection and Fixing via Code Representation Learning,"The software quality and reliability have been proved to be important during the program development. There are many existing studies trying to help improve it on bug detection and automated program repair processes. However, each of them has its own limitation and the overall performance still have some improvement space. In this paper, we proposed a deep learning framework to improve the software quality and reliability on these two detectfix processes. We used advanced code modeling and AI models to have some improvements on the state-of-the-art approaches. The evaluation results show that our approach can have a relative improvement up to 206% in terms of F-1 score when comparing with baselines on bug detection and can have a relative improvement up to 19.8 times on the correct bug-fixing amount when comparing with baselines on automated program repair. These results can prove that our framework can have an outstanding performance on improving software quality and reliability in bug detection and automated program repair processes.  © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098558215&doi=10.1145%2f3377812.3382172&partnerID=40&md5=65b8a72829424d72c849d3f3da912067,"Proceedings - 2020 ACM/IEEE 42nd International Conference on Software Engineering: Companion, ICSE-Companion 2020",Include,,Include,
Brauckmann A.; Goens A.; Castrillon J.,ComPy-Learn: A toolbox for exploring machine learning representations for compilers,"Deep Learning methods have not only shown to improve software performance in compiler heuristics, but also e.g. to improve security in vulnerability prediction or to boost developer productivity in software engineering tools. A key to the success of such methods across these use cases is the expressiveness of the representation used to abstract from the program code. Recent work has shown that different such representations have unique advantages in terms of performance. However, determining the best-performing one for a given task is often not obvious and requires empirical evaluation. Therefore, we present ComPy-Learn, a toolbox for conveniently defining, extracting, and exploring representations of program code. With syntax-level language information from the Clang compiler frontend and low-level information from the LLVM compiler backend, the tool supports the construction of linear and graph representations and enables an efficient search for the best-performing representation and model for tasks on program code.  © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096107918&doi=10.1109%2fFDL50818.2020.9232946&partnerID=40&md5=e835ad547e9cf1fd235357bd6cf867fc,Forum on Specification and Design Languages,Include,,,
Li Y.,Improving bug detection and fixing via code representation learning,"The software quality and reliability have been proved to be important during the program development. There are many existingstudies trying to help improve it on bug detection and automatedprogram repair processes. However, each of them has its own limitation and the overall performance still have some improvementspace. In this paper, we proposed a deep learning framework toimprove the software quality and reliability on these two detectfix processes. We used advanced code modeling and AI models tohave some improvements on the state-of-the-art approaches. Theevaluation results show that our approach can have a relative improvement up to 206% in terms of F-1 score when comparing withbaselines on bug detection and can have a relative improvementup to 19.8 times on the correct bug-fixing amount when comparing with baselines on automated program repair. These results canprove that our framework can have an outstanding performanceon improving software quality and reliability in bug detection andautomated program repair processes. © 2020 Copyright held by the owner/author(s).",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094145554&doi=10.1145%2f3377812.3382172&partnerID=40&md5=960c19729b1b443829d9315daf1b75eb,Proceedings - International Conference on Software Engineering,Duplicate,,,
Lin G.; Zhang J.; Luo W.; Pan L.; Xiang Y.; De Vel O.; Montague P.,Cross-Project Transfer Representation Learning for Vulnerable Function Discovery,"Machine learning is now widely used to detect security vulnerabilities in the software, even before the software is released. But its potential is often severely compromised at the early stage of a software project when we face a shortage of high-quality training data and have to rely on overly generic hand-crafted features. This paper addresses this cold-start problem of machine learning, by learning rich features that generalize across similar projects. To reach an optimal balance between feature-richness and generalizability, we devise a data-driven method including the following innovative ideas. First, the code semantics are revealed through serialized abstract syntax trees (ASTs), with tokens encoded by Continuous Bag-of-Words neural embeddings. Next, the serialized ASTs are fed to a sequential deep learning classifier (Bi-LSTM) to obtain a representation indicative of software vulnerability. Finally, the neural representation obtained from existing software projects is then transferred to the new project to enable early vulnerability detection even with a small set of training labels. To validate this vulnerability detection approach, we manually labeled 457 vulnerable functions and collected 30 000+ nonvulnerable functions from six open-source projects. The empirical results confirmed that the trained model is capable of generating representations that are indicative of program vulnerability and is adaptable across multiple projects. Compared with the traditional code metrics, our transfer-learned representations are more effective for predicting vulnerable functions, both within a project and across multiple projects. © 2005-2012 IEEE.",Article,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044759580&doi=10.1109%2fTII.2018.2821768&partnerID=40&md5=7b39cae920b250cce5566de38edd8f68,IEEE Transactions on Industrial Informatics,Include,,,
Koc U.; Wei S.; Foster J.S.; Carpuat M.; Porter A.A.,An empirical assessment of machine learning approaches for triaging reports of a Java static analysis tool,"Despite their ability to detect critical bugs in software, developers consider high false positive rates to be a key barrier to using static analysis tools in practice. To improve the usability of these tools, researchers have recently begun to apply machine learning techniques to classify and filter false positive analysis reports. Although initial results have been promising, the long-term potential and best practices for this line of research are unclear due to the lack of detailed, large-scale empirical evaluation. To partially address this knowledge gap, we present a comparative empirical study of four machine learning techniques, namely hand-engineered features, bag of words, recurrent neural networks, and graph neural networks, for classifying false positives, using multiple ground-truth program sets. We also introduce and evaluate new data preparation routines for recurrent neural networks and node representations for graph neural networks, and show that these routines can have a substantial positive impact on classification accuracy. Overall, our results suggest that recurrent neural networks (which learn over a program's source code) outperform the other subject techniques, although interesting tradeoffs are present among all techniques. Our observations provide insight into the future research needed to speed the adoption of machine learning approaches in practice. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067964497&doi=10.1109%2fICST.2019.00036&partnerID=40&md5=4a03f036f9e8002482aee7dfc82d5482,"Proceedings - 2019 IEEE 12th International Conference on Software Testing, Verification and Validation, ICST 2019",Include,,,
Li Y.; Wang S.; Nguyen T.N.; Van Nguyen S.,Improving bug detection via context-based code representation learning and attention-based neural networks,"Bug detection has been shown to be an effective way to help developers in detecting bugs early, thus, saving much effort and time in software development process. Recently, deep learning-based bug detection approaches have gained successes over the traditional machine learning-based approaches, the rule-based program analysis approaches, and mining-based approaches. However, they are still limited in detecting bugs that involve multiple methods and suffer high rate of false positives. In this paper, we propose a combination approach with the use of contexts and attention neural network to overcome those limitations. We propose to use as the global context the Program Dependence Graph (PDG) and Data Flow Graph (DFG) to connect the method under investigation with the other relevant methods that might contribute to the buggy code. The global context is complemented by the local context extracted from the path on the AST built from the method's body. The use of PDG and DFG enables our model to reduce the false positive rate, while to complement for the potential reduction in recall, we make use of the attention neural network mechanism to put more weights on the buggy paths in the source code. That is, the paths that are similar to the buggy paths will be ranked higher, thus, improving the recall of our model. We have conducted several experiments to evaluate our approach on a very large dataset with +4.973M methods in 92 different project versions. The results show that our tool can have a relative improvement up to 160% on F-score when comparing with the state-of-the-art bug detection approaches. Our tool can detect 48 true bugs in the list of top 100 reported bugs, which is 24 more true bugs when comparing with the baseline approaches. We also reported that our representation is better suitable for bug detection and relatively improves over the other representations up to 206% in accuracy. © 2019 Association for Computing Machinery. All rights reserved.",Article,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120130347&doi=10.1145%2f3360588&partnerID=40&md5=c59c9874585380c66a93a3079e51cc7d,Proceedings of the ACM on Programming Languages,Include,,,
Diaz-Pace J.A.; Tommasel A.; Godoy D.,Towards anticipation of architectural smells using link prediction techniques,"Software systems naturally evolve, and this evolution often brings design problems that cause system degradation. Architectural smells are typical symptoms of such problems, and several of these smells are related to undesired dependencies among modules. The early detection of these smells is important for developers, because they can plan ahead for maintenance or refactoring efforts, thus preventing system degradation. Existing tools for identifying architectural smells can detect the smells once they exist in the source code. This means that their undesired dependencies are already created. In this work, we explore a forward-looking approach that is able to infer groups of likely module dependencies that can anticipate architectural smells in a future system version. Our approach considers the current module structure as a network, along with information from previous versions, and applies link prediction techniques (from the field of social network analysis). In particular, we focus on dependency-related smells, such as Cyclic Dependency and Hub-like Dependency, which fit well with the link prediction model. An initial evaluation with two open-source projects shows that, under certain considerations, the predictions of our approach are satisfactory. Furthermore, the approach can be extended to other types of dependency-based smells or metrics. © 2018 IEEE.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058275146&doi=10.1109%2fSCAM.2018.00015&partnerID=40&md5=735f0c987e0c433b10f67a72f9f2a97b,"Proceedings - 18th IEEE International Working Conference on Source Code Analysis and Manipulation, SCAM 2018",Include,,Include,
Hadj-Kacem M.; Bouassida N.,Deep Representation Learning for Code Smells Detection using Variational Auto-Encoder,"Detecting code smells is an important research problem in the software maintenance. It assists the subsequent steps of the refactoring process so as to improve the quality of the software system. However, most of existing approaches have been limited to the use of structural information. There have been few researches to detect code smells using semantic information although its proven effectiveness in many software engineering problems. In addition, they do not capture entirely the semantic embedded in the source code. This paper attempts to fill this gap by proposing a semantic-based approach that detects bad smells which are scattered at different levels of granularity in the source code. To this end, we use an Abstract Syntax Tree with a Variational Auto-Encoder in the detection of three code smells. The code smells are Blob, Feature Envy and Long Method. We have performed our experimental evaluation on nine open-source projects and the results have achieved a considerable overall accuracy. To further evaluate the performance of our approach, we compare our results with a state-of-the-art method on the same publicly available dataset. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073195905&doi=10.1109%2fIJCNN.2019.8851854&partnerID=40&md5=2eaf6624f11a6ef208211dabcb36df5f,Proceedings of the International Joint Conference on Neural Networks,Include,,,
Wu B.; Liu S.; Xiao Y.; Li Z.; Sun J.; Lin S.-W.,Learning Program Semantics for Vulnerability Detection via Vulnerability-Specific Inter-procedural Slicing,"Learning-based approaches that learn code representations for software vulnerability detection have been proven to produce inspiring results. However, they still fail to capture complete and precise vulnerability semantics for code representations. To address the limitations, in this work, we propose a learning-based approach namely SnapVuln, which first utilizes multiple vulnerability-specific inter-procedural slicing algorithms to capture vulnerability semantics of various types and then employs a Gated Graph Neural Network (GGNN) with an attention mechanism to learn vulnerability semantics. We compare SnapVuln with state-of-the-art learning-based approaches on two public datasets, and confirm that SnapVuln outperforms them. We further perform an ablation study and demonstrate that the completeness and precision of vulnerability semantics captured by SnapVuln contribute to the performance improvement. © 2023 Owner/Author.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180555589&doi=10.1145%2f3611643.3616351&partnerID=40&md5=692aaffa5f587038352bbcc822a1a86b,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,Include,,Include,
Zhang C.; Xin Y.,VulGAI: vulnerability detection based on graphs and images,"Deep learning models have been widely used in the field of vulnerability detection. Deep learning-based vulnerability detection methods can automatically learn code patterns. Some methods consider processing codes as text sequences to achieve scalable vulnerability detection. They leverage natural language processing models to extract code features. These methods do not consider the code's semantic structure and treat code slices as text. Vulnerability detection methods based on graph structures and graph neural networks are more accurate than text-based methods. However, these methods lack scalability in practice. Both graph generation and graph neural network training are all time-consuming. We propose a vulnerability detection method based on graphs and images (VulGAI). VulGAI choose the more reasonable node centrality to generate the image. It can preserve program details and distinguish node importance from different perspectives. In addition, we design a more efficient CNN model, which reduces computational overhead and improves detection performance (Time and Accuracy). We implement VulGAI and evaluate six methods (VulDePecker, SySeVR, Devign, VulCNN, mVulPreter, and VulGAI) on 40,657 functions. Experimental results show that VulGAI achieves higher Accuracy, TPR, and F1-Score than the others. In addition, we compare VulGAI and VulCNN on 30270 real-world functions. VulGAI outperforms VulCNN by 1.48 times in the number of TP. VulGAI is about 3.9 times faster than VulCNN in detection time. © 2023 Elsevier Ltd",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173161023&doi=10.1016%2fj.cose.2023.103501&partnerID=40&md5=9e57107e2986651d8ddcf8caabc908fc,Computers and Security,Include,,Include,
Hao J.; Luo S.; Pan L.,A novel vulnerability severity assessment method for source code based on a graph neural network,"Context: Vulnerability severity assessment is an important part of vulnerability management that can help security personnel determine the priority of vulnerability repair work. Objective: Aiming at the problems of low evaluation efficiency and poor timeliness in the existing method, a vulnerability severity evaluation method combining a function call graph and vulnerability attribute graph is proposed. Method: This method constructs a function call graph centered on vulnerable functions and uses the call relationship between vulnerable functions and sensitive API functions to reflect the severity of the damage of the vulnerable functions. The graph attention neural network algorithm is used to mine the key vulnerability characteristics in the function call graph and the vulnerability attribute graph to realize the assessment of vulnerability severity. Results: The ablation experiment results showed that the combined vulnerability attribute graph and function call graph had higher evaluation accuracy than the vulnerability attribute graph or function call graph alone, which increased by 6.85% and 32.90%, respectively. Compared with other existing methods, our method has achieved a better evaluation effect, and the evaluation accuracy has increased by 10%. Conclusion: The vulnerability severity assessment method incorporating function call graphs and vulnerability property graphs demonstrates an enhancement in the ability to represent the severity of vulnerabilities and increases the efficiency of vulnerability severity evaluation through elimination of the requirement for manual analysis. © 2023",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159789401&doi=10.1016%2fj.infsof.2023.107247&partnerID=40&md5=595dd25f95f5a584f70f056f531a35a0,Information and Software Technology,Include,,,
Tang G.; Yang L.; Zhang L.; Cao W.; Meng L.; He H.; Kuang H.; Yang F.; Wang H.,An attention-based automatic vulnerability detection approach with GGNN,"Vulnerability detection has long been an important issue in software security. The existing methods mainly define the rules and features of vulnerabilities through experts, which are time-consuming and laborious, and usually with poor accuracy. Thus automatic vulnerability detection methods based on code representation graph and Graph Neural Network (GNN) have been proposed with the advantage of effectively capture both the semantics and structure information of the source code, showing a better performance. However, these methods ignore the redundant information in the graph and the GNN model, leading to a still unsatisfactory performance. To alleviate this problem, we propose a attention-based automatic vulnerability detection approach with Gated Graph Sequence Neural Network (GGNN). Firstly, we introduce two preprocessing methods namely pruning and symbolization representation to reduce the redundant information of the input code representation graph, and then put the graph into the GGNN layer to update the node features. Next, the key subgraph extraction and global feature aggregation are realized through the attention-based Pooling layers. Finally, the classification result is obtained through a linear classifier. The experimental results show the effectiveness of our proposed preprocessing methods and attention-based Pooling layers, especially the higher Accuracy and F1-score gains compared with the state-of-the-art automatic vulnerability detection approaches. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152895909&doi=10.1007%2fs13042-023-01824-7&partnerID=40&md5=addd333bf03eebcb80f6b62c16ad9400,International Journal of Machine Learning and Cybernetics,Include,,Include,
Qian J.; Ju X.; Chen X.,GNet4FL: effective fault localization via graph convolutional neural network,"Fault localization aims to efficiently locate faults when debugging programs, reducing software development and maintenance costs. Spectrum-based fault location (SBFL) is the most commonly used fault location technology, which calculates and ranks the suspicious value of each program entity with a specific formula by counting the coverage information of all the program entities and execution results of test cases. However, previous SBFL techniques suffered from low accuracy due to the sole use of execution coverage. This paper proposed an approach GNet4FL based on the graph convolutional neural network. GNet4FL first collects static features based on code structure and dynamic features based on test results. Then, GNet4FL uses GraphSAGE to obtain node representation of source codes and performs feature fusion on an entity consisting of multiple nodes, which preserves the topological information of the graph. Finally, the representation of each entity is input to the multi-layer perceptron for training and ranking entities. The results of the study showed that GNet4FL successfully located 160 out of 262 faults, outperforming the three state-of-the-art methods by 94, 42, and 14% in Top-1 accuracy, and having close results to Grace with less cost. Furthermore, we investigated the impact of each component (i.e., graph neural network, pruning, and dynamic features) of GNet4FL on the results. We found that all of these components had a positive impact on the proposed approach. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154028757&doi=10.1007%2fs10515-023-00383-z&partnerID=40&md5=ef68872cbc4291cbb11fb474154c4d03,Automated Software Engineering,Include,,,
Chen Y.; Ding Z.; Alowain L.; Chen X.; Wagner D.,DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection,"We propose and release a new vulnerable source code dataset. We curate the dataset by crawling security issue websites, extracting vulnerability-fixing commits and source codes from the corresponding projects. Our new dataset contains 18,945 vulnerable functions spanning 150 CWEs and 330,492 non-vulnerable functions extracted from 7,514 commits. Our dataset covers 295 more projects than all previous datasets combined. Combining our new dataset with previous datasets, we present an analysis of the challenges and promising research directions of using deep learning for detecting software vulnerabilities.We study 11 model architectures belonging to 4 families. Our results showthat deep learning is still not ready for vulnerability detection, due to high false positive rate, low F1 score, and difficulty of detecting hard CWEs. In particular, we demonstrate an important generalization challenge for the deployment of deep learning-based models. We show that increasing the volume of training data may not further improve the performance of deep learning models for vulnerability detection, but might be useful to improve the generalization ability to unseen projects. We also identify hopeful future research directions. We demonstrate that large language models (LLMs) are a promising research direction for ML-based vulnerability detection, outperforming Graph Neural Networks (GNNs) with code-structure features in our experiments. Moreover, developing source code specific pre-training objectives is a promising research direction to improve the vulnerability detection performance. © 2023 Copyright held by the owner/author(s).",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175703612&doi=10.1145%2f3607199.3607242&partnerID=40&md5=cd4c26a57ee14789f230355ab2baeeb2,ACM International Conference Proceeding Series,Include,,,
Zhang C.; Yu T.; Liu B.; Xin Y.,Vulnerability detection based on federated learning,"Context: Detecting potential vulnerabilities is a key step in defending against network attacks. However, manual detection is time-consuming and requires expertise. Therefore, vulnerability detection must require automated techniques. Objective: Vulnerability detection methods based on deep learning need to rely on sufficient vulnerable code samples. However, the problem of code islands has not been extensively researched. For example, in the case of multi-party vulnerability data, how to securely combine multi-party data to improve vulnerability detection performance. From the perspectives of data augmentation and data security, we propose a vulnerability detection framework based on federated learning (VDBFL). VDBFL is a new model for vulnerability code detection that combines multi-party data. Method: Firstly, VDBFL utilizes the code property graph as a code representation. The code property graph contains various semantic dependencies of the code. Secondly, VDBFL utilizes graph neural networks and convolutional neural networks as the code feature extractor. VDBFL utilizes the jump-structured graph attention network to aggregate node information of important neighbors. Finally, VDBFL utilizes horizontal federated learning to train a local vulnerability detection model for the client. Result: In the real world, VDBFL improves F1-Score by 37.4% compared to the vulnerability detection method Reveal. Among the 5401 vulnerability samples, VDBFL detected 11.8 times more vulnerabilities than Reveal. Conclusion: Under different datasets, VDBFL has shown better performance than advanced vulnerability detection methods in multiple metrics. In addition, the federated learning stage of VDBFL can be expanded on top of the feature extraction stage of any vulnerable detection method. © 2023",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178012067&doi=10.1016%2fj.infsof.2023.107371&partnerID=40&md5=a4a4d156a7de399955acc40c2eb449b6,Information and Software Technology,Include,,,
Tang M.; Tang W.; Gui Q.; Hu J.; Zhao M.,A vulnerability detection algorithm based on residual graph attention networks for source code imbalance (RGAN),"It is essential to detect potential vulnerabilities in software to ensure its safety. As software systems become more complex, traditional static vulnerability detection methods perform poorly. Currently, deep learning-based vulnerability detection models only extract source code vulnerability features using sequences or graphs. Sequential neural networks ignore structural information in the code, such as control flow diagrams and data flow diagrams. Additionally, graph neural networks cannot accurately extract features due to the lack of effective methods for extracting nodes’ features and aggregating global information. To address the above issue, we propose a vulnerability detection algorithm based on residual graph attention networks for source code imbalance (RGAN). Firstly, a local feature extraction module (PE-BL-A module) is designed. Using the sequence neural network, the module extracts various useful features, including node features in a control flow diagram based on local semantic features. Secondly, we present the Residual Graph Attention Network module (RGAT). To learn and update node features along the control flow direction, the module uses a graph attention network with residual connections. In this module, a mean biaffine attention pooling mechanism is proposed that can extract total graph vulnerability features more effectively. Thirdly, a dynamic cross-entropy loss function is designed. Using this function, it can handle sample imbalances during training. Finally, experiments conducted on several benchmark datasets demonstrate that the proposed model achieves state-of-the-art results. © 2023",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174739465&doi=10.1016%2fj.eswa.2023.122216&partnerID=40&md5=94e2526ac216a9a47dc35d30db8111a8,Expert Systems with Applications,Include,,Include,
Tao W.; Su X.; Wan J.; Wei H.; Zheng W.,Vulnerability detection through cross-modal feature enhancement and fusion,"Software vulnerability detection is critical to computer security. Most existing vulnerability detection methods use single modal-based vulnerability detection models, which cannot effectively extract cross-modal features. To solve this problem, we propose a new multimodal deep learning based vulnerability detection method through a cross-modal feature enhancement and fusion. Firstly, we utilize a special compilation and debugging method to obtain the alignment relationship between source code statements and assembly instructions, as well as between source code variables and assembly code registers. Based on this alignment relationship and program slicing technology, we propose a cross-slicing method to generate bimodal program slices. Then, we propose a cross-modal feature enhanced code representation learning model to capture the fine-grained semantic correlation between source code and assembly code by using the co-attention mechanisms. Finally, vulnerability detection is achieved by feature level fusion of semantic features captured in fine-grained aligned source code and assembly code. Extensive experiments show that our method improves the performance of vulnerability detection compared with state-of-the-art methods. Specifically, our method achieves an accuracy of 97.4% and an F1-measure of 93.4% on the SARD dataset. An average accuracy of 95.4% and an F1-measure of 89.1% on two real-world software projects (i.e., FFmpeg and OpenSSL) is also achieved by our method, improving over SOTA method 4.5% and 2.9%. © 2023 Elsevier Ltd",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164226069&doi=10.1016%2fj.cose.2023.103341&partnerID=40&md5=ca46f4fe4e03e4bca2666a232984994d,Computers and Security,Include,,Include,
Fan Y.; Wan C.; Fu C.; Han L.; Xu H.,VDoTR: Vulnerability detection based on tensor representation of comprehensive code graphs,"Code vulnerability detection has long been a critical issue due to its potential threat to computer systems. It is imperative to detect source code vulnerabilities in software and remediate them to avoid cyber attacks. To automate detection and reduce labor costs, many deep learning-based methods have been proposed. However, these approaches have been found to be either ineffective in detecting multiple classes of vulnerabilities or limited by treating original source code as a natural language sequence without exploiting the structural information of code. In this paper, we propose VDoTR, a model that leverages a new tensor representation of comprehensive code graphs, including AST, CFG, DFG, and NCS, to detect multiple types of vulnerabilities. Firstly, a tensor structure is introduced to represent the structured information of code, which deeply captures code features. Secondly, a new Circle Gated Graph Neural Network (CircleGGNN) is designed based on tensor for hidden state embedding of nodes. CircleGGNN can perform heterogeneous graph information fusion more directly and effectively. Lastly, a 1-D convolution-based output layer is applied to hidden embedding features for classification. The experimental results demonstrate that the detection performance of VDoTR is superior to other approaches with higher accuracy, precision, recall, and F1-measure on multiple datasets for vulnerability detection. Moreover, we illustrate which code graph contributes the most to the performance of VDoTR and which code graph is more sensitive to represent vulnerability features for different types of vulnerabilities through ablation experiments. © 2023",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152599286&doi=10.1016%2fj.cose.2023.103247&partnerID=40&md5=b08c018dcb6c1cbaa89c8808b2af2a6c,Computers and Security,Include,,Include,
Sachdeva A.; Lazarine B.; Zhu H.; Samtani S.,User Profiling and Vulnerability Introduction Prediction in Social Coding Repositories: A Dynamic Graph Embedding Approach: Vulnerability Introduction Prediction in Social Coding Repositories,"Social Coding Repositories (SCRs) such as GitHub host open-source code that is significant to the global economy. However, open-source code is especially vulnerable, with most vulnerabilities being introduced due to human error. An important mitigation strategy is preventing the introduction of vulnerabilities. One of the ways this can be achieved is through targeted developer security training, which necessitates the identification of high-risk actors and predicting the introduction of vulnerabilities. In this study, we propose a novel framework for predicting the introduction of vulnerabilities in SCRs by users, with a novel dynamic graph representation learning model, security continuous propagation, and evolution (seCoPE). The proposed seCoPE framework addresses the limitations of existing methods by incorporating the relative influence of nodes on the propagation of information to generate high-quality nodal embeddings. We systematically evaluate seCoPE against prevailing Recurrent Neural Network (RNN) based and Attention-based models on a vulnerability introduction dataset. The proposed framework has important implications for cybersecurity providers, firms, and software developers.  © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171448656&doi=10.1145%2f3607505.3607512&partnerID=40&md5=5e5eed1da91608cfff8e39fbf2bbaef2,ACM International Conference Proceeding Series,Include,,,
Wang S.; Huang C.; Yu D.; Chen X.,VulGraB: Graph-embedding-based code vulnerability detection with bi-directional gated graph neural network,"Code vulnerabilities can have serious consequences such as system attacks and data leakage, making it crucial to perform code vulnerability detection during the software development phase. Deep learning is an emerging approach for vulnerability detection tasks. Existing deep learning-based code vulnerability detection methods are usually based on word2vec embedding of linear sequences of source code, followed by code vulnerability detection through RNNs network. However, such methods can only capture the superficial structural or syntactic information of the source code text, which is not suitable for modeling the complex control flow and data flow and miss edge information in the graph structure constructed by the source code, with limited effect of neural network model. To solve the above problems, this article proposes a code vulnerability detection method, named VulGraB, which is based on graph embedding and bidirectional gated graph neural networks. VulGraB uses node2vec to convert the program-dependent graphs into graph embeddings of the code, which contain rich structure information of the source code, improving the ability of features to express nonlinear information to a certain extent. Then the BiGGNN is used for training, and finally the accuracy of the detection results is evaluated using target program. The bi-directional gated neural network utilizes a bi-directional recurrent structure, which is beneficial to global information aggregation. The experimental results show that the accuracy of VulGraB is significantly improved over the baseline models on two datasets, with F1 scores of 85.89% and 97.24% being the highest, demonstrating that VulGraB consistently outperforms other effective vulnerability detection models. © 2023 John Wiley & Sons Ltd.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152473653&doi=10.1002%2fspe.3205&partnerID=40&md5=d2796319b2e3f7249116999d618965af,Software - Practice and Experience,Include,,,
Yang Y.; Bo X.; Wang Z.; Shao X.; Xie X.,Graph representation learning and software homology matching based A study of JAVA code vulnerability detection techniques,"In nowadays using different tools and apps is a basic need of people's behavior in life, but the security issues arising from the existence of source code plagiarism among tools and apps are likely to bring huge losses to companies and even countries, so detecting the existence of vulnerabilities or malicious code in software becomes an important part of protecting information and detecting software security. This project is based on the aspect of JAVA code vulnerability detection based on graph representation learning and software homology comparison to carry out research. This project will be based on the content of deep learning, using a large number of vulnerable source code, extracting its features, and transforming it into a graph so that it can be tested source code for comparison and report the vulnerability content. The main work and results of this project are as follows: 1.By extracting the example dataset and generating json files to save the feature information of relevant java code; by generating vector files, bytecode files and dot files, and batch extracting nodes and edges based on the contents of the dot files for subsequent machine learning use, the before and after steps and operations form a logical self-consistency to ensure the integrity of the project. 2.Through the study of graph neural networks and graph convolutional neural networks, relevant models are selected for machine learning using predecessor files and manual model tuning is performed to ensure good learning results and feedback for the machine learning part of the project. 3.This project training dataset negative samples for sard above the shared dataset, which contains 46636 java vulnerability source code, and dataset support environment, test dataset negative samples dataset also from sard, positive samples dataset are generated from the relevant person in charge. 4.Based on Graph Neural Network (GNN) and Graph Convolutional Neural Network (GCN), this project will design and implement a whole set of automated vulnerability detection system for java code. 5. All the related contents of this project, after the human extensive search of domestic and foreign related papers and materials, there are not all projects or contents similar to this project, the same papers and materials appear, all the problems involved in this project and related ideas are for the project this group of people thinking, looking for solutions.  © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162926361&doi=10.1145%2f3590003.3590028&partnerID=40&md5=fe0ccfba626f94562c12fb8a65ecc1ad,ACM International Conference Proceeding Series,Include,,,
Şahin C.B.,Semantic-based vulnerability detection by functional connectivity of gated graph sequence neural networks,"In computer security, semantic learning is helpful in understanding vulnerability requirements, realizing source code semantics, and constructing vulnerability knowledge. Nevertheless, learning how to extract and select the most valuable features for software vulnerability detection remains difficult. In this paper, we first derive a subset of vulnerability knowledge representations from the Functional Connectivity (FC) of Graph Gated Sequence Neural Networks (GGNNs). The Gated Graph Sequence Neural Networks can be utilized to capture the long-term dependency to understand a high-level representation of potential vulnerabilities in order to detect vulnerabilities on a target project. Studying functional connectivity-based Graph Neural Networks ensures our deep understanding of the operation of sequence graph networks as highly complex interconnected systems. This ensures that the model focuses on vulnerability-related code, which makes it more appropriate for vulnerability mining tasks. Which constructs a composite semantic code property graph for code representation based on the causes of vulnerabilities. The experimental findings indicate that the suggested Model can select relevant discriminative features and achieve superior performance than benchmark methods. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145500304&doi=10.1007%2fs00500-022-07777-3&partnerID=40&md5=df0914786b4bd21b14ee00081fc4155e,Soft Computing,Include,,,
Wang M.; Tao C.; Guo H.,LCVD: Loop-oriented code vulnerability detection via graph neural network,"Due to the unique mechanism and complex structure, loops in programs can easily lead to various vulnerabilities such as dead loops, memory leaks, resource depletion, etc. Traditional approaches to loop-oriented program analysis (e.g. loop summarization) are costly with a high rate of false positives in complex software systems. To address the issues above, recent works have applied deep learning (DL) techniques to vulnerability detection. However, existing DL-based approaches mainly focused on the general characteristics of most vulnerabilities without considering the semantic information of specific vulnerabilities. As a typical structure in programs, loops are highly iterative with multi-paths. Currently, there is a lack of available approaches to represent loops, as well as useful methods to extract the implicit vulnerability patterns. Therefore, this paper introduces LCVD, an automated loop-oriented code vulnerability detection approach. LCVD represents the source code as the Loop-flow Abstract Syntax Tree (LFAST), which focuses on interleaving multi-paths around loop structures. Then a novel Loop-flow Graph Neural Network (LFGNN) is proposed to learn both the local and overall structure of loop-oriented vulnerabilities. The experimental results demonstrate that LCVD outperforms the three static analysis-based and four state-of-the-art DL-based vulnerability detection approaches across evaluation settings. © 2023 Elsevier Inc.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85157985357&doi=10.1016%2fj.jss.2023.111706&partnerID=40&md5=9d08c9e5a66deffd43cab0392ed9ed3c,Journal of Systems and Software,Include,,,
Tang W.; Tang M.; Ban M.; Zhao Z.; Feng M.,CSGVD: A deep learning approach combining sequence and graph embedding for source code vulnerability detection,"In order to secure software, it is critical to detect potential vulnerabilities. The performance of traditional static vulnerability detection methods is limited by predefined rules, which rely heavily on the expertise of developers. Existing deep learning-based vulnerability detection models usually use only a single sequence or graph embedding approach to extract vulnerability features. Sequence embedding-based models ignore the structured information inherent in the code, and graph embedding-based models lack effective node and graph embedding methods. As a result, we propose a novel deep learning-based approach, CSGVD (Combining Sequence and Graph embedding for Vulnerability Detection), which considers function-level vulnerability detection as a graph binary classification task. Firstly, we propose a PE-BL module, which inherits and enhances the knowledge from the pre-trained language model. It extracts the code's local semantic features as node embedding in the control flow graph by using sequence embedding. Secondly, CSGVD uses graph neural networks to extract the structured information of the graph. Finally, we propose a mean biaffine attention pooling, M-BFA, to better aggregate node information as a graph's feature representation. The experimental results show that CSGVD outperforms the existing state-of-the-art models and obtains 64.46% accuracy on the real-world benchmark dataset from CodeXGLUE for vulnerability detection. © 2023 Elsevier Inc.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147191808&doi=10.1016%2fj.jss.2023.111623&partnerID=40&md5=35cd17dd043c1d9487c1e1b02c7a2420,Journal of Systems and Software,Include,,Include,
Nguyen S.; Vu T.T.; Vo H.D.,VFFINDER: A Graph-Based Approach for Automated Silent Vulnerability-Fix Identification,"The increasing reliance of software projects on third-party libraries has raised concerns about the security of these libraries due to hidden vulnerabilities. Managing these vul-nerabilities is challenging due to the time gap between fixes and public disclosures. Moreover, a significant portion of open-source projects silently fix vulnerabilities without disclosure, impacting vulnerability management. Existing tools like OWASP heavily rely on public disclosures, hindering their effectiveness in detecting unknown vulnerabilities. To tackle this problem, automated identification of vulnerability-fixing commits has emerged. However, identifying silent vulnerability fixes remains challenging. This paper presents VFFINDER, a novel graph-based approach for automated silent vulnerability fix identification. VFFINDER captures structural changes using Abstract Syntax Trees (ASTs) and represents them in annotated ASTs. VFFINDER distinguishes vulnerability-fixing commits from non-fixing ones using attention-based graph neural network models to extract structural features. We conducted experiments to evaluate VFFINDER on a dataset of 36K+ fixing and non-fixing commits in 507 real-world C/C++ projects. Our results show that VFFINDER significantly improves the state-of-the-art methods by 39-83% in Precision, 19-148% in Recall, and 30%-109% in F1. Especially, VFFINDER speeds up the silent fix identification process by up to 47% with the same review effort of 5% compared to the existing approaches.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173098270&doi=10.1109%2fKSE59128.2023.10299438&partnerID=40&md5=32132664d3df53b29a7ef7891aaaeca6,"Proceedings - International Conference on Knowledge and Systems Engineering, KSE",Include,,,
Wen X.-C.; Wang X.; Gao C.; Wang S.; Liu Y.; Gu Z.,When Less is Enough: Positive and Unlabeled Learning Model for Vulnerability Detection,"Automated code vulnerability detection has gained increasing attention in recent years. The deep learning (DL)-based methods, which implicitly learn vulnerable code patterns, have proven effective in vulnerability detection. The performance of DL-based methods usually relies on the quantity and quality of labeled data. However, the current labeled data are generally automatically collected, such as crawled from human-generated commits, making it hard to ensure the quality of the labels. Prior studies have demonstrated that the non-vulnerable code (i.e., negative labels) tends to be unreliable in commonly-used datasets, while vulnerable code (i.e., positive labels) is more determined. Considering the large numbers of unlabeled data in practice, it is necessary and worth exploring to leverage the positive data and large numbers of unlabeled data for more accurate vulnerability detection. In this paper, we focus on the Positive and Unlabeled (PU) learning problem for vulnerability detection and propose a novel model named PILOT, i.e., Positive and unlabeled Learning mOdel for vulnerability deTection. PILOT only learns from positive and unlabeled data for vulnerability detection. It mainly contains two modules: (1) A distance-aware label selection module, aiming at generating pseudo-labels for selected unlabeled data, which involves the inter-class distance prototype and progressive fine-tuning; (2) A mixed-supervision representation learning module to further alleviate the influence of noise and enhance the discrimination of representations. Extensive experiments in vulnerability detection are conducted to evaluate the effectiveness of PILOT based on real-world vulnerability datasets. The experimental results show that PILOT outperforms the popular weakly supervised methods by 2.78%-18.93% in the PU learning setting. Compared with the state-of-the-art methods, PILOT also improves the performance of 1.34%-12.46 % in F1 score metrics in the supervised setting. In addition, PILOT can identify 23 mislabeled from the FFMPeg+Qemu dataset in the PU learning setting based on manual checking.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179004291&doi=10.1109%2fASE56229.2023.00144&partnerID=40&md5=014eb4c9c30ff19b855d8b63cbfe320b,"Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023",Include,,,
Yang J.; Ruan O.; Zhang J.,Tensor-based gated graph neural network for automatic vulnerability detection in source code,"The rapid expansion of smart devices leads to the increasing demand for vulnerability detection in the cyber security field. Writing secure source codes is crucial to protect applications and software. Recent vulnerability detection methods are mainly using machine learning and deep learning. However, there are still some challenges, how to learn accurate source code semantic embedding at the function level, how to effectively perform vulnerability detection using the learned semantic embedding of source code and how to solve the overfitting problem of learning-based models. In this paper, we consider codes as various graphs with node features and propose a tensor-based gated graph neural network called TensorGNN to produce code embedding for function-level vulnerability detection. First, we propose a high-dimensional tensor for combining different code graph representations. Second, inspired by the work of tensor technology, we propose the TensorGNN model to produce accurate code representations using the graph tensor. We evaluate our model on 7 C and C++ large open-source code corpus (e.g. SARD&NVD, Debian, SATE IV, FFmpeg, libpng&LibTiff, Wireshark and Github datasets), which contains 13 types of vulnerabilities. Our TensorGNN model improves on existing state-of-the-art works by 10%–30% on average in terms of vulnerability detection accuracy and F1, while our TensorGNN model needs less training time and model parameters. Specifically, compared with other existing works, our model reduces 25–47 times of the number of parameters and decreases 3–10 times of training time. Results of evaluations show that TensorGNN has better performance while using fewer training parameters and less training time. © 2023 John Wiley & Sons, Ltd.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177856805&doi=10.1002%2fstvr.1867&partnerID=40&md5=1a569590b2491578fb19b6dbb6a325d8,Software Testing Verification and Reliability,Include,,,
Cheng X.,Vulnerability Detection via Typestate-Guided Code Representation Learning,"Machine learning, including deep learning, has found success in various domains. Recently, the focus has shifted to using deep learning, like graph neural networks, for static vulnerability detection. Existing methods represent code as an embedding vector and train models on safe and vulnerable code patterns to predict vulnerabilities. However, these models lack precise bug detection, as they prioritize coarse-grained classification over understanding vulnerability semantics, such as typestate properties. This paper introduces an innovative typestate-guided code embedding technique for accurate static vulnerability detection. We select and retain feasible typestate sequences extracted from typestate analysis using self-supervised contrastive learning in a pretrained path embedding model. This reduces the need for labeled data in training downstream models for vulnerability detection. Evaluation on real-world projects showcases our approach’s superiority over recent learning-based approaches. It outperforms them by substantial margins across various metrics like precision, recall and F1 Score. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177163808&doi=10.1007%2f978-981-99-7584-6_22&partnerID=40&md5=d29b35db1d99029cafefb87159254b23,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,Include,
Li W.; Li X.; Feng W.; Jin G.; Liu Z.; Jia J.,Vulnerability Detection Based on Unified Code Property Graph,"As the number of source codes grows rapidly, detecting source code vulnerabilities in current software has become an important study. Most current deep learning-based vulnerability detection technologies treat source code as a sequence, which loses the source code’s structural information, leading to many false positives in the detection results. We propose a novel source code vulnerability detection model, named UCPGVul, based on the Unified Code Property Graph (UCPG). A new graph representation, UCPG, is proposed to extract semantic features from the source code. By extracting features from UCPG, our proposed UCPGVul model can capture more vulnerability features. Experimental results on a publicly available dataset show that UCPGVul can achieve more accurate and stable detection results compared to five state-of-the-art methods. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172249628&doi=10.1007%2f978-981-99-6222-8_30&partnerID=40&md5=33ae0e4b5456900bb0974d21eb318e95,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,,
Fernaldy K.; Wardhana Asnar Y.D.,Detecting Command Injection and Cross-site Scripting Vulnerabilities Using Graph Representations,"Web-based applications, such as JavaScript-based applications, have vastly grown in scope and features. As web-based applications grow, the potential of vulnerabilities emerging inside such applications also grows. One of the ways to detect vulnerabilities inside web-based applications is to perform a static code analysis. Several static code analysis tools have been developed and are able to detect vulnerabilities inside JavaScript-based applications. However, these tools use abstract syntax tree representations in their analysis, therefore the analysis can't be performed efficiently. This paper proposes a static code analysis to detect vulnerabilities inside JavaScript-based applications using data-flow graph, control-flow graph, and call graph representations. Using taint analysis, a static code analysis tool is able to detect vulnerabilities in the form of command injection, and cross-site scripting (XSS). Test results showed that the static code analysis tool successfully detected vulnerabilities from four open-source projects. copy; 2023 IEEE. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177458192&doi=10.1109%2fICoDSE59534.2023.10291446&partnerID=40&md5=4afb705b33b8eb7a88f648b664c5490e,"Proceedings of 2023 IEEE International Conference on Data and Software Engineering, ICoDSE 2023",Include,,Include,
Li X.; Xin Y.; Zhu H.; Yang Y.; Chen Y.,Cross-domain vulnerability detection using graph embedding and domain adaptation,"Vulnerability detection is an effective means to maintain cyberspace security. Machine learning methods have risen much attention in software security due to their advantage of accuracy and automation. However, current researches mainly focus on in-domain vulnerability detection where the training data and test data belong to the same domain. Due to application scenarios, coding habits, and other factors, vulnerabilities in different software projects may obey different probability distributions. This discrepancy compromises the performance of machine learning methods when they are applied to a brand-new project. To address this cold start problem, we propose a cross-domain vulnerability detection framework using graph embedding and deep domain adaption (VulGDA). It works in a variety of cross-domain fashions, including the Zero-Shot fashion that no labeled data in the target domain is available for training. VulGDA is decomposed to graph embedding and domain adaptation. At the graph embedding stage, we transform the samples in source code into graph representations where elements are directly concatenated according to their syntactic and semantic relationships. Then, we aggregate information from neighbors and edges defined in the graph into real-valued vectors. By graph embedding, VulGDA extracts comprehensive vulnerability features and compromises the challenge of long-term dependency. Aiming at the discrepancy between training data and test data, domain adaption is used to train a feature generator. This feature generator maps the graph embedding to a “deep” feature that is discriminative for vulnerability detection, and invariant to the shift between domains. We perform a systematic experiment to validate the effectiveness of VulGDA. The results show that combining graph embedding and deep domain adaptation promotes VulGDA's performance in cross-domain vulnerability detection. Compared with the state-of-the-art methods, our method has better performance under the cold start condition. © 2022",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145617321&doi=10.1016%2fj.cose.2022.103017&partnerID=40&md5=15b2ba79fa4afd2aa82af96a915df12e,Computers and Security,Include,,,
Ni C.; Guo X.; Zhu Y.; Xu X.; Yang X.,Function-Level Vulnerability Detection Through Fusing Multi-Modal Knowledge,"Software vulnerabilities damage the functionality of software systems. Recently, many deep learning-based approaches have been proposed to detect vulnerabilities at the function level by using one or a few different modalities (e.g., text representation, graph-based representation) of the function and have achieved promising performance. However, some of these existing studies have not completely leveraged these diverse modalities, particularly the underutilized image modality, and the others using images to represent functions for vulnerability detection have not made adequate use of the significant graph structure underlying the images. In this paper, we propose MVulD, a multi-modal-based function-level vulnerability detection approach, which utilizes multi-modal features of the function (i.e., text representation, graph representation, and image representation) to detect vulnerabilities. Specifically, MVulD utilizes a pre-trained model (i.e., UniXcoder) to learn the semantic information of the textual source code, employs the graph neural network to distill graph-based representation, and makes use of computer vision techniques to obtain the image representation while retaining the graph structure of the function. We conducted a large-scale experiment on 25,816 functions. The experimental results show that MVulD improves four state-of-the-art baselines by 30.8%-81.3%, 12.8%-27.4%, 48.8%-115%, and 22.9%-141% in terms of F1-score, Accuracy, Precision, and PR-AUC respectively.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179002505&doi=10.1109%2fASE56229.2023.00084&partnerID=40&md5=c4ca6b4d197b1c4cef905dbb95bbf33d,"Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023",Include,,,
Mirsky Y.; MacOn G.; Brown M.; Yagemann C.; Pruett M.; Downing E.; Mertoguno S.; Lee W.,VulChecker: Graph-based Vulnerability Localization in Source Code,"In software development, it is critical to detect vulnerabilities in a project as early as possible. Although, deep learning has shown promise in this task, current state-of-the-art methods cannot classify and identify the line on which the vulnerability occurs. Instead, the developer is tasked with searching for an arbitrary bug in an entire function or even larger region of code. In this paper, we propose VulChecker: a tool that can precisely locate vulnerabilities in source code (down to the exact instruction) as well as classify their type (CWE). To accomplish this, we propose a new program representation, program slicing strategy, and the use of a message-passing graph neural network to utilize all of code's semantics and improve the reach between a vulnerability's root cause and manifestation points. We also propose a novel data augmentation strategy for cheaply creating strong datasets for vulnerability detection in the wild, using free synthetic samples available online.With this training strategy,VulCheckerwas able to identify 24 CVEs (10 from 2019&2020) in 19 projects taken from the wild, with nearly zero false positives compared to a commercial tool that could only detect 4. VulChecker also discovered an exploitable zero-day vulnerability, which has been reported to developers for responsible disclosure. © 2023 32nd USENIX Security Symposium, USENIX Security 2023. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172385383&partnerID=40&md5=b65bb84e01429db78bbf2ec291d6097f,"32nd USENIX Security Symposium, USENIX Security 2023",Include,,,
Xue J.; Yu Z.; Song Y.; Qin Z.; Sun X.; Wang W.,VulSAT: Source Code Vulnerability Detection Scheme Based on SAT Structure,"The number of software vulnerabilities have increased rapidly, and their forms have shown the characteristics of complexity and diversity, which has brought severe challenges to software systems. Deep learning can automatically learn the features of code and is widely used in source code vulnerability detection. Some studies treat codes as text sequences, ignoring the structural relationship between lines of code. Other studies extract the code as a graph structure, but ignore the order relationship of code lines and do not make full use of the dependencies between code lines. This paper proposes a C/C++ source code vulnerability detection scheme based on SAT (Structure-Aware Transformer) structure. It first standardizes the source code, then extracts the PDG (program dependency graph) representation of source code, next convert each node into a vector representation using sentence embedding, which retains the dependencies between nodes. Finally input it into the SAT architecture model for training, and judge whether the input program contains vulnerabilities according to the output results. We compared VulSAT with a variety of vulnerability detection methods (i.e., Devign, SySeVR, VulCNN, Checkmarx, VulDeePecker), and selected C/C++ functions in the SARD vulnerability dataset as experimental objects. The performance of accuracy rate and false positive rate has been improved to a certain extent.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174681667&doi=10.1109%2fICSIP57908.2023.10271020&partnerID=40&md5=6303903a0553b7309b1e4efac7d12f2d,"2023 8th International Conference on Signal and Image Processing, ICSIP 2023",Include,,,
Li Q.; Guo Z.; Li X.; Chen Q.; Zhou S.; Hu R.; Jiang Y.; Chen H.,Vulnerability Detection Based on Attention Mechanism and Deep Graph Convolutional Network,"To address the problem of incomplete graph structure features due to the lack of contextual information in existing graph neural network-based vulnerability mining methods and the problem of over-smoothing that prevents the model from learning higher-order features of the graph structure resulting in poor prediction performance, a vulnerability detection method based on deep graph convolutional networks and attention mechanism, PSG-GCNIIAT, is proposed. PSG fuses order relational graphs on the basis of program dependency graphs so that code statements have the ability to sense their contextual information, and generates embedding vectors of code lines by abstracting syntax trees to achieve deep structure feature extraction of graph nodes. GCNIIAT uses a deep graph convolutional network, GCNII, combined with a graph attention mechanism to more effectively identify graph structure features of program slices associated with vulnerabilities. The experimental results show that the vulnerability detection model GCNIIAT proposed in this paper has obvious advantages over Vuldeepecker, GCN and GGNN in accuracy and F1 value indicators, and can effectively improve the performance of program vulnerability detection. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175201336&doi=10.1109%2fSCSET58950.2023.00037&partnerID=40&md5=54036ac7d25a07f8ac86a89905b3af33,"Proceedings - 2023 International Seminar on Computer Science and Engineering Technology, SCSET 2023",Include,,Include,
Yu S.-Y.; Achamyeleh Y.G.; Wang C.; Kocheturov A.; Eisen P.; Al Faruque M.A.,CFG2VEC: Hierarchical Graph Neural Network for Cross-Architectural Software Reverse Engineering,"Mission-critical embedded software is critical to our society's infrastructure but can be subject to new security vulnerabilities as technology advances. When security issues arise, Reverse Engineers (REs) use Software Reverse Engineering (SRE) tools to analyze vulnerable binaries. However, existing tools have limited support, and REs undergo a time-consuming, costly, and error-prone process that requires experience and expertise to understand the behaviors of software and vulnerabilities. To improve these tools, we propose cfg2vec, a Hierarchical Graph Neural Network (GNN) based approach. To represent binary, we propose a novel Graph-of-Graph (GoG) representation, combining the information of control-flow and function-call graphs. Our cfg2vec learns how to represent each binary function compiled from various CPU architectures, utilizing hierarchical GNN and the siamese network-based supervised learning architecture. We evaluate cfg2vec's capability of predicting function names from stripped binaries. Our results show that cfg2vec outperforms the state-of-the-art by 24.54% in predicting function names and can even achieve 51.84% better given more training data. Additionally, cfg2vec consistently outperforms the state-of-the-art for all CPU architectures, while the baseline requires multiple training to achieve similar performance. More importantly, our results demonstrate that our cfg2vec could tackle binaries built from unseen CPU architectures, thus indicating that our approach can generalize the learned knowledge. Lastly, we demonstrate its practicability by implementing it as a Ghidra plugin used during resolving DARPA Assured MicroPatching (AMP) challenges. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171770894&doi=10.1109%2fICSE-SEIP58684.2023.00031&partnerID=40&md5=d1de185a4b61cb504dd7b84cdb706159,Proceedings - International Conference on Software Engineering,Exclude,,,
Ganz T.; Imgrund E.; Härterich M.; Rieck K.,CodeGraphSMOTE - Data Augmentation for Vulnerability Discovery,"The automated discovery of vulnerabilities at scale is a crucial area of research in software security. While numerous machine learning models for detecting vulnerabilities are known, recent studies show that their generalizability and transferability heavily depend on the quality of the training data. Due to the scarcity of real vulnerabilities, available datasets are highly imbalanced, making it difficult for deep learning models to learn and generalize effectively. Based on the fact that programs can inherently be represented by graphs and to leverage recent advances in graph neural networks, we propose a novel method to generate synthetic code graphs for data augmentation to enhance vulnerability discovery. Our method includes two significant contributions: a novel approach for generating synthetic code graphs and a graph-to-code transformer to convert code graphs into their code representation. Applying our augmentation strategy to vulnerability discovery models achieves the same originally reported F1-score with less than 20 % of the original dataset and we outperform the F1-score of prior work on augmentation strategies by up to 25.6 % in detection performance. © 2023, IFIP International Federation for Information Processing.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169070482&doi=10.1007%2f978-3-031-37586-6_17&partnerID=40&md5=c330a7e55e690a560e961818f726fea0,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,,
Wang S.; Wang X.; Sun K.; Jajodia S.; Wang H.; Li Q.,GraphSPD: Graph-Based Security Patch Detection with Enriched Code Semantics,"With the increasing popularity of open-source software, embedded vulnerabilities have been widely propagating to downstream software. Due to different maintenance policies, software vendors may silently release security patches without providing sufficient advisories (e.g., CVE). This leaves users unaware of security patches and provides attackers good chances to exploit unpatched vulnerabilities. Thus, detecting those silent security patches becomes imperative for secure software maintenance. In this paper, we propose a graph neural network based security patch detection system named GraphSPD, which represents patches as graphs with richer semantics and utilizes a patch-tailored graph model for detection. We first develop a novel graph structure called PatchCPG to represent software patches by merging two code property graphs (CPGs) for the pre-patch and post-patch source code as well as retaining the context, deleted, and added components for the patch. By applying a slicing technique, we retain the most relevant context and reduce the size of PatchCPG. Then, we develop the first end-to-end deep learning model called PatchGNN to determine if a patch is security-related directly from its graph-structured PatchCPG. PatchGNN includes a new embedding process to convert PatchCPG into a numeric format and a new multi-attributed graph convolution mechanism to adapt diverse relationships in PatchCPG. The experimental results show GraphSPD can significantly outperform the state-of-the-art approaches on security patch detection.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166049487&doi=10.1109%2fSP46215.2023.10179479&partnerID=40&md5=7406fabfa206c6c0509c0e2a440c0d44,Proceedings - IEEE Symposium on Security and Privacy,Include,,,
Day P.; Iannucci S.; Banicescu I.,Generating Host-Based Data from Network Traces for Intrusion Detection,"Network intrusion detection has been an active research area for the last 20 years. However, there is a limited amount of publicly available datasets, and, most importantly, most of them are either related to network traces or host-based metrics. For this reason, in this paper, a method for the generation of a hybrid dataset encompassing both network data and host-based data is proposed. We specifically focus on a case study based on the File Transfer Protocol (FTP), a well-known protocol already used with several existing datasets. The proposed methodology consists of two phases, namely: (i) the creation of a seed dataset with correlated network and host-based data and (ii) the creation of a model thereof based on a multi-layer perceptron with discretization for the prediction of host-based data given a network trace. The experimental results indicate that the accuracy of the generation is up to 98% and depends on the number of bins used to encode data and the network size. We also investigate the effects of scaling the network size and show that increasing the bin size is necessary to achieve similar results. To the best of our knowledge, this paper is the first to correlate network-based and host-based traffic. The developed source code was published with an open-source license as an additional contribution. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168857948&doi=10.1109%2fCOMPSAC57700.2023.00041&partnerID=40&md5=fb1375bc5e1d0616777eb096b3283e5a,Proceedings - International Computer Software and Applications Conference,Exclude,,Exclude,
Zhou X.; Pang J.; Zhang C.; Yue F.; Wang J.; Liu G.,TS-GGNN: Combining Graph and Sequence Features for Vulnerability Detection in Source Code,"Software vulnerability detection is crucial for maintaining the security and stability of software systems. In this paper, we propose a novel neural network model called TS-GGNN to address the problem of vulnerability detection in source code slices. The TS-GGNN model effectively captures both local and global features of vulnerable code by fusing sequence features with graph features. To achieve this, we utilize graph structure and sequence structure learning approaches to comprehensively extract valuable information from the source code slices. Our experiments are conducted on the SARD dataset, which consists of 61,638 code samples annotated for the presence or absence of vulnerabilities. The results demonstrate that TS-GGNN has the best vulnerability detection performance, with an accuracy of 99.4%, a precision of 98.81%, and an F1 score as high as 99.4% thereby validating the effectiveness of the TS-GGNN model in capturing features relevant to software vulnerabilities.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163405645&doi=10.1109%2fCISCE58541.2023.10142859&partnerID=40&md5=858b0ff35c1046eeefb38744e97cc35f,"2023 5th International Conference on Communications, Information System and Computer Engineering, CISCE 2023",Include,,Include,
Wang Z.; Meng S.; Chen Y.,Vulnerability Detection with Representation Learning,"It is essential to identify potentially vulnerable code in our software systems. Deep neural network techniques have been used for vulnerability detection. However, existing methods usually ignore the feature representation of vulnerable datasets, resulting in unsatisfactory model performance. Such vulnerability detection techniques should achieve high accuracy, relatively high true-positive rate, and low false-negative rate. At the same time, it needs to be able to complete the vulnerability detection of actual projects and does not require additional expert knowledge or tedious configuration. In this article, we propose and implement VDDRL (A Vulnerability Detection Method Based On Deep Representation Learning). This deep representation learning-based vulnerability detection method combines feature extraction and ensemble learning. VDDRL uses the word2vec model to convert the source code into a vector representation. Deep representations of vulnerable code are learned from vulnerable code token sequences using LSTM models and then trained for classification using traditional machine learning algorithms. The training dataset we use is derived from actual projects and contains seven different types of vulnerabilities. Through comparative experiments on datasets, VDDRL achieves an Accuracy of 95.6%–98.7%, a Precision of 91.6%–99.0%, a Recall of 84.7%–99.5%, and an F1 of 88.1%–99.2%. Both perform better than the baseline method. Our experimental results show that VDDRL is a generic, lightweight, and extensible vulnerability detection method. Compared with other methods, it has better performance and robustness. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151064354&doi=10.1007%2f978-981-99-0272-9_8&partnerID=40&md5=dc655cbd775e4d02c08f789b50ed3e9f,Communications in Computer and Information Science,Include,,,
Ou W.; Ding S.H.H.,MaGnn: Binary-Source Code Matching by Modality-Sharing Graph Convolution for Binary Provenance Analysis,"The number and variety of binaries running on electrical devices, public clouds, and on-premise infrastructure have been increasing rapidly. Recent successful supply chain attacks indicate that even for binaries known to be developed by trustful developers, they can still contain malicious functionalities and copy-and-pasted vulnerabilities that pose security risks to operational systems and end users. By analyzing the origin of a target code, code provenance analysis helps to relieve such problem by revealing information about the origin of a binary sample such as the author or the included software bill-of-materials. Since in most cases source symbol information is removed during the compilation process, given a binary code sample, matching it to its corresponding source code could improve the accuracy and efficiency of the provenance analysis. Existing binary-source code matching methods focus on comparing manually selected code literals (e.g. the number of if/else statements). However, these methods suffer from the issue of generalizability and require significant manual efforts.Different from the previous methods, we propose a machine learning-based binary-source code matching system, MaGnn, which measures the consistency of an input binary-source code pair by automatically extracting high-dimensional feature representations of the input and calculating the functionality similarity. With the Siamese architecture that shares a unified encoder across two modalities, McGnn is able to calculate the similarity of the input binary-source code pair with the automatically-extracted functionality representations. With the graph convolution neural network as the representation encoder, MaGnn is able to learn and encode the functionality information of the input pairs from their graph features into high-dimensional representation vectors. We benchmark MaGnn with a state-of-the-art binary-source code matching method and two machine-learning models on six out-of-sample datasets collected from five real-world libraries. Our experiment results show that MaGnn outperforms the baselines on most out-of-sample datasets. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168903836&doi=10.1109%2fCOMPSAC57700.2023.00091&partnerID=40&md5=fbfe9cda0fe6402edb6c14d48bae73ed,Proceedings - International Computer Software and Applications Conference,Exclude,,,
Kraker W.D.; Vranken H.; Hommmersom A.,GLICE: Combining Graph Neural Networks and Program Slicing to Improve Software Vulnerability Detection,"This paper introduces the GLICE (Graph Neural Network with program slice) model for static code analysis to detect vulnerabilities in source code. GLICE combines inter-procedural program slicing with a Graph Neural Network. It builds upon and extends prior work that applies program slicing (as in the SySeVR model) and Graph Neural Networks (as in the FUNDED model) for vulnerability detection. We apply GLICE on a data set of C/C++ code samples with out-of-bounds write (CWE-787) and out-of-bounds read (CWE-125) butter overflow vulnerabilities. We perform experiments with GLICE to evaluate trade-offs in the depth of the inter-procedural analysis, and to compare GLICE with prior models by evaluating the effectiveness for vulnerability detection and the usage of resources. Our experimental results show that detection accuracy of GLICE improves up to 13% when compared to FUNDED, while the time required to train the GLICE model is about 9 times smaller. GLICE allows configuring the depth of the interprocedural analysis. Our experimental results show that increasing the depth will improve detection, which however requires more computing resources. This allows a user of GLICE to steer the trade-off between detection accuracy and computational efficiency.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168239975&doi=10.1109%2fEuroSPW59978.2023.00009&partnerID=40&md5=8defe123556105593a18ef221e5cdfa6,"Proceedings - 8th IEEE European Symposium on Security and Privacy Workshops, Euro S and PW 2023",Include,,,
Abdelaziz T.; Hobor A.,Smart Learning to Find Dumb Contracts,"We introduce Deep Learning Vulnerability Analyzer (DLVA), a vulnerability detection tool for Ethereum smart contracts based on powerful deep learning techniques for sequential data adapted for bytecode. We train DLVA to judge bytecode even though the supervising oracle, Slither, can only judge source code. DLVA’s training algorithm is general: we “extend” a source code analysis to bytecode without any manual feature engineering, predefined patterns, or expert rules. DLVA’s training algorithm is also robust: it overcame a 1.25% error rate mislabeled contracts, and—the student surpassing the teacher—found vulnerable contracts that Slither mislabeled. In addition to extending a source code analyzer to bytecode, DLVA is much faster than conventional tools for smart contract vulnerability detection based on formal methods: DLVA checks contracts for 29 vulnerabilities in 0.2 seconds, a 10–1,000x speedup compared to traditional tools. DLVA has three key components. First, Smart Contract to Vector (SC2V) uses neural networks to map arbitrary smart contract bytecode to an high-dimensional floating-point vector. We benchmark SC2V against 4 state-of-the-art graph neural networks and show that it improves model differentiation by an average of 2.2%. Second, Sibling Detector (SD) classifies contracts when a target contract’s vector is Euclidian-close to a labeled contract’s vector in a training set; although only able to judge 55.7% of the contracts in our test set, it has an average Slither-predictive accuracy of 97.4% with a false positive rate of only 0.1%. Third, Core Classifier (CC) uses neural networks to infer vulnerable contracts regardless of vector distance. We benchmark DLVA’s CC with 10 “off-the-shelf” machine learning techniques and show that the CC improves average accuracy by 11.3%. Overall, DLVA predicts Slither’s labels with an overall accuracy of 92.7% and associated false positive rate of 7.2%. Lastly, we benchmark DLVA against nine well-known smart contract analysis tools. Despite using much less analysis time, DLVA completed every query, leading the pack with an average accuracy of 99.7%, pleasingly balancing high true positive rates with low false positive rates. © USENIX Security 2023. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165213965&partnerID=40&md5=9f86915e452dcbad95cd1aa61e3fcc54,"32nd USENIX Security Symposium, USENIX Security 2023",Include,,,
Wang J.; Huang M.; Nie Y.; Kuang X.; Li X.; Zhong W.,Fine-Grained Source Code Vulnerability Detection via Graph Neural Networks,"Although the number of exploitable vulnerabilities in software continues to increase, the speed of bug fixes and software updates have not increased accordingly. It is therefore crucial to analyze the source code and identify vulnerabilities in the early phase of software development. However, vulnerability location in most of the current machine learning-based methods tends to concentrate at the function level. It undoubtedly imposes a burden on further manual code audits when faced with large-scale source code projects. In this paper, a fine-grained source code vulnerability detection model based on Graph Neural Networks (GNNs) is proposed with the aim of locating vulnerabilities at the function level and line level. Our empirical evaluation on different C/C++ datasets demonstrated that our proposed model outperforms the state-of-the-art methods and achieves significant improvements even when faced with more complex, real-project source code. © 2023 Knowledge Systems Institute Graduate School. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170065533&doi=10.18293%2fSEKE2023-115&partnerID=40&md5=0394a3677f82786986e04fcdec1fee65,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",Include,,,
Patrick-Evans J.; Dannehl M.; Kinder J.,XFL: Naming Functions in Binaries with Extreme Multi-label Learning,"Reverse engineers benefit from the presence of identifiers such as function names in a binary, but usually these are removed for release. Training a machine learning model to predict function names automatically is promising but fundamentally hard: unlike words in natural language, most function names occur only once. In this paper, we address this problem by introducing eXtreme Function Labeling (XFL), an extreme multi-label learning approach to selecting appropriate labels for binary functions. XFL splits function names into tokens, treating each as an informative label akin to the problem of tagging texts in natural language. We relate the semantics of binary code to labels through Dexter, a novel function embedding that combines static analysis-based features with local context from the call graph and global context from the entire binary. We demonstrate that XFL/Dexter outperforms the state of the art in function labeling on a dataset of 10,047 binaries from the Debian project, achieving a precision of 83.5%. We also study combinations of XFL with alternative binary embeddings from the literature and show that Dexter consistently performs best for this task. As a result, we demonstrate that binary function labeling can be effectively phrased in terms of multi-label learning, and that binary function embeddings benefit from including explicit semantic features.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166482994&doi=10.1109%2fSP46215.2023.10179439&partnerID=40&md5=85626a2952c38bc805bcf46cc4f0334d,Proceedings - IEEE Symposium on Security and Privacy,Exclude,,,
Zhang H.; Kishi T.,Long Method Detection Using Graph Convolutional Networks,"Long Method is a code smell that frequently happens in software development, which refers to the com-plex method with multiple functions. Detecting and refactoring such problems has been a popular topic in software refactoring, and many detection approaches have been proposed. In past years, the approaches based on metrics or rules have been the leading way in long method detection. However, the approach based on deep learning has also attracted extensive attention in recent studies. In this paper, we propose a graph-based deep learning approach to de-tect Long Method. The key point of our approach is that we extended the PDG (Program Dependency Graph) into a Directed-Heterogeneous Graph as the input graph and used the GCN (Graph Convolutional Network) to build a graph neural network for Long Method detection. Moreover, to get substantial data samples for the deep learning task, we propose a novel semi-automatic approach to generate a large number of data samples. Finally, to prove the validity of our approach, we compared our approach with the existing approaches based on five groups of datasets manually reviewed. The evaluation result shows that our approach achieved a good performance in Long Method detection. © 2023, Information Processing Society of Japan. All rights reserved.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169480537&doi=10.2197%2fipsjjip.31.469&partnerID=40&md5=64c615bceca1579d612103656725e595,Journal of Information Processing,Include,,Include,
Guo W.; Fang Y.; Huang C.; Ou H.; Lin C.; Guo Y.,HyVulDect: A hybrid semantic vulnerability mining system based on graph neural network,"In recent years, software programs tend to be large and complex, software has become the infrastructure of modern society, but software security issues can not be ignored. software vulnerabilities have become one of the main threats to computer security. There are countless cases of exploiting source code vulnerabilities to launch attacks. At the same time, the development of open source software has made source code vulnerability detection more and more critical. Traditional vulnerability mining methods have been unable to meet the security analysis needs of complex software because of the high false-positive rate and false-negative rate. To resolve the existing problems, we propose a graph neural network vulnerability mining system named HyVulDect based on hybrid semantics, which constructs a composite semantic code property graph for code representation based on the causes of vulnerabilities. A gated graph neural network is used to extract deep semantic information. Since most of the vulnerabilities are data flow associated, we use taint analysis to extract the taint propagation chain, use the BiLSTM model to extract the token-level features of the context, and finally use the classifier to classify the fusion features. We introduce a dual-attention mechanism that allows the model to focus on vulnerability-related code, making it more suitable for vulnerability mining tasks. The experimental results show that HyVulDect outperforms existing state-of-the-art methods and can achieve an accuracy rate of 92% on the benchmark dataset. Compared with the rule-based static mining tools Flawfinder, RATS, and Cppcheck, it has better performance and can effectively detect the actual CVE source code vulnerabilities. © 2022 Elsevier Ltd",Review,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134880709&doi=10.1016%2fj.cose.2022.102823&partnerID=40&md5=7c0d39840ad714fb2d4762a2437aa558,Computers and Security,Include,,,
Luo Y.; Xu W.; Xu D.,Compact Abstract Graphs for Detecting Code Vulnerability with GNN Models,"Source code representation is critical to the machine-learning-based approach to detecting code vulnerability. This paper proposes Compact Abstract Graphs (CAGs) of source code in different programming languages for predicting a broad range of code vulnerabilities with Graph Neural Network (GNN) models. CAGs make the source code representation aligned with the task of vulnerability classification and reduce the graph size to accelerate model training with minimum impact on the prediction performance. We have applied CAGs to six GNN models and large Java/C datasets with 114 vulnerability types in Java programs and 106 vulnerability types in C programs. The experiment results show that the GNN models have performed well, with accuracy ranging from 94.7% to 96.3% on the Java dataset and from 91.6% to 93.2% on the C dataset. The resultant GNN models have achieved promising performance when applied to more than 2,500 vulnerabilities collected from real-world software projects. The results also show that using CAGs for GNN models is significantly better than ASTs, CFGs (Control Flow Graphs), and PDGs (Program Dependence Graphs). A comparative study has demonstrated that the CAG-based GNN models can outperform the existing methods for machine learning-based vulnerability detection.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144086642&doi=10.1145%2f3564625.3564655&partnerID=40&md5=a8df527c9c6a10e7f895ff4800eb4fc9,ACM International Conference Proceeding Series,Include,,,
Liu Z.; Fang Y.; Huang C.; Xu Y.,MFXSS: An effective XSS vulnerability detection method in JavaScript based on multi-feature model,"The widespread use of web applications has also made them more vulnerable to hackers, resulting in the leakage of large amounts of application and personal privacy data. Cross-site scripting (XSS) attacks are one of the most significant threats to web applications. Attackers can inject scripts to control the victim's browser to send data or execute commands, leading to the theft of privacy or the hijacking of login tokens. Therefore, we proposed a multi-feature fusion-based neural network vulnerability detection model for detecting XSS vulnerabilities in the JavaScript source code of websites (We termed our implementation of this approach MFXSS). We combine abstract syntax tree (AST) and code control flow graph (CFG) to convert the generalized sample data into graph structure and code string structure. Then, through the graph convolutional neural network, weighted aggregation, and the bidirectional recurrent neural network, the logical call features and the context execution relationship features of the source code are extracted and fused respectively. Finally, the fused feature vectors are used to detect and predict XSS vulnerabilities in JavaScript. In the experiment, we designed multiple control experiments to verify that the model construction is optimal, and the accuracy rates in the standard and variant datasets are 0.997 and 0.986. Moreover, in comparing similar detection schemes, MFXSS also performs better. Applying the model to an actual web environment, we successfully detected the presence of XSS vulnerabilities in websites. © 2022 Elsevier Ltd",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142136187&doi=10.1016%2fj.cose.2022.103015&partnerID=40&md5=eb1a928fab60b2f8770f3043b3edb47f,Computers and Security,Include,,,
Cheng X.; Zhang G.; Wang H.; Sui Y.,Path-sensitive code embedding via contrastive learning for software vulnerability detection,"Machine learning and its promising branch deep learning have shown success in a wide range of application domains. Recently, much effort has been expended on applying deep learning techniques (e.g., graph neural networks) to static vulnerability detection as an alternative to conventional bug detection methods. To obtain the structural information of code, current learning approaches typically abstract a program in the form of graphs (e.g., data-flow graphs, abstract syntax trees), and then train an underlying classification model based on the (sub)graphs of safe and vulnerable code fragments for vulnerability prediction. However, these models are still insufficient for precise bug detection, because the objective of these models is to produce classification results rather than comprehending the semantics of vulnerabilities, e.g., pinpoint bug triggering paths, which are essential for static bug detection. This paper presents ContraFlow, a selective yet precise contrastive value-flow embedding approach to statically detect software vulnerabilities. The novelty of ContraFlow lies in selecting and preserving feasible value-flow (aka program dependence) paths through a pretrained path embedding model using self-supervised contrastive learning, thus significantly reducing the amount of labeled data required for training expensive downstream models for path-based vulnerability detection. We evaluated ContraFlow using 288 real-world projects by comparing eight recent learning-based approaches. ContraFlow outperforms these eight baselines by up to 334.1%, 317.9%, 58.3% for informedness, markedness and F1 Score, and achieves up to 450.0%, 192.3%, 450.0% improvement for mean statement recall, mean statement precision and mean IoU respectively in terms of locating buggy statements.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136799873&doi=10.1145%2f3533767.3534371&partnerID=40&md5=e74c09d0c019b5dec610654bd695b380,ISSTA 2022 - Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis,Include,,Include,
Lin C.; Xu Y.; Fang Y.; Liu Z.,VulEye: A Novel Graph Neural Network Vulnerability Detection Approach for PHP Application,"Following advances in machine learning and deep learning processing, cyber security experts are committed to creating deep intelligent approaches for automatically detecting software vulnerabilities. Nowadays, many practices are for C and C++ programs, and methods rarely target PHP application. Moreover, many of these methods use LSTM (Long Short-Term Memory) but not GNN (Graph Neural Networks) to learn the token dependencies within the source code through different transformations. That may lose a lot of semantic information in terms of code representation. This article presents a novel Graph Neural Network vulnerability detection approach, VulEye, for PHP applications. VulEye can assist security researchers in finding vulnerabilities in PHP projects quickly. VulEye first constructs the PDG (Program Dependence Graph) of the PHP source code, slices PDG with sensitive functions contained in the source code into sub-graphs called SDG (Sub-Dependence Graph), and then makes SDG the model input to train with a Graph Neural Network model which contains three stack units with a GCN layer, Top-k pooling layer, and attention layer, and finally uses MLP (Multi-Layer Perceptron) and softmax as a classifier to predict if the SDG is vulnerable. We evaluated VulEye on the PHP vulnerability test suite in Software Assurance Reference Dataset. The experiment reports show that the best macro-average F1 score of the VulEye reached 99% in the binary classification task and 95% in the multi-classes classification task. VulEye achieved the best result compared with the existing open-source vulnerability detection implements and other state-of-art deep learning models. Moreover, VulEye can also locate the precise area of the flaw, since our SDG contains code slices closely related to vulnerabilities with a key triggering sensitive/sink function. © 2023 by the authors.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146468835&doi=10.3390%2fapp13020825&partnerID=40&md5=18e5279034f59365a34fda512d5d2da2,Applied Sciences (Switzerland),Include,,,
Chauhan V.K.; Kumar A.,Vulnerability Detection in Source Code using Deep Representation Learning,"Every year, whether or not they may be discovered internally in personal code or are made public, software program issues are found extra frequently. Those weaknesses might be exploited, ensuing in denial of provider, gadget compromise, or statistics leaks. We developed a large-scale characteristic-stage vulnerability detection method using gadgets getting to know employing open-source C and C++ code. We advanced a giant dataset of hundreds of thousands of open-source features and tagged it with cautiously selected findings from 3 separate studies companies intending to augment previously labeled vulnerability datasets. Capacity vulnerabilities are determined using static analyzers. The marked dataset is to be had at https://osf.io/d45bw/. Using those datasets, we created a brief and scalable vulnerability detection approach based on deep characteristic illustration gaining knowledge that reads source code lexis at once. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149739065&doi=10.1109%2fSMART55829.2022.10047614&partnerID=40&md5=32b553f0afd5d62b5fd357123a2badbb,"Proceedings of the 2022 11th International Conference on System Modeling and Advancement in Research Trends, SMART 2022",Include,,,
Şahin S.E.; Özyedierler E.M.; Tosun A.,Predicting vulnerability inducing function versions using node embeddings and graph neural networks,"Context: Predicting software vulnerabilities over code changes is a difficult task due to obtaining real vulnerability data and their associated code fixes from software projects as software organizations are often reluctant to report those. Objective: We aim to propose a vulnerability prediction model that runs after every code change, and identifies vulnerability inducing functions in that version. We also would like to assess the success of node and token based source code representations over abstract syntax trees (ASTs) on predicting vulnerability inducing functions. Method: We train neural networks to represent node embeddings and token embeddings over ASTs in order to obtain feature representations. Then, we build two Graph Neural Networks (GNNs) with node embeddings, and compare them against Convolutional Neural Network (CNN) and Support Vector Machine (SVM) with token representations. Results: We report our empirical analysis over the change history of vulnerability inducing functions of Wireshark project. GraphSAGE model using source code representation via ASTs achieves the highest AUC rate, while CNN models using token representations achieves the highest recall, precision and F1 measure. Conclusion: Representing functions with their structural information extracted from ASTs, either in token form or in complete graph form, is great at predicting vulnerability inducing function versions. Transforming source code into token frequencies as a natural language text fails to build successful models for vulnerability prediction in a real software project. © 2022 Elsevier B.V.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123002701&doi=10.1016%2fj.infsof.2022.106822&partnerID=40&md5=faca0fa5b8ecb873804f1428477ad855,Information and Software Technology,Include,,,
Hin D.; Kan A.; Chen H.; Babar M.A.,LineVD: Statement-level Vulnerability Detection using Graph Neural Networks,"Current machine-learning based software vulnerability detection methods are primarily conducted at the function-level. However, a key limitation of these methods is that they do not indicate the specific lines of code contributing to vulnerabilities. This limits the ability of developers to efficiently inspect and interpret the predictions from a learnt model, which is crucial for integrating machine-learning based tools into the software development work-flow. Graph-based models have shown promising performance in function-level vulnerability detection, but their capability for statement-level vulnerability detection has not been extensively explored. While interpreting function-level predictions through explainable AI is one promising direction, we herein consider the statement-level software vulnerability detection task from a fully supervised learning perspective. We propose a novel deep learning framework, LineVD, which formulates statement-level vulnerability detection as a node classification task. LineVD leverages control and data dependencies between statements using graph neural networks, and a transformer-based model to encode the raw source code tokens. In particular, by addressing the conflicting outputs between function-level and statement-level information, LineVD significantly improve the prediction performance without vulnerability status for function code. We have conducted extensive experi-ments against a large-scale collection of real-world C/C++ vulnerabilities obtained from multiple real-world projects, and demonstrate an increase of 105% in F1-score over the current state-of-the-art. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134019413&doi=10.1145%2f3524842.3527949&partnerID=40&md5=5148d83b0082ec460c9f6f5ef06cd8e1,"Proceedings - 2022 Mining Software Repositories Conference, MSR 2022",Include,,,
Wu Y.; Zou D.; Dou S.; Yang W.; Xu D.; Jin H.,VulCNN: An Image-inspired Scalable Vulnerability Detection System,"Since deep learning (DL) can automatically learn features from source code, it has been widely used to detect source code vulnerability. To achieve scalable vulnerability scanning, some prior studies intend to process the source code directly by treating them as text. To achieve accurate vulnerability detection, other approaches consider distilling the program semantics into graph representations and using them to detect vulnerability. In practice, text-based techniques are scalable but not accurate due to the lack of program semantics. Graph-based methods are accurate but not scalable since graph analysis is typically time-consuming. In this paper, we aim to achieve both scalability and accuracy on scanning large-scale source code vulnerabilities. Inspired by existing DL-based image classification which has the ability to analyze millions of images accurately, we prefer to use these techniques to accomplish our purpose. Specifically, we propose a novel idea that can efficiently convert the source code of a function into an image while preserving the program details. We implement Vul-CNN and evaluate it on a dataset of 13,687 vulnerable functions and 26,970 non-vulnerable functions. Experimental results report that VulCNN can achieve better accuracy than eight state-of-the-art vul-nerability detectors (i.e., Checkmarx, FlawFinder, RATS, TokenCNN, VulDeePecker, SySeVR, VulDeeLocator, and Devign). As for scalability, VulCNN is about four times faster than VulDeePecker and SySeVR, about 15 times faster than VulDeeLocator, and about six times faster than Devign. Furthermore, we conduct a case study on more than 25 million lines of code and the result indicates that VulCNN can detect large-scale vulnerability. Through the scanning reports, we finally discover 73 vulnerabilities that are not reported in NVD. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133506161&doi=10.1145%2f3510003.3510229&partnerID=40&md5=5067c6763020b702bf6f767155caf849,Proceedings - International Conference on Software Engineering,Include,,,
Li R.; Chen B.; Zhang F.; Sun C.; Peng X.,Detecting Runtime Exceptions by Deep Code Representation Learning with Attention-Based Graph Neural Networks,"Uncaught runtime exceptions have been recognized as one of the commonest root causes of real-life exception bugs in Java applications. However, existing runtime exception detection techniques rely on symbolic execution or random testing, which may suffer the scalability or coverage problem. Rule-based bug detectors (e.g., SpotBugs) provide limited rule support for runtime exceptions. Inspired by the recent successes in applying deep learning to bug detection, we propose a deep learning-based technique, named Drex, to identify not only the types of runtime exceptions that a method might signal but also the statement scopes that might signal the detected runtime exceptions. It is realized by graph-based code representation learning with (i) a lightweight analysis to construct a joint graph of CFG, DFG and AST for each method without requiring a build environment so as to comprehensively characterize statement syntax and semantics and (ii) an attention-based graph neural network to learn statement embeddings in order to distinguish different types of potentially signaled runtime exceptions with interpretability. Our evaluation on 54,255 methods with caught runtime exceptions and 54,255 methods without caught runtime exceptions from 5,996 GitHub Java projects has indicated that Drex improves baseline approaches by up to 18.2% in exact accuracy and 41.6% in F1-score. Drex detects 20 new uncaught runtime exceptions in 13 real-life pro-jects, 7 of them have been fixed, while none of them is detected by rule-based bug detectors (i.e., SpotBugs and PMD).  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134875978&doi=10.1109%2fSANER53432.2022.00053&partnerID=40&md5=8cd8ed205b17dc752c7516483d7b729d,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",Include,,Include,
Pooja S.; Chandrakala C.B.; Raju L.K.,Developer's Roadmap to Design Software Vulnerability Detection Model Using Different AI Approaches,"Automatic software vulnerability detection has caught the eyes of researchers as because software vulnerabilities are exploited vehemently causing major cyber-attacks. Thus, designing a vulnerability detector is an inevitable approach to eliminate vulnerabilities. With the advances of Natural language processing in the application of interpreting source code as text, AI approaches based on Machine Learning, Deep Learning and Graph Neural Network have impactful research works. The key requirement for developing an AI based vulnerability detector model from a developer perspective is to identify which AI model to adopt, availability of labelled dataset, how to represent essential feature and tokenizing the extracted feature vectors, specification of vulnerability coverage with detection granularity. Most of the literature review work explores AI approaches based on either Machine Learning or Deep Learning model. The existing literature work either highlight only feature representation technique or identifying granularity level and dataset. A qualitative comparative analysis on ML, DL, GNN based model is presented in this work to get a complete picture on VDM thus addressing the challenges of a researcher to choose suitable architecture, feature representation and processing required for designing a VDM. This work focuses on putting together all the essential bits required for designing an automated software vulnerability detection model using any various AI approaches.  © 2022 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135246233&doi=10.1109%2fACCESS.2022.3191115&partnerID=40&md5=12f897bd45967eb6a5347c5f822d8604,IEEE Access,Include,,,
Zou D.; Hu Y.; Li W.; Wu Y.; Zhao H.; Jin H.,mVulPreter: A Multi-Granularity Vulnerability Detection System With Interpretations,"Due to the powerful automatic feature extraction, deep learning-based vulnerability detection methods have evolved significantly in recent years. However, almost all current work focuses on detecting vulnerabilities at a single granularity (<italic>i.e</italic>., slice-level or function-level). In practice, slice-level vulnerability detection is fine-grained but may contain incomplete vulnerability details. Function-level vulnerability detection includes full vulnerability semantics but may contain vulnerability-unrelated statements. Meanwhile, they pay more attention to predicting whether the source code is vulnerable and cannot pinpoint which statements are more likely to be vulnerable. In this paper, we design <italic>mVulPreter</italic>, a multi-granularity vulnerability detector that can provide interpretations of detection results. Specifically, we propose a novel technique to effectively blend the advantages of function-level and slice-level vulnerability detection models and output the detection results&#x0027; interpretation only by the model itself. We evaluate <italic>mVulPreter</italic> on a dataset containing 5,310 vulnerable functions and 7,601 non-vulnerable functions. The experimental results indicate that <italic>mVulPreter</italic> outperforms existing state-of-the-art vulnerability detection approaches (<italic>i.e</italic>., <italic>Checkmarx</italic>, <italic>FlawFinder</italic>, <italic>RATS</italic>, <italic>TokenCNN</italic>, <italic>StatementLSTM</italic>, <italic>SySeVR</italic>, and <italic>Devign</italic>). IEEE",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137554035&doi=10.1109%2fTDSC.2022.3199769&partnerID=40&md5=d4831c43be79246dab220be2e289fcae,IEEE Transactions on Dependable and Secure Computing,Include,,,
Hanif H.; Maffeis S.,VulBERTa: Simplified Source Code Pre-Training for Vulnerability Detection,"This paper presents VulBERTa, a deep learning approach to detect security vulnerabilities in source code. Our approach pre-trains a RoBERTa model with a custom tokenisation pipeline on real-world code from open-source C/C++ projects. The model learns a deep knowledge representation of the code syntax and semantics, which we leverage to train vulnerability detection classifiers. We evaluate our approach on binary and multi-class vulnerability detection tasks across several datasets (Vuldeepecker, Draper, REVEAL and muVuldeepecker) and benchmarks (CodeXGLUE and D2A). The evaluation results show that VulBERTa achieves state-of-the-art performance and outperforms existing approaches across different datasets, despite its conceptual simplicity, and limited cost in terms of size of training data and number of model parameters. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140716771&doi=10.1109%2fIJCNN55064.2022.9892280&partnerID=40&md5=07ed4262e06c2595020fac04ff332b88,Proceedings of the International Joint Conference on Neural Networks,Exclude,,Include,Exclude
Yan G.; Chen S.; Bail Y.; Li X.,Can Deep Learning Models Learn the Vulnerable Patterns for Vulnerability Detection?,"Deep learning has been widely used for the security issue of vulnerability prediction. However, it is confusing to explain how a deep learning model makes decisions on the prediction, although such a model achieves a good performance. Meanwhile, it is also difficult to discover which part of the source code is concentrated on by this black-box model. To this end, we present an empirical evaluation to explore how the deep learning model works on predicting vulnerability and whether it precisely captures the critical code segments to represent the vulnerable patterns. First of all, we build a new vulnerability dataset, called Juliet+, in which vulnerability-related code lines of both positive (bad) and negative (good) samples are labeled manually with substantial efforts, based on the Juliet Test Suite. After that, four deep learning models by leveraging attention mechanisms are empirically implemented to detect vulnerability through mining vulnerable patterns from the source code. We conduct extensive experiments to evaluate the effectiveness of such four models and to analyze the interpretability with evaluation metrics such as Hit@k. The empirical experiment results reveal that the deep learning models with attention, to some extent, can focus on the vulnerability-related code segments that are profitable to interpret the result of vulnerability detection, especially when we adopt the graph neural network model. We further investigate what factors affect the interpretability of models including the class distribution, the number of samples, and the differences of sample features. We find the graph neural network model performs better on part of the dataset which contains balanced and sufficient samples with obvious differences between vulnerable and non-vulnerable patterns. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136989786&doi=10.1109%2fCOMPSAC54236.2022.00142&partnerID=40&md5=7dae859cbf5309de1a4c77fa15eb9138,"Proceedings - 2022 IEEE 46th Annual Computers, Software, and Applications Conference, COMPSAC 2022",Include,,,
Wu B.; Liu S.; Feng R.; Xie X.; Siow J.; Lin S.,Enhancing Security Patch Identification by Capturing Structures in Commits,"With the rapid increasing number of open source software (OSS), the majority of the software vulnerabilities in the open source components are fixed silently, which leads to the deployed software that integrated them being unable to get a timely update. Hence, it is critical to design a security patch identification system to ensure the security of the utilized software. However, most of the existing works for security patch identification just consider the changed code and the commit message of a commit as a flat sequence of tokens with simple neural networks to learn its semantics, while the structure information is ignored. To address these limitations, in this paper, we propose our well-designed approach E-SPI, which extracts the structure information hidden in a commit for effective identification. Specifically, it consists of the code change encoder to extract the syntactic of the changed code with the BiLSTM to learn the code representation and the message encoder to construct the dependency graph for the commit message with the graph neural network (GNN) to learn the message representation. We further enhance the code change encoder by embedding contextual information related to the changed code. To demonstrate the effectiveness of our approach, we conduct the extensive experiments against six state-of-the-art approaches on the existing dataset and from the real deployment environment. The experimental results confirm that our approach can significantly outperform current state-of-the-art baselines. IEEE",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135750651&doi=10.1109%2fTDSC.2022.3192631&partnerID=40&md5=03faa8fe5f35a1bdcf6a280e89552e9d,IEEE Transactions on Dependable and Secure Computing,Include,,Include,
Yang H.; Yang H.; Zhang L.,VDHGT: A Source Code Vulnerability Detection Method Based on Heterogeneous Graph Transformer,"Vulnerability detection is still a challenging problem. The source code representation method used by the existing vulnerability detection methods cannot fully contain the context information of the vulnerability occurrence statement, and the vulnerability detection model does not fully consider the importance of the context statement to the vulnerability occurrence statement. Aiming at the problems raised above, this paper proposes a source code vulnerability detection method based on the heterogeneous graph transformer. The method proposed in this paper adopts a novel source code representation method—the vulnerability dependence representation graph, which includes the control dependence of the vulnerability occurrence statement and the data dependence of the variables involved in the statement. At the same time, this paper builds a graph learning network for vulnerability dependence representation graph based on the heterogeneous graph transformer, which can automatically learn the importance of contextual sentences for vulnerable sentences. To prove the effectiveness of the method in this paper, experiments were carried out on the SARD data set, and the average accuracy rate was 95.4% and the recall rate was 92.4%. The average performance is improved by 4.1%–62.7%. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140476757&doi=10.1007%2f978-3-031-18067-5_16&partnerID=40&md5=f7aa123f037071d1b10aa98db66facd0,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,,
Jiang Z.,Source Code Vulnerability Mining Method based on Graph Neural Network,"Vulnerability discovery is an important field of computer security research and development today. Because most of the current vulnerability discovery methods require large-scale manual auditing, and the code parsing process is cumbersome and time-consuming, the vulnerability discovery effect is reduced. Therefore, for the uncertainty of vulnerability discovery itself, it is the most basic tool design principle that auxiliary security analysts cannot completely replace them. The purpose of this paper is to study the source code vulnerability discovery method based on graph neural network. This paper analyzes the three processes of data preparation, source code vulnerability mining and security assurance of the source code vulnerability mining method, and also analyzes the suspiciousness and particularity of the experimental results. The empirical analysis results show that the types of traditional source code vulnerability mining methods become more concise and convenient after using graph neural network technology, and we conducted a survey and found that more than 82% of people felt that the design source code vulnerability mining method used When it comes to graph neural networks, it is found that the design efficiency has become higher. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136337928&doi=10.1109%2fICETCI55101.2022.9832392&partnerID=40&md5=fde87702d1ceb4b6ac1fc1fdf344d1f0,"2022 IEEE 2nd International Conference on Electronic Technology, Communication and Information, ICETCI 2022",Include,,Include,
Rabheru R.; Hanif H.; Maffeis S.,A Hybrid Graph Neural Network Approach for Detecting PHP Vulnerabilities,"We validate our approach in the wild by discovering 4 novel vulnerabilities in established WordPress plugins. This paper presents DeepTective, a deep learning-based approach to detect vulnerabilities in PHP source code. Our approach implements a novel hybrid technique that combines Gated Recurrent Units and Graph Convolutional Networks to detect SQLi, XSS and OSCI vulnerabilities leveraging both syntactic and semantic information. We evaluate DeepTective and compare it to the state of the art on an established synthetic dataset and on a novel real-world dataset collected from GitHub. Experimental results show that DeepTective outperformed other solutions, including recent machine learning-based vulnerability detection approaches, on both datasets. The gap is noticeable on the synthetic dataset, where our approach achieves very high classification performance, but grows even wider on the realistic dataset, where most existing tools fail to transfer their detection ability, whereas DeepTective achieves an F1 score of 88.12%.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141069074&doi=10.1109%2fDSC54232.2022.9888816&partnerID=40&md5=cfd7e321bea4879cb5fcb78b57af4ac6,"5th IEEE Conference on Dependable and Secure Computing, DSC 2022 and SECSOC 2022 Workshop, PASS4IoT 2022 Workshop SICSA International Paper/Poster Competition in Cybersecurity",Include,,,
Cao S.; Sun X.; Bo L.; Wu R.; Li B.; Tao C.,MVD: Memory-Related Vulnerability Detection Based on Flow-Sensitive Graph Neural Networks,"Memory-related vulnerabilities constitute severe threats to the security of modern software. Despite the success of deep learning-based approaches to generic vulnerability detection, they are still limited by the underutilization of flow information when applied for detecting memory-related vulnerabilities, leading to high false positives. In this paper, we propose MVD, a statement-level Memory-related Vulnerability Detection approach based on flow-sensitive graph neural networks (FS-GNN). FS-GNN is employed to jointly embed both unstructured information (i.e., source code) and structured information (i.e., control- and data-flow) to capture implicit memory-related vulnerability patterns. We evaluate MVD on the dataset which contains 4,353 real-world memory-related vulnerabilities, and compare our approach with three state-of-the-art deep learning-based approaches as well as five popular static analysis-based memory detectors. The experiment results show that MVD achieves better detection accuracy, outperforming both state-of-the-art DL-based and static analysis-based approaches. Furthermore, MVD makes a great trade-off between accuracy and efficiency. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133519100&doi=10.1145%2f3510003.3510219&partnerID=40&md5=1f1c9a8b53c4e5850c9714d51db35d49,Proceedings - International Conference on Software Engineering,Include,,,
Cao S.; Sun X.; Bo L.; Wei Y.; Li B.,BGNN4VD: Constructing Bidirectional Graph Neural-Network for Vulnerability Detection,"Context: Previous studies have shown that existing deep learning-based approaches can significantly improve the performance of vulnerability detection. They represent code in various forms and mine vulnerability features with deep learning models. However, the differences of code representation forms and deep learning models make various approaches still have some limitations. In practice, their false-positive rate (FPR) and false-negative rate (FNR) are still high. Objective: To address the limitations of existing deep learning-based vulnerability detection approaches, we propose BGNN4VD (Bidirectional Graph Neural Network for Vulnerability Detection), a vulnerability detection approach by constructing a Bidirectional Graph Neural-Network (BGNN). Method: In Phase 1, we extract the syntax and semantic information of source code through abstract syntax tree (AST), control flow graph (CFG), and data flow graph (DFG). Then in Phase 2, we use vectorized source code as input to Bidirectional Graph Neural-Network (BGNN). In Phase 3, we learn the different features between vulnerable code and non-vulnerable code by introducing backward edges on the basis of traditional Graph Neural-Network (GNN). Finally in Phase 4, a Convolutional Neural-Network (CNN) is used to further extract features and detect vulnerabilities through a classifier. Results: We evaluate BGNN4VD on four popular C/C++ projects from NVD and GitHub, and compare it with four state-of-the-art (Flawfinder, RATS, SySeVR, and VUDDY) vulnerab ility detection approaches. Experiment results show that, when compared these baselines, BGNN4VD achieves 4.9%, 11.0%, and 8.4% improvement in F1-measure, accuracy and precision, respectively. Conclusion: The proposed BGNN4VD achieves a higher precision and accuracy than the state-of-the-art methods. In addition, when applied on the latest vulnerabilities reported by CVE, BGNN4VD can still achieve a precision at 45.1%, which demonstrates the feasibility of BGNN4VD in practical application. © 2021",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103334174&doi=10.1016%2fj.infsof.2021.106576&partnerID=40&md5=649f46166db76c21002626593f04ce4b,Information and Software Technology,Include,,,
Song Z.; Wang J.; Liu S.; Fang Z.; Yang K.,HGVul: A Code Vulnerability Detection Method Based on Heterogeneous Source-Level Intermediate Representation,"Vulnerability detection on source code can prevent the risk of cyber-attacks as early as possible. However, lacking fine-grained analysis of the code has rendered the existing solutions still suffering from low performance; besides, the explosive growth of open-source projects has dramatically increased the complexity and diversity of the source code. This paper presents HGVul, a code vulnerability detection method based on heterogeneous intermediate representation of source code. The key of the proposed method is the fine-grained handling on heterogeneous source-level intermediate representation (SIR) without expert knowledge. It first extracts graph SIR of code with multiple syntactic-semantic information. Then, HGVul splits the SIR into different subgraphs according to various semantic relations, which are used to obtain semantic information conveyed by different types of edges. Next, a graph neural network with attention operations is deployed on each subgraph to learn representation, which captures the subtle effects from node neighbors on their representation. Finally, the learned code feature representations are utilized to perform vulnerability detection. Experiments are conducted on multiple datasets. The F1 of HGVul reaches 96.1% on the sample-balanced Big-Vul-VP dataset and 88.3% on the unbalanced Big-Vul dataset. Further experiments on actual open-source project datasets prove the better performance of HGVul.  © 2022 Zihua Song et al.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129314783&doi=10.1155%2f2022%2f1919907&partnerID=40&md5=acfe9a476db18fb89687d385fa8fdd90,Security and Communication Networks,Include,,,
Ding Y.; Suneja S.; Zheng Y.; Laredo J.; Morari A.; Kaiser G.; Ray B.,VELVET: A noVel Ensemble Learning approach to automatically locate VulnErable sTatements,"Automatically locating vulnerable statements in source code is crucial to assure software security and alleviate developers' debugging efforts. This becomes even more important in today's software ecosystem, where vulnerable code can flow easily and unwittingly within and across software repositories like GitHub. Across such millions of lines of code, traditional static and dynamic approaches struggle to scale. Although existing machine-learning-based approaches look promising in such a setting, most work detects vulnerable code at a higher granularity - at the method or file level. Thus, developers still need to inspect a significant amount of code to locate the vulnerable statement(s) that need to be fixed. This paper presents Velvet, a novel ensemble learning approach to locate vulnerable statements. Our model combines graph-based and sequence-based neural networks to successfully capture the local and global context of a program graph and effectively understand code semantics and vulnerable patterns. To study Velvet's effectiveness, we use an off-the-shelf synthetic dataset and a recently published real-world dataset. In the static analysis setting, where vulnerable functions are not detected in advance, Velvet achieves 4.5× better performance than the baseline static analyzers on the real-world data. For the isolated vulnerability localization task, where we assume the vulnerability of a function is known while the specific vulnerable statement is unknown, we compare Velvet with several neural networks that also attend to local and global context of code. Velvet achieves 99.6% and 43.6% top-1 accuracy over synthetic data and real-world data, respectively, outperforming the baseline deep learning models by 5.3-29.0%.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127031754&doi=10.1109%2fSANER53432.2022.00114&partnerID=40&md5=52f8fa0cd17e6cd221bc2a6f6b90c2e5,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",Include,,,
Nguyen V.-A.; Nguyen D.Q.; Nguyen V.; Le T.; Tran Q.H.; Phung D.,ReGVD: Revisiting Graph Neural Networks for Vulnerability Detection,"Identifying vulnerabilities in the source code is essential to protect the software systems from cyber security attacks. It, however, is also a challenging step that requires specialized expertise in security and code representation. To this end, we aim to develop a general, practical, and programming language-independent model capable of running on various source codes and libraries without difficulty. Therefore, we consider vulnerability detection as an inductive text classification problem and propose ReGVD, a simple yet effective graph neural network-based model for the problem. In particular, ReGVD views each raw source code as a flat sequence of tokens to build a graph, wherein node features are initialized by only the token embedding layer of a pre-trained programming language (PL) model. ReGVD then leverages residual connection among GNN layers and examines a mixture of graph-level sum and max poolings to return a graph embedding for the source code. ReGVD outperforms the existing state-of-the-art models and obtains the highest accuracy on the real-world benchmark dataset from CodeXGLUE for vulnerability detection. Our code is available at: https://github.com/daiquocnguyen/GNN-ReGVD. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128155921&doi=10.1109%2fICSE-Companion55297.2022.9793807&partnerID=40&md5=ead1f06fa683209f9301b928840b5491,Proceedings - International Conference on Software Engineering,Include,,,
Wu T.; Chen L.; Du G.; Zhu C.; Cui N.; Shi G.,Inductive Vulnerability Detection via Gated Graph Neural Network,"Vulnerability detection is an essential means to ensure the normal operation of various software tools and system security. The Recurrent Neural Networks (RNNs) have achieved remarkable results in vulnerability detection, but the sequence-based code representation has great limitations in feature expression and propagation. In this paper, we propose a fine-grained code vulnerability detection framework based on Gated Graph Neural Network (GGNN). Firstly, we process the source code into fine-grained slices. Secondly, graph embedding of code slices is constructed by clustering neighborhood information. Finally, GGNN is used to learn the syntax and semantic information of vulnerability codes for graph-level classification. Furthermore, we theoretically analyze that GGNN has a strong inductive learning ability. This means that the model requires only a small amount of training data to obtain sufficient advanced features, which is significant for vulnerability detection tasks that are difficult to collect data sets. We carry out conventional experiments and inductive experiments with manually collected data sets, and the results show that the framework is superior to RNNs in vulnerability detection performance. Moreover, our framework performs better than RNNs under inductive conditions. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130846469&doi=10.1109%2fCSCWD54268.2022.9776051&partnerID=40&md5=6896f26785fbfbf10fba33ae7844bd52,"2022 IEEE 25th International Conference on Computer Supported Cooperative Work in Design, CSCWD 2022",Include,,,
Qian J.; Ju X.; Chen X.; Shen H.; Shen Y.,AGFL: A Graph Convolutional Neural Network-Based Method for Fault Localization,"Fault localization techniques have been developed for decades. Spectrum Based Fault Localization (SBFL) is a popular strategy in this research topic. However, SBFL is well known for low accuracy, mainly due to simply using a coverage matrix of program executions. In this paper, we propose a method based on graph neural network (AGFL), characterized by the adjacent matrix of the abstract syntax tree and the word vector of each program token. Referring to the Dstar, we calculate the suspiciousness of the statements and rank these statements. The experiment carried on Defects4J, a widely used benchmark, reveals that AGFL can locate 178 of the 262 studied bugs within Top-1, while state-of-the-art techniques at most locate 148 within Top-1. We also investigate the impacts of hyper-parameters (e.g., epoch and learning rate). The results show that AGFL has the best effect when the epoch is 100 and the learning rate is 0.0001. This value of epoch and learning rate increases by 66% compared to the worst on Top-1. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138900023&doi=10.1109%2fQRS54544.2021.00077&partnerID=40&md5=4d8c8936839e1d46ec0184447d0afc82,"IEEE International Conference on Software Quality, Reliability and Security, QRS",Include,,Include,
Wu Y.; Lu J.; Zhang Y.; Jin S.,Vulnerability Detection in C/C++ Source Code with Graph Representation Learning,"An open challenge in software vulnerability detection is how to identify potential vulnerabilities of source code at a fine-grained level automatically. This paper proposes an approach to automate vulnerability detection in source code at the software function level based on graph representation learning without the efforts of security experts. The proposed approach firstly represents software functions as Simplified Code Property Graphs (SCPG), which can conserve syntactic and semantic information of source code while keeping itself small enough for computing. It then utilizes graph neural network and multi layer perceptrons to learn graph representations and extract features automatically, saving efforts of feature engineering. The comparison experiments demonstrate the effectiveness of the proposed approach. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103439913&doi=10.1109%2fCCWC51732.2021.9376145&partnerID=40&md5=a7e6b3ad521d4c8c52f4acfa3f048dbd,"2021 IEEE 11th Annual Computing and Communication Workshop and Conference, CCWC 2021",Include,,,
Zheng W.; Jiang Y.; Su X.,Vu1SPG: Vulnerability detection based on slice property graph representation learning,"Vulnerability detection is an important issue in software security. Although various data-driven vulnerability detection methods have been proposed, the task remains challenging since the diversity and complexity of real-world vulnerable code in syntax and semantics make it difficult to extract vulnerable features with regular deep learning models, especially in analyzing a large program. Moreover, the fact that real-world vulnerable codes contain a lot of redundant information unrelated to vulnerabilities will further aggravate the above problem. To mitigate such challenges, we define a novel code representation named Slice Property Graph (SPG), and then propose VulSPG, a new vulnerability detection approach using the improved R-GCN model with triple attention mechanism to identify potential vulnerabilities in SPG. Our approach has at least two advantages over other methods. First, our proposed SPG can reflect the rich semantics and explicit structural information that may be relevance to vulnerabilities, while eliminating as much irrelevant information as possible to reduce the complexity of graph. Second, VulSPG incorporates triple attention mechanism in R-GCNs to achieve more effective learning of vulnerability patterns from SPG. We have extensively evaluated VulSPG on two large-scale datasets with programs from SARD and real-world projects. Experimental results prove the effectiveness and efficiency of VulSPG.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126394310&doi=10.1109%2fISSRE52982.2021.00054&partnerID=40&md5=43007b746f7d6abcaf08fab52274f36d,"Proceedings - International Symposium on Software Reliability Engineering, ISSRE",Include,,,
Choi Y.; Kwon Y.-W.,Comparison of Program Representations on Vulnerability Detection with Graph Neural Networks,"As software vulnerabilities have surged, efforts to discover them have increased. The syntactic and semantic information of a program is required to detect vulnerabilities. Each information can be represented as a graph, such as Abstract Syntax Tree and Program Dependency Graph. In this paper, the program representations were extracted using various static analysis tools, including Clang Static Analyzer, Joern, and SVF, and compared using Graph Neural Networks to select the appropriate representations for vulnerability detection in C/C++. From the comparison, PDG shows the best performance among the multiple representations. This result indicates a suitable program representation and a tool for vulnerability detection that can be utilized in research utilizing graph neural networks. Copyrights © 2021 The Institute of Electronics and Information Engineer",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123220765&doi=10.5573%2fIEIESPC.2021.10.6.477&partnerID=40&md5=110a3b6e3ca352a0bd3587b3875497a6,IEIE Transactions on Smart Processing and Computing,Include,,Include,
Xia X.; Wang Y.; Yang Y.,Source Code Vulnerability Detection Based on SAR-GIN,"With the development of the Internet era, software technology is being used more and more commonly, and the detection of vulnerabilities in the corresponding software must be efficient and accurate. However, software vulnerabilities are diverse, and mining vulnerabilities through source code requires a high level of professional experience for developers. Previous vulnerability detection solutions either relied on expert-defined features or used recursive neural networks only for code sequences, making it difficult to extract complex features of vulnerabilities in the traditional code space. In recent years, with the booming development of artificial intelligence technology, some scholars have started to try to combine graph neural networks to extract graph structure information of source code for software vulnerability detection. In this paper, by introducing a method based on Graph Isomorphism Network (GIN) combined with a self-attention aggregation mechanism for vulnerability detection, we achieve superior detection results. By assigning different attention weights to each layer, the self-attention mechanism helps to solve the problem of too smooth node representation and poor comprehensive performance of graph-level output. In this paper, we propose Self Attention Readout Graph Isomorphism Network (SAR-GIN), which efficiently extracts and utilizes global information at all depths by combining GIN with a self-attention mechanism in generating global graph-level features. Meanwhile, the experimental results on CWE-400, CWE-190 datasets, combined with the discrete Fourier transform, show that the modeling approach in this paper achieves superior results compared to other models.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128636129&doi=10.1109%2fCECIT53797.2021.00202&partnerID=40&md5=a8ed7158323cb10544edad6bc36b66ec,"Proceedings - 2021 2nd International Conference on Electronics, Communications and Information Technology, CECIT 2021",Include,,,
Cheng X.; Wang H.; Hua J.; Xu G.; Sui Y.,DeepWukong: Statically Detecting Software Vulnerabilities Using Deep Graph Neural Network,"Static bug detection has shown its effectiveness in detecting well-defined memory errors, e.g., memory leaks, buffer overflows, and null dereference. However, modern software systems have a wide variety of vulnerabilities. These vulnerabilities are extremely complicated with sophisticated programming logic, and these bugs are often caused by different bad programming practices, challenging existing bug detection solutions. It is hard and labor-intensive to develop precise and efficient static analysis solutions for different types of vulnerabilities, particularly for those that may not have a clear specification as the traditional well-defined vulnerabilities. This article presents DeepWukong, a new deep-learning-based embedding approach to static detection of software vulnerabilities for C/C++ programs. Our approach makes a new attempt by leveraging advanced recent graph neural networks to embed code fragments in a compact and low-dimensional representation, producing a new code representation that preserves high-level programming logic (in the form of control-and data-flows) together with the natural language information of a program. Our evaluation studies the top 10 most common C/C++ vulnerabilities during the past 3 years. We have conducted our experiments using 105,428 real-world programs by comparing our approach with four well-known traditional static vulnerability detectors and three state-of-the-art deep-learning-based approaches. The experimental results demonstrate the effectiveness of our research and have shed light on the promising direction of combining program analysis with deep learning techniques to address the general static code analysis challenges.  © 2021 ACM.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105713814&doi=10.1145%2f3436877&partnerID=40&md5=f2f88288533288e48de75486035787b6,ACM Transactions on Software Engineering and Methodology,Include,,,
Li Y.; Wang S.; Nguyen T.,Fault localization with code coverage representation learning,"In this paper, we propose DeepRL4FL, a deep learning fault localization (FL) approach that locates the buggy code at the statement and method levels by treating FL as an image pattern recognition problem. DeepRL4FL does so via novel code coverage representation learning (RL) and data dependencies RL for program statements. Those two types of RL on the dynamic information in a code coverage matrix are also combined with the code representation learning on the static information of the usual suspicious source code. This combination is inspired by crime scene investigation in which investigators analyze the crime scene (failed test cases and statements) and related persons (statements with dependencies), and at the same time, examine the usual suspects who have committed a similar crime in the past (similar buggy code in the training data). For the code coverage information, DeepRL4FL first orders the test cases and marks error-exhibiting code statements, expecting that a model can recognize the patterns discriminating between faulty and non-faulty statements/methods. For dependencies among statements, the suspiciousness of a statement is seen taking into account the data dependencies to other statements in execution and data flows, in addition to the statement by itself. Finally, the vector representations for code coverage matrix, data dependencies among statements, and source code are combined and used as the input of a classifier built from a Convolution Neural Network to detect buggy statements/methods. Our empirical evaluation shows that DeepRL4FL improves the top-1 results over the state-of-the-art statement-level FL baselines from 173.1% to 491.7%. It also improves the top-1 results over the existing method-level FL baselines from 15.0% to 206.3%.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115690270&doi=10.1109%2fICSE43902.2021.00067&partnerID=40&md5=737eed969785228e7fac690efc32c8fd,Proceedings - International Conference on Software Engineering,Include,,Include,
Sun H.; Tong Y.; Zhao J.; Gu Z.,DVul-WLG: Graph Embedding Network Based on Code Similarity for Cross-Architecture Firmware Vulnerability Detection,"Vulnerabilities in the firmware of embedded devices have led to many IoT security incidents. Embedded devices have multiple architectures and the firmware source code of embedded devices is difficult to obtain, which makes it difficult to detect firmware vulnerabilities. In this paper, we propose a neural network model called DVul-WLG for cross-architecture firmware vulnerability detection. This model analyzes the similarity between the binary function of the vulnerability and the binary function of the firmware to determine whether the firmware contains the vulnerability. The similarity between functions is calculated by comparing the features of the attribute control flow graph (ACFG) of the functions. DVul-WLG uses Word2vec, LSTM (Long Short-Term Memory) and an improved graph convolutional neural network (GCN) to extract the features of ACFG. This model embeds instructions of different architectures into the same space through canonical correlation analysis (CCA), and expresses instructions of different architectures in the form of intermediate vectors. In this way, the heterogeneity of architectures can be ignored when comparing cross-architecture similarity. We compared DVul-WLG with the advanced method FIT and the basic method Gemini through experiments. Experiments show that DVul-WLG has a higher AUC (Area Under the Curve) value. We also detected vulnerabilities in the real firmware. The accuracy of DVul-WLG is 89%, while FIT and Gemini are 78% and 73%, respectively. © 2021, Springer Nature Switzerland AG.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121869477&doi=10.1007%2f978-3-030-91356-4_17&partnerID=40&md5=86945b8e7c1bb89a48e2e84b2fb63e97,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Rabheru R.; Hanif H.; Maffeis S.,DeepTective: Detection of PHP vulnerabilities using hybrid graph neural networks,"This paper presents DeepTective, a deep learning-based approach to detect vulnerabilities in PHP source code. DeepTective implements a novel hybrid technique that combines Gated Recurrent Units and Graph Convolutional Networks to detect SQLi, XSS and OSCI vulnerabilities leveraging both syntactic and semantic information. Experimental results show that our model outperformed related solutions on both synthetic and realistic datasets, and was able to discover 4 novel vulnerabilities in established WordPress plugins. © 2021 Owner/Author.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100455359&doi=10.1145%2f3412841.3442132&partnerID=40&md5=1370ecafe97d6cc5c719ae62f9a97786,Proceedings of the ACM Symposium on Applied Computing,Include,,Include,
Wang L.; Li X.; Wang R.; Xin Y.; Gao M.; Chen Y.,Prennsem: A heterogeneous ensemble learning framework for vulnerability detection in software,"Automated vulnerability detection is one of the critical issues in the realm of software security. Existing solutions to this problem are mostly based on features that are defined by human experts and directly lead to missed potential vulnerability. Deep learning is an effective method for automating the extraction of vulnerability characteristics. Our paper proposes intelligent and automated vulnerability detection while using deep representation learning and heterogeneous ensemble learning. Firstly, we transform sample data from source code by removing segments that are unrelated to the vulnerability in order to reduce code analysis and improve detection efficiency in our experiments. Secondly, we represent the sample data as real vectors by pre-training on the corpus and maintaining its semantic information. Thirdly, the vectors are fed to a deep learning model to obtain the features of vulnerability. Lastly, we train a heterogeneous ensemble classifier. We analyze the effectiveness and resource consumption of different network models, pre-training methods, classifiers, and vulnerabilities separately in order to evaluate the detection method. We also compare our approach with some well-known vulnerability detection commercial tools and academic methods. The experimental results show that our proposed method provides improvements in false positive rate, false negative rate, precision, recall, and F1 score. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096027213&doi=10.3390%2fapp10227954&partnerID=40&md5=03bc504a1a2f1180eaeade249a8e409a,Applied Sciences (Switzerland),Include,,,
Zhang Y.; Liu X.; Du D.,Static detection of vulnerabilities via graph attention hierarchically,"With the rapid growth of the software industry, the risks of vulnerabilities are inevitably increasing. Deep learning based methods have been widely used in vulnerability detection in recent years. Since the inherent graph structure of source code contains rich semantics, many deep learning works have exploited graph neural networks to enhance code representation. Despite their novel design, learning the structural information in the graph hierarchically and focusing on important nodes are still problems to better capture vulnerability semantics. To tackle this bottleneck, we propose a novel neural model for vulnerability detection. A SAGPool module is designed to automatically chooses important nodes to retain hierarchically in each graph convolution layer. Our model is trained and tested over the REVEAL dataset built on two popular and well-maintained open-source projects. The experimental results demonstrate that our model outperforms the state-of-the-art methods. © 2021 11th International Workshop on Computer Science and Engineering, WCSE 2021. All Rights Reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114202299&doi=10.18178%2fwcse.2021.06.002&partnerID=40&md5=6d5bf4b6f0666309c54e4ed8eca9d669,"2021 11th International Workshop on Computer Science and Engineering, WCSE 2021",Include,,,
Feng Q.; Feng C.; Hong W.,Graph Neural Network-based Vulnerability Predication,"Automatic vulnerability detection is challenging. In this paper, we report our in-progress work of vulnerability prediction based on graph neural network (GNN). We propose a general GNN-based framework for predicting the vulnerabilities in program functions. We study the different instantiations of the framework in representative program graph representations, initial node encodings, and GNN learning methods. The preliminary experimental results on a representative benchmark indicate that the GNN-based method can improve the accuracy and recall rates of vulnerability prediction. © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096658254&doi=10.1109%2fICSME46990.2020.00096&partnerID=40&md5=c5b9c0290496d31a4e99dd5ec5ba325a,"Proceedings - 2020 IEEE International Conference on Software Maintenance and Evolution, ICSME 2020",Include,,,
Zeng J.; Nie X.; Chen L.; Li J.; Du G.; Shi G.,An efficient vulnerability extrapolation using similarity of graph kernel of PDGs,"Discovering the potential vulnerabilities in software plays a crucial role in ensuring the security of computer system. This paper proposes a method that can assist security auditors with the analysis of source code. When security auditors identify new vulnerabilities, our method can be adopted to make a list of recommendations that may have the same vulnerabilities for the security auditors. Our method relies on graph representation to automatically extract the mode of PDG(program dependence graph, a structure composed of control dependence and data dependence). Besides, it can be applied to the vulnerability extrapolation scenario, thus reducing the amount of audit code. We worked on an open-source vulnerability test set called Juliet. According to the evaluation results, the clustering effect produced is satisfactory, so that the feature vectors extracted by the Graph2Vec model are applied to labeling and supervised learning indicators are adopted to assess the model for its ability to extract features. On a total of 12, 000 small data sets, the training score of the model can reach up to 99.2%, and the test score can reach a maximum of 85.2%. Finally, the recommendation effect of our work is verified as satisfactory. © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101273031&doi=10.1109%2fTrustCom50675.2020.00229&partnerID=40&md5=9f0915ad6ce62a2cf52be8a097ca8ed3,"Proceedings - 2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications, TrustCom 2020",Include,,,
Li X.; Wang L.; Xin Y.; Yang Y.; Chen Y.,Automated vulnerability detection in source code using minimum intermediate representation learning,"Vulnerability is one of the root causes of network intrusion. An effective way to mitigate security threats is to discover and patch vulnerabilities before an attack. Traditional vulnerability detection methods rely on manual participation and incur a high false positive rate. The intelligent vulnerability detection methods suffer from the problems of long-term dependence, out of vocabulary, coarse detection granularity and lack of vulnerable samples. This paper proposes an automated and intelligent vulnerability detection method in source code based on the minimum intermediate representation learning. First, the sample in the form of source code is transformed into a minimum intermediate representation to exclude the irrelevant items and reduce the length of the dependency. Next, the intermediate representation is transformed into a real value vector through pre-training on an extended corpus, and the structure and semantic information are retained. Then, the vector is fed to three concatenated convolutional neural networks to obtain high-level features of vulnerability. Last, a classifier is trained using the learned features. To validate this vulnerability detection method, an experiment was performed. The empirical results confirmed that compared with the traditional methods and the state-of-the-art intelligent methods, our method has a better performance with fine granularity. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081957445&doi=10.3390%2fapp10051692&partnerID=40&md5=3ea74372a9c82ab89172ae353a2d7f60,Applied Sciences (Switzerland),Include,,,
Zhou Y.; Liu S.; Siow J.; Du X.; Liu Y.,Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks,"Vulnerability identification is crucial to protect the software systems from attacks for cyber security. It is especially important to localize the vulnerable functions among the source code to facilitate the fix. However, it is a challenging and tedious process, and also requires specialized security expertise. Inspired by the work on manually-defined patterns of vulnerabilities from various code representation graphs and the recent advance on graph neural networks, we propose Devign, a general graph neural network based model for graph-level classification through learning on a rich set of code semantic representations. It includes a novel Conv module to efficiently extract useful features in the learned rich node representations for graph-level classification. The model is trained over manually labeled datasets built on 4 diversified large-scale open-source C projects that incorporate high complexity and variety of real source code instead of synthesis code used in previous works. The results of the extensive evaluation on the datasets demonstrate that Devign outperforms the state of the arts significantly with an average of 10.51% higher accuracy and 8.68% F1 score, increases averagely 4.66% accuracy and 6.37% F1 by the Conv module. © 2019 Neural information processing systems foundation. All rights reserved.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089940996&partnerID=40&md5=360e4ac4b80f50a82fbee08b6e8712d6,Advances in Neural Information Processing Systems,Include,,Include,
Morgachev G.; Ignatyev V.; Belevantsev A.,Detection of variable misuse using static analysis combined with machine learning,"Industrial static analyzers are able to detect only several narrow classes of algorithmic errors, for example actual arguments order swapped with formal parameters, forgotten renaming of variable after copy-paste. However, even for these categories essential part of errors is lost because of heuristical design of a checker. We propose the generalization of specified errors in the form of variable misuse problem and deal with it using machine learning. The proposed method uses message propagation through the program model represented as a graph, combining data from multiple analysis levels, including AST, dataflow. We introduce several error criteria, which were evaluated on the set of open source projects with millions of LoC. Testing in close to industrial conditions shows good false positive and missed errors ratio comparable with remaining detectors and allows to include developed checker (after a minor rework) into a general purpose production static analyzer for error detection. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081319485&doi=10.1109%2fISPRAS47671.2019.00009&partnerID=40&md5=c20c1b1eee9c4f56e23317ce1c8773fb,"Proceedings - 2019 Ivannikov Ispras Open Conference, ISPRAS 2019",Include,,Include,
Wang H.; Ye G.; Tang Z.; Tan S.H.; Huang S.; Fang D.; Feng Y.; Bian L.; Wang Z.,Combining Graph-Based Learning with Automated Data Collection for Code Vulnerability Detection,"This paper presents FUNDED (Flow-sensitive vUl-Nerability coDE Detection), a novel learning framework for building vulnerability detection models. Funded leverages the advances in graph neural networks (GNNs) to develop a novel graph-based learning method to capture and reason about the program's control, data, and call dependencies. Unlike prior work that treats the program as a sequential sequence or an untyped graph, Funded learns and operates on a graph representation of the program source code, in which individual statements are connected to other statements through relational edges. By capturing the program syntax, semantics and flows, Funded finds better code representation for the downstream software vulnerability detection task. To provide sufficient training data to build an effective deep learning model, we combine probabilistic learning and statistical assessments to automatically gather high-quality training samples from open-source projects. This provides many real-life vulnerable code training samples to complement the limited vulnerable code samples available in standard vulnerability databases. We apply Funded to identify software vulnerabilities at the function level from program source code. We evaluate Funded on large real-world datasets with programs written in C, Java, Swift and Php, and compare it against six state-of-the-art code vulnerability detection models. Experimental results show that Funded significantly outperforms alternative approaches across evaluation settings. © 2005-2012 IEEE.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098786569&doi=10.1109%2fTIFS.2020.3044773&partnerID=40&md5=38482a134182eb97d899b34ee5f5e116,IEEE Transactions on Information Forensics and Security,Include,,,
Liu S.; Lin G.; Han Q.-L.; Wen S.; Zhang J.; Xiang Y.,DeepBalance: Deep-Learning and Fuzzy Oversampling for Vulnerability Detection,"Software vulnerability has long been an important but critical research issue in cybersecurity. Recently, the machine learning (ML)-based approach has attracted increasing interest in the research of software vulnerability detection. However, the detection performance of existing ML-based methods require further improvement. There are two challenges: one is code representation for ML and the other is class imbalance between vulnerable code and nonvulnerable code. To overcome these challenges, this article develops a DeepBalance system, which combines the new ideas of deep code representation learning and fuzzy-based class rebalancing. We design a deep neural network with bidirectional long short-term memory to learn invariant and discriminative code representations from labeled vulnerable and nonvulnerable code. Then, a new fuzzy oversampling method is employed to rebalance the training data by generating synthetic samples for the class of vulnerable code. To evaluate the performance of the new system, we carry out a series of experiments in a real-world ground-truth dataset that consists of the code from the projects of LibTIFF, LibPNG, and FFmpeg. The results show that the proposed new system can significantly improve the vulnerability detection performance. For example, the improvement is 15% in terms of F-measure. © 1993-2012 IEEE.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087818690&doi=10.1109%2fTFUZZ.2019.2958558&partnerID=40&md5=1d6e91446ab3e47e3b789368129fd877,IEEE Transactions on Fuzzy Systems,Include,,,
Russell R.; Kim L.; Hamilton L.; Lazovich T.; Harer J.; Ozdemir O.; Ellingwood P.; McConley M.,Automated Vulnerability Detection in Source Code Using Deep Representation Learning,"Increasing numbers of software vulnerabilities are discovered every year whether they are reported publicly or discovered internally in proprietary code. These vulnerabilities can pose serious risk of exploit and result in system compromise, information leaks, or denial of service. We leveraged the wealth of C and C++ open-source code available to develop a largescale function-level vulnerability detection system using machine learning. To supplement existing labeled vulnerability datasets, we compiled a vast dataset of millions of open-source functions and labeled it with carefully-selected findings from three different static analyzers that indicate potential exploits. Using these datasets, we developed a fast and scalable vulnerability detection tool based on deep feature representation learning that directly interprets lexed source code. We evaluated our tool on code from both real software packages and the NIST SATE IV benchmark dataset. Our results demonstrate that deep feature representation learning on source code is a promising approach for automated software vulnerability detection. © 2018 IEEE.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062238891&doi=10.1109%2fICMLA.2018.00120&partnerID=40&md5=8615995e948557980d3ccd0c31eb28e4,"Proceedings - 17th IEEE International Conference on Machine Learning and Applications, ICMLA 2018",Include,,,
Lin G.; Zhang J.; Luo W.; Pan L.; Xiang Y.,Poster: Vulnerability discovery with function representation learning from unlabeled projects,"In cybersecurity, vulnerability discovery in source code is a fundamental problem. To automate vulnerability discovery, Machine learning (ML) based techniques has attracted tremendous attention. However, existing ML-based techniques focus on the component or file level detection, and thus considerable human effort is still required to pinpoint the vulnerable code fragments. Using source code files also limit the generalisability of the ML models across projects. To address such challenges, this paper targets at the function-level vulnerability discovery in the cross-project scenario. A function representation learning method is proposed to obtain the high-level and generalizable function representations from the abstract syntax tree (AST). First, the serialized ASTs are used to learn project independence features. Then, a customized bi-directional LSTM neural network is devised to learn the sequential AST representations from the large number of raw features. The new function-level representation demonstrated promising performance gain, using a unique dataset where we manually labeled 6000+ functions from three open-source projects. The results confirm that the huge potential of the new AST-based function representation learning. © 2017 author(s).",Conference paper,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041433336&doi=10.1145%2f3133956.3138840&partnerID=40&md5=8b6e92bb5d8442d175adc77d8de43b50,Proceedings of the ACM Conference on Computer and Communications Security,Include,Exclude,Exclude,
Noel S.; Jajodia S.; O'Berry B.; Jacobs M.,Efficient minimum-cost network hardening via exploit dependency graphs,"In-depth analysis of network security vulnerability must consider attacker exploits not just in isolation, but also in combination. The general approach to this problem is to compute attack paths (combinations of exploits), from which one can decide whether a given set of network hardening measures guarantees the safety of given critical resources. We go beyond attack paths to compute actual sets of hardening measures (assignments of initial network conditions) that guarantee the safety of given critical resources. Moreover, for given costs associated with individual hardening measures, we compute assignments that minimize overall cost. By doing our minimization at the level of initial conditions rather than exploits, we resolve hardening irrelevancies and redundancies in a way that cannot be done through previously proposed exploit-level approaches. Also, we use an efficient exploit-dependency representation based on monotonic logic that has polynomial complexity, as opposed to many previous attack graph representations having exponential complexity. © 2003 IEEE.",Conference paper,2003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944727025&doi=10.1109%2fCSAC.2003.1254313&partnerID=40&md5=a2de5ffc4cdc08a263dc047539666f02,"Proceedings - Annual Computer Security Applications Conference, ACSAC",Exclude,,,
Wan M.; Liu K.,An improved eliminating SQL injection attacks based regular expressions matching,"Web applications have brought with them new classes of network security vulnerabilities, such as SQL Injection Attack. SQL Injection Attack is a class of attacks that many of the Web-based systems are highly vulnerable to, and there is no know fool-proof defense against such attacks. Static analysis is one of the techniques in defense of SQL Injection. In this paper, we propose an improved technique eliminates the need to modify source code of application scripts. The improved Eliminating SQL Injection Attacks technique bases the regular expressions instead of using SQL Graph representation using SQL-FSM in static analysis. © 2012 IEEE.",Conference paper,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874329400&doi=10.1109%2fICCECT.2012.235&partnerID=40&md5=27cc147ff8a37241620c5685f6174239,"Proceedings - 2012 International Conference on Control Engineering and Communication Technology, ICCECT 2012",Exclude,,,
Wang C.; Zhang L.; Zhang X.,Multi-grained contextual code representation learning for commit message generation,"Commit messages, precisely describing the code changes for each commit in natural language, makes it possible for developers and succeeding reviewers to understand the code changes without digging into implementation details. However, the semantic and structural gap between code and natural language poses a significant challenge for commit message generation. Several researchers have proposed automated techniques to generate commit messages. Nevertheless, the information about the code is not sufficiently exploited. In this paper, we propose multi-grained contextual code representation learning for commit message generation (COMU). We extract multi-grained information from the changed code at the line and AST levels (i.e., Code_Diff and AST_Diff). In Code_Diff, we construct global contextual semantic information about the changed code, and mark whether a line of code has changed with three different tokens. In AST_Diff, we extract the code structure from source code changes and combine the extracted structure with four types of editing operations to explicitly focus on the detailed information of the changed part. In addition, we build the experimental datasets, since there is still no publicly sufficient dataset for this task. The release of this dataset would contribute to advancing research in this field. We perform an extensive experiment to evaluate the effectiveness of COMU. The experimental evaluation and human study show that our model outperforms the baseline model. © 2023 Elsevier B.V.",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181049521&doi=10.1016%2fj.infsof.2023.107393&partnerID=40&md5=f2983b9a75a90ce016d168edd3b02f6a,Information and Software Technology,Exclude,,Include,
He Y.; Wang L.; Wang K.; Zhang Y.; Zhang H.; Li Z.,COME: Commit Message Generation with Modification Embedding,"Commit messages concisely describe code changes in natural language and are important for program comprehension and maintenance. Previous studies proposed some approaches for automatic commit message generation, but their performance is limited due to inappropriate representation of code changes and improper combination of translation-based and retrieval-based approaches. To address these problems, this paper introduces a novel framework named COME, in which modification embeddings are used to represent code changes in a fine-grained way, a self-supervised generative task is designed to learn contextualized code change representation, and retrieval-based and translation-based methods are combined through a decision algorithm. The average improvement of COME over the state-of-the-art approaches is 9.2% on automatic evaluation metrics and 8.0% on human evaluation metrics. We also analyse the effectiveness of COME's three main components and each of them results in an improvement of 8.6%, 8.7% and 5.2%.  © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167710827&doi=10.1145%2f3597926.3598096&partnerID=40&md5=b883dadfbb5393cdedf588457d62c203,ISSTA 2023 - Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis,Include,,,
Heričko T.,Automatic Data-Driven Software Change Identification via Code Representation Learning,"Changes to a software project are inevitable as the software requires continuous adaptations, improvements, and corrections throughout maintenance. Identifying the purpose and impact of changes made to the codebase is critical in software engineering. However, manually identifying and characterizing software changes can be a time-consuming and tedious process that adds to the workload of software engineers. To address this challenge, several attempts have been made to automatically identify and demystify intents of software changes based on software artifacts such as commit change logs, issue reports, change messages, source code files, and software documentation. However, these existing approaches have their limitations. These include a lack of data, limited performance, and an inability to evaluate compound changes. This paper presents a doctoral research proposal that aims to automate the process of identifying commit-level changes in software projects using software repository mining and code representation learning models. The research background, state-of-The-Art, research objectives, research agenda, and threats to validity are discussed.  © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162197083&doi=10.1145%2f3593434.3593505&partnerID=40&md5=62ad586a74bcf14c65dd7a362887bfc5,ACM International Conference Proceeding Series,Include,,,
Wang L.; Tang X.; He Y.; Ren C.; Shi S.; Yan C.; Li Z.,Delving into Commit-Issue Correlation to Enhance Commit Message Generation Models,"Commit message generation (CMG) is a challenging task in automated software engineering that aims to generate natural language descriptions of code changes for commits. Previous methods all start from the modified code snippets, outputting commit messages through template-based, retrieval-based, or learning-based models. While these methods can summarize what is modified from the perspective of code, they struggle to provide reasons for the commit. The correlation between commits and issues that could be a critical factor for generating rational commit messages is still unexplored. In this work, we delve into the correlation between commits and issues from the perspective of dataset and methodology. We construct the first dataset anchored on combining correlated commits and issues. The dataset consists of an unlabeled commit-issue parallel part and a labeled part in which each example is provided with human-annotated rational information in the issue. Furthermore, we propose ExGroFi (Extraction, Grounding, Ene-tuning), a novel paradigm that can introduce the correlation between commits and issues into the training phase of models. To evaluate whether it is effective, we perform comprehensive experiments with various state-of-the-art CMG models. The results show that compared with the original models, the performance of ExGroFi-enhanced models is significantly improved.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179013679&doi=10.1109%2fASE56229.2023.00050&partnerID=40&md5=c85aef858b594a67f8220592f4171414,"Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023",Include,,,
Liu Z.; Tang Z.; Xia X.; Yang X.,CCRep: Learning Code Change Representations via Pre-Trained Code Model and Query Back,"Representing code changes as numeric feature vectors, i.e., code change representations, is usually an essential step to automate many software engineering tasks related to code changes, e.g., commit message generation and just-in-time defect prediction. Intuitively, the quality of code change representations is crucial for the effectiveness of automated approaches. Prior work on code changes usually designs and evaluates code change representation approaches for a specific task, and little work has investigated code change encoders that can be used and jointly trained on various tasks. To fill this gap, this work proposes a novel Code Change Representation learning approach named CCRep, which can learn to encode code changes as feature vectors for diverse downstream tasks. Specifically, CCRep regards a code change as the combination of its before-change and after-change code, leverages a pre-trained code model to obtain high-quality contextual embeddings of code, and uses a novel mechanism named query back to extract and encode the changed code fragments and make them explicitly interact with the whole code change. To evaluate CCRep and demonstrate its applicability to diverse code-change-related tasks, we apply it to three tasks: commit message generation, patch correctness assessment, and just-in-time defect prediction. Experimental results show that CCRep outperforms the state-of-the-art techniques on each task. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171787263&doi=10.1109%2fICSE48619.2023.00014&partnerID=40&md5=eeec6477c1b78fed1aba08833e1d12f8,Proceedings - International Conference on Software Engineering,Include,,,
Zhang F.; Chen B.; Zhao Y.; Peng X.,Slice-Based Code Change Representation Learning,"Code changes are at the very core of software development and maintenance. Deep learning techniques have been used to build a model from a massive number of code changes to solve software engineering tasks, e.g., commit message generation and bug-fix commit identification. However, existing code change representation learning approaches represent code change as lexical tokens or syntactical AST (abstract syntax tree) paths, limiting the capability to learn semantics of code changes. Besides, they mostly do not consider noisy or tangled code change, hurting the accuracy of solved tasks. To address the above problems, we first propose a slice-based code change representation approach which considers data and control dependencies between changed code and unchanged code. Then, we propose a pre-trained sparse Transformer model, named CCS2VEC, to learn code change representations with three pre-training tasks. Our experiments by fine-tuning our pre-trained model on three downstream tasks have demonstrated the improvement of CCS2VEC over the state-of-the-art CC2VEC. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160563876&doi=10.1109%2fSANER56733.2023.00038&partnerID=40&md5=e44fc443ec0fa0c3f87ee88b0feecbe4,"Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",Include,,,
Zhang J.; Maddila C.; Bairi R.; Bird C.; Raizada U.; Agrawal A.; Jhawar Y.; Herzig K.; Van Deursen A.,Using Large-scale Heterogeneous Graph Representation Learning for Code Review Recommendations at Microsoft,"Code review is an integral part of any mature software development process, and identifying the best reviewer for a code change is a well-accepted problem within the software engineering community. Selecting a reviewer who lacks expertise and understanding can slow development or result in more defects. To date, most reviewer recommendation systems rely primarily on historical file change and review information; those who changed or reviewed a file in the past are the best positioned to review in the future.We posit that while these approaches are able to identify and suggest qualified reviewers, they may be blind to reviewers who have the needed expertise and have simply never interacted with the changed files before. Fortunately, at Microsoft, we have a wealth of work artifacts across many repositories that can yield valuable information about our developers. To address the aforementioned problem, we present Coral, a novel approach to reviewer recommendation that leverages a socio-technical graph built from the rich set of entities (developers, repositories, files, pull requests (PRs), work items, etc.) and their relationships in modern source code management systems. We employ a graph convolutional neural network on this graph and train it on two and a half years of history on 332 repositories within Microsoft.We show that Coral is able to model the manual history of reviewer selection remarkably well. Further, based on an extensive user study, we demonstrate that this approach identifies relevant and qualified reviewers who traditional reviewer recommenders miss, and that these developers desire to be included in the review process. Finally, we find that ""classical""reviewer recommendation systems perform better on smaller (in terms of developers) software projects while Coral excels on larger projects, suggesting that there is ""no one model to rule them all."" © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167921721&doi=10.1109%2fICSE-SEIP58684.2023.00020&partnerID=40&md5=a0274a779711b1042772bf9e7a85e888,Proceedings - International Conference on Software Engineering,Include,,Include,
Janke M.; Mader P.,Graph Based Mining of Code Change Patterns from Version Control Commits,"Detailed knowledge of frequently recurring code changes can be beneficial for a variety of software engineering activities. For example, it is a key step to understand the process of software evolution, but is also necessary when developing more sophisticated code completion features predicting likely changes. Previous attempts on automatically finding such code change patterns were mainly based on frequent itemset mining, which essentially finds sets of edits occurring in close proximity. However, these approaches do not analyze the interplay among code elements, e.g., two code objects being named similarly, and thereby neglect great potential in identifying a number of meaningful patterns. We present a novel method for the automated mining of code change patterns from Git repositories that captures these context relations between individual edits. Our approach relies on a transformation of source code into a graph representation, while keeping relevant relations present. We then apply graph mining techniques to extract frequent subgraphs, which can be used for further analysis of development projects. We suggest multiple usage scenarios for the resulting pattern type. Additionally, we propose a transformation into complex event processing (CEP) rules which allows for easier application, especially for event-based auto-completion recommenders or similar tools. For evaluation, we mined seven open-source code repositories. We present 25 frequent change patterns occurring across these projects. We found these patterns to be meaningful, easy to interpret and mostly persistent across project borders. On average, a pattern from our set appeared in 45 percent of the analyzed code changes. © 1976-2012 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087505021&doi=10.1109%2fTSE.2020.3004892&partnerID=40&md5=e76b830889769952391f6929bac2b9a4,IEEE Transactions on Software Engineering,Exclude,,,
Dong J.; Lou Y.; Zhu Q.; Sun Z.; Li Z.; Zhang W.; Hao D.,FIRA: Fine-Grained Graph-Based Code Change Representation for Automated Commit Message Generation,"Commit messages summarize code changes of each commit in nat-ural language, which help developers understand code changes without digging into detailed implementations and play an essen-tial role in comprehending software evolution. To alleviate human efforts in writing commit messages, researchers have proposed var-ious automated techniques to generate commit messages, including template-based, information retrieval-based, and learning-based techniques. Although promising, previous techniques have limited effectiveness due to their coarse-grained code change representations. This work proposes a novel commit message generation technique, FIRA, which first represents code changes via fine-grained graphs and then learns to generate commit messages automati-cally. Different from previous techniques, FIRA represents the code changes with fine-grained graphs, which explicitly describe the code edit operations between the old version and the new version, and code tokens at different granularities (i.e., sub-tokens and integral tokens). Based on the graph-based representation, FIRA generates commit messages by a generation model, which includes a graph-neural-network-based encoder and a transformer-based decoder. To make both sub-tokens and integral tokens as available ingredients for commit message generation, the decoder is further incorporated with a novel dual copy mechanism. We further per-form an extensive study to evaluate the effectiveness of FIRA. Our quantitative results show that FIRA outperforms state-of-the-art techniques in terms of BLEU, ROUGE-L, and METEOR; and our ablation analysis further shows that major components in our technique both positively contribute to the effectiveness of FIRA. In addition, we further perform a human study to evaluate the quality of generated commit messages from the perspective of developers, and the results consistently show the effectiveness of FIRA over the compared techniques. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133555793&doi=10.1145%2f3510003.3510069&partnerID=40&md5=0b410951296235c34ca7d23bcda92d56,Proceedings - International Conference on Software Engineering,Include,,,
Nie L.Y.; Gao C.; Zhong Z.; Lam W.; Liu Y.; Xu Z.,CoreGen: Contextualized Code Representation Learning for Commit Message Generation,"Automatic generation of high-quality commit messages for code commits can substantially facilitate software developers’ works and coordination. However, the semantic gap between source code and natural language poses a major challenge for the task. Several studies have been proposed to alleviate the challenge but none explicitly involves code contextual information during commit message generation. Specifically, existing research adopts static embedding for code tokens, which maps a token to the same vector regardless of its context. In this paper, we propose a novel Contextualized code representation learning strategy for commit message Generation (CoreGen). CoreGen first learns contextualized code representations which exploit the contextual information behind code commit sequences. The learned representations of code commits built upon Transformer are then fine-tuned for downstream commit message generation. Experiments on the benchmark dataset demonstrate the superior effectiveness of our model over the baseline models with at least 28.18% improvement in terms of BLEU-4 score. Furthermore, we also highlight the future opportunities in training contextualized code representations on larger code corpus as a solution to low-resource tasks and adapting the contextualized code representation framework to other code-to-text generation tasks. © 2021 Elsevier B.V.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109449734&doi=10.1016%2fj.neucom.2021.05.039&partnerID=40&md5=49a6f07c2732987fe2a592ea84cd3e03,Neurocomputing,Exclude,,Include,Exclude
Yousofvand L.; Soleimani S.; Rafe V.,Automatic bug localization using a combination of deep learning and model transformation through node classification,"Bug localization is the task of automatically locating suspicious commands in the source code. Many automated bug localization approaches have been proposed for reducing costs and speeding up the bug localization process. These approaches allow developers to focus on critical commands. In this paper, we propose to treat the bug localization problem as a node classification problem. As in the existing training sets, where whole graphs are labeled as buggy and bug-free, it is required first to label all nodes in each graph. To do this, we use the Gumtree algorithm, which labels the nodes by comparing the buggy graphs with their corresponding fixed graphs. In classification, we propose to use a type of graph neural networks (GNNs), GraphSAGE. The used dataset for training and testing is JavaScript buggy code and their corresponding fixed code. The results demonstrate that the proposed method outperforms other related methods. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150659552&doi=10.1007%2fs11219-023-09625-5&partnerID=40&md5=ca9ae9885894b791b4c68c220de3be7f,Software Quality Journal,Include,,,
Xu Z.; Lu K.; Sheng V.S.,Logic Error Localization and Correction with Machine Learning,"We aim to propose a system repairing programs with logic errors to be functionally correct among different programming languages. Logic error program repair has always been a thorny problem: First, a logic error is usually harder to repair than a syntax error in a program because it has no diagnostic feedback from compilers. Second, it requires inferring in different ranges (i.e., the distance of related code lines) and tracking symbols across its pseudocode, source code, and test cases. Third, the logic error datasets are scarce, since an ideal logic error dataset should contain lots of components during the development procedure of a program, including a program specification, pseudocode, source code, test cases, and test reports (i.e., test case failure report). In our work, we propose novel solutions to these challenges. First, we introduce pseudocode information to assist logic error localization and correction. We construct a code-pseudocode graph to connect symbols across a source code and its pseudocode and then apply a graph neural network to localize and correct logic errors. Second, we collect logic errors generated in the process of syntax error repairing via DrRepair from 500 programs in the SPoC dataset and reconstruct them to our single logic error dataset, which we leverage to train and evaluate our models. Our experimental results show that we achieve 99.39% localization accuracy and 19.20% full repair accuracy on logic errors with five-fold cross-validation. Based on our current work, we will replenish and construct more complete public logic error datasets and propose a novel system to comprehend different programming languages from several perspectives and correct logic errors to be functionally correct. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168252069&partnerID=40&md5=92f6a907b8224915ea20b1e8a8e10b1e,"Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",Include,,,
Zhang J.; Wang X.; Zhang H.; Sun H.; Liu X.; Hu C.; Liu Y.,Detecting Condition-Related Bugs with Control Flow Graph Neural Network,"Automated bug detection is essential for high-quality software development and has attracted much attention over the years. Among the various bugs, previous studies show that the condition expressions are quite error-prone and the condition-related bugs are commonly found in practice. Traditional approaches to automated bug detection are usually limited to compilable code and require tedious manual effort. Recent deep learning-based work tends to learn general syntactic features based on Abstract Syntax Tree (AST) or apply the existing Graph Neural Networks over program graphs. However, AST-based neural models may miss important control flow information of source code, and existing Graph Neural Networks for bug detection tend to learn local neighbourhood structure information. Generally, the condition-related bugs are highly influenced by control flow knowledge, therefore we propose a novel CFG-based Graph Neural Network (CFGNN) to automatically detect condition-related bugs, which includes a graph-structured LSTM unit to efficiently learn the control flow knowledge and long-distance context information. We also adopt the API-usage attention mechanism to leverage the API knowledge. To evaluate the proposed approach, we collect real-world bugs in popular GitHub repositories and build a large-scale condition-related bug dataset. The experimental results show that our proposed approach significantly outperforms the state-of-the-art methods for detecting condition-related bugs.  © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167727229&doi=10.1145%2f3597926.3598142&partnerID=40&md5=d1528e96d16abc5373ecd30bb07bcb45,ISSTA 2023 - Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis,Include,,,
Tian H.; Liu K.; Li Y.; Kaboré A.K.; Koyuncu A.; Habib A.; Li L.; Wen J.; Klein J.; Bissyandé T.F.,The Best of Both Worlds: Combining Learned Embeddings with Engineered Features for Accurate Prediction of Correct Patches,"A large body of the literature on automated program repair develops approaches where patches are automatically generated to be validated against an oracle (e.g., a test suite). Because such an oracle can be imperfect, the generated patches, although validated by the oracle, may actually be incorrect. While the state-of-the-art explores research directions that require dynamic information or rely on manually-crafted heuristics, we study the benefit of learning code representations in order to learn deep features that may encode the properties of patch correctness. Our empirical work investigates different representation learning approaches for code changes to derive embeddings that are amenable to similarity computations of patch correctness identification, and assess the possibility of accurate classification of correct patch by combining learned embeddings with engineered features. Experimental results demonstrate the potential of learned embeddings to empower Leopard (a patch correctness predicting framework implemented in this work) with learning algorithms in reasoning about patch correctness: a machine learning predictor with BERT transformer-based learned embeddings associated with XGBoost achieves an AUC value of about 0.803 in the prediction of patch correctness on a new dataset of 2,147 labeled patches that we collected for the experiments. Our investigations show that deep learned embeddings can lead to complementary/better performance when comparing against the state-of-the-art, PATCH-SIM, which relies on dynamic information. By combining deep learned embeddings and engineered features, Panther (the upgraded version of Leopard implemented in this work) outperforms Leopard with higher scores in terms of AUC, +Recall and -Recall, and can accurately identify more (in)correct patches that cannot be predicted by the classifiers only with learned embeddings or engineered features. Finally, we use an explainable ML technique, SHAP, to empirically interpret how the learned embeddings and engineered features are contributed to the patch correctness prediction. © 2023 Copyright held by the owner/author(s).",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164237362&doi=10.1145%2f3576039&partnerID=40&md5=c5699fa7328a6c7f276d39f9de22523e,ACM Transactions on Software Engineering and Methodology,Include,,,
Tang F.; He P.,Software Defect Prediction using Multi-scale Structural Information,"In recent years, most researches have used the sequence of nodes in the abstract syntax tree (AST) of code to extract features for software defect prediction (SDP). While the AST is a kind of graph data, it may ignore some part of the structural information to use the original graph data as a sequence for input. Thus, Graph neural network (GNN) has been used to extract structural information in SDP. However, existing researches ignore that GNN learning is inherently local. It is difficult to interact between remote nodes and to capture long-term dependencies in source code. We apply a combination model of GNN Transformer to predict the software defects. Using an AST directly as the input, GNN extracts local features and structural information between the node and its neighbors. We then encode the relative and absolute positions of the nodes in the AST. The position encodings are passed into the Transformer along with the feature information extracted by GNN to extract the global features, which are the long-term dependencies between nodes. Finally, the extracted fused features are used in the SDP. Experiments on the PROMISE dataset have shown that our method achieves higher F-measure and better identification of defective features in source code than the state-of-the-art SDP method. © 2023 Copyright held by the owner/author(s).",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168248665&doi=10.1145%2f3594315.3594371&partnerID=40&md5=eebaffafd0ee850460b3597b2d4f44c6,ACM International Conference Proceeding Series,Include,,Include,
Yin G.; Wang W.; Li H.,OdegVul: An Approach for Statement-Level Defect Prediction,"Defect prediction research has been conducted for more than 40 years, with the goal of estimating the defect-prone blocks of source code. Prior studies, however, had two major limitations: (1) coarse-grained defect prediction results and (2) weak long-Term dependencies modeling. As a result, developers need to review the prediction results to gure out which function or even which line of code produced the issue. In this study, we present OdegVul, a novel statement-level defect prediction model, to address these concerns. To capture both semantic and structural relationships between statements, a statement representation framework combining deep learning and graph neural networks is designed. Then the long-Term dependencies between statements are encoded as a partial di®erential equation of a graph neural network. Through the experiment of 32 releases of 9 open-source Java projects, we found that semantic and structural dependencies are crucial to statement-level defect prediction. OdegVul outperforms other state-of-The-Art (SOTA) predictors and achieves reasonable performance in cross-project statement-level defect prediction scenarios. The ner granularity of predicting results reduces the developer's workforce in reviewing the prediction results and increases the practicality of the defect prediction model. The source code of OdegVul is available at https://github.com/CoderYinDaqiang/OdegVul. © 2023 World Scientific Publishing Co. Pte Ltd. All rights reserved.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178406847&doi=10.1142%2fS0218194023500614&partnerID=40&md5=db95d746566f2cd43af558d55858f1e6,International Journal of Software Engineering and Knowledge Engineering,Include,,,
Yin Y.; Shi Y.; Zhao Y.; Wahab F.,Multi-graph learning-based software defect location,"Software quality is key to the success of software systems. Modern software systems are growing in their worth based on industry needs and becoming more complex, which inevitably increases the possibility of more defects in software systems. Software repairing is time-consuming, especially locating the source files related to specific software defect reports. To locate defective source files more quickly and accurately, automated software defect location technology is generated and has a huge application value. The existing deep learning-based software defect location method focuses on extracting the semantic correlation between the source file and the corresponding defect reports. However, the extensive code structure information contained in the source files is ignored. To this end, we propose a software defect location method, namely, multi-graph learning-based software defect location (MGSDL). By extracting the program dependency graphs for functions, each source file is converted into a graph bag containing multiple graphs (i.e., multi-graph). Further, a multi-graph learning method is proposed, which learns code structure information from multi-graph to establish the semantic association between source files and software defect reports. Experiments' results on four publicly available datasets, AspectJ, Tomcat, Eclipse UI, and SWT, show that MGSDL improves on average 3.88%, 5.66%, 13.23%, 9.47%, and 3.26% over the competitive methods in five evaluation metrics, rank@10, rank@5, MRR, MAP, and AUC, respectively. © 2023 John Wiley & Sons Ltd.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152077576&doi=10.1002%2fsmr.2552&partnerID=40&md5=05fae7aae53840e8e104ebbedbcab80e,Journal of Software: Evolution and Process,Include,,,
Ma Y.-F.; Du Y.; Li M.,Capturing the Long-Distance Dependency in the Control Flow Graph via Structural-Guided Attention for Bug Localization,"To alleviate the burden of software maintenance, bug localization, which aims to automatically locate the buggy source files based on the bug report, has drawn significant attention in the software mining community. Recent studies indicate that the program structure in source code carries more semantics reflecting the program behavior, which is beneficial for bug localization. Benefiting from the rich structural information in the Control Flow Graph (CFG), CFG-based bug localization methods have achieved the state-of-the-art performance. Existing CFG-based methods extract the semantic feature from the CFG via the graph neural network. However, the step-wise feature propagation in the graph neural network suffers from the problem of information loss when the propagation distance is long, while the long-distance dependency is rather common in the CFG. In this paper, we argue that the long-distance dependency is crucial for feature extraction from the CFG, and propose a novel bug localization model named sgAttention. In sgAttention, a particularly designed structural-guided attention is employed to globally capture the information in the CFG, where features of irrelevant nodes are masked for each node to facilitate better feature extraction from the CFG. Experimental results on four widely-used open-source software projects indicate that sgAttention averagely improves the state-of-the-art bug localization methods by 32.9% and 29.2% and the state-of-the-art pre-trained models by 5.8% and 4.9% in terms of MAP and MRR, respectively. © 2023 International Joint Conferences on Artificial Intelligence. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170357286&partnerID=40&md5=a91320049d84720a0f4e3003c8bc9486,IJCAI International Joint Conference on Artificial Intelligence,Include,,,
Lin B.; Wang S.; Wen M.; Mao X.,Context-Aware Code Change Embedding for Better Patch Correctness Assessment,"Despite the capability in successfully fixing more and more real-world bugs, existing Automated Program Repair (APR) techniques are still challenged by the long-standing overfitting problem (i.e., a generated patch that passes all tests is actually incorrect). Plenty of approaches have been proposed for automated patch correctness assessment (APCA). Nonetheless, dynamic ones (i.e., those that needed to execute tests) are time-consuming while static ones (i.e., those built on top of static code features) are less precise. Therefore, embedding techniques have been proposed recently, which assess patch correctness via embedding token sequences extracted from the changed code of a generated patch. However, existing techniques rarely considered the context information and program structures of a generated patch, which are crucial for patch correctness assessment as revealed by existing studies. In this study, we explore the idea of context-Aware code change embedding considering program structures for patch correctness assessment. Specifically, given a patch, we not only focus on the changed code but also take the correlated unchanged part into consideration, through which the context information can be extracted and leveraged. We then utilize the AST path technique for representation where the structure information from AST node can be captured. Finally, based on several pre-defined heuristics, we build a deep learning based classifier to predict the correctness of the patch. We implemented this idea as Cache and performed extensive experiments to assess its effectiveness. Our results demonstrate that Cache can (1) perform better than previous representation learning based techniques (e.g., Cache relatively outperforms existing techniques by 6%, 3%, and 16%, respectively under three diverse experiment settings), and (2) achieve overall higher performance than existing APCA techniques while even being more precise than certain dynamic ones including PATCH-SIM (92.9% vs. 83.0%). Further results reveal that the context information and program structures leveraged by Cache contributed significantly to its outstanding performance.  © 2022 Association for Computing Machinery.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130752121&doi=10.1145%2f3505247&partnerID=40&md5=896d9827ba64bf2c9e1c335c5f5a6100,ACM Transactions on Software Engineering and Methodology,Include,,Include,
Zhou C.; He P.; Zeng C.; Ma J.,Software defect prediction with semantic and structural information of codes based on Graph Neural Networks,"Context: Most defect prediction methods consider a series of traditional manually designed static code metrics. However, only using these hand-crafted features is impractical. Some researchers use the Convolutional Neural Network (CNN) to capture the potential semantic information based on the program's Syntax Trees (ASTs). In recent years, leveraging the dependency relationships between software modules to construct a software network and using network embedding models to capture the structural information have been helpful in defect prediction. This paper simultaneously takes the semantic and structural information into account and proposes a method called CGCN. Objective: This study aims to validate the feasibility and performance of the proposed method in software defect prediction. Method: Abstract Syntax Trees and a Class Dependency Network (CDN) are first generated based on the source code. For ASTs, symbolic tokens are extracted and encoded into vectors. The numerical vectors are then used as input to the CNN to capture the semantic information. For CDN, a Graph Convolutional Network (GCN) is used to learn the structural information of the network automatically. Afterward, the learned semantic and structural information are combined with different weights. Finally, we concatenate the learned features with traditional hand-crafted features to train a classifier for more accurate defect prediction. Results: The proposed method outperforms the state-of-the-art defect prediction models for both within-project prediction (including within-version and cross-version) and cross-project prediction on 21 open-source projects. In general, within-version prediction achieves better performance in the three prediction tasks. Conclusion: The proposed method of combining semantic and structural information can improve the performance of software defect prediction. © 2022 Elsevier B.V.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137157816&doi=10.1016%2fj.infsof.2022.107057&partnerID=40&md5=740103e40f40a306ecea8e7469a5306f,Information and Software Technology,Include,,,
Zhu Z.; Tong H.; Wang Y.; Li Y.,Enhancing bug localization with bug report decomposition and code hierarchical network,"Bug localization, which aims to locate buggy source code files for given bug reports, is a crucial yet challenging software-mining task. Despite remarkable success, the state of the art falls short in handling (1) bug reports with diverse characteristics and (2) programs with wildly different behaviors. In response, this paper proposes a graph-based neural model BLOCO for automated bug localization. To be specific, our proposed model decomposes bug reports into several bug clues to capture bug-related information from various perspectives for highly diverse bug reports. To understand the program in depth, we first design a code hierarchical network structure, Code-NoN, based on basic blocks to represent source code files. Correspondingly, a multilayer graph neural network is tailored to capture program behaviors from the Code-NoN structure of each source code file. Finally, BLOCO further incorporates a bi-affine classifier to comprehensively predict the relationship between the bug reports and source files. Extensive experiments on five large-scale real-world projects demonstrate that the proposed model significantly outperforms existing techniques. © 2022 Elsevier B.V.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129970669&doi=10.1016%2fj.knosys.2022.108741&partnerID=40&md5=dcf53451ff1638c350a605c6a6f43b2a,Knowledge-Based Systems,Include,,Include,
Ma Y.-F.; Li M.,The flowing nature matters: feature learning from the control flow graph of source code for bug localization,"Bug localization plays an important role in software maintenance. Traditional works treat the source code from the lexical perspective, while some recent researches indicate that exploiting the program structure is beneficial for improving bug localization. Control flow graph (CFG) is a widely used graph representation, which essentially represents the program structure. Although using graph neural network for feature learning is a straightforward way and has been proven effective in various software mining problems, this approach is inappropriate since adjacent nodes in the CFG could be totally unrelated in semantics. On the other hand, previous statements may affect the semantics of subsequent statements along the execution path, which we call the flowing nature of control flow graph. In this paper, we claim that the flowing nature should be explicitly considered and propose a novel model named cFlow for bug localization, which employs a particular designed flow-based GRU for feature learning from the CFG. The flow-based GRU exploits the program structure represented by the CFG to transmit the semantics of statements along the execution path, which reflects the flowing nature. Experimental results on widely-used real-world software projects show that cFlow significantly outperforms the state-of-the-art bug localization methods, indicating that exploiting the program structure from the CFG with respect to the flowing nature is beneficial for improving bug localization. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124741118&doi=10.1007%2fs10994-021-06078-4&partnerID=40&md5=0b5e48501b89aea5d491f3dc8a1b3770,Machine Learning,Include,,Include,
Deng X.; He P.; Zhou C.Y.,Data Selection for Cross-Project Defect Prediction with Local and Global Features of Source Code,"An open challenge for cross-project defect prediction (CPDP) is how to select the most appropriate training data for target project to build quality predictor. To our knowledge, existing methods are mostly dominated by traditional hand-crafted features, which do not fully encode the global structure between codes nor the semantics of code tokens. This work is to propose an improved method which is capable of automatically learning features for representing source code, and uses these feataures for training data selection. First, we propose a framework ALGoF to automatically learn the local semantic and global structural features of code files. Then, we analyze the feasibility of the learned features for data selection. Besides, we also validate the effectiveness of ALGoF by comparing with the traditional method. The experiments have been conducted on six defect datasets available at the PROMISE repository. The results show that ALGoF method helps to guide the training data selection for CPDP, and achieves a 48.31% improvement rate of F-measure. Meanwhile, our method has statistically significant advantages over the traditional method, especially when using both the local semantic and global structural features as the representation of code files. The maximum improvement of F-measure can reach 42.6%. © 2022 Knowledge Systems Institute Graduate School. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137158661&doi=10.18293%2fSEKE2022-086&partnerID=40&md5=4ea2bcb83fee6ceea53c18fb4ca971e3,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",Include,,Include,
Liang C.; Rümmer P.; Brockschmidt M.,Exploring Representation of Horn Clauses using GNNs,"In recent years, the application of machine learning in program verification, and the embedding of programs to capture semantic information, has been recognised as an important tool by many research groups. Learning program semantics from raw source code is challenging due to the complexity of real-world programming language syntax and due to the difficulty of reconstructing long-distance relational information implicitly represented in programs using identifiers. Addressing the first point, we consider Constrained Horn Clauses (CHCs) as a standard representation of program verification problems, providing a simple and programming language-independent syntax. For the second challenge, we explore graph representations of CHCs, and propose a new Relational Hypergraph Neural Network (R-HyGNN) architecture to learn program features. We introduce two different graph representations of CHCs. One is called constraint graph (CG), and emphasizes syntactic information of CHCs by translating the symbols and their relations in CHCs as typed nodes and binary edges, respectively, and constructing the constraints as abstract syntax trees. The second one is called control- and data-flow hypergraph (CDHG), and emphasizes semantic information of CHCs by representing the control and data flow through ternary hyperedges. We then propose a new GNN architecture, R-HyGNN, extending Relational Graph Convolutional Networks, to handle hypergraphs. To evaluate the ability of R-HyGNN to extract semantic information from programs, we use R-HyGNNs to train models on the two graph representations, and on five proxy tasks with increasing difficulty, using benchmarks from CHC-COMP 2021 as training data. The most difficult proxy task requires the model to predict the occurrence of clauses in counter-examples, which subsumes satisfiability of CHCs. CDHG achieves 90.59% accuracy in this task. Furthermore, R-HyGNN has perfect predictions on one of the graphs consisting of more than 290 clauses. Overall, our experiments indicate that R-HyGNN can capture intricate program features for guiding verification problems.  © 2022 Copyright for this paper by its authors.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137580710&partnerID=40&md5=2eebf0ee10bb742a5844e08d1c5b851f,CEUR Workshop Proceedings,Exclude,,Include,Exclude
Yang C.,Accelerating redundancy-based program repair via code representation learning and adaptive patch filtering,"Automated program repair (APR) has attracted extensive attention and many APR techniques have been proposed recently, in which redundancy-based techniques have achieved great success. However, they still suffer from the efficiency issue mainly caused by the inaccuracy of measuring code similarity, which may produce meaningless patches that hinder the generation and validation of correct patches. To solve this issue, we propose a novel method AccPR, which leverages code representation to measure code similarity and employs adaptive patch filtering to accelerate redundancy-based APR. We have implemented a prototype of AccPR and integrated it with a SOTA APR tool, SimFix, where the average improvement of efficiency is 47.85%, indicating AccPR is promising.  © 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116232872&doi=10.1145%2f3468264.3473496&partnerID=40&md5=4f7aeeee9bb1beafd792ed92b4bb36af,ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,Exclude,,,
Sikic L.; Kurdija A.S.; Vladimir K.; Silic M.,Graph Neural Network for Source Code Defect Prediction,"Predicting defective software modules before testing is a useful operation that ensures that the time and cost of software testing can be reduced. In recent years, several models have been proposed for this purpose, most of which are built using deep learning-based methods. However, most of these models do not take full advantage of a source code as they ignore its tree structure or they focus only on a small part of a code. To investigate whether and to what extent information from this structure can be beneficial in predicting defective source code, we developed an end-to-end model based on a convolutional graph neural network (GCNN) for defect prediction, whose architecture can be adapted to the analyzed software, so that projects of different sizes can be processed with the same level of detail. The model processes the information of the nodes and edges from the abstract syntax tree (AST) of the source code of a software module and classifies the module as defective or not defective based on this information. Experiments on open source projects written in Java have shown that the proposed model performs significantly better than traditional defect prediction models in terms of AUC and F-score. Based on the F-scores of the existing <italic>state-of-the-art</italic> models, the model has shown comparable predictive capabilities for the analyzed projects. © 2022 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123383541&doi=10.1109%2fACCESS.2022.3144598&partnerID=40&md5=6f026f26f6828fe3c1f1e28156cf823d,IEEE Access,Include,,Include,
Shi K.; Lu Y.; Liu G.; Wei Z.; Chang J.,MPT-embedding: An unsupervised representation learning of code for software defect prediction,"Software project defect prediction can help developers allocate debugging resources. Existing software defect prediction models are usually based on machine learning methods, especially deep learning. Deep learning-based methods tend to build end-to-end models that directly use source code-based abstract syntax trees (ASTs) as input. They do not pay enough attention to the front-end data representation. In this paper, we propose a new framework to represent source code called multiperspective tree embedding (MPT-embedding), which is an unsupervised representation learning method. MPT-embedding parses the nodes of ASTs from multiple perspectives and encodes the structural information of a tree into a vector sequence. Experiments on both cross-project defect prediction (CPDP) and within-project defect prediction (WPDP) show that, on average, MPT-embedding provides improvements over the state-of-the-art method. © 2020 John Wiley & Sons, Ltd.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097534520&doi=10.1002%2fsmr.2330&partnerID=40&md5=8dab33d2af777d2aa2c02a0486aa036e,Journal of Software: Evolution and Process,Include,,Include,
Xu J.; Ai J.; Shi T.,Software Defect Prediction for Specific Defect Types based on Augmented Code Graph Representation,"In a software life cycle, improving quality and identifying and repairing defects has become an important research topic. Previous studies have proposed defect prediction based on artificial measurement features, a method whose quality is unfortunately difficult to guarantee. On the other hand, many current studies have attempted to predict all types of defects using a single model, which is difficult to achieve. In this paper, Augmented-CPG, a new code graph representation, is proposed. Based on this representation, a defect region candidate extraction method related to the defect type is proposed. Graphic neural networks are introduced to learn defect features. We carried out experiments on three different types of defects, and the results show that our method can effectively predict specific types of defects. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123502800&doi=10.1109%2fDSA52907.2021.00097&partnerID=40&md5=5212e2ef64a23438c28141c1e4289fd2,"Proceedings - 2021 8th International Conference on Dependable Systems and Their Applications, DSA 2021",Include,,Include,
Vasudevan S.; Jiang W.; Bieber D.; Singh R.; Shojaei H.; Ho R.; Sutton C.,Learning Semantic Representations to Verify Hardware Designs,"Verification is a serious bottleneck in the industrial hardware design cycle, routinely requiring person-years of effort. Practical verification relies on a “best effort” process that simulates the design on test inputs. This suggests a new research question: Can this simulation data be exploited to learn a continuous representation of a hardware design that allows us to predict its functionality? As a first approach to this new problem, we introduce Design2Vec, a deep architecture that learns semantic abstractions of hardware designs. The key idea is to work at a higher level of abstraction than the gate or the bit level, namely the Register Transfer Level (RTL), which is similar to software source code, and can be represented by a graph that incorporates control and data flow. This allows us to learn representations of RTL syntax and semantics using a graph neural network. We apply these representations to several tasks within verification, including predicting what cover points of the design will be covered (simulated) by a test, and generating new tests to cover desired cover points. We evaluate Design2Vec on three real-world hardware designs, including the TPU, Google’s industrial chip used in commercial data centers. Our results demonstrate that Design2Vec dramatically outperforms baseline approaches that do not incorporate the RTL semantics and scales to industrial designs. It generates tests that cover design points that are considered hard to cover with manually written tests by design verification experts in a fraction of the time. © 2021 Neural information processing systems foundation. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132007856&partnerID=40&md5=ade8c5d55d4b3e2f000a1b5709123082,Advances in Neural Information Processing Systems,Exclude,,Include,Exclude
Tian H.; Liu K.; Kabore A.K.; Koyuncu A.; Li L.; Klein J.; Bissyande T.F.,Evaluating Representation Learning of Code Changes for Predicting Patch Correctness in Program Repair,"A large body of the literature of automated program repair develops approaches where patches are generated to be validated against an oracle (e.g., a test suite). Because such an oracle can be imperfect, the generated patches, although validated by the oracle, may actually be incorrect. While the state of the art explore research directions that require dynamic information or that rely on manually-crafted heuristics, we study the benefit of learning code representations in order to learn deep features that may encode the properties of patch correctness. Our empirical work mainly investigates different representation learning approaches for code changes to derive embeddings that are amenable to similarity computations. We report on findings based on embeddings produced by pre-trained and re-trained neural networks. Experimental results demonstrate the potential of embeddings to empower learning algorithms in reasoning about patch correctness: a machine learning predictor with BERT transformer-based embeddings associated with logistic regression yielded an AUC value of about 0.8 in the prediction of patch correctness on a deduplicated dataset of 1000 labeled patches. Our investigations show that learned representations can lead to reasonable performance when comparing against the state-of-the-art, PATCH-SIM, which relies on dynamic information. These representations may further be complementary to features that were carefully (manually) engineered in the literature. © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090838760&doi=10.1145%2f3324884.3416532&partnerID=40&md5=807aa80dc39926ee3a76b026cd76a328,"Proceedings - 2020 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020",Include,,Include,
Shi K.; Lu Y.; Chang J.; Wei Z.,PathPair2Vec: An AST path pair-based code representation method for defect prediction,"Software project defect prediction (SDP) can predict the bug probability of software by their features and allocate their testing efforts. The existing software defect prediction methods can be divided into two categories: methods based on traditional handcrafted features and methods based on automatically made abstract features, especially those made by deep learning. The current research indicates that deep learning-based automatic features can achieve better performance than handcrafted features. Code2vec (Alon et al. 2019) is one of the best source code representation models, which leverages deep learning to learn automatic representations from code. In this paper, inspired by code2vec, we propose a new AST path pair-based source code representation method (PathPair2Vec) and apply it to software project defect prediction. We first propose the concept of the short path to describe each terminal node and its control logic. Then, we design a new sequence encoding method to code the different parts of the terminal node and its control logic. Finally, by pairs of short paths, we describe the semantic information of code and fuse them by an attention mechanism. Experiments on the PROMISE dataset show that our method improves the F1 score by 17.88% over the state-of-the-art SDP method, and the AST path pair-based source code representation can better identify the defect features of the source code. © 2020 Elsevier Ltd",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085928963&doi=10.1016%2fj.cola.2020.100979&partnerID=40&md5=2f38eee29116449336d8e934062d0794,Journal of Computer Languages,Include,,,
Zhang X.; Lu Y.; Shi K.,CB-Path2Vec: A Cross Block Path Based Representation for Software Defect Prediction,"Software defects are common in software projects and threaten the security of software. Software defect prediction has been proven to be an effective method to solve software security problems, assisting developers in finding potential errors and effectively allocating test resources, in the early stage of the software life cycle. Traditional defect prediction models are designed based on hand-designed metric features, but these features usually cannot capture the semantic and structural information of code. In order to solve this problem, this paper proposes a novel software defect prediction model called CB-Path2Vec, which can automatically learn features composed of Cross Block path for representing source code and use them for software defect prediction. An evaluation on the public PROMISE dataset shows that on average CB-Path2Vec improvements over the state-of-the-art method both on within-project defect prediction (WPDP) and cross-project defect prediction (CPDP). © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101683378&doi=10.1109%2fICCC51575.2020.9344956&partnerID=40&md5=168573d2392fdb2ab881db7e179d77a4,"2020 IEEE 6th International Conference on Computer and Communications, ICCC 2020",Include,,Include,
Wang S.; Liu T.; Nam J.; Tan L.,Deep Semantic Feature Learning for Software Defect Prediction,"Software defect prediction, which predicts defective code regions, can assist developers in finding bugs and prioritizing their testing efforts. Traditional defect prediction features often fail to capture the semantic differences between different programs. This degrades the performance of the prediction models built on these traditional features. Thus, the capability to capture the semantics in programs is required to build accurate prediction models. To bridge the gap between semantics and defect prediction features, we propose leveraging a powerful representation-learning algorithm, deep learning, to learn the semantic representations of programs automatically from source code files and code changes. Specifically, we leverage a deep belief network (DBN) to automatically learn semantic features using token vectors extracted from the programs' abstract syntax trees (AST) (for file-level defect prediction models) and source code changes (for change-level defect prediction models). We examine the effectiveness of our approach on two file-level defect prediction tasks (i.e., file-level within-project defect prediction and file-level cross-project defect prediction) and two change-level defect prediction tasks (i.e., change-level within-project defect prediction and change-level cross-project defect prediction). Our experimental results indicate that the DBN-based semantic features can significantly improve the examined defect prediction tasks. Specifically, the improvements of semantic features against existing traditional features (in F1) range from 2.1 to 41.9 percentage points for file-level within-project defect prediction, from 1.5 to 13.4 percentage points for file-level cross-project defect prediction, from 1.0 to 8.6 percentage points for change-level within-project defect prediction, and from 0.6 to 9.9 percentage points for change-level cross-project defect prediction. © 1976-2012 IEEE.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055712889&doi=10.1109%2fTSE.2018.2877612&partnerID=40&md5=6325ceb2e2a227c0354c7da8e1fe49f8,IEEE Transactions on Software Engineering,Exclude,,Include,
Yasunaga M.; Liang P.,"Graph-based, self-supervised program repair from diagnostic feedback","We consider the problem of learning to repair programs from diagnostic feedback (e.g., compiler error messages). Program repair is challenging for two reasons: First, it requires reasoning and tracking symbols across source code and diagnostic feedback. Second, labeled datasets available for program repair are relatively small. In this work, we propose novel solutions to these two challenges. First, we introduce a program-feedback graph, which connects symbols relevant to program repair in source code and diagnostic feedback, and then apply a graph neural network on top to model the reasoning process. Second, we present a self-supervised learning paradigm for program repair that leverages unlabeled programs available online to create a large amount of extra program repair examples, which we use to pre-train our models. We evaluate our proposed approach on two applications: correcting introductory programming assignments (DeepFix dataset) and correcting the outputs of program synthesis (SPoC dataset). Our final system, DrRepair, significantly outperforms prior work, achieving 68.2% full repair rate on DeepFix (+22.9% over the prior best), and 48.4% synthesis success rate on SPoC (+3.7% over the prior best). Copyright 2020 by the author(s).",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094774454&partnerID=40&md5=8d54ec79554fc63afde98c2a36893a75,"37th International Conference on Machine Learning, ICML 2020",Include,,,
Oßner C.; Böhm K.,Graphs for mining-based defect localization in multithreaded programs,"Trends in modern multicore architecture design requires software developers to develop and debug multithreaded programs. Consequently, software developers must face new challenges because of bug patterns occurring at runtime and due to the non-deterministic behavior of multi-threaded program executions. This calls for new defect-localization techniques. There has been much work in the field of defect localization for sequential programs on the one side and on the localization of specific multithreading bugs on the other side, but we are not aware of any general technique for multithreaded programs. This paper proposes such an approach. It generalizes data mining-based defect-localization techniques for sequential programs. The techniques work by analyzing call graphs. More specifically, we propose new graph representations of multithreaded program executions as well as two mining-based localization approaches based on these representations. Our evaluation shows that our technique yields good results and is able to find defects that other approaches cannot localize. © 2012 Springer Science+Business Media New York.",Article,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877803123&doi=10.1007%2fs10766-012-0237-2&partnerID=40&md5=178e4e41a5ebee92727f35645193c127,International Journal of Parallel Programming,Include,,,
Viet Phan A.; Le Nguyen M.; Thu Bui L.,Convolutional neural networks over control flow graphs for software defect prediction,"Existing defects in software components is unavoidable and leads to not only a waste of time and money but also many serious consequences. To build predictive models, previous studies focus on manually extracting features or using tree representations of programs, and exploiting different machine learning algorithms. However, the performance of the models is not high since the existing features and tree structures often fail to capture the semantics of programs. To explore deeply programs' semantics, this paper proposes to leverage precise graphs representing program execution flows, and deep neural networks for automatically learning defect features. Firstly, control flow graphs are constructed from the assembly instructions obtained by compiling source code; we thereafter apply multi-view multi-layer directed graph-based convolutional neural networks (DGCNNs) to learn semantic features. The experiments on four real-world datasets show that our method significantly outperforms the baselines including several other deep learning approaches. © 2017 IEEE.",Conference paper,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048483561&doi=10.1109%2fICTAI.2017.00019&partnerID=40&md5=707b5b2e13cd2bb78a670a75996004a4,"Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI",Include,,,
Loyola P.; Matsuo Y.,Learning Feature Representations from Change Dependency Graphs for Defect Prediction,"Given the heterogeneity of the data that can be extracted from the software development process, defect prediction techniques have focused on associating different sources of data with the introduction of faulty code, usually relying on handcrafted features. While these efforts have generated considerable progress over the years, little attention has been given to the fact that the performance of any predictive model depends heavily on the representation of the data used, and that different representations can lead to different results. We consider this a relevant problem, as it could be affecting directly the efforts towards generating safer software systems. Therefore, we propose to study the impact of the representation of the data in defect prediction models. To this end, we focus on the use of developer activity data, from which we structure dependency graphs. Then, instead of manually generating features, such as network metrics, we propose two models inspired by recent advances in representation learning which are able to automatically generate feature representations from graph data. These new representations are compared against manually crafted features for defect prediction in real world software projects. Our results show that automatically learned features are competitive, reaching increments in prediction performance up to 13%. © 2017 IEEE.",Conference paper,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040798659&doi=10.1109%2fISSRE.2017.30&partnerID=40&md5=1717868172cec4ce3bd9499ccd62e29c,"Proceedings - International Symposium on Software Reliability Engineering, ISSRE",Include,,Include,
Wang S.; Liu T.; Tan L.,Automatically learning semantic features for defect prediction,"Software defect prediction, which predicts defective code regions, can help developers find bugs and prioritize their testing efforts. To build accurate prediction models, previous studies focus on manually designing features that encode the characteristics of programs and exploring different machine learning algorithms. Existing traditional features often fail to capture the semantic differences of programs, and such a capability is needed for building accurate prediction models. To bridge the gap between programs' semantics and defect prediction features, this paper proposes to leverage a powerful representation-learning algorithm, deep learning, to learn semantic representation of programs automatically from source code. Specifically, we leverage Deep Belief Network (DBN) to automatically learn semantic features from token vectors extracted from programs' Abstract Syntax Trees (ASTs). Our evaluation on ten open source projects shows that our automatically learned semantic features significantly improve both within-project defect prediction (WPDP) and cross-project defect prediction (CPDP) compared to traditional features. Our semantic features improve WPDP on average by 14.7% in precision, 11.5% in recall, and 14.2% in F1. For CPDP, our semantic features based approach outperforms the state-of-the-art technique TCA+ with traditional features by 8.9% in F1. © 2016 ACM.",Conference paper,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971385322&doi=10.1145%2f2884781.2884804&partnerID=40&md5=6ce4bb6f1752563bff564db00236fe9f,Proceedings - International Conference on Software Engineering,Exclude,,Include,Exclude
Orvalho P.; Piepenbrock J.; Janota M.; Manquinho V.,Graph Neural Networks for Mapping Variables Between Programs,"Automated program analysis is a pivotal research domain in many areas of Computer Science - Formal Methods and Artificial Intelligence, in particular. Due to the undecidability of the problem of program equivalence, comparing two programs is highly challenging. Typically, in order to compare two programs, a relation between both programs' sets of variables is required. Thus, mapping variables between two programs is useful for a panoply of tasks such as program equivalence, program analysis, program repair, and clone detection. In this work, we propose using graph neural networks (GNNs) to map the set of variables between two programs based on both programs' abstract syntax trees (ASTs). To demonstrate the strength of variable mappings, we present three use-cases of these mappings on the task of program repair to fix well-studied and recurrent bugs among novice programmers in introductory programming assignments (IPAs). Experimental results on a dataset of 4166 pairs of incorrect/correct programs show that our approach correctly maps 83% of the evaluation dataset. Moreover, our experiments show that the current state-of-the-art on program repair, greatly dependent on the programs' structure, can only repair about 72% of the incorrect programs. In contrast, our approach, which is solely based on variable mappings, can repair around 88.5%. © 2023 The Authors.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175817799&doi=10.3233%2fFAIA230468&partnerID=40&md5=bad761c4241bb9c0564fa129bd2312a8,Frontiers in Artificial Intelligence and Applications,Include,,,
Romanov V.; Ivanov V.,Assessing the Importance of Global Relationships for Source Code Analysis Using Graph Neural Networks,"Representing the source code as a sequence of tokens does not capture long-distance dependencies and inter-project dependencies. In this study, we analyze to which extent inter-project (global) relationships can be used in machine learning tasks related to source code analysis. Our findings show that information implicitly stored in inter-project relationships can be used to select the next called function among candidates with an accuracy of 92%. We demonstrate that source code embeddings achieve the best performance on transfer learning tasks when they are computed with graph neural networks in a multitask mode. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164256776&doi=10.1007%2f978-3-031-35501-1_44&partnerID=40&md5=a05fe0297af81215f9c24d1f6f3e2057,Lecture Notes in Networks and Systems,Include,,Include,
Antal G.; Hegedus P.; Herczeg Z.; Loki G.; Ferenc R.,Is JavaScript Call Graph Extraction Solved Yet? A Comparative Study of Static and Dynamic Tools,"Code analysis is more important than ever because JavaScript is increasingly popular and actively used, both on the client and server sides. Most algorithms for analyzing vulnerabilities, finding coding issues, or inferring type depend on the call graph representation of the underlying program. Luckily, there are quite a few tools to get this job done already. However, their performance in vitro and especially in vivo has not yet been extensively compared and evaluated. In this paper, we compare several approaches for building JavaScript call graphs, namely five static and two dynamic approaches on 26 WebKit SunSpider programs, and two static and two dynamic approaches on 12 real-world Node.js programs. The tools under examination using static techniques were npm call graph, IBM WALA, Google Closure Compiler, Approximate Call Graph, and Type Analyzer for JavaScript. We performed dynamic analyzes relying on the nodejs-cg tool (a customized Node.js runtime) and the NodeProf instrumentation and profiling framework. We provide a quantitative evaluation of the results, and a result quality analysis based on 941 manually validated call edges. On the SunSpider programs, which do not take any inputs, so dynamic extraction could be complete, all the static tools also performed well. For example, TAJS found 93% of all edges while having a 97% precision compared to the precise dynamic call graph. When it comes to real-world Node.js modules, our evaluation shows that static tools struggle with parsing the code and fail to detect a significant amount of call edges that dynamic approaches can capture. Nonetheless, a significant number of edges not detected by dynamic approaches are also reported. Among these, however, there are also edges that are real, but for some reason the unit tests did not execute the branches in which these calls were included. © 2013 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149815933&doi=10.1109%2fACCESS.2023.3255984&partnerID=40&md5=02aeda5e3e81627cce09dca2955e4770,IEEE Access,Exclude,,,
Garg P.; Sengamedu S.H.,Synthesizing code quality rules from examples,"Static Analysis tools have rules for several code quality issues and these rules are created by experts manually. In this paper, we address the problem of automatic synthesis of code quality rules from examples. We formulate the rule synthesis problem as synthesizing first order logic formulas over graph representations of code. We present a new synthesis algorithm RhoSynth that is based on Integer Linear Programming-based graph alignment for identifying code elements of interest to the rule. We bootstrap RhoSynth by leveraging code changes made by developers as the source of positive and negative examples. We also address rule refinement in which the rules are incrementally improved with additional user-provided examples. We validate RhoSynth by synthesizing more than 30 Java code quality rules. These rules have been deployed as part of Amazon CodeGuru Reviewer and their precision exceeds 75% based on developer feedback collected during live code-reviews within Amazon. Through comparisons with recent baselines, we show that current state-of-the-art program synthesis approaches are unable to synthesize most of these rules.  © 2022 Owner/Author.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147918199&doi=10.1145%2f3563350&partnerID=40&md5=243d11ba161459f1d0f17922d46c3692,Proceedings of the ACM on Programming Languages,Exclude,,,
Nadim M.; Mondal D.; Roy C.K.,Leveraging structural properties of source code graphs for just-in-time bug prediction,"The most common use of data visualization is to minimize the complexity for proper understanding. A graph is one of the most commonly used representations for understanding relational data. It produces a simplified representation of data that is challenging to comprehend if kept in a textual format. In this study, we propose a methodology to utilize the relational properties of source code in the form of a graph to identify Just-in-Time (JIT) bug prediction in software systems during different revisions of software evolution and maintenance. We presented a method to convert the source codes of commit patches to equivalent graph representations and named it Source Code Graph (SCG). To understand and compare multiple source code graphs, we extracted several structural properties of these.graphs, such as the density, number of cycles, nodes, edges, etc. We then utilized the attribute values of those SCGs to visualize and detect buggy software commits. We process more than 246 K software commits from 12 subject systems in this investigation. Our investigation on these 12 open-source software projects written in C++ and Java programming languages shows that if we combine the features from SCG with conventional features used in similar studies, we will get the increased performance of Machine Learning (ML) based buggy commit detection models. We also find the increase of F1 Scores in predicting buggy and non-buggy commits statistically significant using the Wilcoxon Signed Rank Test. Since SCG-based feature values represent the style or structural properties of source code updates or changes in the software system, it suggests the importance of careful maintenance of source code style or structure for keeping a software system bug-free. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125647013&doi=10.1007%2fs10515-022-00326-0&partnerID=40&md5=e1bee7a7a259198ea08691007f2c1829,Automated Software Engineering,Include,,,
Ohtsuki M.; Kakeshita T.,Graph Expression for Various Software Documents As Unified Format,"We are developing an educational environment system named VRale-SCM to foster IT engineers necessary for the recent information society. VRale-SCM allows students to deepen their understanding by viewing source code and class diagrams in a virtual space. In this paper, we examined the possibility of using graphs to represent not only source code and class diagrams but also various software documents generated during the software development lifecycle as a framework for viewing them in a virtual space. While there have been attempts to represent individual software documents using a graph, there have been no attempts to represent relationships among these software documents. It will become possible to trace their relationships by interconnecting them, which is expected to facilitate the understanding of the students. In this paper, we shall examine the composition of some of the software documents in each process and attempt to represent the source code and design patterns in the graphs. We shall also check them with visualization tools. Using the graph representation is expected to contribute to understanding by presenting various metrics by applying the analysis in existing studies. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139568732&doi=10.1109%2fIIAIAAI55812.2022.00046&partnerID=40&md5=6f72e8eba2e80d6113ca4e1b7e03965a,"Proceedings - 2022 12th International Congress on Advanced Applied Informatics, IIAI-AAI 2022",Exclude,,,
Françoso Dal Piccol Sotto L.; Kaufmann P.; Atkinson T.; Kalkreuth R.; Porto Basgalupp M.,Graph representations in genetic programming,"Graph representations promise several desirable properties for genetic programming (GP); multiple-output programs, natural representations of code reuse and, in many cases, an innate mechanism for neutral drift. Each graph GP technique provides a program representation, genetic operators and overarching evolutionary algorithm. This makes it difficult to identify the individual causes of empirical differences, both between these methods and in comparison to traditional GP. In this work, we empirically study the behaviour of Cartesian genetic programming (CGP), linear genetic programming (LGP), evolving graphs by graph programming and traditional GP. By fixing some aspects of the configurations, we study the performance of each graph GP method and GP in combination with three different EAs: generational, steady-state and (1 + λ). In general, we find that the best choice of representation, genetic operator and evolutionary algorithm depends on the problem domain. Further, we find that graph GP methods can increase search performance on complex real-world regression problems and, particularly in combination with the (1 + λ) EA, are significantly better on digital circuit synthesis tasks. We further show that the reuse of intermediate results by tuning LGP’s number of registers and CGP’s levels back parameter is of utmost importance and contributes significantly to better convergence of an optimization algorithm when solving complex problems that benefit from code reuse. © 2021, The Author(s).",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116093091&doi=10.1007%2fs10710-021-09413-9&partnerID=40&md5=46d88eea1a90d4c47582ccb43f91e64b,Genetic Programming and Evolvable Machines,Exclude,,,
Li F.,Graph based answer set programming solver systems,"Answer set programming (ASP) is a popular nonmonotonic-logic based paradigm for knowledge representation and solving combinatorial problems. Computing the answer set of an ASP program is NP-hard in general, and researchers have been investing significant effort to speed it up. The majority of current ASP solvers employ SAT solver-like technology to find these answer sets. As a result, justification for why a literal is in the answer set is hard to produce. There are dependency graph based approaches to find answer sets, but due to the representational limitations of dependency graphs, such approaches are limited. This paper proposes a novel dependency graph-based approach for finding answer sets in which conjunction of goals is explicitly represented as a node which allows arbitrary answer set programs to be uniformly represented. Our representation preserves causal relationships allowing for justification for each literal in the answer set to be elegantly found. In this paper, we explore two different approaches based on the graph representation: bottom-up and top-down. The bottom-up approach finds models by assigning truth values along with the topological order, while the top-down approach generates models starting from the constraints. © F. Li This work is licensed under the Creative Commons Attribution License.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115831650&doi=10.4204%2fEPTCS.345.44&partnerID=40&md5=27dc8d338ade76bd4c736ebc406d3f1e,"Electronic Proceedings in Theoretical Computer Science, EPTCS",Exclude,,,
Faustino A.,Graphs based on IR as Representation of Code: Types and Insights,"Mainstream compilers infer code properties from data structures, such as trees and graphs. The latter is useful to represent the control flow and the data dependencies in a code. In addition, graphs can also be used in learning tasks, such as classifying applications given their raw code, predicting the best-performing compute device (e.g., CPU, GPU) or predicting the optimal thread coarsening factor. This paper investigates the performance of graph neural networks on classifying applications given their raw code, for different type of graphs extracted from LLVM's intermediate representation. The results indicate that adding new (different) edges and/or nodes is not a fact of performance improvement. This paper shows a compact representation tends to achieve the best performance. As a result of such investigation, this paper has three main contributions: (1) an infrastructure to explore such graphs on different tasks, (2) compact graphs from LLVM's intermediate representation, (3) and a detailed evaluation of different types of graphs on a learning task.  © 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117277950&doi=10.1145%2f3475061.3475063&partnerID=40&md5=6f81747c562228cac316203c1d406f14,ACM International Conference Proceeding Series,Include,,,
Wilhelm M.E.; Stuber M.D.,EAGO.jl: easy advanced global optimization in Julia,"An extensible open-source deterministic global optimizer (EAGO) programmed entirely in the Julia language is presented. EAGO was developed to serve the need for supporting higher-complexity user-defined functions (e.g. functions defined implicitly via algorithms) within optimization models. EAGO embeds a first-of-its-kind implementation of McCormick arithmetic in an Evaluator structure allowing for the construction of convex/concave relaxations using a combination of source code transformation, multiple dispatch, and context-specific approaches. Utilities are included to parse user-defined functions into a directed acyclic graph representation and perform symbolic transformations enabling dramatically improved solution speed. EAGO is compatible with a wide variety of local optimizers, the most exhaustive library of transcendental functions, and allows for easy accessibility through the JuMP modelling language. Together with Julia's minimalist syntax and competitive speed, these powerful features make EAGO a versatile research platform enabling easy construction of novel meta-solvers, incorporation and utilization of new relaxations, and extension to advanced problem formulations encountered in engineering and operations research (e.g. multilevel problems, user-defined functions). The applicability and flexibility of this novel software is demonstrated on a diverse set of examples. Lastly, EAGO is demonstrated to perform comparably to state-of-the-art commercial optimizers on a benchmarking test set. © 2020 Informa UK Limited, trading as Taylor & Francis Group.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089251067&doi=10.1080%2f10556788.2020.1786566&partnerID=40&md5=05c29398a950cc6b7e95f3fddc158a5f,Optimization Methods and Software,Exclude,,Exclude,
Ciuciu-Kiss J.T.; Tóth M.; Bozó I.,Towards Version Controlling in RefactorErl,"Static source code analyser tools are operating on an intermediate representation of the source code that is usually a tree or a graph. Those representations need to be updated according to the different versions of the source code. However, the developers might be interested in the changes or might need information about previous versions, therefore, keeping different versions of the source code analysed by the tools are required. RefactorErl is an open-source static analysis and transformation tool for Erlang that uses a graph representation to store and manipulate the source code. The aim of our research was to create an extension of the Semantic Program Graph of RefactorErl that is able to store different versions of the source code in a single graph. The new method resulted in 30% memory footprint decrease compared to the available workaround solutions. © 2021 University of Szeged, Institute of Informatics. All rights reserved.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123455221&doi=10.14232%2fACTACYB.289386&partnerID=40&md5=16656e07696503bd9b7686a118bd27bf,Acta Cybernetica,Exclude,,Include,Exclude
Ma G.; Xiao Y.; Capota M.; Willke T.L.; Nazarian S.; Bogdan P.; Ahmed N.K.,Learning Code Representations Using Multifractal-based Graph Networks,"Learning representations of software codes is a critical problem for a wide range of system applications, e.g., compiler optimization, software classification, malicious software detection, and performance optimization. Recently, learning graph-based representations of software programs has been used to model the inherent structural dependencies in programming languages (e.g., C++, Python). In this paper, we propose a novel graph neural network framework that utilizes multifractal analysis for LLVM intermediate representations (IR). We then show empirically that the proposed framework is capable of capturing long-range structural dependencies that appear in software codes. We conduct experiments and comparisons on two downstream system applications: (1) predicting heterogeneous compute device mappings (graph classification), and (2) compiler reachability analysis (node classification). We observe that introducing a structural inductive bias through multifractal topological features enables GNNs to capture long-range dependencies among nodes, thus, it improves the accuracy of GNN models for applications that require learning code representations. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125331798&doi=10.1109%2fBigData52589.2021.9671685&partnerID=40&md5=22957dc504e8c13cf20c5622363f8402,"Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",Exclude,,Include,Exclude
Bedadala P.; Manasa D.; Nair L.S.,Generation of call graph for Java higher order functions,"The Lambda expression introduced in Java 8 gives a functional style to the object-oriented program. The major highlights of lambda expression include lazy evaluation, code readability, avoiding code duplication. A static call graph can be usedto visualize every possible run that the program might take. Due to the recent software development using Java, the new features aintroduced in Java 8 may be explored. Hence this demands the need for the call graphs generated for such software. This paper suggests an algorithm for the construction of a call graph for the lambda constructs. A static call graph will be generated by preserving the signature of the methods. The model suggested here uses an intermediate Abstract syntax tree (AST) like representation which is further transformed and optimized into a call graph representation. © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091342401&doi=10.1109%2fICCES48766.2020.09138056&partnerID=40&md5=972244855bd54b13c6130612c9d7577c,"Proceedings of the 5th International Conference on Communication and Electronics Systems, ICCES 2020",Exclude,,,
Sotto L.F.D.P.; Kaufmann P.; Atkinson T.; Kalkreuth R.; Basgalupp M.P.,A study on graph representations for genetic programming,"Graph representations promise several desirable properties for Genetic Programming (GP); multiple-output programs, natural representations of code reuse and, in many cases, an innate mechanism for neutral drift. Each graph GP technique provides a program representation, genetic operators and overarching evolutionary algorithm. This makes it difficult to identify the individual causes of empirical differences, both between these methods and in comparison to traditional GP. In this work, we empirically study the behavior of Cartesian Genetic Programming (CGP), Linear Genetic Programming (LGP), Evolving Graphs by Graph Programming (EGGP) and traditional GP. By fixing some aspects of the configurations, we study the performance of each graph GP method and GP in combination with three different EAs: generational, steady-state and (1 + λ). In general, we find that the best choice of representation, genetic operator and evolutionary algorithm depends on the problem domain. Further, we find that graph GP methods, particularly in combination with the (1 + λ) EA are significantly better on digital circuit synthesis tasks. © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091800454&doi=10.1145%2f3377930.3390234&partnerID=40&md5=995a507f67891d986d43d4c32d863347,GECCO 2020 - Proceedings of the 2020 Genetic and Evolutionary Computation Conference,Exclude,,,
Rodriguez-Prieto O.; Mycroft A.; Ortin F.,An efficient and scalable platform for java source code analysis using overlaid graph representations,"Although source code programs are commonly written as textual information, they enclose syntactic and semantic information that is usually represented as graphs. This information is used for many different purposes, such as static program analysis, advanced code search, coding guideline checking, software metrics computation, and extraction of semantic and syntactic information to create predictive models. Most of the existing systems that provide these kinds of services are designed ad hoc for the particular purpose they are aimed at. For this reason, we created ProgQuery, a platform to allow users to write their own Java program analyses in a declarative fashion, using graph representations. We modify the Java compiler to compute seven syntactic and semantic representations, and store them in a Neo4j graph database. Such representations are overlaid, meaning that syntactic and semantic nodes of the different graphs are interconnected to allow combining different kinds of information in the queries/analyses. We evaluate ProgQuery and compare it to the related systems. Our platform outperforms the other systems in analysis time, and scales better to program sizes and analysis complexity. Moreover, the queries coded show that ProgQuery is more expressive than the other approaches. The additional information stored by ProgQuery increases the database size and associated insertion time, but these increases are significantly lower than the query/analysis performance gains obtained. © 2013 IEEE.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084183700&doi=10.1109%2fACCESS.2020.2987631&partnerID=40&md5=ee322fceee2e3a34cdad96cec6631c00,IEEE Access,Exclude,,,
Vytovtov P.; Chuvilin K.,Unsupervised classifying of software source code using graph neural networks,Usually automated programming systems consist of two parts: Source code analysis and source code generation. This paper is focused on the first part. Automated source code analysis can be useful for errors and vulnerabilities searching and for representing source code snippets for further investigating. Also gotten representations can be used for synthesizing source code snippets of certain types. A machine learning approach is used in this work. The training set is formed by augmented abstract syntax trees of Java classes. A graph autoencoder is trained and a latent representation of Java classes graphs is inspected. Experiments showed that the proposed model can split Java classes graphs to common classes with some business logic implementation and interfaces and utility classes. The results are good enough be used for more accurate software source code generation. © 2019 FRUCT.,Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066427020&doi=10.23919%2fFRUCT.2019.8711909&partnerID=40&md5=321504e348d93cb779e51a5c899811fc,"Conference of Open Innovation Association, FRUCT",Include,,Include,
Vasilev V.S.; Legalov A.I.,Loop-invariant Optimization in the Pifagor Language,"Abstract: The paper considers methods of program transformation equivalent to optimizing the cycle invariant, applied to the functional data-flow model implemented in the Pifagor programming language. Optimization of the cycle invariant in imperative programming languages is reduced to a displacement from the cycle of computations that do not depend on variables that are changes in the loop. A feature of the functional data flow parallel programming language Pifagor is the absence of explicitly specified cyclic computations (the loop operator). However, recurring calculations in this language can be specified recursively or by applying specific language constructs (parallel lists). Both mechanisms provide the possibility of parallel execution. In the case of optimizing a recursive function, repeated calculations are carried out into an auxiliary function, the main function performing only the calculation of the invariant. When optimizing the invariant in computations over parallel lists, the calculation of the invariant moves from the function that executes over the list items to the function containing the call. The paper provides a definition of “invariant” applied to the Pifagor language, algorithms for its optimization, and examples of program source codes, their graph representations (the program dependence graph) before and after optimization. The algorithm shown for computations over parallel lists is applicable only to the Pifagor language, because it rests upon specific data structures and the computational model of this language. However, the algorithm for transforming recursive functions may be applied to other programming languages. © 2018, Allerton Press, Inc.",Article,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062598671&doi=10.3103%2fS0146411618070295&partnerID=40&md5=0e94d0a915a7a8a3dcd7160469295f20,Automatic Control and Computer Sciences,Exclude,,,
Antal G.; Hegedus P.; Toth Z.; Ferenc R.; Gyimothy T.,Static javascript call graphs: A comparative study,"The popularity and wide adoption of JavaScript both at the client and server side makes its code analysis more important than ever before. Most of the algorithms for vulnerability analysis, coding issue detection, or type inference rely on the call graph representation of the underlying program. Despite some obvious advantages of dynamic analysis, static algorithms should also be considered for call graph construction as they do not require extensive test beds for programs and their costly execution and tracing. In this paper, we systematically compare five widely adopted static algorithms-implemented by the npm call graph, IBM WALA, Google Closure Compiler, Approximate Call Graph, and Type Analyzer for JavaScript tools-for building JavaScript call graphs on 26 WebKit SunSpider benchmark programs and 6 real-world Node.js modules. We provide a performance analysis as well as a quantitative and qualitative evaluation of the results. We found that there was a relatively large intersection of the found call edges among the algorithms, which proved to be 100% precise. However, most of the tools found edges that were missed by all others. ACG had the highest precision followed immediately by TAJS, but ACG found significantly more call edges. As for the combination of tools, ACG and TAJS together covered 99% of the found true edges by all algorithms, while maintaining a precision as high as 98%. Only two of the tools were able to analyze up-to-date multi-file Node.js modules due to incomplete language features support. They agreed on almost 60% of the call edges, but each of them found valid edges that the other missed. © 2018 IEEE.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058310848&doi=10.1109%2fSCAM.2018.00028&partnerID=40&md5=8e1fb1d947ed208139b5d7a54e9722bf,"Proceedings - 18th IEEE International Working Conference on Source Code Analysis and Manipulation, SCAM 2018",Exclude,,,
Liu Z.; Jiang F.; Qian S.,Semantic consistency checking for model transformations,"Model transformation, as a key technique of MDA, is error-prone because of conceptual flaws in design and man-made errors in manual transformation rules. So the consistency checking of model transformations is of great importance for MDA. in this paper, a framework of semantic consistency checking for model transformation is proposed and discussed. In this framework, a graph representation is required to describe model languages, model transformation rules, and source code. Then several semantic properties are selected to be studied, and algorithms based on critical pairs are given to check whether these properties are preserved by model transformations. At last, a case study is performed to demonstrate the feasibility. © 2010 IEEE.",Conference paper,2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77958060899&doi=10.1109%2fICCET.2010.5486198&partnerID=40&md5=649d71d1ac6a793daf3f95aaa0d26e8d,"ICCET 2010 - 2010 International Conference on Computer Engineering and Technology, Proceedings",Include,,,
JayPrakash L.T.,Impact analysis of UML design changes using model slicing,"We propose a technique for analysis of impact of design changes using dynamic slicing of UML models. For a software architecture specified using UML, we first transform a given model into a graph representation which we have named Model Dependency Graph (MDG). MDG combines information available in the interaction model along with the relevant information available in class model into an integrated model. For a given slicing criterion, our slicing algorithm traverses the constructed MDG to identify the relevant model elements forming the dynamic slice. We use these slices to identify the model changes, and their impact. Our impact analysis methodology is based on using the difference between the dynamic slices computed before and after changes are made to the model. Our methodology's novelty lies in performing impact analysis based on a graph metamodel as against independently processing separate UML models. © 2013 IEEE.",Conference paper,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893900992&doi=10.1109%2fCPSM.2013.6703086&partnerID=40&md5=59ebf77dda3f3274f15fd215b8507ca5,"2013 IEEE 1st International Workshop on Communicating Business Process and Software Models: Quality, Understandability, and Maintainability, CPSM 2013",Exclude,,,
Lin Y.; Zhang S.; Zhao J.,Incremental call graph reanalysis for AspectJ software,"Program call graph representation can be used to support many tasks in compiler optimization, program comprehension, and software maintenance. During software evolution, the call graph needs to remain fairly precise and be updated quickly in response to software changes. In this paper, we present an approach to incremental update, instead of exhaustive analysis of the initially constructed call graph in AspectJ software. Our approach first decomposes the source code edits between the updated and initial software versions into a set of atomic change representations, which capture the semantic differences. Then, we explore the relationship between atomic changes and call graph to incrementally update the initially constructed graph, instead of rebuilding it from the ground up. We implement the reanalysis approach on top of the ajc AspectJ compiler and perform an empirical study on 24 versions of eight AspectJ benchmarks. The experiment result shows that our approach can reduce a large portion of unnecessary reanalysis cost as program changes occur, and significant savings are observed for the incremental reconstruction of AspectJ call graph in comparison with an exhaustive analysis, with no loss in precision.",Conference paper,2009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70849102604&doi=10.1109%2fICSM.2009.5306311&partnerID=40&md5=44a4c248b02d70d06d59ec484f91ab42,"IEEE International Conference on Software Maintenance, ICSM",Exclude,,,
Hassan M.O.; Deruelle L.; Basson H.,Towards a change propagation process in software architecture,"In the context of software architecture evolution, understanding the implications of change impact propagation is necessary for various activities including the change management. We propose in this paper a formal model and a platform based on eclipse plugins, for modeling and analysis of software architecture description. This will provide a graph representation of the architecture description, which is implemented in an eclipse platform. The model is based on graph rewriting and represents software architecture components and their corresponding various relationships that are extracted from the architecture description source code. The implementation uses parsers based on grammars specification files, which include features permitting to produce a graph representation of the software source codes. The Drools expert system is a knowledge based system, which performs rules on obtained graphs such as to deduce knowledge. This is used by a software change propagation engine to help identifying the change effects throughout different software architecture components.",Conference paper,2009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77957310474&partnerID=40&md5=8ac0c29d9ff598701e374a22904a41d8,"18th International Conference on Software Engineering and Data Engineering 2009, SEDE 2009",Exclude,,,
Singh V.; Gupta R.; Neamtiu I.,MG++: Memory graphs for analyzing dynamic data structures,"Memory graphs are very useful in understanding the behavior of programs that use dynamically allocated data structures. We present a new memory graph representation, MG++, and a memory graph construction algorithm, that greatly enhance the utility of memory graphs. First, in addition to capturing the shapes of dynamically-constructed data structures, MG++ also captures how they evolve as the program executes and records the source code statements that play a role in their evolution to assist in debugging. Second, MG++ captures the history of actions performed by the memory allocator. This is useful in debugging programs that internally manage storage or in cases where understanding program behavior requires examining memory allocator actions. Our binary instrumentation-based algorithm for MG++ construction does not rely on the knowledge of memory allocator functions or on symbol table information. Our algorithm works for custom memory allocators as well as for in-program memory management. Experiments studying the time and space efficiency for real-world programs show that MG++ representation is space-efficient and the time overhead for MG++ construction algorithm is practical. We show that MG++ is effective for fault location and for analyzing binaries to detect heap buffer overflow attacks. © 2015 IEEE.",Conference paper,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928668020&doi=10.1109%2fSANER.2015.7081839&partnerID=40&md5=d9bb216cae5c66b0997b3e4f18d8d4c2,"2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering, SANER 2015 - Proceedings",Exclude,,,
Allamanis M.; Brockschmidt M.; Khademi M.,Learning to represent programs with graphs,"Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code’s known sematics. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures. In this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VARNAMING, in which a network attempts to predict the name of a variable given its usage, and VARMISUSE, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VARMISUSE task in many cases. Additionally, our testing showed that VARMISUSE identifies a number of bugs in mature open-source projects. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083951710&partnerID=40&md5=db31acc270c475e5034bdd2dae64f154,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",Include,,,
Tóth M.; Bozó I.,Static analysis of complex software systems implemented in Erlang,"Static software analyser tools use different levels of intermediate source code representations that depend on the syntax and semantics of the language to be analysed. Most of the analyser tools use graph representation to efficiently retrieve information. Building such graphs for dynamically typed languages, such as Erlang, is not straightforward. In this paper we present static analysis methods to define the Dependency Graph representation of Erlang programs. The introduced methods cover the data-, control-, behaviour-flow and dependency analyses for sequential and parallel language constructs. © 2012 Springer-Verlag.",Conference paper,2012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864996660&doi=10.1007%2f978-3-642-32096-5_9&partnerID=40&md5=fa2ec3678d4112c90e7d0a699f8333a2,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Wang T.; Su X.; Ma P.,Program normalization for removing code variations,"Code variations are widely believed to impede program analysis. This paper introduces a program normalization approach to remove code variations. Semantic-preserving transformations are performed on the system dependence graphs of programs. As a result, various syntactically different but semantically equivalent constructs are transformed to the same system dependence graph representation, so that code variations are removed. This approach establishes a good framework for testing the semantic equivalence of source codes and it can facilitate program analysis. © 2008 IEEE.",Conference paper,2008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951474821&doi=10.1109%2fCSSE.2008.957&partnerID=40&md5=7238d32a522f5e0e6371b6f7c0921991,"Proceedings - International Conference on Computer Science and Software Engineering, CSSE 2008",Exclude,,,
Deruelle L.; Basson H.,An eclipse platform for analysis and manipulation of distributed multi-language software,"In this paper, we propose formal approach and a platform, based on eclipse plugins, for analysis of distributed multi-language software. These provide a graph representation of the distributed software software, integrated within formal models which are implemented in an eclipse platform. The models represent software components and their corresponding various relationships which are extracted from the source codes files of an eclipse project. The eclipse implementation uses javacc tool allowing to generate parsers based on grammars specifications files, which include features to produce a graph representation of the software components developed in various languages. We develop a distributed version of DROOLS expert system to perform rules on obtained graphs such as to deduce knowledge and to deal with change propagation process. The change propagation process is based on our expert system in order to evaluate the impact of a change performed on a local part of a software program to the distributed ones.",Conference paper,2008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650670045&partnerID=40&md5=2a9811345102fa8b905f50bf236e5d09,"21st International Conference on Computer Applications in Industry and Engineering, CAINE 2008",Exclude,,Include,Exclude
Costantini S.; D'Antona O.; Provetti A.,On the equivalence and range of applicability of graph-based representations of logic programs,"Logic programs under Answer Sets semantics can be studied, and actual computation can be carried out, by means of representing them by directed graphs. Several reductions of logic programs to directed graphs are now available. We compare our proposed representation, called Extended Dependency Graph, to the Block Graph representation recently defined by Linke [Proc. IJCAI-2001, 2001, pp. 641-648]. On the relevant fragment of well-founded irreducible programs, extended dependency and block graph turns out to be isomorphic. So, we argue that graph representation of general logic programs should be abandoned in favor of graph representation of well-founded irreducible programs, which are more concise, more uniform in structure while being equally expressive. © 2002 Elsevier Science B.V. All rights reserved.",Article,2002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037121493&doi=10.1016%2fS0020-0190%2802%2900290-9&partnerID=40&md5=56d1b85dd870c6732e3cf8cd6f7efc85,Information Processing Letters,Exclude,,,
Verbaere M.; Payement A.; De Moor O.,Scripting refactorings with JunGL,"We describe JunGL, a language to script refactoring transformations. It manipulates a graph representation of the program, including extensible semantic information such as variable binding and dataflow. JunGL enables the full automation of complex refactorings: finding program elements of interest, checking preconditions and performing the transformation itself.",Conference paper,2006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34248372495&doi=10.1145%2f1176617.1176656&partnerID=40&md5=dd4902967f558f6da397c86cc455304a,"Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA",Exclude,,,
Deruelle L.; Basson H.; Bouneffa M.; Hattat J.,An eclipse platform extension for analysis and manipulation of multi-language software code,"In this paper, we propose formal model and a plat- form, based on eclipse plugins, for analysis of multi- language software. These provide a graph representa- Tion of the software source codes, database schemas, resource files, integrated within formal models which are implemented in an eclipse platform. The models are based on graphs rewriting, and represent software components and their corresponding various relation- ships which are extracted from the source codes files of an eclipse project. The implementation uses javacc tool allowing to generate parsers based on grammars specifications files, which include features permitting to produce a graph representation of the software compo- nents. The JBoss Rule expert system performs rules on obtained graphs such as to deduce knowledge which is not provided by the current eclipse platform. Ob- Tained knowledge concerns relationships between soft- ware components such as database tables and their use by Java Query Statements. Furthermore, this knowl- edge is used by a software change propagation plugins in order to evaluate the impact of changed database ta- bles.",Conference paper,2007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883262847&partnerID=40&md5=da47db8ad82448df9415641d4c483f90,"20th International Conference on Computer Applications in Industry and Engineering 2007, CAINE 2007",Exclude,,,
Hassan M.O.; Deruelle L.; Basson H.; Ahmad A.,A change propagation process for distributed software architecture,"In the context of software architecture evolution, understanding the impacts of a change to be applied on a distributed software architecture is necessary for various activities related to maintenance and change management. In this paper, we propose formal models and a platform based on eclipse plugins for modeling and analysis of the software architecture description and their related source codes. The proposed models aim at the construction of graph representation based on the architecture description and the software source codes. The graph implementation is mapped with facts of a distributed knowledge-based system, which performs change propagation rules to evaluate the impact of a change performed on distributed components.",Conference paper,2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78751518771&doi=10.5220%2f0002998400780085&partnerID=40&md5=a4cbfce1ed77626577f677e3a3deaf4c,ENASE 2010 - Proceedings of the 5th International Conference on Evaluation of Novel Approaches to Software Engineering,Exclude,,,
Deruelle L.; Melab N.; Bouneffa M.; Basson H.,Analysis and manipulation of distributed multi-language software code,"The authors propose a formal model and a platform to deal with distributed multi-language software analysis. These provide a graph representation of the software codes (source codes and byte-codes), a change propagation process based on graph rewriting, and an automatic profiling tool to measure the contribution of any component to the global performance of the software. The program codes are structured by a multi-graph in which the nodes represent the software components linked by edges representing the meaningful relationships. The software components and their relationships are extracted from the byte-code files, using the mocha decompiler tool, and from the source codes files, using the Javacc tool. Javacc allows one to generate parsers, based on grammar specification files, which include features to produce an XML (eXtensible Markup Language) representation of the software components. Furthermore, a graph of the software components is constructed on the top of the XML files, providing program analysis. This is implemented by an integrated platform including the mocha decompiler, a multi-language parsing tool, a software change management module, and a profiling tool. © 2001 IEEE.",Conference paper,2001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963863727&doi=10.1109%2fSCAM.2001.972665&partnerID=40&md5=7497ad0293f9e8b237277fc0d09d54d2,Proceedings - 1st IEEE International Workshop on Source Code Analysis and Manipulation,Exclude,,,
Sulaiman S.; Sulaiman S.,genDMG: A generic graph representation layout to visualize existing software artifacts,"Examining software artifacts of an existing software system to understand their functionalities based on source codes can be a very daunting task. Many tools have emerged to assist software understanding or program comprehension, which normally consist of graph representations in a reverse engineering environment. These tools are known as reverse engineering or software visualization tools. This paper describes a document-like and modularized software visualization method called generic DocLike Modularized Graph (genDMG) that employs a graph drawing technique to represent software artifacts written either in structured or object-oriented. An example illustrates how the graph representations could assist software maintainers' program comprehension. A comparative study shows genDMG can improve what other methods could support in software visualization. © 2009 Springer-Verlag.",Conference paper,2009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-76649105822&doi=10.1007%2f978-3-642-05036-7_75&partnerID=40&md5=7cfd00c3986525ef01427de02b5e424d,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Henderson T.A.D.; Podgurski A.,Sampling code clones from program dependence graphs with GRAPLE,"We present GRAPLE, a method to generate a representative sample of recurring (frequent) subgraphs of any directed labeled graph(s). GRAPLE is based on frequent subgraph mining, absorbing Markov chains, and Horvitz-Thompson estimation. It can be used to sample any kind of graph representation for programs. One of many software engineering applications for finding recurring subgraphs is detecting duplicated code (code clones) from representations such as program dependence graphs (PDGs) and abstract syntax trees. To assess the usefulness of clones detected from PDGs, we conducted a case study on a 73 KLOC commercial Android application developed over 5 years. Nine of the application's developers participated. To our knowledge, it is the first study to have professional developers examine code clones detected from PDGs. We describe a new PDG generation tool jpdg for JVM languages, which was used to generate the dependence graphs used in the study. © 2016 ACM.",Conference paper,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105852223&doi=10.1145%2f2989238.2989241&partnerID=40&md5=57ea03d70c106b81dbb6f84dfff502b8,"SWAN 2016 - Proceedings of the 2nd International Workshop on Software Analytics, co-located with FSE 2016",Include,,,
Mens T.; Demeyer S.; Janssens D.,Formalising behaviour preserving program transformations,"The notion of refactoring —transforming the source-code of an object-oriented program without changing its external behaviour— has increased the need for a precise definition of refactorings and their properties. This paper introduces a graph representation of those aspects of the source code that should be preserved by a refactoring, and graph rewriting rules as a formal specification for the refactoring transformations themselves. To this aim, we use type graphs, forbidden subgraphs, embedding mechansims, negative application conditions and controlled graph rewriting. We show that it is feasible to reason about the effect of refactorings on object-oriented programs independently of the programming language being used. This is crucial for the next generation of refactoring tools. © Springer-Verlag Berlin Heidelberg 2002.",Conference paper,2002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937207194&doi=10.1007%2f3-540-45832-8_22&partnerID=40&md5=2eff7a53afeccb058d06ef86d7260299,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Mens T.; Van Eetvelde N.; Demeyer S.; Janssens D.,Formalizing refactorings with graph transformations,"The widespread interest in refactoring - transforming the source-code of an object-oriented program without changing its external behaviour - has increased the need for a precise definition of refactoring transformations and their properties. In this paper we explore the use of graph rewriting for specifying refactorings and their effect on programs. We introduce a graph representation for programs and show how two representative refactorings can be expressed by graph productions. Then we demonstrate that it is possible to prove that refactorings preserve certain program properties, and that graph rewriting is a suitable formalism for such proofs. Copyright © 2005 John Wiley & Sons, Ltd.",Article,2005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-23944525125&doi=10.1002%2fsmr.316&partnerID=40&md5=06b360378221c1f418a0057e73e7e0c4,Journal of Software Maintenance and Evolution,Exclude,,,
Dalla Preda M.; Vidali V.,Abstract Similarity Analysis,"Code similarity is an important component of program analysis that finds application in many fields of computer science. Graph based representations of programs, such as control flow graphs and dependency graphs, are often used as a basis for deciding code similarity. Indeed, many similarity algorithms observe particular properties of these graph-based representations of programs in order to decide whether two programs are similar or not. In this work we propose a general framework for similarity analysis where the similarity of programs is expressed in terms of abstractions of their control flow graphs representation. In particular, we consider abstractions of the basic blocks of a control flow graph. © 2017 The Author(s)",Article,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015396065&doi=10.1016%2fj.entcs.2017.02.006&partnerID=40&md5=5d2efaf9e98c89ca80a91ca98363212b,Electronic Notes in Theoretical Computer Science,Exclude,,Exclude,
Sulaiman S.,Viewing software artifacts for different software maintenance categories using graph representations,"Information needed during an iterative process of a software maintenance process is much different from that of a software development process. Without up-dated documents, software maintainers need to gain information required to solve different maintenance categories through source codes hence consuming more time and effort. With the emergence of reverse engineering tools, the process of understanding source codes to solve maintenance tasks in different maintenance categories can be improved. Such tools employ diverse software visualisation methods that generate graph representations of parsed software artifacts. This paper discusses on how the graph representations provided by the proposed DocLike Modularised Graph (DMG) method employed in DocLike Viewer prototype tool can serve different levels of information needed by software maintainers in the case of corrective, adaptive and perfective maintenance category. It is observed that not only do software maintainers require diverse level of information; the necessity of the information is also not exactly of the same degree.",Article,2004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952802847&partnerID=40&md5=3749689197d7d1a426c737b25bf721b4,Malaysian Journal of Computer Science,Exclude,,,
Chauhan N.; Dutta M.; Singh M.,A program model based regression test selection technique for object-oriented programs,"We propose a regression test selection technique that is based on analysis of source code of an object-oriented program. First we construct a System dependency graph model of the original program from the source code. When some modification is executed in a program, the constructed model is updated to reflect the changes. Our approach in addition to capturing control and data dependencies represents the dependencies arising from object-relations. The test cases that exercise the affected model elements in the program model are selected for regression testing. In our approach System Design Graph representation will be used for regression test selection for analyzing and comparing the code changes of original and modified program. Empirical studies carried out by us show that our technique selects on an average of 26.36. % more fault-revealing test cases compared to a Control Dependence Graph based technique while incurring about 37.34% increase in regression test suite size. © 2015 IEEE.",Conference paper,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946944553&doi=10.1109%2fCSNT.2015.87&partnerID=40&md5=73cbb3bb30c97954a758d1bea176dfb3,"Proceedings - 2015 5th International Conference on Communication Systems and Network Technologies, CSNT 2015",Exclude,,,
Verbaere M.; Ettinger R.; De Moor O.,JunGL: A scripting language for refactoring,"Refactorings are behaviour-preserving program transformations, typically for improving the structure of existing code. A few of these transformations have been mechanised in interactive development environments. Many more refactorings have been proposed, and it would be desirable for programmers to script their own refactorings. Implementing such source-to-source transformations, however, is quite complex: even the most sophisticated development environments contain significant bugs in their refactoring tools. We present a domain-specific language for refactoring, named JunGL. It manipulates a graph representation of the program: all information about the program, including ASTs for its compilation units, variable binding, control flow and so on is represented in a uniform graph format. The language is a hybrid of a functional language (in the style of ML) and a logic query language (akin to Datalog). JunGL furthermore has a notion of demand-driven evaluation for constructing computed information in the graph, such as control flow edges. Borrowing from earlier work on the specification of compiler optimisations, JunGL uses socalled 'path queries' to express dataflow properties. We motivate the design of JunGL via a number of nontrivial refactorings, and describe its implementation on the .NET platform. Copyright 2006 ACM.",Conference paper,2006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247132712&partnerID=40&md5=c1200b53181c023dba0caaa10fe5e86e,Proceedings - International Conference on Software Engineering,Exclude,,,
Devanbu P.T.; Rosenblum D.S.; Wolf A.L.,Generating testing and analysis tools with Aria,"Many software testing and analysis tools manipulate graph representations of programs, such as abstract syntax trees or abstract semantics graphs. Handcrafting such tools in conventional programming languages can be difficult, error prone, and time consuming. Our approach is to use application generators targeted for the domain of graph-representation-based testing and analysis tools. Moreover, we generate the generators themselves, so that the development of tools based on different languages and/or representations can also be supported better. In this article we report on our experiences in developing and using a system called Aria that generates testing and analysis tools based on an abstract semantics graph representation for C and C++ called Reprise. Aria itself was generated by the Genoa system. We demonstrate the utility of Aria and, thereby, the power of our approach, by showing Aria's use in the development of a number of useful testing and analysis tools. © 1996 ACM.",Article,1996,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029713449&doi=10.1145%2f226155.226157&partnerID=40&md5=35e2f5353363773eb56a92dea2202653,ACM Transactions on Software Engineering and Methodology,Exclude,,Include,Exclude
Chambers Craig; Dean Jeffrey; Grove David,Framework for selective recompilation in the presence of complex intermodule dependencies,"Compilers and other programming environment tools derive information from the source code of programs; derived information includes compiled code, interprocedural summary information, and call graph views. If the source program changes, the derived information needs to be updated. We present a simple framework for maintaining intermodule dependencies, embodying different tradeoffs in terms of space usage, speed of processing, and selectivity of invalidation, that eases the implementation of incremental update of derived information. Our framework augments a directed acyclic graph representation of dependencies with factoring nodes (to save space) and filtering nodes (to increase selectivity), and it includes an algorithm for efficient invalidation processing. We show how several schemes for selective recompilation, such as smart recompilation, filter sets for interprocedural summary information, and dependencies for whole-program optimization of object-oriented languages, map naturally onto our framework. For this latter application, by exploiting the facilities of our framework, we are able to reduce the number of lines of source code recompiled by a factor of seven over a header file-based scheme, and by a factor of two over the previous state-of-the-art selective dependency mechanism without consuming additional space.",Conference paper,1995,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029191681&partnerID=40&md5=e8bc242ae3bfe65c700475c8310e3810,Proceedings - International Conference on Software Engineering,Exclude,,,
Devanbu Premkumar T.; Rosenblum David S.; Wolf Alexander L.,Automated construction of testing and analysis tools,"Many software testing and analysis tool manipulate graph representations of programs, such as abstract syntax trees or abstract semantics graphs. Hand-crafting such tools in conventional programming languages can be difficult,error prone, and time consuming. Our approach is to use application generators targeted for the domain of graph-representation based testing and analysis tools. Moreover, we generate the generators themselves, so theat the development of tools based on different languages and or representations can also be supported better. In this paper we report on our experiences in developing a system called Aria that generates testing and analysis tools based on an abstract semantics graph representation for C and C++ called Reprise. Aria itself was generated by the Genoa system. We demonstrate the utility of Aria and, thereby, the power of our approach, by showing Aria's use in the development of a tool that derives control dependence graphs directly from Reprise abstract semantics graphs.",Conference paper,1994,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028166437&partnerID=40&md5=17fc474086dfdbe01a1743846f4a1380,Proceedings - International Conference on Software Engineering,Exclude,,,
Guo J.; Liu J.; Liu X.; Wan Y.; Li L.,Summarizing source code with Heterogeneous Syntax Graph and dual position,"Code summarization attempts to summarize the semantics of source code by automatically producing brief natural-language descriptions. Most existing work proposes to learn from the Abstract Syntax Tree (AST) and plain text of source code for summary generation. However, little attention has been paid to the structural heterogeneity and layout features of source code. In this paper, we present a novel framework titled HETSUM to address these issues. Specifically, a Heterogeneous Syntax Graph (HSG) is first built by designing six types of augmented edges in AST, which indicates the heterogeneous structure of source code. Meanwhile, a dual position is designed for each token in the source code by considering the layout information. Moreover, we develop a heterogeneous graph neural network in HETSUM to encode the HSG while extracting the code layout features with the Transformer encoder. By assimilating the learned code token vectors into the HSG encoder, HETSUM can capture the relations between its two encoders for improved code representation. To facilitate the generation of high-quality summaries, we integrate a copying mechanism into the decoding procedure while expanding the Transformer decoding sublayer. Extensive experiments on the Java and Python datasets prove that HETSUM is superior to seventeen state-of-the-art baselines. To promote reproducibility studies, we make the implementation of HETSUM available at https://github.com/GJCEXP/HETSUM. © 2023 Elsevier Ltd",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166740779&doi=10.1016%2fj.ipm.2023.103415&partnerID=40&md5=dc4459ca66428a5d71d2096ab6bda77c,Information Processing and Management,Include,,,
Guo J.; Liu J.; Liu X.; Li L.,Summarizing source code through heterogeneous feature fusion and extraction,"Code summarization, which seeks to automatically produce a succinct natural-language description to summarize the functionality of source code, plays an essential role in maintaining the software. Currently, plentiful approaches have been proposed to first encode the source code based on its Abstract Syntax Tree (AST), and then decode it into a textual summary. However, most existing works interpret the AST-based syntax structure as a homogeneous graph, without discriminating the different relations between graph nodes (e.g., the parent–child and sibling relations) in a heterogeneous way. To mitigate this issue, this paper proposes HETCOS to extract the syntactic and sequential features of source code by exploring its inherent heterogeneity for code summarization. Specifically, we first build a Heterogeneous Code Graph (HCG) that fuses the syntax structure and code sequence with eight types of edges/relations designed between graph nodes. Moreover, we present a heterogeneous graph neural network for capturing the diverse relations in HCG. The represented HCG is then fed into a Transformer decoder, followed by a multi-head attention-based copying mechanism to support high-quality summary generation. Extensive experiments on the major Java and Python datasets illustrate the superiority of our approach over sixteen state-of-the-art baselines. To promote reproducibility studies, we make the implementation of HETCOS publicly accessible at https://github.com/GJCEXP/HETCOS. © 2023 Elsevier B.V.",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175065989&doi=10.1016%2fj.inffus.2023.102058&partnerID=40&md5=09eece79fe63cf31d6e773c7b9b352cd,Information Fusion,Include,,,
Shi C.; Cai B.; Zhao Y.; Gao L.; Sood K.; Xiang Y.,CoSS: Leveraging Statement Semantics for Code Summarization,"Automated code summarization tools allow generating descriptions for code snippets in natural language, which benefits software development and maintenance. Recent studies demonstrate that the quality of generated summaries can be improved by using additional code representations beyond token sequences. The majority of contemporary approaches mainly focus on extracting code syntactic and structural information from abstract syntax trees (ASTs). However, from the view of macro-structures, it is challenging to identify and capture semantically meaningful features due to fine-grained syntactic nodes involved in ASTs. To fill this gap, we investigate how to learn more code semantics and control flow features from the perspective of code statements. Accordingly, we propose a novel model entitled CoSS for code summarization. CoSS adopts a Transformer-based encoder and a graph attention network-based encoder to capture token-level and statement-level semantics from code token sequence and control flow graph, respectively. Then, after receiving two-level embeddings from encoders, a joint decoder with a multi-head attention mechanism predicts output sequences verbatim. Performance evaluations on Java, Python, and Solidity datasets validate that CoSS outperforms nine state-of-the-art (SOTA) neural code summarization models in effectiveness and is competitive in execution efficiency. Further, the ablation study reveals the contribution of each model component.  © 1976-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151331220&doi=10.1109%2fTSE.2023.3256362&partnerID=40&md5=f688da43a2e74f73561d98236d57f320,IEEE Transactions on Software Engineering,Include,,,
Zeng J.; Qu Z.; Cai B.,Structure and Sequence Aligned Code Summarization with Prefix and Suffix Balanced Strategy,"Source code summarization focuses on generating qualified natural language descriptions of a code snippet (e.g., functionality, usage and version). In an actual development environment, descriptions of the code are missing or not consistent with the code due to human factors, which makes it difficult for developers to comprehend and conduct subsequent maintenance. Some existing methods generate summaries from the sequence information of code without considering the structural information. Recently, researchers have adopted the Graph Neural Networks (GNNs) to capture the structural information with modified Abstract Syntax Trees (ASTs) to comprehensively represent a source code, but the alignment method of the two information encoder is hard to decide. In this paper, we propose a source code summarization model named SSCS, a unified transformer-based encoder–decoder architecture, for capturing structural and sequence information. SSCS is designed upon a structure-induced transformer with three main novel improvements. SSCS captures the structural information in a multi-scale aspect with an adapted fusion strategy and adopts a hierarchical encoding strategy to capture the textual information from the perspective of the document. Moreover, SSCS utilizes a bidirectional decoder which generates a summary from opposite direction to balance the generation performance between prefix and suffix. We conduct experiments on two public Java and Python datasets to evaluate our method and the result show that SSCS outperforms the state-of-art code summarization methods. © 2023 by the authors.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156244162&doi=10.3390%2fe25040570&partnerID=40&md5=e6b87370ba5285c63b699000de0567f2,Entropy,Include,,,
Guo J.; Liu J.; Liu X.; Wan Y.; Zhao Y.; Li L.; Liu K.; Klein J.; Bissyandé T.F.,PyScribe–Learning to describe python code,"Code comment generation, which attempts to summarize the functionality of source code in textual descriptions, plays an important role in automatic software development research. Currently, several structural neural networks have been exploited to preserve the syntax structure of source code based on abstract syntax trees (ASTs). However, they can not well capture both the long-distance and local relations between nodes while retaining the overall structural information of AST. To mitigate this problem, we present a prototype tool titled PyScribe, which extends the Transformer model to a new encoder-decoder-based framework. Particularly, the triplet position is designed and integrated into the node-level and edge-level structural features of AST for producing Python code comments automatically. This paper, to the best of our knowledge, makes the first effort to model the edges of AST as an explicit component for improved code representation. By specifying triplet positions for each node and edge, the overall structural information can be well preserved in the learning process. Moreover, the captured node and edge features go through a two-stage decoding process to yield higher qualified comments. To evaluate the effectiveness of PyScribe, we resort to a large dataset of code-comment pairs by mining Jupyter Notebooks from GitHub, for which we have made it publicly available to support further studies. The experimental results reveal that PyScribe is indeed effective, outperforming the state-ofthe-art by achieving an average BLEU score (i.e., av-BLEU) of (Formula presented.) 0.28. © 2023 The Authors. Software: Practice and Experience published by John Wiley & Sons Ltd.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179352137&doi=10.1002%2fspe.3291&partnerID=40&md5=a6f06e9e93298b54afb8224fcc63ac0b,Software - Practice and Experience,Include,,Include,
Zeng J.; He Y.; Zhang T.; Xu Z.; Han Q.,CLG-Trans: Contrastive learning for code summarization via graph attention-based transformer,"Automated code summarization is the task of automatically generating natural language descriptions of source code, which is an important research topic in the software engineering field. Many methods in recent studies were based on deep learning techniques, which effectively improve the performance of code summarization. Most of the existing code summarization methods use different kinds of neural networks to learn source code information. Some methods use graph neural network (GNN) to represent abstract syntax tree (AST) and fuse the structural information of source code. However, these methods still have two important issues: 1) they cannot solve the Out-Of-Vocabulary (OOV) problem effectively; 2) the structural information of source code they can capture is limited. In order to address the above-mentioned challenges, we propose a novel automated code summarization model named CLG-Trans in this work. This model uses the Byte Pair Encoding (BPE) algorithm and pointer-generator network to tackle the OOV problem. Then it utilizes the fusion of contrastive learning strategy and dynamic graph attention mechanism to effectively capture rich structure information of source code sequences. Experimental results on Funcom dataset show that CLG-Trans outperforms seven state-of-the-art models (i.e., Hybrid-DRL, Ast-Attendgru, Transformer, codeGnn, Rencos, CodeBERT and SIT) by averagely increasing 19.48% and 13.17% on BLEU scores and ROUGUE-L score, respectively. In addition, CLG-Trans achieves an improvement of 16.14% and 4.70% in BLEU scores and ROUGE-L score compared with our previously proposed model DG-Trans. © 2023 Elsevier B.V.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146339240&doi=10.1016%2fj.scico.2023.102925&partnerID=40&md5=4eafb730187cf493a6ec32d10b197f44,Science of Computer Programming,Include,,,
Li J.; Wang X.; Lyu C.,ACAGNN: Source Code Representation Based on Fine-Grained Multi-view Program Features,"Existing program comprehension models represent a single code feature and coarse code granularity. They tend to consider the shal- low features of source code (e.g., method names, characters, etc.) and ignore the structured features of source code such as Abstract Syntax Tree (AST), Control Flow Graph (CFG), and Application Programming Interface Dependency Graph (ADG), resulting in an incomplete representation of the source code. Although there are approaches to model ASTs, ASTs are efficient in representing code structure information. They have shortcomings in capturing the calling relationships of methods in the code for the entire class library, which does not allow the model to represent the global program accurately. To address these issues, we propose a multi-view source code representation model called ACAGNN, which uses a designed matching mechanism to learn multi-view code structure representation at the node-level and apply it to downstream code classification tasks. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161117660&doi=10.1007%2f978-981-99-2385-4_36&partnerID=40&md5=06b6e73732a56c7c7766badf6fe78300,Communications in Computer and Information Science,Include,,,
Hou S.; Chen L.; Ju M.; Ye Y.,Leveraging Comment Retrieval for Code Summarization,"Open-source code often suffers from mismatched or missing comments, leading to difficult code comprehension, and burdening software development and maintenance. In this paper, we design a novel code summarization model CodeFiD to address this laborious challenge. Inspired by retrieval-augmented methods for open-domain question answering, CodeFiD first retrieves a set of relevant comments from code collections for a given code, and then aggregates presentations of code and these comments to produce a natural language sentence that summarizes the code behaviors. Different from current code summarization works that focus on improving code representations, our model resorts to external knowledge to enhance code summarizing performance. Extensive experiments on public code collections demonstrate the effectiveness of CodeFiD by outperforming state-of-the-art counterparts across all programming languages. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150987296&doi=10.1007%2f978-3-031-28238-6_34&partnerID=40&md5=6b4efb2dcea0bc40895b46fe4b046810,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,Include,
Lu X.; Niu J.,Enhancing source code summarization from structure and semantics,"Source code summarization aims to generate concise and high-quality natural language descriptions for code snippets. High-quality code summaries can help developers better understand source codes. Researchers have made great efforts to generate more accurate summaries; however, due to the lack of preservation of source code structure and semantics, previous approaches have struggled to generate summaries that accurately describe the functionality or other major characteristics of codes. In this paper, we propose a novel approach called Code Structure and Semantic Fusion (CSSF) for automatically generating summaries for source code. CSSF can utilize both the structural and semantic information of source codes. To achieve this, we extract the overall structure of the Abstract Syntax Tree (AST) by expanding the AST and using a heterogeneous graph attention network. Furthermore, we use an additional sequence model to obtain the semantic information of the code fragment. Finally, we fuse the two kinds of information through a novel modality fusion method. We evaluate our approach on a widely used Java dataset; experimental results confirm that our approach outperforms existing methods. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169592244&doi=10.1109%2fIJCNN54540.2023.10191872&partnerID=40&md5=04716b0190a2fc92ed349a9eef4cdb7e,Proceedings of the International Joint Conference on Neural Networks,Include,,,
Kuang L.; Zhou C.; Yang X.,Code comment generation based on graph neural network enhanced transformer model for code understanding in open-source software ecosystems,"In open-source software ecosystems, the scale of source code is getting larger and larger, and developers often use various methods (good code comments or method names, etc.) to make the code easier to read and understand. However, high-quality code comments or method names are often unavailable due to tight project schedules or other reasons in open-source software ecosystems such as Github. Therefore, in this work, we try to use deep learning models to generate appropriate code comments or method names to help software development and maintenance, which requires a non-trivial understanding of the code. Therefore, we propose a Graph neural network enhanced Transformer model (GTrans for short) to learn code representation to understand code better. Specifically, GTrans learns code representation from code sequences and graphs. We use a Transformer encoder to capture the global representation from code sequence and a graph neural network (GNN) encoder to focus on the local details in the code graph, and then use a decoder to combine both global and local representations by attention mechanism. We use three public datasets collected from GitHub to evaluate our model. In an extensive evaluation, we show that GTrans outperforms the state-of-the-art models up to 3.8% increase in METEOR metrics on code comment generation and outperforms the state-of-the-art models by margins of 5.8%–9.4% in ROUGE metrics on method name generation after some adjustments on the structure. Empirically, we find the method name generation task depends on more local information than global, and the code comment generation task is in contrast. Our data and code are available at https://github.com/zc-work/GTrans. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132075222&doi=10.1007%2fs10515-022-00341-1&partnerID=40&md5=92dc28fb349520100fd5fb371068b6b3,Automated Software Engineering,Include,,,
Kuang L.; Ge F.; Zhang L.,Suggesting method names based on graph neural network with salient information modelling,"Descriptive method names have a great impact on improving program readability and facilitating software maintenance. Recently, due to high similarity between the task of method naming and text summarization, large amount of research based on natural language processing has been conducted to generate method names. However, method names are much shorter compared to long source code sequences. The salient information of the whole code snippet account for an relatively small part. Additionally, unlike natural language, source code has complicated structure information. Thus, modelling the salient information from highly structured input presents a great challenge. To tackle this problem, we propose a graph neural network (GNN)-based model with a novel salient information selection layer. Specifically, to comprehensively encode the tokens of the source code, we employ a GNN-based encoder, which can be directly applied to the code graph to ensure that the syntactic information of code structure and semantic information of code sequence can be modelled sufficiently. To effectively discriminate the salient information, we introduce an information selection layer which contains two parts: a global filter gate used to filter irrelevant information, and a semantic-aware convolutional layer used to focus on the semantic information contained in code sequence. To improve the precision of the copy mechanism when decoding, we introduce a salient feature enhanced attention mechanism to facilitate the accuracy of copying tokens from input. Experimental results on an open source dataset indicate that our proposed model, equipped with the salient information selection layer, can effectively improve method naming performance compared to other state-of-the-art models. © 2022 John Wiley & Sons Ltd.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129806202&doi=10.1111%2fexsy.13030&partnerID=40&md5=8030820388d4b8b9471db9601604bba6,Expert Systems,Include,,,
Tian Z.; Zhang C.; Tian B.,Code Summarization Through Learning Linearized AST Paths with Transformer,"The lack of code comments is common in software projects. This work proposes TFSum, which generates from a function’s source code a readable summary to describe its functionality, with a Transformer based model trained on sequences linearized from the function’s abstract syntax tree (AST). To ensure the quality of the generated summaries, TFSum firstly parses from the function’s source code an AST of semantic richness, as the raw representation of the function; but linearizes and pre-processes it into a set of normalized token sequences, for efficient and effective following semantic representation learning. On this basis, an encoder-decoder based generative model that adopts the Transformer architecture is designed and trained to automatically generate code comments. The experimental evaluations conducted on a public dataset show the superiority of TFSum over state-of-the-art neural code summarization methods, with the BLEU score reaching 46.84. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Book chapter,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147852355&doi=10.1007%2f978-3-031-20738-9_7&partnerID=40&md5=220cea88b634670078d9d23b2a52a7f4,Lecture Notes on Data Engineering and Communications Technologies,Include,,,
Wu B.; Liang B.; Zhang X.,Turn tree into graph: Automatic code review via simplified AST driven graph convolutional network,"Automatic code review (ACR), which can relieve the costs of manual inspection, is an indispensable and essential task in software engineering. To deal with ACR, existing work is to serialize the abstract syntax tree (AST). However, making sense of the whole AST with sequence encoding approach is a daunting task, mostly due to some redundant nodes in AST hinder the transmission of node information. Not to mention that the serialized representation is inadequate to grasp the information of tree structure in AST. In this paper, we first present a new large-scale Apache Automatic Code Review (AACR) dataset for ACR task since there is still no publicly available dataset in this task. The release of this dataset would push forward the research in this field. Based on it, we propose a novel Simplified AST based Graph Convolutional Network (SimAST-GCN) to deal with ACR task. Concretely, to improve the efficiency of node information dissemination, we first simplify the AST of code by deleting the redundant nodes that do not contain connection attributes, and thus deriving a Simplified AST. Then, we construct a relation graph for each code based on the Simplified AST to properly embody the relations among code fragments of the tree structure into the graph. Subsequently, in the light of the merit of graph structure, we explore a graph convolution networks architecture that follows an attention mechanism to leverage the crucial implications of code fragments to derive code representations. Finally, we exploit a simple but effective subtraction operation in the representations between the original and revised code, enabling the revised difference to be preferably learned for deciding the results of ACR. Experimental results on the AACR dataset illustrate that our proposed model outperforms the state-of-the-art methods. © 2022 Elsevier B.V.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134877579&doi=10.1016%2fj.knosys.2022.109450&partnerID=40&md5=ca398d0bbf9b948417125efb4f7e9d55,Knowledge-Based Systems,Include,,Include,
Zhou Y.; Shen J.; Zhang X.; Yang W.; Han T.; Chen T.,Automatic source code summarization with graph attention networks,"Source code summarization aims to generate concise descriptions for code snippets in a natural language, thereby facilitates program comprehension and software maintenance. In this paper, we propose a novel approach–GSCS–to automatically generate summaries for Java methods, which leverages both semantic and structural information of the code snippets. To this end, GSCS utilizes Graph Attention Networks to process the tokenized abstract syntax tree of the program, which employ a multi-head attention mechanism to learn node features in diverse representation sub-spaces, and aggregate features by assigning different weights to its neighbor nodes. GSCS further harnesses an additional RNN-based sequence model to obtain the semantic features and optimizes the structure by combining its output with a transformed embedding layer. We evaluate our approach on two widely-adopted Java datasets; the experiment results confirm that GSCS outperforms the state-of-the-art baselines. © 2022 Elsevier Inc.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126290388&doi=10.1016%2fj.jss.2022.111257&partnerID=40&md5=e3f7e6aa4ea01ae7593bda0c338965ec,Journal of Systems and Software,Include,,,
Qu Z.; Hu Y.; Zeng J.; Cai B.; Yang S.,Method Name Generation Based on Code Structure Guidance,"The proper names of software engineering functions and methods can greatly assist developers in understanding and maintaining the code. Most researchers convert the method name generation task into the text summarization task. They take the token sequence and the abstract syntax tree (AST) of source code as input, and generate method names with a decoder. However, most proposed models learn semantic and structural features of the source code separately, resulting in poor performance in the method name generation task. Actually, each token in source code must have a corresponding node in its AST. Inspired by this observation, we propose SGMNG, a structure-guided method name generation model that learns the representation of two combined features. Additionally, we build a code graph called code relation graph (CRG) to describe the code structure clearly. CRG retains the structure of the AST of source code and contains data flows and control flows. SGMNG captures the semantic features of the code by encoding the token sequence and captures the structural features of the code by encoding the CRG. Then, SGMNG matches tokens in the sequence and nodes in the CRG to construct the combination of two features. We demonstrate the effectiveness of the proposed approach on the public dataset Java-Small with 700K samples, which indicates that our approach achieves significant improvement over the state-of-the-art baseline models in the ROUGE metric.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135770882&doi=10.1109%2fSANER53432.2022.00127&partnerID=40&md5=900a09371c404e9dc1383cf4e06642b7,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",Include,,Include,
Guo J.; Liu J.; Wan Y.; Li L.; Zhou P.,Modeling Hierarchical Syntax Structure with Triplet Position for Source Code Summarization,"Automatic code summarization, which aims to describe the source code in natural language, has become an essential task in software maintenance. Our fellow researchers have attempted to achieve such a purpose through various machine learning-based approaches. One key challenge keeping these approaches from being practical lies in the lacking of retaining the semantic structure of source code, which has unfortunately been overlooked by the state-of-the-art methods. Existing approaches resort to representing the syntax structure of code by modeling the Abstract Syntax Trees (ASTs). However, the hierarchical structures of ASTs have not been well explored. In this paper, we propose CODESCRIBE to model the hierarchical syntax structure of code by introducing a novel triplet position for code summarization. Specifically, CODESCRIBE leverages the graph neural network and Transformer to preserve the structural and sequential information of code, respectively. In addition, we propose a pointer-generator network that pays attention to both the structure and sequential tokens of code for a better summary generation. Experiments on two real-world datasets in Java and Python demonstrate the effectiveness of our proposed approach when compared with several state-of-the-art baselines. © 2022 Association for Computational Linguistics.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139035948&partnerID=40&md5=75c1f5cac559ddb1ae026364e3707e4a,Proceedings of the Annual Meeting of the Association for Computational Linguistics,Include,,,
Wang X.; Wu Q.; Zhang H.; Lyu C.; Jiang X.; Zheng Z.; Lyu L.; Hu S.,HELoC: Hierarchical Contrastive Learning of Source Code Representation,"Abstract syntax trees (ASTs) play a crucial role in source code representation. However, due to the large number of nodes in an AST and the typically deep AST hierarchy, it is challenging to learn the hierarchical structure of an AST effectively. In this paper, we propose HELoC, a hierarchical contrastive learning model for source code representation. To effectively learn the AST hierarchy, we use contrastive learning to allow the network to predict the AST node level and learn the hierarchical relationships between nodes in a self-supervised manner, which makes the representation vectors of nodes with greater differences in AST levels farther apart in the embedding space. By using such vectors, the structural similarities between code snippets can be measured more precisely. In the learning process, a novel GNN (called Residual Self-attention Graph Neural Network, RSGNN) is designed, which enables HELoC to focus on embedding the local structure of an AST while capturing its overall structure. HELoC is self-supervised and can be applied to many source code related downstream tasks such as code classification, code clone detection, and code clustering after pre-training. Our extensive experiments demonstrate that HELoC outperforms the state-of-the-art source code representation models.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133210433&doi=10.1145%2f3524610.3527896&partnerID=40&md5=d8f8aab6c1c776d3d977371794cf1a1c,IEEE International Conference on Program Comprehension,Include,,,
Hou S.; Chen L.; Ye Y.,Summarizing Source Code from Structure and Context,"Modern software developers tend to engage in social coding platforms to reuse code snippets to expedite the development process, while the codes on such platforms are often suffering from comments being mismatched, missing or outdated. This puts the code search and comprehension in difficulty, and increases the burden of maintenance for software building upon these codes. As summarizing code is beneficial yet it is very expensive for manual operation, in this paper, we elaborate an automatic and effective code summarization paradigm to address this laborious challenge. We represent a given code snippet as an abstract syntax tree (AST), and generate a set of compositional root-to-leaf paths to make the AST accessible regarding code context and structure in a less complex yet expressive way. Accordingly, we design a tree-based transformer model, called TreeXFMR, on these paths to summarize source code in a hierarchical attention operation. This yields two advantages on code representation learning: (1) attention mechanisms at token-and path-level attend the semantics and interactions of source code from different aspects; (2) bi-level positional encodings introduced reveal the intra- and inter-path structure of AST and improve the unambiguity of the representations. During decoding, TreeXFMR attends such learned representations to produce each output of natural language word. We further pre-train the transformer to achieve faster and better training convergence results. Extensive experiments on the code collection from GitHub demonstrate the effectiveness of TreeXFMR, which significantly outperforms state-of-the-art baselines. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140713399&doi=10.1109%2fIJCNN55064.2022.9892013&partnerID=40&md5=5f620b70d83f1491fb0fcaeaf72aadaf,Proceedings of the International Joint Conference on Neural Networks,Include,,,
Yuan Z.; Tan C.; Huang S.,Code Synonyms Do Matter: Multiple Synonyms Matching Network for Automatic ICD Coding,"Automatic ICD coding is defined as assigning disease codes to electronic medical records (EMRs). Existing methods usually apply label attention with code representations to match related text snippets. Unlike these works that model the label with the code hierarchy or description, we argue that the code synonyms can provide more comprehensive knowledge based on the observation that the code expressions in EMRs vary from their descriptions in ICD. By aligning codes to concepts in UMLS, we collect synonyms of every code. Then, we propose a multiple synonyms matching network to leverage synonyms for better code representation learning, and finally help the code classification. Experiments on the MIMIC-III dataset show that our proposed method outperforms previous state-of-the-art methods. © 2022 Association for Computational Linguistics.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140492793&partnerID=40&md5=1b93282e1bdbc8401edc4cf1ea28bdb7,Proceedings of the Annual Meeting of the Association for Computational Linguistics,Exclude,,,
Jin D.; Liu P.; Zhu Z.,Automatically Generating Code Comment Using Heterogeneous Graph Neural Networks,"Code summarization aims to generate readable summaries that describe the functionality of source code pieces. The main purpose of the code summarization is to help software developers understand the code and save their precious time. However, since programming languages are highly structured, it is challenging to generate high-quality code summaries. For this reason, this paper proposes a new approach named CCHG to automatically generate code comments. Compared to recent models that use additional information such as Abstract Syntax Trees as input, our proposed method only uses the most original code as input. We believe that programming languages are the same as natural languages. Each line of code is equivalent to a sentence, representing an independent meaning. Therefore, we split the entire code snippet into several sentence-level code. Coupled with token-level code, there are two types of code that need to be processed. So we propose heterogeneous graph networks to process the sentence-level and token-level code. Even though we do not introduce additional structural knowledge, the experimental results show that our model has a considerable performance, which indicates that our model can fully learn structural information and sequence information from code snippets.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135841227&doi=10.1109%2fSANER53432.2022.00125&partnerID=40&md5=ca88a884cb1bb226fb8db79ee007e615,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",Include,,,
Zhang F.; Chen B.; Li R.; Peng X.,A hybrid code representation learning approach for predicting method names,"Program semantic properties such as class names, method names, and variable names and types play an important role in software development and maintenance. Method names are of particular importance because they provide the cornerstone of abstraction for developers to communicate with each other for various purposes (e.g., code review and program comprehension). Existing method name prediction approaches often represent code as lexical tokens or syntactical AST (abstract syntax tree) paths, making them difficult to learn code semantics and hindering their effectiveness in predicting method names. Initial attempts have been made to represent code as execution traces to capture code semantics, but suffer scalability in collecting execution traces. In this paper, we propose a hybrid code representation learning approach, named METH2SEQ, to encode a method as a sequence of distributed vectors. METH2SEQ represents a method as (1) a bag of paths on the program dependence graph, (2) a sequence of typed intermediate representation statements and (3) a sentence of natural language comment, to scalably capture code semantics. The learned sequence of vectors of a method is fed to a decoder model to predict method names. Our evaluation with a dataset of 280.5K methods in 67 Java projects has demonstrated that METH2SEQ outperforms the two state-of-the-art code representation learning approaches in F1-score by 92.6% and 36.6%, while also outperforming two state-of-the-art method name prediction approaches in F1-score by 85.6% and 178.1%. © 2021 Elsevier Inc.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107616552&doi=10.1016%2fj.jss.2021.111011&partnerID=40&md5=e96fd839823d7d7ff6490f49b2347f9b,Journal of Systems and Software,Include,,Include,
Liang J.; Zou W.; Zhang J.; Huang Z.; Sun C.,A Deep Method Renaming Prediction and Refinement Approach for Java Projects,"During the process of software development and maintenance, developers would regularly refactor existing source code to improve efficiency and maintainability. Among various code refactoring activities, method renaming often happens within the whole project evolution process. To perform method renaming, developers should first identify the exact methods that should be renamed, which is generally tedious and error-prone through manual analysis. Towards this end, researchers have proposed some approaches to automatically recommend candidate methods for renaming. To further improve the performance of existing techniques, in this paper, we propose a novel approach that fully leverages historical code changes and overlapping relationships among code entities to identify renaming opportunities for methods. Specifically, we first embed methods into vectors and incorporate overlapping relationships among code entities by using different attention heads in a deep learning network. Then, we apply these obtained vectors to train a classifier to predict potential renaming opportunities for methods. Finally, we utilize historical renaming activities of related code entities to further refine the predicted results. Experimental results on 114,398 methods from 10 open source Java projects show that our approach could outperform the state-of-the-art approach by achieving an average F-measure of 80.02%. To better validate the effectiveness of our approach, we also explore the performance of some major components of our approach. For example, we find that employing related code entities help to improve the performance of our approach by 40.40% in terms of the average F-measure. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144110732&doi=10.1109%2fQRS54544.2021.00052&partnerID=40&md5=af58d21ad95db5185ea469ffaf7621be,"IEEE International Conference on Software Quality, Reliability and Security, QRS",Include,,Include,
Ge F.; Kuang L.,Keywords Guided Method Name Generation,"High quality method names are descriptive and readable, which are helpful for code development and maintenance. The majority of recent research suggest method names based on the text summarization approach. They take the token sequence and abstract syntax tree of the source code as input, and generate method names through a powerful neural network based model. However, the tokens composing the method name are closely related to the entity name within its method implementation. Actually, high proportions of the tokens in method name can be found in its corresponding method implementation, which makes it possible for incorporating these common shared token information to improve the performance of method naming task. Inspired by this key observation, we propose a two-stage keywords guided method name generation approach to suggest method names. Specifically, we decompose the method naming task into two subtasks, including keywords extraction task and method name generation task. For the keywords extraction task, we apply a graph neural network based model to extract the keywords from source code. For the method name generation task, we utilize the extracted keywords to guide the method name generation model. We apply a dual selective gate in encoder to control the information flow, and a dual attention mechanism in decoder to combine the semantics of input code sequence and keywords. Experiment results on an open source dataset demonstrate that keywords guidance can facilitate method naming task, which enables our model to outperform the competitive state-of-The-Art models by margins of 1.5%-3.5% in ROUGE metrics. Especially when programs share one common token with method names, our approach improves the absolute ROUGE-1 score by 7.8%.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113196338&doi=10.1109%2fICPC52881.2021.00027&partnerID=40&md5=3fd814c4f9f0acd066e3e0edeede365e,IEEE International Conference on Program Comprehension,Include,,,
Desai U.; Sridhara G.; Tamilselvam S.,Advances in Code Summarization,"Several studies have suggested that comments describing source code can help mitigate the burden of program understanding. However, software systems usually lack adequate comments and even when present, the comments may be obsolete or unhelpful. Researchers have addressed this issue by automatically generating comments from source code, a task referred to as Code Summarization. In this technical presentation, we take a deeper look at some of the significant, recent works in the area of code summarization and how each of them attempts to take a new perspective of this task including methods leveraging RNNs, Transformers, Graph neural networks and Reinforcement learning. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115693556&doi=10.1109%2fICSE-Companion52605.2021.00141&partnerID=40&md5=9461f97f900e4c4e2d00e5008e89145b,Proceedings - International Conference on Software Engineering,Include,,Include,
Liu S.; Chen Y.; Xie X.; Siow J.; Liu Y.,RETRIEVAL-AUGMENTED GENERATION FOR CODE SUMMARIZATION VIA HYBRID GNN,"Source code summarization aims to generate natural language summaries from structured code snippets for better understanding code functionalities. However, automatic code summarization is challenging due to the complexity of the source code and the language gap between the source code and natural language summaries. Most previous approaches either rely on retrieval-based (which can take advantage of similar examples seen from the retrieval database, but have low generalization performance) or generation-based methods (which have better generalization performance, but cannot take advantage of similar examples). This paper proposes a novel retrieval-augmented mechanism to combine the benefits of both worlds. Furthermore, to mitigate the limitation of Graph Neural Networks (GNNs) on capturing global graph structure information of source code, we propose a novel attention-based dynamic graph to complement the static graph representation of the source code, and design a hybrid message passing GNN for capturing both the local and global structural information. To evaluate the proposed approach, we release a new challenging benchmark, crawled from diversified large-scale open-source C projects (total 95k+ unique functions in the dataset). Our method achieves the state-of-the-art performance, improving existing methods by 1.42, 2.44 and 1.29 in terms of BLEU-4, ROUGE-L and METEOR. © 2021 ICLR 2021 - 9th International Conference on Learning Representations. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121205001&partnerID=40&md5=a4d297a0cd465773b6670095c2fff13e,ICLR 2021 - 9th International Conference on Learning Representations,Include,,,
Zhang X.; Yang S.; Duan L.; Lang Z.; Shi Z.; Sun L.,Transformer-XL with Graph Neural Network for Source Code Summarization,"Source code summarization is the task of generating a readable natural language to describe the functionality of source code. Code summarization is rapidly expanding, especially as the research takes great advantage of advances in neural networks and artificial intelligence technologies. Some mainstream methods input the structural information (abstract syntax tree (AST)) of the source code into the language model to generate relatively satisfactory comments. However, existing methods can not capture code's long dependencies from AST for effective code summarization. In this paper, we provide a novel way to generate code summaries by combining a graph-based neural network and a Transformer-XL network. We utilize the graph-based neural network to better capture the structure information of AST, and the Transformer-XL network to learn important tokens in the AST and alleviate the problem of long dependency. We evaluate our technique on the standard Java dataset. The experimental results show that the effectiveness of our model is remarkable. It pushes the precision score to 60.73% (5.21% absolute improvement) and the F1 score to 51.06%.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124318560&doi=10.1109%2fSMC52423.2021.9658619&partnerID=40&md5=03ee09ce85de4e698cecdde03bb3d2ba,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",Include,,Include,
Zeng J.; Zhang T.; Xu Z.,DG-Trans: Automatic Code Summarization via Dynamic Graph Attention-based Transformer,"Automatic code summarization is an important topic in the software engineering field, which aims to automatically generate the description for the source code. Based on Graph Neural Networks (GNN), most existing methods apply them to Abstract Syntax Tree (AST) to achieve code summarization. However, these methods face two major challenges: 1) they can only capture limited structural information of the source code; 2) they did not effectively solve Out-Of-Vocabulary (OOV) problems by reducing vocabulary size. In order to resolve these problems, in this paper, we propose a novel code summarization model named Dynamic Graph attention-based Transformer (DG-Trans for short), which effectively captures abundant information of the code subword sequence and utilizes the fusion of dynamic graph attention mechanism and Transformer. Extensive experiments show that DG-Trans is able to outperform state-of-the-art models (such as Ast-Attendgru, Transformer, and CodeGNN) by averagely increasing 8.39% and 8.86% on BLEU scores and ROUGUE-L, respectively. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146199326&doi=10.1109%2fQRS54544.2021.00088&partnerID=40&md5=1d7eda6868c42c29189049d9fd3a7224,"IEEE International Conference on Software Quality, Reliability and Security, QRS",Include,,,
LeClair A.; Haque S.; Wu L.; McMillan C.,Improved code summarization via a graph neural network,"Automatic source code summarization is the task of generatingnatural language descriptions for source code. Automatic code summarization is a rapidly expanding research area, especially as thecommunity has taken greater advantage of advances in neural network and AI technologies. In general, source code summarizationtechniques use the source code as input and outputs a natural language description. Yet a strong consensus is developing that usingstructural information as input leads to improved performance. Thefirst approaches to use structural information flattened the AST intoa sequence. Recently, more complex approaches based on randomAST paths or graph neural networks have improved on the modelsusing flattened ASTs. However, the literature still does not describethe using a graph neural network together with source code sequence as separate inputs to a model. Therefore, in this paper, wepresent an approach that uses a graph-based neural architecturethat better matches the default structure of the AST to generatethese summaries. We evaluate our technique using a data set of2.1 million Java method-comment pairs and show improvementover four baseline techniques, two from the software engineeringliterature, and two from machine learning literature. © 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091891388&doi=10.1145%2f3387904.3389268&partnerID=40&md5=ce69209bb60c6825fb0237b8e58ffa4f,IEEE International Conference on Program Comprehension,Include,,Include,
Rahman M.; Palani D.; Rigby P.C.,Natural Software Revisited,"Recent works have concluded that software code is more repetitive and predictable, i.e. more natural, than English texts. On re-examination, we find that much of the apparent 'naturalness' of source code is due to the presence of language specific syntax, especially separators, such as semi-colons and brackets. For example, separators account for 44% of all tokens in our Java corpus. When we follow the NLP practices of eliminating punctuation (e.g., separators) and stopwords (e.g., keywords), we find that code is still repetitive and predictable, but to a lesser degree than previously thought. We suggest that SyntaxTokens be filtered to reduce noise in code recommenders. Unlike the code written for a particular project, API code usage is similar across projects: a file is opened and closed in the same manner regardless of domain. When we restrict our n-grams to those contained in the Java API, we find that API usages are highly repetitive. Since API calls are common across programs, researchers have made reliable statistical models to recommend sophisticated API call sequences. Sequential n-gram models were developed for natural languages. Code is usually represented by an AST which contains control and data flow, making n-grams models a poor representation of code. Comparing n-grams to statistical graph representations of the same codebase, we find that graphs are more repetitive and contain higherlevel patterns than n-grams. We suggest that future work focus on statistical code graphs models that accurately capture complex coding patterns. Our replication package makes our scripts and data available to future researchers[1]. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072268618&doi=10.1109%2fICSE.2019.00022&partnerID=40&md5=3a29e89592980d8aae1bca34eb9308e0,Proceedings - International Conference on Software Engineering,Exclude,,,
Lu M.; Liu Y.; Li H.; Tan D.; He X.; Bi W.; Li W.,Hyperbolic function embedding: Learning hierarchical representation for functions of source code in hyperbolic space,"Recently, source code mining has received increasing attention due to the rapid increase of open-sourced code repositories and the tremendous values implied in this large dataset, which can help us understand the organization of functions or classes in different software and analyze the impact of these organized patterns on the software behaviors. Hence, learning an effective representation model for the functions of source code, from a modern view, is a crucial problem. Considering the inherent hierarchy of functions, we propose a novel hyperbolic function embedding (HFE) method, which can learn a distributed and hierarchical representation for each function via the Poincaré ball model. To achieve this, a function call graph (FCG) is first constructed to model the call relationship among functions. To verify the underlying geometry of FCG, the Ricci curvature model is used. Finally, an HFE model is built to learn the representations that can capture the latent hierarchy of functions in the hyperbolic space, instead of the Euclidean space, which are usually used in those state-of-the-art methods. Moreover, HFE is more compact in terms of lower dimensionality than the existing graph embedding methods. Thus, HFE is more effective in terms of computation and storage. To experimentally evaluate the performance of HFE, two application scenarios, namely, function classification and link prediction, have been applied. HFE achieves up to 7.6% performance improvement compared to the chosen state-of-the-art methods, namely, Node2vec and Struc2vec. © 2019 by the authors.",Article,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061872138&doi=10.3390%2fsym11020254&partnerID=40&md5=6c5c53d9c208b17eb6077ad1121a8f2b,Symmetry,Include,,,
Nguyen T.; Cicotti P.; Bylaska E.; Quinlan D.; Baden S.,"Automatic translation of MPI source into a latency-tolerant, data-driven form","Hiding communication behind useful computation is an important performance programming technique but remains an inscrutable programming exercise even for the expert. We present Bamboo, a code transformation framework that can realize communication overlap in applications written in MPI without the need to intrusively modify the source code. We reformulate MPI source into a task dependency graph representation, which partially orders the tasks, enabling the program to execute in a data-driven fashion under the control of an external runtime system. Experimental results demonstrate that Bamboo significantly reduces communication delays while requiring only modest amounts of programmer annotation for a variety of applications and platforms, including those employing co-processors and accelerators. Moreover, Bamboo's performance meets or exceeds that of labor-intensive hand coding. The translator is more than a means of hiding communication costs automatically; it demonstrates the utility of semantic level optimization against a well-known library. © 2017 Elsevier Inc.",Article,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015722274&doi=10.1016%2fj.jpdc.2017.02.009&partnerID=40&md5=bd799638fbb461ec317f227bb53c6fe8,Journal of Parallel and Distributed Computing,Exclude,,Exclude,
Cao R.; Chen L.; Li J.; Zhang H.; Xu H.; Zhang W.; Yu K.,A Heterogeneous Graph to Abstract Syntax Tree Framework for Text-to-SQL,"Text-to-SQL is the task of converting a natural language utterance plus the corresponding database schema into a SQL program. The inputs naturally form a heterogeneous graph while the output SQL can be transduced into an abstract syntax tree (AST). Traditional encoder-decoder models ignore higher-order semantics in heterogeneous graph encoding and introduce permutation biases during AST construction, thus incapable of exploiting the refined structure knowledge precisely. In this work, we propose a generic heterogeneous graph to abstract syntax tree (HG2AST) framework to integrate dedicated structure knowledge into statistics-based models. On the encoder side, we leverage a line graph enhanced encoder (LGESQL) to iteratively update both node and edge features through dual graph message passing and aggregation. On the decoder side, a grammar-based decoder first constructs the equivalent SQL AST and then transforms it into the desired SQL via post-processing. To avoid over-fitting permutation biases, we propose a golden tree-oriented learning (GTL) algorithm to adaptively control the expanding order of AST nodes. The graph encoder and tree decoder are combined into a unified framework through two auxiliary modules. Extensive experiments on various text-to-SQL datasets, including single/multi-table, single/cross-domain, and multilingual settings, demonstrate the superiority and broad applicability.  © 1979-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165895564&doi=10.1109%2fTPAMI.2023.3298895&partnerID=40&md5=14cbb6faed50ab156b65cb91e9f684ab,IEEE Transactions on Pattern Analysis and Machine Intelligence,Exclude,,Include,
Su X.; Zhang Q.; Shi C.; Liu J.; Hu L.,Syntax Tree Constrained Graph Network for Visual Question Answering,"Visual Question Answering (VQA) aims to automatically answer natural language questions related to given image content. Existing VQA methods integrate vision modeling and language understanding to explore the deep semantics of the question. However, these methods ignore the significant syntax information of the question, which plays a vital role in understanding the essential semantics of the question and guiding the visual feature refinement. To fill the gap, we suggested a novel Syntax Tree Constrained Graph Network (STCGN) for VQA based on entity message passing and syntax tree. This model is able to extract a syntax tree from questions and obtain more precise syntax information. Specifically, we parse questions and obtain the question syntax tree using the Stanford syntax parsing tool. From the word level and phrase level, syntactic phrase features and question features are extracted using a hierarchical tree convolutional network. We then design a message-passing mechanism for phrase-aware visual entities and capture entity features according to a given visual context. Extensive experiments on VQA2.0 datasets demonstrate the superiority of our proposed model. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178622580&doi=10.1007%2f978-981-99-8073-4_10&partnerID=40&md5=58e6d9070eb329241a215be00c9e80cd,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,Exclude,
Du C.; Li Y.; Wang Y.; Yu J.,Study on Automatic Code Summary Generation Method based on Graph Neural Network,"Automatic code summary generation techniques can help developers and other technical personnel to understand and comprehend the functions and structure of code more quickly. In existing methods of automatic code abstraction generation, there is a problem of poor utilization of code structure information, therefore, a model of automatic code abstraction generation based on graph neural network is proposed. Firstly, the abstract syntax tree is extracted from the code, and then the abstract syntax tree of the code is transformed into a graph representation using control flow statements in the data stream, which is trained by a graph convolutional neural network, and the obtained training results are fused with the original sequence representation to finally obtain a source code representation that incorporates the semantic information of the code context and structural information. Meanwhile, to improve the stability of the summary generation model, a deep learning model based on a multi-headed self-attentive mechanism is used to improve the existing sequence-to-sequence summary generation model. The accuracy and stability of the model-generated summaries are improved. Validation was performed on publicly available datasets, and experimental results show that the method achieves better results on BLEU-4, METEOR, and ROUGE-L metrics compared to other baseline models.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179505390&doi=10.1109%2fDSA59317.2023.00015&partnerID=40&md5=0ec978da5b42e327c8a031c00cb980f3,"Proceedings - 2023 10th International Conference on Dependable Systems and Their Applications, DSA 2023",Include,,Include,
Yang G.; Jin T.; Dou L.,Heterogeneous Directed Hypergraph Neural Network over abstract syntax tree (AST) for Code Classification,"Code classification is a difficult issue in program understanding and automatic coding. Due to the elusive syntax and complicated semantics in programs, most existing studies use techniques based on abstract syntax tree (AST) and graph neural network (GNN) to create code representations for code classification. These techniques utilize the structure and semantic information of the code, but they only take into account pairwise associations and neglect the high-order correlations that already exist between nodes in the AST, which may result in the loss of code structural information. On the other hand, while a general hypergraph can encode high-order data correlations, it is homogeneous and undirected which will result in a lack of semantic and structural information such as node types, edge types, and directions between child nodes and parent nodes when modeling AST. In this study, we propose to represent AST as a heterogeneous directed hypergraph (HDHG) and process the graph by heterogeneous directed hypergraph neural network (HDHGN) for code classification. Our method improves code understanding and can represent high-order data correlations beyond paired interactions. We assess heterogeneous directed hypergraph neural network (HDHGN) on public datasets of Python and Java programs. Our method outperforms previous AST-based and GNN-based methods, which demonstrates the capability of our model. © 2023 Knowledge Systems Institute Graduate School. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170092438&doi=10.18293%2fSEKE2023-136&partnerID=40&md5=0db69ae8a2a9b72d28c356d2d0fef154,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",Include,,Include,
Long T.; Xie Y.; Chen X.; Zhang W.; Cao Q.; Yu Y.,Multi-View Graph Representation for Programming Language Processing: An Investigation into Algorithm Detection,"Program representation, which aims at converting program source code into vectors with automatically extracted features, is a fundamental problem in programming language processing (PLP). Recent work tries to represent programs with neural networks based on source code structures. However, such methods often focus on the syntax and consider only one single perspective of programs, limiting the representation power of models. This paper proposes a multi-view graph (MVG) program representation method. MVG pays more attention to code semantics and simultaneously includes both data flow and control flow as multiple views. These views are then combined and processed by a graph neural network (GNN) to obtain a comprehensive program representation that covers various aspects. We thoroughly evaluate our proposed MVG approach in the context of algorithm detection, an important and challenging subfield of PLP. Specifically, we use a public dataset POJ-104 and also construct a new challenging dataset ALG-109 to test our method. In experiments, MVG outperforms previous methods significantly, demonstrating our model's strong capability of representing source code. © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147550181&partnerID=40&md5=59c88dcae8e71c3b1db0eb1776516e66,"Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022",Include,,,
Wijendra D.R.; Hewagamage K.P.,Cognitive Complexity Reduction through Control Flow Graph Generation,"The cognitive complexity of a software determines the human comprehension effort to determine its underlying logic. The human comprehension effort preliminary depends on the person, who deals with the software, the source code and the problem to be addressed. The understandability of a given source code is varying with each user such that the cognitive complexity results with a subjective measurement. The graphical representation of the logical behavior of a source code implies the individual to comprehend the logic easily rather than referring to its original code base. This paper evaluates the possibility of using control flow graph representation to reduce the cognitive complexity of a given source code, thereby ensuring a less software complexity. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135633012&doi=10.1109%2fI2CT54291.2022.9824923&partnerID=40&md5=bd29848be32df14ddcd45175bf1b614d,"2022 IEEE 7th International conference for Convergence in Technology, I2CT 2022",Exclude,,,
Zhang K.; Wang W.; Zhang H.; Li G.; Jin Z.,Learning to Represent Programs with Heterogeneous Graphs,"Code representation, which transforms programs into vectors with semantics, is essential for source code processing. We have witnessed the effectiveness of incorporating structural information (i.e., graph) into code representations in recent years. Specifically, the abstract syntax tree (AST) and the AST-augmented graph of the program contain much structural and semantic information, and most existing studies apply them for code representation. The graph adopted by existing approaches is homogeneous, i.e., it discards the type information of the edges and the nodes lying within AST. That may cause plausible obstruction to the representation model. In this paper, we propose to leverage the type information in the graph for code representation. To be specific, we propose the heterogeneous program graph (HPG), which provides the types of the nodes and the edges explicitly. Furthermore, we employ the heterogeneous graph transformer (HGT) architecture to generate representations based on HPG, considering the type of information during processing. With the additional types in HPG, our approach can capture complex structural information, produce accurate and delicate representations, and finally perform well on certain tasks. Our in-depth evaluations upon four classic datasets for two typical tasks (i.e., method name prediction and code classification) demonstrate that the heterogeneous types in HPG benefit the representation models. Our proposed HPG+HGT also outperforms the SOTA baselines on the subject tasks and datasets.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133172400&doi=10.1145%2f3524610.3527905&partnerID=40&md5=67576308d1c90ff9f1cafa4129a545ce,IEEE International Conference on Program Comprehension,Include,,Include,
Wu Q.; Jiang X.; Zheng Z.; Gao X.; Lyu C.; Lyu L.,Code Representation Based on Hybrid Graph Modelling,"Several sequence- or abstract syntax tree (AST)-based models have been proposed for modelling lexical-level and syntactic-level information of source code. However, an effective method of learning code semantic information is still lacking. Thus, we propose a novel code representation method based on hybrid graph modelling, called HGCR. HGCR is a code information extraction model. Specifically, in HGCR, two novel graphs, the Structure Graph (SG) and the Execution Data Flow Graph (EDFG), are first extracted from AST to model the syntactic structural and semantic information of source code, respectively. Then, two improved graph neural networks are applied to learn the graphs to obtain an effective code representation. We demonstrate the effectiveness of our model on two common code understanding tasks: code classification and code clone detection. Empirically, our model outperforms state-of-the-art models. © 2021, Springer Nature Switzerland AG.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121904967&doi=10.1007%2f978-3-030-92307-5_35&partnerID=40&md5=b4be88d3b89f31e430c408dceff98715,Communications in Computer and Information Science,Include,,,
Aiyankovil K.G.; Monahan R.; O’Donoghue D.P.,Upcycling formal specifications for similar implementations with Arís,"We describe the Arís system for creating new formal specifications for source code by transferring existing specifications to similar implementations. We show the code graphs underlying its operation, graph matching supports retrieval, and pattern completion enables transfer of specifications to new implementations. A theorem prover formally verifies the new specifications. Copyright © 2021 for this paper by its authors.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120983707&partnerID=40&md5=5386ed2a59e342566d9738b0f729c12a,CEUR Workshop Proceedings,Exclude,,Include,Exclude
Wang Y.; Li H.,Code Completion by Modeling Flattened Abstract Syntax Trees as Graphs,"Code completion has become an essential component of integrated development environments. Contemporary code completion methods rely on the abstract syntax tree (AST) to generate syntactically correct code. However, they cannot fully capture the sequential and repetitive patterns of writing code and the structural information of the AST. To alleviate these problems, we propose a new code completion approach named CCAG, which models the flattened sequence of a partial AST as an AST graph. CCAG uses our proposed AST Graph Attention Block to capture different dependencies in the AST graph for representation learning in code completion. The sub-tasks of code completion are optimized via multi-task learning in CCAG, and the task balance is automatically achieved using uncertainty without the need to tune task weights. The experimental results show that CCAG has superior performance than state-of-the-art approaches and it is able to provide intelligent code completion. © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111430007&partnerID=40&md5=cf52515dc57a57dab1b36daad9a9a8a4,"35th AAAI Conference on Artificial Intelligence, AAAI 2021",Exclude,,Include,
Malloy B.A.; McGregor J.D.; Elliott S.A.,Using the Sage++ Toolkit to Model Control Flow and Extend Cyclomatic Complexity,"The unavailability of comprehensive, user-friendly programming environments is one of the most imposing obstacles to the development and testing of software applications. The most critical advances needed to remove the obstacles are improved tools for program analysis, visualization, evaluation, and debugging. In this project, we use a tool, Sage++, to model control flow using an internal representation of the source code called a program tree, a form similar to an abstract syntax tree. We use the xvcg tool to visualize the control flow graph. To facilitate program evaluation, the control flow graph representation is used to compute software complexity using McCabe's cyclomatic complexity measure. Since cyclomatic complexity does not include program exceptions in its consideration, we extend the complexity measure to include C++ exceptions, since they alter flow of control and thereby affect the cyclomatic complexity of the program.",Conference paper,2000,https://www.scopus.com/inward/record.uri?eid=2-s2.0-1642320407&partnerID=40&md5=df6a4723ab9d79be73a7df2d3a2632ef,Proceedings of the Joint Conference on Information Sciences,Exclude,,,
Pancake C.M.,Customizable portrayals of program structure,"Current debugging tools offer few facilities for user-defined views of program behavior; those that exist are difficult to use. This paper demonstrates that visual idioms derived from the programmer's conceptual view can make debugging both easier and more responsive to user needs. Ii describes a user-defined abstraction, the program phase tree (PPT), that displays information on dynamic program structure. The PPT is specified interactively with the help of a graphical editing tool. Since the user docs not need to modify program code, nor learn a specification language, no new source of error is introduced. Moreover, since the visual idiom - representation of program structure as a tree of activity phases - is derived from the familiar concept of a call graph, learning time is negligible. The integration of PPT representations into two common types of parallel debuggers (breakpoint-style and trace-based) is described.",Conference paper,1993,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032946743&doi=10.1145%2f174266.174274&partnerID=40&md5=bc4708af1eb38d7c56aa157385dc7334,"Proceedings of the 1993 ACM/ONR Workshop on Parallel and Distributed Debugging, PADD 1993",Exclude,,,
Kinloch D.A.; Munro M.,Understanding C programs using the Combined C graph representation,"The process of program comprehension is often aided by the use of static analysis tools to provide a maintainer with different views of the code. Each view however often requires a different intermediate program representation, leading to redundancies and repetition of information. A solution is to develop a single intermediate representation which contains sufficient information to construct each program view. This paper describes the Combined C Graph (CCG), a fine-grained intermediate representation for programs written in the C language from which program slices, call graph, flow-sensitive data flow, definition-use and control dependence views can be easily constructed. The CCG allows the representation of embedded side effects and control flows and value-returning functions with value parameters. The effects of pointer parameters are also modelled. Construction of the CCG makes use of the PERPLEX C analysis tool which produces a generic Prolog fact base representation of the source code. Existing data flow analysis techniques are extended to allow the computation of flow-sensitive data flow analysis information. © 1994 IEEE.",Conference paper,1994,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84914134693&doi=10.1109%2fICSM.1994.336777&partnerID=40&md5=2adf2b5881d5e222c3446dcdd12f1fca,"Proceedings - 1994 International Conference on Software Maintenance, ICSM 1994",Exclude,,,
Bhuiyan M.H.M.,The Call Graph Chronicles: Unleashing the Power Within,"Call graph generation is critical for program understanding and analysis, but achieving both accuracy and precision is challenging. Existing methods trade off one for the other, particularly in dy- namic languages like JavaScript. This paper introduces ""Graphia,""an approach that combines structural and semantic information using a Graph Neural Network (GNN) to enhance call graph accu- racy. Graphia's two-step process employs an initial call graph as training data for the GNN, which then uncovers true call edges in new programs. Experimental results show Graphia significantly improves true positive rates in vulnerability detection, achieving up to 95%. This approach advances call graph accuracy by effectively incorporating code structure and context, particularly in complex dynamic language scenarios. © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180550989&doi=10.1145%2f3611643.3617854&partnerID=40&md5=35176d270a32379943dcc133e5f657ac,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,Include,,,
Liang J.; Du Z.; Liang J.; Yao K.; Cao F.,Long and Short-Range Dependency Graph Structure Learning Framework on Point Cloud,"Graph convolutional neural networks can effectively process geometric data and thus have been successfully used in point cloud data representation. However, existing graph-based methods usually adopt the K-nearest neighbor (KNN) algorithm to construct graphs, which may not be optimal for point cloud analysis tasks, owning to the solution of KNN is independent of network training. In this paper, we propose a novel graph structure learning convolutional neural network (GSLCN) for multiple point cloud analysis tasks. The fundamental concept is to propose a general graph structure learning architecture (GSL) that builds long-range and short-range dependency graphs. To learn optimal graphs that best serve to extract local features and investigate global contextual information, respectively, we integrated the GSL with the designed graph convolution operator under a unified framework. Furthermore, we design the graph structure losses with some prior knowledge to guide graph learning during network training. The main benefit is that given labels and prior knowledge are taken into account in GSLCN, providing useful supervised information to build graphs and thus facilitating the graph convolution operation for the point cloud. Experimental results on challenging benchmarks demonstrate that the proposed framework achieves excellent performance for point cloud classification, part segmentation, and semantic segmentation.  © 1979-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165918718&doi=10.1109%2fTPAMI.2023.3298711&partnerID=40&md5=13d6e0511bdbcdb06a18d25c55c9e830,IEEE Transactions on Pattern Analysis and Machine Intelligence,Exclude,,,
Duan R.; Yan C.; Wang J.; Jiang C.,Class-homophilic-based data augmentation for improving graph neural networks,"Data augmentation has been shown to improve graph neural networks (GNNs). Existing graph data augmentation is achieved by adding or removing edges or changing the input node features due to graph data's complexity and non-Euclidean nature. However, the graphs generated by the above augmentation operations have similar or identical structures as the original graph, which leads to similar or identical structural information learned by GNNs from the original and augmented graphs. Two problems arise from this: restricted information and low applicability. To solve these problems, we propose Class-hOmophilic-based Data Augmentation (CODA), which improves existing GNNs by helping them learn adequate and extra structural class information, which is lacking in the original graph, and promotes GNNs’ application to graphs with a large number of interclass edges. We first pretrain the GNNs and then design a new augmentation method that generates an approximate class-homophilic graph according to the pretrained GNNs. In the end, we design learnable node-level self-attention mechanisms with telescopic coefficients, which result in GNNs integrating the structural information of the two graphs in a more principled way to break the constraint of pretrained GNNs. Extensive experiments on various datasets show that augmentation via CODA improves performance and applicability across GNN architectures. The source code of CODA is publicly available at https://github.com/graphNN/CODA. © 2023 Elsevier B.V.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151801308&doi=10.1016%2fj.knosys.2023.110518&partnerID=40&md5=5b63e7ce95ae8386c441de9f594cc0b1,Knowledge-Based Systems,Exclude,,,
Ju M.; Fan Y.; Zhang C.; Ye Y.,Let Graph Be the Go Board: Gradient-Free Node Injection Attack for Graph Neural Networks via Reinforcement Learning,"Graph Neural Networks (GNNs) have drawn significant attentions over the years and been broadly applied to essential applications requiring solid robustness or vigorous security standards, such as product recommendation and user behavior modeling. Under these scenarios, exploiting GNN’s vulnerabilities and further downgrading its performance become extremely incentive for adversaries. Previous attackers mainly focus on structural perturbations or node injections to the existing graphs, guided by gradients from the surrogate models. Although they deliver promising results, several limitations still exist. For the structural perturbation attack, to launch a proposed attack, adversaries need to manipulate the existing graph topology, which is impractical in most circumstances. Whereas for the node injection attack, though being more practical, current approaches require training surrogate models to simulate a white-box setting, which results in significant performance downgrade when the surrogate architecture diverges from the actual victim model. To bridge these gaps, in this paper, we study the problem of black-box node injection attack, without training a potentially misleading surrogate model. Specifically, we model the node injection attack as a Markov decision process and propose Gradient-free Graph Advantage Actor Critic, namely G2A2C, a reinforcement learning framework in the fashion of advantage actor critic. By directly querying the victim model, G2A2C learns to inject highly malicious nodes with extremely limited attacking budgets, while maintaining a similar node feature distribution. Through our comprehensive experiments over eight acknowledged benchmark datasets with different characteristics, we demonstrate the superior performance of our proposed G2A2C over the existing state-of-the-art attackers. Source code is publicly available at: https://github.com/jumxglhf/G2A2C. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167872457&partnerID=40&md5=36a5f9ab75590a16ad648d345cf5e05d,"Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",Exclude,,Exclude,
Sarkar D.; Roy S.; Malakar S.; Sarkar R.,A modified GNN architecture with enhanced aggregator and Message Passing Functions,"Graph neural networks (GNN) uphold the essence of irregularly structured information embedded in a graph via message passing among the nodes and aggregating the node features at various levels of the graph. In the past, researchers have extensively used the GNN models for several semi-supervised node classification tasks. Existing GNN models do not use nodes’ information sufficiently. The use of inter-node feature-level correlational information with the existing GNN models might lead to more powerful learning models. Here, a weighting scheme has been developed for message passing and aggregation functions. This model has been named “Vector GNN”, or in short, “VecGNN”, due to its relationship with vector space. VecGNN takes into consideration the relative position of a node with respect to its neighboring nodes in the feature space, which influences the weight of features passed to the information aggregation phase. These weights are assigned using two different statistical measures: Jaccard's coefficient and Cosine similarity. The proposed weighting scheme uses a generalized approach that can be easily incorporated into several GNN frameworks. VecGNN is evaluated using three citation datasets: Citeseer, Pubmed, and Cora. On these datasets, three sets of experiments have been conducted with varying numbers of training and testing nodes. We have used training, validation, and test set nodes with ratios of 1:1:8, 2:1:7, and 3:1:6. Experimenting on these, we observe an improvement of 2%–4% over the baseline models: Graph Convolution Network (GCN), Graph Attention Network (GAT), and Jumping Knowledge Networks (JKNets). The source code is available at the link https://github.com/sourodeeproy/VecGNN. © 2023 Elsevier Ltd",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149678684&doi=10.1016%2fj.engappai.2023.106077&partnerID=40&md5=9cf6e022122ea4389c23acc69dd159ae,Engineering Applications of Artificial Intelligence,Exclude,,,
Yeh P.-K.; Chen H.-W.; Chen M.-S.,Random Walk Conformer: Learning Graph Representation from Long and Short Range,"While graph neural networks (GNNs) have achieved notable success in various graph mining tasks, conventional GNNs only model the pairwise correlation in 1-hop neighbors without considering the long-term relations and the high-order patterns, thus limiting their performances. Recently, several works have addressed these issues by exploring the motif, i.e., frequent subgraphs. However, these methods usually require an unacceptable computational time to enumerate all possible combinations of motifs. In this paper, we introduce a new GNN framework, namely Random Walk Conformer (RWC), to exploit global correlations and local patterns based on the random walk, which is a promising method to discover the graph structure. Besides, we propose random walk encoding to help RWC capture topological information, which is proven more expressive than conventional spatial encoding. Extensive experiment results manifest that RWC achieves state-of-the-art performance on graph classification and regression tasks. The source code of RWC is available at https://github.com/b05901024/RandomWalkConformer. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168252858&partnerID=40&md5=e32eec42a3a6c34d5fa29e7ac7ed51fc,"Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",Exclude,,,
Wang H.; Fu Y.; Yu T.; Hu L.; Jiang W.; Pu S.,PROSE: Graph Structure Learning via Progressive Strategy,"Graph Neural Networks (GNNs) have been a powerful tool to acquire high-quality node representations dealing with graphs, which strongly depends on a promising graph structure. In the real world scenarios, it is inevitable to introduce noises in graph topology. To prevent GNNs from the disturbance of irrelevant edges or missing edges, graph structure learning is proposed and has attracted considerable attentions in recent years. In this paper, we argue that current graph structure learning methods still pay no regard to the status of nodes and just judge all of their connections simultaneously using a monotonous standard, which will lead to indeterminacy and instability in the optimization process. We designate these methods as status-unaware models. To demonstrate the rationality of our point of view, we conduct exploratory experiments on publicly available datasets, and discover some exciting observations. Afterwards, we propose a new model named Graph Structure Learning via Progressive Strategy (PROSE) according to the observations, which uses a progressive strategy to acquire ideal graph structure in a status-aware way. Concretely, PROSE consists of progressive structure splitting module (PSS) and progressive structure refining module (PSR) to modify node connections according to their global potency, and we also introduce horizontal position encoding and vertical position encoding in order to capture fruitful graph topology information ignored by previous methods. On several widely-used graph datasets, we conduct extensive experiments to demonstrate the effectiveness of our model, and the source code 1 https://github.com/tigerbunny2023/PROSE is provided.  © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171344722&doi=10.1145%2f3580305.3599476&partnerID=40&md5=5d827427c38c48f4686d20047c24fde6,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Exclude,,,
Bi W.; Xu B.; Sun X.; Xu L.; Shen H.; Cheng X.,Predicting the Silent Majority on Graphs: Knowledge Transferable Graph Neural Network,"Graphs consisting of vocal nodes (""the vocal minority"") and silent nodes (""the silent majority""), namely VS-Graph, are ubiquitous in the real world. The vocal nodes tend to have abundant features and labels. In contrast, silent nodes only have incomplete features and rare labels, e.g., the description and political tendency of politicians (vocal) are abundant while not for ordinary civilians (silent) on the twitter's social network. Predicting the silent majority remains a crucial yet challenging problem. However, most existing Graph Neural Networks (GNNs) assume that all nodes belong to the same domain, without considering the missing features and distribution-shift between domains, leading to poor ability to deal with VS-Graph. To combat the above challenges, we propose Knowledge Transferable Graph Neural Network (KTGNN), which models distribution-shifts during message passing and learns representation by transferring knowledge from vocal nodes to silent nodes. Specifically, we design the domain-adapted ""feature completion and message passing mechanism""for node representation learning while preserving domain difference. And a knowledge transferable classifier based on KL-divergence is followed. Comprehensive experiments on real-world scenarios (i.e., company financial risk assessment and political elections) demonstrate the superior performance of our method. Our source code has been open-sourced1. © 2023 Owner/Author.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159371830&doi=10.1145%2f3543507.3583287&partnerID=40&md5=e4168dfd4e921ae6e9e7a41b8e2e336d,"ACM Web Conference 2023 - Proceedings of the World Wide Web Conference, WWW 2023",Exclude,,Exclude,
Liu Y.; Han H.; Zhou G.; Yang C.; Zhang S.; Huang H.; Shi C.; Zhao T.; Wu J.; Wang H.,GammaGL: A Multi-Backend Library for Graph Neural Networks,"Graph Neural Networks (GNNs) have shown their superiority in modeling graph-structured data, and gained much attention over the last five years. Though traditional deep learning frameworks such as TensorFlow and PyTorch provide convenient tools for implementing neural network algorithms, they do not support the key operations of GNNs well, e.g., the message passing computation based on sparse matrices. To address this issue, GNN libraries such as PyG are proposed by introducing rich Application Programming Interfaces (APIs) specialized for GNNs. However, most current GNN libraries only support a specific deep learning framework as the backend, e.g., PyG is tied up with PyTorch. In practice, users usually need to combine GNNs with other neural network components, which may come from their co-workers or open-source codes with different deep-learning backends. Consequently, users have to be familiar with various GNN libraries, and rewrite their GNNs with corresponding APIs. To provide a more convenient user experience, we present Gamma Graph Library (GammaGL), a GNN library that supports multiple deep learning frameworks as backends. GammaGL uses a framework-agnostic design that allows users to easily switch between deep learning backends on top of existing components with a single line of code change. Following the tensor-centric design idea, GammaGL splits the graph data into several key tensors, and abstracts GNN computational processes (such as message passing and graph mini-batch operations) into a few key functions. We develop many efficient operators in GammaGL for acceleration. So far, GammaGL has provided more than 40 GNN examples that can be applied to a variety of downstream tasks. GammaGL also provides tools for heterogeneous graph neural networks and recommendations to facilitate research in related fields. We present the performance of models implemented by GammaGL and the time consumption of our optimized operators to show the efficiency. Our library is available at https://github.com/BUPTGAMMA/GammaGL. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168677220&doi=10.1145%2f3539618.3591891&partnerID=40&md5=e232b5d0df0d4d71117ce27bea70aa1e,SIGIR 2023 - Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,Exclude,,Exclude,
Na G.S.,Substructure interaction graph network with node augmentation for hybrid chemical systems of heterogeneous substructures,"Complex chemical systems containing multiple heterogeneous substructures are common in real-world chemical applications, such as hybrid perovskites and inorganic catalysts. Although graph neural networks (GNNs) have achieved numerous successes in predicting the physical and chemical properties of a single molecule or crystal structure, GNNs for multiple heterogeneous substructures have not yet been studied in chemical science. In this paper, we propose substructure interaction graph network with node augmentation (SIGNNA) that is an integrated architecture of heterogeneous GNNs to predict the physical and chemical properties from the interactions between the heterogeneous substructures of the chemical systems. In addition to the network architecture, we devise a node augmentation method to generate valid subgraphs from given chemical systems for graph-based machine learning, even though the decomposed substructures are physically invalid. SIGNNA outperformed state-of-the-art GNNs in the experimental evaluations and the high-throughput screening on benchmark materials datasets of hybrid organic–inorganic perovskites and inorganic catalysts. The source code of SIGNNA is publicly available at https://github.com/ngs00/signna. © 2022 The Author(s)",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140139891&doi=10.1016%2fj.commatsci.2022.111835&partnerID=40&md5=4a767e687fe3d8dadcd947f64bfac752,Computational Materials Science,Exclude,,Exclude,
Wu S.; Shen X.; Xia R.,Commonsense Knowledge Graph Completion Via Contrastive Pretraining and Node Clustering,"The nodes in the commonsense knowledge graph (CSKG) are normally represented by free-form short text (e.g., word or phrase). Different nodes may represent the same concept. This leads to the problems of edge sparsity and node redundancy, which challenges CSKG representation and completion. On the one hand, edge sparsity limits the performance of graph representation learning; On the other hand, node redundancy makes different nodes corresponding to the same concept have inconsistent relations with other nodes. To address the two problems, we propose a new CSKG completion framework based on Contrastive Pretraining and Node Clustering (CPNC). Contrastive Pretraining constructs positive and negative head-tail node pairs on CSKG and utilizes contrastive learning to obtain better semantic node representation. Node Clustering aggregates nodes with the same concept into a latent concept, assisting the task of CSKG completion. We evaluate our CPNC approach on two CSKG completion benchmarks (CN-100K and ATOMIC), where CPNC outperforms the state-of-the-art methods. Extensive experiments demonstrate that both Contrastive Pretraining and Node Clustering can significantly improve the performance of CSKG completion. The source code of CPNC is publicly available on https://github.com/NUSTM/CPNC. © 2023 Association for Computational Linguistics.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175453934&partnerID=40&md5=c35cb33200e532763e490c7dd6156d15,Proceedings of the Annual Meeting of the Association for Computational Linguistics,Exclude,,,
Wang K.; Liang Y.; Li X.; Li G.; Ghanem B.; Zimmermann R.; zhou Z.; Yi H.; Zhang Y.; Wang Y.,Brave the Wind and the Waves: Discovering Robust and Generalizable Graph Lottery Tickets,"The training and inference of Graph Neural Networks (GNNs) are costly when scaling up to large-scale graphs. Graph Lottery Ticket (GLT) has presented the first attempt to accelerate GNN inference on large-scale graphs by jointly pruning the graph structure and the model weights. Though promising, GLT encounters robustness and generalization issues when deployed in real-world scenarios, which are also long-standing and critical problems in deep learning ideology. In real-world scenarios, the distribution of unseen test data is typically diverse. We attribute the failures on out-of-distribution (OOD) data to the incapability of discerning causal patterns, which remain stable amidst distribution shifts. In traditional spase graph learning, the model performance deteriorates dramatically as the graph/network sparsity exceeds a certain high level. Worse still, the pruned GNNs are hard to generalize to unseen graph data due to limited training set at hand. To tackle these issues, we propose the Resilient Graph Lottery Ticket (RGLT) to find more robust and generalizable GLT in GNNs. Concretely, we reactivate a fraction of weights/edges by instantaneous gradient information at each pruning point. After sufficient pruning, we conduct environmental interventions to extrapolate potential test distribution. Finally, we perform last several rounds of model averages to further improve generalization. We provide multiple examples and theoretical analyses that underpin the universality and reliability of our proposal. Further, RGLT has been experimentally verified across various independent identically distributed (IID) and out-of-distribution (OOD) graph benchmarks. The source code for this work is available at <uri>https://github.com/Lyccl/RGLT</uri> for PyTorch implementation. IEEE",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179830536&doi=10.1109%2fTPAMI.2023.3342184&partnerID=40&md5=8d61b393d25894e4925c8d7356a3fcc2,IEEE Transactions on Pattern Analysis and Machine Intelligence,Exclude,,Exclude,
Hosseini R.; Simini F.; Vishwanath V.; Sivakumar R.; Shanmugavelu S.; Chen Z.; Zlotnik L.; Wang M.; Colangelo P.; Deng A.; Lassen P.; Pathan S.,Exploring the Use of Dataflow Architectures for Graph Neural Network Workloads,"Graph Neural Networks (GNNs), which learn representations of non-euclidean data, are rapidly rising in popularity and are used in several computationally demanding scientific applications. As these deep learning models become more prevalent in practical applications, their performance during inference becomes increasingly critical. GNNs have been shown to suffer from hard memory and computational bottlenecks on traditional hardware platforms (i.e. GPUs) due in part to their reliance on non-contiguous data structures. While dataflow architectures used by emerging hardware accelerators provide a potential solution to alleviate these issues, end-to-end GNN models are generally not yet supported by these platforms. Thus, it is not currently possible to directly compare the performance of GNNs on traditional GPUs with these hardware accelerators. In this work, we analyze the performance of operators relevant to modern GNNs on three platforms: NVIDIA A100 GPU, Groq GroqChip1, and SambaNova Reconfigurable Dataflow Unit (RDU). Specifically, we first profile several modern GNN models on traditional GPUs to determine the operators, fused kernels, and message passing layers most relevant to these architectures. Then, we systematically benchmark and analyze the performance for each of these levels of abstraction on each hardware platform. Our analysis shows that (1) due to their reliance on non-contiguous data, GNNs suffer from cache inefficiency on conventional GPUs (2) dataflow architectures, due in part to their cache-less design, are able to implicitly optimize for operators pertinent to GNNs and, (3) the RDU and GroqChip1 platforms enable significant inference speedup compared to traditional GPU on pertinent subsets of end-to-end GNN networks. Our open source code is available at https://github.com/ryienh/gnn-ops-benchmark. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171386118&doi=10.1007%2f978-3-031-40843-4_48&partnerID=40&md5=7aaa749f57afbd12d6b9a93f08ab59d4,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,Exclude,
Wen X.-C.; Chen Y.; Gao C.; Zhang H.; Zhang J.M.; Liao Q.,Vulnerability Detection with Graph Simplification and Enhanced Graph Representation Learning,"Prior studies have demonstrated the effectiveness of Deep Learning (DL) in automated software vulnerability detection. Graph Neural Networks (GNNs) have proven effective in learning the graph representations of source code and are commonly adopted by existing DL-based vulnerability detection methods. However, the existing methods are still limited by the fact that GNNs are essentially difficult to handle the connections between long-distance nodes in a code structure graph. Besides, they do not well exploit the multiple types of edges in a code structure graph (such as edges representing data flow and control flow). Consequently, despite achieving state-of-the-art performance, the existing GNN-based methods tend to fail to capture global information (i.e., long-range dependencies among nodes) of code graphs. To mitigate these issues, in this paper, we propose a novel vulnerability detection framework with grAph siMplification and enhanced graph rePresentation LEarning, named AMPLE. AMPLE mainly contains two parts: 1) graph simplification, which aims at reducing the distances between nodes by shrinking the node sizes of code structure graphs; 2) enhanced graph representation learning, which involves one edge-aware graph convolutional network module for fusing heterogeneous edge information into node representations and one kernel-scaled representation module for well capturing the relations between distant graph nodes. Experiments on three public benchmark datasets show that AMPLE outperforms the state-of-the-art methods by 0.39%-35.32% and 7.64%-199.81% with respect to the accuracy and F1 score metrics, respectively. The results demonstrate the effectiveness of AMPLE in learning global information of code graphs for vulnerability detection. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171196046&doi=10.1109%2fICSE48619.2023.00191&partnerID=40&md5=10fc8fedd7bbaa32d682dafa677fb841,Proceedings - International Conference on Software Engineering,Include,,Include,
Yin S.; Zhong G.,LGI-GT: Graph Transformers with Local and Global Operators Interleaving,"Since Transformers can alleviate some critical and fundamental problems of graph neural networks (GNNs), such as over-smoothing, over-squashing and limited expressiveness, they have been successfully applied to graph representation learning and achieved impressive results. However, although there are many works dedicated to make graph Transformers (GTs) aware of the structure and edge information by specifically tailored attention forms or graph-related positional and structural encodings, few works address the problem of how to construct high-performing GTs with modules of GNNs and Transformers. In this paper, we propose a novel graph Transformer with local and global operators interleaving (LGI-GT), in which we further design a new method propagating embeddings of the [CLS] token for global information representation. Additionally, we propose an effective message passing module called edge enhanced local attention (EELA), which makes LGI-GT a full-attention GT. Extensive experiments demonstrate that LGI-GT performs consistently better than previous state-of-the-art GNNs and GTs, while ablation studies show the effectiveness of the proposed LGI scheme and EELA. The source code of LGI-GT is available at https://github.com/shuoyinn/LGI-GT. © 2023 International Joint Conferences on Artificial Intelligence. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170380374&partnerID=40&md5=511f0cfead1d55c4f33d82b50a6a7992,IJCAI International Joint Conference on Artificial Intelligence,Exclude,,,
Maurya S.K.; Liu X.; Murata T.,Simplifying approach to node classification in Graph Neural Networks,"Graph Neural Networks (GNNs) have become one of the indispensable tools to learn from graph-structured data, and their usefulness has been shown in wide variety of tasks. In recent years, there have been tremendous improvements in architecture design, resulting in better performance on various prediction tasks. In general, these neural architectures combine node feature aggregation and feature transformation using learnable weight matrix in the same layer. This makes it challenging to analyze the importance of node features aggregated from various hops and the expressiveness of the neural network layers. As different graph datasets show varying levels of homophily and heterophily in features and class label distribution, it becomes essential to understand which features are important for the prediction tasks without any prior information. In this work, we decouple the node feature aggregation step and depth of graph neural network, and empirically analyze how different aggregated features play a role in prediction performance. We show that not all features generated via aggregation steps are useful, and often using these less informative features can be detrimental to the performance of the GNN model. Through our experiments, we show that learning certain subsets of these features can lead to better performance on wide variety of datasets. Based on our observations, we introduce several key design strategies for graph neural networks. More specifically, we propose to use softmax as a regularizer and ”soft-selector” of features aggregated from neighbors at different hop distances; and L2-Normalization over GNN layers. Combining these techniques, we present a simple and shallow model, Feature Selection Graph Neural Network (FSGNN), and show empirically that the proposed model achieves comparable or even higher accuracy than state-of-the-art GNN models in nine benchmark datasets for the node classification task, with remarkable improvements up to 51.1%. Source code available at https://github.com/sunilkmaurya/FSGNN/. © 2022 Elsevier B.V.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130550289&doi=10.1016%2fj.jocs.2022.101695&partnerID=40&md5=ed2d1629afee3a31ac27dab3854c3969,Journal of Computational Science,Exclude,,,
Gu H.; Cheng H.; Ma A.; Li Y.; Wang J.; Xu D.; Ma Q.,scGNN 2.0: a graph neural network tool for imputation and clustering of single-cell RNA-Seq data,"MOTIVATION: Gene expression imputation has been an essential step of the single-cell RNA-Seq data analysis workflow. Among several deep-learning methods, the debut of scGNN gained substantial recognition in 2021 for its superior performance and the ability to produce a cell-cell graph. However, the implementation of scGNN was relatively time-consuming and its performance could still be optimized. RESULTS: The implementation of scGNN 2.0 is significantly faster than scGNN thanks to a simplified close-loop architecture. For all eight datasets, cell clustering performance was increased by 85.02% on average in terms of adjusted rand index, and the imputation Median L1 Error was reduced by 67.94% on average. With the built-in visualizations, users can quickly assess the imputation and cell clustering results, compare against benchmarks and interpret the cell-cell interaction. The expanded input and output formats also pave the way for custom workflows that integrate scGNN 2.0 with other scRNA-Seq toolkits on both Python and R platforms. AVAILABILITY AND IMPLEMENTATION: scGNN 2.0 is implemented in Python (as of version 3.8) with the source code available at https://github.com/OSU-BMBL/scGNN2.0. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online. © The Author(s) 2022. Published by Oxford University Press. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143180863&doi=10.1093%2fbioinformatics%2fbtac684&partnerID=40&md5=256a24005abec79051f56acc6c9acd0b,"Bioinformatics (Oxford, England)",Exclude,,,
Coskun M.,Intrinsic graph topological correlation for graph convolutional network propagation,"Recently, Graph Convolutional Networks (GCNs) and their variants become popular to learn graph-related tasks. These tasks include link prediction, node classification, and node embedding, among many others. In the node classification problem, the input is a graph with some labeled nodes and the features associated with these nodes and the objective is to predict the unlabeled nodes. While the GCNs have been successfully applied to this problem, some caveats that are inherited from classical deep learning remain unsolved. One such inherited caveat is that, during classification, GCNs only consider the nodes that are a few neighbors away from the labeled nodes. However, considering only a few steps away nodes could not effectively exploit the underlying graph topological information. To remedy this problem, the state-of-the-art methods leverage the network diffusion approaches, such as personalized PageRank and its variants, to fully account for the graph topology. However, these approaches overlook the fact that the network diffusion methods favour high degree nodes in the graph, resulting in the propagation of the labels to the unlabeled,hub nodes. In order to overcome bias, in this paper, we propose to utilize a dimensionality reduction technique, which is conjugate with personalized PageRank. Testing on four real-world networks that are commonly used in benchmarking GCNs’ performance for the node classification task, we systematically evaluate the performance of the proposed methodology and show that our approach outperforms existing methods for wide ranges of parameter values. Since our method requires only a few training epochs, it releases the heavy training burden of GCNs. The source code of the proposed method is freely available at https://github.com/mustafaCoskunAgu/ScNP/blob/master/TRJMain.m. © 2022",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129454614&doi=10.1016%2fj.csi.2022.103655&partnerID=40&md5=02dec62173317ff2e67ca4e6f9df3737,Computer Standards and Interfaces,Exclude,,Exclude,
Wang K.; Yu Y.; Huang C.; Zhao Z.; Dong J.,Heterogeneous graph neural network for attribute completion,"Heterogeneous graphs consist of multiple types of nodes and edges, and contain comprehensive information and rich semantics, which can properly model real-world complex systems. However, the attribute values of nodes are often incomplete with many missing attributes, as the cost of collecting node attributes is prohibitively expensive or even impossible (e.g., sensitive personal information). While a handful of graph neural network (GNN) models are developed for attribute completion in heterogeneous networks, most of them either ignore the use of similarity between nodes in feature space, or overlook the different importance of different-order neighbor nodes for attribute completion, resulting in poor performance. In this paper, we propose a general Attribute Completion framework for HEterogeneous Networks (AC-HEN), which is composed of feature aggregation, structure aggregation, and multi-view embedding fusion modules. Specifically, AC-HEN leverages feature aggregation and structure aggregation to obtain multi-view embeddings considering neighbor aggregation in both feature space and network structural space, which distinguishes different contributions of different neighbor nodes by conducting weighted aggregation. Then AC-HEN uses the multi-view embeddings to complete the missing attributes via an embedding fusion module in a weak supervised learning paradigm. Extensive experiments on three real-world heterogeneous network datasets demonstrate the superiority of AC-HEN against state-of-the-art baselines in both attribute completion and node classification. The source code is available at: https://github.com/Code-husky/AC-HEN. © 2022 Elsevier B.V.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133572219&doi=10.1016%2fj.knosys.2022.109171&partnerID=40&md5=44166b838258de46c304bdaa5ee76a5d,Knowledge-Based Systems,Exclude,,,
Dong Y.; Zhang B.; Yuan Y.; Zou N.; Wang Q.; Li J.,RELIANT: Fair Knowledge Distillation for Graph Neural Networks,"Graph Neural Networks (GNNs) have shown satisfying performance on various graph learning tasks. To achieve better fitting capability, most GNNs are with a large number of parameters, which makes these GNNs computationally expensive. Therefore, it is difficult to deploy them onto edge devices with scarce computational resources, e.g., mobile phones and wearable smart devices. Knowledge Distillation (KD) is a common solution to compress GNNs, where a light-weighted model (i.e., the student model) is encouraged to mimic the behavior of a computationally expensive GNN (i.e., the teacher GNN model). Nevertheless, most existing GNN-based KD methods lack fairness consideration. As a consequence, the student model usually inherits and even exaggerates the bias from the teacher GNN. To handle such a problem, we take initial steps towards fair knowledge distillation for GNNs. Specifically, we first formulate a novel problem of fair knowledge distillation for GNN-based teacher-student frameworks. Then we propose a principled framework named RELIANT to mitigate the bias exhibited by the student model. Notably, the design of RELIANT is decoupled from any specific teacher and student model structures, and thus can be easily adapted to various GNN-based KD frameworks. We perform extensive experiments on multiple real-world datasets, which corroborates that RELIANT achieves less biased GNN knowledge distillation while maintaining high prediction utility. Open-source code can be found at https://github.com/yushundong/RELIANT. Copyright © 2023 by SIAM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148270885&partnerID=40&md5=e7539299a7283da465b05a8c9435f0b1,"2023 SIAM International Conference on Data Mining, SDM 2023",Exclude,,,
Park J.-D.; Tran C.; Shin W.-Y.; Cao X.,Grad-Align: Gradual Network Alignment via Graph Neural Networks (Student Abstract),"Network alignment (NA) is the task of finding the correspondence of nodes between two networks. Since most existing NA methods have attempted to discover every node pair at once, they may fail to utilize node pairs that have strong consistency across different networks in the NA task. To tackle this challenge, we propose Grad-Align, a new NA method that gradually discovers node pairs by making full use of either node pairs exhibiting strong consistency or prior matching information. Specifically, the proposed method gradually aligns nodes based on both the similarity of embeddings generated using graph neural networks (GNNs) and the Tversky similarity, which is an asymmetric set similarity using the Tversky index applicable to networks with different scales. Experimental evaluation demonstrates that Grad-Align consistently outperforms state-of-the-art NA methods in terms of the alignment accuracy. Our source code is available at https://github.com/jindeok/Grad-Align. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123976981&partnerID=40&md5=e55045f419fcfcd9aa703c337303527d,"Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022",Exclude,,,
Liu Z.; Wang Y.; Bernard J.; Munzner T.,Visualizing Graph Neural Networks with CorGIE: Corresponding a Graph to Its Embedding,"Graph neural networks (GNNs) are a class of powerful machine learning tools that model node relations for making predictions of nodes or links. GNN developers rely on quantitative metrics of the predictions to evaluate a GNN, but similar to many other neural networks, it is difficult for them to understand if the GNN truly learns characteristics of a graph as expected. We propose an approach to corresponding an input graph to its node embedding (aka latent space), a common component of GNNs that is later used for prediction. We abstract the data and tasks, and develop an interactive multi-view interface called CorGIE to instantiate the abstraction. As the key function in CorGIE, we propose the K-hop graph layout to show topological neighbors in hops and their clustering structure. To evaluate the functionality and usability of CorGIE, we present how to use CorGIE in two usage scenarios, and conduct a case study with five GNN experts. Availability: Open-source code at http://github.com/zipengliu/corgie-ui/, supplemental materials & video at http://osf.io/tr3sb/. © 2022 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124176177&doi=10.1109%2fTVCG.2022.3148197&partnerID=40&md5=20c9528354fcac8d9590275d48f0db46,IEEE Transactions on Visualization and Computer Graphics,Exclude,,,
Zheng W.; Huang E.W.; Rao N.; Katariya S.; Wang Z.; Subbian K.,COLD BREW: DISTILLING GRAPH NODE REPRESENTATIONS WITH INCOMPLETE OR MISSING NEIGHBORHOODS,"Graph Neural Networks (GNNs) have achieved state-of-the-art performance in node classification, regression, and recommendation tasks. GNNs work well when rich and high-quality connections are available. However, their effectiveness is often jeopardized in many real-world graphs in which node degrees have power-law distributions. The extreme case of this situation, where a node may have no neighbors, is called Strict Cold Start (SCS). SCS forces the prediction to rely completely on the node's own features. We propose Cold Brew, a teacher-student distillation approach to address the SCS and noisy-neighbor challenges for GNNs. We also introduce feature contribution ratio (FCR), a metric to quantify the behavior of inductive GNNs to solve SCS. We experimentally show that FCR disentangles the contributions of different graph data components and helps select the best architecture for SCS generalization. We further demonstrate the superior performance of Cold Brew on several public benchmark and proprietary e-commerce datasets, where many nodes have either very few or noisy connections. Our source code is available at https://github.com/amazon-research/gnn-tail-generalization. © 2022 ICLR 2022 - 10th International Conference on Learning Representationss. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148164663&partnerID=40&md5=e1e5b86b1c971df2fb247a3bdd8d15c2,ICLR 2022 - 10th International Conference on Learning Representations,Exclude,,,
Harn P.-W.; Yeddula S.D.; Hui B.; Zhang J.; Sun L.; Sun M.-T.; Ku W.-S.,IGRP: Iterative Gradient Rank Pruning for Finding Graph Lottery Ticket,"Graph Neural Networks (GNNs) have shown promising performance in many applications, yet remain extremely difficult to train over large-scale graph datasets. Existing weight pruning techniques can prune out the layer weights; however, they cannot fully address the high computation complexity of GNN inference, caused by large graph size and complicated node connections. In this paper, we propose an Iterative Gradient Rank Pruning (IGRP) algorithm to find graph lottery tickets (GLT) of GNNs where each GLT includes a pruned adjacency matrix and a sub-network. Our IGRP can avoid layer collapse and the winning ticket achieves Maximal critical compression. We evaluate the proposed method on small-scale (Cora and Citeseer), medium-scale (PubMed and Wiki-CS), and large-scale (Ogbn-ArXiv and Ogbn-Products) graph datasets. We demonstrate that both Single-shot and Multi-shot of IGRP outperform the state-of-the-art unified GNN sparsification (UGS) framework on node classification. The source code can be found in https://github.com/poweiharn/IGRP_GNN. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147944613&doi=10.1109%2fBigData55660.2022.10020964&partnerID=40&md5=103c506a4b305c0eface5ec3ac3f3a1a,"Proceedings - 2022 IEEE International Conference on Big Data, Big Data 2022",Exclude,,,
Jiang S.; Man Y.; Song Z.; Yu Z.; Zhuo D.,Fast Graph Neural Tangent Kernel via Kronecker Sketching,"Many deep learning tasks have to deal with graphs (e.g., protein structures, social networks, source code abstract syntax trees). Due to the importance of these tasks, people turned to Graph Neural Networks (GNNs) as the de facto method for learning on graphs. GNNs have become widely applied due to their convincing performance. Unfortunately, one major barrier to using GNNs is that GNNs require substantial time and resources to train. Recently, a new method for learning on graph data is Graph Neural Tangent Kernel (GNTK) (Du et al. 2019a). GNTK is an application of Neural Tangent Kernel (NTK) (Jacot, Gabriel, and Hongler 2018) (a kernel method) on graph data, and solving NTK regression is equivalent to using gradient descent to train an infinite-wide neural network. The key benefit of using GNTK is that, similar to any kernel method, GNTK’s parameters can be solved directly in a single step. This can avoid time-consuming gradient descent. Meanwhile, sketching has become increasingly used in speeding up various optimization problems, including solving kernel regression. Given a kernel matrix of n graphs, using sketching in solving kernel regression can reduce the running time to o(n3). But unfortunately such methods usually requires extensive knowledge about the kernel matrix beforehand, while in the case of GNTK we find that the construction of the kernel matrix is already O(n2N4), assuming each graph has N nodes. The kernel matrix construction time can be a major performance bottleneck when the size of graphs N increases. A natural question to ask is thus whether we can speed up the kernel matrix construction to improve GNTK regression’s end-to-end running time. This paper provides the first algorithm to construct the kernel matrix in o(n2N3) running time. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147734001&partnerID=40&md5=a9792baba81b9d03c5ec6c7b5e86664c,"Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022",Exclude,,,
Ahn H.; Yang Y.; Gan Q.; Moon T.; Wipf D.,Descent Steps of a Relation-Aware Energy Produce Heterogeneous Graph Neural Networks,"Heterogeneous graph neural networks (GNNs) achieve strong performance on node classification tasks in a semi-supervised learning setting. However, as in the simpler homogeneous GNN case, message-passing-based heterogeneous GNNs may struggle to balance between resisting the oversmoothing that may occur in deep models, and capturing long-range dependencies of graph structured data. Moreover, the complexity of this trade-off is compounded in the heterogeneous graph case due to the disparate heterophily relationships between nodes of different types. To address these issues, we propose a novel heterogeneous GNN architecture in which layers are derived from optimization steps that descend a novel relation-aware energy function. The corresponding minimizer is fully differentiable with respect to the energy function parameters, such that bilevel optimization can be applied to effectively learn a functional form whose minimum provides optimal node representations for subsequent classification tasks. In particular, this methodology allows us to model diverse heterophily relationships between different node types while avoiding oversmoothing effects. Experimental results on 8 heterogeneous graph benchmarks demonstrate that our proposed method can achieve competitive node classification accuracy. The source code of our algorithm is available at https://github.com/hongjoon0805/HALO. © 2022 Neural information processing systems foundation. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163212691&partnerID=40&md5=3b4c5551bce38ebabbbf6e6cdfc11325,Advances in Neural Information Processing Systems,Exclude,,,
Liu C.; Su H.; Dou Y.; Chen K.; Sun Y.,Optimizing GNN on ARM Multi-Core Processors,"Graph Neural Network (GNN) has shown great success in graph learning, including physics systems, protein interfaces, disease classification, molecular fingerprints, etc. Due to the complexity of the real-world tasks and the big graph datasets, current GNN models become increasingly bigger and more complicated to enhance the learning ability and prediction accuracy. In addition, GNN contains two main major components graph operation and neural network (NN) operation, both are executed alternately during processing. The interleaved complex processing of GNN poses a challenge for many computational platforms, especially for those without accelerators. Current optimization frameworks solely for deep learning or graph computing cannot achieve good performance on GNN. In this work, we first investigate the performance bottlenecks when handling GNN over multi-core processors. Then, we perform a set of optimization strategies to leverage the capability of multi-core processors for GNN processing. Specifically, we build a set of microkernels for graph operations of GNN with assembly instructions that can exploit the capability of SIMD processing units within a core and implement a task allocator based on a greedy algorithm to balance the workloads between the cores of CPU. In addition, we use some strategies to optimize NN operation for GNN, according to the characteristics of NN operation in GNN. Experimental results show that the proposed methods can achieve a maximum of 2.88x and 4.08x performance improvements for various GNN models on Phytium 2000+ and Kunpeng 920 over the state-of-the-art GNN framework.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152242446&doi=10.1109%2fHPCC-DSS-SmartCity-DependSys57074.2022.00206&partnerID=40&md5=097367f49c8023419ba8d5694833faa0,"Proceedings - 24th IEEE International Conference on High Performance Computing and Communications, 8th IEEE International Conference on Data Science and Systems, 20th IEEE International Conference on Smart City and 8th IEEE International Conference on Dependability in Sensor, Cloud and Big Data Systems and Application, HPCC/DSS/SmartCity/DependSys 2022",Exclude,,,
Yang M.; Shen Y.; Li R.; Qi H.; Zhang Q.; Yin B.,A New Perspective on the Effects of Spectrum in Graph Neural Networks,"Many improvements on GNNs can be deemed as operations on the spectrum of the underlying graph matrix, which motivates us to directly study the characteristics of the spectrum and their effects on GNN performance. By generalizing most existing GNN architectures, we show that the correlation issue caused by the unsmooth spectrum becomes the obstacle to leveraging more powerful graph filters as well as developing deep architectures, which therefore restricts GNNs' performance. Inspired by this, we propose the correlation-free architecture which naturally removes the correlation issue among different channels, making it possible to utilize more sophisticated filters within each channel. The final correlation-free architecture with more powerful filters consistently boosts the performance of learning graph representations. Code is available at https://github.com/qslim/gnn-spectrum. Copyright © 2022 by the author(s)",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143435804&partnerID=40&md5=4069c12ef8fd3c3e64eb8454f70cebf9,Proceedings of Machine Learning Research,Exclude,,,
Rahman M.K.; Agrawal A.; Azad A.,MarkovGNN: Graph Neural Networks on Markov Diffusion,"Most real-world networks contain well-defined community structures where nodes are densely connected internally within communities. To learn from these networks, we develop MarkovGNN that captures the formation and evolution of communities directly in different convolutional layers. Unlike most Graph Neural Networks (GNNs) that consider a static graph at every layer, MarkovGNN generates different stochastic matrices using a Markov process and then uses these community-capturing matrices in different layers. MarkovGNN is a general approach that could be used with most existing GNNs. We experimentally show that MarkovGNN outperforms other GNNs for clustering, node classification, and visualization tasks. The source code of MarkovGNN is publicly available at https://github.com/HipGraph/MarkovGNN.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137513063&doi=10.1145%2f3487553.3524713&partnerID=40&md5=6d25b1c7556d572ccc4e8863b45957c9,WWW 2022 - Companion Proceedings of the Web Conference 2022,Exclude,,,
Li H.; Cao J.; Zhu J.; Liu Y.; Zhu Q.; Wu G.,Curvature graph neural network,"Graph neural networks (GNNs) have achieved great success in many graph-based tasks. Much work is dedicated to empowering GNNs with adaptive locality ability, which enables the measurement of the importance of neighboring nodes to the target node by a node-specific mechanism. However, the current node-specific mechanisms are deficient in distinguishing the importance of nodes in the topology structure. We believe that the structural importance of neighboring nodes is closely related to their importance in aggregation. In this paper, we introduce discrete graph curvature (the Ricci curvature) to quantify the strength of the structural connection of pairwise nodes. We propose a curvature graph neural network (CGNN), which effectively improves the adaptive locality ability of GNNs by leveraging the structural properties of graph curvature. To improve the adaptability of curvature on various datasets, we explicitly transform curvature into the weights of neighboring nodes by the necessary negative curvature processing module and curvature normalization module. Then, we conduct numerous experiments on various synthetic and real-world datasets. The experimental results on synthetic datasets show that CGNN effectively exploits the topology structure information and that the performance is significantly improved. CGNN outperforms the baselines on 5 dense node classification benchmark datasets. This study provides a deepened understanding of how to utilize advanced topology information and assign the importance of neighboring nodes from the perspective of graph curvature and encourages bridging the gap between graph theory and neural networks. The source code is available at https://github.com/GeoX-Lab/CGNN. © 2021",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123978683&doi=10.1016%2fj.ins.2021.12.077&partnerID=40&md5=10a592ca10a518d6233984ba4f4b95a1,Information Sciences,Exclude,,,
Ju M.; Hou S.; Fan Y.; Zhao J.; Ye Y.; Zhao L.,Adaptive Kernel Graph Neural Network,"Graph neural networks (GNNs) have demonstrated great success in representation learning for graph-structured data. The layer-wise graph convolution in GNNs is shown to be powerful at capturing graph topology. During this process, GNNs are usually guided by pre-defined kernels such as Laplacian matrix, adjacency matrix, or their variants. However, the adoptions of pre-defined kernels may restrain the generalities to different graphs: mismatch between graph and kernel would entail sub-optimal performance. For example, GNNs that focus on low-frequency information may not achieve satisfactory performance when high-frequency information is significant for the graphs, and vice versa. To solve this problem, in this paper, we propose a novel framework - i.e., namely Adaptive Kernel Graph Neural Network (AKGNN) - which learns to adapt to the optimal graph kernel in a unified manner at the first attempt. In the proposed AKGNN, we first design a data-driven graph kernel learning mechanism, which adaptively modulates the balance between all-pass and low-pass filters by modifying the maximal eigenvalue of the graph Laplacian. Through this process, AKGNN learns the optimal threshold between high and low frequency signals to relieve the generality problem. Later, we further reduce the number of parameters by a parameterization trick and enhance the expressive power by a global readout function. Extensive experiments are conducted on acknowledged benchmark datasets and promising results demonstrate the outstanding performance of our proposed AKGNN by comparison with state-of-the-art GNNs. The source code is publicly available at: https://github.com/jumxglhf/AKGNN. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140200396&partnerID=40&md5=1ac96eec9bfa52c04dfb3ce314f198b1,"Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022",Exclude,,,
You H.; Lu Z.; Zhou Z.; Fu Y.; Lin Y.,Early-Bird GCNs: Graph-Network Co-optimization towards More Efficient GCN Training and Inference via Drawing Early-Bird Lottery Tickets,"Graph Convolutional Networks (GCNs) have emerged as the state-of-the-art deep learning model for representation learning on graphs. However, it remains notoriously challenging to train and inference GCNs over large graph datasets, limiting their application to large real-world graphs and hindering the exploration of deeper and more sophisticated GCN graphs. This is because as the graph size grows, the sheer number of node features and the large adjacency matrix can easily explode the required memory and data movements. To tackle the aforementioned challenges, we explore the possibility of drawing lottery tickets when sparsifying GCN graphs, i.e., subgraphs that largely shrink the adjacency matrix yet are capable of achieving accuracy comparable to or even better than their full graphs. Specifically, we for the first time discover the existence of graph early-bird (GEB) tickets that emerge at the very early stage when sparsifying GCN graphs, and propose a simple yet effective detector to automatically identify the emergence of such GEB tickets. Furthermore, we advocate graph-model co-optimization and develop a generic efficient GCN early-bird training framework dubbed GEBT that can significantly boost the efficiency of GCN training by (1) drawing joint early-bird tickets between the GCN graphs and models and (2) enabling simultaneously sparsification of both the GCN graphs and models. Experiments on various GCN models and datasets consistently validate our GEB finding and the effectiveness of our GEBT, e.g., our GEBT achieves up to 80.2% ∼ 85.6% and 84.6% ∼ 87.5% savings of GCN training and inference costs while offering a comparable or even better accuracy as compared to state-of-the-art methods. Our source code and supplementary material are available at https://github.com/RICE-EIC/Early-Bird-GCN. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134957344&partnerID=40&md5=971af8214cd7acd8b1d015986c08c3a3,"Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022",Exclude,,Exclude,
Pan Z.; Yu Y.; Chang J.,A Distributed Graph Inference Computation Framework Based on Graph Neural Network Model,"A graph is a structure that can effectively represent objects and the relationships between them. Graph Neural Networks (GNNs) enable deep learning to be applied in the graph domain. However, most GNN models are trained offline and cannot be directly used in real-time monitoring scenarios. In addition, due to the very large data scale of the graph, a single machine cannot meet the demand, and there is a performance bottleneck. Therefore, we propose a distributed graph neural network inference computing framework, which can be applied to GNN models in the form of Encoder-Decoder. We propose the idea of “single-point inference, message passing, distributed computing”, which enables the system to use offline-trained GNNs for real-time inference computations on graph data. To maintain the model effect, we add the second-degree subgraph and mailbox mechanism to the continuous iterative calculation. Finally, our results on public datasets show that this method greatly improves the upper limit of inference computation and has better timeliness. And it maintains a good model effect on three types of classical tasks. The source code is published in a Github repository. © 2022 Knowledge Systems Institute Graduate School. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137168559&doi=10.18293%2fSEKE2022-042&partnerID=40&md5=1b574cc83009569d0cc26e8dc5762280,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",Exclude,,,
Wang C.; Qiu Y.; Gao D.; Scherer S.,Lifelong Graph Learning,"Graph neural networks (GNN) are powerful models for many graph-structured tasks. Existing models often assume that the complete structure of the graph is available during training. In practice, however, graph-structured data is usually formed in a streaming fashion so that learning a graph continuously is often necessary. In this paper, we bridge GNN and lifelong learning by converting a continual graph learning problem to a regular graph learning problem so GNN can inherit the lifelong learning techniques developed for convolutional neural networks (CNN). We propose a new topology, the feature graph, which takes features as new nodes and turns nodes into independent graphs. This successfully converts the original problem of node classification to graph classification. In the experiments, we demonstrate the efficiency and effectiveness of feature graph networks (FGN) by continuously learning a sequence of classical graph datasets. We also show that FGN achieves superior performance in two applications, i.e., lifelong human action recognition with wearable devices and feature matching. To the best of our knowledge, FGN is the first method to bridge graph learning and lifelong learning via a novel graph topology. Source code is available at https://github.com/wang-chen/LGL. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139538343&doi=10.1109%2fCVPR52688.2022.01335&partnerID=40&md5=aced028bbe785abc704796e8b32da9aa,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,Exclude,,,
Ganz T.; Härterich M.; Warnecke A.; Rieck K.,Explaining Graph Neural Networks for Vulnerability Discovery,"Graph neural networks (GNNs) have proven to be an effective tool for vulnerability discovery that outperforms learning-based methods working directly on source code. Unfortunately, these neural networks are uninterpretable models, whose decision process is completely opaque to security experts, which obstructs their practical adoption. Recently, several methods have been proposed for explaining models of machine learning. However, it is unclear whether these methods are suitable for GNNs and support the task of vulnerability discovery. In this paper we present a framework for evaluating explanation methods on GNNs. We develop a set of criteria for comparing graph explanations and linking them to properties of source code. Based on these criteria, we conduct an experimental study of nine regular and three graph-specific explanation methods. Our study demonstrates that explaining GNNs is a non-Trivial task and all evaluation criteria play a role in assessing their efficacy. We further show that graph-specific explanations relate better to code semantics and provide more information to a security expert than regular methods.  © 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120859469&doi=10.1145%2f3474369.3486866&partnerID=40&md5=58173a485d8e906abf06a809c1a8d8d6,"AISec 2021 - Proceedings of the 14th ACM Workshop on Artificial Intelligence and Security, co-located with CCS 2021",Include,,,
Maurya S.K.; Liu X.; Murata T.,Graph Neural Networks for Fast Node Ranking Approximation,"Graphs arise naturally in numerous situations, including social graphs, transportation graphs, web graphs, protein graphs, etc. One of the important problems in these settings is to identify which nodes are important in the graph and how they affect the graph structure as a whole. Betweenness centrality and closeness centrality are two commonly used node ranking measures to find out influential nodes in the graphs in terms of information spread and connectivity. Both of these are considered as shortest path based measures as the calculations require the assumption that the information flows between the nodes via the shortest paths. However, exact calculations of these centrality measures are computationally expensive and prohibitive, especially for large graphs. Although researchers have proposed approximation methods, they are either less efficient or suboptimal or both. We propose the first graph neural network (GNN) based model to approximate betweenness and closeness centrality. In GNN, each node aggregates features of the nodes in multihop neighborhood. We use this feature aggregation scheme to model paths and learn how many nodes are reachable to a specific node. We demonstrate that our approach significantly outperforms current techniques while taking less amount of time through extensive experiments on a series of synthetic and real-world datasets. A benefit of our approach is that the model is inductive, which means it can be trained on one set of graphs and evaluated on another set of graphs with varying structures. Thus, the model is useful for both static graphs and dynamic graphs. Source code is available at https://github.com/sunilkmaurya/GNN_Ranking  © 2021 Owner/Author.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108973458&doi=10.1145%2f3446217&partnerID=40&md5=91c626f02bbcd61cfd849a6738237940,ACM Transactions on Knowledge Discovery from Data,Exclude,,,
Thost V.; Chen J.,DIRECTED ACYCLIC GRAPH NEURAL NETWORKS,"Graph-structured data ubiquitously appears in science and engineering. Graph neural networks (GNNs) are designed to exploit the relational inductive bias exhibited in graphs; they have been shown to outperform other forms of neural networks in scenarios where structure information supplements node features. The most common GNN architecture aggregates information from neighborhoods based on message passing. Its generality has made it broadly applicable. In this paper, we focus on a special, yet widely used, type of graphs-DAGs-and inject a stronger inductive bias-partial ordering-into the neural network design. We propose the directed acyclic graph neural network, DAGNN, an architecture that processes information according to the flow defined by the partial order. DAGNN can be considered a framework that entails earlier works as special cases (e.g., models for trees and models updating node representations recurrently), but we identify several crucial components that prior architectures lack. We perform comprehensive experiments, including ablation studies, on representative DAG datasets (i.e., source code, neural architectures, and probabilistic graphical models) and demonstrate the superiority of DAGNN over simpler DAG architectures as well as general graph architectures. © 2021 ICLR 2021 - 9th International Conference on Learning Representations. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150297597&partnerID=40&md5=44fa676e66c7a03f1b98a02093429dfe,ICLR 2021 - 9th International Conference on Learning Representations,Exclude,,,
Simonsen C.P.; Thiesson F.M.; Philipsen M.P.; Moeslund T.B.,GENERALIZING FLOOR PLANS USING GRAPH NEURAL NETWORKS,"The proliferation of indoor maps is limited by the manual process of generalizing floor plans. Previous attempts at automating similar processes use rasterization for structure. With Graph Neural Networks (GNN) it is now possible to skip rasterization and rely on the inherent structures in CAD drawings. A core component in floor plan generalization is localization of doors. We show how floor plan graphs can be extracted directly from CAD primitives and how state-of-the-art GNNs can be used to classify graph nodes as door or non-door. Generalization is represented by the creation of placeholder bounding boxes using the labelled graph nodes. Our graph-based approach completely outperforms the Faster R-CNN baseline, which fail to locate any doors with the desired localization accuracy. To support further development of graph-based methods and comparison with raster-based methods, we publish a new dataset that consists of both image and graph-based floor plan representations. Code and dataset is available at https://github.com/Chrps/MapGeneralization. © 2021 IEEE",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125592328&doi=10.1109%2fICIP42928.2021.9506514&partnerID=40&md5=519ce74fc6be118c1b834bdead72290e,"Proceedings - International Conference on Image Processing, ICIP",Exclude,,,
Xu F.; Yao Q.; Hui P.; Li Y.,Automorphic Equivalence-aware Graph Neural Network,"Distinguishing the automorphic equivalence of nodes in a graph plays an essential role in many scientific domains, e.g., computational biologist and social network analysis. However, existing graph neural networks (GNNs) fail to capture such an important property. To make GNN aware of automorphic equivalence, we first introduce a localized variant of this concept — ego-centered automorphic equivalence (Ego-AE). Then, we design a novel variant of GNN, i.e., GRAPE, that uses learnable AE-aware aggregators to explicitly differentiate the Ego-AE of each node’s neighbors with the aids of various subgraph templates. While the design of subgraph templates can be hard, we further propose a genetic algorithm to automatically search them from graph data. Moreover, we theoretically prove that GRAPE is expressive in terms of generating distinct representations for nodes with different Ego-AE features, which fills in a fundamental gap of existing GNN variants. Finally, we empirically validate our model on eight real-world graph data, including social network, e-commerce co-purchase network, and citation network, and show that it consistently outperforms existing GNNs. The source code is public available at https://github.com/tsinghua-fib-lab/GRAPE. © 2021 Neural information processing systems foundation. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132032395&partnerID=40&md5=4fb3d54b33cd0a1a2bc3896974fb5cc5,Advances in Neural Information Processing Systems,Exclude,,,
Ji X.; Li H.; Pan Z.; Gao X.; Tu C.,"Decentralized, Unlabeled Multi-Agent Navigation in Obstacle-Rich Environments using Graph Neural Networks","We propose a decentralized, learning-based solution to the challenging problem of unlabeled multi-agent navigation among obstacles, where robots need to simultaneously tackle the problems of goal assignment, local collision avoidance, and navigation. Our method has each robot infer their desired action by communicating with each other as well as a set of position-fixed routers. The inference is carried out on a graph neural network (GNN) with both robot and router nodes. We train our GNN using imitation learning on a small group of robots, where we modify the centralized version of the concurrent goal assignment and planning algorithm (CAPT) as our expert. By sharing weights among all robots and routers, our model can scale to unseen environments with any number of possibly kinodynamic agents during test time. We have achieved a success rate of 91.2% and 85.6% for point and car-like robots, respectively. Source code will be publicly available upon the publication of the work.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124353668&doi=10.1109%2fIROS51168.2021.9636088&partnerID=40&md5=0c7d395ca8ebba6238a424d313052d80,IEEE International Conference on Intelligent Robots and Systems,Exclude,,,
Li J.; Xu K.; Chen L.; Zheng Z.; Liu X.,GraphGallery: A Platform for Fast Benchmarking and Easy Development of Graph Neural Networks Based Intelligent Software,"Graph Neural Networks (GNNs) have recently shown to be powerful tools for representing and analyzing graph data. So far GNNs is becoming an increasingly critical role in software engineering including program analysis, type inference, and code representation. In this paper, we introduce GraphGallery, a platform for fast benchmarking and easy development of GNNs based software. GraphGallery is an easy-to-use platform that allows developers to automatically deploy GNNs even with less domain-specific knowledge. It offers a set of implementations of common GNN models based on mainstream deep learning frameworks. In addition, existing GNNs toolboxes such as PyG and DGL can be easily incorporated into the platform. Experiments demonstrate the reliability of implementations and superiority in fast coding. The official source code of GraphGallery is available at https://github.com/EdisonLeeeee/GraphGallery and a demo video can be found at https://youtu.be/mv7Zs1YeaYo. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115718417&doi=10.1109%2fICSE-Companion52605.2021.00024&partnerID=40&md5=73313e97d03836c7b3688057a63d76bd,Proceedings - International Conference on Software Engineering,Exclude,,Exclude,
Feng B.; Wang Y.; Li X.; Yang S.; Peng X.; Ding Y.,SGQuant: Squeezing the Last Bit on Graph Neural Networks with Specialized Quantization,"With the increasing popularity of graph-based learning, Graph Neural Networks (GNNs) win lots of attention from research and industry field because of their high accuracy. However, existing GNNs suffer from high memory footprints (e.g., node embedding features). This high memory footprint hurdles the potential applications towards memory-constrained devices, such as the widely-deployed IoT devices. To this end, we propose a specialized GNN quantization scheme, SGQuant, to systematically reduce the GNN memory consumption. Specifically, we first propose a GNN-Tailored quantization algorithm design and a GNN quantization fine-Tuning scheme to reduce memory consumption while maintaining accuracy. Then, we investigate the multi-granularity quantization strategy that operates at different levels (components, graph topology, and layers) of GNN computation. Moreover, we offer an automatic bit-selecting (ABS) to pinpoint the most appropriate quantization bits for the above multi-granularity quantizations. Intensive experiments show that SGQuant can effectively reduce the memory footprint from 4.25× to 31.9× compared with the original full-precision GNNs while limiting the accuracy drop to 0.4% on average. © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098752679&doi=10.1109%2fICTAI50040.2020.00198&partnerID=40&md5=44ebfda57713fcf04ae2c2597f803856,"Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI",Exclude,,,
Feng W.; Zhang J.; Dong Y.; Han Y.; Luan H.; Xu Q.; Yang Q.; Kharlamov E.; Tang J.,Graph random neural networks for semi-supervised learning on graphs,"We study the problem of semi-supervised learning on graphs, for which graph neural networks (GNNs) have been extensively explored. However, most existing GNNs inherently suffer from the limitations of over-smoothing [6, 23, 24, 30], non-robustness [48, 45], and weak-generalization when labeled nodes are scarce. In this paper, we propose a simple yet effective framework—GRAPH RANDOM NEURAL NETWORKS (GRAND)—to address these issues. In GRAND, we first design a random propagation strategy to perform graph data augmentation. Then we leverage consistency regularization to optimize the prediction consistency of unlabeled nodes across different data augmentations. Extensive experiments on graph benchmark datasets suggest that GRAND significantly outperforms state-of-the-art GNN baselines on semi-supervised node classification. Finally, we show that GRAND mitigates the issues of over-smoothing and non-robustness, exhibiting better generalization behavior than existing GNNs. The source code of GRAND is publicly available at https://github.com/Grand20/grand. © 2020 Neural information processing systems foundation. All rights reserved.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104649257&partnerID=40&md5=c4f765d132e36034ff933f95ac60b2a9,Advances in Neural Information Processing Systems,Exclude,,,
Barceló P.; Kostylev E.V.; Monet M.; Pérez J.; Reutter J.; Silva J.-P.,THE LOGICAL EXPRESSIVENESS OF GRAPH NEURAL NETWORKS,"The ability of graph neural networks (GNNs) for distinguishing nodes in graphs has been recently characterized in terms of the Weisfeiler-Lehman (WL) test for checking graph isomorphism. This characterization, however, does not settle the issue of which Boolean node classifiers (i.e., functions classifying nodes in graphs as true or false) can be expressed by GNNs. We tackle this problem by focusing on Boolean classifiers expressible as formulas in the logic FOC2, a well-studied fragment of first order logic. FOC2 is tightly related to the WL test, and hence to GNNs. We start by studying a popular class of GNNs, which we call AC-GNNs, in which the features of each node in the graph are updated, in successive layers, only in terms of the features of its neighbors. We show that this class of GNNs is too weak to capture all FOC2 classifiers, and provide a syntactic characterization of the largest subclass of FOC2 classifiers that can be captured by AC-GNNs. This subclass coincides with a logic heavily used by the knowledge representation community. We then look at what needs to be added to AC-GNNs for capturing all FOC2 classifiers. We show that it suffices to add readout functions, which allow to update the features of a node not only in terms of its neighbors, but also in terms of a global attribute vector. We call GNNs of this kind ACR-GNNs. We experimentally validate our findings showing that, on synthetic data conforming to FOC2 formulas, AC-GNNs struggle to fit the training data while ACR-GNNs can generalize even to graphs of sizes not seen during training. © 2020 8th International Conference on Learning Representations, ICLR 2020. All rights reserved.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150641174&partnerID=40&md5=39191a9208da0ea544fdae531e123f5a,"8th International Conference on Learning Representations, ICLR 2020",Exclude,,Exclude,
Knyazev B.; Taylor G.W.; Amer M.R.,Understanding attention and generalization in graph neural networks,"We aim to better understand attention over nodes in graph neural networks (GNNs) and identify factors influencing its effectiveness. We particularly focus on the ability of attention GNNs to generalize to larger, more complex or noisy graphs. Motivated by insights from the work on Graph Isomorphism Networks, we design simple graph reasoning tasks that allow us to study attention in a controlled environment. We find that under typical conditions the effect of attention is negligible or even harmful, but under certain conditions it provides an exceptional gain in performance of more than 60% in some of our classification tasks. Satisfying these conditions in practice is challenging and often requires optimal initialization or supervised training of attention. We propose an alternative recipe and train attention in a weakly-supervised fashion that approaches the performance of supervised models, and, compared to unsupervised models, improves results on several synthetic as well as real datasets. Source code and datasets are available at https://github.com/bknyaz/graph_attention_pool. © 2019 Neural information processing systems foundation. All rights reserved.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090177053&partnerID=40&md5=de0cc145ef4c9876709ca7d81537dbaa,Advances in Neural Information Processing Systems,Exclude,,,
Kim G.; Hong S.; Franz M.; Song D.,Improving cross-platform binary analysis using representation learning via graph alignment,"Cross-platform binary analysis requires a common representation of binaries across platforms, on which a specific analysis can be performed. Recent work proposed to learn low-dimensional, numeric vector representations (i.e., embeddings) of disassembled binary code, and perform binary analysis in the embedding space. Unfortunately, however, existing techniques fall short in that they are either (i) specific to a single platform producing embeddings not aligned across platforms, or (ii) not designed to capture the rich contextual information available in a disassembled binary. We present a novel deep learning-based method, XBA, which addresses the aforementioned problems. To this end, we first abstract binaries as typed graphs, dubbed binary disassembly graphs (BDGs), which encode control-flow and other rich contextual information of different entities found in a disassembled binary, including basic blocks, external functions called, and string literals referenced. We then formulate binary code representation learning as a graph alignment problem, i.e., finding the node correspondences between BDGs extracted from two binaries compiled for different platforms. XBA uses graph convolutional networks to learn the semantics of each node, (i) using its rich contextual information encoded in the BDG, and (ii) aligning its embeddings across platforms. Our formulation allows XBA to learn semantic alignments between two BDGs in a semi-supervised manner, requiring only a limited number of node pairs be aligned across platforms for training. Our evaluation shows that XBA can learn semantically-rich embeddings of binaries aligned across platforms without apriori platform-specific knowledge. By training our model only with 50% of the oracle alignments, XBA was able to predict, on average, 75% of the rest. Our case studies further show that the learned embeddings encode knowledge useful for cross-platform binary analysis.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136810430&doi=10.1145%2f3533767.3534383&partnerID=40&md5=f456e81f1c7d3b81a1893c5b130189a4,ISSTA 2022 - Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis,Exclude,,,
Yang J.; Fu C.; Liu X.-Y.; Yin H.; Zhou P.,Codee: A Tensor Embedding Scheme for Binary Code Search,"Given a target binary function, the binary code search retrieves top-K similar functions in the repository, and similar functions represent that they are compiled from the same source codes. Searching binary code is particularly challenging due to large variations of compiler tool-chains and options and CPU architectures, as well as thousands of binary codes. Furthermore, there are some pivotal issues in current binary code search schemes, including inaccurate text-based or token-based analysis, slow graph matching, or complex deep learning processes. In this paper, we present an unsupervised tensor embedding scheme, Codee, to carry out code search efficiently and accurately at the binary function level. First, we use an NLP-based neural network to generate the semantic-aware token embedding. Second, we propose an efficient basic block embedding generation algorithm based on the network representation learning model. We learn both the semantic information of instructions and the control flow structural information to generate the basic block embedding. Then we use all basic block embeddings in a function to obtain a variable-length function feature vector. Third, we build a tensor to generate function embeddings based on the tensor singular value decomposition, which compresses the variable-length vectors into short fixed-length vectors to facilitate efficient search afterward. We further propose a dynamic tensor compression algorithm to incrementally update the function embedding database. Finally, we use the local sensitive hash method to find the top-KK similar matching functions in the repository. Compared with state-of-the-art cross-optimization-level code search schemes, such as Asm2Vec and DeepBinDiff, our scheme achieves higher average search accuracy, shorter feature vectors, and faster feature generation performance using four datasets, OpenSSL, Coreutils, libgmp and libcurl. Compared with other cross-platform and cross-optimization-level code search schemes, such as Gemini, Safe, the average recall of our method also outperforms others.  © 1976-2012 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100808995&doi=10.1109%2fTSE.2021.3056139&partnerID=40&md5=20107c24a50f39dfa4977485252a4ddb,IEEE Transactions on Software Engineering,Exclude,,,
Wang M.; Interrante-Grant A.; Whelan R.; Leek T.,COBRA-GCN: Contrastive Learning to Optimize Binary Representation Analysis with Graph Convolutional Networks,"The ability to quickly identify whether two binaries are similar is critical for many security applications, with use cases ranging from triaging millions of novel malware samples, to identifying whether a binary contains a known exploitable bug. There have been many program analysis approaches to solving this problem, however, most machine learning approaches in the last 5 years have focused on function similarity, and there have been no techniques released that are able to perform robust many to many comparisons of full programs. In this paper, we present the first machine learning approach capable of learning a robust representation of programs based on their similarity, using a combination of supervised natural language processing and graph learning. We name our prototype COBRA: Contrastive Learning to Optimize Binary Representation Analysis. We evaluate our model on several different metrics for program similarity, such as compiler optimizations, code obfuscations, and different pieces of semantically similar source code. Our approach outperforms current techniques for full binary diffing, achieving an F1 score and AUC.6 and.12, respectively, higher than BinDiff while also having the ability to perform many-to-many comparisons. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134308965&doi=10.1007%2f978-3-031-09484-2_4&partnerID=40&md5=820f60e12484f50d90dd682cd807d323,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Guo Y.; Li P.; Luo Y.; Wang X.; Wang Z.,Exploring GNN Based Program Embedding Technologies for Binary Related Tasks,"With the rapid growth of program scale, program analysis, mainte-nance and optimization become increasingly diverse and complex. Applying learning-assisted methodologies onto program analysis has attracted ever-increasing attention. However, a large number of program factors including syntax structures, semantics, running platforms and compilation configurations block the effective re-alization of these methods. To overcome these obstacles, existing works prefer to be on a basis of source code or abstract syntax tree, but unfortunately are sub-optimal for binary-oriented analysis tasks closely related to the compilation process. To this end, we propose a new program analysis approach that aims at solving program-level and procedure-level tasks with one model, by taking advantage of the great power of graph neural networks from the level of binary code. By fusing the semantics of control flow graphs, data flow graphs and call graphs into one model, and embedding instructions and values simultaneously, our method can effectively work around emerging compilation-related problems. By testing the proposed method on two tasks, binary similarity detection and dead store prediction, the results show that our method is able to achieve as high accuracy as 83.25%, and 82.77%.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133161669&doi=10.1145%2f3524610.3527900&partnerID=40&md5=7849e312ebe5217cf738f249435b5fea,IEEE International Conference on Program Comprehension,Exclude,,Include,Exclude
Tian Z.; Li J.; Xue P.; Tian J.; Mao H.; Huang Y.,Functionality Recognition on Binary Code with Neural Representation Learning,"The functionality recognition of binary code has important application value in malware analysis, software forensics, binary code similarity analysis and other applications. Most of the existing methods are based on source code or machine learning strategies to carry out program similarity analysis, and this similarity analysis is also applied to a pair of programs, there are limitations in detection accuracy and quantity. Inspired by the recent great success of neural networks and representation learning in various program analysis tasks, We propose NPFI to analyze the binary code of the program and identify its functionality from the perspective of assembly instruction sequence. To evaluate the performance of NPFI, we built a large dataset consisting of 39,000 programs from six different categories collected from Google Code Jam. A large number of experiments show that the accuracy of NPFI in binary code function recognition can reach 95.8%, which is much better than the existing methods.  © 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125837947&doi=10.1145%2f3488933.3489033&partnerID=40&md5=eee9b40b605d53de1a0bced12674f451,ACM International Conference Proceeding Series,Exclude,,Exclude,
Wang K.; Yan M.; Zhang H.; Hu H.,Unified Abstract Syntax Tree Representation Learning for Cross-Language Program Classification,"Program classification can be regarded as a high-level abstraction of code, laying a foundation for various tasks related to source code comprehension, and has a very wide range of applications in the field of software engineering, such as code clone detection, code smell classification, defects classification, etc. The cross-language program classification can realize code transfer in different programming languages, and can also promote cross-language code reuse, thereby helping developers to write code quickly and reduce the development time of code transfer. Most of the existing studies focus on the semantic learning of the code, whilst few studies are devoted to cross-language tasks. The main challenge of cross-language program classification is how to extract semantic features of different programming languages. In order to cope with this difficulty, we propose a Unified Abstract Syntax Tree (namely UAST in this paper) neural network. In detail, the core idea of UAST consists of two unified mechanisms. First, UAST learns an AST representation by unifying the AST traversal sequence and graph-like AST structure for capturing semantic code features. Second, we construct a mechanism called unified vocabulary, which can reduce the feature gap between different programming languages, so it can achieve the role of cross-language program classification. Besides, we collect a dataset containing 20,000 files of five programming languages, which can be used as a benchmark dataset for the cross-language program classification task. We have done experiments on two datasets, and the results show that our proposed approach out-performs the state-of-the-art baselines in terms of four evaluation metrics (Precision, Recall, F1-score, and Accuracy).  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133153756&doi=10.1145%2f3524610.3527915&partnerID=40&md5=39053c8e722b50b94b0c9375c39fd15b,IEEE International Conference on Program Comprehension,Include,,Include,
Merrill M.A.; Zhang G.; Althoff T.,MULTIVERSE: Mining Collective Data Science Knowledge from Code on the Web to Suggest Alternative Analysis Approaches,"Data analyses are based on a series of ""decision points""including data filtering, feature operationalization and selection, model specification, and parametric assumptions. ""Multiverse Analysis""research has shown that a lack of exploration of these decisions can lead to non-robust conclusions based on highly sensitive decision points. Importantly, even if myopic analyses are technically correct, analysts' focus on one set of decision points precludes them from exploring alternate formulations that may produce very different results. Prior work has also shown that analysts' exploration is often limited based on their training, domain, and personal experience. However, supporting analysts in exploring alternative approaches is challenging and typically requires expert feedback that is costly and hard to scale. Here, we formulate the tasks of identifying decision points and suggesting alternative analysis approaches as a classification task and a sequence-to-sequence prediction task, respectively. We leverage public collective data analysis knowledge in the form of code submissions to the popular data science platform Kaggle to build the first predictive model which supports Multiverse Analysis. Specifically, we mine this code repository for 70k small differences between 40k submissions, and demonstrate that these differences often highlight key decision points and alternative approaches in their respective analyses.We leverage information on relationships within libraries through neural graph representation learning in a multitask learning framework. We demonstrate that our model, MULTIVERSE, is able to correctly predict decision points with up to 0.81 ROC AUC, and alternative code snippets with up to 50.3% GLEU, and that it performs favorably compared to a suite of baselines and ablations. We show that when our model has perfect information about the location of decision points, say provided by the analyst, its performance increases significantly from 50.3% to 73.4% GLEU. Finally, we show through a human evaluation that real data analysts find alternatives provided by MULTIVERSE to be more reasonable, acceptable, and syntactically correct than alternatives from comparable baselines, including other transformer-based seq2seq models.  © 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114930081&doi=10.1145%2f3447548.3467455&partnerID=40&md5=3db2efc4442406821c8ab5f1e393ab01,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Exclude,,,
Lu M.; Wang Y.; Tan D.; Zhao L.,Student Program Classification Using Gated Graph Attention Neural Network,"Source code mining has received increasing attention, among which code classification plays a significant role in code understanding and automatic coding. Most source code mining efforts aim at the source code of projects, which are usually large and standardized, but less for student programs. There are two differences between project codes and student programs. On the one hand, some work on project codes is based on relatively single information, which is far from enough for student programs. Because student programs are relatively small, which makes them contain less information. Consequently, it is necessary to mine as much information as possible in student programs. On the other hand, the variable or function naming and the structure of the student programs are usually irregular, as compared with the source codes of projects. To learn from student programs, we proposed a Graph Neural Network (GNN) based model, which integrates data flow and function call information to the Abstract Syntax Tree (AST), and applies an improved GNN model to the integrated graph to achieve the state-of-art student program classification accuracy. The experiment results have shown that the proposed work can classify student programs with accuracy over 97%. © 2013 IEEE.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117607455&doi=10.1109%2fACCESS.2021.3063475&partnerID=40&md5=26575eb8c4dfa836f1de5454370cb284,IEEE Access,Include,,,
Ji Y.; Cui L.; Huang H.H.,Vestige: Identifying Binary Code Provenance for Vulnerability Detection,"Identifying the compilation provenance of a binary code helps to pinpoint the specific compilation tools and configurations that were used to produce the executable. Unfortunately, existing techniques are not able to accurately differentiate among closely related executables, especially those generated with minor different compiling configurations. To address this problem, we have designed a new provenance identification system, Vestige. We build a new representation of the binary code, i.e., attributed function call graph (AFCG), that covers three types of features: idiom features at the instruction level, graphlet features at the function level, and function call graph at the binary level. Vestige applies a graph neural network model on the AFCG and generates representative embeddings for provenance identification. The experiment shows that Vestige achieves 96% accuracy on the publicly available datasets of more than 6,000 binaries, which is significantly better than previous works. When applied for binary code vulnerability detection, Vestige can help to improve the top-1 hit rate of three recent code vulnerability detection methods by up to 27%. © 2021, Springer Nature Switzerland AG.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111112223&doi=10.1007%2f978-3-030-78375-4_12&partnerID=40&md5=936e45574e58f893af44e7c2d7b71001,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Yu Z.; Cao R.; Tang Q.; Nie S.; Huang J.; Wu S.,Order matters: Semantic-aware neural networks for binary code similarity detection,"Binary code similarity detection, whose goal is to detect similar binary functions without having access to the source code, is an essential task in computer security. Traditional methods usually use graph matching algorithms, which are slow and inaccurate. Recently, neural network-based approaches have made great achievements. A binary function is first represented as an control-flow graph (CFG) with manually selected block features, and then graph neural network (GNN) is adopted to compute the graph embedding. While these methods are effective and efficient, they could not capture enough semantic information of the binary code. In this paper we propose semantic-aware neural networks to extract the semantic information of the binary code. Specially, we use BERT to pre-train the binary code on one token-level task, one block-level task, and two graph-level tasks. Moreover, we find that the order of the CFG’s nodes is important for graph similarity detection, so we adopt convolutional neural network (CNN) on adjacency matrices to extract the order information. We conduct experiments on two tasks with four datasets. The results demonstrate that our method outperforms the state-of-art models. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097128887&partnerID=40&md5=5e289593a1710bb4002d137a30131367,AAAI 2020 - 34th AAAI Conference on Artificial Intelligence,Exclude,,Exclude,
Duan Y.; Li X.; Wang J.; Yin H.,DEEPBINDIFF: Learning Program-Wide Code Representations for Binary Diffing,"Binary diffing analysis quantitatively measures the differences between two given binaries and produces fine-grained basic block level matching. It has been widely used to enable different kinds of critical security analysis. However, all existing program analysis and machine learning based techniques suffer from low accuracy, poor scalability, coarse granularity, or require extensive labeled training data to function. In this paper, we propose an unsupervised program-wide code representation learning technique to solve the problem. We rely on both the code semantic information and the program-wide control flow information to generate basic block embeddings. Furthermore, we propose a khop greedy matching algorithm to find the optimal diffing results using the generated block embeddings. We implement a prototype called DEEPBINDIFF and evaluate its effectiveness and efficiency with a large number of binaries. The results show that our tool outperforms the state-of-the-art binary diffing tools by a large margin for both cross-version and cross-optimization-level diffing. A case study for OpenSSL using real-world vulnerabilities further demonstrates the usefulness of our system. © 2020 27th Annual Network and Distributed System Security Symposium, NDSS 2020. All Rights Reserved.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108560987&doi=10.14722%2fndss.2020.24311&partnerID=40&md5=d676b4af4bd515fd4f93a51b44e7437d,"27th Annual Network and Distributed System Security Symposium, NDSS 2020",Exclude,,,
Shi E.; Wang Y.; Du L.; Zhang H.; Han S.; Zhang D.; Sun H.,CoCoAST: Representing Source Code via Hierarchical Splitting and Reconstruction of Abstract Syntax Trees,"Recently, machine learning techniques especially deep learning techniques have made substantial progress on some code intelligence tasks such as code summarization, code search, clone detection, etc. How to represent source code to effectively capture the syntactic, structural, and semantic information is a key challenge. Recent studies show that the information extracted from abstract syntax trees (ASTs) is conducive to code representation learning. However, existing approaches fail to fully capture the rich information in ASTs due to the large size/depth of ASTs. In this paper, we propose a novel model CoCoAST that hierarchically splits and reconstructs ASTs to comprehensively capture the syntactic and semantic information of code without the loss of AST structural information. First, we hierarchically split a large AST into a set of subtrees and utilize a recursive neural network to encode the subtrees. Then, we aggregate the embeddings of subtrees by reconstructing the split ASTs to get the representation of the complete AST. Finally, we combine AST representation carrying the syntactic and structural information and source code embedding representing the lexical information to obtain the final neural code representation. We have applied our source code representation to two common program comprehension tasks, code summarization and code search. Extensive experiments have demonstrated the superiority of CoCoAST. To facilitate reproducibility, our data and code are available https://github.com/s1530129650/CoCoAST . © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173621153&doi=10.1007%2fs10664-023-10378-9&partnerID=40&md5=c13a0a2c7d54cce36d56f84297dc75a7,Empirical Software Engineering,Include,,Include,
Yang J.; Fu C.; Deng F.; Wen M.; Guo X.; Wan C.,Toward Interpretable Graph Tensor Convolution Neural Network for Code Semantics Embedding,"Intelligent deep learning-based models have made significant progress for automated source code semantics embedding, and current research works mainly leverage natural language-based methods and graph-based methods. However, natural language-based methods do not capture the rich semantic structural information of source code, and graph-based methods do not utilize rich distant information of source code due to the high cost of message-passing steps.In this article, we propose a novel interpretable model, called graph tensor convolution neural network (GTCN), to generate accurate code embedding, which is capable of comprehensively capturing the distant information of code sequences and rich code semantics structural information. First, we propose to utilize a high-dimensional tensor to integrate various heterogeneous code graphs with node sequence features, such as control flow, data flow. Second, inspired by the current advantages of graph-based deep learning and efficient tensor computations, we propose a novel interpretable graph tensor convolution neural network for learning accurate code semantic embedding from the code graph tensor. Finally, we evaluate three popular applications on the GTCN model: variable misuse detection, source code prediction, and vulnerability detection. Compared with current state-of-the-art methods, our model achieves higher scores with respect to the top-1 accuracy while costing less training time.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168769136&doi=10.1145%2f3582574&partnerID=40&md5=ba7fac921dc538ffe1e6a93800dcd2d5,ACM Transactions on Software Engineering and Methodology,Include,,,
Zhang G.; Merrill M.A.; Liu Y.; Heer J.; Althoff T.,CORAL: COde RepresentAtion learning with weakly-supervised transformers for analyzing data analysis,"Large scale analysis of source code, and in particular scientific source code, holds the promise of better understanding the data science process, identifying analytical best practices, and providing insights to the builders of scientific toolkits. However, large corpora have remained unanalyzed in depth, as descriptive labels are absent and require expert domain knowledge to generate. We propose a novel weakly supervised transformer-based architecture for computing joint representations of code from both abstract syntax trees and surrounding natural language comments. We then evaluate the model on a new classification task for labeling computational notebook cells as stages in the data analysis process from data import to wrangling, exploration, modeling, and evaluation. We show that our model, leveraging only easily-available weak supervision, achieves a 38% increase in accuracy over expert-supplied heuristics and outperforms a suite of baselines. Our model enables us to examine a set of 118,000 Jupyter Notebooks to uncover common data analysis patterns. Focusing on notebooks with relationships to academic articles, we conduct the largest study of scientific code to date and find that notebooks which devote an higher fraction of code to the typically labor-intensive process of wrangling data in expectation exhibit decreased citation counts for corresponding papers. We also show significant differences between academic and non-academic notebooks, including that academic notebooks devote substantially more code to wrangling and exploring data, and less on modeling. © 2022, The Author(s).",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126774781&doi=10.1140%2fepjds%2fs13688-022-00327-9&partnerID=40&md5=a8e32194694d6166b5290864d0fc7867,EPJ Data Science,Include,,,
Jinpa T.; Gao Y.,Code Representation Learning Using Prüfer Sequences (Student Abstract),"An effective and efficient encoding of the source code of a computer program is critical to the success of sequence-to-sequence deep neural network models for code representation learning. In this study, we propose to use the Prüfer sequence of the Abstract Syntax Tree (AST) of a computer program to design a sequential representation scheme that preserves the structural information in an AST. Our representation makes it possible to develop deep-learning models in which signals carried by lexical tokens in the training examples can be exploited automatically and selectively based on their syntactic role and importance. Unlike other recently-proposed approaches, our representation is concise and lossless in terms of the structural information of the AST. Results from our experiment show that prüfersequence-based representation is indeed highly effective and efficient. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147607636&partnerID=40&md5=fde81c806a8d45c389e74d6a5a2580b9,"Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022",Include,,,
Yang K.; Yu H.; Fan G.; Yang X.; Huang Z.,A graph sequence neural architecture for code completion with semantic structure features,"Code completion plays an important role in intelligent software development for accelerating coding efficiency. Recently, the prediction models based on deep learning have achieved good performance in code completion task. However, the existing models cannot avoid three drawbacks: (i) In the existing models, the code representation loses the information (parent–child information between nodes) and lacks many effective features (orientation between nodes). (ii) The known code structure information is not fully utilized, which will cause the model to generate completely irrelevant results. (iii) Simple sequence modeling ignores repeated patterns and structural information. Besides, previous works cannot capture the characteristics of correlation and directionality between nodes. In this paper, we propose a Code Completion approach named CC-GGNN, which is graph model based on Gated Graph Neural Networks (GGNNs) to address the problems. We introduce a new architecture to obtain the effective code features from code representation. In order to utilize the known information, we propose Classification Mechanism, which classifies the representation of the node using the known parent node and constructs training graph in the model. The experimental results show that our model outperforms the state-of-the-art methods MRR@5 at most 9.2% and ACC at most 11.4% in datasets. © 2022 John Wiley & Sons, Ltd.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122136280&doi=10.1002%2fsmr.2414&partnerID=40&md5=970b6c7fa148f561f4d2147c0e4ad322,Journal of Software: Evolution and Process,Include,,,
Zügner D.; Kirschstein T.; Catasta M.; Leskovec J.; Günnemann S.,LANGUAGE-AGNOSTIC REPRESENTATION LEARNING OF SOURCE CODE FROM STRUCTURE AND CONTEXT,"Source code (Context) and its parsed abstract syntax tree (AST; Structure) are two complementary representations of the same computer program. Traditionally, designers of machine learning models have relied predominantly either on Structure or Context. We propose a new model, which jointly learns on Context and Structure of source code. In contrast to previous approaches, our model uses only language-agnostic features, i.e., source code and features that can be computed directly from the AST. Besides obtaining state-of-the-art on monolingual code summarization on all five programming languages considered in this work, we propose the first multilingual code summarization model. We show that jointly training on non-parallel data from multiple programming languages improves results on all individual languages, where the strongest gains are on low-resource languages. Remarkably, multilingual training only from Context does not lead to the same improvements, highlighting the benefits of combining Structure and Context for representation learning on code. © 2021 ICLR 2021 - 9th International Conference on Learning Representations. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149138769&partnerID=40&md5=4e233116ed104a3bb5d58e031d653e5b,ICLR 2021 - 9th International Conference on Learning Representations,Include,,Include,
Tang B.; Li B.; Bo L.; Wu X.; Cao S.; Sun X.,GrasP: Graph-to-Sequence Learning for Automated Program Repair,"Many deep learning models, for example, neural machine translation (NMT) models, have been developed for Automated Program Repair (APR). Due to the advantages of NMT model's strong generalization ability and less manual in-tervention, NMT-based methods perform well in APR. However, previous NMT-based APR approaches regard a code snippet as a sequence of tokens, which ignores the inherent structure of code. In this paper, we propose a novel end-to-end approach with Graph-to-Sequence learning, GrasP, to generate patches for buggy methods. To better represent the buggy method, we use a graph based on abstract syntax tree (AST) to represent the source code. In order to learn complex graph representation, we introduce the attention-based encoder-decoder model for graph-to-sequence learning. The empirical evaluation on the popular benchmark Defects4J shows that GrasP can generate compilable patches for 75 bugs, of which 34 patches are correct. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146199863&doi=10.1109%2fQRS54544.2021.00091&partnerID=40&md5=6bc06b1dda865890b178f523886edc45,"IEEE International Conference on Software Quality, Reliability and Security, QRS",Include,,,
Liu L.; Nguyen H.; Karypis G.; Sengamedu S.,Universal Representation for Code,"Learning from source code usually requires a large amount of labeled data. Despite the possible scarcity of labeled data, the trained model is highly task-specific and lacks transferability to different tasks. In this work, we present effective pre-training strategies on top of a novel graph-based code representation, to produce universal representations for code. Specifically, our graph-based representation captures important semantics between code elements (e.g., control flow and data flow). We pre-train graph neural networks on the representation to extract universal code properties. The pre-trained model then enables the possibility of fine-tuning to support various downstream applications. We evaluate our model on two real-world datasets – spanning over 30M Java methods and 770K Python methods. Through visualization, we reveal discriminative properties in our universal code representation. By comparing multiple benchmarks, we demonstrate that the proposed framework achieves state-of-the-art results on method name prediction and code graph link prediction. © 2021, Springer Nature Switzerland AG.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111035967&doi=10.1007%2f978-3-030-75768-7_2&partnerID=40&md5=4ef743435f71959828255e3974d6b29c,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,,
Venkatakeerthy S.; Aggarwal R.; Jain S.; Desarkar M.S.; Upadrasta R.; Srikant Y.N.,IR2Vec: LLVM IR Based Scalable Program Embeddings,"We propose IR2VEC, a Concise and Scalable encoding infrastructure to represent programs as a distributed embedding in continuous space. This distributed embedding is obtained by combining representation learning methods with flow information to capture the syntax as well as the semantics of the input programs. As our infrastructure is based on the Intermediate Representation (IR) of the source code, obtained embeddings are both language and machine independent. The entities of the IR are modeled as relationships, and their representations are learned to form a seed embedding vocabulary. Using this infrastructure, we propose two incremental encodings: Symbolic and Flow-Aware. Symbolic encodings are obtained from the seed embedding vocabulary, and Flow-Aware encodings are obtained by augmenting the Symbolic encodings with the flow information. We show the effectiveness of our methodology on two optimization tasks (Heterogeneous device mapping and Thread coarsening). Our way of representing the programs enables us to use non-sequential models resulting in orders of magnitude of faster training time. Both the encodings generated by IR2VEC outperform the existing methods in both the tasks, even while using simple machine learning models. In particular, our results improve or match the state-of-the-art speedup in 11/14 benchmark-suites in the device mapping task across two platforms and 53/68 benchmarks in the thread coarsening task across four different platforms. When compared to the other methods, our embeddings are more scalable, is non-data-hungry, and has better Out-Of-Vocabulary (OOV) characteristics. © 2020 ACM.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098870321&doi=10.1145%2f3418463&partnerID=40&md5=a137d37f2ec0c45ad5f31e65125d6a10,ACM Transactions on Architecture and Code Optimization,Include,,,
Cvitkovic M.; Singh B.; Anandkumar A.,Open vocabulary learning on source code with a graph-structured cache,"Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names. Reasoning over such a vocabulary is not something for which most NLP methods are designed. We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code. We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task - with over 100% relative improvement on the latter - at the cost of a moderate increase in computation time. © 36th International Conference on Machine Learning, ICML 2019. All rights reserved.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078072426&partnerID=40&md5=05e02a0ff3c9ea6667e013574ef10611,"36th International Conference on Machine Learning, ICML 2019",Include,,,
Zhang Y.; Wang G.; Li C.; Gan Z.; Brockett C.; Dolan B.,POINTER: Constrained progressive text generation via insertion-based generative pre-training,"Large-scale pre-trained language models, such as BERT and GPT-2, have achieved excellent performance in language representation learning and free-form text generation. However, these models cannot be directly employed to generate text under specified lexical constraints. To address this challenge, we present POINTER, a simple yet novel insertion-based approach for hard-constrained text generation. The proposed method operates by progressively inserting new tokens between existing tokens in a parallel manner. This procedure is recursively applied until a sequence is completed. The resulting coarse-to-fine hierarchy makes the generation process intuitive and interpretable. We pre-train our model with the proposed progressive insertion-based objective on a 12GB Wikipedia dataset, and fine-tune it on downstream hard-constrained generation tasks. Non-autoregressive decoding yields an empirically logarithmic time complexity during inference time. Experimental results on both News and Yelp datasets demonstrate that POINTER achieves state-of-the-art performance on constrained text generation. We released the pre-trained models and the source code to facilitate future research. © 2020 Association for Computational Linguistics.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102840672&partnerID=40&md5=ab144a18419d96817e855767c6f00b8d,"EMNLP 2020 - 2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference",Exclude,,,
Shi Z.; Swersky K.; Tarlow D.; Ranganathan P.; Hashemi M.,LEARNING EXECUTION THROUGH NEURAL CODE FUSION,"As the performance of computer systems stagnates due to the end of Moore's Law, there is a need for new models that can understand and optimize the execution of general purpose code. While there is a growing body of work on using Graph Neural Networks (GNNs) to learn static representations of source code, these representations do not understand how code executes at runtime. In this work, we propose a new approach using GNNs to learn fused representations of general source code and its execution. Our approach defines a multi-task GNN over low-level representations of source code and program state (i.e., assembly code and dynamic memory states), converting complex source code constructs and data structures into a simpler, more uniform format. We show that this leads to improved performance over similar methods that do not use execution and it opens the door to applying GNN models to new tasks that would not be feasible from static code alone. As an illustration of this, we apply the new model to challenging dynamic tasks (branch prediction and prefetching) from the SPEC CPU benchmark suite, outperforming the state-of-the-art by 26% and 45% respectively. Moreover, we use the learned fused graph embeddings to demonstrate transfer learning with high performance on an indirectly related algorithm classification task. © 2020 8th International Conference on Learning Representations, ICLR 2020. All rights reserved.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105543852&partnerID=40&md5=16f7d289640c1830341c28d0aa059365,"8th International Conference on Learning Representations, ICLR 2020",Exclude,,,
Kampffmeyer M.; Løkse S.; Bianchi F.M.; Jenssen R.; Livi L.,The deep kernelized autoencoder,"Autoencoders learn data representations (codes) in such a way that the input is reproduced at the output of the network. However, it is not always clear what kind of properties of the input data need to be captured by the codes. Kernel machines have experienced great success by operating via inner-products in a theoretically well-defined reproducing kernel Hilbert space, hence capturing topological properties of input data. In this paper, we enhance the autoencoder's ability to learn effective data representations by aligning inner products between codes with respect to a kernel matrix. By doing so, the proposed kernelized autoencoder allows learning similarity-preserving embeddings of input data, where the notion of similarity is explicitly controlled by the user and encoded in a positive semi-definite kernel matrix. Experiments are performed for evaluating both reconstruction and kernel alignment performance in classification tasks and visualization of high-dimensional data. Additionally, we show that our method is capable to emulate kernel principal component analysis on a denoising task, obtaining competitive results at a much lower computational cost. © 2018 Elsevier B.V.",Article,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050465973&doi=10.1016%2fj.asoc.2018.07.029&partnerID=40&md5=fc118d3a0afd137adfcdef80a9b605d9,Applied Soft Computing Journal,Exclude,,,
Sun T.; Allix K.; Kim K.; Zhou X.; Kim D.; Lo D.; Bissyande T.F.; Klein J.,"DexBERT: Effective, Task-Agnostic and Fine-Grained Representation Learning of Android Bytecode","The automation of an increasingly large number of software engineering tasks is becoming possible thanks to Machine Learning (ML). One foundational building block in the application of ML to software artifacts is the representation of these artifacts (e.g., source code or executable code) into a form that is suitable for learning. Traditionally, researchers and practitioners have relied on manually selected features, based on expert knowledge, for the task at hand. Such knowledge is sometimes imprecise and generally incomplete. To overcome this limitation, many studies have leveraged representation learning, delegating to ML itself the job of automatically devising suitable representations and selections of the most relevant features. Yet, in the context of Android problems, existing models are either limited to coarse-grained whole-app level (e.g., apk2vec) or conducted for one specific downstream task (e.g., smali2vec). Thus, the produced representation may turn out to be unsuitable for fine-grained tasks or cannot generalize beyond the task that they have been trained on. Our work is part of a new line of research that investigates effective, task-agnostic, and fine-grained universal representations of bytecode to mitigate both of these two limitations. Such representations aim to capture information relevant to various low-level downstream tasks (e.g., at the class-level). We are inspired by the field of Natural Language Processing, where the problem of universal representation was addressed by building Universal Language Models, such as BERT, whose goal is to capture abstract semantic information about sentences, in a way that is reusable for a variety of tasks. We propose DexBERT, a BERT-like Language Model dedicated to representing chunks of DEX bytecode, the main binary format used in Android applications. We empirically assess whether DexBERT is able to model the DEX language and evaluate the suitability of our model in three distinct class-level software engineering tasks: Malicious Code Localization, Defect Prediction, and Component Type Classification. We also experiment with strategies to deal with the problem of catering to apps having vastly different sizes, and we demonstrate one example of using our technique to investigate what information is relevant to a given task.  © 1976-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170519171&doi=10.1109%2fTSE.2023.3310874&partnerID=40&md5=0ad210d58ac1e830e40255f73edee98f,IEEE Transactions on Software Engineering,Exclude,,Exclude,
Du Y.; Yu Z.,Pre-training Code Representation with Semantic Flow Graph for Effective Bug Localization,"Enlightened by the big success of pre-training in natural language processing, pre-trained models for programming languages have been widely used to promote code intelligence in recent years. In particular, BERT has been used for bug localization tasks and impressive results have been obtained. However, these BERT-based bug localization techniques suffer from two issues. First, the pre-trained BERT model on source code does not adequately capture the deep semantics of program code. Second, the overall bug localization models neglect the necessity of large-scale negative samples in contrastive learning for representations of changesets and ignore the lexical similarity between bug reports and changesets during similarity estimation. We address these two issues by 1) proposing a novel directed, multiple-label code graph representation named Semantic Flow Graph (SFG), which compactly and adequately captures code semantics, 2) designing and training SemanticCodeBERT based on SFG, and 3) designing a novel Hierarchical Momentum Contrastive Bug Localization technique (HMCBL). Evaluation results show that our method achieves state-of-the-art performance in bug localization. © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171247925&doi=10.1145%2f3611643.3616338&partnerID=40&md5=e08baefee4d93ec33ea9e8ad9a0cf336,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,Include,,,
Niu C.; Li C.; Ng V.; Luo B.,Comparing the Pretrained Models of Source Code by Re-pretraining Under a Unified Setup,"Recent years have seen the successful application of large pretrained models of source code (CodePTMs) to code representation learning, which have taken the field of software engineering (SE) from task-specific solutions to task-agnostic generic models. By the remarkable results, CodePTMs are seen as a promising direction in both academia and industry. While a number of CodePTMs have been proposed, they are often not directly comparable because they differ in experimental setups such as pretraining dataset, model size, evaluation tasks, and datasets. In this article, we first review the experimental setup used in previous work and propose a standardized setup to facilitate fair comparisons among CodePTMs to explore the impacts of their pretraining tasks. Then, under the standardized setup, we re-pretrain CodePTMs using the same model architecture, input modalities, and pretraining tasks, as they declared and fine-tune each model on each evaluation SE task for evaluating. Finally, we present the experimental results and make a comprehensive discussion on the relative strength and weakness of different pretraining tasks with respect to each SE task. We hope our view can inspire and advance the future study of more powerful CodePTMs. IEEE",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171754905&doi=10.1109%2fTNNLS.2023.3308595&partnerID=40&md5=d0467fe91db9f21685d98a7a586c60c7,IEEE Transactions on Neural Networks and Learning Systems,Include,,Include,
Chimalakonda S.; Das D.; Mathai A.; Tamilselvam S.; Kumar A.,The Landscape of Source Code Representation Learning in AI-Driven Software Engineering Tasks,"Appropriate representation of source code and its relevant properties form the backbone of Artificial Intelligence (AI)/ Machine Learning (ML) pipelines for various software engineering (SE) tasks such as code classification, bug prediction, code clone detection, and code summarization. In the literature, researchers have extensively experimented with different kinds of source code representations (syntactic, semantic, integrated, customized) and ML techniques such as pre-trained BERT models. In addition, it is common for researchers to create hand-crafted and customized source code representations for an appropriate SE task. In a 2018 survey [1], Allamanis et al. listed nearly 35 different ways of of representing source code for different SE tasks like Abstract Syntax Trees (ASTs), customized ASTs, Control Flow Graphs (CFGs), Data Flow Graphs (DFGs) and so on. The main goal of this tutorial is two-fold (i) Present an overview of the state-of-the-art of source code representations and corresponding ML pipelines with an explicit focus on the merits and demerits of each of the representations (ii) Practical challenges in infusing different code-views in the state-of-the-art ML models and future research directions. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171831752&doi=10.1109%2fICSE-Companion58688.2023.00098&partnerID=40&md5=7fb2dc0b10e16392fad70c3acc840702,Proceedings - International Conference on Software Engineering,Include,,,
Zhao J.; Rong Y.; Guo Y.; He Y.; Chen H.,Understanding Programs by Exploiting (Fuzzing) Test Cases,"Semantic understanding of programs has attracted great attention in the community. Inspired by recent successes of large language models (LLMs) in natural language understanding, tremendous progress has been made by treating programming language as another sort of natural language and training LLMs on corpora of program code. However, programs are essentially different from texts after all, in a sense that they are normally heavily structured and syntax-strict. In particular, programs and their basic units (i.e., functions and subroutines) are designed to demonstrate a variety of behaviors and/or provide possible outputs, given different inputs. The relationship between inputs and possible outputs/behaviors represents the functions/subroutines and profiles the program as a whole. Therefore, we propose to incorporate such a relationship into learning, for achieving a deeper semantic understanding of programs. To obtain inputs that are representative enough to trigger the execution of most part of the code, we resort to fuzz testing and propose fuzz tuning to boost the performance of program understanding and code representation learning, given a pre-trained LLM. The effectiveness of the proposed method is verified on two program understanding tasks including code clone detection and code classification, and it outperforms current state-of-the-arts by large margins. Code is available at https://github.com/rabbitjy/FuzzTuning. © 2023 Association for Computational Linguistics.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173691344&partnerID=40&md5=d9a46934efa969111a8f9dc41521f5d7,Proceedings of the Annual Meeting of the Association for Computational Linguistics,Exclude,,Include,Exclude
Li Y.; Wang S.; Nguyen T.N.,Contextuality of Code Representation Learning,"Advanced machine learning models (ML) have been successfully leveraged in several software engineering (SE) applications. The existing SE techniques have used the embedding models ranging from static to contextualized ones to build the vectors for program units. The contextualized vectors address a phenomenon in natural language texts called polysemy, which is the coexistence of different meanings of a word/phrase. However, due to different nature, program units exhibit the nature of mixed polysemy. Some code tokens and statements exhibit polysemy while other tokens (e.g., keywords, separators, and operators) and statements maintain the same meaning in different contexts. A natural question is whether static or contextualized embeddings fit better with the nature of mixed polysemy in source code. The answer to this question is helpful for the SE researchers in selecting the right embedding model. We conducted experiments on 12 popular sequence-/tree-/graph-based embedding models and on the samples of a dataset of 10,222 Java projects with +14M methods. We present several contextuality evaluation metrics adapted from natural-language texts to code structures to evaluate the embeddings from those models. Among several findings, we found that the models with higher contextuality help a bug detection model perform better than the static ones. Neither static nor contextualized embedding models fit well with the mixed polysemy nature of source code. Thus, we develop Hycode, a hybrid embedding model that fits better with the nature of mixed polysemy in source code.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179003533&doi=10.1109%2fASE56229.2023.00029&partnerID=40&md5=a7534a657318d2c3d46776b193ca0886,"Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023",Include,,,
Meng C.; Ao J.; Ko T.; Wang M.; Li H.,CoBERT: Self-Supervised Speech Representation Learning Through Code Representation Learning,"Speech is the surface form of a finite set of phonetic units, which can be represented by discrete codes. We propose the Code BERT (CoBERT) approach for self-supervised speech representation learning. The idea is to convert an utterance to a sequence of discrete codes, and perform code representation learning, where we predict the code representations based on a masked view of the original speech input. Unlike the prior self-distillation approaches of which the teacher and the student are of the same modality, our target model predicts representations from a different modality. CoBERT outperforms the most recent state-of-the-art performance on the ASR task and brings significant improvements on the SUPERB speech translation (ST) task. Our code and models are released at https://github.com/mct10/CoBERT. © 2023 International Speech Communication Association. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171528624&doi=10.21437%2fInterspeech.2023-1390&partnerID=40&md5=4408b70aef72b9b859bed2314f33017e,"Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH",Exclude,,,
Lin Z.; Li G.; Zhang J.; Deng Y.; Zeng X.; Zhang Y.; Wan Y.,XCode: Towards Cross-Language Code Representation with Large-Scale Pre-Training,"Source code representation learning is the basis of applying artificial intelligence to many software engineering tasks such as code clone detection, algorithm classification, and code summarization. Recently, many works have tried to improve the performance of source code representation from various perspectives, e.g., introducing the structural information of programs into latent representation. However, when dealing with rapidly expanded unlabeled cross-language source code datasets from the Internet, there are still two issues. Firstly, deep learning models for many code-specific tasks still suffer from the lack of high-quality labels. Secondly, the structural differences among programming languages make it more difficult to process multiple languages in a single neural architecture.To address these issues, in this article, we propose a novel Cross-language Code representation with a large-scale pre-Training (XCode) method. Concretely, we propose to use several abstract syntax trees and ELMo-enhanced variational autoencoders to obtain multiple pre-Trained source code language models trained on about 1.5 million code snippets. To fully utilize the knowledge across programming languages, we further propose a Shared Encoder-Decoder (SED) architecture which uses the multi-Teacher single-student method to transfer knowledge from the aforementioned pre-Trained models to the distilled SED. The pre-Trained models and SED will cooperate to better represent the source code. For evaluation, we examine our approach on three typical downstream cross-language tasks, i.e., source code translation, code clone detection, and code-To-code search, on a real-world dataset composed of programming exercises with multiple solutions. Experimental results demonstrate the effectiveness of our proposed approach on cross-language code representations. Meanwhile, our approach performs significantly better than several code representation baselines on different downstream tasks in terms of multiple automatic evaluation metrics.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130754433&doi=10.1145%2f3506696&partnerID=40&md5=b2c60159ed514b3de7d7cdd2aaa6e896,ACM Transactions on Software Engineering and Methodology,Include,,,
Keller P.; Kaboré A.K.; Plein L.; Klein J.; Le Traon Y.; Bissyandé T.F.,What You See is What it Means! Semantic Representation Learning of Code based on Visualization and Transfer Learning,"Recent successes in training word embeddings for Natural Language Processing (NLP) tasks have encouraged a wave of research on representation learning for source code, which builds on similar NLP methods. The overall objective is then to produce code embeddings that capture the maximum of program semantics. State-of-the-art approaches invariably rely on a syntactic representation (i.e., raw lexical tokens, abstract syntax trees, or intermediate representation tokens) to generate embeddings, which are criticized in the literature as non-robust or non-generalizable. In this work, we investigate a novel embedding approach based on the intuition that source code has visual patterns of semantics. We further use these patterns to address the outstanding challenge of identifying semantic code clones. We propose the WySiWiM (What You See Is What It Means"") approach where visual representations of source code are fed into powerful pre-trained image classification neural networks from the field of computer vision to benefit from the practical advantages of transfer learning. We evaluate the proposed embedding approach on the task of vulnerable code prediction in source code and on two variations of the task of semantic code clone identification: code clone detection (a binary classification problem), and code classification (a multi-classification problem). We show with experiments on the BigCloneBench (Java), Open Judge (C) that although simple, our WySiWiM approach performs as effectively as state-of-the-art approaches such as ASTNN or TBCNN. We also showed with data from NVD and SARD that WySiWiM representation can be used to learn a vulnerable code detector with reasonable performance (accuracy 1/490%). We further explore the influence of different steps in our approach, such as the choice of visual representations or the classification algorithm, to eventually discuss the promises and limitations of this research direction.  © 2021 Copyright held by the owner/author(s).",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130697770&doi=10.1145%2f3485135&partnerID=40&md5=52a1303320e21c7950828ae961ad8df7,ACM Transactions on Software Engineering and Methodology,Exclude,,,
Cui N.; Jiang Y.; Gu X.; Shen B.,Zero-Shot Program Representation Learning,"Learning program representations has been the core prerequisite of code intelligence tasks (e.g., code search and code clone detection). The state-of-the-art pre-trained models such as CodeBERT require the availability of large-scale code corpora. However, gathering training samples can be costly and infeasible for domain-specific languages such as Solidity for smart contracts. In this paper, we propose Zecoler, a zero-shot learning approach for code representations. Zecoler is built upon a pre-trained programming language model. In order to elicit knowledge from the pre-trained models efficiently, Zecoler casts the downstream tasks to the same form of pre-training tasks by inserting trainable prompts into the original input. Then, it employs the prompt learning technique to optimize the pre-trained model by merely adjusting the original input. This enables the representation model to efficiently fit the scarce task-specific data while reusing pre-trained knowledge. We evaluate Zecoler in three code intelligence tasks in two programming languages that have no training samples, namely, Solidity and Go, with model trained in corpora of common languages such as Java. Experimental results show that our approach significantly outperforms baseline models in both zero-shot and few-shot settings.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133187003&doi=10.1145%2f3524610.3527888&partnerID=40&md5=f2a904c1fc587c4c5d7d2c038cd7f666,IEEE International Conference on Program Comprehension,Exclude,,Include,Exclude
Niu C.; Li C.; Ng V.; Ge J.; Huang L.; Luo B.,SPT-Code: Sequence-to-Sequence Pre-Training for Learning Source Code Representations,"Recent years have seen the successful application of large pretrained models to code representation learning, resulting in substantial improvements on many code-related downstream tasks. But there are issues surrounding their application to SE tasks. First, the majority of the pre-trained models focus on pre-training only the encoder of the Transformer. For generation tasks that are addressed using models with the encoder-decoder architecture, however, there is no reason why the decoder should be left out during pre-training. Second, many existing pre-trained models, including state-of-the-art models such as T5-learning, simply reuse the pretraining tasks designed for natural languages. Moreover, to learn the natural language description of source code needed eventually for code-related tasks such as code summarization, existing pretraining tasks require a bilingual corpus composed of source code and the associated natural language description, which severely limits the amount of data for pre-training. To this end, we propose SPT-Code, a sequence-to-sequence pre-trained model for source code. In order to pre-train SPT-Code in a sequence-to-sequence manner and address the aforementioned weaknesses associated with existing pre-training tasks, we introduce three pre-training tasks that are specifically designed to enable SPT-Code to learn knowledge of source code, the corresponding code structure, as well as a natural language description of the code without relying on any bilingual corpus, and eventually exploit these three sources of information when it is applied to downstream tasks. Experimental results demonstrate that SPT-Code achieves state-of-the-art performance on five code-related downstream tasks after fine-tuning. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133513452&doi=10.1145%2f3510003.3510096&partnerID=40&md5=18a9ca084d782c4090bd202321d344e9,Proceedings - International Conference on Software Engineering,Exclude,,Include,Exclude
Cleuziou G.; Flouvat F.,Learning student program embeddings using abstract execution traces,"Improving the pedagogical effectiveness of programming training platforms is a hot topic that requires the construction of fine and exploitable representations of learners’ programs. This article presents a new approach for learning program embeddings. Starting from the hypothesis that the function of a program, but also its”style”, can be captured by analyzing its execution traces, the code2aes2vec method proceeds in two steps. A first step generates abstract execution sequences (AES) from both predefined test cases and abstract syntax trees (AST) of the submitted programs. The doc2vec method is then used to learn condensed vector representations (embeddings) of the programs from these AESs. Experiments performed on real data sets shows that the embeddings generated by code2aes2vec efficiently capture both the semantics and the style of the programs. Finally, we show the relevance of the program embeddings thus generated on the task of automatic feedback propagation as a proof of concept. © EDM 2021.All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174296119&partnerID=40&md5=4ac0ae3f44fe08acecfcaea4b2988118,"Proceedings of the 14th International Conference on Educational Data Mining, EDM 2021",Include,,,
Wang D.; Yu Y.; Li S.; Dong W.; Wang J.; Qing L.,MulCode: A Multi-task Learning Approach for Source Code Understanding,"Recent years have witnessed the significant rise of Deep Learning (DL) techniques applied to source code. Researchers exploit DL for a multitude of tasks and achieve impressive results. However, most tasks are explored separately, resulting in a lack of generalization of the solutions. In this work, we propose MulCode, a multi-task learning approach for source code understanding that learns unified representation space for tasks, with the pre-trained BERT model for the token sequence and the Tree-LSTM model for abstract syntax trees. Furthermore, we integrate two source code views into a hybrid representation via the attention mechanism and set learnable uncertainty parameters to adjust the tasks' relationship.We train and evaluate MulCode in three downstream tasks: comment classification, author attribution, and duplicate function detection. In all tasks, MulCode outperforms the state-of-the-art techniques. Moreover, experiments on three unseen tasks demonstrate the generalization ability of MulCode compared with state-of-the-art embedding methods. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106562192&doi=10.1109%2fSANER50967.2021.00014&partnerID=40&md5=19013a3e0211265450216dfea0cf9212,"Proceedings - 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2021",Include,,Include,
Zeng C.; Yu Y.; Li S.; Xia X.; Wang Z.; Geng M.; Bai L.; Dong W.; Liao X.,deGraphCS: Embedding Variable-based Flow Graph for Neural Code Search,"With the rapid increase of public code repositories, developers maintain a great desire to retrieve precise code snippets by using natural language. Despite existing deep learning-based approaches that provide end-to-end solutions (i.e., accept natural language as queries and show related code fragments), the performance of code search in the large-scale repositories is still low in accuracy because of the code representation (e.g., AST) and modeling (e.g., directly fusing features in the attention stage). In this paper, we propose a novel learnable deep Graph for Code Search (called deGraphCS) to transfer source code into variable-based flow graphs based on an intermediate representation technique, which can model code semantics more precisely than directly processing the code as text or using the syntax tree representation. Furthermore, we propose a graph optimization mechanism to refine the code representation and apply an improved gated graph neural network to model variable-based flow graphs. To evaluate the effectiveness of deGraphCS, we collect a large-scale dataset from GitHub containing 41,152 code snippets written in the C language and reproduce several typical deep code search methods for comparison. The experimental results show that deGraphCS can achieve state-of-the-art performance and accurately retrieve code snippets satisfying the needs of the users.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153750091&doi=10.1145%2f3546066&partnerID=40&md5=bd8b4bfceb84f7efe993d499261fbcd2,ACM Transactions on Software Engineering and Methodology,Include,,,
Liu S.; Xie X.; Siow J.; Ma L.; Meng G.; Liu Y.,GraphSearchNet: Enhancing GNNs via Capturing Global Dependencies for Semantic Code Search,"Code search aims to retrieve accurate code snippets based on a natural language query to improve software productivity and quality. With the massive amount of available programs such as (on GitHub or Stack Overflow), identifying and localizing the precise code is critical for the software developers. In addition, Deep learning has recently been widely applied to different code-related scenarios, e.g., vulnerability detection, source code summarization. However, automated deep code search is still challenging since it requires a high-level semantic mapping between code and natural language queries. Most existing deep learning-based approaches for code search rely on the sequential text i.e., feeding the program and the query as a flat sequence of tokens to learn the program semantics while the structural information is not fully considered. Furthermore, the widely adopted Graph Neural Networks (GNNs) have proved their effectiveness in learning program semantics, however, they also suffer the problem of capturing the global dependencies in the constructed graph, which limits the model learning capacity. To address these challenges, in this paper, we design a novel neural network framework, named GraphSearchNet, to enable an effective and accurate source code search by jointly learning the rich semantics of both source code and natural language queries. Specifically, we propose to construct graphs for the source code and queries with bidirectional GGNN (BiGGNN) to capture the local structural information of the source code and queries. Furthermore, we enhance BiGGNN by utilizing the multi-head attention module to supplement the global dependencies that BiGGNN missed to improve the model learning capacity. The extensive experiments on Java and Python programming language from the public benchmark CodeSearchNet confirm that GraphSearchNet outperforms current state-of-the-art works by a significant margin.  © 1976-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147215823&doi=10.1109%2fTSE.2022.3233901&partnerID=40&md5=4f9fb5cff1da1852cf94db76ca82598e,IEEE Transactions on Software Engineering,Include,,,
Li J.; Liu F.; Zhao Y.; Li G.; Jin Z.,MCodeSearcher: Multi-View Contrastive Learning for Code Search,"Code search has been a critical software development activity in facilitating developers to retrieve a proper code snippet from open-source repositories given a user intent. In recent years, large-scale pre-trained models have shown impressive performance on code representation learning and have achieved state-of-the-art performance on code search task. However, it is challenging for these models to distinguish the functionally equivalent code snippets with dissimilar implementations or the non-equivalent code snippets that look similar. Due to the diversity of the code implementations, it is necessary for the code search engines to identify the functional similarities or dissimilarities of source code so as to return the functionally matched source code for a given query. Besides, existing pre-trained models mainly focus on learning the semantic representations of code snippets. The semantic correlation between the code snippet and natural language query is not sufficiently exploited. An effective code search tool not only needs to understand the relationship between queries and code snippets but also needs to identify the relationship between diversified code snippets. To address these limitations, we propose a novel multi-view contrastive learning model MCodeSearcher for code retrieval, aiming at sufficiently exploiting (1) the semantic correlation between queries and code snippets, and (2) the relationship between functionally equivalent code snippets. To achieve this, we design contrastive training objectives from three views and pre-train our model with these objectives. The experimental results on five representative code search datasets show that our approach significantly outperforms the state-of-the-art methods.  © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175738682&doi=10.1145%2f3609437.3609456&partnerID=40&md5=acf1ca517f251064a4222af6c3a50e87,ACM International Conference Proceeding Series,Exclude,,Include,
Ma Y.; Yu Y.; Li S.; Jia Z.; Ma J.; Xu R.; Dong W.; Liao X.,MulCS: Towards a Unified Deep Representation for Multilingual Code Search,"Code search aims to search for relevant code snippets through queries, which has become an essential requirement to assist programmers in software development. With the availability of large and rapidly growing source code repositories covering various languages, multilingual code search can leverage more training data to learn complementary information across languages. Contrastive learning can naturally understand the similarity between functionally equivalent code across different languages by narrowing the distance between objects with the same function while keeping dissimilar objects further apart. Some works exist addressing monolingual code search problems with contrastive learning, however, they mainly exploit every specific programming language's textual semantics or syntactic structures for code representation. Due to the high diversity of different languages in terms of syntax, format, and structure, these methods limit the performance of contrastive learning in multilingual training. To bridge this gap, we propose a unified semantic graph representation approach toward multilingual code search called MulCS. Specifically, we first design a general semantic graph construction strategy across different languages by Intermediate Representation (IR). Furthermore, we introduce the contrastive learning module integrated into a gated graph neural network (GGNN) to enhance query-multilingual code matching. The extensive experiments on three representative languages illustrate that our method outperforms state-of-the-art models by 10.7% to 77.5% in terms of MRR on average. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160560651&doi=10.1109%2fSANER56733.2023.00021&partnerID=40&md5=7891f2c53d03c2ddb212c471a64458da,"Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",Include,,,
Shi E.; Wang Y.; Gu W.; Du L.; Zhang H.; Han S.; Zhang D.; Sun H.,CoCoSoDa: Effective Contrastive Learning for Code Search,"Code search aims to retrieve semantically relevant code snippets for a given natural language query. Recently, many approaches employing contrastive learning have shown promising results on code representation learning and greatly improved the performance of code search. However, there is still a lot of room for improvement in using contrastive learning for code search. In this paper, we propose CoCoSoDa to effectively utilize contrastive learning for code search via two key factors in contrastive learning: data augmentation and negative samples. Specifically, soft data augmentation is to dynamically masking or replacing some tokens with their types for input sequences to generate positive samples. Momentum mechanism is used to generate large and consistent representations of negative samples in a mini-batch through maintaining a queue and a momentum encoder. In addition, multimodal contrastive learning is used to pull together representations of code-query pairs and push apart the unpaired code snippets and queries. We conduct extensive experiments to evaluate the effectiveness of our approach on a large-scale dataset with six programming languages. Experimental results show that: (1) CoCoSoDa outperforms 18 baselines and especially exceeds CodeBERT, GraphCodeBERT, and UniXcoder by 13.3%, 10.5%, and 5.9% on average MRR scores, respectively. (2) The ablation studies show the effectiveness of each component of our approach. (3) We adapt our techniques to several different pre-trained models such as RoBERTa, CodeBERT, and GraphCodeBERT and observe a significant boost in their performance in code search. (4) Our model performs robustly under different hyper-parameters. Furthermore, we perform qualitative and quantitative analyses to explore reasons behind the good performance of our model. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171576775&doi=10.1109%2fICSE48619.2023.00185&partnerID=40&md5=9d247e9ab3eb10129063e443fe4b59a7,Proceedings - International Conference on Software Engineering,Exclude,,Include,Exclude
Cai B.; Yu Y.; Hu Y.,CSSAM: Code Search via Attention Matching of Code Semantics and Structures,"Code search greatly improves developers' coding efficiency by retrieving reusable code segments with natural language queries. Despite the continuous efforts in improving both the effectiveness and efficiency of code search, two issues remained unsolved. First, programming languages have inherent strong structural linkages, and feature mining of code as text form would omit the structural information contained inside it. Second, there is a potential semantic relationship between code and query, it is challenging to align code and text across sequences so that vectors are spatially consistent during similarity matching.To tackle both issues, in this paper, a code search model named CSSAM (Code Semantics and Structures Attention Matching) is proposed. By introducing semantic and structural matching mechanisms, CSSAM effectively extracts and fuses multidimensional code features. Specifically, the cross and co-attention layer was developed to facilitate high-latitude spatial alignment of code and query at the token level. By leveraging the residual interaction, a matching module is designed to preserve more code semantics and descriptive features, which enhances the relevance between the code and its corresponding query text. Besides, to improve the model's comprehension of the code's inherent structure, a code representation structure named CSRG (Code Semantic Representation Graph) is proposed for jointly representing abstract syntax tree nodes and the data flow of the codes. According to the experimental results on two publicly available datasets containing 475k and 330k code segments, CSSAM significantly outperforms the baselines in terms of achieving the highest SR@1/5/10, MRR, and NDCG@50 on both datasets, respectively. Moreover, the ablation study is conducted to quantitatively measure the impact of each key component of CSSAM on the efficiency and effectiveness of code search, which offers insights into the improvement of advanced code search solutions. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160518672&doi=10.1109%2fSANER56733.2023.00045&partnerID=40&md5=7e48b84e94fed7f1284f7dfb216876a4,"Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",Include,,,
Bibi N.; Maqbool A.; Rana T.; Afzal F.; Akgul A.; Eldin S.M.,Enhancing Semantic Code Search With Deep Graph Matching,"The job of discovering appropriate code snippets against a natural language query is an important task for software developers. Appropriate code retrieval increases software productivity and quality as well. In contrast to traditional information retrieval techniques, code search necessitates bridging the semantic breach between programming languages and natural language to search code fragments. Deep neural networks for search codes have recently been a hot topic in research. The standard neural code quest approaches present source code and query in the form of text as independent embedding, then calculate the semantic similarity between them using vector distance (e.g., using cosine similarity). Although recent research utilized query and code snippets during code search, it overlooked the contained rich semantic information and deep structural features between them. In this study, we are also dealing with the problem of code search by providing a deep neural solution that facilitates software developers during software development. Our proposed model effectively used neural graph matching and a searching approach for semantic code retrieval. It first converts both query and code fragments in graph format and then the semantic matching module is used to facilitate the process of matching that will retrieve the best-matched code snippets. It not only exploits the enriched semantic meanings and features, but it also uses the cross-attention mechanism to learn the fine-grained similarity that exists between query and code. The proposed model's evaluation is done using the Codesearchnet dataset with six representative programming languages. It provides comparatively good results as compared to existing baselines. It enables users to find required code snippets, and ranking is used to retrieve top 10 results. The accuracy of the proposed system is approximately 97%.  © 2013 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153339400&doi=10.1109%2fACCESS.2023.3263878&partnerID=40&md5=21f77dc33aad580599fa5861d5673b96,IEEE Access,Include,,,
Shi Y.; Yin Y.; Wang Z.; Lo D.; Zhang T.; Xia X.; Zhao Y.; Xu B.,How to better utilize code graphs in semantic code search?,"Semantic code search greatly facilitates software reuse, which enables users to find code snippets highly matching user-specified natural language queries. Due to the rich expressive power of code graphs (e.g., control-flow graph and program dependency graph), both of the two mainstream research works (i.e., multi-modal models and pre-trained models) have attempted to incorporate code graphs for code modelling. However, they still have some limitations: First, there is still much room for improvement in terms of search effectiveness. Second, they have not fully considered the unique features of code graphs. In this paper, we propose a Graph-to-Sequence Converter, namely G2SC. Through converting the code graphs into lossless sequences, G2SC enables to address the problem of small graph learning using sequence feature learning and capture both the edges and nodes attribute information of code graphs. Thus, the effectiveness of code search can be greatly improved. In particular, G2SC first converts the code graph into a unique corresponding node sequence by a specific graph traversal strategy. Then, it gets a statement sequence by replacing each node with its corresponding statement. A set of carefully designed graph traversal strategies guarantee that the process is one-to-one and reversible. G2SC enables capturing rich semantic relationships (i.e., control flow, data flow, node/relationship properties) and provides learning model-friendly data transformation. It can be flexibly integrated with existing models to better utilize the code graphs. As a proof-of-concept application, we present two G2SC enabled models: GSMM (G2SC enabled multi-modal model) and GSCodeBERT (G2SC enabled CodeBERT model). Extensive experiment results on two real large-scale datasets demonstrate that GSMM and GSCodeBERT can greatly improve the state-of-the-art models MMAN and GraphCodeBERT by 92% and 22% on R@1, and 63% and 11.5% on MRR, respectively.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143074294&doi=10.1145%2f3540250.3549087&partnerID=40&md5=3fff757818bd06978797e83b1081d809,ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,Include,,Include,
Zhao W.; Liu Y.,Utilizing Edge Attention in Graph-Based Code Search,"Code search refers to searching code snippets with specific functions in a large codebase according to natural language description. Classic code search approaches, using information retrieval technologies, fail to utilize code semantics and bring noisy and irrelevant. During the last recent years, there has been an ample increase in the number of deep learning-based approaches, which embeds lexical semantics into unified vectors to achieve higher-level mapping between natural language queries and source code. However, these approaches are struggling with how to mine and utilize deep code semantics. In this work, we study how to leverage deeper source code semantics in graph-based source code search, given graph-based representation is a promising way of capturing program and has rich explainability. We propose a novel code search approach called EAGCS (Edge Attention-based Graph Code Search), which is composed of a novel code graph representation method called APDG (Advanced Program Dependence Graph) and a graph neural network called EAGGNN (Edge Attention-based GGNN) which can learn the latent code semantics of APDG. Experiment results demonstrate that our model outperforms the GGNN-based search model and DeepCS. Moreover, our comparison study shows that different edge enhancement strategies have different contributions to learning the code semantics. © 2022 Knowledge Systems Institute Graduate School. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137157657&doi=10.18293%2fSEKE2022-078&partnerID=40&md5=5a5fdb1837e9cbd46a4d24033f0e7cb9,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",Include,,,
Deng Z.; Xu L.; Liu C.; Yan M.; Xu Z.; Lei Y.,Fine-grained Co-Attentive Representation Learning for Semantic Code Search,"Code search aims to find code snippets from large-scale code repositories based on the developer's query intent. A significant challenge for code search is the semantic gap between programming language and natural language. Recent works have indicated that deep learning (DL) techniques can perform well by automatically learning the relationships between query and code. Among these DL-based approaches, the state-of-the-art model is TabCS, a two-stage attention-based model for code search. However, TabCS still has two limitations: semantic loss and semantic confusion. TabCS breaks the structural information of code into token-level words of abstract syntax tree (AST), which loses the sequential semantics between words in programming statements, and it uses a co-attention mechanism to build the semantic correlation of code-query after fusing all features, which may confuse the correlations between individual code features and query. In this paper, we propose a code search model named FcarCS (Fine-grained Co-Attentive Representation Learning Model for Semantic Code Search). FcarCS extracts code textual features (i.e., method name, API sequence, and tokens) and structural features that introduce a statement-level code structure. Unlike TabCS, FcarCS splits AST into a series of subtrees corresponding to code statements and treats each subtree as a whole to preserve sequential semantics between words in code statements. FcarCS constructs a new fine-grained co-attention mechanism to learn interdependent representations for each code feature and query, respectively, instead of performing one co-attention process for the fused code features like TabCS. Generally, this mechanism leverages row/column-wise CNN to enable our model to focus on the strongly correlated local information between code feature and Query. We train and evaluate FcarCS on an open Java dataset with 475k and 10k code/query pairs, respectively. Experimental results show that FcarCS achieves an MRR of 0.613, outperforming three state-of-the-art models DeepCS, UNIF, and TabCS, by 117.38%, 16.76%, and 12.68%, respectively. We also performed a user study for each model with 50 real-world queries, and the results show that FcarCS returned code snippets that are more relevant than the baseline models.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135793766&doi=10.1109%2fSANER53432.2022.00055&partnerID=40&md5=1795969acdea1df7b7ad47fcfce02acd,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",Include,,,
Xu L.; Yang H.; Liu C.; Shuai J.; Yan M.; Lei Y.; Xu Z.,Two-Stage Attention-Based Model for Code Search with Textual and Structural Features,"Searching and reusing existing code from a large scale codebase can largely improve developers' programming efficiency. To support code reuse, early code search models leverage information retrieval (IR) techniques to index a large-scale code corpus and return relevant code according to developers' search query. However, IR-based models fail to capture the semantics in code and query. To tackle this issue, developers applied deep learning (DL) techniques to code search models. However, these models either are too complex to determine an effective method efficiently or learning for semantic correlation between code and query inadequately.To bridge the semantic gap between code and query effectively and efficiently, we propose a code search model TabCS (Two-stage Attention-Based model for Code Search) in this study. TabCS extracts code and query information from the code textual features (i.e., method name, API sequence, and tokens), the code structural feature (i.e., abstract syntax tree), and the query feature (i.e., tokens). TabCS performs a two-stage attention net-work structure. The first stage leverages attention mechanisms to extract semantics from code and query considering their semantic gap. The second stage leverages a co-attention mechanism to capture their semantic correlation and learn better code/query representation. We evaluate the performance of TabCS on two existing large-scale datasets with 485k and 542k code snippets, respectively. Experimental results show that TabCS achieves an MRR of 0.57 on Hu et al.'s dataset, outperforming three state-of-the-art models CARLCS-CNN, DeepCS, and UNIF by 18%, 70%, 12%, respectively. Meanwhile, TabCS gains an MRR of 0.54 on Husain et al.'s, outperforming CARLCS-CNN, DeepCS, and UNIF by 32%, 76%, 29%, respectively. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106570287&doi=10.1109%2fSANER50967.2021.00039&partnerID=40&md5=a2919fe897a6c6adecf47a4796258956,"Proceedings - 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2021",Include,,,
Fang S.; Tan Y.-S.; Zhang T.; Liu Y.,Self-Attention Networks for Code Search,"Context: Developers tend to search and reuse code snippets from a large-scale codebase when they want to implement some functions that exist in the previous projects, which can enhance the efficiency of software development. Objective: As the first deep learning-based code search model, DeepCS outperforms prior models such as Sourcere and CodeHow. However, it utilizes two separate LSTM to represent code snippets and natural language descriptions respectively, which ignores semantic relations between code snippets and their descriptions. Consequently, the performance of DeepCS falls into the bottleneck, and thus our objective is to break this bottleneck. Method: We propose a self-attention joint representation learning model, named SAN-CS (Self-Attention Network for Code Search). Comparing with DeepCS, we directly utilize the self-attention network to construct our code search model. By a weighted average operation, self-attention networks can fully capture the contextual information of code snippets and their descriptions. We first utilize two individual self-attention networks to represent code snippets and their descriptions, respectively, and then we utilize the self-attention network to conduct an extra joint representation network for code snippets and their descriptions, which can build semantic relationships between code snippets and their descriptions. Therefore, SAN-CS can break the performance bottleneck of DeepCS. Results: We evaluate SAN-CS on the dataset shared by Gu et al. and choose two baseline models, DeepCS and CARLCS-CNN. Experimental results demonstrate that SAN-CS achieves significantly better performance than DeepCS and CARLCS-CNN. In addition, SAN-CS has better execution efficiency than DeepCS at the training and testing phase. Conclusion: This paper proposes a code search model, SAN-CS. It utilizes the self-attention network to perform the joint attention representations for code snippets and their descriptions, respectively. Experimental results verify the effectiveness and efficiency of SAN-CS. © 2021 Elsevier B.V.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100726176&doi=10.1016%2fj.infsof.2021.106542&partnerID=40&md5=362114e3aa6e8c9821e7f86e9b9e704a,Information and Software Technology,Exclude,,,
Bai T.; Ge Y.; Guo S.; Zhang Z.; Gong L.,Enhanced Natural Language Interface for Web-Based Information Retrieval,"Database application is at the core of most web application systems such as web-based email, source codes repository management, public scientific data repository management, news portals, and publication repository of various fields. However, the usage of these database systems for data and information retrieval is severely limited because of lacking support for processing search queries expressed in a natural language (NL). Most web interfaces for databases today only take search queries entered in some form of logical combination of keywords or text strings, which restrict the scope and depth of what a web user really wants to search for, even though natural language based data or information retrieval has made significant advances in recent years. To overcome or at least to alleviate such limitation in web information services, we propose in this article an improved neural model based on an existing framework IRNet for NL query of databases, in which a representation of Gated Graph Neural Network (GGNN) is introduced to encode the database entities and relations. We also represent and use the database values in the prediction model to identify and match table and column names for automatic synthesize a correct SQL statement from a query expressed in a NL sentence. Experiments with a public dataset demonstrates the promising potential of our approach. © 2021 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172606454&doi=10.1109%2fACCESS.2020.3048164&partnerID=40&md5=7ae63af14c18aeb686873bf2d02dcccb,IEEE Access,Exclude,,Include,Exclude
Ling X.; Wu L.; Wang S.; Pan G.; Ma T.; Xu F.; Liu A.X.; Wu C.; Ji S.,Deep Graph Matching and Searching for Semantic Code Retrieval,"Code retrieval is to find the code snippet from a large corpus of source code repositories that highly matches the query of natural language description. Recent work mainly uses natural language processing techniques to process both query texts (i.e., human natural language) and code snippets (i.e., machine programming language), however, neglecting the deep structured features of query texts and source codes, both of which contain rich semantic information. In this article, we propose an end-to-end deep graph matching and searching (DGMS) model based on graph neural networks for the task of semantic code retrieval. To this end, we first represent both natural language query texts and programming language code snippets with the unified graph-structured data, and then use the proposed graph matching and searching model to retrieve the best matching code snippet. In particular, DGMS not only captures more structural information for individual query texts or code snippets, but also learns the fine-grained similarity between them by cross-attention based semantic matching operations. We evaluate the proposed DGMS model on two public code retrieval datasets with two representative programming languages (i.e., Java and Python). Experiment results demonstrate that DGMS significantly outperforms state-of-the-art baseline models by a large margin on both datasets. Moreover, our extensive ablation studies systematically investigate and illustrate the impact of each part of DGMS. © 2021 ACM.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108944290&doi=10.1145%2f3447571&partnerID=40&md5=14c8a672080f2758dab68933fd5645df,ACM Transactions on Knowledge Discovery from Data,Include,,,
Shuai J.; Xu L.; Liu C.; Yan M.; Xia X.; Lei Y.,Improving code search with co-attentive representation learning,"Searching and reusing existing code from a large-scale codebase,e.g, GitHub, can help developers complete a programming task efficiently. Recently, Gu et al. proposed a deep learning-based model(i.e., DeepCS), which significantly outperformed prior models. TheDeepCS embedded codebase and natural language queries intovectors by two LSTM (long and short-term memory) models separately, and returned developers the code with higher similarityto a code search query. However, such embedding method learnedtwo isolated representations for code and query but ignored theirinternal semantic correlations. As a result, the learned isolated representations of code and query may limit the effectiveness of codesearch.To address the aforementioned issue, we propose a co-attentiverepresentation learning model, i.e., Co-Attentive RepresentationLearning Code Search-CNN (CARLCS-CNN). CARLCS-CNN learnsinterdependent representations for the embedded code and querywith a co-attention mechanism. Generally, such mechanism learnsa correlation matrix between embedded code and query, and coattends their semantic relationship via row/column-wise max-pooling.In this way, the semantic correlation between code and query candirectly affect their individual representations. We evaluate the effectiveness of CARLCS-CNN on Gu et al.'s dataset with 10k queries.Experimental results show that the proposed CARLCS-CNN modelsignificantly outperforms DeepCS by 26.72% in terms of MRR (meanreciprocal rank). Additionally, CARLCS-CNN is five times fasterthan DeepCS in model training and four times in testing. © 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091951300&doi=10.1145%2f3387904.3389269&partnerID=40&md5=ba7158538eb785e30119c7669a708cca,IEEE International Conference on Program Comprehension,Exclude,,,
Wan Y.; Shu J.; Sui Y.; Xu G.; Zhao Z.; Wu J.; Yu P.,Multi-modal attention network learning for semantic source code retrieval,"Code retrieval techniques and tools have been playing a key role in facilitating software developers to retrieve existing code fragments from available open-source repositories given a user query (e.g., a short natural language text describing the functionality for retrieving a particular code snippet). Despite the existing efforts in improving the effectiveness of code retrieval, there are still two main issues hindering them from being used to accurately retrieve satisfiable code fragments from large-scale repositories when answering complicated queries. First, the existing approaches only consider shallow features of source code such as method names and code tokens, but ignoring structured features such as abstract syntax trees (ASTs) and control-flow graphs (CFGs) of source code, which contains rich and well-defined semantics of source code. Second, although the deep learning-based approach performs well on the representation of source code, it lacks the explainability, making it hard to interpret the retrieval results and almost impossible to understand which features of source code contribute more to the final results. To tackle the two aforementioned issues, this paper proposes MMAN, a novel Multi-Modal Attention Network for semantic source code retrieval. A comprehensive multi-modal representation is developed for representing unstructured and structured features of source code, with one LSTM for the sequential tokens of code, a Tree-LSTM for the AST of code and a GGNN (Gated Graph Neural Network) for the CFG of code. Furthermore, a multi-modal attention fusion layer is applied to assign weights to different parts of each modality of source code and then integrate them into a single hybrid representation. Comprehensive experiments and analysis on a large-scale real-world dataset show that our proposed model can accurately retrieve code snippets and outperforms the state-of-the-art methods. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074667252&doi=10.1109%2fASE.2019.00012&partnerID=40&md5=091ed6e4921d176bf474c05372e6bc36,"Proceedings - 2019 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019",Include,,Include,
Huang Q.; Qiu A.; Zhong M.; Wang Y.,A Code-Description Representation Learning Model Based on Attention,"Code search is to retrieve source code given a query. By deep learning, the existing work embeds source code and its description into a shared vector space; however, this space is so general that each code token is associated with each description term. In this paper, we propose a code-description representation learning model (CDRL) based on attention. This model refines the general shared space into the specific one. In such space, only semantically related code tokens and description terms are associated. The experimental results show that this model could retrieve relevant source code effectively and outperform the state-of-the-art method (e.g., CODEnn and QECK) by 4-8% in terms of precision when the first query result is inspected. © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083559812&doi=10.1109%2fSANER48275.2020.9054830&partnerID=40&md5=bb178020431f2ca49e9facfd113bb893,"SANER 2020 - Proceedings of the 2020 IEEE 27th International Conference on Software Analysis, Evolution, and Reengineering",Exclude,,,
Rücklé A.; Swarnkar K.; Gurevych I.,Improved cross-lingual question retrieval for community question answering,"We perform cross-lingual question retrieval in community question answering (cQA), i.e., we retrieve similar questions for queries that are given in another language. The standard approach to cross-lingual information retrieval, which is to automatically translate the query to the target language and continue with a monolingual retrieval model, typically falls short in cQA due to translation errors. This is even more the case for specialized domains such as in technical cQA, which we explore in this work. To remedy, we propose two extensions to this approach that improve cross-lingual question retrieval: (1) we enhance an NMT model with monolingual cQA data to improve the translation quality, and (2) we improve the robustness of a state-of-the-art neural question retrieval model to common translation errors by adding back-translations during training. Our results show that we achieve substantial improvements over the baseline approach and considerably close the gap to a setup where we have access to an external commercial machine translation service (i.e., Google Translate), which is often not the case in many practical scenarios. Our source code and data is publicly available. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066906830&doi=10.1145%2f3308558.3313502&partnerID=40&md5=87403626c2c899dedbcf707cfa6c114a,"The Web Conference 2019 - Proceedings of the World Wide Web Conference, WWW 2019",Exclude,,,
Mehrotra N.; Sharma A.; Jindal A.; Purandare R.,Improving Cross-Language Code Clone Detection via Code Representation Learning and Graph Neural Networks,"Code clone detection is an important aspect of software development and maintenance. The extensive research in this domain has helped reduce the complexity and increase the robustness of source code, thereby assisting bug detection tools. However, the majority of the clone detection literature is confined to a single language. With the increasing prevalence of cross-platform applications, functionality replication across multiple languages is common, resulting in code fragments having similar functionality but belonging to different languages. Since such clones are syntactically unrelated, single language clone detection tools are not applicable in their case. In this article, we propose a semi-supervised deep learning-based tool Rubhus, capable of detecting clones across different programming languages. Rubhus uses the control and data flow enriched abstract syntax trees (ASTs) of code fragments to leverage their syntactic and structural information and then applies graph neural networks (GNNs) to extract this information for the task of clone detection. We demonstrate the effectiveness of our proposed system through experiments conducted over datasets consisting of Java, C, and Python programs and evaluate its performance in terms of precision, recall, and F1 score. Our results indicate that Rubhus outperforms the state-of-the-art cross-language clone detection tools.  © 1976-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171552856&doi=10.1109%2fTSE.2023.3311796&partnerID=40&md5=184af2dea409f1cc30a0e20bdf4e97d8,IEEE Transactions on Software Engineering,Include,,Include,
Yu D.; Yang Q.; Chen X.; Chen J.; Xu Y.,Graph-based code semantics learning for efficient semantic code clone detection,"Recent studies have shown that high-quality code semantics learning can effectively improve the performance of code clone detection. However, existing approaches suffer from two major drawbacks: (a) insufficient utilization of code representations, leading to inefficient semantics learning, and (b) low efficiency of clone detection, resulting in massive detection time. Therefore, we are motivated to propose an efficient semantics learning method while speeding up the detection process. Specifically, to address the first one, we adopt either CFG (Control Flow Graph) or PDG (Program Dependency Graph) as our initial code representation because of their rich semantic information. Further, we propose a novel graph-based code semantics learning method, which can capture critical information at token, statement, edge, and graph levels. To address the second one, we design a Siamese graph-matching network based on attention mechanisms. It can uniformly generate graph embeddings for code fragments and facilitate parallel detection of semantic clones, thus significantly boosting the speed of semantic clone detection. We evaluated our approach on two Java benchmark datasets, Google Code Jam and BigCloneBench. The experimental results show that our model outperforms the SOTA (State-Of-The-Art) lightweight models and is over 20x faster in detection. In addition, our model performs on par with the large Bert-based models and is over 110x faster in detection. Our code and dataset are available online at: https://github.com/HduDBSI/CodeGraph4CCDetector. © 2022",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144452421&doi=10.1016%2fj.infsof.2022.107130&partnerID=40&md5=6e1b8c80ca04b3a15872a41e4d6a3a30,Information and Software Technology,Include,,,
Dai L.,A study on the application of graph neural network in code clone detection: Improving the performance of code clone detection through graph neural networks and attention mechanisms,"With the increasing scale of software and the growing number of software developers, code cloning has become an important issue in software engineering. To detect code clones, this paper proposes a new method that converts source code into an Abstract Syntax Tree (AST), then adds edges from the Control Flow Graph (CFG) and Data Flow Graph (DFG) to the AST to form a graph. We then feed the graph into the Graph Matching Network (GMN) model and Pairwise Node Comparison (PNC) captures the edge and node information of the graph to calculate the graph similarity, thus converting code clone detection into a binary classification problem. Finally, experiments are conducted on the public dataset BigCloneBench, and the results show that the proposed method has high accuracy and scalability in code clone detection relative to other methods. © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169707859&doi=10.1145%2f3605801.3605834&partnerID=40&md5=c24ef0d4d173cbc93d0289bd51b243ab,ACM International Conference Proceeding Series,Include,,,
Zhang Q.; Jin D.; Wang Y.; Gong Y.,Semantic Clone Detection Based on Code Feature Fusion Learning,"Code clones are duplicated code snippets that significantly threaten software maintenance and the public corpora of code representation learning. Traditionally, code context and its structure information abstract syntax tree (AST), control flow graph (CFG) are typical representations of source code, and context-based models and structure-based models contributed significantly to the development of code clone detection. In this paper, we present a hybrid embedding model for code clone detection (HEM-CCD), a fusion method of token sequential information and graph-based structure information. We insert tokens' global context information encoded by a bi-directional recurrent neural network into the AST-based graph for comprehensive code semantic representation. Then, feeding the graph into a gated graph neural network we generate code semantic vectors for similarity evaluation. We have implemented our model on two public clone datasets (BigCloneBench and GoogleCodeJam), and the results indicate that HEM-CCD outperforms several state-of-the-art approaches.  © 2023 World Scientific Publishing Company.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165164929&doi=10.1142%2fS0218194023500249&partnerID=40&md5=0c153652b907a9e9530ec7da2ec06cf0,International Journal of Software Engineering and Knowledge Engineering,Include,,,
Wang Y.; Ye Y.; Wu Y.; Zhang W.; Xue Y.; Liu Y.,Comparison and Evaluation of Clone Detection Techniques with Different Code Representations,"As one of bad smells in code, code clones may increase the cost of software maintenance and the risk of vulnerability propagation. In the past two decades, numerous clone detection technologies have been proposed. They can be divided into text-based, token-based, tree-based, and graph-based approaches according to their code representations. Different code representations abstract the code details from different perspectives. However, it is unclear which code representation is more effective in detecting code clones and how to combine different code representations to achieve ideal performance. In this paper, we present an empirical study to compare the clone detection ability of different code representations. Specifically, we reproduce 12 clone detection algorithms and divide them into different groups according to their code representations. After analyzing the empirical results, we find that token and tree representations can perform better than graph representation when detecting simple code clones. However, when the code complexity of a code pair increases, graph representation becomes more effective. To make our findings more practical, we perform manual analysis on open-source projects to seek a possible distribution of different clone types in the open-source community. Through the results, we observe that most clone pairs belong to simple code clones. Based on this observation, we discard heavyweight graph-based clone detection algorithms and conduct combination experiments to find out a suitable combination of token-based and tree-based approaches for achieving scalable and effective code clone detection. We develop the suitable combination into a tool called TACC and evaluate it with other state-of-the-art code clone detectors. Experimental results indicate that TACC performs better and has the ability to detect large-scale code clones. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171786042&doi=10.1109%2fICSE48619.2023.00039&partnerID=40&md5=a4da879f1da06fab62ab67400787b400,Proceedings - International Conference on Software Engineering,Include,,,
Qiu S.; Wang S.; Liang Y.; Jiang W.; Zhang F.,Code Clone Detection via Software Visualization Representation Learning,"Code clone detection technology aims to automatically detect code similarity and help developers identify and reduce code duplication. While code syntax analysis-based methods are commonly used for clone detection, they may not capture semantic information due to bypassing the analysis of code text. To address this issue, this paper proposes a new method called visualization representation learning for code clone detection (VRL4CCD). This method converts source code fragments into grayscale images to preserve textual information and then utilizes VGG16 and a self-attention mechanism to extract features related to code semantic similarity. A siamese neural network is used to learn the similarity pattern between code features. Experimental results on the Big Clone Bench and Google Code Jam datasets demonstrate that VRL4CCD outperforms current clone detection methods regarding precision, recall, and F1-score, indicating the effectiveness of code visualization technology in clone detection tasks. © 2023 Knowledge Systems Institute Graduate School. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170064360&doi=10.18293%2fSEKE23-226&partnerID=40&md5=2102f145c0e46ef09e2729f0ad1d86f7,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",Exclude,,,
Fu L.; Ji S.; Liu C.; Liu P.; Duan F.; Wang Z.; Chen W.; Wang T.,Focus: Function clone identification on cross-platform,"Automatic identification of function clones on cross-platform aims at determining whether two functions are identical or not without access to the source code, which is a fundamental challenge in vulnerability search, code plagiarism detection, and malware classification. With the rapid development of deep neural network in program analysis, the state-of-the-art neural network-based function clone identification methods propose to represent functions as embeddings by graph neural network (GNN). However, such a novel representation of functions brings in two challenges. (1) The feature engineering that accurately maps the raw data of binary code to machine learning features is complicated. (2) A highly accurate embedding of functions requires a customized GNN to focus on the most critical features to identify binary code. To the best of our knowledge, currently, a comprehensive work that can overcome the above challenges is still missing. In this paper, we propose a novel prototype named as Focus, which is designed to accurately and efficiently identify similar functions. Specifically, inspired by natural language processing techniques which effectively learns text semantic across natural languages, Focus can learn representative semantic features of functions by a customized learning model. To address the second challenge, a multi-head attention mechanism can be employed to capture the critical features of a function. Through extensive experiments, we demonstrate that Focus achieves high accuracy of function clone identification on a broad range of eight architectures. In particular, the identification performance (AUC value) of Focus is 97% and 99% for cross-platform and single-platform, respectively. Furthermore, the evaluation in real world applications shows that our Focus identifies 24 vulnerable functions among the top-30 candidates, which is one time higher than the baseline approaches. © 2021 Wiley Periodicals LLC.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119834775&doi=10.1002%2fint.22752&partnerID=40&md5=0febd6744a943977c4f30e0a8729b183,International Journal of Intelligent Systems,Include,,,
Mehrotra N.; Agarwal N.; Gupta P.; Anand S.; Lo D.; Purandare R.,Modeling Functional Similarity in Source Code With Graph-Based Siamese Networks,"Code clones are duplicate code fragments that share (nearly) similar syntax or semantics. Code clone detection plays an important role in software maintenance, code refactoring, and reuse. A substantial amount of research has been conducted in the past to detect clones. A majority of these approaches use lexical and syntactic information to detect clones. However, only a few of them target semantic clones. Recently, motivated by the success of deep learning models in other fields, including natural language processing and computer vision, researchers have attempted to adopt deep learning techniques to detect code clones. These approaches use lexical information (tokens) and(or) syntactic structures like abstract syntax trees (ASTs) to detect code clones. However, they do not make sufficient use of the available structural and semantic information, hence limiting their capabilities. This paper addresses the problem of semantic code clone detection using program dependency graphs and geometric neural networks, leveraging the structured syntactic and semantic information. We have developed a prototype tool Holmes, based on our novel approach and empirically evaluated it on popular code clone benchmarks. Our results show that Holmes performs considerably better than the other state-of-the-art tool, TBCCD. We also assessed Holmes on unseen projects and performed cross dataset experiments to evaluate the generalizability of Holmes. Our results affirm that Holmes outperforms TBCCD since most of the pairs that Holmes detected were either undetected or suboptimally reported by TBCCD. © 1976-2012 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113236624&doi=10.1109%2fTSE.2021.3105556&partnerID=40&md5=23c76e79cd41b745e2448d8240e34e32,IEEE Transactions on Software Engineering,Include,,,
Hu Y.; Zou D.; Peng J.; Wu Y.; Shan J.; Jin H.,TreeCen: Building Tree Graph for Scalable Semantic Code Clone Detection,"Code clone detection is an important research problem that has attracted wide attention in software engineering. Many methods have been proposed for detecting code clone, among which text-based and token-based approaches are scalable but lack consideration of code semantics, thus resulting in the inability to detect semantic code clones. Methods based on intermediate representations of codes can solve the problem of semantic code clone detection. However, graph-based methods are not practicable due to code compilation, and existing tree-based approaches are limited by the scale of trees for scalable code clone detection. In this paper, we propose TreeCen, a scalable tree-based code clone detector, which satisfies scalability while detecting semantic clones effectively. Given the source code of a method, we first extract its abstract syntax tree (AST) based on static analysis and transform it into a simple graph representation (i.e., tree graph) according to the node type, rather than using traditional heavyweight tree matching. We then treat the tree graph as a social network and adopt centrality analysis on each node to maintain the tree details. By this, the original complex tree can be converted into a 72-dimensional vector while containing comprehensive structural information of the AST. Finally, these vectors are fed into a machine learning model to train a detector and use it to find code clones. We conduct comparative evaluations on effectiveness and scalability. The experimental results show that TreeCen maintains the best performance of the other six state-of-the-art methods (i.e., SourcererCC, RtvNN, DeepSim, SCDetector, Deckard, and ASTNN) with F1 scores of 0.99 and 0.95 on BigCloneBench and Google Code Jam datasets, respectively. In terms of scalability, TreeCen is about 79 times faster than the other state-of-the-art tree-based semantic code clone detector (ASTNN), about 13 times faster than the fastest graph-based approach (SCDetector), and even about 22 times faster than the one-time trained token-based detector (RtvNN).  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146924679&doi=10.1145%2f3551349.3556927&partnerID=40&md5=276d014d1c9463673e20d8750580700a,ACM International Conference Proceeding Series,Include,,,
Liu H.; Zhao H.; Han C.; Hou L.,Low-Complexity Code Clone Detection using Graph-based Neural Networks,"Code clone detection is of great significance for intellectual property protection and software maintenance. Deep learning has been applied in some research and achieved better performance than traditional methods. To adapt to more application scenarios and improve the detection efficiency, this paper proposes a low-complex code clone detection with the graph- based neural network. As the input of the neural network, code features are represented by abstract syntax trees (ASTs), in which the redundant edges are removed. The operation of pruning avoids interference in the message passing of the network and reduces the size of the graph. Then, the graph pairs for the code clone detection are sent into the message passing neural networks (MPNN). In addition, the gated recurrent unit (GRU) is used to learn the information between graph pairs to avoid the operation of Graph mapping. After multiple iterations, the attention mechanism is used to read out the graph vector, and the cosine similarity is calculated on the graph vector to obtain the code similarity. Through the experiments on two datasets, the results show that the proposed clone detection scheme removes about 20 % of the redundant edges and reduces 25 % of model weights, 16% of multiply-accumulate operations (MACs). In the end, the proposed method effectively reduces the training time of graph neural network while presenting a similar performance to the baseline network. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152299989&doi=10.1109%2fMSN57253.2022.00129&partnerID=40&md5=9f953d397742cd6b27e23a5711dbace7,"Proceedings - 2022 18th International Conference on Mobility, Sensing and Networking, MSN 2022",Include,,Include,
Hu B.; Wu Y.; Peng X.; Sha C.; Wang X.; Fu B.; Zhao W.,Predicting Change Propagation between Code Clone Instances by Graph-based Deep Learning,"Code clones widely exist in open-source and industrial software projects and are still recognized as a threat to software main-tenance due to the additional effort required for the simultaneous maintenance of multiple clone instances and potential defects caused by inconsistent changes in clone instances. To alleviate the threat, it is essential to accurately and efficiently make the decisions of change propagation between clone instances. Based on an exploratory study on clone change propagation with five famous open-source projects, we find that a clone class can have both propagation-required changes and propagation-free changes and thus fine-grained change propagation decision is required. Based on the findings, we propose a graph-based deep learning approach to predict the change propagation requirements of clone instances. We develop a graph representation, named Fused Clone Program Dependency Graph (FC-PDG), to capture the textual and structural code contexts of a pair of clone instances along with the changes on one of them. Based on the representation, we design a deep learning model that uses a Relational Graph Convolutional Network (R-GCN) to predict the change propagation requirement. We evaluate the approach with a dataset constructed based on 51 open-source Java projects, which includes 24,672 pairs of matched changes and 38,041 non-matched changes. The results show that the approach achieves high precision (83.1%), recall (81.2%), and F1-score (82.1%). Our further evaluation with three other open-source projects confirms the generality of the trained clone change propagation prediction model.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133200335&doi=10.1145%2f3524610.3527766&partnerID=40&md5=8c8aeedb22b2c682a2e4551b6716b887,IEEE International Conference on Program Comprehension,Include,,,
Svacina J.; Bushong V.; Das D.; Cerny T.,Semantic Code Clone Detection Method for Distributed Enterprise Systems,"Conventional approaches to code clone detection consider systems from elementary construct perspectives, making it difficult to detect semantic clones. This paper argues that semantic clone detection could be improved for enterprise systems since they typically use well-established architectures and standards. Semantic clone detection is crucial for enterprises where software’s codebase grows and evolves and maintenance costs rise significantly. While researchers have proposed many code clone detection techniques, there is a lack of solutions targeted explicitly toward enterprise systems and even fewer solutions dedicated to semantic clones. Semantic clones exhibit the same behavior between clone pairs but differ in the syntactic structure. This paper proposes a novel approach to detect semantic clones for enterprise frameworks. The driving idea is to transform a particular enterprise application into a control-flow graph representation. Next, various proprietary similarity functions are applied to compare targeted enterprise metadata for each pair of the control-flow graph fragment. As a result, we achieve to detect semantic clones with high accuracy and reasonable time complexity. Copyright © 2022 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141042331&doi=10.5220%2f0011032200003200&partnerID=40&md5=821290481147d732f9c2a421ef315ce8,"International Conference on Cloud Computing and Services Science, CLOSER - Proceedings",Exclude,,,
Shen B.; Zhang W.; Yu A.; Wei Z.; Liang G.; Zhao H.; Jin Z.,Cross-language Code Coupling Detection: A Preliminary Study on Android Applications,"Framework-based multi-lingual software is increasingly prevalent, but it also brings negative effects and extra burden on software maintenance and evolution, because of the introduced cross-language code coupling, which are usually mixed with framework-specific conventions. Researchers have proposed various approaches to code coupling detection, but there is still a lack of necessary support for cross-language coupling detection in framework-based software development. In this paper, we present a preliminary study about cross-language coupling detection in software development based on the Android application framework. We investigate the characteristics of multi-lingual changes in the top-100 starred open-source Android repositories on GitHub, and find that multi-lingual commits are non-trivial: their code changes are more scattered, and more inclined to introduce bugs than other commits. To mitigate the side-effect of multi-lingual development, we propose Grace, a Graph-based cross-language co-change suggestion approach for Android application development. Grace (a) designs a language-agnostic graph to represent code elements from different languages, and (b) employs an entity-based collaborative filtering algorithm to detect and rank candidates of cross-language code couplings, from the graph representation of the latest version as well as the historical multi-lingual commits of a repository. To evaluate the effectiveness of Grace, we apply it to the two tasks of cross-language co-change suggestion and inconsistency checking. Results show that Grace (a) can effectively suggest cross-language co-changed files and types, and (b) can also find existing and potential bugs or code smells caused by inconsistent co-changes.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123374875&doi=10.1109%2fICSME52107.2021.00040&partnerID=40&md5=02a0177e6d15d8ef3d9a05a7c074f7b7,"Proceedings - 2021 IEEE International Conference on Software Maintenance and Evolution, ICSME 2021",Exclude,,Include,
Ji X.; Liu L.; Zhu J.,Code Clone Detection with Hierarchical Attentive Graph Embedding,"Code clone serves as a typical programming manner that reuses the existing code to solve similar programming problems, which greatly facilitates software development but recurs program bugs and maintenance costs. Recently, deep learning-based detection approaches gradually present their effectiveness on feature representation and detection performance. Among them, deep learning approaches based on abstract syntax tree (AST) construct models relying on the node embedding technique. In AST, the semantic of nodes is obviously hierarchical, and the importance of nodes is quite different to determine whether the two code fragments are cloned or not. However, some approaches do not fully consider the hierarchical structure information of source code. Some approaches ignore the different importance of nodes when generating the features of source code. Thirdly, when the tree is very large and deep, many approaches are vulnerable to the gradient vanishing problem during training. In order to properly address these challenges, we propose a hierarchical attentive graph neural network embedding model-HAG for the code clone detection. Firstly, the attention mechanism is applied on nodes in AST to distinguish the importance of different nodes during the model training. In addition, the HAG adopts graph convolutional network (GCN) to propagate the code message on AST graph and then exploits a hierarchical differential pooling GCN to sufficiently capture the code semantics at different structure level. To evaluate the effectiveness of HAG, we conducted extensive experiments on public clone dataset and compared it with seven state-of-the-art clone detection models. The experimental results demonstrate that the HAG achieves superior detection performance compared with baseline models. Especially, in the detection of moderately Type-3 or Type-4 clones, the HAG particularly outperforms baselines, indicating the strong detection capability of HAG for semantic clones. Apart from that, the impacts of the hierarchical pooling, attention mechanism and critical model parameters are systematically discussed. © 2021 World Scientific Publishing Company.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108504823&doi=10.1142%2fS021819402150025X&partnerID=40&md5=3727ad1687104d345c750a459d003607,International Journal of Software Engineering and Knowledge Engineering,Include,,,
Lu Z.; Li R.; Hu H.; Zhou W.-A.,A code clone detection algorithm based on graph convolution network with AST tree edge,"Detecting code cloning will prevent it from bringing risks such as vulnerabilities and intellectual property disputes in complex software systems such as large-scale defense software systems and commercial software systems. In the field of deep code clone detection, neural networks such as Tree-CNN and Tree-LSTM, which extract features from AST (abstract syntax tree), can't collect global information of upper and lower nodes, and information can't flow globally, but graph neural network can avoid this problem. This paper presents a method of edging AST, and uses GCN (Graph Convolutional Network) and GAT(Graph Attention Networks) to extract code feature vector. Finally, the experiment is carried out on BigCloneBench data set, using several common binary classification indexes, and analyzing the time consumption, it is concluded that the effect and time efficiency of using graph neural network for code clone detection are significantly improved, especially for the code fragments with completely different semantics.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140923450&doi=10.1109%2fQRS-C55045.2021.00156&partnerID=40&md5=cdb1920d1758a453955a77a6c54f6ec9,"Proceedings - 2021 21st International Conference on Software Quality, Reliability and Security Companion, QRS-C 2021",Include,,,
Xu K.; Liu Y.,SCCD-GAN: An Enhanced Semantic Code Clone Detection Model Using GAN,"Code clone refers to a pair of semantically similar but syntactically similar or different code fragments that exist in code base. Excessive code clones in software system will cause a negative impact on system development and maintenance. In recent years, as deep learning has become a hot research area of machine learning, researchers have tried to apply deep learning techniques to code clone detection tasks. They have proposed a series of detection techniques using including unstructured (code in the form of sequential tokens) and structured (code in the form of abstract syntax trees and control-flow graphs) information to detect semantically similar but syntactically different code clone, which is the most difïîcult-to-detect clone type. However, although these methods have achieved an important improvement in the precision of semantic code clone detection, the corresponding false positive rate(FPR) is also at a very high level, making these methods unable to be effectively applied to real-world code bases. This paper proposed S C C D - G A N, an enhanced semantic code clone detection model which based on a graph representation form of programs and uses Graph Attention Network to measure the similarity of code pairs and achieved a lower detection F P R than existing methods. We built the graph representation of the code by expanding the control flow and data flow information to the original abstract syntax tree, and equipped with an attention mechanism to our model that focuses on the most important code parts and features which contribute much to the final detection precision. We implemented and evaluated our proposed method based on the benchmark dataset in the field of code clone detectionBigCloneBench2 and Google Code Jam. S C C D - G A N performed better than the existing state-of-the-art methods in terms of precision and false positive rate. ©2021 IEEE",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125205818&doi=10.1109%2fICECE54449.2021.9674552&partnerID=40&md5=f22e2f0159ad2ce1329266e99268e3e1,"2021 IEEE 4th International Conference on Electronics and Communication Engineering, ICECE 2021",Include,,Include,
Chen Z.,Semantic based Cross-Language Clone Related Bug Detection,"Code clones are widespread in software since programmers always reuse code to reduce programming effort. As programming languages are continuing to evolve and morph, code clones also widely exist across different languages for platform compatibility and adoption. Although code clones can improve development efficiency, they are prone to introducing bugs. Existing code clone detection technologies, however, mainly focused on single programming language or syntactical features of code. The syntax of different programming language are diverse because of syntax sugar, and many cloning pairs are semantic related instead of syntactic similar, such as Type 4 clones. To bridge the gap between syntax and semantic, and detect clone-related bugs more accurately, we explore an IR (Intermediate Representation) based method to represent code semantic representation information of multiple language code. We utilize graph neural network to learn code semantic representation. Through the semantic representation, we can detect more cross-language clone related bugs across multiple language.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127493196&doi=10.1109%2fAINIT54228.2021.00101&partnerID=40&md5=6ced2448716044d6fed75c1d1331ad66,"Proceedings - 2021 2nd International Seminar on Artificial Intelligence, Networking and Information Technology, AINIT 2021",Include,,,
Wu Y.; Zou D.; Dou S.; Yang S.; Yang W.; Cheng F.; Liang H.; Jin H.,SCDetector: Software Functional Clone Detection Based on Semantic Tokens Analysis,"Code clone detection is to find out code fragments with similar functionalities, which has been more and more important in software engineering. Many approaches have been proposed to detect code clones, in which token-based methods are the most scalable but cannot handle semantic clones because of the lack of consideration of program semantics. To address the issue, researchers conduct program analysis to distill the program semantics into a graph representation and detect clones by matching the graphs. However, such approaches suffer from low scalability since graph matching is typically time-consuming. In this paper, we propose SCDetector to combine the scalability of token-based methods with the accuracy of graph-based methods for software functional clone detection. Given a function source code, we first extract the control flow graph by static analysis. Instead of using traditional heavyweight graph matching, we treat the graph as a social network and apply social-network-centrality analysis to dig out the centrality of each basic block. Then we assign the centrality to each token in a basic block and sum the centrality ofthe same token in different basic blocks. By this, a graph is turned into certain tokens with graph details (i.e., centrality), called semantic tokens. Finally, these semantic tokens are fed into a Siamese architecture neural network to train a code clone detector. We evaluate SCDetector on two large datasets of functionally similar code. Experimental results indicate that our system is superior to four state-of-the-art methods (i.e., SourcererCC, Deckard, RtvNN, and ASTNN) and the time cost of SCDetector is 14 times less than a traditional graph-based method (i.e., CCSharp) on detecting semantic clones. © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099212810&doi=10.1145%2f3324884.3416562&partnerID=40&md5=7637baf6c518b1c7013ceb5c4b83a3ee,"Proceedings - 2020 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020",Include,,,
Wang W.; Li G.; Ma B.; Xia X.; Jin Z.,Detecting Code Clones with Graph Neural Network and Flow-Augmented Abstract Syntax Tree,"Code clones are semantically similar code fragments pairs that are syntactically similar or different. Detection of code clones can help to reduce the cost of software maintenance and prevent bugs. Numerous approaches of detecting code clones have been proposed previously, but most of them focus on detecting syntactic clones and do not work well on semantic clones with different syntactic features. To detect semantic clones, researchers have tried to adopt deep learning for code clone detection to automatically learn latent semantic features from data. Especially, to leverage grammar information, several approaches used abstract syntax trees (AST) as input and achieved significant progress on code clone benchmarks in various programming languages. However, these AST-based approaches still can not fully leverage the structural information of code fragments, especially semantic information such as control flow and data flow. To leverage control and data flow information, in this paper, we build a graph representation of programs called flow-augmented abstract syntax tree (FA-AST). We construct FA-AST by augmenting original ASTs with explicit control and data flow edges. Then we apply two different types of graph neural networks (GNN) on FA-AST to measure the similarity of code pairs. As far as we have concerned, we are the first to apply graph neural networks on the domain of code clone detection. We apply our FA-AST and graph neural networks on two Java datasets: Google Code Jam and BigCloneBench. Our approach outperforms the state-of-the-art approaches on both Google Code Jam and BigCloneBench tasks. © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083565137&doi=10.1109%2fSANER48275.2020.9054857&partnerID=40&md5=bf82acc679eee5776a729dba7d685a8d,"SANER 2020 - Proceedings of the 2020 IEEE 27th International Conference on Software Analysis, Evolution, and Reengineering",Include,,,
Ding S.H.H.; Fung B.C.M.; Charland P.,Asm2Vec: Boosting static representation robustness for binary clone search against code obfuscation and compiler optimization,"Reverse engineering is a manually intensive but necessary technique for understanding the inner workings of new malware, finding vulnerabilities in existing systems, and detecting patent infringements in released software. An assembly clone search engine facilitates the work of reverse engineers by identifying those duplicated or known parts. However, it is challenging to design a robust clone search engine, since there exist various compiler optimization options and code obfuscation techniques that make logically similar assembly functions appear to be very different. A practical clone search engine relies on a robust vector representation of assembly code. However, the existing clone search approaches, which rely on a manual feature engineering process to form a feature vector for an assembly function, fail to consider the relationships between features and identify those unique patterns that can statistically distinguish assembly functions. To address this problem, we propose to jointly learn the lexical semantic relationships and the vector representation of assembly functions based on assembly code. We have developed an assembly code representation learning model \emph{Asm2Vec}. It only needs assembly code as input and does not require any prior knowledge such as the correct mapping between assembly functions. It can find and incorporate rich semantic relationships among tokens appearing in assembly code. We conduct extensive experiments and benchmark the learning model with state-of-the-art static and dynamic clone search approaches. We show that the learned representation is more robust and significantly outperforms existing methods against changes introduced by obfuscation and optimizations. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063294467&doi=10.1109%2fSP.2019.00003&partnerID=40&md5=b172407cb92b6ee0ce1868cd5698c425,Proceedings - IEEE Symposium on Security and Privacy,Exclude,,,
Cai J.; Li B.; Zhang T.; Zhang J.; Sun X.,Fine-grained smart contract vulnerability detection by heterogeneous code feature learning and automated dataset construction,"Context: Recently, several deep learning based smart contract vulnerability detection approaches have been proposed. However, challenges still exist in applying deep learning for fine-grained vulnerability detection in smart contracts, including the lack of the dataset with sufficient statement-level labeled smart contract samples and neglect of heterogeneity between syntax and semantic features during code feature learning. Objective: To utilize deep learning for fine-grained smart contract vulnerability detection, we propose a security best practices (SBP) based dataset construction approach to address the scarcity of datasets. Moreover, we propose a syntax-sensitive graph neural network to address the challenge of heterogeneous code feature learning. Method: The dataset construction approach is motivated by the insight that smart contract code fragments guarded by security best practices may contain vulnerabilities in their original unguarded code form. Thus, we locate and strip security best practices from the smart contract code to recover its original vulnerable code form and perform sample labeling. Meanwhile, as the heterogeneity between tree-structured syntax features embodied inside the abstract syntax tree (AST) and graph-structured semantic features reflected by relations between statements, we propose a code graph whose nodes are each statement's AST subtree with a syntax-sensitive graph neural network that enhances the graph neural network by a child-sum tree-LSTM cell to learn these heterogeneous features for fine-grained smart contract vulnerability detection. Results: We compare our approach with three state-of-the-art deep learning-based approaches that only support contract-level vulnerability detection and two popular static analysis-based approaches that support fine detection granularity. The experiment results show that our approach outperforms the baselines at both coarse and fine granularities. Conclusion: In this paper, we propose utilizing security best practices inside the smart contract code to construct the dataset with statement-level labels. To learn both tree-structured syntax and graph-structured semantic code features, we propose a syntax-sensitive graph neural network. The experimental results show that our approach outperforms the baselines. © 2023 Elsevier Inc.",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180003952&doi=10.1016%2fj.jss.2023.111919&partnerID=40&md5=f8c6ac95fe3f1d112dae245ff2f18316,Journal of Systems and Software,Include,,,
Lin X.; Zhou M.; Cao S.; Wang J.; Sun X.,The Best of Both Worlds: Integrating Semantic Features with Expert Features for Smart Contract Vulnerability Detection,"Over the past few years, smart contract suffers from serious security threats of vulnerabilities, resulting in enormous economic losses. What’s worse, due to the immutable and irreversible features, vulnerable smart contracts which have been deployed in the the blockchain can only be detected rather than fixed. Conventional approaches heavily rely on hand-crafted vulnerability rules, which is time-consuming and difficult to cover all the cases. Recent deep learning approaches alleviate this issue but fail to explore the integration of them together to boost the smart contract vulnerability detection yet. Therefore, we propose to build a novel model, SmartFuSE, for the smart contract vulnerability detection by leveraging the best of semantic features and expert features. SmartFuSE performs static analysis to respectively extract vulnerability-specific expert patterns and joint graph structures at the function-level to frame the rich program semantics of vulnerable code, and leverages a novel graph neural network with the hybrid attention pooling layer to focus on critical vulnerability features. To evaluate the effectiveness of our proposed SmartFuSE, we conducted extensive experiments on 40k contracts in two benchmarks. The experimental results demonstrate that SmartFuSE can significantly outperform state-of-the-art analysis-based and DL-based detectors. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178561279&doi=10.1007%2f978-981-99-8104-5_2&partnerID=40&md5=f8a3114024c599eb4600438405b97f26,Communications in Computer and Information Science,Include,,,
Jin S.; Zhai Y.; Zhong Y.; Cui J.; Xu L.; Sun H.; Lei Y.,Securing Blockchain Using Propagation Chain Learning,"Smart contract vulnerabilities are the most common and severe type of blockchain vulnerability, which may result in very serious economic and property losses. Vulnerability detection and repair are necessary to ensure the security of the blockchain. Currently, the-state-of-art smart contract vulnerability detection methods (e.g. Oyente and Securify) use heuristics based on human-designed algorithms, which have certain shortcomings in different application scenarios. Therefore, this paper proposes a smart contract vulnerability detection method, i.e. CuVuD, which uses Propagation Chain Learning to solve the current vulnerability detection problem. This method first parses the source code, then obtains and trims the propagation chain of smart contracts, and finally detects vulnerabilities in smart contracts. To verify the effectiveness of CuVuD, this paper compares the CuVuD method with seven the-state-of-art smart contract vulnerability detection methods on a large-scale smart contract dataset based on the Solidity language. The experimental results show that CuVuD’s effectiveness in detecting smart contract vulnerabilities is significantly higher than seven the-state-of-art smart contract vulnerability detection methods, significantly improving the ability to detect vulnerabilities. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178555785&doi=10.1007%2f978-981-99-8101-4_8&partnerID=40&md5=d10b162261ba84eb31e50767ce0658e7,Communications in Computer and Information Science,Include,,,
Zou L.; Gong C.; Wu Z.; Tan J.; Tang J.; Jiang Z.; Li D.,A General Smart Contract Vulnerability Detection Framework with Self-attention Graph Pooling,"In recent years, the increasing development of Web 3.0 has generated growing attention toward blockchain and smart contracts. However, due to their immutability, smart contracts still exhibit various vulnerabilities that hackers can exploit, resulting in significant losses. Numerous smart contracts on various blockchains, including Ethereum, have been attacked due to various vulnerabilities. The inefficiency of detecting these vulnerabilities has become a major bottleneck in advancing blockchain and smart contracts. Although detecting smart contract vulnerabilities has attracted much attention, most existing machine learning-based methods rely on adequate expert knowledge and target only specific known vulnerabilities via binary classification models. To address this limitation, our proposed approach introduced a general vulnerability detection method that can be applied to identify various common vulnerabilities via a uniform framework. We leveraged the Abstract Syntax Trees (AST) and self-attention-based graph pooling models to generate topological graphs from smart contract code analysis. We adopted Graph Neural Networks for vulnerability detection. Experimental results demonstrated that the proposed approach exhibited satisfactory performance in detecting multiple and unseen vulnerabilities compared to traditional methods. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178549654&doi=10.1007%2f978-981-99-8104-5_1&partnerID=40&md5=8591d0a411982e39de09c9421fa30b06,Communications in Computer and Information Science,Include,,,
Gong P.; Yang W.; Wang L.; Wei F.; HaiLaTi K.; Liao Y.,GRATDet: Smart Contract Vulnerability Detector Based on Graph Representation and Transformer,"Smart contracts have led to more efficient development in finance and healthcare, but vulnerabilities in contracts pose high risks to their future applications. The current vulnerability detection methods for contracts are either based on fixed expert rules, which are inefficient, or rely on simplistic deep learning techniques that do not fully leverage contract semantic information. Therefore, there is ample room for improvement in terms of detection precision. To solve these problems, this paper proposes a vulnerability detector based on deep learning techniques, graph representation, and Transformer, called GRATDet. The method first performs swapping, insertion, and symbolization operations for contract functions, increasing the amount of small sample data. Each line of code is then treated as a basic semantic element, and information such as control and data relationships is extracted to construct a new representation in the form of a Line Graph (LG), which shows more structural features that differ from the serialized presentation of the contract. Finally, the node information and edge information of the graph are jointly learned using an improved Transformer–GP model to extract information globally and locally, and the fused features are used for vulnerability detection. The effectiveness of the method in reentrancy vulnerability detection is verified in experiments, where the F1 score reaches 95.16%, exceeding state-of-the-art methods. © 2023 Tech Science Press. All rights reserved.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173516910&doi=10.32604%2fcmc.2023.038878&partnerID=40&md5=37853fef490b5fe9dc00287a0e0e8bf6,"Computers, Materials and Continua",Include,,Include,
Liu Z.; Qian P.; Wang X.; Zhuang Y.; Qiu L.; Wang X.,Combining Graph Neural Networks with Expert Knowledge for Smart Contract Vulnerability Detection,"Smart contract vulnerability detection draws extensive attention in recent years due to the substantial losses caused by hacker attacks. Existing efforts for contract security analysis heavily rely on rigid rules defined by experts, which are labor-intensive and non-scalable. More importantly, expert-defined rules tend to be error-prone and suffer the inherent risk of being cheated by crafty attackers. Recent researches focus on the symbolic execution and formal analysis of smart contracts for vulnerability detection, yet to achieve a precise and scalable solution. Although several methods have been proposed to detect vulnerabilities in smart contracts, there is still a lack of effort that considers combining expert-defined security patterns with deep neural networks. In this paper, we explore using graph neural networks and expert knowledge for smart contract vulnerability detection. Specifically, we cast the rich control- and data- flow semantics of the source code into a contract graph. To highlight the critical nodes in the graph, we further design a node elimination phase to normalize the graph. Then, we propose a novel temporal message propagation network to extract the graph feature from the normalized graph, and combine the graph feature with designed expert patterns to yield a final detection system. Extensive experiments are conducted on all the smart contracts that have source code in Ethereum and VNT Chain platforms. Empirical results show significant accuracy improvements over the state-of-the-art methods on three types of vulnerabilities, where the detection accuracy of our method reaches 89.15, 89.02, and 83.21 percent for reentrancy, timestamp dependence, and infinite loop vulnerabilities, respectively. © 1989-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109397423&doi=10.1109%2fTKDE.2021.3095196&partnerID=40&md5=7bd04392f0c0af5571c7a03762d62919,IEEE Transactions on Knowledge and Data Engineering,Include,,,
Cai J.; Li B.; Zhangv J.; Sun X.; Chen B.,Extended Abstract of Combine Sliced Joint Graph with Graph Neural Networks for Smart Contract Vulnerability Detection,"Existing smart contract vulnerability detection efforts heavily rely on fixed rules defined by experts, which are inefficient and inflexible. To overcome the limitations of existing vulnerability detection approaches, we propose a GNN based approach. First, we construct a graph representation for a smart contract function with syntactic and semantic features by combining abstract syntax tree (AST), control flow graph (CFG), and program dependency graph (PDG). To further strengthen the presentation ability of our approach, we perform program slicing to normalize the graph and eliminate the redundant information unrelated to vulnerabilities. Then, we use a Bidirectional Gated Graph Neural-Network model with hybrid attention pooling to identify potential vulnerabilities in smart contract functions. Experiment results show that our approach can achieve 89.2% precision and 92.9% recall in smart contract vulnerability detection on our dataset and reveal the effectiveness and efficiency of our approach. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160566114&doi=10.1109%2fSANER56733.2023.00101&partnerID=40&md5=c0e6c95589b1dd3c88aca141cf69d969,"Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",Include,,,
Nguyen H.H.; Nguyen N.-M.; Xie C.; Ahmadi Z.; Kudendo D.; Doan T.-N.; Jiang L.,MANDO-HGT: Heterogeneous Graph Transformers for Smart Contract Vulnerability Detection,"Smart contracts in blockchains have been increasingly used for high-value business applications. It is essential to check smart contracts' reliability before and after deployment. Although various program analysis and deep learning techniques have been proposed to detect vulnerabilities in either Ethereum smart contract source code or bytecode, their detection accuracy and scalability are still limited. This paper presents a novel framework named MANDO-HGT for detecting smart contract vulnerabilities. Given Ethereum smart contracts, either in source code or bytecode form, and vulnerable or clean, MANDO-HGT custom-builds heterogeneous contract graphs (HCGs) to represent control-flow and/or function-call information of the code. It then adapts heterogeneous graph transformers (HGTs) with customized meta relations for graph nodes and edges to learn their embeddings and train classifiers for detecting various vulnerability types in the nodes and graphs of the contracts more accurately. We have collected more than 55K Ethereum smart contracts from various data sources and verified the labels for 423 buggy and 2,742 clean contracts to evaluate MANDO-HGT. Our empirical results show that MANDO-HGT can significantly improve the detection accuracy of other state-of-the-art vulnerability detection techniques that are based on either machine learning or conventional analysis techniques. The accuracy improvements in terms of F1-score range from 0.7% to more than 76% at either the coarse-grained contract level or the fine-grained line level for various vulnerability types in either source code or bytecode. Our method is general and can be retrained easily for different vulnerability types without the need for manually defined vulnerability patterns.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166351291&doi=10.1109%2fMSR59073.2023.00052&partnerID=40&md5=f758ad7d33f8d0cc7ac1d0b7bb8e088c,"Proceedings - 2023 IEEE/ACM 20th International Conference on Mining Software Repositories, MSR 2023",Include,,Include,
Zhang Y.; Liu D.,Toward Vulnerability Detection for Ethereum Smart Contracts Using Graph-Matching Network,"With the blooming of blockchain-based smart contracts in decentralized applications, the security problem of smart contracts has become a critical issue, as vulnerable contracts have resulted in severe financial losses. Existing research works have explored vulnerability detection methods based on fuzzing, symbolic execution, formal verification, and static analysis. In this paper, we propose two static analysis approaches called ASGVulDetector and BASGVulDetector for detecting vulnerabilities in Ethereum smart contacts from source-code and bytecode perspectives, respectively. First, we design a novel intermediate representation called abstract semantic graph (ASG) to capture both syntactic and semantic features from the program. ASG is based on syntax information but enriched by code structures, such as control flow and data flow. Then, we apply two different training models, i.e., graph neural network (GNN) and graph matching network (GMN), to learn the embedding of ASG and measure the similarity of the contract pairs. In this way, vulnerable smart contracts can be identified by calculating the similarity to labeled ones. We conduct extensive experiments to evaluate the superiority of our approaches to state-of-the-art competitors. Specifically, ASGVulDetector improves the best of three source-code-only static analysis tools (i.e., SmartCheck, Slither, and DR-GCN) regarding the F1 score by 12.6% on average, while BASGVulDetector improves that of the three detection tools supporting bytecode (i.e., ContractFuzzer, Oyente, and Securify) regarding the F1 score by 25.6% on average. We also investigate the effectiveness and advantages of the GMN model for detecting vulnerabilities in smart contracts. © 2022 by the authors.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147411558&doi=10.3390%2ffi14110326&partnerID=40&md5=6170681772b53722d0bebb4332e655c7,Future Internet,Include,,Include,
Cai J.; Li B.; Zhang J.; Sun X.; Chen B.,Combine sliced joint graph with graph neural networks for smart contract vulnerability detection,"Smart contract security has drawn extensive attention in recent years because of the enormous economic losses caused by vulnerabilities. Even worse, fixing bugs in a deployed smart contract is difficult, so developers must detect security vulnerabilities in a smart contract before deployment. Existing smart contract vulnerability detection efforts heavily rely on fixed rules defined by experts, which are inefficient and inflexible. To overcome the limitations of existing vulnerability detection approaches, we propose a GNN based approach for smart contract vulnerability detection. First, we construct a graph representation for a smart contract function with syntactic and semantic features by combining abstract syntax tree (AST), control flow graph (CFG), and program dependency graph (PDG). To further strengthen the presentation ability of our approach, we perform program slicing to normalize the graph and eliminate the redundant information unrelated to vulnerabilities. Then, we use a Bidirectional Gated Graph Neural-Network model with hybrid attention pooling to identify potential vulnerabilities in smart contract functions. Empirical results show that our approach can achieve 89.2% precision and 92.9% recall in smart contract vulnerability detection on our dataset and reveal the effectiveness and efficiency of our approach. © 2022 Elsevier Inc.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141321797&doi=10.1016%2fj.jss.2022.111550&partnerID=40&md5=71e722ea23da022d024f0445104f170d,Journal of Systems and Software,Include,,Include,
Han D.; Li Q.; Zhang L.; Xu T.,A Smart Contract Vulnerability Detection Model Based on Syntactic and Semantic Fusion Learning,"As a trusted decentralized application, smart contracts manage a large number of digital assets on the blockchain. Vulnerability detection of smart contracts is an important part of ensuring the security of digital assets. At present, many researchers extract features of smart contract source code for vulnerability detection based on deep learning methods. However, the current research mainly focuses on the single representation form of the source code, which cannot fully obtain the rich semantic and structural information contained in the source code, so it is not conducive to the detection of various and complex smart contract vulnerabilities. Aiming at this problem, this paper proposes a vulnerability detection model based on the fusion of syntax and semantic features. The syntactic and semantic representation of the source code is obtained from the abstract syntax tree and control flow graph of the smart contract through TextCNN and Graph Neural Network. The syntactic and semantic features are fused, and the fused features are used to detect vulnerabilities. Experiments show that the detection accuracy and recall rate of this model have been improved on the detection tasks of five types of vulnerabilities, with an average precision of 96% and a recall rate of 90%, which can effectively identify smart contract vulnerabilities.  © 2023 Daojun Han et al.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148101619&doi=10.1155%2f2023%2f9212269&partnerID=40&md5=4adcc873283819266ee40faf9bb4c941,Wireless Communications and Mobile Computing,Include,,,
Nguyen H.H.; Nguyen N.-M.; Doan H.-P.; Ahmadi Z.; Doan T.-N.; Jiang L.,MANDO-GURU: vulnerability detection for smart contract source code by heterogeneous graph embeddings,"Smart contracts are increasingly used with blockchain systems for high-value applications. It is highly desired to ensure the quality of smart contract source code before they are deployed. This paper proposes a new deep learning-based tool, MANDO-GURU, that aims to accurately detect vulnerabilities in smart contracts at both coarse-grained contract-level and fine-grained line-level. Using a combination of control-flow graphs and call graphs of Solidity code, we design new heterogeneous graph attention neural networks to encode more structural and potentially semantic relations among different types of nodes and edges of such graphs and use the encoded embeddings of the graphs and nodes to detect vulnerabilities. Our validation of real-world smart contract datasets shows that MANDO-GURU can significantly improve many other vulnerability detection techniques by up to 24% in terms of the F1-score at the contract level, depending on vulnerability types. It is the first learning-based tool for Ethereum smart contracts that identify vulnerabilities at the line level and significantly improves the traditional code analysis-based techniques by up to 63.4%. Our tool is publicly available at https://github.com/MANDO-Project/ge-sc-machine. A test version is currently deployed at http://mandoguru.com, and a demo video of our tool is available at http://mandoguru.com/demo-video.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143053694&doi=10.1145%2f3540250.3558927&partnerID=40&md5=3c64b411740bd09da4dabb3f6a448a86,ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,Include,,Include,
Han D.; Li Q.; Zhang L.; Xu T.,A smart contract vulnerability detection model based on graph neural networks,"In recent years, smart contract vulnerability detection methods mostly view smart contract source code as natural language for processing, which cannot fully capture the semantic and structural features of the source code and has a high rate of false positives and missing positives. To improve the accuracy of vulnerability detection, this paper uses Graph Neural Network to obtain the semantic and structural information of the source code and Convolutional Neural Network to assist learning. We propose a graph neural network-based vulnerability detection model for smart contracts, which transforms smart contracts into control flow graphs, learns graph embedding using graph neural networks, and introduces Convolutional Neural Networks to learn the node order information of control flow graphs, and finally performs vulnerability detection using graph embedding and node order information. Experimenting on real datasets, our accuracy and F1 values are improved and the model can effectively detect smart contract vulnerabilities.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152192949&doi=10.1109%2fICFTIC57696.2022.10075325&partnerID=40&md5=f0465ad00d8a06b470ad570a20b799cc,"2022 4th International Conference on Frontiers Technology of Information and Computer, ICFTIC 2022",Include,,Include,
Yang S.; Gu X.; Shen B.,Self-Supervised Learning of Smart Contract Representations,"Learning smart contract representations can greatly facilitate the development of smart contracts in many tasks such as bug detection and clone detection. Existing approaches for learning program representations are difficult to apply to smart contracts which have insufficient data and significant homogenization. To overcome these challenges, in this paper, we propose SRCL, a novel, self-supervised approach for learning smart contract representations. Unlike ex-isting supervised methods, which are tied on task-specific data labels, SRCL leverages large-scale unlabeled data by self-supervised learning of both local and global information of smart contracts. It automatically extracts structural sequences from abstract syntax trees (ASTs). Then, two discriminators are designed to guide the Transformer encoder to learn local and global semantic features of smart contracts. We evaluate SRCL on a dataset of 75,006 smart contracts collected from Etherscan. Experimental results show that SRCL considerably outperforms the state-of-the-art code represen-tation models on three downstream tasks.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133158808&doi=10.1145%2f3524610.3527894&partnerID=40&md5=8ca8720f70660086fafd22863769106d,IEEE International Conference on Program Comprehension,Include,,,
Deng L.; Wen H.; Xin M.; Li H.; Pan Z.; Sun L.,ENIMANAL: Augmented cross-architecture IoT malware analysis using graph neural networks,"IoT malware analysis is crucial for understanding the behavior and purpose of malware samples. While deep learning methods have been applied to IoT malware analysis using sequences or graphs to represent system calls, these approaches have limitations in their semantic representation of system call names. This paper presents ENIMANAL, a novel cross-architecture IoT malware analysis method based on graph neural networks. ENIMANAL leverages information from the Linux Programmer Manual to improve the semantic representation of dynamic system call information. By fusing semantic and structural information, ENIMANAL constructs a unique feature representation called an attributed system call graph (ASCG). We evaluated ENIMANAL on a dataset of 63k IoT malware samples with 9 CPU architectures and find that it outperforms comparison methods by up to 46% in macro precision and 38% in macro recall, achieving macro precision, macro recall and macro f1-score of over 98%. Furthermore, we verify the robustness of ENIMANAL against “zero-day” IoT malware. © 2023 Elsevier Ltd",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163515435&doi=10.1016%2fj.cose.2023.103323&partnerID=40&md5=1260fc55684f4aa7a58e370bf97d3222,Computers and Security,Include,,,
Liu Z.; Wang R.; Japkowicz N.; Gomes H.M.; Peng B.; Zhang W.,SeGDroid: An Android malware detection method based on sensitive function call graph learning[Formula presented],"Malware is still a challenging security problem in the Android ecosystem, as malware is often obfuscated to evade detection. In such case, semantic behavior feature extraction is crucial for training a robust malware detection model. In this paper, we propose a novel Android malware detection method (named SeGDroid) that focuses on learning the semantic knowledge from sensitive function call graphs (FCGs). Specifically, we devise a graph pruning method to build a sensitive FCG on the base of an original FCG. The method preserves the sensitive API (security-related API) call context and removes the irrelevant nodes of FCGs. We propose a node representation method based on word2vec and social-network-based centrality to extract attributes for graph nodes. Our representation aims at extracting the semantic knowledge of the function calls and the structure of graphs. Using this representation, we induce graph embeddings of the sensitive FCGs associated with node attributes using a graph convolutional neural network algorithm. To provide a model explanation, we further propose a method that calculates node importance. This creates a mechanism for understanding malicious behavior. The experimental results show that SeGDroid achieves an F-score of 98% in the case of malware detection on the CICMal2020 dataset and an F-score of 96% in the case of malware family classification on the MalRadar dataset. In addition, the provided model explanation is able to trace the malicious behavior of the Android malware. © 2023 Elsevier Ltd",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168809141&doi=10.1016%2fj.eswa.2023.121125&partnerID=40&md5=c539c69ac6fae152726153ca36eb0105,Expert Systems with Applications,Include,,,
Wu H.; Luktarhan N.; Tian G.; Song Y.,An Android Malware Detection Approach to Enhance Node Feature Differences in a Function Call Graph Based on GCNs,"The smartphone has become an indispensable tool in our daily lives, and the Android operating system is widely installed on our smartphones. This makes Android smartphones a prime target for malware. In order to address threats posed by malware, many researchers have proposed different malware detection approaches, including using a function call graph (FCG). Although an FCG can capture the complete call–callee semantic relationship of a function, it will be represented as a huge graph structure. The presence of many nonsensical nodes affects the detection efficiency. At the same time, the characteristics of the graph neural networks (GNNs) make the important node features in the FCG tend toward similar nonsensical node features during the propagation process. In our work, we propose an Android malware detection approach to enhance node feature differences in an FCG. Firstly, we propose an API-based node feature by which we can visually analyze the behavioral properties of different functions in the app and determine whether their behavior is benign or malicious. Then, we extract the FCG and the features of each function from the decompiled APK file. Next, we calculate the API coefficient inspired by the idea of the TF–IDF algorithm and extract the sensitive function called subgraph (S-FCSG) based on API coefficient ranking. Finally, before feeding the S-FCSG and node features into the GCN model, we add the self-loop for each node of the S-FCSG. A 1-D convolutional neural network and fully connected layers are used for further feature extraction and classification, respectively. The experimental result shows that our approach enhances the node feature differences in an FCG, and the detection accuracy is greater than that of models using other features, suggesting that malware detection based on a graph structure and GNNs has a lot of space for future study. © 2023 by the authors.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160444990&doi=10.3390%2fs23104729&partnerID=40&md5=f7b434d3d80a359e530ff86feacaa673,Sensors,Include,,,
Miao H.; Bao H.; Tang Z.; Li W.; Wang W.; Chen H.; Liu F.; Sun Y.,AST2Vec: A Robust Neural Code Representation for Malicious PowerShell Detection,"In recent years, PowerShell has become a commonly used carrier to wage cyber attacks. As a script, PowerShell is easy to obfuscate to evade detection. Thus, they are difficult to detect directly using traditional anti-virus software. Existing advanced detection methods generally recover obfuscated scripts before detection. However, most deobfuscation tools can not achieve precise recovery on obfuscated scripts due to emerging obfuscation techniques. To solve the problem, we propose a robust neural code representation method, namely AST2Vec, to detect malicious PowerShell without de-obfuscating scripts. 6 Abstract Syntax Tree (AST) recovery-related statement nodes are defined to identify obfuscated subtrees. Then AST2Vec splits the large AST of entire PowerShell scripts into a set of small subtrees rooted by these 6 types of nodes and performs tree-based neural embeddings on all extracted subtrees by capturing lexical and syntactical knowledge of statement nodes. Based on the sequence of statement vectors, a bidirectional recursive neural network (Bi-RNN) is modeled to leverage the context of statements and finally produce vector representation of scripts. We evaluate the proposed method for malicious PowerShell detection through extensive experiments. Experimental results indicate that our model outperforms the state-of-the-art approaches. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178514641&doi=10.1007%2f978-3-031-45933-7_13&partnerID=40&md5=4494d55ff52abdbd18f1100ae2f6fd97,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,,
Rozi M.F.; Ban T.; Ozawa S.; Yamada A.; Takahashi T.; Kim S.; Inoue D.,Detecting Malicious JavaScript Using Structure-Based Analysis of Graph Representation,"Malicious JavaScript code in web applications poses a significant threat as cyber attackers exploit it to perform various malicious activities. Detecting these malicious scripts is challenging, given their diverse nature and the continuous evolution of attack techniques. Most approaches formulate this task as a static or sequential feature of the script, which is insufficient in terms of flexibility to various attack techniques and the ability to capture the script's semantic meaning. To address this issue, we propose an alternative approach that leverages JavaScript code's abstract syntax tree (AST) representation, focusing on distinctive syntactic structure features. The proposed approach uses graph neural networks to extract structural features from the AST graph while considering the attribute features of individual nodes, which uses neural message passing with neighborhood aggregation. The proposed method encodes both the local AST graph structure and attributes of the nodes. It enables capturing the source code's semantic meaning and exploits the signature structure in the AST representations. The proposed method consistently achieved high detection performance in extensive experiments on two different datasets, with accuracy scores of 99.4% and 96.92%. The obtained evaluation metrics demonstrate the effectiveness of our approach in accurately detecting malicious JavaScript code, with our proposed method successfully detecting more than 81% for various attack types and achieving an almost twofold performance improvement on JS-Droppers compared to the sequence-based approach. In addition, we observed that the AST graph structure represented the code's semantic meaning, exhibiting distinctive patterns and signatures that could be effectively captured using the proposed method.  © 2013 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172989806&doi=10.1109%2fACCESS.2023.3317266&partnerID=40&md5=bbd56b60ec2e4b7191116403b187c21e,IEEE Access,Include,,,
Zhao C.; Zhang Z.; Wu T.; Fan D.,A Multi-view Graph Learning Approach for Host-Based Malicious Behavior Detection,"Due to the continuous evolution of malware, host-based malicious behavior detection is urgently needed in cyber security. An increasing amount of research is focused on developing techniques to detect host-based malicious behavior using rule engines and machine learning methods. However, current detection approaches concentrate on the specific or sequential features of malicious behaviors. Those methods ignore the internal information of an attack and structural information between multiple attacks. So it is difficult to detect malicious behaviors on the host comprehensively. To address the problem, we present MVGD, an approach for detecting malicious behavior using a multi-view graph learning method using audit logs. The multi-view information of the graph includes structural information, path information, and event-type information. Firstly, we construct a host-based behavior dependency graph, which describes the dependencies among processes, files, registries, etc. on the host. Then, in order to maintain the causality of a single attack path, a deepwalk technique is applied to capture sequential information. Next, the structural information of malicious behaviors is extracted using graph neural networks to describe the correlation between multiple attack paths. Finally, malicious behaviors can be detected by the combination of the structural, path, and event information. Experiments over three datasets indicate that MVGD achieves state-of-the-art performance. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174521761&doi=10.1007%2f978-3-031-35415-1_20&partnerID=40&md5=5925967b80bdade752d8c4d49a591df7,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Zhu J.; Yao Y.; Deng X.; Yong Y.; Wang Y.; Chen L.; Xue Z.; Zhao R.,SAWD: Structural-Aware Webshell Detection System with Control Flow Graph,"With the increasing prevalence of web servers, protecting them from cyber attacks has become a crucial task for online service providers. Webshells, which are backdoors to websites, are commonly used by hackers to gain unauthorized access to web servers. However, traditional methods for detecting webshells often fail to produce satisfactory results due to the use of obfuscation or encryption to conceal their characteristics. In recent years, webshell detection methods based on deep learning (DL) have received significant attention, but they struggle to preserve the syntax and semantic information contained in the source code. In this paper, we propose a structural-aware webshell detection system to address these problems, denoted as SAWD. Specifically, we first generate the control flow graph (CFG) with syntax and semantic information from the PHP source code. Then, we leverage CFG to build our graph representation, which consists of the adjacency matrix and keywords-based basic block features. Finally, based on our graph representation, we adopt convolutional neural networks (GCN) combined with graph pooling to detect webshells more efficiently. Experimental results demonstrate that our method outperforms state-of-the-art webshell detection systems on the collected dataset. © 2023 Knowledge Systems Institute Graduate School. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170088196&doi=10.18293%2fSEKE2023-205&partnerID=40&md5=17552b54f84adbc66130e38cb0079c34,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",Include,,Include,
Malhotra V.; Potika K.; Stamp M.,A comparison of graph neural networks for malware classification,"Managing the threat posed by malware requires accurate detection and classification techniques. Traditional detection strategies, such as signature scanning, rely on manual analysis of malware to extract relevant features, which is labor intensive and requires expert knowledge. Function call graphs consist of a set of program functions and their inter-procedural calls, providing a rich source of information that can be leveraged to classify malware without the labor intensive feature extraction step of traditional techniques. In this research, we treat malware classification as a graph classification problem. Based on Local Degree Profile features, we train a wide range of Graph Neural Network (GNN) architectures to generate embeddings which we then classify. We find that our best GNN models outperform previous comparable research involving the well-known MalNet-Tiny Android malware dataset. In addition, our GNN models do not suffer from the overfitting issues that commonly afflict non-GNN techniques, although GNN models require longer training times. © 2023, The Author(s), under exclusive licence to Springer-Verlag France SAS, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165906021&doi=10.1007%2fs11416-023-00493-y&partnerID=40&md5=1daf672a23b8d2e77b4834eb80e8f981,Journal of Computer Virology and Hacking Techniques,Include,,,
Li Y.; Hu Y.; Wang Y.; He Y.; Lu H.; Gu D.,RGDroid: Detecting Android Malware with Graph Convolutional Networks against Structural Attacks,"The rapid growth of Android malware calls for anti-malware systems to detect malware automatically. Detecting malware effectively is a non-trivial problem due to the high overlap in behaviors between malware and benign apps. Most existing automated Android malware detection methods use statistic features extracted from apps or graphs generated from method calls to identify malware. However, the methods that only use statistic features lead to false positives due to ignoring program semantics. Existing graph-based approaches suffer scalability problems due to the heavy-weight program analysis and time-consuming graph matching. In addition, graph-based approaches could be evaded by modifying dependencies among method calls. As a result, crafted malicious apps resemble the benign ones.In this paper, we propose a novel deep learning-based detection system, named RGDroid, which is capable of detecting malware under graph structural attacks. It combines API information extracted from Android document and learns behavior features from function call graph by graph neural network. Specifically, to defend against graph adversarial attacks, RGDroid reduces the connectivity of different functional parts to mitigate the effect of structural modifications on the final graph embedding. To comprehensively evaluate the robustness of RGDroid, we implement four influential graph adversarial attacks to simulate current capabilities and knowledge of Android malware attackers. The attack success rate (ASR) of two state-of-the-art detection systems (i.e., MaMaDroid, MalScan) is above 70.0% while the ASR of RGDroid under the four graph attacks is below 6.1%. © 2023 IEEE.2",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160579246&doi=10.1109%2fSANER56733.2023.00065&partnerID=40&md5=ba23602805ffb5cbb8ea038f76b4a395,"Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",Include,,,
Fang Y.; Huang C.; Zeng M.; Zhao Z.; Huang C.,JStrong: Malicious JavaScript detection based on code semantic representation and graph neural network,"Web development technology has experienced significant progress. The creation of JavaScript has highly enriched the interactive ability of the client. However, the attacker uses the dynamic characteristics of the JavaScript language to embed malicious code into web pages to achieve the purpose of smuggling, redirection, and so on. Traditional methods based on static feature detection are therefore difficult to detect malicious code after confusion, and the method based on dynamic analysis is inefficient. To meet these challenges, this paper proposes a static detection model JStrong based on graph neural network. The model first generates an abstract syntax tree from the JavaScript source code, and then adds data flow and control flow information into the program dependency graph. In addition, we embed the nodes and edges of the graph into the feature vector and fully learn the features of the whole graph through the graph neural network. We take advantage of a real-world dataset collected from the top website and GitHub to evaluate JStrong and compare it to the state-of-the-art method. Experimental results show that JStrong achieves near-perfect classification performance and is superior to the state-of-the-art method. © 2022 Elsevier Ltd",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128369219&doi=10.1016%2fj.cose.2022.102715&partnerID=40&md5=4f6874e954626fa4d1fe9d83d50e7502,Computers and Security,Include,,,
Jiang C.; Yin K.; Xia C.; Huang W.,FedHGCDroid: An Adaptive Multi-Dimensional Federated Learning for Privacy-Preserving Android Malware Classification,"With the popularity of Android and its open source, the Android platform has become an attractive target for hackers, and the detection and classification of malware has become a research hotspot. Existing malware classification methods rely on complex manual operation or large-volume high-quality training data. However, malware data collected by security providers contains user privacy information, such as user identity and behavior habit information. The increasing concern for user privacy poses a challenge to the current malware classification scheme. Based on this problem, we propose a new android malware classification scheme based on Federated learning, named FedHGCDroid, which classifies malware on Android clients in a privacy-protected manner. Firstly, we use a convolutional neural network and graph neural network to design a novel multi-dimensional malware classification model HGCDroid, which can effectively extract malicious behavior features to classify the malware accurately. Secondly, we introduce an FL framework to enable distributed Android clients to collaboratively train a comprehensive Android malware classification model in a privacy-preserving way. Finally, to adapt to the non-IID distribution of malware on Android clients, we propose a contribution degree-based adaptive classifier training mechanism FedAdapt to improve the adaptability of the malware classifier based on Federated learning. Comprehensive experimental studies on the Androzoo dataset (under different non-IID data settings) show that the FedHGCDroid achieves more adaptability and higher accuracy than the other state-of-the-art methods. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133730316&doi=10.3390%2fe24070919&partnerID=40&md5=8d8a25388d51d5e08cfc934e0d266e62,Entropy,Include,,Include,
Li C.; Cheng Z.; Zhu H.; Wang L.; Lv Q.; Wang Y.; Li N.; Sun D.,DMalNet: Dynamic malware analysis based on API feature engineering and graph learning,"Application Programming Interfaces (APIs) are widely considered a useful data source for dynamic malware analysis to understand the behavioral characteristics of malware. However, the accuracy of API-based malware analysis is limited for two reasons. (1) Existing solutions often only consider the API names while ignoring the API arguments, or cannot fully exploit the semantic information from different types of arguments. (2) The relationship between API calls is important to describe the software behavior but is difficult to capture. To overcome the above limitations, we propose DMalNet, a novel malware analysis framework for accurate malware detection and classification. Specifically, we first present a hybrid feature encoder to extract semantic features from API names and arguments. Then, we derive an API call graph from the API call sequence to convert the relationship between API calls into the structural information of the graph. Finally, we design a graph neural network to implement the malware detection and type classification. To evaluate our approach, we use datasets of over 20k benign and 18k malicious samples belonging to 8 malware types. DMalNet achieves 98.43% and 91.42% accuracy on malware detection and malware type classification, respectively. We also conduct ablation studies to assess the impact of API feature engineering and the graph learning model. Further experiments show that DMalNet can effectively detect malware. © 2022 Elsevier Ltd",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136149274&doi=10.1016%2fj.cose.2022.102872&partnerID=40&md5=9056ce3e9edb18fd359f92bc3fd2658f,Computers and Security,Exclude,,,
Deldar F.; Abadi M.; Ebrahimifard M.,Android Malware Detection Using One-Class Graph Neural Networks,"With the widespread use of Android smartphones, the Android platform has become an attractive target for cybersecurity attackers and malware authors. Meanwhile, the growing emergence of zero-day malware has long been a major concern for cybersecurity researchers. This is because malware that has not been seen before often exhibits new or unknown behaviors, and there is no documented defense against it. In recent years, deep learning has become the dominant machine learning technique for malware detection and could achieve outstanding achievements. Currently, most deep malware detection techniques are supervised in nature and require training on large datasets of benign and malicious samples. However, supervised techniques usually do not perform well against zero-day malware. Semi-supervised and unsupervised deep malware detection techniques have more potential to detect previously unseen malware. In this paper, we present MalGAE, a novel end-to-end deep malware detection technique that leverages one-class graph neural networks to detect Android malware in a semi-supervised manner. MalGAE represents each Android application with an attributed function call graph (AFCG) to benefit the ability of graphs to model complex relationships between data. It builds a deep one-class classifier by training a stacked graph autoencoder with graph convolutional layers on benign AFCGs. Experimental results show that MalGAE can achieve good detection performance in terms of different evaluation measures. © 2022 ISC. All rights reserved.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154031860&doi=10.22042%2fisecure.2022.14.3.6&partnerID=40&md5=0d4621b971c75ae4eb9acdb2e0fe27ff,ISeCure,Include,,,
Wu Y.; Shi J.; Wang P.; Zeng D.; Sun C.,DeepCatra: Learning flow- and graph-based behaviours for Android malware detection,"As Android malware grows and evolves, deep learning has been introduced into malware detection, resulting in great effectiveness. Recent work is considering hybrid models and multi-view learning. However, they use only simple features, limiting the accuracy of these approaches in practice. This study proposes DeepCatra, a multi-view learning approach for Android malware detection, whose model consists of a bidirectional LSTM (BiLSTM) and a graph neural network (GNN) as subnets. The two subnets rely on features extracted from statically computed call traces leading to critical APIs derived from public vulnerabilities. For each Android app, DeepCatra first constructs its call graph and computes call traces reaching critical APIs. Then, temporal opcode features used by the BiLSTM subnet are extracted from the call traces, while flow graph features used by the GNN subnet are constructed from all call traces and inter-component communications. We evaluate the effectiveness of DeepCatra by comparing it with several state-of-the-art detection approaches. Experimental results on over 18,000 real-world apps and prevalent malware show that DeepCatra achieves considerable improvement, for example, 2.7%–14.6% on the F1 measure, which demonstrates the feasibility of DeepCatra in practice. © 2022 The Authors. IET Information Security published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135527542&doi=10.1049%2fise2.12082&partnerID=40&md5=3152147b39ea8e4972c073be9c38a31e,IET Information Security,Include,,Include,
Lu X.; Zhao J.; Lio P.,Robust android malware detection based on subgraph network and denoising GCN network,"This paper proposes an Android malware detection model based on Android Function Call Graph (FCG) and Denoising Graph Convolutional Neural Network. This study proposes a method to simplify the FCG to reduce its size, and a new method to construct vertex feature vectors. The model uses the subgraph network to detect the underlying structural features of the FCG and discover the confusion attack. A denoising graph neural network is applied to graph convolution to reduce the impact of obfuscation attacks. © 2022 Owner/Author.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134028889&doi=10.1145%2f3498361.3538778&partnerID=40&md5=bf14b2e8235d432e08c872c73c27b69e,"MobiSys 2022 - Proceedings of the 2022 20th Annual International Conference on Mobile Systems, Applications and Services",Include,,,
Ebrahimi M.; Chai Y.; Samtani S.; Chen H.,CROSS-LINGUAL CYBERSECURITY ANALYTICS IN THE INTERNATIONAL DARK WEB WITH ADVERSARIAL DEEP REPRESENTATION LEARNING1,"International dark web platforms operating within multiple geopolitical regions and languages host a myriad of hacker assets such as malware, hacking tools, hacking tutorials, and malicious source code. Cybersecurity analytics organizations employ machine learning models trained on human-labeled data to automatically detect these assets and bolster their situational awareness. However, the lack of human-labeled training data is prohibitive when analyzing foreign-language dark web content. In this research note, we adopt the computational design science paradigm to develop a novel IT artifact for cross-lingual hacker asset detection (CLHAD). CLHAD automatically leverages the knowledge learned from English content to detect hacker assets in non-English dark web platforms. CLHAD encompasses a novel Adversarial deep representation learning (ADREL) method, which generates multilingual text representations using generative adversarial networks (GANs). Drawing upon the state of the art in cross-lingual knowledge transfer, ADREL is a novel approach to automatically extract transferable text representations and facilitate the analysis of multilingual content. We evaluate CLHAD on Russian, French, and Italian dark web platforms and demonstrate its practical utility in hacker asset profiling, and conduct a proof-of-concept case study. Our analysis suggests that cybersecurity managers may benefit more from focusing on Russian to identify sophisticated hacking assets. In contrast, financial hacker assets are scattered among several dominant dark web languages. Managerial insights for security managers are discussed at operational and strategic levels. © 2022 University of Minnesota. All rights reserved.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180129735&doi=10.25300%2fMISQ%2f2022%2f16618&partnerID=40&md5=d71a106989b689e231593a6508145a3a,MIS Quarterly: Management Information Systems,Exclude,,,
Deldar F.; Abadi M.; Ebrahimifard M.,Android Malware Detection Using Supervised Deep Graph Representation Learning,"Despite the continuous evolution and significant improvement of cybersecurity mechanisms, malware threats remain one of the most important concerns in cyberspace. Meanwhile, Android malware plays a big role in these ever-growing threats. In recent years, deep learning has become the dominant machine learning technique for malware detection and continues to make outstanding achievements. Deep graph representation learning is the task of embedding graph-structured data into a low-dimensional space using deep learning models. Recently, autoencoders have proven to be an effective way for deep representation learning. However, it is not straightforward to apply the idea of autoencoder to graph-structured data because of their irregular structure. In this paper, we present DroidMalGNN, a novel deep learning technique that combines autoencoders with graph neural networks (GNNs) to detect Android malware in an end-to-end manner. DroidMalGNN represents each Android application with an attributed function call graph (AFCG) that allows it to model complex relationships between data. For more efficiency, DroidMalGNN performs graph representation learning in a supervised manner where two autoencoders are trained with benign and malicious AFCGs separately. In this way, it generates two informative embedding vectors for each AFCG in a low-dimensional space and feeds them into a dense neural network to classify the AFCG as benign or malicious. Our experimental results show that DroidMalGNN can achieve good detection performance in terms of different evaluation measures. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143788381&doi=10.1109%2fICCKE57176.2022.9960076&partnerID=40&md5=a99f31a7c61015064be24edcd2eed972,"2022 12th International Conference on Computer and Knowledge Engineering, ICCKE 2022",Include,,,
Zhang W.; Liu H.; Liu F.; Ramachandra R.; Busch C.,Effective Presentation Attack Detection Driven by Face Related Task,"The robustness and generalization ability of Presentation Attack Detection (PAD) methods is critical to ensure the security of Face Recognition Systems (FRSs). However, in a real scenario, Presentation Attacks (PAs) are various and it is hard to predict the Presentation Attack Instrument (PAI) species that will be used by the attacker. Existing PAD methods are highly dependent on the limited training set and cannot generalize well to unknown PAI species. Unlike this specific PAD task, other face related tasks trained by huge amount of real faces (e.g. face recognition and attribute editing) can be effectively adopted into different application scenarios. Inspired by this, we propose to trade position of PAD and face related work in a face system and apply the free acquired prior knowledge from face related tasks to solve face PAD, so as to improve the generalization ability in detecting PAs. The proposed method, first introduces task specific features from other face related task, then, we design a Cross-Modal Adapter using a Graph Attention Network (GAT) to re-map such features to adapt to PAD task. Finally, face PAD is achieved by using the hierarchical features from a CNN-based PA detector and the re-mapped features. The experimental results show that the proposed method can achieve significant improvements in the complicated and hybrid datasets, when compared with the state-of-the-art methods. In particular, when training on the datasets OULU-NPU, CASIA-FASD, and Idiap Replay-Attack, we obtain HTER (Half Total Error Rate) of 5.48% for the testing dataset MSU-MFSD, outperforming the baseline by 7.39%. The source code is available at https://github.com/WentianZhang-ML/FRT-PAD. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144533388&doi=10.1007%2f978-3-031-20065-6_24&partnerID=40&md5=53174f70b40852a835808510c5d3f43d,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,Exclude,
Hu J.L.; Ebrahimi M.; Li W.; Li X.; Chen H.,Multi-view Representation Learning from Malware to Defend Against Adversarial Variants,"Deep learning-based adversarial malware detectors have yielded promising results in detecting never-before-seen malware executables without relying on expensive dynamic behavior analysis and sandbox. Despite their abilities, these detectors have been shown to be vulnerable to adversarial malware variants - meticulously modified, functionality-preserving versions of original malware executables generated by machine learning. Due to the nature of these adversarial modifications, these adversarial methods often use a single view of malware executables (i.e., the binary/hexadecimal view) to generate adversarial malware variants. This provides an opportunity for the defenders (i.e., malware detectors) to detect the adversarial variants by utilizing more than one view of a malware file (e.g., source code view in addition to the binary view). The rationale behind this idea is that while the adversary focuses on the binary view, certain characteristics of the malware file in the source code view remain untouched which leads to the detection of the adversarial malware variants. To capitalize on this opportunity, we propose Adversarially Robust Multiview Malware Defense (ARMD), a novel multi-view learning framework to improve the robustness of DL-based malware detectors against adversarial variants. Our experiments on three renowned open-source deep learning-based malware detectors across six common malware categories show that ARMD is able to improve the adversarial robustness by up to seven times on these malware detectors.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148453933&doi=10.1109%2fICDMW58026.2022.00066&partnerID=40&md5=857e415b9f41782fd619468754e1864c,"IEEE International Conference on Data Mining Workshops, ICDMW",Include,,,
Mester A.; Bodó Z.,Malware Classification Based on Graph Convolutional Neural Networks and Static Call Graph Features,"Advanced Persistent Threats (APT) are targeted, high level cybersecurity risk factors facing governments, financial units and other organizations. The attribution of APTs – gathering information about the origin of an attack – is an important key in the process of securing an organisation’s infrastructure, prioritizing the measures to be taken depending on the actor(s) targeting the organisation. In practice, an elementary step in the process of attribution is determining the family and/or author of a sample, based on the binary file and/or its dynamic analysis – i.e. a multi-class classification problem regarding the family/author label. There are numerous methods in the literature aimed to label a sample based on its control flow graph or API sequence graph. We aim to summarize the literature on these methods, and offer another method to classify malware families leveraging the static call graph of a PE executable, as well as the functions’ instruction lists, using a locality-sensitive hashing method to obtain the node feature vectors. Our results are compared to recent publications in the field. © 2022, Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137997125&doi=10.1007%2f978-3-031-08530-7_45&partnerID=40&md5=2a40b7eb82c26515edc7efbf2a1fca5c,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Wang R.; Zheng J.; Shi Z.; Tan Y.,Detecting Malware Using Graph Embedding and DNN,"Nowadays, the popularity of intelligent terminals makes malwares more and more serious. Among the many features of application, the call graph can accurately express the behavior of the application. The rapid development of graph neural network in recent years provides a new solution for the malicious analysis of application using call graphs as features. However, there are still problems such as low accuracy. This paper established a large-scale data set containing more than 40,000 samples and selected the class call graph, which was extracted from the application, as the feature and used the graph embedding combined with the deep neural network to detect the malware. The experimental results show that the accuracy of the detection model proposed in this paper is 97.7%; the precision is 96.6%; the recall is 96.8%; the F1-score is 96.4%, which is better than the existing detection model based on Markov chain and graph embedding detection model.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137332194&doi=10.1109%2fICBCTIS55569.2022.00018&partnerID=40&md5=579e1c36c16f0afca4b77172abe3b7b3,"Proceedings - 2022 International Conference on Blockchain Technology and Information Security, ICBCTIS 2022",Include,,,
Ling X.; Wu L.; Deng W.; Qu Z.; Zhang J.; Zhang S.; Ma T.; Wang B.; Wu C.; Ji S.,MalGraph: Hierarchical Graph Neural Networks for Robust Windows Malware Detection,"With the ever-increasing malware threats, malware detection plays an indispensable role in protecting information systems. Although tremendous research efforts have been made, there are still two key challenges hindering them from being applied to accurately and robustly detect malwares. Firstly, most of them represent executables with shallow features, but ignore their semantic and structural information. Secondly, they are primarily based on representations that can be easily modified by attackers and thus cannot provide robustness against adversarial attacks. To tackle the challenges, we present MalGraph, which first represents executables with hierarchical graphs and then uses an end-to-end learning framework based on graph neural networks for malware detection. In particular, a hierarchical graph consists of a function call graph that captures the interaction semantics among different functions at the inter-function level and corresponding control-flow graphs for learning the structural semantics of each function at the intra-function level. We argue the abstraction and hierarchy nature of hierarchical graphs makes them not only easy to capture rich structural information of executables, but also be immune to adversarial attacks. Evaluations show that MalGraph not only outperforms state-of-the-art malware detection, but also exhibits stronger robustness against adversarial attacks by a large margin. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133286884&doi=10.1109%2fINFOCOM48880.2022.9796786&partnerID=40&md5=1042ba15bbc091936aab376b6e16918e,Proceedings - IEEE INFOCOM,Include,,Include,
Lo W.W.; Layeghy S.; Sarhan M.; Gallagher M.; Portmann M.,Graph Neural Network-based Android Malware Classification with Jumping Knowledge,"This paper presents a new Android malware de-tection method based on Graph Neural Networks (GNNs) with Jumping-Knowledge (JK). Android function call graphs (FCGs) consist of a set of program functions and their inter-procedural calls. Thus, this paper proposes a GNN-based method for Android malware detection by capturing meaningful intra-procedural call path patterns. In addition, a Jumping-Knowledge technique is applied to minimize the effect of the over-smoothing problem, which is common in GNNs. The proposed method has been extensively evaluated using two benchmark datasets. The results demonstrate the superiority of our approach compared to state-of-the-art approaches in terms of key classification metrics, which demonstrates the potential of GNNs in Android malware detection and classification.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141032606&doi=10.1109%2fDSC54232.2022.9888878&partnerID=40&md5=41417c8b6bb201d6b52877c0ad4e2bdd,"5th IEEE Conference on Dependable and Secure Computing, DSC 2022 and SECSOC 2022 Workshop, PASS4IoT 2022 Workshop SICSA International Paper/Poster Competition in Cybersecurity",Include,,,
Jia J.; Chan P.K.,Representation Learning with Function Call Graph Transformations for Malware Open Set Recognition,"Open set recognition (OSR) problem has been a challenge in many machine learning (ML) applications, such as security. As new/unknown malware families occur regularly, it is difficult to exhaust samples that cover all the classes for the training process in ML systems. An advanced malware classification system should classify the known classes correctly while sensitive to the unknown class. In this paper, we introduce a self-supervised pre-training approach for the OSR problem in malware classification. We propose two transformations for the function call graph (FCG) based malware representations to facilitate the pretext task. Also, we present a statistical thresholding approach to find the optimal threshold for the unknown class. Moreover, the experiment results indicate that our proposed pre-training process can improve different performances of different downstream loss functions for the OSR problem. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139314658&doi=10.1109%2fIJCNN55064.2022.9892931&partnerID=40&md5=b224ed5f3cea7f30c977a9b08c51e4bc,Proceedings of the International Joint Conference on Neural Networks,Exclude,,,
Wu Q.; Sun P.; Hong X.; Zhu X.; Liu B.,An Android Malware Detection and Malicious Code Location Method Based on Graph Neural Network,"In recent years, enormously Android malware poses a significant threat to Android platform security. To detect malicious applications, researchers have done a lot of work, in which finding and locating malicious code segments is an important research content. In the previous research, most detection methods cannot directly locate malicious code, and some methods with the locate ability can only find some specific types of malicious operations. This paper proposed a graph convolution algorithm and weighted mechanism to find malicious nodes implied in the Android application function call graph and provided a general method for malicious code location. We analyzed the sub-graph structural differences between benign code and malicious payload in the function call graph, constructed graph convolution operation to make the nodes in the graph learn the surrounding sub-graph structure, designed the weighting mechanism to set the malicious score to every code node, and filtered out the nodes with the highest malicious score to locate the malicious code fragments. On the dataset composed of 2650 malicious and 2650 benign applications, the accuracy of malware detection is 92.6%, and the accuracy of malicious code location is between 72.6% and 88.1%, indicating that our method is accurate and efficient.  © 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122617410&doi=10.1145%2f3490725.3490733&partnerID=40&md5=8404af3fcb19d228d8a890460359d164,ACM International Conference Proceeding Series,Include,,,
Puodzius C.; Zendra O.; Heuser A.; Noureddine L.,Accurate and Robust Malware Analysis through Similarity of External Calls Dependency Graphs (ECDG),"Malware is a primary concern in cybersecurity, being one of the attacker's favorite cyberweapons. Over time, malware evolves not only in complexity but also in diversity and quantity. Malware analysis automation is thus crucial. In this paper we present ECDGs, a shorter call graph representation, and a new similarity function that is accurate and robust. Toward this goal, we revisit some principles of malware analysis research to define basic primitives and an evaluation paradigm addressed for the setup of more reliable experiments. Our benchmark shows that our similarity function is very efficient in practice, achieving speedup rates of 3.30x and 354,11x wrt. radiff2 for the standard and the cache-enhanced implementations, respectively. Our evaluations generate clusters that produce almost unerring results - homogeneity score of 0.983 for the accuracy phase - and marginal information loss for a highly polluted dataset - NMI score of 0.974 between initial and final clusters of the robustness phase. Overall, ECDGs and our similarity function enable autonomous frameworks for malware search and clustering that can assist human-based analysis or improve classification models for malware analysis. © 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113248617&doi=10.1145%2f3465481.3470115&partnerID=40&md5=c0463ecb9a4d92672166e032acb4af24,ACM International Conference Proceeding Series,Exclude,,,
Li C.; Shen G.; Sun W.,Cross-Architecture Intemet-of-Things Malware Detection Based on Graph Neural Network,"The number of Internet of Things (IoT) devices has exploded in recent years. Due to the simple implementation and difficult-to-patch firmware, IoT devices are vulnerable to malware attacks. Static analysis is a feasible way to understand the behavior of IoT malware for detection and mitigation. However, unlike traditional malware on personal computers or smartphones, the diversity of processor architecture on IoT devices brings a variety of challenges for researchers. Current malware detection methods based on operation code or byte code cannot address the multi-architecture issue well. In this paper, we propose a cross-architecture IoT malware detection method based on graph neural network(GNN). We represent each binary file as a function call graph(FCG), since FCG is a higher-level architecture-independent feature. Natural language processing model is used to extract semantic information from operation code in our method. Enable semantic information as node feature and then we use GNN to extract structural information from FCG. Our method takes both semantic and structural information into account to identify malware. We also create a dataset that covers 5 different processor architectures to evaluate our method. The experiment we conduct over the dataset shows that our method performs better than other methods and is capable to detect unknown malware. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116483744&doi=10.1109%2fIJCNN52387.2021.9533500&partnerID=40&md5=5c53247451dda355319f5366ae0e3717,Proceedings of the International Joint Conference on Neural Networks,Exclude,,,
Zhang C.; Zhou Q.; Huang Y.; Tang K.; Gui H.; Liu F.,Automatic Detection of Android Malware via Hybrid Graph Neural Network,"Automatic malware detection was aimed at determining whether the application is malicious or not with automated systems. Android malware attacks have gained tremendous pace owing to the widespread use of mobile devices. Although significant progress has been made in antimalware techniques, these methods mainly rely on the program features, ignoring the importance of source code analysis. Furthermore, the dynamic analysis is low code coverage and poor efficiency. Hence, we propose an automatic Android malware detection approach, named HyGNN-Mal. It analyzes the Android applications at source code level by exploiting the sequence and structure information. Meanwhile, we combine the typical static features, permissions, and APIs. In HyGNN-Mal, we utilize a deep traversal tree neural network (Deep-TNN) to process the code structure information. Particularly, we add position information to code sequence information before putting in self-attention mechanism. The evaluations conducted on multiple public datasets indicate that our method can accurately identify and classify the malicious software, and their best accuracy is 99.62% and 99.2%, respectively.  © 2022 Chunyan Zhang et al.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130644021&doi=10.1155%2f2022%2f7245403&partnerID=40&md5=d4e26e7b3858fb8d84f32a11c7387928,Wireless Communications and Mobile Computing,Include,,,
Zheng R.; Wang Q.; He J.; Fu J.; Suri G.; Jiang Z.,Cryptocurrency Mining Malware Detection Based on Behavior Pattern and Graph Neural Network,"Miner malware has been steadily increasing in recent years as the value of cryptocurrency rises, which poses a considerable threat to users' device security. Miner malware has obvious behavior patterns in order to participate in blockchain computing. However, most miner malware detection methods use raw bytes feature and sequential opcode as detection features. It is difficult for these methods to obtain better detection results due to not modeling robust features. In this paper, a miner malware identification method based on graph classification network is designed by analyzing the features of function call graph and control flow graph of miner malware, called MBGINet. MBGINet can model the behavior graph relationship of miner malware by extracting the connection features of critical nodes in the behavior graph. Finally, MBGINet transforms these node features into the feature vectors of the graph for miner malware identification. In the test experiments, datasets with different volumes are used for simulating real-world scenarios. The experimental results show that the MBGINet method achieves a leading and stable performance compared to the dedicated opcode detection method and obtains an accuracy improvement of 3.08% on the simulated in-the-wild dataset. Meanwhile, MBGINet gains an advantage over the general malware detection method Malconv. These experimental results demonstrate the superiority of the MBGINet method, which has excellent characteristics in adapting to realistic scenarios.  © 2022 Rui Zheng et al.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128269189&doi=10.1155%2f2022%2f9453797&partnerID=40&md5=fb6fdf3fb825610b598fc123cd270985,Security and Communication Networks,Include,,Include,
Norouzian M.R.; Xu P.; Eckert C.; Zarras A.,Hybroid: Toward Android Malware Detection and Categorization with Program Code and Network Traffic,"Android malicious applications have become so sophisticated that they can bypass endpoint protection measures. Therefore, it is safe to admit that traditional anti-malware techniques have become cumbersome, thereby raising the need to develop efficient ways to detect Android malware. In this paper, we present Hybroid, a hybrid Android malware detection and categorization solution that utilizes program code structures as static behavioral features and network traffic as dynamic behavioral features for detection (binary classification) and categorization (multi-label classification). For static analysis, we introduce a natural-language-processing-inspired technique based on function call graph embeddings and design a graph-neural-network-based approach to convert the whole graph structure of an Android app to a vector. For dynamic analysis, we extract network flow features from the raw network traffic by capturing each application’s network flow. Finally, Hybroid utilizes the network flow features combined with the graphs’ vectors to detect and categorize the malware. Our solution demonstrates 97.0% accuracy on average for malware detection and 94.0% accuracy for malware categorization. Also, we report remarkable results in different performance metrics such as F1-score, precision, recall, and AUC. © 2021, Springer Nature Switzerland AG.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121872834&doi=10.1007%2f978-3-030-91356-4_14&partnerID=40&md5=ae343ea2d7add68039d64de9a2835d1a,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Huang W.; Jia C.; Yu M.; Li G.; Liu C.; Jiang J.,UTANSA: Static Approach for Multi-Language Malicious Web Scripts Detection,"In order to detect malicious web scripts automatically, many detection methods using static features and machine learning are proposed. However, the existing detection methods can only detect web scripts of specific programming languages. This paper proposes the unified text features and abstract syntax tree(AST) node sequence features algorithm(UTANSA) that exploits the text feature classification method and AST node classification method, together with the corresponding unified method to enhance the generalization ability of the model. Through the algorithm, two unified approaches are proposed based on text features and AST node features respectively, so that the detection model can detect multi-language web scripts. We choose scripts written in the JavaScript(JS) and PHP languages for experimentation to evaluate our approach. The results show that the detection model trained with the proposed method has a similar detection effect as trained with only JS samples or PHP samples.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123221977&doi=10.1109%2fISCC53001.2021.9631400&partnerID=40&md5=8ce63bb7b3e8bba312a888b84517349e,Proceedings - IEEE Symposium on Computers and Communications,Include,,Include,
Zhou X.; Zhou X.,Homology Detection of Malicious Codes Based on a Fuzzy Graph Neural Network,"Malicious code detection and homology analysis has been a hot research field in malicious code analysis. The API call graph extracted from malicious code can express the behavior information of malicious code effectively, but the efficiency of malicious code analysis based on graph structure is low because of the high algorithm complexity of solving subgraph isomorphism. To solve these problems, a new method of malicious code homology detection based on a fuzzy graph neural network is proposed. First, the malicious code features are selected and summarized, then the malicious code features are extracted, and finally the malicious code features are compared. Static analysis is used to analyze malicious code, extract its API call graph, and then process the API call graph to make it match the input of the convolutional neural network. With the help of the online code analysis platform, the platform adopts a sandbox mechanism, integrates more than 90 kinds of antivirus software, and analyzes the samples uploaded by users, which can give malicious evaluations. Experimental results show that the accuracy rate of malicious code homology analysis is 93%, and the accuracy rate of malicious code detection is 96%.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125965944&doi=10.1109%2fIAAI54625.2021.9699879&partnerID=40&md5=7f4b0d04a5e921a8e2876efa19d4de6a,"2021 IEEE International Conference on Industrial Application of Artificial Intelligence, IAAI 2021",Include,,,
Zou D.; Wu Y.; Yang S.; Chauhan A.; Yang W.; Zhong J.; Dou S.; Jin H.,IntDroid: Android Malware Detection Based on API Intimacy Analysis,"Android, the most popular mobile operating system, has attracted millions of users around the world. Meanwhile, the number of new Android malware instances has grown exponentially in recent years. On the one hand, existing Android malware detection systems have shown that distilling the program semantics into a graph representation and detecting malicious programs by conducting graph matching are able to achieve high accuracy on detecting Android malware. However, these traditional graph-based approaches always perform expensive program analysis and suffer from low scalability on malware detection. On the other hand, because of the high scalability of social network analysis, it has been applied to complete large-scale malware detection. However, the social-network-analysis-based method only considers simple semantic information (i.e., centrality) for achieving market-wide mobile malware scanning, which may limit the detection effectiveness when benign apps show some similar behaviors as malware. In this article, we aim to combine the high accuracy of traditional graph-based method with the high scalability of social-network-analysis-based method for Android malware detection. Instead of using traditional heavyweight static analysis, we treat function call graphs of apps as complex social networks and apply social-network-based centrality analysis to unearth the central nodes within call graphs. After obtaining the central nodes, the average intimacies between sensitive API calls and central nodes are computed to represent the semantic features of the graphs. We implement our approach in a tool called IntDroid and evaluate it on a dataset of 3,988 benign samples and 4,265 malicious samples. Experimental results show that IntDroid is capable of detecting Android malware with an F-measure of 97.1% while maintaining a True-positive Rate of 99.1%. Although the scalability is not as fast as a social-network-analysis-based method (i.e., MalScan), compared to a traditional graph-based method, IntDroid is more than six times faster than MaMaDroid. Moreover, in a corpus of apps collected from GooglePlay market, IntDroid is able to identify 28 zero-day malware that can evade detection of existing tools, one of which has been downloaded and installed by more than ten million users. This app has also been flagged as malware by six anti-virus scanners in VirusTotal, one of which is Symantec Mobile Insight.  © 2021 ACM.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105741673&doi=10.1145%2f3442588&partnerID=40&md5=414d1b2de80007dd4d4794434dc5d216,ACM Transactions on Software Engineering and Methodology,Exclude,,,
Renjith G.; Aji S.,Vulnerability Analysis and Detection Using Graph Neural Networks for Android Operating System,"Android operating system approximately contains around 93 million lines of code, mainly consisting of C, C++ and Java languages. There is no strict software engineering life-cycle followed during Android software development, and hence the design flaws and vulnerabilities are largely reported. Rising security attacks targeting Android manifests the importance of early detection of vulnerabilities in Android operating system. The existing mechanisms either focus on Android Apps or short code differences of the Android framework, and hence they are less effective for Android operating system. In this work, we extracted all the officially reported publicly accessible Android Java vulnerabilities in application and framework layers from 2015 till June 2021. The extracted vulnerable and corresponding fixed (secure) code are then converted into the graphical form using different intermediate graph representations, and then graph features are extracted. Vectorization techniques are used for converting node features of the graph into numerical formats. A vulnerability detection mechanism based on Graph Neural Network is designed and achieved an F1-score of 0.92. To the best of our knowledge, this will be one of the first works for Android operating system source code vulnerability detection technique exploiting the potential of Graph Neural Networks. © 2021, Springer Nature Switzerland AG.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122043434&doi=10.1007%2f978-3-030-92571-0_4&partnerID=40&md5=4572538ed90c4cfd6eb83138ffd7e4e1,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,,
Errica F.; Iadarola G.; Martinelli F.; Mercaldo F.; Micheli A.,Robust Malware Classification via Deep Graph Networks on Call Graph Topologies,"We propose a malware classification system that is shown to be robust to some common intra-procedural obfuscation techniques. Indeed, by training the Contextual Graph Markov Model on the call graph representation of a program, we classify it using only topological information, which is unaffected by such obfuscations. In particular, we show that the structure of the call graph is sufficient to achieve good accuracy on a multi-class classification benchmark. © 2021 ESANN Intelligence and Machine Learning. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126084314&doi=10.14428%2fesann%2f2021.ES2021-82&partnerID=40&md5=b4f128b93a501718cc0f334bf55a2add,"ESANN 2021  Proceedings - 29th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning",Include,,Include,
Rozi M.F.; Ban T.; Ozawa S.; Kim S.; Takahashi T.; Inoue D.,JStrack: Enriching Malicious JavaScript Detection Based on AST Graph Analysis and Attention Mechanism,"Malicious JavaScript is one of the most common tools for attackers to exploit the vulnerability of web applications. It can carry potential risks such as spreading malware, phishing, or collecting sensitive information. Though there are numerous types of malicious JavaScript that are difficult to detect, generalizing the malicious script’s signature can help catch more complex JavaScripts that use obfuscation techniques. This paper aims at detecting malicious JavaScripts based on structure and attribute analysis of abstract syntax trees (ASTs) that capture the generalized semantic meaning of the source code. We apply a graph convolutional neural network (GCN) to process the AST features and get a graph representation via neural message passing with neighborhood aggregation. The attention layer enriches our method to track pertinent parts of scripts that may contain the signature of malicious intent. We comprehensively evaluate the performance of our proposed approach on a real-world dataset to detect malicious websites. The proposed method demonstrates promising performance in terms of detection accuracy and robustness against obfuscated samples. © 2021, Springer Nature Switzerland AG.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121913208&doi=10.1007%2f978-3-030-92270-2_57&partnerID=40&md5=f5447afcae093e424ec42d6ba4e49536,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,,
Xu P.; Eckert C.; Zarras A.,Detecting and categorizing Android malware with graph neural networks,"Android is the most dominant operating system in the mobile ecosystem. As expected, this trend did not go unnoticed by miscreants, and quickly enough, it became their favorite platform for discovering new victims through malicious apps. These apps have become so sophisticated that they can bypass anti-malware measures implemented to protect the users. Therefore, it is safe to admit that traditional anti-malware techniques have become cumbersome, sparking the urge to come up with an efficient way to detect Android malware. In this paper, we present a novel Natural Language Processing (NLP) inspired Android malware detection and categorization technique based on Function Call Graph Embedding. We design a graph neural network (graph embedding) based approach to convert the whole graph structure of an Android app to a vector. We then utilize the graphs' vectors to detect and categorize the malware families. Our results reveal that graph embedding yields better results as we get 99.6% accuracy on average for the malware detection and 98.7% accuracy for the malware categorization. © 2021 Owner/Author.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105002437&doi=10.1145%2f3412841.3442080&partnerID=40&md5=e72bea33749e6b2ae33362c2b1495173,Proceedings of the ACM Symposium on Applied Computing,Include,,Include,
Feng P.; Ma J.; Li T.; Ma X.; Xi N.; Lu D.,Android Malware Detection via Graph Representation Learning,"With the widespread usage of Android smartphones in our daily lives, the Android platform has become an attractive target for malware authors. There is an urgent need for developing an automatic malware detection approach to prevent the spread of malware. The low code coverage and poor efficiency of the dynamic analysis limit the large-scale deployment of malware detection methods based on dynamic features. Therefore, researchers have proposed a plethora of detection approaches based on abundant static features to provide efficient malware detection. This paper explores the direction of Android malware detection based on graph representation learning. Without complex feature graph construction, we propose a new Android malware detection approach based on lightweight static analysis via the graph neural network (GNN). Instead of directly extracting Application Programming Interface (API) call information, we further analyze the source code of Android applications to extract high-level semantic information, which increases the barrier of evading detection. Particularly, we construct approximate call graphs from function invocation relationships within an Android application to represent this application and further extract intrafunction attributes, including required permission, security level, and Smali instructions' semantic information via Word2Vec, to form the node attributes within graph structures. Then, we use the graph neural network to generate a vector representation of the application, and then malware detection is performed on this representation space. We conduct experiments on real-world application samples. The experimental results demonstrate that our approach implements high effective malware detection and outperforms state-of-the-art detection approaches.  © 2021 Pengbin Feng et al.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108460555&doi=10.1155%2f2021%2f5538841&partnerID=40&md5=3f2f66345e7c0de62657ea62064f880f,Mobile Information Systems,Include,,Include,
Feng P.; Ma J.; Li T.; Ma X.; Xi N.; Lu D.,Android Malware Detection Based on Call Graph via Graph Neural Network,"With the widespread usage of Android smart-phones in our daily lives, Android platform has become an attractive target for malware authors. There is an urgent need for developing automatic malware detection approach to prevent the spread of malware. Traditional signature-based detection methods cannot handle the rapid evolution of complex malware or the emerging of new types of malware. Due to the limitation on code coverage and poor efficiency of the dynamic analysis, in this paper, we propose a new Android malware detection approach based on static analysis via graph neural network. Instead of extracting Application Programming Interface (API) call information, we further analyze the source code of Android applications to extract high-level semantic information, which increases the barrier of evading detection. Particularly, we construct approximate call graph from function invocation relationships within an Android application to represent this application, and further extract intra-function attributes, including required permission, security level and statistical instructions information, to form the node attributes within graph structures. Then, we use graph neural network (GNN) to generate a vector representation of the application, and then malware classification is performed on this representation. We conduct experiments on real-world application samples. The experimental results demonstrate that our approach implements high effective malware detection and outperforms state-of-the-art detection approaches. © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102122227&doi=10.1109%2fNaNA51271.2020.00069&partnerID=40&md5=4f77ffd5ff0f36805716c6017fdb2f7a,"Proceedings - 2020 International Conference on Networking and Network Applications, NaNA 2020",Include,,,
Dounavi H.-M.; Mpanti A.; Nikolopoulos S.D.; Polenakis I.,A graph-based framework for malicious software detection and classification utilizing temporal-graphs,"In this paper we present a graph-based framework that, utilizing relations between groups of System-calls, detects whether an unknown software sample is malicious or benign, and classifies a malicious software to one of a set of known malware families. In our approach we propose a novel graph representation of dependency graphs by capturing their structural evolution over time constructing sequential graph instances, the so-called Temporal Graphs. The partitions of the temporal evolution of a graph defined by specific time-slots, results to different types of graphs representations based upon the information we capture across the capturing of its evolution. The proposed graph-based framework utilizes the proposed types of temporal graphs computing similarity metrics over various graph characteristics in order to conduct the malware detection and classification procedures. Finally, we evaluate the detection rates and the classification ability of our proposed graph-based framework conducting a series of experiments over a set of known malware samples pre-classified into malware families.  © 2021 - IOS Press.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118750824&doi=10.3233%2fJCS-210057&partnerID=40&md5=6b0eae64efbad8139bd91e9a7347c8b1,Journal of Computer Security,Exclude,,Include,Exclude
Dalton T.; Schmidtler M.; Khodabakhshi A.H.,Classifying Malware Using Function Representations in a Static Call Graph,"We propose a deep learning approach for identifying malware families using the function call graphs of × 86 assembly instructions. Though prior work on static call graph analysis exists, very little involves the application of modern, principled feature learning techniques to the problem. In this paper, we introduce a system utilizing an executable’s function call graph where function representations are obtained by way of a recurrent neural network (RNN) autoencoder which maps sequences of × 86 instructions into dense, latent vectors. These function embeddings are then modeled as vertices in a graph with edges indicating call dependencies. Capturing rich, node-level representations as well as global, topological properties of an executable file greatly improves malware family detection rates and contributes to a more principled approach to the problem in a way that deliberately avoids tedious feature engineering and domain expertise. We test our approach by performing several experiments on a Microsoft malware classification data set and achieve excellent separation between malware families with a classification accuracy of 99.41%. © 2020, Springer Nature Switzerland AG.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101316767&doi=10.1007%2f978-3-030-66046-8_20&partnerID=40&md5=d1b66edd0dc91c43d46bbe76b9a38ba5,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,Exclude,
Mpanti A.; Nikolopoulos S.D.; Polenakis I.,Malicious software detection utilizing temporal-graphs,"In this work we propose a graph-based model that, utilizing relations between groups of System-calls, distinguishes malicious from benign software samples utilizing a behavioral graph representing their interaction with the operating system. More precisely, given a System-call Dependency Graph (ScDG) that depicts the malware's behavior, we first transform it to a more abstract representation, utilizing the indexing of System-calls to a set of groups of similar functionality, constructing thus a mutation tolerant graph that we call Group Relation Graph (GrG); we pointed out that behavior-based graph representations had not leveraged the aspect of the temporal evolution of the graph. Hence, the novelty of our work is that, preserving the initial representations of GrG graphs, we focus on augmenting the potentials of theses graphs by adding further features that enhance its detection abilities. To that end, we construct periodical instances of the graph that represent its temporal evolution concerning its structural modifications, creating another graph representation that we call Temporal Graphs. In this paper, we present the theoretical background behind our approach, and demonstrate the overall architecture of our proposed detection model alongside with its underlying main principles and its structural key-components. © 2019 Copyright Association for Computing Machinery.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073053147&doi=10.1145%2f3345252.3345269&partnerID=40&md5=3d1704997e47e84d83b4ffad13d2eb50,ACM International Conference Proceeding Series,Exclude,,,
Zhao B.-L.; Liu F.-D.; Shan Z.; Chen Y.-H.; Liu J.,Graph similarity metric using graph convolutional network: Application to malware similarity match,"Nowadays, malware is a serious threat to the Internet. Traditional signature-based malware detection method can be easily evaded by code obfuscation. Therefore, many researchers use the high-level structure of malware like function call graph, which is impacted less from the obfuscation, to find the malware variants. However, existing graph match methods rely on approximate calculation, which are inefficient and the accuracy cannot be effectively guaranteed. Inspired by the successful application of graph convolutional network in node classification and graph classification, we propose a novel malware similarity metric method based on graph convolutional network. We use graph convolutional network to compute the graph embedding vectors, and then we calculate the similarity metric of two graph based on the distance between two graph embedding vectors. Experimental results on the Kaggle dataset show that our method can applied to the graph based malware similarity metric method, and the accuracy of clustering application with our method reaches to 97% with high time efficiency. © 2019 The Institute of Electronics, Information and Communication Engineers.",Article,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071951069&doi=10.1587%2ftransinf.2018EDL8259&partnerID=40&md5=194d71e093c927ae697c4fed72c642a7,IEICE Transactions on Information and Systems,Include,,,
Pektaş A.; Acarman T.,Deep learning for effective Android malware detection using API call graph embeddings,"High penetration of Android applications along with their malicious variants requires efficient and effective malware detection methods to build mobile platform security. API call sequence derived from API call graph structure can be used to model application behavior accurately. Behaviors are extracted by following the API call graph, its branching, and order of calls. But identification of similarities in graphs and graph matching algorithms for classification is slow, complicated to be adopted to a new domain, and their results may be inaccurate. In this study, the authors use the API call graph as a graph representation of all possible execution paths that a malware can track during its runtime. The embedding of API call graphs transformed into a low dimension numeric vector feature set is introduced to the deep neural network. Then, similarity detection for each binary function is trained and tested effectively. This study is also focused on maximizing the performance of the network by evaluating different embedding algorithms and tuning various network configuration parameters to assure the best combination of the hyper-parameters and to reach at the highest statistical metric value. Experimental results show that the presented malware classification is reached at 98.86% level in accuracy, 98.65% in F-measure, 98.47% in recall and 98.84% in precision, respectively. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064149005&doi=10.1007%2fs00500-019-03940-5&partnerID=40&md5=a60844e28c5afae53c9c7449d5b0dd59,Soft Computing,Exclude,,,
Mpanti A.; Nikolopoulos S.D.; Polenakis I.,A graph-based model for malicious software detection exploiting domination relations between system-call groups,"In this paper, we propose a graph-based algorithmic technique for malware detection, utilizing the System-call Dependency Graphs (ScDG) obtained through taint analysis traces. We leverage the grouping of system-calls into system-call groups with respect to their functionality to merge disjoint vertices of ScDG graphs, transforming them to Group Relation Graphs (GrG); note that, the GrG graphs represent malware's behavior being hence more resilient to probable mutations of its structure. More precisely, we extend the use of GrG graphs by mapping their vertices on the plane utilizing the degrees and the vertex-weights of a specific underlying graph of the GrG graph as to compute domination relations. Furthermore, we investigate how the activity of each system-call group could be utilized in order to distinguish graph-representations of malware and benign software. The domination relations among the vertices of GrG graphs result to a new graph representation that we call Coverage Graph of the GrG graph. Finally, we evaluate the potentials of our detection model using graph similarity between Coverage Graphs of known malicious and benign software samples of various types. © 2018 Association for Computing Machinery. ACM",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061151234&doi=10.1145%2f3274005.3274028&partnerID=40&md5=40fc0c3ee9236ad433c8ad2a6c63aaf4,ACM International Conference Proceeding Series,Include,Exclude,Exclude,
Gibert D.; Lamas A.; Martins R.; Mateu C.; Planes J.,An android malware detection framework using graph embeddings and convolutional neural networks,"With the widespread use of mobile phones, the number of malware targeting smart devices has increased exponentially. In particular, the number of malware targeting Android devices, as it is the most popular operative system among smartphones. This paper proposes a novel framework for android malware detection based on the function call graph representation of an application. Our method generates an embedding of the function call graph using random walks and then, a convolutional neural network extracts features from their embedded matrix representation and labels a given application as benign or malicious considering the learned features. The method has been evaluated on a dataset of 3871 APKs and compared against DREBIN, a baseline benchmark. Experiments show that the method achieves competitive results without relying on the manual extraction of features. © 2019 The authors and IOS Press. All rights reserved.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085018116&doi=10.3233%2fFAIA190107&partnerID=40&md5=90c005f9bfb6cbe75672a581f9e5590c,Frontiers in Artificial Intelligence and Applications,Include,,,
Frenkel S.; Zakharov V.,Brief Announcement: Graph-Based and Probabilistic Discrete Models Used in Detection of Malicious Attacks,"Design of program secure systems is connected with choice of mathematical models of the systems. A widely-used approach to malware detection (or classification as “benign-malicious”) is based on the system calls traces similarity measurement. Presently both the set-theoretical metrics (for example, Jaccard similarity, the Edit (Levenshtein) distance (ED) [1]) between the traces of system calls and the Markov chain based models of attack effect are used. Jaccard similarity is used when the traces are considered as a non-ordering set. The Edit Distance, namely, the minimal number of edit operations (delete, insert and substitute of a single symbol) required to convert one sequence to the other, is used as it reflects the traces ordering and semantics. However, the time and space complexity of the edit distance between two strings requires quadratic (in symbol numbers) complexity [1]. The traces can also be represented as a system calls graphs [2], the nodes of which are the system calls (or the items of the q-grams [1]). That is, we can consider the traces description by the ordered string as a partial case of the graph representation, for which it is possible to use the same similarity metrics with the same computational complexity. This work demonstrates a framework for combining both graph-based and probabilistic models enabling both the analysis of the system robustness to malicious attacks and malicious codes recognition and detection. © 2018, Springer International Publishing AG, part of Springer Nature.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049050544&doi=10.1007%2f978-3-319-94147-9_15&partnerID=40&md5=a147eebf4a5e4a923bdd6a5ccc7e65b3,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Nikolopoulos S.D.; Polenakis L.,A graph-based model for malicious code detection exploiting dependencies of system-call groups,"In this paper, we propose a graph-based algorithmic technique for malware detection. More precisely, we utilize the system-call dependency graphs (or, for short, ScD graphs), obtained by capturing taint analysis traces and a set of various similarity metrics in order to detect whether an unknown test sample is a malicious or a benign one. For the sake of generalization, we decide to empower our model against strong mutations by applying our detection technique on a weighted directed graph resulting from ScD graph after grouping disjoint subsets of its vertices. Additionally, we propose the Δ-Similarity metric, which is based on the Euclidean distance operating on the in-degree and out-degree of ScD's nodes along with their corresponding weights, distinguishing thus graph-representations of malware and benign software. Finally, we evaluate the potentials of our detection model and show that its performance makes it competing to other detection models. Copyright © 2015 ACM.",Conference paper,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957656012&doi=10.1145%2f2812428.2812432&partnerID=40&md5=e368cde8f8412b2ddd835d62c4d9c59b,ACM International Conference Proceeding Series,Include,,,
Azad M.A.; Morla R.,"Early identification of spammers through identity linking, social network and call features","Multiple identities are created to gain financial benefits by performing malicious activities such as spamming, committing frauds and abusing the system. A single malicious individual may have a large number of identities in order to make malicious activities to a large number of legitimate individuals. Linking identities of an individual would help in protecting the legitimate users from abuses, frauds, and maintains reputation of the service provider. Simply analyzing each identity's historical behavior is not sufficient to block spammers frequently changing identity because spammers quickly discards the identity and start using new one. Moreover, spammers may appear as a legitimate user on an initial analysis, for example because of small number of interactions from any identity. The challenge is to identify the spammer by analyzing the aggregate behavior of an individual rather than that of a single calling identity. This paper presents EIS (early identification of spammers) system for the early identification of spammers frequently changing identities. Specifically, EIS system consists of three modules and uses social call graph among identities. (1) An ID-CONNECT module that links identities that belongs to a one physical individual based on a social network structure and calling attributes of identities; (2) a reputation module that computes reputation of an individual by considering his aggregate behavior from his different identities; and (3) a detection module that computes automated threshold below which individuals are classified as a spammer or a non-spammer. We evaluate the proposed system on a synthetic data-set that has been generated for the different graph networks and different percentage of spammers. Performance analysis shows that EIS is effective against spammers frequently changing their identities and is able to achieve high true positive rate when spammers have high small overlap in target victims from their identities. © 2016 Elsevier B.V.",Article,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007454159&doi=10.1016%2fj.jocs.2016.10.019&partnerID=40&md5=02752dbd222b46ff39bc9dcc4629eed2,Journal of Computational Science,Exclude,,,
Cao S.; Sun X.; Bo L.; Wu R.; Li B.; Wu X.; Tao C.; Zhang T.; Liu W.,Learning to Detect Memory-related Vulnerabilities,"Memory-related vulnerabilities can result in performance degradation or even program crashes, constituting severe threats to the security of modern software. Despite the promising results of deep learning (DL)-based vulnerability detectors, there exist three main limitations: (1) rich contextual program semantics related to vulnerabilities have not yet been fully modeled; (2) multi-granularity vulnerability features in hierarchical code structure are still hard to be captured; and (3) heterogeneous flow information is not well utilized. To address these limitations, in this article, we propose a novel DL-based approach, called MVD+, to detect memory-related vulnerabilities at the statement-level. Specifically, it conducts both intraprocedural and interprocedural analysis to model vulnerability features, and adopts a hierarchical representation learning strategy, which performs syntax-aware neural embedding within statements and captures structured context information across statements based on a novel Flow-Sensitive Graph Neural Networks, to learn both syntactic and semantic features of vulnerable code. To demonstrate the performance, we conducted extensive experiments against eight state-of-the-art DL-based approaches as well as five well-known static analyzers on our constructed dataset with 6,879 vulnerabilities in 12 popular C/C++ applications. The experimental results confirmed that MVD+ can significantly outperform current state-of-the-art baselines and make a great trade-off between effectiveness and efficiency.  © 2023 Copyright held by the owner/author(s).",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183325353&doi=10.1145%2f3624744&partnerID=40&md5=ada411ab2849e459230c34255ab66df2,ACM Transactions on Software Engineering and Methodology,Include,,,
Wan Z.; Liu X.; Wang B.; Qiu J.; Li B.; Guo T.; Chen G.; Wang Y.,Spatio-temporal Contrastive Learning-enhanced GNNs for Session-based Recommendation,"Session-based recommendation (SBR) systems aim to utilize the user’s short-term behavior sequence to predict the next item without the detailed user profile. Most recent works try to model the user preference by treating the sessions as between-item transition graphs and utilize various graph neural networks (GNNs) to encode the representations of pair-wise relations among items and their neighbors. Some of the existing GNN-based models mainly focus on aggregating information from the view of spatial graph structure, which ignores the temporal relations within neighbors of an item during message passing and the information loss results in a sub-optimal problem. Other works embrace this challenge by incorporating additional temporal information but lack sufficient interaction between the spatial and temporal patterns. To address this issue, inspired by the uniformity and alignment properties of contrastive learning techniques, we propose a novel framework called Session-based Recommendation with Spatio-temporal Contrastive Learning-enhanced GNNs (RESTC). The idea is to supplement the GNN-based main supervised recommendation task with the temporal representation via an auxiliary cross-view contrastive learning mechanism. Furthermore, a novel global collaborative filtering graph embedding is leveraged to enhance the spatial view in the main task. Extensive experiments demonstrate the significant performance of RESTC compared with the state-of-the-art baselines. We release our source code at https://github.com/SUSTechBruce/RESTC-Source-code. © 2023 Association for Computing Machinery. All rights reserved.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181454862&doi=10.1145%2f3626091&partnerID=40&md5=1b69322692bc5cac11fe20aef6c7c7d0,ACM Transactions on Information Systems,Exclude,,,
Zeng C.; Zhou B.; Dong H.; Wu H.; Xie P.; Guan Z.,A General Source Code Vulnerability Detection Method via Ensemble of Graph Neural Networks,"Deep neural networks have been recently utilized in source code vulnerability detection methods due to their automated feature learning capabilities. However, current deep vulnerability detection models heavily rely on fixed code static analysis tools, limiting their applicability to a single programming language. Furthermore, the existing models often fail to fully extract semantic features from the source code, leading to limited generalization capabilities. To address these challenges, this paper proposes a language-agnostic code vulnerability detection framework based on ensemble of graph neural networks. Our approach considers the source program as a linear token sequence and constructs an initial graph representation by capturing the co-occurrence relationships between tokens. The model’s hidden layers leverage a combination of graph convolutional module and gated graph neural networks to extract semantic features from vulnerable code. To adaptively learn the importance of each vulnerability feature, we introduce a self-attention layer after the hidden layer. Additionally, to enhance model stability and prevent overfitting, we incorporate residual connections and flooding regularization techniques. Experimental results on real-world vulnerability datasets demonstrate our approach surpasses previous SOTA approaches by a margin of over 2.37% in terms of detection accuracy. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2024.",Conference paper,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181976167&doi=10.1007%2f978-981-99-9331-4_37&partnerID=40&md5=233bc7479f4f344bcafc23a298b5134f,Communications in Computer and Information Science,Include,,,
Pan J.-H.; Du P.-F.,SilenceREIN: seeking silencers on anchors of chromatin loops by deep graph neural networks,"Silencers are repressive cis-regulatory elements that play crucial roles in transcriptional regulation. Experimental methods for identifying silencers are always costly and time-consuming. Computational methods, which relies on genomic sequence features, have been introduced as alternative approaches. However, silencers do not have significant epigenomic signature. Therefore, we explore a new way to computationally identify silencers, by incorporating chromatin structural information. We propose the SilenceREIN method, which focuses on finding silencers on anchors of chromatin loops. By using graph neural networks, we extracted chromatin structural information from a regulatory element interaction network. SilenceREIN integrated the chromatin structural information with linear genomic signatures to find silencers. The predictive performance of SilenceREIN is comparable or better than other states-of-the-art methods. We performed a genome-wide scanning to systematically find silencers in human genome. Results suggest that silencers are widespread on anchors of chromatin loops. In addition, enrichment analysis of transcription factor binding motif support our prediction results. As far as we can tell, this is the first attempt to incorporate chromatin structural information in finding silencers. All datasets and source codes of SilenceREIN have been deposited in a GitHub repository (https://github.com/JianHPan/SilenceREIN). © 2024 Oxford University Press. All rights reserved.",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181773971&doi=10.1093%2fbib%2fbbad494&partnerID=40&md5=540ae3ebad3ef74b3a154e5146c4b86a,Briefings in Bioinformatics,Exclude,,,
Qin Y.; Gao C.; Tu Z.; Wu H.; Wei S.; Wang Y.; Zhang L.; Li Y.,Modeling Multi-Grained User Preference in Location Visitation,"Location prediction acts as a fundamental service in today's location-based information platform, which helps users access locations satisfying their demands, improving both user experience and platform profit. Since users with unambiguous demands prefer specific locations while users with compound demands consider first regions and then specific locations, it is necessary to model multi-grained user preferences at different geographical scales. However, most of the existing works concentrate on user preferences at the location-scale only, which can not understand users traveling behaviors thoroughly. In this paper, we propose to model both the fine-grained user preferences at the location scale and the coarsegrained user preferences at the region scale. Specifically, the proposed model harnesses the efficient information extraction power of graph neural networks. Moreover, the proposed geographical calibration method also helps to capture multi-grained user preferences accurately. Experiments on datasets of two very large cities demonstrate the significant performance improvement using our approach over state-of-the-art models. We also conduct experiments to further demonstrate the effectiveness of each component in the proposed model. Source codes of this paper are available at https://github.com/tsinghua-fib-lab/SIGSPATIAL-MMGUP/.  © 2023 Owner/Author(s).",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182515926&doi=10.1145%2f3589132.3625628&partnerID=40&md5=d728390e20c9c21e5914731502b52f66,GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems,Exclude,,,
Jia T.; Li J.; Zhuo L.; Zhang J.,Self-guided disentangled representation learning for single image dehazing,"Image dehazing has received extensive research attention as images collected in hazy weather are limited by low visibility and information dropout. Recently, disentangled representation learning has made excellent progress in various vision tasks. However, existing networks for low-level vision tasks lack efficient feature interaction and delivery mechanisms in the disentanglement process or an evaluation mechanism for the degree of decoupling in the reconstruction process, rendering direct application to image dehazing challenging. We propose a self-guided disentangled representation learning (SGDRL) algorithm with a self-guided disentangled network to realize multi-level progressive feature decoupling through sharing and interaction. The self-guided disentangled (SGD) network extracts image features using the multi-layer backbone network, and attribute features are weighted using the self-guided attention mechanism for the backbone features. In addition, we introduce a disentanglement-guided (DG) module to evaluate the degree of feature decomposition and guide the feature fusion process in the reconstruction stage. Accordingly, we develop SGDRL-based unsupervised and semi-supervised single image dehazing networks. Extensive experiments demonstrate the superiority of the proposed method for real-world image dehazing. The source code is available at https://github.com/dehazing/SGDRL. © 2024 Elsevier Ltd",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182402898&doi=10.1016%2fj.neunet.2024.106107&partnerID=40&md5=bc5384beb8d0a216d234c33b8ad085df,Neural Networks,Exclude,,,
Zhao Q.; Yang F.; An D.; Lian J.,Modeling Structured Dependency Tree with Graph Convolutional Networks for Aspect-Level Sentiment Classification,"Aspect-based sentiment analysis is a fine-grained task where the key goal is to predict sentiment polarities of one or more aspects in a given sentence. Currently, graph neural network models built upon dependency trees are widely employed for aspect-based sentiment analysis tasks. However, most existing models still contain a large amount of noisy nodes that cannot precisely capture the contextual relationships between specific aspects. Meanwhile, most studies do not consider the connections between nodes without direct dependency edges but play critical roles in determining the sentiment polarity of an aspect. To address the aforementioned limitations, we propose a Structured Dependency Tree-based Graph Convolutional Network (SDTGCN) model. Specifically, we explore construction of a structured syntactic dependency graph by incorporating positional information, sentiment commonsense knowledge, part-of-speech tags, syntactic dependency distances, etc., to assign arbitrary edge weights between nodes. This enhances the connections between aspect nodes and pivotal words while weakening irrelevant node links, enabling the model to sufficiently express sentiment dependencies between specific aspects and contextual information. We utilize part-of-speech tags and dependency distances to discover relationships between pivotal nodes without direct dependencies. Finally, we aggregate node information by fully considering their importance to obtain precise aspect representations. Experimental results on five publicly available datasets demonstrate the superiority of our proposed model over state-of-the-art approaches; furthermore, the accuracy and F1-score show a significant improvement on the majority of datasets, with increases of 0.74, 0.37, 0.65, and 0.79, 0.75, 1.17, respectively. This series of enhancements highlights the effective progress made by the STDGCN model in enhancing sentiment classification performance. © 2024 by the authors.",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183155929&doi=10.3390%2fs24020418&partnerID=40&md5=92b78186e74d04f62898ce8256733625,Sensors,Exclude,,Exclude,
Tu W.; Xiao B.; Liu X.; Zhou S.; Cai Z.; Cheng J.,Revisiting Initializing Then Refining: An Incomplete and Missing Graph Imputation Network,"With the development of various applications, such as recommendation systems and social network analysis, graph data have been ubiquitous in the real world. However, graphs usually suffer from being absent during data collection due to copyright restrictions or privacy-protecting policies. The graph absence could be roughly grouped into attribute-incomplete and attribute-missing cases. Specifically, attribute-incomplete indicates that a portion of the attribute vectors of all nodes are incomplete, while attribute-missing indicates that all attribute vectors of partial nodes are missing. Although various graph imputation methods have been proposed, none of them is custom-designed for a common situation where both types of graph absence exist simultaneously. To fill this gap, we develop a novel graph imputation network termed revisiting initializing then refining (RITR), where both attribute-incomplete and attribute-missing samples are completed under the guidance of a novel initializing-then-refining imputation criterion. Specifically, to complete attribute-incomplete samples, we first initialize the incomplete attributes using Gaussian noise before network learning, and then introduce a structure-attribute consistency constraint to refine incomplete values by approximating a structure-attribute correlation matrix to a high-order structure matrix. To complete attribute-missing samples, we first adopt structure embeddings of attribute-missing samples as the embedding initialization, and then refine these initial values by adaptively aggregating the reliable information of attribute-incomplete samples according to a dynamic affinity structure. To the best of our knowledge, this newly designed method is the first end-to-end unsupervised framework dedicated to handling hybrid-absent graphs. Extensive experiments on six datasets have verified that our methods consistently outperform the existing state-of-the-art competitors. Our source code is available at https://github.com/WxTu/RITR. IEEE",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182948522&doi=10.1109%2fTNNLS.2024.3349850&partnerID=40&md5=3a25177aed79bf446d89347acfa67f54,IEEE Transactions on Neural Networks and Learning Systems,Exclude,,,
An P.; Zhu D.; Quan S.; Ding J.; Ma J.; Yang Y.; Liu Q.,ESC-Net: Alleviating Triple Sparsity on 3D LiDAR Point Clouds for Extreme Sparse Scene Completion,"3D scene completion (SC) has made progress in the last three years. From the application of mobile robot system, SC should support the downstream task (i.e. mapping or perception), instead of only predicting the completed scenes. However, as the low-cost few-beam LiDAR is widely applied in mobile robot, gap between SC and downstream tasks is large. To generate the high quality completion result, the bottleneck lies in the triple sparsity of input, ground truth (GT) occupancy, and GT foreground. To deal with the triple sparsity, we present an extreme sparse scene completion network (ESC-Net). At first, input sparsity hides most of the spatial information of the scene. A feature completion (FC) decoder is designed to mine the spatial feature using feature-level completion. Then, GT occupancy sparsity hinders representation learning of the real scene with continuous surfaces. A multi-view multi-task attention (MMA) loss is presented to recover the high-quality object boundaries via correcting occupancy and semantic labels of regions from 3D and bird&#x0027;s eye view (BEV) spaces. After that, GT foreground sparsity is the imbalance of foreground and background GT labels. It causes the inaccuracy of local 3D object completion. A combination network (ESC-Net-D) is presented to recover 3D structural details of both foreground and background. Experiment is conducted on KITTI and SemanticPOSS datasets. It shows that ESC-Net has the performance higher than current methods not only on completion task, but also on the downstream tasks (i.e. 3D registration, 3D object detection). Hence, we believe that ESC-Net benefits to the community of mobile robot. Source code is released soon. IEEE",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182932006&doi=10.1109%2fTMM.2024.3355647&partnerID=40&md5=4daf9c624e391e1e2150c170a98c207b,IEEE Transactions on Multimedia,Exclude,,,
Germán Márquez A.; Varela-Vaca Á.J.; Gómez López M.T.; Galindo J.A.; Benavides D.,Vulnerability impact analysis in software project dependencies based on Satisfiability Modulo Theories (SMT),"Software development projects are built on top of external libraries and tools that help manage code and databases and/or facilitate deployment. The external libraries that assist in these tasks create dependent relations with the developed software, thereby increasing the use of dependencies as a common practice. There exist mechanisms in the projects to set up software dependencies in terms of versions and restrictions between said projects. However, any problem, error, or vulnerability affecting a software's configuration dependencies can render the whole project vulnerable. This turns a secure dependency into an insecure dependency, and hinders the maintenance of security in software development projects, since current tools do not cover all possible configurations of dependencies. In this paper, our approach that enables the analysis and inference of the configuration of dependencies of projects in terms of potentially vulnerable configurations. The proposal is developed by constructing a dependency graph network attributed to vulnerabilities. Formal models are integrated based on Satisfiability Modulo Theories (SMT) to enable automatic analysis, such as the identification of the most secure configuration of dependencies. The automatic analysis facilitates ascertaining the vulnerability-free configurations of dependencies with maximum and minimum vulnerability impacts. This proposal has been evaluated by analysing more than 140 Python open-source code repositories and better results than other proposals have been achieved. © 2023 The Author(s)",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182635943&doi=10.1016%2fj.cose.2023.103669&partnerID=40&md5=834224e767b5bba537bc8f8ced49d010,Computers and Security,Include,,Include,
Zhou D.; Wu Y.; Peng X.; Zhang J.; Li Z.,Revealing code change propagation channels by evolution history mining,"Changes on source code may propagate to distant code entities through various kinds of relationships, which may form up change propagation channels. It is however difficult for developers to reveal code change propagate channels due to sophisticated interrelationships among code entities. In this work, we propose a novel graph representation for the changed code entities and related code entities changed within a range of space and time so that the types of relationships along which the changes are propagated can be explicitly presented. Then a subgraph mining technique is used to find the frequent change propagation channels. We finally reveal 40 types of frequent change propagation channels that cover over 98% cases of code change propagation in five well-known open-source Java projects. We find evidence that the code changes propagated through an unchanged intermediate code entity consume more time than those through a changed one, indicating the difficulties in maintaining code entities that related through indirect relationships. We find that a small proportion of code entities frequently appear in the FCPCs, and confirm the semantic relationships between code entities covered by 50 instances of FCPCs, indicating potential usefulness for developers to explain the range of change impact from given source code changes. © 2023 Elsevier Inc.",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182227254&doi=10.1016%2fj.jss.2023.111912&partnerID=40&md5=dea6dc9ea39b04ebffd934c96940f2bd,Journal of Systems and Software,Include,,,
Liu Y.; Li D.; Wang J.; Li B.; Hang B.,MDLR: A Multi-Task Disentangled Learning Representations for unsupervised time series domain adaptation,"Unsupervised Time Series Domain Adaptation (UTSDA) is a method for transferring information from a labeled source domain to an unlabeled target domain. The majority of existing UTSDA approaches focus on learning a domain-invariant feature space by reducing the gap between domains. However, the single-task representation learning methods have limited expressive capability, while ignoring the distinctive season-related and trend-related domain-invariant mechanisms across different domains. To address this, we introduce a novel approach, distinct from existing methods, through a theoretical analysis of UTSDA from the perspective of causal inference. This analysis establishes a solid theoretical foundation for identifying and modeling such consistent domain-invariant mechanisms, which is a significant advancement in the field. As a solution, we introduce MDLR, a multi-task disentangled learning framework designed for UTSDA. MDLR utilizes a dual-tower architecture with a trend feature extractor (TFE) and a season feature extractor (SFE) to extract trend-related and season-related information. This approach ensures that domain-invariant features at different scales can be better represented. Additionally, MDLR is designed with two tasks: a label classifier and a domain classifier, enabling iterative training of the entire model. The experiments conducted on three datasets, namely UCIHAR, WISDM, and HHAR_SA, along with visualization results, have shown the effectiveness of the proposed approach. The source code for our MDLR model is available to the public at https://github.com/MoranCoder95/MDLR/. © 2024 Elsevier Ltd",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182027073&doi=10.1016%2fj.ipm.2023.103638&partnerID=40&md5=a440f8de5321778ab1ae9423b7b0dfe2,Information Processing and Management,Exclude,,,
Liu C.; Li R.; Chen S.; Zheng L.; Jiang D.,Adaptive dual graph regularization for clustered multi-task learning,"The key challenge of multi-task learning is how to exploit the structure across all tasks. In practice, relevant tasks are partially associated with similar meaningful feature subgroups, which implies an overlapped task-feature co-cluster structure. Besides discovering relationships at the task level, collaboratively identifying relevant meaningful structure relationship among features is beneficial to properly capture the structure of tasks. Toward this aim, we propose a clustered multi-task learning approach that collaboratively learns the cluster structure for both task and feature level effects. Specifically, an adaptive dual graph regularization, which respectively formulates the similarity of tasks and features, is introduced to guide the learning process to discover task-feature co-cluster relationship in a flexible way. Additionally, without any prior knowledge, the similarity weight of dual graph regularization can be automatically inferred through adaptive graph learning during model training. Experimental studies validate the effectiveness of our approach in terms of improving predictive performance and capturing clear cluster structure among tasks. The source code of the proposed method is available at GitHub: https://github.com/CLiu272/AdualGraph. © 2024 Elsevier B.V.",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183147141&doi=10.1016%2fj.neucom.2024.127259&partnerID=40&md5=8c9de255da1efeaa3230a5aee679e3b9,Neurocomputing,Exclude,,,
Ling Y.; Chen J.; Ren Y.; Pu X.; Xu J.; Zhu X.; He L.,Dual Label-Guided Graph Refinement for Multi-View Graph Clustering,"With the increase of multi-view graph data, multi-view graph clustering (MVGC) that can discover the hidden clusters without label supervision has attracted growing attention from researchers. Existing MVGC methods are often sensitive to the given graphs, especially influenced by the low quality graphs, i.e., they tend to be limited by the homophily assumption. However, the widespread real-world data hardly satisfy the homophily assumption. This gap limits the performance of existing MVGC methods on low homophilous graphs. To mitigate this limitation, our motivation is to extract high-level view-common information which is used to refine each view’s graph, and reduce the influence of non-homophilous edges. To this end, we propose dual label-guided graph refinement for multi-view graph clustering (DuaLGR), to alleviate the vulnerability in facing low homophilous graphs. Specifically, DuaLGR consists of two modules named dual label-guided graph refinement module and graph encoder module. The first module is designed to extract the soft label from node features and graphs, and then learn a refinement matrix. In cooperation with the pseudo label from the second module, these graphs are refined and aggregated adaptively with different orders. Subsequently, a consensus graph can be generated in the guidance of the pseudo label. Finally, the graph encoder module encodes the consensus graph along with node features to produce the high-level pseudo label for iteratively clustering. The experimental results show the superior performance on coping with low homophilous graph data. The source code for DuaLGR is available at https://github.com/YwL-zhufeng/DuaLGR. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168244800&partnerID=40&md5=906b092e250ecbf5e4c2b22dc9a1a7f9,"Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",Exclude,,Exclude,
Liu Y.; Yang X.; Zhou S.; Liu X.; Wang Z.; Liang K.; Tu W.; Li L.; Duan J.; Chen C.,Hard Sample Aware Network for Contrastive Deep Graph Clustering,"Contrastive deep graph clustering, which aims to divide nodes into disjoint groups via contrastive mechanisms, is a challenging research spot. Among the recent works, hard sample mining-based algorithms have achieved great attention for their promising performance. However, we find that the existing hard sample mining methods have two problems as follows. 1) In the hardness measurement, the important structural information is overlooked for similarity calculation, degrading the representativeness of the selected hard negative samples. 2) Previous works merely focus on the hard negative sample pairs while neglecting the hard positive sample pairs. Nevertheless, samples within the same cluster but with low similarity should also be carefully learned. To solve the problems, we propose a novel contrastive deep graph clustering method dubbed Hard Sample Aware Network (HSAN) by introducing a comprehensive similarity measure criterion and a general dynamic sample weighing strategy. Concretely, in our algorithm, the similarities between samples are calculated by considering both the attribute embeddings and the structure embeddings, better revealing sample relationships and assisting hardness measurement. Moreover, under the guidance of the carefully collected high-confidence clustering information, our proposed weight modulating function will first recognize the positive and negative samples and then dynamically up-weight the hard sample pairs while down-weighting the easy ones. In this way, our method can mine not only the hard negative samples but also the hard positive sample, thus improving the discriminative capability of the samples further. Extensive experiments and analyses demonstrate the superiority and effectiveness of our proposed method. The source code of HSAN is shared at https://github.com/yueliu1999/HSAN and a collection (papers, codes and, datasets) of deep graph clustering is shared at https://github.com/yueliu1999/Awesome-DeepGraph-Clustering on Github. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167965918&partnerID=40&md5=e9aaabbcaa24af1d4166d0ca857b5583,"Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",Exclude,,,
Chen N.; Sun Q.; Wang J.; Li X.; Gao M.,Pass-Tuning: Towards Structure-Aware Parameter-Efficient Tuning for Code Representation Learning,"Code pre-trained models (CodePTMs) have recently become the de-facto paradigm for various tasks in the domain of code intelligence. To achieve excellent performance, the widely used strategy is to fine-tune all the parameters of CodePTMs. However, as the model size increases along with the number of downstream tasks, this strategy becomes excessively expensive. There are also some prior works that utilize Parameter-Efficient Learning (PEL) methods for model tuning in natural language processing to mitigate similar problems, but applying them directly to CodePTMs fails to capture the inherent structural characteristics of codes. To address the problem, in this paper, we propose Pass-Tuning for structure-aware Parameter-Efficient code representation learning. Specifically, a plug-and-play graph neural network module that can learn from Abstract Syntax Tree (AST) is employed as a tunable prefix. On the one hand, Pass-Tuning can further exploit the structural information of source code. On the other hand, it could serve as a replacement for full fine-tuning. We evaluate our method on multiple tasks across eight programming languages, including code understanding and generation. These results demonstrate the effectiveness, robustness, and universality of our method. Our codes and resources are available at https://github.com/nchen909/Pass-Tuning. © 2023 Association for Computational Linguistics.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183291258&partnerID=40&md5=130096fe208ad4c87992e14275cc752b,Findings of the Association for Computational Linguistics: EMNLP 2023,Include,,,
Wang R.; Xu Y.; Wu Y.,Python Open-Source Code Traceability Model Based on Graph Neural Networks,"When programmers write project code, they may copy or reference some open-source code, which may include defective code, causing vulnerabilities in the project. This causes a potential threat to the project and threatens the security of the software supply chain. Therefore, to protect the code security, the Python open-source code traceability model based on graph neural networks is proposed to calculate the similarity between the programmers' Python code and the Python open-source code. Firstly, each function in Python code is parsed into one Type Abstract Syntax Tree. Secondly, graph neural networks are used to calculate the function similarity between the two Type Abstract Syntax Trees of the original code and open-source code. Thirdly, the overall similarity of a Python project that consists of many functions is calculated based on the function similarity following the maximum retention principle. The experiment was conducted on three datasets: StudentWork, GitDown, and Obfuscated-GitDown. The experiment shows that the results calculated by our model are more reasonable, which places more emphasis on similarity in code structure than on code text. Taking the Pyobfuscate obfuscation scenario as an example, our model considering code structure gets similarity 18.12%39.54% higher than other methods that calculate similarity based on the code text.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182602964&doi=10.1109%2fDASC%2fPiCom%2fCBDCom%2fCy59711.2023.10361385&partnerID=40&md5=27f6abcf2cadb5d3996750d3f7c403bc,"2023 IEEE International Conference on Dependable, Autonomic and Secure Computing, International Conference on Pervasive Intelligence and Computing, International Conference on Cloud and Big Data Computing, International Conference on Cyber Science and Technology Congress, DASC/PiCom/CBDCom/CyberSciTech 2023",Include,,,
Wen X.; Gao C.; Ye J.; Li Y.; Tian Z.; Jia Y.; Wang X.,Meta-Path Based Attentional Graph Learning Model for Vulnerability Detection,"In recent years, deep learning (DL)-based methods have been widely used in code vulnerability detection. The DL-based methods typically extract structural information from source code, e.g., code structure graph, and adopt neural networks such as Graph Neural Networks (GNNs) to learn the graph representations. However, these methods fail to consider the heterogeneous relations in the code structure graph, i.e., the heterogeneous relations mean that the different types of edges connect different types of nodes in the graph, which may obstruct the graph representation learning. Besides, these methods are limited in capturing long-range dependencies due to the deep levels in the code structure graph. In this paper, we propose a <bold>M</bold>eta-path based <bold>A</bold>ttentional <bold>G</bold>raph learning model for code vul<bold>NE</bold>rability de<bold>T</bold>ection, called <bold>MAGNET</bold>. MAGNET constructs a multi-granularity meta-path graph for each code snippet, in which the heterogeneous relations are denoted as meta-paths to represent the structural information. A meta-path based hierarchical attentional graph neural network is also proposed to capture the relations between distant nodes in the graph. We evaluate MAGNET on three public datasets and the results show that MAGNET outperforms the best baseline method in terms of F1 score by 6.32&#x0025;, 21.50&#x0025;, and 25.40&#x0025;, respectively. MAGNET also achieves the best performance among all the baseline methods in detecting Top-25 most dangerous Common Weakness Enumerations (CWEs), further demonstrating its effectiveness in vulnerability detection. IEEE",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181565485&doi=10.1109%2fTSE.2023.3340267&partnerID=40&md5=9c9216204be8bcbf11c14281c7e7a27f,IEEE Transactions on Software Engineering,Include,,Include,
Huang J.; Ji Y.; Qin Z.; Yang Y.; Shen H.T.,Dominant SIngle-Modal SUpplementary Fusion (SIMSUF) For Multimodal Sentiment Analysis,"Multimodal sentiment analysis remains a big challenge due to the lack of effective fusion solutions. An effective fusion is expected to obtain the correct semantic representation for all modalities, and simultaneously thoroughly explore the contribution of each modality. In this paper, we propose a dominant SIngle-Modal SUpplementary Fusion (SIMSUF) approach to perform effective multimodal fusion for sentiment analysis. The SIMSUF is composed of three major components, a dominant modality supplementary module, a modality enhancement module, and a multimodal fusion module. The dominant modality supplementary module realizes dominant modality determination by estimating mutual dependence between every two modalities, and then the dominant modality is adopted to supplement other modalities for representative feature learning. To further explore the modality contribution, we propose a two-branch modality enhancement module, where one branch learns common representation distribution for multiple modalities, and simultaneously a specific modality enhancement branch is presented to perform semantic difference enhancement and distribution difference enhancement for each modality. Finally, a dominant modality leading fusion module is designed to fuse multimodal representations of two branches for sentiment analysis. Extensive experiments are evaluated on the CMU-MOSEI and CMU-MOSI datasets. Experiment results certify that our approach is superior to the state-of-the-art approaches. The source code of this work is available at <uri>https://github.com/HumanCenteredUndestanding/SIMSUF</uri>. IEEE",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181571514&doi=10.1109%2fTMM.2023.3344358&partnerID=40&md5=24252570464be7c35f012843bc23dc5e,IEEE Transactions on Multimedia,Exclude,,,
Wang C.; Wu Y.; Zhang X.,Mucha: Multi-channel based Code Change Representation Learning for Commit Message Generation,"Commit messages provide a natural language description of the changes made to the code, enabling developers to swiftly comprehend the alterations without delving into the implementation complexities. Nevertheless, generating commit messages faces a considerable challenge due to the semantic and structural differences between code and natural language. Several researchers have put forward automated techniques aimed at generating commit messages. However, the full potential of code-related information is not yet fully harnessed. In this paper, we propose a Multi-channel based Code Change Representation Learning for Commit Message Generation(Mucha). We first compare the changed code and the corresponding AST before and after the change. Subsequently, we extract the altered information from various granularities and employ a multi-channel approach to capture the code changes, utilizing the extracted information as the basis for our analysis. In addition, we also use the query mechanism and attention mechanism to assist in learning the final code change representation. We build the experimental dataset, since there is still no publicly sufficient dataset for this task. The release of this dataset would serve as a valuable contribution towards advancing research in this particular field. We conduct a comprehensive experiment to assess the effectiveness of Mucha. The experimental evaluation demonstrates that our model outperforms the baseline model, which has significant improvements of at least 18.2%, 72.2%, and 10.5% against the baselines.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182507690&doi=10.1109%2fQRS60937.2023.00064&partnerID=40&md5=845c2223544b004371822a6c9fe2a50c,"IEEE International Conference on Software Quality, Reliability and Security, QRS",Include,,,
Zhou X.; Xu B.; Han D.; Yang Z.; He J.; Lo D.,CCBERT: Self-Supervised Code Change Representation Learning,"Numerous code changes are made by developers in their daily work, and a superior representation of code changes is desired for effective code change analysis. Recently, Hoang et al. proposed CC2Vec, a neural network-based approach that learns a distributed representation of code changes to capture the semantic intent of the changes. Despite demonstrated effectiveness in multiple tasks, CC2Vec has several limitations: 1) it considers only coarse-grained information about code changes, and 2) it relies on log messages rather than the self-contained content of the code changes. In this work, we propose CCBERT (Code Change BERT), a new Transformer-based pre-trained model that learns a generic representation of code changes based on a large-scale dataset containing massive unlabeled code changes. CCBERT is pre-trained on four proposed self-supervised objectives that are specialized for learning code change representations based on the contents of code changes. CCBERT perceives fine-grained code changes at the token level by learning from the old and new versions of the content, along with the edit actions. Our experiments demonstrate that CCBERT significantly outperforms CC2Vec or the state-of-the-art approaches of the downstream tasks by 7.7%-14.0% in terms of different metrics and tasks. CCBERT consistently outperforms large pre-trained code models, such as CodeBERT, while requiring 6-10× less training time, 5-30× less inference time, and 7.9× less GPU memory. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177641047&doi=10.1109%2fICSME58846.2023.00028&partnerID=40&md5=cd662d4955dede8fb29162f6bd7cc22b,"Proceedings - 2023 IEEE International Conference on Software Maintenance and Evolution, ICSME 2023",Include,,Include,
Zhang Z.; Liu L.; Chang J.; Wang L.; Liao L.,Commit Classification via Diff-Code GCN based on System Dependency Graph,"Commit Classification, an automated process of classifying Diff-Code based on their purpose, plays a crucial role in enhancing comprehension and the quality of software. Some previous studies only used commit messages or code metrics to represent diff-code but lacked code context structure characterization. Alternatively, other studies have used Abstract Syntax Trees (ASTs) tokens to represent diff-code but did not consider contextual information like data dependency and control dependency. In this paper, we propose a new commit classification model called Diff-Code GCN (Graph Convolutional Network). Specifically, we firstly build a more detailed system dependency graph (SDG) of the commit, and secondly use program slicing to search the impact scope of diff-code. Thirdly, we extract the scope as a Change Impact Graph (CIG). We utilize GCN to extract contextual information from CIG and combine it with syntactic changed information of ASTs to represent the commit. Finally, we classify the commit into three maintenance categories (corrective, perfective, and adaptive). We evaluate our model based on commonly used datasets and compare our model with popular commit classification approaches. The experiment result well shows that both in within-project and cross-project prediction tasks, our model performs better than baseline models.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182520712&doi=10.1109%2fQRS60937.2023.00053&partnerID=40&md5=eaee00d90d1ca5c9b7f9598b67000bfb,"IEEE International Conference on Software Quality, Reliability and Security, QRS",Include,,,
Wang Z.; Shang J.,Towards Zero-shot Relation Extraction in Web Mining: A Multimodal Approach with Relative XML Path,"The rapid growth of web pages and the increasing complexity of their structure poses a challenge for web mining models. Web mining models are required to understand semi-structured web pages, particularly when little is known about the subject or template of a new page. Current methods migrate language models to web mining by embedding the XML source code into the transformer or encoding the rendered layout with graph neural networks. However, these approaches do not take into account the relationships between text nodes within and across pages. In this paper, we propose a new approach, ReXMiner, for zero-shot relation extraction in web mining. ReXMiner encodes the shortest relative paths in the Document Object Model (DOM) tree of the web page which is a more accurate and efficient signal for key-value pair extraction within a web page. It also incorporates the popularity of each text node by counting the occurrence of the same text node across different web pages. We use contrastive learning to address the issue of sparsity in relation extraction. Extensive experiments on public benchmarks show that our method, ReXMiner, outperforms the state-of-the-art baselines in the task of zero-shot relation extraction in web mining. © 2023 Association for Computational Linguistics.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183295495&partnerID=40&md5=56e4c2a4c87f5bdb57ecd45a12af161b,Findings of the Association for Computational Linguistics: EMNLP 2023,Exclude,,,
Jiang J.; Li P.; Lv X.; Yang Y.,DMCL: Robot Autonomous Navigation via Depth Image Masked Contrastive Learning,"Achieving high performance in deep reinforcement learning relies heavily on the ability to obtain good state representations from pixel inputs. However, learning an observation-space-to-action-space mapping from high-dimensional inputs is challenging in reinforcement learning, particularly when dealing with consecutive depth images as input states. In addition, we observe that the consecutive inputs of depth images are highly correlated for the autonomous navigation of a mobile robot, which inspires us to capture temporal correlations between consecutive inputs and infer scene change relationships. To this end, we propose a novel end-to-end robot vision navigation method dubbed DMCL, which obtains good spatial-temporal state representation via Depth image Masked Contrastive Learning. It reconstructs the latent representation from consecutive depth images masked in both spatial and temporal dimensions, resulting in a complete environment state representation. To obtain the optimal navigation policy, we leverage the Soft Actor-Critic reinforcement learning in conjunction with the above representation learning. Extensive experiments demonstrate that the proposed DMCL outperforms representative state-of-the-art methods. The source code will be made publicly available. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182526208&doi=10.1109%2fIROS55552.2023.10341836&partnerID=40&md5=92c4ba3f01574dd714cbc560b5a70836,IEEE International Conference on Intelligent Robots and Systems,Exclude,,,
Bahrehvar M.; Moshirpour M.,Agile Teaching: Automated Student Support and Feedback Generation,"The software engineering industry prioritizes efficiency through the use of tools and processes such as version control and Agile methodologies. Automation has allowed developers to be more productive and deliver superior results. However, automation is not as widespread in software engineering education. To improve educational outcomes and provide more effective feedback to students, this research implements software engineering methods and automation techniques in software engineering education and evaluates their effectiveness. Our focus is on establishing a connection between source code and natural language, allowing us to generate a natural language description from a given source code sample. To generate feedback, we employ deep learning models to learn code representations and gain a deeper understanding of code. However, the complexity of code makes it challenging to learn its representation accurately. After learning about code, we compare students' code with the instructor-provided solution based on configurable thresholds and generate comments to provide guidance. This work extends the Transformer model, GraphCodeBERT, which is a pre-trained model for programming languages that incorporates the inherent structure of code. We utilize both syntax-level information, such as abstract syntax trees, and semantic-level information, such as data flow, during pre-training. The data flow graph has nodes representing variables and edges indicating the 'where-the-value-comes-from' relationship between variables. Our model is based on the Transformer neural architecture and uses a gated graph neural network model to learn code embeddings. This function incorporates code structure, a copy mechanism, and relative position representations, allowing the model to better understand the semantics of code. We evaluated our approach on the Java dataset in terms of BLEU, METEOR, and ROUGE-L metrics and compared it with the state-of-the-art code comment generation model, GTrans. Our model demonstrated improvements in two metrics of METEOR and ROUGE-L. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182996856&doi=10.1109%2fFIE58773.2023.10343212&partnerID=40&md5=d3e308ef7df40a1e0f115e8dcd2217d9,"Proceedings - Frontiers in Education Conference, FIE",Exclude,,Include,
Jin Y.; Huan C.; Zhang H.; Liu Y.; Song S.L.; Zhao R.; Zhang Y.; He C.; Chen W.,G-Sparse: Compiler-Driven Acceleration for Generalized Sparse Computation for Graph Neural Networks on Modern GPUs,"Graph Neural Network (GNN) learning over non-Euclidean graph data has recently drawn a rapid increase of interest in many domains. Generalized sparse computation is crucial for maximizing the performance of GNN learning, while most recent GNNs primarily focused on optimizing coarse-grained parallelism associated with nodes, edges, and additional feature dimensions. However, efficiently implementing generalized sparse computation is challenging. The performance optimization of generalized sparse computation lacking in-depth architecture-aware design is seldom supported by existing Domain-Specific Languages (DSLs) and is hard to be tuned by experts, which involves substantial trial and error. In this work, we propose G-Sparse, a new compiler framework that extends the popular Halide compiler to enable effective acceleration for generalized sparse computations for GNNs through compiler-driven optimizations and auto-tuning. To facilitate generalized sparse computations, G-Sparse separates algorithms from schedules and introduces several novel sparse computation optimization techniques for modern GPUs, including two-dimensional shared memory optimizations and efficient cost-driven design space exploration and auto-tuning. Extensive evaluation against highly-optimized state-of-the-art sparse computation kernels and on end-to-end GNN training and inference efficiency has demonstrated that our proposed G-Sparse achieves up to a 4.75× speedup over the state-of-the-art sparse kernels, and a training and inference speedup of 1.37×∼ 2.25× over three popular GNN frameworks including GCN, GraphSAGE, and GAT. The source code of G-Sparse is publicly available at https://github.com/TuGraph-family/tugraph-db/tree/master/learn.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182605297&doi=10.1109%2fPACT58117.2023.00020&partnerID=40&md5=3cce4edcc603cccd118205307b9cee2b,"Parallel Architectures and Compilation Techniques - Conference Proceedings, PACT",Exclude,,,
Wang J.; Le X.; Peng X.; Chen C.,Adaptive Hinge Balance Loss for Document-Level Relation Extraction,"Document-Level Relation Extraction aims at predicting relations between entities from multiple sentences. A common practice is to select multi-label classification thresholds to decide whether a relation exists between an entity pair. However, in the document-level task, most entity pairs do not express any relations, resulting in a highly imbalanced distribution between positive and negative classes. We argue that the imbalance problem affects threshold selection and may lead to incorrect ""no-relation"" predictions. In this paper, we propose to down-weight the easy negatives by utilizing a distance between the classification threshold and the predicted score of each relation. Our novel Adaptive Hinge Balance Loss measures the difficulty of each relation class with the distance, putting more focus on hard, misclassified relations, i.e. the minority positive relations. Experiment results on Re-DocRED demonstrate the superiority of our approach over other balancing methods. Source codes are available at https://github.com/Jize-W/HingeABL. © 2023 Association for Computational Linguistics.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183298586&partnerID=40&md5=7995ec9e27c462ee891aabf007e3c380,Findings of the Association for Computational Linguistics: EMNLP 2023,Exclude,,,
Hong J.W.; Na M.G.,Anomaly Detection Using Graph Neural Network in Nuclear Power Plants,"In nuclear power plants (NPPs), accidents can occur due to a variety of causes. When an anomaly occurs, the operator needs to identify the cause of the accident and take appropriate actions. If operators do not act quickly, severe accident beyond the control area can occur. Therefore, it is essential to ensure safety by minimizing risks. Detecting anomalies quickly is important for maintaining the integrity of NPPs. Recently, research using artificial intelligence (AI) to detect anomalies in NPPs has been actively conducted. However, existing AI cannot figure out the relationship between data, so it uses data independently. This does not reflect the characteristics of NPPs. The components of NPPs are not completely independent. If one component fails, it affects other components as well. Therefore, it is necessary to understand the correlation between components. Graph neural network (GNN) is an artificial neural network for processing data represented by graphs. A graph is a data composed of points and lines, and points are defined by connections with neighboring points. That is, related points are connected by lines and displayed as graph data. Through this, GNN also learns the correlation between data. This study proposes anomaly detection of NPPs using GNN as part of basic research. © 2023 American Nuclear Society, Incorporated.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183325970&doi=10.13182%2fNPICHMIT23-41096&partnerID=40&md5=b1c834b2f69ba3b88b7548ef63750f8f,"Proceedings of 13th Nuclear Plant Instrumentation, Control and Human-Machine Interface Technologies, NPIC and HMIT 2023",Exclude,,Exclude,
Chhipa P.C.; Rodahl Holmgren J.; De K.; Saini R.; Liwicki M.,Can Self-Supervised Representation Learning Methods Withstand Distribution Shifts and Corruptions?,"Self-supervised representation learning (SSL) in computer vision aims to leverage the inherent structure and relationships within data to learn meaningful representations without explicit human annotation, enabling a holistic understanding of visual scenes. Robustness in vision machine learning ensures reliable and consistent performance, enhancing generalization, adaptability, and resistance to noise, variations, and adversarial attacks. Self-supervised representation learning paradigms, namely contrastive learning, knowledge distillation, mutual information maximization, and clustering, have been considered to have shown advances in invariant learning representations. This work investigates the robustness of learned representations of SSL approaches focusing on distribution shifts and image corruptions in computer vision. Detailed experiments have been conducted to study the robustness of SSL methods on distribution shifts and image corruptions. The empirical analysis demonstrates a clear relationship between the performance of learned representations within SSL paradigms and the severity of distribution shifts and corruptions. Notably, higher levels of shifts and corruptions are found to significantly diminish the robustness of the learned representations. These findings highlight the critical impact of distribution shifts and image corruptions on the performance and resilience of SSL methods, emphasizing the need for effective strategies to mitigate their adverse effects. The study strongly advocates for future research in the field of self-supervised representation learning to prioritize the key aspects of safety and robustness in order to ensure practical applicability. The source code and results are available on GitHub. 1 © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182928560&doi=10.1109%2fICCVW60793.2023.00481&partnerID=40&md5=2a7583a14f25bd9781a8beb0115dbca8,"Proceedings - 2023 IEEE/CVF International Conference on Computer Vision Workshops, ICCVW 2023",Exclude,,Exclude,
Jia N.,ASLEEP: A Shallow neural modEl for knowlEdge graph comPletion,"Knowledge graph completion aims to predict missing relations between entities in a knowledge graph. One of the effective ways for knowledge graph completion is knowledge graph embedding. However, existing embedding methods usually focus on combined models, variant deep neural networks, or additional information, which inevitably increase computational complexity and are unfriendly to real-time applications. In this paper, we take a step back and propose a novel shallow neural network model for knowledge graph completion. Specifically, given an entity pair, our model first extracts features of head and tail entities through linear transformations. Then entity features are integrated into an entity-pair representation via a max operation followed by a non-linear transformation. Finally, according to the entity-pair representation, our model calculates probability of each relation through multi-label modeling to predict relations for the given entity pair. Experimental results over two widely used datasets show that our model outperforms the baseline methods. The source code of this paper can be obtained from https://github.com/Joni-gogogo/KBC-ASLEEP. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161696806&doi=10.1007%2f978-981-99-1642-9_9&partnerID=40&md5=2234a689a3544249aaf4de0eefd10bfd,Communications in Computer and Information Science,Exclude,,Exclude,
Boutalbi R.; Ait-Saada M.; Iurshina A.; Staab S.; Nadif M.,Tensor-based Graph Modularity for Text Data Clustering,"Graphs are used in several applications to represent similarities between instances. For text data, we can represent texts by different features such as bag-of-words, static embeddings (Word2vec, GloVe, etc.), and contextual embeddings (BERT, RoBERTa, etc.), leading to multiple similarities (or graphs) based on each representation. The proposal posits that incorporating the local invariance within every graph and the consistency across different graphs leads to a consensus clustering that improves the document clustering. This problem is complex and challenged with the sparsity and the noisy data included in each graph. To this end, we rely on the modularity metric, which effectively evaluates graph clustering in such circumstances. Therefore, we present a novel approach for text clustering based on both a sparse tensor representation and graph modularity. This leads to cluster texts (nodes) while capturing information arising from the different graphs. We iteratively maximize a Tensor-based Graph Modularity criterion. Extensive experiments on benchmark text clustering datasets are performed, showing that the proposed algorithm referred to as Tensor Graph Modularity -TGM- outperforms other baseline methods in terms of clustering task. The source code is available at https: //github.com/TGMclustering/TGMclustering. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135070550&doi=10.1145%2f3477495.3531834&partnerID=40&md5=1ec8eb233cdf48b166adddc1d0db01b6,SIGIR 2022 - Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval,Exclude,,Exclude,
Chen C.-J.; Crawford E.; Stanley N.,A Graph Coarsening Algorithm for Compressing Representations of Single-Cell Data with Clinical or Experimental Attributes,"Graph-based algorithms have become essential in the analysis of single-cell data for numerous tasks, such as automated cell-phenotyping and identifying cellular correlates of experimental perturbations or disease states. In large multi-patient, multi-sample single-cell datasets, the analysis of cell-cell similarity graphs representations of these data becomes computationally prohibitive. Here, we introduce cytocoarsening, a novel graph-coarsening algorithm that significantly reduces the size of single-cell graph representations, which can then be used as input to downstream bioinformatics algorithms for improved computational efficiency. Uniquely, cytocoarsening considers both phenotypical similarity of cells and similarity of cells associated clinical or experimental attributes in order to more readily identify condition-specific cell populations. The resulting coarse graph representations were evaluated based on both their structural correctness and the capacity of downstream algorithms to uncover the same biological conclusions as if the full graph had been used. Cytocoarsening is provided as open source code at https://github.com/ChenCookie/cytocoarsening.  © 2022 The Authors.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144294090&doi=10.1142%2f9789811270611_0009&partnerID=40&md5=35a45439cd0563a6028e1841006153c2,Pacific Symposium on Biocomputing,Exclude,,,
Shi W.; Li F.; Li J.; Fei H.; Ji D.,Effective Token Graph Modeling using a Novel Labeling Strategy for Structured Sentiment Analysis,"The state-of-the-art model for structured sentiment analysis casts the task as a dependency parsing problem, which has some limitations: (1) The label proportions for span prediction and span relation prediction are imbalanced. (2) The span lengths of sentiment tuple components may be very large in this task, which will further exacerbates the imbalance problem. (3) Two nodes in a dependency graph cannot have multiple arcs, therefore some overlapped sentiment tuples cannot be recognized. In this work, we propose nichetargeting solutions for these issues. First, we introduce a novel labeling strategy, which contains two sets of token pair labels, namely essential label set and whole label set. The essential label set consists of the basic labels for this task, which are relatively balanced and applied in the prediction layer. The whole label set includes rich labels to help our model capture various token relations, which are applied in the hidden layer to softly influence our model. Moreover, we also propose an effective model to well collaborate with our labeling strategy, which is equipped with the graph attention networks to iteratively refine token representations, and the adaptive multi-label classifier to dynamically predict multiple relations between token pairs. We perform extensive experiments on 5 benchmark datasets in four languages. Experimental results show that our model outperforms previous SOTA models by a large margin. © 2022 Association for Computational Linguistics.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147541777&partnerID=40&md5=9e293ebd19642fe3393d8cbab202ad44,Proceedings of the Annual Meeting of the Association for Computational Linguistics,Exclude,,,
Chen S.; Xu S.; Yao Y.; Xu F.,Untangling Composite Commits by Attributed Graph Clustering,"During software development, it is considered to be a best practice if each commit represents one distinct concern, such as fixing a bug or adding a new feature. However, developers may not always follow this practice and sometimes tangle multiple concerns into a single composite commit. This makes automatic commit untangling a necessary task, and recent approaches mainly untangle commits via applying graph clustering on the code dependency graph. In this paper, we propose a new commit untangling approach, ComUnt, to decompose the composite commits into atomic ones. Different from existing approaches, ComUnt is built upon the observation that both the textual content of code statements and the dependencies between code statements contain useful semantic information so as to better comprehend the committed code changes. Based on this observation, ComUnt first constructs an attributed graph for each commit, where code statements and various code dependencies are modeled as nodes and edges, respectively, and the textual body of code statements are maintained as node attributes. It then conducts attributed graph clustering on the constructed graph. The used attributed graph clustering algorithm can simultaneously encode both graph structure and node attributes so as to better separate the code changes into clusters with distinct concerns. We evaluate our approach on nine C# projects, and the experimental result shows that ComUnt improves the state-of-the-art by 7.8% in terms of untangling accuracy, and meanwhile it is more than 6 times faster.  © 2022 Association for Computing Machinery.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139556972&doi=10.1145%2f3545258.3545267&partnerID=40&md5=243fc68212f7e1da0843bdafb29510f9,ACM International Conference Proceeding Series,Include,,Include,
Savidis A.; Savaki C.,Software Architecture Mining from Source Code with Dependency Graph Clustering and Visualization,"The software architecture represents an important asset, constituting a shared vision amongst the software engineers of the various system components. Good architectures link to modular design, with loose coupling and cohesion defining which operations are grouped together to form a modular architectural entity. Modularity is achieved by practice otherwise we may observe a mismatch where the source code diverges from the primary architectural vision. In fact, class groups with dense interdependencies denote the real architectural entities as derived and implied directly from source code. In this work, we created a tool to assist in mining the actual system architecture. We extract all sorts of dependencies by processing all source files, and then using graph clustering, we capture and interactively visualize strongly coupled class groups with configurable weights. We also support forced clustering on namespaces, packages and folders. © 2022 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174876755&doi=10.5220%2f0010896800003124&partnerID=40&md5=11b2876a6a5a73299d54c0b747250869,"Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",Include,,,
Yin Y.; Ruan J.; Li Y.; Li Y.; Pan Z.,Syntax-based metamorphic relation prediction via the bagging framework,"Software testing is an indispensable part of the software engineering industry, which guarantees product reliability and safety. Traditional testing approaches face the testing Oracle problem, they are difficult to construct the expected outputs with the increasing of program complexity. As a result, metamorphic testing, which tests the program by examining the relationship between the execution results, is proposed. However, existing manual metamorphic relation construction requires huge effects of domain experts, and automatic methods are unstable and inefficient due to the insufficient software feature mining. Hence, we proposed a multi-dimensional program structure-based metamorphic relation prediction approach, which is composed of feature extraction and prediction model building. In the feature extraction stage, the testing program is converted to multiple intermediate structures (such as control flow graphs and abstract syntax trees) to explore its features. In the prediction model building stage, the extracted feature set is used as the training set, and a novel semi-supervised support vector machine-bagging-K-nearest neighbors algorithm is designed to train the prediction model. Besides, a two-phase hybrid granularity search algorithm is proposed to improve the prediction performance by selecting the optimal number of weak classifiers. Compared with existing approaches, our proposed model can improve the accuracy by around 14%. © 2021 John Wiley & Sons Ltd.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121360772&doi=10.1111%2fexsy.12902&partnerID=40&md5=afa44a71cca853ab24bd173c8f02d449,Expert Systems,Exclude,,,
Zhang L.; Su J.; Chen Y.; Miao Z.; Min Z.; Hu Q.; Shi X.,Towards Better Document-level Relation Extraction via Iterative Inference,"Document-level relation extraction (RE) aims to extract the relations between entities from the input document that usually containing many difficultly-predicted entity pairs whose relations can only be predicted through relational inference. Existing methods usually directly predict the relations of all entity pairs of input document in a one-pass manner, ignoring the fact that predictions of some entity pairs heavily depend on the predicted results of other pairs. To deal with this issue, in this paper, we propose a novel document-level RE model with iterative inference. Our model is mainly composed of two modules: 1) a base module expected to provide preliminary relation predictions on entity pairs; 2) an inference module introduced to refine these preliminary predictions by iteratively dealing with difficultly-predicted entity pairs depending on other pairs in an easy-to-hard manner. Unlike previous methods which only consider feature information of entity pairs, our inference module is equipped with two Extended Cross Attention units, allowing it to exploit both feature information and previous predictions of entity pairs during relational inference. Furthermore, we adopt a two-stage strategy to train our model. At the first stage, we only train our base module. During the second stage, we train the whole model, where contrastive learning is introduced to enhance the training of inference module. Experimental results on three commonly-used datasets show that our model consistently outperforms other competitive baselines. Our source code is available at https://github.com/DeepLearnXMU/DocRE-II. © 2022 Association for Computational Linguistics.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149438691&partnerID=40&md5=0a4ca73e8eec4ccbd2258ac04cea7962,"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022",Exclude,,,
Chourasia P.; Ramakrishnan G.; Apte V.; Kumar S.,Algorithm Identification in Programming Assignments,"Current autograders of programming assignments are typically program output based; they fall short in many ways: e.g. they do not carry out subjective evaluations such as code quality, or whether the code has followed any instructor specified constraints; this is still done manually by teaching assistants. In this paper, we tackle a specific aspect of such evaluation: to verify whether a program implements a specific algorithm that the instructor specified. An algorithm, e.g. bubble sort, can be coded in myriad different ways, but a human can always understand the code and spot, say a bubble sort, vs. a selection sort. We develop and compare four approaches to do precisely this: given the source code of a program known to implement a certain functionality, identify the algorithm used, among a known set of algorithms. The approaches are based on code similarity, Support Vector Machine (SVM) with tree or graph kernels, and transformer neural architectures based only source code (CodeBERT), and the extension of this that includes code structure (GraphCodeBERT). Furthermore, we use a model for explainability (LIME) to generate insights into why certain programs get certain labels. Results based on our datasets of sorting, searching and shortest path codes, show that GraphCodeBERT, fine-tuned with scrambled source code, i.e., where identifiers are replaced consistently with arbitrary words, gives the best performance in algorithm identification, with accuracy of 96-99% depending on the functionality. Additionally, we add uncalled function source code elimination to our pre-processing pipeline of test programs, to improve the accuracy of classification of obfuscated source code.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133208644&doi=10.1145%2f3524610.3527914&partnerID=40&md5=6a56c84be9f2726f6427bcd02ca3cbe6,IEEE International Conference on Program Comprehension,Include,,Include,
Al-Debagy O.; Martinek P.,Dependencies-based microservices decomposition method,"A microservices identification method was proposed by this research paper. The proposed method consists of two parts; the first part is representing the source code of the monolithic application as a class dependency graph. This graph represents the structure of the monolithic application and the relationships between the classes of the application. The second part of the method is a graph clustering algorithm to identify the microservices through analyzing the dependencies between the classes of the monolithic application and cluster classes with solid relationships to generate microservice candidates. The method was tested with 8 different applications and 11 clustering algorithms were examined to find the most accurate and efficient algorithm. The proposed method produced promising results when compared to other methods in the literature with 0.8 averaged F-Measure ‘F1’ score and 0.44 averaged NGM score. The F1 score shows that the proposed method has good accuracy in detecting microservices candidates. Newman Girvan Modularity metric ‘NGM’ score shows that the generated microservices candidates are properly structured and that there are well-defined relationships among the clustered classes of the generated microservices. © 2021 Informa UK Limited, trading as Taylor & Francis Group.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105020336&doi=10.1080%2f1206212X.2021.1915444&partnerID=40&md5=08cedd231472d717ede187789604a42e,International Journal of Computers and Applications,Include,,,
Doan K.D.; Manchanda S.; Mahapatra S.; Reddy C.K.,Interpretable Graph Similarity Computation via Differentiable Optimal Alignment of Node Embeddings,"Computing graph similarity is an important task in many graph-related applications such as retrieval in graph databases or graph clustering. While numerous measures have been proposed to capture the similarity between a pair of graphs, Graph Edit Distance (GED) and Maximum Common Subgraphs (MCS) are the two widely used measures in practice. GED and MCS are domain-agnostic measures of structural similarity between the graphs and define the similarity as a function of pairwise alignment of different entities (such as nodes, edges, and subgraphs) in the two graphs. The explicit explainability offered by the pairwise alignment provides transparency and justification of the similarity score, thus, GED and MCS have important practical applications. However, their exact computations are known to be NP-hard. While recently proposed neural-network based approximations have been shown to accurately compute these similarity scores, they have limited ability in providing comprehensive explanations compared to classical combinatorial algorithms, e.g., Beam search. This paper aims at efficiently approximating these domain-agnostic similarity measures through a neural network, and simultaneously learning the alignments (i.e., explanations) similar to those of classical intractable methods. Specifically, we formulate the similarity between a pair of graphs as the minimal ""transformation""cost from one graph to another in the learnable node-embedding space. We show that, if node embedding is able to capture its neighborhood context closely, our proposed similarity function closely approximates both the alignment and the similarity score of classical methods. Furthermore, we also propose an efficient differentiable computation of our proposed objective for model training. Empirically, we demonstrate that the proposed method achieves up to 50%-100% reduction in the Mean Squared Error for the graph similarity approximation task and up to 20% improvement in the retrieval evaluation metrics for the graph retrieval task. The source code is available at https://github.com/khoadoan/GraphOTSim. © 2021 ACM.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111703568&doi=10.1145%2f3404835.3462960&partnerID=40&md5=eee63403918df19b6fd5bbf46fbe2a37,SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval,Exclude,,,
Pourasghar B.; Izadkhah H.; Isazadeh A.; Lotfi S.,A graph-based clustering algorithm for software systems modularization,"Context: Clustering algorithms, as a modularization technique, are used to modularize a program aiming to understand large software systems as well as software refactoring. These algorithms partition the source code of the software system into smaller and easy-to-manage modules (clusters). The resulting decomposition is called the software system structure (or software architecture). Due to the NP-hardness of the modularization problem, evolutionary clustering approaches such as the genetic algorithm have been used to solve this problem. These methods do not make much use of the information and knowledge available in the artifact dependency graph which is extracted from the source code. Objective: To overcome the limitations of the existing modularization techniques, this paper presents a new modularization technique named GMA (Graph-based Modularization Algorithm). Methods: In this paper, a new graph-based clustering algorithm is presented for software modularization. To this end, the depth of relationships is used to compute the similarity between artifacts, as well as seven new criteria are proposed to evaluate the quality of a modularization. The similarity presented in this paper enables the algorithm to use graph-theoretic information. Results: To demonstrate the applicability of the proposed algorithm, ten folders of Mozilla Firefox with different domains and functions, along with four other applications, are selected. The experimental results demonstrate that the proposed algorithm produces modularization closer to the human expert's decomposition (i.e., directory structure) than the other existing algorithms. Conclusion: The proposed algorithm is expected to help a software designer in the software reverse engineering process to extract easy-to-manage and understandable modules from source code. © 2020 Elsevier B.V.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095748789&doi=10.1016%2fj.infsof.2020.106469&partnerID=40&md5=23bafc7abded00db06bb72f18870e788,Information and Software Technology,Include,,Include,
Krahn M.; Bernard F.; Golyanik V.,Convex Joint Graph Matching and Clustering via Semidefinite Relaxations,"This paper proposes a new algorithm for simultaneous graph matching and clustering. For the first time in the literature,these two problems are solved jointly and synergetically without relying on any training data,which brings advantages for identifying similar arbitrary objects in compound 3D scenes and matching them. For joint reasoning,we first rephrase graph matching as a rigid point set registration problem operating on spectral graph embeddings. Consequently,we utilise efficient convex semidefinite program relaxations for aligning points in Hilbert spaces and add coupling constraints to model the mutual dependency and exploit synergies between both tasks. We outperform state of the art in challenging cases with non-perfectly matching and noisy graphs,and we show successful applications on real compound scenes with multiple 3D elements. Our source code and data are publicly available.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125010826&doi=10.1109%2f3DV53792.2021.00129&partnerID=40&md5=1c46ef8c756826acb541d4d1cb95c2f3,"Proceedings - 2021 International Conference on 3D Vision, 3DV 2021",Exclude,,,
Drakopoulos G.; Kafeza E.,One Dimensional Cross-Correlation Methods for Deterministic and Stochastic Graph Signals with A Twitter Application in Julia,"Graph signal processing is increasingly becoming important for discovering latent patterns, primarily higher order ones, in massive, linked, and possibly semistructured data. The latter may well include social networks, digital images, music spectrograms, brain connectivity maps, protein-to-protein interaction graphs, and even event dependency graphs between events from standard probability spaces. Computing efficiently the cross-correlation between two graph signals can be a versatile similarity metric between them, paving the way for distance metrics in graph clustering or graph classification tasks in numerous domains. In this conference paper methods from a broad class of cross-correlation methodologies which convert deterministic graphs to one dimensional signals are examined. This analysis is then extended to a class of random graphs with the latter being treated as stochastic signals. As a concrete application, these approaches are applied to benchmark data consisting respectively of Twitter connectivity graphs and instances of synthetic stochastic ones.  © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095600912&doi=10.1109%2fSEEDA-CECNSM49515.2020.9221815&partnerID=40&md5=4a241ed17e82ea0e18d233809a9bb70e,"SEEDA-CECNSM 2020 - 5th South-East Europe Design Automation, Computer Engineering, Computer Networks and Social Media Conference",Exclude,,,
Lin Z.; Kang Z.,Graph Filter-based Multi-view Attributed Graph Clustering,"Graph clustering has become an important research topic due to the proliferation of graph data. However, existing methods suffer from two major drawbacks. On the one hand, most methods can not simultaneously exploit attribute and graph structure information. On the other hand, most methods are incapable of handling multi-view data which contain sets of different features and graphs. In this paper, we propose a novel Multi-view Attributed Graph Clustering (MvAGC) method, which is simple yet effective. Firstly, a graph filter is applied to features to obtain a smooth representation without the need of learning the parameters of neural networks. Secondly, a novel strategy is designed to select a few anchor points, so as to reduce the computation complexity. Thirdly, a new regularizer is developed to explore high-order neighborhood information. Our extensive experiments indicate that our method works surprisingly well with respect to state-of-the-art deep neural network methods. The source code is available at https://github.com/sckangz/MvAGC. © 2021 International Joint Conferences on Artificial Intelligence. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113537372&partnerID=40&md5=22bc7ae4f3db31721d934d5b16d18e22,IJCAI International Joint Conference on Artificial Intelligence,Exclude,,,
Zou Y.; Ban B.; Xue Y.; Xu Y.,CCGraph: a PDG-based code clone detector with approximate graph matching,"Software clone detection is an active research area, which is very important for software maintenance, bug detection, etc. The two pieces of cloned code reflect some similarities or equivalents in the syntax or structure of the code representations. There are many representations of code like AST, token, PDG, etc. The PDG (Program Dependency Graph) of source code can contain both syntactic and structural information. However, most existing PDG-based tools are quite time-consuming and miss many clones because they detect code clones with exact graph matching by using subgraph isomorphism. In this paper, we propose a novel PDG-based code clone detector, CCGraph, that uses graph kernels. Firstly, we normalize the structure of PDGs and design a two-stage filtering strategy by measuring the characteristic vectors of codes. Then we detect the code clones by using an approximate graph matching algorithm based on the reforming WL (Weisfeiler-Lehman) graph kernel. Experiment results show that CCGraph retains a high accuracy, has both better recall and F1-score values, and detects more semantic clones than other two related state-of-the-art tools. Besides, CCGraph is much more efficient than the existing PDG-based tools. © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099266573&doi=10.1145%2f3324884.3416541&partnerID=40&md5=e9649945fd8d1b9486b8b22bb1db30f9,"Proceedings - 2020 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020",Include,,,
Pârtachi P.-P.; Dash S.K.; Allamanis M.; Barr E.T.,Flexeme: Untangling commits using lexical flows,"Today, most developers bundle changes into commits that they submit to a shared code repository. Tangled commits intermix distinct concerns, such as a bug fix and a new feature. They cause issues for developers, reviewers, and researchers alike: they restrict the usability of tools such as git bisect, make patch comprehension more difficult, and force researchers who mine software repositories to contend with noise. We present a novel data structure, the -NFG, a multiversion Program Dependency Graph augmented with name flows. A -NFG directly and simultaneously encodes different program versions, thereby capturing commits, and annotates data flow edges with the names/lexemes that flow across them. Our technique, Flexeme, builds a -NFG from commits, then applies Agglomerative Clustering using Graph Similarity to that -NFG to untangle its commits. At the untangling task on a C# corpus, our implementation, Heddle, improves the state-of-the-art on accuracy by 0.14, achieving 0.81, in a fraction of the time: Heddle is 32 times faster than the previous state-of-the-art. © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097194961&doi=10.1145%2f3368089.3409693&partnerID=40&md5=3655a2d95887a2382e1a1056ae653ae3,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,Include,,Include,
Ebrahimpour Boroojeny A.; Shrestha A.; Sharifi-Zarchi A.; Gallagher S.R.; Sahinalp S.C.; Chitsaz H.,Graph Traversal Edit Distance and Extensions,"Many problems in applied machine learning deal with graphs (also called networks), including social networks, security, web data mining, protein function prediction, and genome informatics. The kernel paradigm beautifully decouples the learning algorithm from the underlying geometric space, which renders graph kernels important for the aforementioned applications. In this article, we give a new graph kernel, which we call graph traversal edit distance (GTED). We introduce the GTED problem and give the first polynomial time algorithm for it. Informally, the GTED is the minimum edit distance between two strings formed by the edge labels of respective Eulerian traversals of the two graphs. Also, GTED is motivated by and provides the first mathematical formalism for sequence co-assembly and de novo variation detection in bioinformatics. We demonstrate that GTED admits a polynomial time algorithm using a linear program in the graph product space that is guaranteed to yield an integer solution. To the best of our knowledge, this is the first approach to this problem. We also give a linear programming relaxation algorithm for a lower bound on GTED. We use GTED as a graph kernel and evaluate it by computing the accuracy of a support vector machine (SVM) classifier on a few data sets in the literature. Our results suggest that our kernel outperforms many of the common graph kernels in the tested data sets. As a second set of experiments, we successfully cluster viral genomes using GTED on their assembly graphs obtained from de novo assembly of next-generation sequencing reads. © Copyright 2020, Mary Ann Liebert, Inc., publishers 2020.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081945129&doi=10.1089%2fcmb.2019.0511&partnerID=40&md5=d0623dc18433b52728b3db154f23ab8f,Journal of Computational Biology,Exclude,,,
Höppner F.; Jahnke M.,Enriched Weisfeiler-Lehman Kernel for Improved Graph Clustering of Source Code,"To perform cluster analysis on graphs we utilize graph kernels, Weisfeiler-Lehman kernel in particular, to transform graphs into a vector representation. Despite good results, these kernels have been criticized in the literature for high dimensionality and high sensitivity, so we propose an efficient subtree distance measure that is subsequently used to enrich the vector representations and enables more sensitive distance measurements. We demonstrate the usefulness in an application, where the graphs represent different source code snapshots, and a cluster analysis of these snapshots provides the lecturer an overview about the overall performance of a group of students. © 2020, The Author(s).",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084262556&doi=10.1007%2f978-3-030-44584-3_20&partnerID=40&md5=21eef57863f917b964b0b50d656747bf,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,Include,
Zhang F.; Li G.; Liu C.; Song Q.,Flowchart-based cross-language source code similarity detection,"Source code similarity detection has various applications in code plagiarism detection and software intellectual property protection. In computer programming teaching, students may convert the source code written in one programming language into another language for their code assignment submission. Existing similarity measures of source code written in the same language are not applicable for the cross-language code similarity detection because of syntactic differences among different programming languages. Meanwhile, existing cross-language source similarity detection approaches are susceptible to complex code obfuscation techniques, such as replacing equivalent control structure and adding redundant statements. To solve this problem, we propose a cross-language code similarity detection (CLCSD) approach based on code flowcharts. In general, two source code fragments written in different programming languages are transformed into standardized code flowcharts (SCFC), and their similarity is obtained by measuring their corresponding SCFC. More specifically, we first introduce the standardized code flowchart (SCFC) model to be the uniform flowcharts representation of source code written in different languages. SCFC is language-independent, and therefore, it can be used as the intermediate structure for source code similarity detection. Meanwhile, transformation techniques are given to transform source code written in a specific programming language into an SCFC. Second, we propose the SCFC-SPGK algorithm based on the shortest path graph kernel to measure the similarity between two SCFCs. Thus, the similarity between two pieces of source code in different programming languages is given by the similarity between SCFCs. Experimental results show that compared with existing approaches, CLCSD has higher accuracy in cross-language source code similarity detection. Furthermore, CLCSD cannot only handle common source code obfuscation techniques used by students in computer programming teaching but also obtain nearly 90% accuracy in dealing with some complex obfuscation techniques. © 2020 Feng Zhang et al.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098566906&doi=10.1155%2f2020%2f8835310&partnerID=40&md5=3c21b3a43795466aaa3c8c8e0b211872,Scientific Programming,Include,,,
Dam K.H.T.,Learning malware using Generalized Graph Kernels,"Machine learning techniques were extensively applied to learn and detect malware. However, these techniques use often rough abstractions of programs. We propose in this work to use a more precise model for programs, namely extended API call graphs, where nodes correspond to API function calls, edges specify the execution order between the API functions, and edge labels indicate the dependence relation between API functions parameters. To learn such graphs, we propose to use Generalized Random Walk Graph Kernels (combined with Support Vector Machines). We implemented our techniques and obtained encouraging results for malware detection: 96.73% of detection rate with 0.73% of false alarms. © 2018 Association for Computing Machinery.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055281835&doi=10.1145%2f3230833.3230840&partnerID=40&md5=5b3961d92d20416b5e29ab939bcec2eb,ACM International Conference Proceeding Series,Include,,Include,
Fu Z.; Lin Y.; Liu Z.; Lam W.,Fact discovery from knowledge base via facet decomposition,"During the past few decades, knowledge bases (KBs) have experienced rapid growth. Nevertheless, most KBs still suffer from serious in-completion. Researchers proposed many tasks such as knowledge base completion and relation prediction to help build the representation of KBs. However, there are some issues unsettled towards enriching the KBs. Knowledge base completion and relation prediction assume that we know two elements of the fact triples and we are going to predict the missing one. This assumption is too restricted in practice and prevents it from discovering new facts directly. To address this issue, we propose a new task, namely, fact discovery from knowledge base. This task only requires that we know the head entity and the goal is to discover facts associated with the head entity. To tackle this new problem, we propose a novel framework that decomposes the discovery problem into several facet discovery components. We also propose a novel auto-encoder based facet component to estimate some facets of the fact. Besides, we propose a feedback learning component to share the information between each facet. We evaluate our framework using a benchmark dataset and the experimental results show that our framework achieves promising results. We also conduct extensive analysis of our framework in discovering different kinds of facts. The source code of this paper can be obtained from https://github.com/thunlp/FFD. © 2019 Association for Computational Linguistics",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085572328&partnerID=40&md5=2650589d401d8ac469b9e256ca0253d9,NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference,Exclude,,,
Karyotis V.; Tsitseklis K.; Sotiropoulos K.; Papavassiliou S.,Enhancing Community Detection for Big Sensor Data Clustering via Hyperbolic Network Embedding,"In this paper we present a novel big data clustering approach for measurements obtained from pervasive sensor networks. To address the potential very large scale of such datasets, we map the problem of data clustering to a community detection one. Datasets are cast in the form of graphs, representing the relations among individual observations and data clustering is mapped to node clustering (community detection) in the data graph. We propose a novel computational approach for enhancing the traditional Girvan-Newman (GN) community detection algorithm via hyperbolic network embedding. The data dependency graph is embedded in the hyperbolic space via Rigel embedding, making it possible to compute more efficiently the hyperbolic edge-betweenness centrality (HEBC) needed in the modified GN algorithm. This allows for more efficient clustering of the nodes of the data graph without significantly sacrificing accuracy. We demonstrate the efficacy of our approach with artificial network and data topologies, and real benchmark datasets. The proposed methodology can be used for efficient clustering of datasets obtained from massive pervasive smart city/building sensor networks, such as the FIESTA-IoT platform, and exploited in various applications such as lower-cost sensing. © 2018 IEEE.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056458909&doi=10.1109%2fPERCOMW.2018.8480134&partnerID=40&md5=082f7ba01a225e8ccef49047803f02bd,"2018 IEEE International Conference on Pervasive Computing and Communications Workshops, PerCom Workshops 2018",Exclude,,,
Gu X.; Zhang H.; Kim S.,CodeKernel: A graph kernel based approach to the selection of API usage examples,"Developers often want to find out how to use a certain API (e.g., FileReader.read in JDK library). API usage examples are very helpful in this regard. Over the years, many automated methods have been proposed to generate code examples by clustering and summarizing relevant code snippets extracted from a code corpus. These approaches simplify source code as method invocation sequences or feature vectors. Such simplifications only model partial aspects of the code and tend to yield inaccurate examples. We propose CodeKernel, a graph kernel based approach to the selection of API usage examples. Instead of approximating source code as method invocation sequences or feature vectors, CodeKernel represents source code as object usage graphs. Then, it clusters graphs by embedding them into a continuous space using a graph kernel. Finally, it outputs code examples by selecting a representative graph from each cluster using designed ranking metrics. Our empirical evaluation shows that CodeKernel selects more accurate code examples than the related work (MUSE and eXoaDocs). A user study involving 25 developers in a multinational company also confirms the usefulness of CodeKernel in selecting API usage examples. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078952975&doi=10.1109%2fASE.2019.00061&partnerID=40&md5=85dbd8c1cccc076ea3a48f8a8e86118c,"Proceedings - 2019 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019",Include,,,
Ge X.; Pan Y.; Fan Y.; Fang C.,AMDroid: Android Malware Detection Using Function Call Graphs,"With the rapid development of the mobile Internet, Android has been the most popular mobile operating system. Due to the open nature of Android, c countless malicious applications are hidden in a large number of benign applications, which pose great threats to users. Most previous malware detection approaches mainly rely on features such as permissions, API calls, and opcode sequences. However, these approaches fail to capture structural semantics of applications. In this paper, we propose AMDroid that leverages function call graphs (FCGs) representing the behaviors of applications and applies graph kernels to automatically learn the structural semantics of applications from FCGs. We evaluate AMDroid on the Genome Project, and the experimental results show that AMDroid is effective to detect Android malware with 97.49% detection accuracy. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073879922&doi=10.1109%2fQRS-C.2019.00027&partnerID=40&md5=450d90562bac5df641d3608f9d3d49f5,"Proceedings - Companion of the 19th IEEE International Conference on Software Quality, Reliability and Security, QRS-C 2019",Include,,,
Karyotis V.; Tsitseklis K.; Sotiropoulos K.; Papavassiliou S.,Big data clustering via community detection and hyperbolic network embedding in IoT applications,"In this paper, we present a novel data clustering framework for big sensory data produced by IoT applications. Based on a network representation of the relations among multi-dimensional data, data clustering is mapped to node clustering over the produced data graphs. To address the potential very large scale of such datasets/graphs that test the limits of state-of-the-art approaches, we map the problem of data clustering to a community detection one over the corresponding data graphs. Specifically, we propose a novel computational approach for enhancing the traditional Girvan-Newman (GN) community detection algorithm via hyperbolic network embedding. The data dependency graph is embedded in the hyperbolic space via Rigel embedding, allowing more efficient computation of edge-betweenness centrality needed in the GN algorithm. This allows for more efficient clustering of the nodes of the data graph in terms of modularity, without sacrificing considerable accuracy. In order to study the operation of our approach with respect to enhancing GN community detection, we employ various representative types of artificial complex networks, such as scale-free, small-world and random geometric topologies, and frequently-employed benchmark datasets for demonstrating its efficacy in terms of data clustering via community detection. Furthermore, we provide a proof-of-concept evaluation by applying the proposed framework over multi-dimensional datasets obtained from an operational smart-city/building IoT infrastructure provided by the Federated Interoperable Semantic IoT/cloud Testbeds and Applications (FIESTA-IoT) testbed federation. It is shown that the proposed framework can be indeed used for community detection/data clustering and exploited in various other IoT applications, such as performing more energy-efficient smart-city/building sensing. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.",Article,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045428827&doi=10.3390%2fs18041205&partnerID=40&md5=0f53454f4ddc5ba09779ce173c69b61f,Sensors (Switzerland),Exclude,,,
Nair A.; Meinke K.; Eldh S.,Leveraging mutants for automatic prediction of metamorphic relations using machine learning,"An oracle is used in software testing to derive the verdict (pass/fail) for a test case. Lack of precise test oracles is one of the major problems in software testing which can hinder judgements about quality. Metamorphic testing is an emerging technique which solves both the oracle problem and the test case generation problem by testing special forms of software requirements known as metamorphic requirements. However, manually deriving the metamorphic requirements for a given program requires a high level of domain expertise, is labor intensive and error prone. As an alternative, we consider the problem of automatic detection of metamorphic requirements using machine learning (ML). For this problem we can apply graph kernels and support vector machines (SVM). A significant problem for any ML approach is to obtain a large labeled training set of data (in this case programs) that generalises well. The main contribution of this paper is a general method to generate large volumes of synthetic training data which can improve ML assisted detection of metamorphic requirements. For training data synthesis we adopt mutation testing techniques. This research is the first to explore the area of data augmentation techniques for ML-based analysis of software code. We also have the goal to enhance black-box testing using white-box methodologies. Our results show that the mutants incorporated into the source code corpus not only efficiently scale the dataset size, but they can also improve the accuracy of classification models. © 2019 Association for Computing Machinery.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076425007&doi=10.1145%2f3340482.3342741&partnerID=40&md5=520020b6b6fbb4004758904595495231,"MaLTeSQuE 2019 - Proceedings of the 3rd ACM SIGSOFT International Workshop on Machine Learning Techniques for Software Quality Evaluation, co-located with ESEC/FSE 2019",Exclude,,,
Liu Z.; Xiong C.; Sun M.; Liu Z.,Fine-grained fact verification with kernel graph attention network,"Fact Verification requires fine-grained natural language inference capability that finds subtle clues to identify the syntactical and semantically correct but not well-supported claims. This paper presents Kernel Graph Attention Network (KGAT), which conducts more fine-grained fact verification with kernel-based attentions. Given a claim and a set of potential evidence sentences that form an evidence graph, KGAT introduces node kernels, which better measure the importance of the evidence node, and edge kernels, which conduct fine-grained evidence propagation in the graph, into Graph Attention Networks for more accurate fact verification. KGAT achieves a 70.38% FEVER score and significantly outperforms existing fact verification models on FEVER, a large-scale benchmark for fact verification. Our analyses illustrate that, compared to dot-product attentions, the kernel-based attention concentrates more on relevant evidence sentences and meaningful clues in the evidence graph, which is the main source of KGAT's effectiveness. All source codes of this work are available at https://github.com/thunlp/KernelGAT. © 2020 Association for Computational Linguistics",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108646393&partnerID=40&md5=e70a57417c9e7f209220ee8f75c24ba9,Proceedings of the Annual Meeting of the Association for Computational Linguistics,Exclude,,,
Narayanan A.; Chandramohan M.; Chen L.; Liu Y.,A multi-view context-aware approach to Android malware detection and malicious code localization,"Many existing Machine Learning (ML) based Android malware detection approaches use a variety of features such as security-sensitive APIs, system calls, control-flow structures and information flows in conjunction with ML classifiers to achieve accurate detection. Each of these feature sets provides a unique semantic perspective (or view) of apps’ behaviors with inherent strengths and limitations. Meaning, some views are more amenable to detect certain attacks but may not be suitable to characterize several other attacks. Most of the existing malware detection approaches use only one (or a selected few) of the aforementioned feature sets which prevents them from detecting a vast majority of attacks. Addressing this limitation, we propose MKLDroid, a unified framework that systematically integrates multiple views of apps for performing comprehensive malware detection and malicious code localization. The rationale is that, while a malware app can disguise itself in some views, disguising in every view while maintaining malicious intent will be much harder. MKLDroid uses a graph kernel to capture structural and contextual information from apps’ dependency graphs and identify malice code patterns in each view. Subsequently, it employs Multiple Kernel Learning (MKL) to find a weighted combination of the views which yields the best detection accuracy. Besides multi-view learning, MKLDroid’s unique and salient trait is its ability to locate fine-grained malice code portions in dependency graphs (e.g., methods/classes). Malicious code localization caters several important applications such as supporting human analysts studying malware behaviors, engineering malware signatures, and other counter-measures. Through our large-scale experiments on several datasets (incl. wild apps), we demonstrate that MKLDroid outperforms three state-of-the-art techniques consistently, in terms of accuracy while maintaining comparable efficiency. In our malicious code localization experiments on a dataset of repackaged malware, MKLDroid was able to identify all the malice classes with 94% average recall. Our work opens up two new avenues in malware research: (i) enables the research community to elegantly look at Android malware behaviors in multiple perspectives simultaneously, and (ii) performing precise and scalable malicious code localization. © 2017, Springer Science+Business Media, LLC.",Article,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028588565&doi=10.1007%2fs10664-017-9539-8&partnerID=40&md5=8ecb03b5f443da3ffed5de80762b0e96,Empirical Software Engineering,Include,,Include,
Zhao L.; Wu S.; Jiang J.; Li W.; Luo J.; Li J.,Novel overlapping subgraph clustering for the detection of antigen epitopes,"Motivation Antigens that contain overlapping epitopes have been occasionally reported. As current algorithms mainly take a one-antigen-one-epitope approach to the prediction of epitopes, they are not capable of detecting these multiple and overlapping epitopes accurately, or even those multiple and separated epitopes existing in some other antigens. Results We introduce a novel subgraph clustering algorithm for more accurate detection of epitopes. This algorithm takes graph partitions as seeds, and expands the seeds to merge overlapping subgraphs based on the term frequency-inverse document frequency (TF-IDF) featured similarity. Then, the merged subgraphs are each classified as an epitope or non-epitope. Tests of our algorithm were conducted on three newly collected datasets of antigens. In the first dataset, each antigen contains only a single epitope; in the second, each antigen contains only multiple and separated epitopes; and in the third, each antigen contains overlapping epitopes. The prediction performance of our algorithm is significantly better than the state-of-art methods. The lifts of the averaged f-scores on top of the best existing methods are 60, 75 and 22% for the single epitope detection, the multiple and separated epitopes detection, and the overlapping epitopes detection, respectively. Availability and implementation The source code is available at github.com/lzhlab/glep/. Supplementary informationSupplementary dataare available at Bioinformatics online. © The Author(s) 2018.",Article,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049097355&doi=10.1093%2fbioinformatics%2fbty051&partnerID=40&md5=9e4b0456b7641a73d0fb25e43f70fa38,Bioinformatics,Exclude,,Exclude,
Mori J.Y.; Llanos C.H.; Huebner M.,A framework to the design and programming of many-core focal-plane vision processors,"The Focal-Plane Image Processing area aims to bring processing elements as near as possible to the pixels and to the camera's focal-plane. Most of the works reported in the literature uses only simple processing elements, in general analog ones, with few flexibility. With the technology advances, a new generation of Vision Processors is emerging. It is expected that multi/many-core systems will be integrated to the pixel sensors, offering several opportunities for parallelism exploration, resulting in high performance and flexible processing systems. The programmability is one of the main problems in this area, since most programmers are not able to create parallel algorithms and applications. In this work, we propose a methodology to the design and programming of many-core focal-plane vision processors. The application is described using a Domain Specific Language, from which the parallelism characteristics are extracted. Afterwards, a new abstract model is derived using techniques such as Program Slicing (PS) and Task-Graph Clustering (TGC). The abstract model is then transformed in a SystemC/TLM2.0 description, in order to allow for different timing accuracy simulations. The results of the simulations are used together with an ASIP design tool in order to determine both the microarchitecture of processing elements and the communication structure of the new system. Finally, from the model derived before, a new source code is generated and programmed into the new platform. In this context, the main concepts and ideas are described in this work, as well as some partial results. © 2015 IEEE.",Conference paper,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963815334&doi=10.1109%2fEUC.2015.24&partnerID=40&md5=efef306df006ec7092a87d7dd398cce3,"Proceedings - IEEE/IFIP 13th International Conference on Embedded and Ubiquitous Computing, EUC 2015",Exclude,,Exclude,
Boroojeny A.E.; Shrestha A.; Sharifi-Zarchi A.; Gallagher S.R.; Sahinalp S.C.; Chitsaz H.,GTED: Graph Traversal Edit Distance,"Many problems in applied machine learning deal with graphs (also called networks), including social networks, security, web data mining, protein function prediction, and genome informatics. The kernel paradigm beautifully decouples the learning algorithm from the underlying geometric space, which renders graph kernels important for the aforementioned applications. In this paper, we give a new graph kernel which we call graph traversal edit distance (GTED). We introduce the GTED problem and give the first polynomial time algorithm for it. Informally, the graph traversal edit distance is the minimum edit distance between two strings formed by the edge labels of respective Eulerian traversals of the two graphs. Also, GTED is motivated by and provides the first mathematical formalism for sequence co-assembly and de novo variation detection in bioinformatics. We demonstrate that GTED admits a polynomial time algorithm using a linear program in the graph product space that is guaranteed to yield an integer solution. To the best of our knowledge, this is the first approach to this problem. We also give a linear programming relaxation algorithm for a lower bound on GTED. We use GTED as a graph kernel and evaluate it by computing the accuracy of an SVM classifier on a few datasets in the literature. Our results suggest that our kernel outperforms many of the common graph kernels in the tested datasets. As a second set of experiments, we successfully cluster viral genomes using GTED on their assembly graphs obtained from de novo assembly of next generation sequencing reads. Our GTED implementation can be downloaded from http://chitsazlab.org/software/gted/. © Springer International Publishing AG, part of Springer Nature 2018.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046159848&doi=10.1007%2f978-3-319-89929-9_3&partnerID=40&md5=cc4b591288afbfadb53a0bf8f43d5591,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,Exclude,
Searles R.; Xu L.; Killian W.; Vanderbruggen T.; Forren T.; Howe J.; Pearson Z.; Shannon C.; Simmons J.; Cavazos J.,Parallelization of Machine Learning Applied to Call Graphs of Binaries for Malware Detection,"Malicious applications have become increasingly numerous. This demands adaptive, learning-based techniques for constructing malware detection engines, instead of the traditional manual-based strategies. Prior work in learning-based malware detection engines primarily focuses on dynamic trace analysis and byte-level n-grams. Our approach in this paper differs in that we use compiler intermediate representations, i.e., the callgraph representation of binaries. Using graph-based program representations for learning provides structure of the program, which can be used to learn more advanced patterns. We use the Shortest Path Graph Kernel (SPGK) to identify similarities between call graphs extracted from binaries. The output similarity matrix is fed into a Support Vector Machine (SVM) algorithm to construct highly-Accurate models to predict whether a binary is malicious or not. However, SPGK is computationally expensive due to the size of the input graphs. Therefore, we evaluate different parallelization methods for CPUs and GPUS to speed up this kernel, allowing us to continuously construct up-To-date models in a timely manner. Our hybrid implementation, which leverages both CPU and GPU, yields the best performance, achieving up to a 14.2x improvement over our already optimized OpenMP version. We compared our generated graph-based models to previously state-of-The-Art feature vector 2-gram and 3-gram models on a dataset consisting of over 22,000 binaries. We show that our classification accuracy using graphs is over 19% higher than either n-gram model and gives a false positive rate (FPR) of less than 0.1%. We are also able to consider large call graphs and dataset sizes because of the reduced execution time of our parallelized SPGK implementation. © 2017 IEEE.",Conference paper,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019600397&doi=10.1109%2fPDP.2017.41&partnerID=40&md5=b53211ec49b3cb90afecdaacbf875587,"Proceedings - 2017 25th Euromicro International Conference on Parallel, Distributed and Network-Based Processing, PDP 2017",Exclude,,,
Frasconi P.; Costa F.; De Raedt L.; De Grave K.,KLog: A language for logical and relational learning with kernels,"We introduce kLog, a novel language for kernelbased learning on expressive logical and relational representations. kLog allows users to specify logical and relational learning problems declaratively. It builds on simple but powerful concepts: learning from interpretations, entity/relationship data modeling, and logic programming. Access by the kernel to the rich representation is mediated by a technique we call graphicalization: the relational representation is first transformed into a graph - in particular, a grounded entity/relationship diagram. Subsequently, a choice of graph kernel defines the feature space. The kLog framework can be applied to tackle the same range of tasks that has made statistical relational learning so popular, including classification, regression, multitask learning, and collective classification. An empirical evaluation shows that kLog can be either more accurate, or much faster at the same level of accuracy, than Tilde and Alchemy. kLog is GPLv3 licensed and is available at http://klog.dinfo.unifi.it along with tutorials.",Conference paper,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949763864&partnerID=40&md5=5a10cce93b2296a4c7a882280c4f8791,IJCAI International Joint Conference on Artificial Intelligence,Exclude,,Exclude,
Frasconi P.; Costa F.; De Raedt L.; De Grave K.,KLog: A language for logical and relational learning with kernels,"We introduce kLog, a novel approach to statistical relational learning. Unlike standard approaches, kLog does not represent a probability distribution directly. It is rather a language to perform kernel-based learning on expressive logical and relational representations. kLog allows users to specify learning problems declaratively. It builds on simple but powerful concepts: learning from interpretations, entity/relationship data modeling, logic programming, and deductive databases. Access by the kernel to the rich representation is mediated by a technique we call graphicalization: the relational representation is first transformed into a graph - in particular, a grounded entity/relationship diagram. Subsequently, a choice of graph kernel defines the feature space. kLog supports mixed numerical and symbolic data, as well as background knowledge in the form of Prolog or Datalog programs as in inductive logic programming systems. The kLog framework can be applied to tackle the same range of tasks that has made statistical relational learning so popular, including classification, regression, multitask learning, and collective classification. We also report about empirical comparisons, showing that kLog can be either more accurate, or much faster at the same level of accuracy, than Tilde and Alchemy. kLog is GPLv3 licensed and is available at http://klog.dinfo.unifi.it along with tutorials. © 2014 Elsevier B.V. All rights reserved.",Article,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908457312&doi=10.1016%2fj.artint.2014.08.003&partnerID=40&md5=f79a711963ba63d4d453e00597da4ac3,Artificial Intelligence,Exclude,,,
Peake I.D.; Blech J.O.; Fernando L.; Sharma D.; Ramaswamy S.; Kande M.,Analysis of software binaries for reengineering-driven product line architecture - An industrial case study,"This paper describes a method for the recovering of software architectures from a set of similar (but unrelated) software products in binary form. One intention is to drive refactoring into software product lines and combine architecture recovery with run time binary analysis and existing clustering methods. Using our runtime binary analysis, we create graphs that capture the dependencies between different software parts. These are clustered into smaller component graphs, that group software parts with high interactions into larger entities. The component graphs serve as a basis for further software product line work. In this paper, we concentrate on the analysis part of the method and the graph clustering. We apply the graph clustering method to a real application in the context of automation / robot configuration software tools. © Peake et al.",Conference paper,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014954197&doi=10.4204%2fEPTCS.182.6&partnerID=40&md5=b9a280dcf333f8991d728f97c88b6d77,"Electronic Proceedings in Theoretical Computer Science, EPTCS",Exclude,,,
Zhang P.; Zhou X.; Pelliccione P.; Leung H.,RBF-MLMR: A Multi-Label Metamorphic Relation Prediction Approach Using RBF Neural Network,"Metamorphic testing has been successfully used in many different fields to solve the test oracle problem. However, how to find a set of appropriate metamorphic relations for metamorphic testing remains a complicated and tedious task. Recently some machine learning approaches have been proposed to predict metamorphic relations. These approaches predicting single label metamorphic relation can alleviate this problem to some extent. However, many applications involve multi-group metamorphic relations, and these approaches are clearly inefficient. To address this problem, in this paper we propose a Multi-Label Metamorphic Relations prediction approach based on an improved radial basis function (RBF) neural network named RBF-MLMR. First, RBF-MLMR uses state-of-The-Art soot analysis tool to generate control flow graph and corresponds labels from the source codes of programs. Second, the extracted nodes and the path properties constitute multi-label data sets for the control flow graph. Finally, a multi-label RBF neural network prediction model is established to predict whether the program satisfies multiple metamorphic relations. In order to improve the prediction results, affinity propagation and k-means clustering algorithms are used to optimize the RBF neural network structure of RBF-MLMR. A set of dedicated experiments based on public programs is conducted to validate RBF-MLMR. The experimental results show that RBF-MLMR can achieve accuracy of around 80% for predicting two and three metamorphic relations. © 2013 IEEE.",Article,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030757764&doi=10.1109%2fACCESS.2017.2758790&partnerID=40&md5=5bcfb6bdbe4f23a6c01baf666ffc5ef7,IEEE Access,Exclude,,,
Li W.; Saidi H.; Sanchez H.; Schäf M.; Schweitzer P.,Detecting similar programs via the weisfeiler-leman graph kernel,"With the increasing availability of source code on the Internet, many new approaches to retrieve, repair, and reuse code have emerged that rely on the ability to efficiently compute the similarity of two pieces of code. The meaning of similarity, however, heavily depends on the application domain. For predicting API calls, for example, programs can be considered similar if they call a specific set of functions in a similar way, while for automated bug fixing, it is important that similar programs share a similar data-flow. In this paper, we propose an algorithm to compute program similarity based on the Weisfeiler-Leman graph kernel. Our algorithm is able to operate on different graph-based representations of programs and thus can be applied in different domains. We show the usefulness of our approach in two experiments using data-flow similarity and API-call similarity. © Springer International Publishing Switzerland 2016.",Conference paper,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977581207&doi=10.1007%2f978-3-319-35122-3_21&partnerID=40&md5=efbb2de52959457686f86e3225086d73,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,Include,
Zhao Y.; Gao S.; Gallinari P.; Guo J.,Zero-shot embedding for unseen entities in knowledge graph,"Knowledge graph (KG) embedding aims at learning the latent semantic representations for entities and relations. However, most existing approaches can only be applied to KG completion, so cannot identify relations including unseen entities (or Out-of-KG entities). In this paper, motivated by the zero-shot learning, we propose a novel model, namely JointE, jointly learning KG and entity descriptions embedding, to extend KG by adding new relations with Out-of-KG entities. The JointE model is evaluated on entity prediction for zero-shot embedding. Empirical comparisons on benchmark datasets show that the proposed JointE model outperforms state-of-the-art approaches. The source code of JointE is available at https://github.com/yzur/JointE.",Article,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021696408&doi=10.1587%2ftransinf.2016EDP7446&partnerID=40&md5=86accf4afd35c62052fd232fe88d9973,IEICE Transactions on Information and Systems,Exclude,,Exclude,
Giatsidis C.; Malliaros F.D.; Vazirgiannis M.,Advanced graph mining for community evaluation in social networks and the web,"Graphs constitute a dominant data structure and appear essentially in all forms of information. Examples are the Web graph, numerous social networks, protein interaction networks, terms dependency graphs and network topologies. The main features of these graphs are their huge volume and rate of change. Presumably, there is important hidden knowledge in the macroscopic topology and features of these graphs. A cornerstone issue here is the detection and evaluation of communities - bearing multiple and diverse semantics. The tutorial reports the basic models of graph structures for undirected, directed and signed graphs and their properties. Next we offer a thorough review of fundamental methods for graph clustering and community detection, on both undirected and directed graphs. Then we survey community evaluation measures, including both the individual node based ones as well as those that take into account aggregate properties of communities. A special mention is made on approaches that capitalize on the concept of degeneracy (k-cores and extensions), as a novel means of community detection and evaluation. We justify the above foundational framework with applications on citation graphs, trust networks and protein graphs. © 2013 Authors.",Conference paper,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874268917&doi=10.1145%2f2433396.2433495&partnerID=40&md5=e31d97fa340c7e3272a66def6f0b901c,WSDM 2013 - Proceedings of the 6th ACM International Conference on Web Search and Data Mining,Exclude,,,
Siddik S.; Gias A.U.; Khaled S.M.,Optimizing software design migration from structured programming to object oriented paradigm,"Several industries are using legacy softwares, developed with Structured Programming (SP) approach, that should be migrated to Object Oriented Paradigm (OOP) for ensuring better software quality parameters like modularity, manageability and extendability. Automating SP to OOP migration is pivotal as it could reduce time that take in the manual process. Given this potential benefit, the issue is yet to be addressed by researchers. This paper addresses the scenario by modeling this problem as a graph clustering problem where SP functions and function calls are vertices and edges respectively. The challenge evolving the problem is to find optimized clusters from graphs. To aid this problem, certain heuristic algorithms based on Monte Carlo and Greedy approaches are being developed. The proposed algorithms have been tested against a collection of real and synthetic data. The numerical results show that greedy algorithms are faster and produced better results than the average performance of Monte Carlo based approaches. © 2014 IEEE.",Conference paper,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905036062&doi=10.1109%2fICCITechn.2014.6997320&partnerID=40&md5=d9270341cfe747f6a60e076323a6220e,"2013 16th International Conference on Computer and Information Technology, ICCIT 2013",Include,,,
Ovatman T.; Buzluca F.; Weigert T.,Applying enhanced graph clustering to software dependency analysis,"Dependencies between classes give key information about the static structure of an object oriented software system. For industrially sized systems it is difficult for the developer to visually analyze the dependencies between classes and to detect patterns of dependencies that frequently occur throughout UML class diagrams. In this paper, automatically detecting dependency patterns in software designs is focused. After applying graph clustering techniques to dependency graphs extracted from class diagrams it has been found that these techniques were not able to detect key dependency patterns An algorithm is proposed to detect such dependencieswhich also improves on the studied graph clustering techniques when applied to dependency analysis of class diagrams.",Conference paper,2010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883645936&partnerID=40&md5=b71a23e739a5ebd49985a2434713bfe0,"19th International Conference on Software Engineering and Data Engineering 2010, SEDE 2010",Include,,,
Gkirtzou K.; Honorio J.; Samaras D.; Goldstein R.; Blaschko M.B.,fMRI analysis with sparse Weisfeiler-Lehman graph statistics,"fMRI analysis has most often been approached with linear methods. However, this disregards information encoded in the relationships between voxels. We propose to exploit the inherent spatial structure of the brain to improve the prediction performance of fMRI analysis. We do so in an exploratory fashion by representing the fMRI data by graphs. We use the Weisfeiler-Lehman algorithm to efficiently compute subtree features of the graphs. These features encode non-linear interactions between voxels, which contain additional discriminative information that cannot be captured by a linear classifier. In order to make use of the efficiency of the Weisfeiler-Lehman algorithm, we introduce a novel pyramid quantization strategy to approximate continuously labeled graphs with a sequence of discretely labeled graphs. To control the capacity of the resulting prediction function, we utilize the elastic net sparsity regularizer. We validate our method on a cocaine addiction dataset showing a significant improvement over elastic net and kernel ridge regression baselines and a reduction in classification error of over 14%. Source code is also available at https://gitorious.org/wlpyramid. © 2013 Springer International Publishing.",Conference paper,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886732258&doi=10.1007%2f978-3-319-02267-3_12&partnerID=40&md5=8afb1cbbc8c8fded1153fbef0bec7465,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Exclude,,,
Siddik Md.S.; Ul Gias A.; Selim Md.; Khaled S.M.; Sakib K.,A direction of migrating procedural paradigm to object based architecture by forming cluster of functions using local search heuristics,"In contrast to procedural programming, object oriented design provides better modularity, manageability and extensibility. Some legacy softwares written in procedural languages phase out of upgrading and support due to an unmanageable design. This paper proposes two variations of local search based heuristic to discover clues for object oriented design from the underlying structure of procedural languages. This has the potential to help a semi-automated migration of legacy software to a new object based design. The scheme was applied on three data instances which were generated from synthetic and real life software. In terms of optimal cluster finding, results show that the proposed technique improves 24.714% and 5.66% more than Greedy and Genetic approaches respectively. © 2014 IEEE.",Conference paper,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904965622&doi=10.1109%2fICIEV.2014.6850767&partnerID=40&md5=74063c4ab0ff8022b93490fc96d539e7,"2014 International Conference on Informatics, Electronics and Vision, ICIEV 2014",Include,,,
Jain L.; Chandran A.; Rawat S.; Srinathan K.,Discovering vulnerable functions by extrapolation: A control-flow graph similarity based approach,"We present a method for vulnerability extrapolation to identify vulnerable functions in source code. Given a known vulnerable function, the proposed method extrapolates to find similar functions in the code base. Vulnerability extrapolation is based on the observation that given a starting vulnerability, similar behavior may be present in many other functions. In order to capture similarity, we represent functions in terms of syntactic and semantic patterns. These patterns are based on several code features like API usage pattern, argument types and control flow graph (CFG) of the functions. We employ a recent technique, called graph kernel to compute similarity directly on the CFGs of functions. We empirically demonstrate the capabilities of the proposed method by evaluating real-world applications to identify vulnerabilities. © Springer International Publishing AG 2016.",Conference paper,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85005995761&doi=10.1007%2f978-3-319-49806-5_32&partnerID=40&md5=29d5d63b0d0ffe222df6c073b51aae40,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,,
Zhang Y.; Lin H.; Yang Z.; Li Y.,Neighborhood hash graph kernel for protein-protein interaction extraction,"Automated extraction of protein-protein interactions (PPIs) from biomedical literatures is an important topic of biomedical text mining. In this paper, we propose an approach based on neighborhood hash graph kernel for this task. In contrast to the existing graph kernel-based approaches for PPI extraction, the proposed approach not only has the capability to make use of full dependency graphs to represent the sentence structure but also effectively control the computational complexity. We evaluate the proposed approach on five publicly available PPI corpora and perform detailed comparisons with other approaches. The experimental result shows that our approach is comparable to the state-of-the-art PPI extraction system and much faster than all-path graph kernel approach on all five PPI corpora. © 2011 Elsevier Inc.",Article,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855922688&doi=10.1016%2fj.jbi.2011.08.011&partnerID=40&md5=742d200fbc81b766293823f96e3feb08,Journal of Biomedical Informatics,Exclude,,,
Bavota G.; De Lucia A.; Marcus A.; Oliveto R.,Automating extract class refactoring: an improved method and its evaluation,"During software evolution the internal structure of the system undergoes continuous modifications. These continuous changes push away the source code from its original design, often reducing its quality, including class cohesion. In this paper we propose a method for automating the Extract Class refactoring. The proposed approach analyzes (structural and semantic) relationships between the methods in a class to identify chains of strongly related methods. The identified method chains are used to define new classes with higher cohesion than the original class, while preserving the overall coupling between the new classes and the classes interacting with the original class. The proposed approach has been first assessed in an artificial scenario in order to calibrate the parameters of the approach. The data was also used to compare the new approach with previous work. Then it has been empirically evaluated on real Blobs from existing open source systems in order to assess how good and useful the proposed refactoring solutions are considered by software engineers and how well the proposed refactorings approximate refactorings done by the original developers. We found that the new approach outperforms a previously proposed approach and that developers find the proposed solutions useful in guiding refactorings. © 2013, Springer Science+Business Media New York.",Article,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84909999876&doi=10.1007%2fs10664-013-9256-x&partnerID=40&md5=a9c97552aca1cd265b4034330f680669,Empirical Software Engineering,Include,,,
Alrabaee S.; Shirani P.; Wang L.; Debbabi M.,FOSSIL: A resilient and efficient system for identifying FOSS functions in Malware binaries,"Identifying free open-source software (FOSS) packages on binaries when the source code is unavailable is important for many security applications, such as malware detection, software infringement, and digital forensics. This capability enhances both the accuracy and the efficiency of reverse engineering tasks by avoiding false correlations between irrelevant code bases. Although the FOSS package identification problem belongs to the field of software engineering, conventional approaches rely strongly on practical methods in data mining and database searching. However, various challenges in the use of these methods prevent existing function identification approaches from being effective in the absence of source code. To make matters worse, the introduction of obfuscation techniques, the use of different compilers and compilation settings, and software refactoring techniques has made the automated detection of FOSS packages increasingly difficult. With very few exceptions, the existing systems are not resilient to such techniques, and the exceptions are not sufficiently efficient. To address this issue, we propose FOSSIL, a novel resilient and efficient system that incorporates three components. The first component extracts the syntactical features of functions by considering opcode frequencies and applying a hidden Markov model statistical test. The second component applies a neighborhood hash graph kernel to random walks derived from control-flow graphs, with the goal of extracting the semantics of the functions. The third component applies z-score to the normalized instructions to extract the behavior of instructions in a function. The components are integrated using a Bayesian network model, which synthesizes the results to determine the FOSS function. The novel approach of combining these components using the Bayesian network has produced stronger resilience to code obfuscation. We evaluate our system on three datasets, including real-world projects whose use of FOSS packages is known, malware binaries for which there are security and reverse engineering reports purporting to describe their use of FOSS, and a large repository of malware binaries. We demonstrate that our system is able to identify FOSS packages in real-world projects with a mean precision of 0.95 and with a mean recall of 0.85. Furthermore, FOSSIL is able to discover FOSS packages in malware binaries that match those listed in security and reverse engineering reports. Our results show that modern malware binaries contain 0.10–0.45 of FOSS packages. © 2018 Copyright is held by the owner/author(s).",Article,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042626945&doi=10.1145%2f3175492&partnerID=40&md5=4700e38acca338a550677f7873de2ea9,ACM Transactions on Privacy and Security,Exclude,,,
Gascon H.; Yamaguchi F.; Arp D.; Rieck K.,Structural detection of Android malware using embedded call graphs,"The number of malicious applications targeting the Android system has literally exploded in recent years. While the security community, well aware of this fact, has proposed several methods for detection of Android malware, most of these are based on permission and API usage or the identification of expert features. Unfortunately, many of these approaches are susceptible to instruction level obfuscation techniques. Previous research on classic desktop malware has shown that some high level characteristics of the code, such as function call graphs, can be used to find similarities between samples while being more robust against certain obfuscation strategies. However, the identification of similarities in graphs is a non-trivial problem whose complexity hinders the use of these features for malware detection. In this paper, we explore how recent developments in machine learning classification of graphs can be efficiently applied to this problem. We propose a method for malware detection based on efficient embeddings of function call graphs with an explicit feature map inspired by a linear-time graph kernel. In an evaluation with 12,158 malware samples our method, purely based on structural features, outperforms several related approaches and detects 89% of the malware with few false alarms, while also allowing to pin-point malicious code structures within Android applications. © 2013 ACM.",Conference paper,2013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889046959&doi=10.1145%2f2517312.2517315&partnerID=40&md5=3aa068a35b123a9ebd5d1f34936feb74,Proceedings of the ACM Conference on Computer and Communications Security,Exclude,,Include,Exclude
Zhong L.-H.; Xu L.; Ye M.-S.; Zheng Y.; Xie B.,An approach for software architecture refactoring based on clustering of extended component dependency graph,"For improving the evolvability of software architecture, the paper proposes a software architecture refactoring strategy based on extended clustering of component dependency relation, which consists of logical relation and evolution relation among components. By using the graph clustering algorithm, the software architecture can be restructured according to the software quality of ""high cohesion and low coupling"" under the control of our refactoring algorithm. Moreover, an example is shown for explaining its usability.",Conference paper,2009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949700560&doi=10.1109%2fCISE.2009.5362854&partnerID=40&md5=7adc7879dea903a9d4b6ad1babc5c55e,"Proceedings - 2009 International Conference on Computational Intelligence and Software Engineering, CiSE 2009",Include,,,
Azriel L.; Ginosar R.; Gueron S.; Mendelson A.,Using scan side channel for detecting IP theft,"We present a process for detection of IP theft in VLSI devices that exploits the internal test scan chains. The IP owner learns implementation details in the suspect device to find evidence of the theft, while the top level function is public. The scan chains supply direct access to the internal registers in the device, thus making it possible to learn the logic functions of the internal combinational logic chunks. Our work introduces an innovative way of applying Boolean function analysis techniques for learning digital circuits with the goal of IP theft detection. By using Boolean function learning methods, the learner creates a partial dependency graph of the internal flip-flops. The graph is further partitioned using the SNN graph clustering method, and individual blocks of combinational logic are isolated. These blocks can be matched with known building blocks that compose the original function. This enables reconstruction of the function implementation to the level of pipeline structure. The IP owner can compare the resulting structure with his own implementation to confirm or refute that an IP violation has occurred. We demonstrate the power of the presented approach with a test case of an open source Bitcoin SHA-256 accelerator, containing more than 80,000 registers. With the presented method we discover the microarchitecture of the module, locate all the main components of the SHA-256 algorithm, and learn the module's flow control. © 2016 ACM.",Conference paper,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983432645&doi=10.1145%2f2948618.2948619&partnerID=40&md5=249335a8906772089328210405101c89,ACM International Conference Proceeding Series,Exclude,,,
Qiu D.; Zhang Q.; Fang S.,Reconstructing Software High-Level Architecture by Clustering Weighted Directed Class Graph,"Software architecture reconstruction plays an important role in software reuse, evolution and maintenance. Clustering is a promising technique for software architecture reconstruction. However, the representation of software, which serves as clustering input, and the clustering algorithm need to be improved in real applications. The representation should contain appropriate and adequate information of software. Furthermore, the clustering algorithm should be adapted to the particular demands of software architecture reconstruction well. In this paper, we first extract Weighted Directed Class Graph (WDCG) to represent object-oriented software. WDCG is a structural and quantitative representation of software, which contains not only the static information of software source code but also the dynamic information of software execution. Then we propose a WDCG-based Clustering Algorithm (WDCG-CA) to reconstruct high-level software architecture. WDCG-CA makes full use of the structural and quantitative information of WDCG, and avoids wrong compositions and arbitrary partitions successfully in the process of reconstructing software architecture. We introduce four metrics to evaluate the performance of WDCG-CA. The results of the comparative experiments show that WDCG-CA outperforms the comparative approaches in most cases in terms of the four metrics. © 2015 World Scientific Publishing Company.",Article,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941884483&doi=10.1142%2fS0218194015500072&partnerID=40&md5=ac56e15253d0402f32dac893408a22ad,International Journal of Software Engineering and Knowledge Engineering,Include,,Include,
Ramadan E.; Naef A.; Ahmed M.,Protein complexes predictions within protein interaction networks using genetic algorithms,"Background: Protein-protein interaction networks are receiving increased attention due to their importance in understanding life at the cellular level. A major challenge in systems biology is to understand the modular structure of such biological networks. Although clustering techniques have been proposed for clustering protein-protein interaction networks, those techniques suffer from some drawbacks. The application of earlier clustering techniques to protein-protein interaction networks in order to predict protein complexes within the networks does not yield good results due to the small-world and power-law properties of these networks. Results: In this paper, we construct a new clustering algorithm for predicting protein complexes through the use of genetic algorithms. We design an objective function for exclusive clustering and overlapping clustering. We assess the quality of our proposed clustering algorithm using two gold-standard data sets. Conclusions: Our algorithm can identify protein complexes that are significantly enriched in the gold-standard data sets. Furthermore, our method surpasses three competing methods: MCL, ClusterOne, and MCODE in terms of the quality of the predicted complexes. The source code and accompanying examples are freely available at http://faculty.kfupm.edu.sa/ics/eramadan/GACluster.zip. © 2016 The Author(s).",Article,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979205097&doi=10.1186%2fs12859-016-1096-4&partnerID=40&md5=ca622674056f0b374b151b5e02a37593,BMC Bioinformatics,Exclude,,,
Selim M.; Siddik M.S.; Rahman T.; Gias A.U.; Khaled S.M.,Approximating object based architecture for legacy software written in procedural languages using Variable Neighborhood Search,"Legacy software, often written in procedural languages, could be a major concern for organizations due to low maintainability. A possible way out could be migrating the software to object oriented architecture, which is easier to maintain due to better modularity. However, a manual migration could take significant time and thus an automated process is required. This migration problem has been modeled as an optimal graph clustering problem where vertices and edges are represented by function and function calls respectively. Solution to this problem is NP-hard and thus meta-heuristic base approaches are potential to get near optimal result. This paper presents a Variable Neighborhood Search (VNS) approach for addressing the modeled graph clustering problem. The method provides a set of clusters that gives a clue for possible structure of the object oriented architecture. This approach is based on the objective to minimize the coupling and maximize the cohesion within the clusters. The proposed algorithm was implemented and its performance was compared with state of the art techniques. It is observed that the proposed method produced 37.15% and 12.02% better results in contrast to genetic algorithm and local search heuristics. © 2014 IEEE.",Conference paper,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949924477&doi=10.1109%2fSKIMA.2014.7083558&partnerID=40&md5=fa5870a96cd8c14d04b26a176d463d65,"SKIMA 2014 - 8th International Conference on Software, Knowledge, Information Management and Applications",Include,,,
Dam K.-H.-T.; Touili T.,Learning android malware,"The number of Android malware is increasing every day. .us Android malware detection is nowadays a big challenge. One of the most tedious tasks in malware detection is the extraction of malicious behaviors. this task is usually done manually and requires a huge e.ort of engineering. To avoid this step, we propose in this paper to use machine learning techniques for malware detection. Unlike the existing learning based approaches, we propose to use API call graphs to represent the behaviors of Android applications. then, given a set of malicious applications and a set of benign applications, we apply well-known learning techniques based on Random Walk Graph Kernel (combined with Support Vector Machines). We can achieve a high detection rate with only few false alarms (98.76% for detection rate with 0.24% of false alarms). © 2017 Association for Computing Machinery.",Conference paper,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030314468&doi=10.1145%2f3098954.3105826&partnerID=40&md5=403586389418039066bead2dfae0150c,ACM International Conference Proceeding Series,Include,,,
Zhang Y.; Wu H.-Y.; Xu J.; Wang J.; Soysal E.; Li L.; Xu H.,Leveraging syntactic and semantic graph kernels to extract pharmacokinetic drug drug interactions from biomedical literature,"Background: Information about drug-drug interactions (DDIs) supported by scientific evidence is crucial for establishing computational knowledge bases for applications like pharmacovigilance. Since new reports of DDIs are rapidly accumulating in the scientific literature, text-mining techniques for automatic DDI extraction are critical. We propose a novel approach for automated pharmacokinetic (PK) DDI detection that incorporates syntactic and semantic information into graph kernels, to address the problem of sparseness associated with syntactic-structural approaches. First, we used a novel all-path graph kernel using shallow semantic representation of sentences. Next, we statistically integrated fine-granular semantic classes into the dependency and shallow semantic graphs. Results: When evaluated on the PK DDI corpus, our approach significantly outperformed the original all-path graph kernel that is based on dependency structure. Our system that combined dependency graph kernel with semantic classes achieved the best F-scores of 81.94 % for in vivo PK DDIs and 69.34 % for in vitro PK DDIs, respectively. Further, combining shallow semantic graph kernel with semantic classes achieved the highest precisions of 84.88 % for in vivo PK DDIs and 74.83 % for in vitro PK DDIs, respectively. Conclusions: We presented a graph kernel based approach to combine syntactic and semantic information for extracting pharmacokinetic DDIs from Biomedical Literature. Experimental results showed that our proposed approach could extract PK DDIs from literature effectively, which significantly enhanced the performance of the original all-path graph kernel based on dependency structure. © 2016 The Author(s).",Article,2016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983591563&doi=10.1186%2fs12918-016-0311-2&partnerID=40&md5=48fd9a07af125343c2a45c96717e6b3e,BMC Systems Biology,Exclude,,Exclude,
Airola A.; Pyysalo S.; Björne J.; Pahikkala T.; Ginter F.; Salakoski T.,All-paths graph kernel for protein-protein interaction extraction with evaluation of cross-corpus learning,"Background: Automated extraction of protein-protein interactions (PPI) is an important and widely studied task in biomedical text mining. We propose a graph kernel based approach for this task. In contrast to earlier approaches to PPI extraction, the introduced all-paths graph kernel has the capability to make use of full, general dependency graphs representing the sentence structure. Results: We evaluate the proposed method on five publicly available PPI corpora, providing the most comprehensive evaluation done for a machine learning based PPI-extraction system. We additionally perform a detailed evaluation of the effects of training and testing on different resources, providing insight into the challenges involved in applying a system beyond the data it was trained on. Our method is shown to achieve state-of-the-art performance with respect to comparable evaluations, with 56.4 F-score and 84.8 AUC on the AImed corpus. Conclusion: We show that the graph kernel approach performs on state-of-the-art level in PPI extraction, and note the possible extension to the task of extracting complex interactions. Cross-corpus results provide further insight into how the learning generalizes beyond individual corpora. Further, we identify several pitfalls that can make evaluations of PPI-extraction systems incomparable, or even invalid. These include incorrect cross-validation strategies and problems related to comparing F-score results achieved on different evaluation resources. Recommendations for avoiding these pitfalls are provided. © 2008 Airola et al; licensee BioMed Central Ltd.",Conference paper,2008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-56649091413&doi=10.1186%2f1471-2105-9-52&partnerID=40&md5=d735a698a7e8200c6a31b9b58bcd386b,BMC Bioinformatics,Exclude,,,
Airola A.; Pyysalo S.; Björne J.; Pahikkala T.; Ginter F.; Salakoski T.,A graph Kernel for protein-protein interaction extraction,"In this paper, we propose a graph kernel based approach for the automated extraction of protein-protein interactions (PPI) from scientific literature. In contrast to earlier approaches to PPI extraction, the introduced alldependency- paths kernel has the capability to consider full, general dependency graphs. We evaluate the proposed method across five publicly available PPI corpora providing the most comprehensive evaluation done for a machine learning based PPI-extraction system. Our method is shown to achieve state-of-the art performance with respect to comparable evaluations, achieving 56.4 F-score and 84.8 AUC on the AI med corpus. Further, we identify several pitfalls that can make evaluations of PPI-extraction systems incomparable, or even invalid. These include incorrect crossvalidation strategies and problems related to comparing F-score results achieved on different evaluation resources.  © 2008 Association for Computational Linguistics.",Conference paper,2008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052896774&partnerID=40&md5=4834257fb9132be5525ad248d0cdafcf,"BioNLP 2008 - Current Trends in Biomedical Natural Language Processing, Proceedings of the Workshop",Exclude,,,
Kinable J.; Kostakis O.,Malware classification based on call graph clustering,"Each day, anti-virus companies receive tens of thousands samples of potentially harmful executables. Many of the malicious samples are variations of previously encountered malware, created by their authors to evade pattern-based detection. Dealing with these large amounts of data requires robust, automatic detection approaches. This paper studies malware classification based on call graph clustering. By representing malware samples as call graphs, it is possible to abstract certain variations away, enabling the detection of structural similarities between samples. The ability to cluster similar samples together will make more generic detection techniques possible, thereby targeting the commonalities of the samples within a cluster. To compare call graphs mutually, we compute pairwise graph similarity scores via graph matchings which approximately minimize the graph edit distance. Next, to facilitate the discovery of similar malware samples, we employ several clustering algorithms, including k-medoids and Density-Based Spatial Clustering of Applications with Noise (DBSCAN). Clustering experiments are conducted on a collection of real malware samples, and the results are evaluated against manual classifications provided by human malware analysts. Experiments show that it is indeed possible to accurately detect malware families via call graph clustering. We anticipate that in the future, call graphs can be used to analyse the emergence of new malware families, and ultimately to automate implementation of generic detection schemes. © 2011 Springer-Verlag France.",Article,2011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80255126150&doi=10.1007%2fs11416-011-0151-y&partnerID=40&md5=629cbf2afef398da345c92a519e46121,Journal in Computer Virology,Include,,,
Guo Y.; Smit G.J.M.; Broersma H.; Rosien M.A.J.; Heysters P.M.,Mapping applications to a coarse grain reconfigurable system,"This paper introduces a method which can be used to map applications written in a high level source language program, like C, to a coarse grain reconfigurable architecture, MONTIUM. The source code is first translated into a control dataflow graph. Then after applying graph clustering, scheduling and allocation on this control dataflow graph, it can be mapped onto the target architecture. The clustering and allocation algorithm are presented in detail. High performance and low power consumption are achieved by exploiting maximum parallelism and locality of reference respectively. Using our mapping method, the flexibility of the MONTIUM architecture can be exploited. © Springer.Verlag Berlin Heidelberg 2003.",Article,2003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-35248866137&doi=10.1007%2f978-3-540-39864-6_18&partnerID=40&md5=5bf101a8b6de5d7a9aa64f4a782affc8,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),Include,,Include,
