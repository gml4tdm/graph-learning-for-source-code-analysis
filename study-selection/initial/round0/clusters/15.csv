Title,Abstract
Multi-scale Multi-step Dependency Graph Neural Network for Multivariate Time-Series Forecasting,"This study addressed the limitations of existing graph neural network methods in time-series prediction, specifically the inability to establish strong dependencies between variables and the weak correlation in time-series across different time scales. To overcome these challenges, we proposed a graph neural network-based multi-scale multi-step dependency (GMSSD) model. To capture temporal dependencies in time-series data, we first designed a temporal convolution module that learns multi-scale representations between sequences. We extracted features at multiple scales using dilated convolutions and a gated linear unit (GLU) while controlling the information flow, thereby capturing temporal dependencies in time-series data. Furthermore, we employed a gated recurrent unit (GRU) and fully connected layers to derive the graph structure and capture the complex relationships between variables in the sequence data. In particular, existing graph neural network methods have a strong dependence on graph structures and are unable to adapt to complex and dynamic graph structures. They also have limitations in capturing long-range dependency relationships within the graph. Therefore, a graph convolution module is designed to explore the current node information and its neighbor information. It has the capability to integrate information contributions from different time steps, effectively capturing the spatial dependencies among nodes. The experimental results show that the proposed model outperformed existing methods in both single-step and multi-step prediction tasks. This study provided a novel approach for time-series forecasting and achieved significant improvements. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd."
Local Dependency-Enhanced Graph Convolutional Network for Aspect-Based Sentiment Analysis,"The task of aspect-based sentiment analysis (ABSA) is to detect the sentiment polarity toward given aspects. Contemporary methods predominantly utilize graph neural networks and incorporate attention mechanisms to dynamically connect aspect terms with their surrounding contexts, resulting in more informative feature representations. However, these methods only consider whether there are dependencies between words when introducing dependencies, ignoring that dependencies between different sentiment words have different effects. Neglecting this could introduce noise and negatively impact the model’s performance. To overcome this limitation, we introduce a novel approach called the local dependency-enhanced graph convolutional network (LDEGCN). Our method combines semantic information and dependency relationships to better capture the affective relationships between words. Specifically, we integrate sentiment knowledge from SenticNet to enrich the sentence’s dependency graph and thoroughly explore the dependency types between contexts and aspects to focus on particular dependency types. The local context weight (LCW) method is employed on the dependency-enhanced graph to emphasize the importance of local contexts, thereby mitigating the issue of long-distance dependencies. Through extensive evaluations of five public datasets, the LDEGCN model demonstrates significant improvements over mainstream models. © 2023 by the authors."
Aspect-level sentiment analysis based on aspect-sentence graph convolution network,"Aspect-level sentiment analysis aims to identify the sentiment polarity of aspect words in sentences. The existing research methods only focus on the grammatical dependencies between words, ignoring the semantic connections between aspect words and the dependency types between words, which limits the performance of the aspect-level sentiment analysis model. Therefore, this paper proposes an aspect-sentence Graph Convolutional Networks model (ASGCN) to perceive more comprehensive semantic information. Specifically, the model consists of sentence-focused GCN (SentenceGCN) and aspects-focused GCN (AspectsGCN) sub models. In the SentenceGCN model, this paper proposes a method to calculate the adjacency matrix (As) of syntactic dependency graph, which uses the position encoding mechanism and pays attention to the influence of different dependency types on semantics, so that SentenceGCN can capture the semantic information of the whole sentence more comprehensively. In the AspectsGCN model, this paper also proposes a method to calculate the adjacency matrix (Aa) of aspect words, which models the relational graph as fully connected and gives weight to the edges between aspect words according to the position, so that the AspectsGCN can pay attention to the semantic relation between different aspect words in the sentence. The proposed model outperforms all baseline models with 86.34 % accuracy and 79.96 F1 score, which indicates that there are more advantages in perceiving semantic information in ASGCN. © 2023 Elsevier B.V."
DGNN: Dependency Graph Neural Network for Multimodal Emotion Recognition in Conversation,"For emotion recognition in conversation (ERC), the modeling of conversational dependency plays a crucial role. Existing methods often directly connect multimodal information and then build a graph neural network based on a fixed number of past and future utterances. The former leads to the lack of interaction between modalities, and the latter is less consistent with the logic of the conversation. Therefore, in order to better build conversational dependency, we propose a Dependency Graph Neural Network (DGNN) for ERC. First, we present a cross-modal fusion transformer for modeling dependency between different modalities of the same utterance. Then, we design a directed graph neural network model based on the adaptive window for modeling dependency between different utterances. The results of the extensive experiments on two benchmark datasets demonstrate the superiority of the proposed model. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd."
Aspect-level sentiment classification via location enhanced aspect-merged graph convolutional networks,"Aspect-level sentiment classification (ALSC) is a fine-grained sentiment analysis task that needs to predict the sentiment polarities of the given aspect terms in the sentence. Recently, emerging research has taken syntactic dependency tree as input and used graph convolutional neural network (GCN) to process ALSC tasks. However, existing GCN-based researches only consider the syntactic connections between words, ignoring the semantic relevance within aspectual entities. To address this deficiency, we propose a graph convolutional network based on Merger aspect entities and Location-aware transformation (MLGCN). Specifically, we use a specific token to replace the aspect entity, whether single-word or multi-word. The merged syntactic dependency graph is obtained through parsing for the sentence after merging aspect words. Then, we feed the sentence into an encoder and apply a novel location-aware function designed in this paper to the encoding result to enhance the model’s attention to the opinion entities. Finally, the dependency graph and the processed sentence encoding are fed to the graph convolutional network for training. Experimental results on five benchmark datasets show that the model proposed in this paper has good performance and achieves satisfactory results, exceeding the vast majority of previous work. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature."
Aspect-based sentiment analysis via multitask learning for online reviews,"Aspect based sentiment analysis(ABSA) aims to identify aspect terms in online reviews and predict their corresponding sentiment polarity. Sentiment analysis poses a challenging fine-grained task. Two typical subtasks are involved: Aspect Term Extraction (ATE) and Aspect Polarity Classification (APC). These two subtasks are usually trained discretely, which ignores the connection between ATE and APC. Concretely, we can relate ATE to APC through aspects and train them concurrently. We mainly use the ATE task as an auxiliary task, allowing the APC to focus more on relevant aspects to facilitate aspect polarity classification. In addition, previous studies have shown that utilizing dependency syntax information with a graph neural network (GNN) also contributes to the performance of the APC task. However, most studies directly input sentence dependency relations into graph neural networks without considering the influence of aspects, which do not emphasize the important dependency relationships. To address these issues, we propose a multitask learning model combining APC and ATE tasks that can extract aspect terms as well as classify aspect polarity simultaneously. Moreover, we exploit multihead attention(MHA) to associate dependency sequences with aspect extraction, which not only combines both ATE and APC tasks but also stresses the significant dependency relations, enabling the model to focus more on words closely related to aspects. According to our experiments on three benchmark datasets, we demonstrate that the connection between ATE and APC can be better established by our model, which enhances aspect polarity classification performance significantly. The source code has been released on GitHub https://github.com/winder-source/MTABSA. © 2023 Elsevier B.V."
Improving aspect-based sentiment analysis with Knowledge-aware Dependency Graph Network,"Aspect-based sentiment analysis (ABSA) aims to mine multiple sentiment–target pairs contained in a review sentence. The main challenge of this task is how to extract the sentiment polarity of a specific sentiment item efficiently. Earlier research focused on recurrent neural networks (RNNs), which implicitly associate the sentiment items with sentiment polarities through an attention mechanism. However, due to the complexity of language and the fact that a sentence contains multiple sentiment pairs, these models often fail to capture sentiment pairs accurately. Most recent efforts have applied syntactic information, especially dependency information, to construct structured models (e.g., tree-based models or graph neural networks) for sentiment analysis. Although these structured models achieve better results, they ignore the domain knowledge related to the entities of the comment sentences. This domain knowledge (e.g., brand reputation, influence) significantly impacts the sentiment polarity. Hence, this paper proposes a Knowledge-aware Dependency Graph Network (KDGN) based on the dependency graph incorporating domain knowledge, dependency labels, and syntax path. Experimental results on the benchmarking datasets demonstrate that our KDGN significantly outperforms previous state-of-the-art methods on the ABSA task, further illustrating that the domain knowledge, dependency labels, and syntax path are crucial for the ABSA task. © 2022 Elsevier B.V."
EDU-Capsule: aspect-based sentiment analysis at clause level,"Many studies on aspect-based sentiment analysis (ABSA) aim to directly predict aspects and polarities at sentence level. However, it is not rare that a long sentence expresses multiple aspects. In this paper, we propose to study ABSA at EDU-level. Elementary discourse unit (EDU) in rhetorical structure theory is an atomic semantic unit, similar to a clause in a sentence. Through manual annotation of 8,823 EDUs, obtained from the SemEval-2014 Task 4 Restaurant Review dataset, we show that more than 97% of EDUs express at most one aspect. Based on this observation, we propose an EDU-level Capsule network for ABSA. EDU-Capsule learns EDU representations within its sentential context for aspect detection and sentiment prediction. EDU-Capsule outperforms strong baselines in our experiments on two benchmark datasets. Both the EDU-level annotations and EDU-Capsule source code are released to support further studies in this area. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature."
Cross and Self Attention Based Graph Convolutional Network for Aspect-Based Sentiment Analysis,"Aspect-based sentiment analysis aims to recognize the sentiment polarity of an aspect in reviews. In general, to analyze the sentiment of an aspect in a sentence, it is essential to capture the dependencies between aspects and the corresponding contexts. Recently, graph neural networks over global dependency structures like dependency trees or self-attention score matrices have been explored for this task. However, these models rely heavily on the quality of information extracted from the global dependency structures. In the meantime, the pairwise correlations between aspects and contexts provide an equally important perspective for sentiment analysis, which is usually ignored in previous works. Motivated by this, we propose a novel approach for aspect-based sentiment analysis by integrating the information extracted from global dependency structures as well as pairwise correlations. To capture the aspect-to-text correlations, we design a CAGCN module based on the cross-attention mechanism. Meanwhile, to effectively exploit the syntactic graph, we design an SAGCN module with the self-attention mechanism to build the overall text-to-text connections. Experimental results on five benchmarks show the effectiveness of our proposed model, producing significantly better results than the baselines. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023."
Dual-Perspective Fusion Network for Aspect-based Multimodal Sentiment Analysis,"Aspect-based multimodal sentiment analysis (ABMSA) is an important sentiment analysis task that analyses aspect-specific sentiment in data with different modalities (usually multimodal data with text and images). Previous works usually ignore the overall sentiment tendency when analyzing the sentiment of each aspect term. However, the overall sentiment tendency is highly correlated with aspect-specific sentiment. In addition, existing methods neglect to explore and make full use of the fine-grained multimodal information closely related to aspect terms. To address these limitations, we propose a dual-perspective fusion network (DPFN) that considers both global and local fine-grained sentiment information in multimodal data. From the global perspective, we use text-image caption pairs to obtain a global representation containing information about the overall sentiment tendencies. From the local fine-grained perspective, we construct two graph structures to explore the fine-grained information in texts and images. Finally, aspect-level sentiment polarities can be obtained by analyzing the combination of global and local fine-grained sentiment information. Experimental results on two multimodal Twitter datasets show that the proposed DPFN model outperforms state-of-the-art methods. The source code is publicly available at <uri>https://github.com/cntian0/DPFN</uri>. IEEE"
DGC-CRL: Dependency Graph Convolution based Contrastive Representation Learning for Chinese Medical Question Matching,"As one kind of domain-specific question answering (QA) systems, the medical QA systems require much more stability, fast system speed and response accuracy. Therefore, the retrieval based QA systems are more suitable, among which the deep semantic matching models become prevalent to be studied and they are playing the very important role on the quality of retrieval based medical QA systems. In this paper, we propose a two-stage solution (named with Dependency Graph Convolution based Contrastive Representation Learning) which includes a dependency graph convolution module to explicitly capture the semantic similarity between Chinese questions. At the first stage, we adopt the contrastive learning to further distinguish the similarity within the domain-specific corpus itself and learn discriminative textual representations. At the second stage, the down-streaming question matching task is benefited by using the newly-learned representations. In our experiments, we collect two Chinese medical datasets (CBLUE-STS and COVID-19) and the results can demonstrate that our proposed method is effective and general to different medical QA corpora. Also the ablation experiments indicate the proposed Dependency Graph Convolution module and contrastive learning method are both efficient. © 2023 The Authors. Published by Elsevier B.V."
Discriminative Reasoning with Sparse Event Representation for Document-level Event-Event Relation Extraction,"Document-level Event-Event Relation Extraction (DERE) aims to extract relations between events in a document. It challenges conventional sentence-level task (SERE) with difficult long-text understanding. In this paper, we propose a novel DERE model (SENDIR) for better document-level reasoning. Different from existing works that build an event graph via linguistic tools, SENDIR does not require any prior knowledge. The basic idea is to discriminate event pairs in the same sentence or span multiple sentences by assuming their different information density: 1) low density in the document suggests sparse attention to skip irrelevant information. Our module 1 designs various types of attention for event representation learning to capture long-distance dependence. 2) High density in a sentence makes SERE relatively easy. Module 2 uses different weights to highlight the roles and contributions of intra- and inter-sentential reasoning, which introduces supportive event pairs for joint modeling. Extensive experiments demonstrate great improvements in SENDIR and the effectiveness of various sparse attention for document-level representations. Codes will be released later. © 2023 Association for Computational Linguistics."
Semantic Enhanced Aspect-Level Text Sentiment Analysis of Graph Neural Networks,"Aspect-level sentiment analysis is a fine-grained text sentiment analysis technology that determines the sentiment tendency of text targets. It is widely used in fields such as product and education evaluation, and assists users in establishing a more comprehensive understanding of entity attributes and making accurate decisions. However, a key challenge is that the majority of existing aspect-level sentiment analysis techniques do not sufficiently extract text syntax dependency and external knowledge features. Therefore, a semantic enhanced aspect-level text sentiment analysis model is proposed herein using graph convolution neural networks to process heterogeneous data. A word embedding vector of the text is input into a bidirectional gated circular neural network to extract contextual semantic information of text and target aspect words, a weighted syntactic dependency graph is constructed based on the type of syntactic dependency, and a knowledge subgraph is constructed based on the text words and external knowledge base, and a graph convolutional neural network is used to process the weighted syntactic dependency graph and knowledge subgraph, to obtain text features that integrate text syntactic structure information and target aspect features that reflects external knowledge information. On this basis, two sets of feature vectors are spliced to complete sentimental polarity classification. Experimental results demonstrate that on the Laptop 14, Restaurant 14, and Restaurant15 datasets, the model F1 values reach 77.34%, 76.58%, and 68.57%, respectively. Compared with baseline models such as ATAE- LSTM, TD-LSTM, and ASGCN the model F1 values increase by an average of 7.28%, 5.71%, and 6.28%, respectively. The proposed model achieves an improved sentimental analysis performance by extracting textual syntactic dependency and external knowledge features. © 2023, Editorial Office of Computer Engineering. All rights reserved."
Enhanced distance-aware self-attention and multi-level match for sentence semantic matching,"Sentence semantic matching is a core research area in natural language processing, which is widely used in various natural language tasks. In recent years, attention mechanism has shown good performance in deep neural networks for sentence semantic matching. Most of the attention-based deep neural networks focus on sentences interaction which ignore modeling the core semantic of the sentence. In other words, they do not consider the importance of the relative distance of words when modeling the sentence semantics, which leads to deviations in modeling the core semantics of the sentence and unstable sentence interaction. Usually, people tend to associate words that are relatively close together when they read and believe that there is a deeper connection between them. Besides, the current interactive matching method after sentence modeling is relatively simple and it may be inadequate. In this paper, we build a well-performed distance-aware self-attention and multi-level matching model (DSSTM) for sentence semantic matching tasks. By considering the importance of different distance tokens, it can get the better original semantics of sentences and hold interactive matching method in multiple level after sentence modeling. To be specific, given two input sentences, we first encode them as contextual embeddings. Then, the contextual embeddings are handled by enhanced distance-aware self-attention to further strengthen the sentence semantic modeling from the whole and local aspect. At the same time, we apply the co-attention layer to extract cross-sentence interaction features while simplifying all the remaining components. Finally, we fuse them into the multi-level matching function to obtain the aggregation vector and learn divers matching representations, which is helpful to capture the diversity of sentence pairs. We conduct experiments on three sentence semantic matching tasks. Experimental results on these public datasets demonstrate that our model outperforms competitive baseline methods and our model has fewer parameters. Our source code is publicly available at https://github.com/xiaodeng-1/DSSTM. © 2022 Elsevier B.V."
Aspect sentiment analysis with heterogeneous graph neural networks,"Aspect-based sentiment analysis technologies may be a very practical methodology for securities trading, commodity sales, movie rating websites, etc. Most recent studies adopt the recurrent neural network or attention-based neural network methods to infer aspect sentiment using opinion context terms and sentence dependency trees. However, due to a sentence often having multiple aspects sentiment representation, these models are hard to achieve satisfactory classification results. In this paper, we discuss these problems by encoding sentence syntax tree, words relations and opinion dictionary information in a unified framework. We called this method heterogeneous graph neural networks (Hete_GNNs). Firstly, we adopt the interactive aspect words and contexts to encode the sentence sequence information for parameter sharing. Then, we utilized a novel heterogeneous graph neural network for encoding these sentences’ syntax dependency tree, prior sentiment dictionary, and some part-of-speech tagging information for sentiment prediction. We perform the Hete_GNNs sentiment judgment and report the experiments on five domain datasets, and the results confirm that the heterogeneous context information can be better captured with heterogeneous graph neural networks. The improvement of the proposed method is demonstrated by aspect sentiment classification task comparison. © 2022 Elsevier Ltd"
Isomer: Transfer enhanced dual-channel heterogeneous dependency attention network for aspect-based sentiment classification,"Aspect-based sentiment classification aims to predict the sentiment polarity of a specific aspect in a sentence. However, most existing methods attempt to construct dependency relations into a homogeneous dependency graph with sparsity and ambiguity, which only considers one type of node and one type of edge, thus cannot cover the comprehensive contextualized features of short texts or consider any additional node types or semantic relation information. To solve those issues, we present a sentiment analysis model, Isomer, which performs dual-channel attention on heterogeneous dependency graphs incorporating external knowledge to integrate additional information effectively. Specifically, a transfer-enhanced dual-channel heterogeneous dependency attention network is designed in Isomer for modeling short texts by heterogeneous dependency graphs. These heterogeneous dependency graphs not only consider different types of information but also incorporate external knowledge. Experiments studies show that Isomer outperforms the-state-of-arts on diverse datasets. Furthermore, the results suggest that Isomer captures the importance of various information features to focus on informative contextual words. © 2022 Elsevier B.V."
A novel locality-sensitive hashing relational graph matching network for semantic textual similarity measurement,"Recent efforts adopt interaction-based models to construct the interaction of words between sentences, which aim to predict whether two sentences are semantically equivalent or not in semantic textual similarity (STS) task. However, these methods lack the global semantic awareness, which make it difficult to distinguish syntactic differences and also suffer from the inference time cost, primarily due to the calculation of the pair-interactions of words. A novel model called Locality-Sensitive Hashing Relational Graph Matching Network (LSHRGMN) is therefore proposed, which tackles these problems by syntactic dependency graph and locality-sensitive hashing (LSH). Specifically, syntactic dependency graph is aware of the global semantic information via rooting in each word to construct several trees and merging all the trees into one graph. LSH mechanism is introduced into pair-interactions of words for the inference efficiency problem. Extensive experiments are conducted on three real-world datasets, and the result shows that the proposed approach acquires higher accuracy and intriguing inference speed. © 2022 Elsevier Ltd"
Exploring fine-grained syntactic information for aspect-based sentiment classification with dual graph neural networks,"The goal of aspect-based sentiment classification (ASC) is to predict the corresponding emotion of a specific target of a sentence. In neural network-based methods for ASC, various sophisticated models such as Recurrent Neural Networks (RNN) and Convolutional Neural Networks (CNN) are widespread. Recently, ongoing research has integrated syntactic structures into graph neural networks (GNN) to deal with ASC tasks. However, these methods are limited due to the noise and inefficient use of information of syntactic dependency trees. This paper proposes a novel GNN based deep learning model to overcome the deficiencies of prior studies. In the proposed model, to exploit the information in the syntactic dependency trees, a novel part-of-speech (POS) guided syntactic dependency graph is constructed for a relational graph attention network (RGAT) to eliminate the noises. Further, a syntactic distance attention-guided layer is designed for a densely connected graph convolutional network (DCGCN), which can fully extract semantic dependency between contextual words. Experiments on three public datasets are carried out to evaluate the effectiveness of the proposed model. Comparing to the baselines, our model, as a best alternative, achieves state-of-arts performance. © 2021 Elsevier B.V."
Multi-View Gated Graph Convolutional Network for Aspect-Level Sentiment Classification,"Aspect-Level Sentiment Classification aims to identify the sentiment polarity of each aspect in a sentence. Syntax-based graph neural networks have been used to model dependencies between opinion words and aspects with good results. However, the analysis of these works is highly dependent on the quality of the dependency graph and may achieve suboptimal results for comments with ambiguous syntax. We explore a novel Multi-View Gated Graph Convolutional Network (MGGCN) to address the above problems. We utilize a Gated Graph Convolutional Network (GateGCN) for a more reasonable interaction of syntactic dependencies and semantic information, where we refine our syntactic dependency graph by adding sentiment knowledge and aspect-aware information to the dependency tree. We use the Inter-aspect Graph Convolutional Network (InterGCN) to capture information about the sentiment dependencies between multiple aspects that appear in a sentence. Finally, by adaptively learning multi-view sentiment information through Simple Residual Multilayer Perceptron(SResMLP). Experimental results on four public datasets show that our proposed model outperforms state-of-the-art models. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG."
Aspect-based Sentiment Analysis with Graph Convolutional Networks over Dependency Awareness,"Aspect-based sentiment analysis (ABSA) aims to predict the sentiment polarities of specific aspects in a comment sentence. Nowadays, models based on graph neural networks enhance semantic perception by using dependency relations on dependency graphs to analyze context and aspect words. However, these models ignore the importance of the dependency type information contained in word relations and do not utilize the dependency types to pay attention to semantic information and the noise problem caused by dependency tree parsing error. To solve the above problems, we propose a novel deep dependency-aware graph convolutional networks (DA-GCN) model in this paper. Among them, the DA-GCN establishes interactive relations with multi-head attention and makes use of the grammar information of dependency perception jointly to effectively learn related information from the generated graphs. We introduce multiple conditional random fields fusing structured attention to better capture specific aspect opinion words. Experimental results on five datasets prove the effectiveness and advancement of our proposed model. © 2022 IEEE."
Aspect-based sentiment analysis via affective knowledge enhanced graph convolutional networks,"Aspect-based sentiment analysis is a fine-grained sentiment analysis task, which needs to detection the sentiment polarity towards a given aspect. Recently, graph neural models over the dependency tree are widely applied for aspect-based sentiment analysis. Most existing works, however, they generally focus on learning the dependency information from contextual words to aspect words based on the dependency tree of the sentence, which lacks the exploitation of contextual affective knowledge with regard to the specific aspect. In this paper, we propose a graph convolutional network based on SenticNet to leverage the affective dependencies of the sentence according to the specific aspect, called Sentic GCN. To be specific, we explore a novel solution to construct the graph neural networks via integrating the affective knowledge from SenticNet to enhance the dependency graphs of sentences. Based on it, both the dependencies of contextual words and aspect words and the affective information between opinion words and the aspect are considered by the novel affective enhanced graph model. Experimental results on multiple public benchmark datasets illustrate that our proposed model can beat state-of-the-art methods. © 2021 Elsevier B.V."
Unsupervised Dependency Graph Network,"Recent work has identified properties of pretrained self-attention models that mirror those of dependency parse structures. In particular, some self-attention heads correspond well to individual dependency types. Inspired by these developments, we propose a new competitive mechanism that encourages these attention heads to model different dependency relations. We introduce a new model, the Unsupervised Dependency Graph Network (UDGN), that can induce dependency structures from raw corpora and the masked language modeling task. Experiment results show that UDGN achieves very strong unsupervised dependency parsing performance without gold POS tags and any other external information. The competitive gated heads show a strong correlation with human-annotated dependency types. Furthermore, the UDGN can also achieve competitive performance on masked language modeling and sentence textual similarity tasks. © 2022 Association for Computational Linguistics."
DocTime: A Document-level Temporal Dependency Graph Parser,"We introduce DocTime - a novel temporal dependency graph (TDG) parser that takes as input a text document and produces a temporal dependency graph. It outperforms previous BERT based solutions by a relative 4-8% on three datasets from modeling the problem as a graph-network with path-prediction loss to incorporate longer range dependencies. This work also demonstrates how the TDG graph can be used to improve the downstream tasks of temporal questions answering and NLI by a relative 4-10% with a new framework that incorporates the temporal dependency graph into the self-attention layer of Transformer models (Time-transformer). Finally, we develop and evaluate on a new temporal dependency graph dataset for the domain of contractual documents, which has not been previously explored in this setting. © 2022 Association for Computational Linguistics."
Balancing the Style-Content Trade-Off in Sentiment Transfer Using Polarity-Aware Denoising,"Text sentiment transfer aims to flip the sentiment polarity of a sentence (positive to negative or vice versa) while preserving its sentiment-independent content. Although current models show good results at changing the sentiment, content preservation in transferred sentences is insufficient. In this paper, we present a sentiment transfer model based on polarity-aware denoising, which accurately controls the sentiment attributes in generated text, preserving the content to a great extent and helping to balance the style-content trade-off. Our proposed model is structured around two key stages in the sentiment transfer process: better representation learning using a shared encoder and sentiment-controlled generation using separate sentiment-specific decoders. Empirical results show that our methods outperforms state-of-the-art baselines in terms of content preservation while staying competitive in terms of style transfer accuracy and fluency. Source code, data, and all other related details are available on Github (https://github.com/SOURO/polarity-denoising-sentiment-transfer ). © 2022, Springer Nature Switzerland AG."
Global Inference with Explicit Syntactic and Discourse Structures for Dialogue-Level Relation Extraction,"Recent research attention for relation extraction has been paid to the dialogue scenario, i.e., dialogue-level relation extraction (DiaRE). Existing DiaRE methods either simply concatenate the utterances in a dialogue into a long piece of text, or employ naive words, sentences or entities to build dialogue graphs, while the structural characteristics in dialogues have not been fully utilized. In this work, we investigate a novel dialogue-level mixed dependency graph (D2G) and an argument reasoning graph (ARG) for DiaRE with a global relation reasoning mechanism. First, we model the entire dialogue into a unified and coherent D2G by explicitly integrating both syntactic and discourse structures, which enables richer semantic and feature learning for relation extraction. Second, we stack an ARG graph on top of D2G to further focus on argument inter-dependency learning and argument representation refinement, for sufficient argument relation inference. In our global reasoning framework, D2G and ARG work collaboratively, iteratively performing lexical, syntactic and semantic information exchange and representation learning over the entire dialogue context. On two DiaRE benchmarks, our framework shows considerable improvements over the current best-performing baselines. Further analyses show that the model effectively solves the long-range dependence issue, and meanwhile gives explainable predictions. © 2022 International Joint Conferences on Artificial Intelligence. All rights reserved."
MEIM: Multi-partition Embedding Interaction Beyond Block Term Format for Efficient and Expressive Link Prediction,"Knowledge graph embedding aims to predict the missing relations between entities in knowledge graphs. Tensor-decomposition-based models, such as ComplEx, provide a good trade-off between efficiency and expressiveness, that is crucial because of the large size of real world knowledge graphs. The recent multi-partition embedding interaction (MEI) model subsumes these models by using the block term tensor format and provides a systematic solution for the trade-off. However, MEI has several drawbacks, some of which carried from its subsumed tensor-decomposition-based models. In this paper, we address these drawbacks and introduce the Multi-partition Embedding Interaction iMproved beyond block term format (MEIM) model, with independent core tensor for ensemble effects and soft orthogonality for max-rank mapping, in addition to multi-partition embedding. MEIM improves expressiveness while still being highly efficient, helping it to outperform strong baselines and achieve state-of-the-art results on difficult link prediction benchmarks using fairly small embedding sizes. The source code is released at https://github.com/tranhungnghiep/MEIM. © 2022 International Joint Conferences on Artificial Intelligence. All rights reserved."
Out of Context: A New Clue for Context Modeling of Aspect-Based Sentiment Analysis,"Aspect-based sentiment analysis (ABSA) aims to predict the sentiment expressed in a review with respect to a given aspect. The core of ABSA is to model the interaction between the context and given aspect to extract aspect-related information. In prior work, attention mechanisms and dependency graph networks are commonly adopted to capture the relations between the context and given aspect. And the weighted sum of context hidden states is used as the final representation fed to the classifier. However, the information related to the given aspect may be already discarded and adverse information may be retained in the context modeling processes of existing models. Such a problem cannot be solved by subsequent modules due to two reasons. First, their operations are conducted on the encoder-generated context hidden states, whose value cannot be changed after the encoder. Second, existing encoders only consider the context while not the given aspect. To address this problem, we argue the given aspect should be considered as a new clue out of context in the context modeling process. As for solutions, we design three streams of aspect-aware context encoders: an aspect-aware LSTM, an aspect-aware GCN, and three aspect-aware BERTs. They are dedicated to generating aspect-aware hidden states which are tailored for the ABSA task. In these aspect-aware context encoders, the semantics of the given aspect is used to regulate the information ow. Consequently, the aspect-related information can be retained and aspect-irrelevant information can be excluded in the generated hidden states. We conduct extensive experiments on several benchmark datasets with empirical analysis, demonstrating the efficacies and advantages of our proposed aspect-aware context encoders. © 2022 AI Access Foundation."
Improving Chinese Named Entity Recognition by Large-Scale Syntactic Dependency Graph,"Named entity recognition (NER) isa preliminary task in natural language processing (NLP). Recognizing Chinese named entities from unstructured texts is challenging due to the lack of word boundaries. Even if performing Chinese Word Segmentation (CWS) could help to determine word boundaries, it is still difficult to determine which words should be clustered together for entity identification, since entities are often composed of multiple-segmented words. As dependency relationships between segmented words could help to determine entity boundaries, it is crucial to employ information related to syntactic dependency relationships to improve NER performance. In this paper, we propose a novel NER model to learn information about syntactic dependency graphs with graph neural networks, and merge learned information into the classic Bidirectional Long Short-Term Memory (BiLSTM) - Conditional Random Field (CRF) NER scheme. In addition, we extract various kinds of task-specific hidden information from multiple CWS and part-of-speech (POS) tagging tasks, to further improve the NER model. We finally leverage multiple self-attention components to integrate multiple kinds of extracted information for named entity identification. Experimental results on three public benchmark datasets show that our model outperforms the state-of-the-art baselines in most scenarios.  © 2014 IEEE."
A Novel Bi-Branch Graph Convolutional Neural Network for Aspect Level Sentiment Classification,"Aspect-level sentiment classification is a fine-grained task in sentiment analysis whose main purpose is to identify the sentiment polarity of a specific aspect. Current Graph Convolutional Network (GCN) has its distinctive superiority in tackling sentiment classification both semantically and syntactically. However, GCN still has deficiencies in introducing the noise during processing and dealing with sentences of complex structure. To address these issues, we propose a novel Bi-branch GCN (Bi-B GCN). In our model, an attention weight graph, by employing the attention mechanism, is constructed to substitute the basic syntax dependency tree and thus to remove the irrelevant information. Furthermore, a semantic dependency graph is devised to supplement the semantic information to the syntax dependency tree, based on which the connection between different words can be captured. In addition, on the task of sentiment classification, the integration of semantic information and the syntactic information is conducted by using a combinational gated mechanism. Substantial experiments to validate the working performance of Bi-B GCN are performed on a variety of datasets. The encouraging results establish a strong evidence of the high accuracy of the proposed model. © 2021 IEEE."
Fine-grained implicit sentiment in financial news: Uncovering hidden bulls and bears,"The field of sentiment analysis is currently dominated by the detection of attitudes in lexically explicit texts such as user reviews and social media posts. In objective text genres such as economic news, indirect expressions of sentiment are common. Here, a positive or negative attitude toward an entity must be inferred from connotational or real-world knowledge. To capture all expressions of subjectivity, a need exists for fine-grained resources and approaches for implicit sentiment analysis. We present the SENTiVENT corpus of English business news that contains token-level annotations for target spans, polar spans, and implicit polarity (positive, negative, or neutral investor sentiment, respectively). We both directly annotate polar expressions and induce them from existing schema-based event annotations to obtain event-implied implicit sentiment tuples. This results in a large dataset of 12,400 sentiment-target tuples in 288 fully annotated articles. We validate the created resource with an inter-annotator agreement study and a series of coarse- to fine-grained supervised deep-representation-learning experiments. Agreement scores show that our annotations are of substantial quality. The coarse-grained experiments involve classifying the positive, negative, and neutral polarity of known polar expressions and, in clause-based experiments, the detection of positive, negative, neutral, and no-polarity clauses. The gold coarse-grained experiments obtain decent performance (76% accuracy and 63% macro-F1) and clause-based detection shows decreased performance (65% accuracy and 57% macro-F1) with the confusion of neutral and no-polarity. The coarse-grained results demonstrate the feasibility of implicit polarity classification as operationalized in our dataset. In the fine-grained experiments, we apply the grid tagging scheme unified model for <polar span, target span, polarity> triplet extraction, which obtains state-of-the-art performance on explicit sentiment in user reviews. We observe a drop in performance on our implicit sentiment corpus compared to the explicit benchmark (22% vs. 76% F1). We find that the current models for explicit sentiment are not directly portable to our implicit task: The larger lexical variety within implicit opinion expressions causes lexical data scarcity. We identify common errors and discuss several recommendations for implicit fine-grained sentiment analysis. Data and source code are available. © 2021 by the author."
Affective Dependency Graph for Sarcasm Detection,"Detecting sarcastic expressions could promote the understanding of natural language in social media. In this paper, we revisit sarcasm detection from a novel perspective, so as to account for the long-range literal sentiment inconsistencies. More concretely, we explore a novel scenario of constructing an affective graph and a dependency graph for each sentence based on the affective information retrieved from external affective commonsense knowledge and the syntactical information of the sentence. Based on it, an Affective Dependency Graph Convolutional Network (ADGCN) framework is proposed to draw long-range incongruity patterns and inconsistent expressions over the context for sarcasm detection by means with interactively modeling the affective and dependency information. Experimental results on multiple benchmark datasets show that our proposed approach outperforms the current state-of-the-art methods in sarcasm detection. © 2021 ACM."
Predicting Research Trends in Artificial Intelligence with Gradient Boosting Decision Trees and Time-aware Graph Neural Networks,"The Science4cast 2021 competition focuses on predicting future edges in an evolving semantic network, where each vertex represents an artificial intelligence concept, and an edge between a pair of vertices denotes that the two concepts have been investigated together in a scientific paper. In this paper, we describe our solution to this competition. We present two distinct approaches: a tree-based gradient boosting approach and a deep learning approach, and demonstrate that both approaches achieve competitive performance. Our final solution, which is based on a blend of the two approaches, achieved the 1st place among all the participating teams. The source code for this paper is available at https://github.com/YichaoLu/Science4cast2021. © 2021 IEEE."
An Aspect-Centralized Graph Convolutional Network for Aspect-Based Sentiment Classification,"Recent works on aspect-based sentiment classification have manifested the great effectiveness of modeling syntactic dependency with graph neural networks (GNN). However, these works ignore the fact of sentiment information decreasing over dependency paths due to the complex syntactic structure. To tackle the above limitation, we explore a novel solution of constructing an Aspect-Centralized Graph (ACG) for each aspect. Specifically, we directly link all words in a sentence to the aspect word and create a more effective way for the interaction between aspects and opinion words. Based on it, we also incorporate syntactic information into the new graph. To achieve this, we substitute edges of ACG with weighed values, which are calculated from the syntactic relative distance between the aspect and context words on the original dependency graph. Then we propose an Aspect Centralized Graph Convolutional Network (ACGCN) to extract aspect-specific features and effectively interact them with context representations. Extensive experiments on five benchmark datasets show that our model achieves better performance over most baseline models and extensively boosts the performance with BERT. © 2021, Springer Nature Switzerland AG."
HAIN: Hierarchical Aggregation and Inference Network for Document-Level Relation Extraction,"Document-level relation extraction (RE) aims to extract relations between entities within a document. Unlike sentence-level RE, it requires integrating evidences across multiple sentences. However, current models still lack the ability to effectively obtain relevant evidences for relation inference from multi-granularity information in the document. In this paper, we propose Hierarchical Aggregation and Inference Network (HAIN), performing the model to effectively predict relations by using global and local information from the document. Specifically, HAIN first constructs a meta dependency graph (mDG) to capture rich long distance global dependency information across the document. It also constructs a mention interaction graph (MG) to model complex local interactions among different mentions. Finally, it creates an entity inference graph (EG), based on which we design a novel hybrid attention mechanism to integrate relevant global and local information for entities. Experimental results demonstrate that our model achieves superior performance on a large-scale document-level dataset (DocRED). Extensive analyses also show that the model is particularly effective in extracting relations between entities across multiple sentences and mentions. © 2021, Springer Nature Switzerland AG."
Do syntax trees help pre-trained transformers extract information?,"Much recent work suggests that incorporating syntax information from dependency trees can improve task-specific transformer models. However, the effect of incorporating dependency tree information into pre-trained transformer models (e.g., BERT) remains unclear, especially given recent studies highlighting how these models implicitly encode syntax. In this work, we systematically study the utility of incorporating dependency trees into pre-trained transformers on three representative information extraction tasks: semantic role labeling (SRL), named entity recognition, and relation extraction. We propose and investigate two distinct strategies for incorporating dependency structure: a late fusion approach, which applies a graph neural network on the output of a transformer, and a joint fusion approach, which infuses syntax structure into the transformer attention layers. These strategies are representative of prior work, but we introduce additional model design elements that are necessary for obtaining improved performance. Our empirical analysis demonstrates that these syntax-infused transformers obtain state-of-the-art results on SRL and relation extraction tasks. However, our analysis also reveals a critical shortcoming of these models: we find that their performance gains are highly contingent on the availability of human-annotated dependency parses, which raises important questions regarding the viability of syntax-augmented transformers in real-world applications. © 2021 Association for Computational Linguistics"
Multi-Grained Dependency Graph Neural Network for Chinese Open Information Extraction,"Recent neural Open Information Extraction (OpenIE) models have improved traditional rule-based systems significantly for Chinese OpenIE tasks. However, these neural models are mainly word-based, suffering from word segmentation errors in Chinese. They utilize dependency information in a shallow way, making multi-hop dependencies hard to capture. This paper proposes a Multi-Grained Dependency Graph Neural Network (MGD-GNN) model to address these problems. MGD-GNN constructs a multi-grained dependency (MGD) graph with dependency edges between words and soft-segment edges between words and characters. Our model makes predictions based on character features while still has word boundary knowledge through word-character soft-segment edges. MGD-GNN updates node representations using a deep graph neural network to fully exploit the topology structure of the MGD graph and capture multi-hop dependencies. Experiments on a large-scale Chinese OpenIE dataset SpanSAOKE shows that our model could alleviate the propagation of word segmentation errors and use dependency information more effectively, giving significant improvements over previous neural OpenIE models. © 2021, Springer Nature Switzerland AG."
Enhanced Named Entity Recognition with Semantic Dependency,"Dependency-based models for the named entity recognition (NER) task have shown promising results by capturing long-distance relationships between words in a sentence. However, while existing models focus on the syntactic dependency between entities, we are unaware of any work that considers semantic dependency. In this work, we study the usefulness of semantic dependency information for NER. We propose a NER model that is guided by semantic dependency graphs instead of syntactic dependency trees. The extensive experiments illustrate the effectiveness of the proposed model and the advantages of semantic dependency over syntactic dependency for NER. Also, it shows correlations between the NER performance and the semantic dependency annotations qualities. © 2021, Springer Nature Switzerland AG."
Dependency graph enhanced dual-transformer structure for aspect-based sentiment classification,"Aspect-based sentiment classification is a popular task aimed at identifying the corresponding emotion of a specific aspect. One sentence may contain various sentiments for different aspects. Many sophisticated methods such as attention mechanism and Convolutional Neural Networks (CNN) have been widely employed for handling this challenge. Recently, semantic dependency tree implemented by Graph Convolutional Networks (GCN) is introduced to describe the inner connection between aspects and the associated emotion words. But the improvement is limited due to the noise and instability of dependency trees. To this end, we propose a dependency graph enhanced dual-transformer network (named DGEDT) by jointly considering the flat representations learnt from Transformer and graph-based representations learnt from the corresponding dependency graph in an iterative interaction manner. Specifically, a dual-transformer structure is devised in DGEDT to support mutual reinforcement between the flat representation learning and graph-based representation learning. The idea is to allow the dependency graph to guide the representation learning of the transformer encoder and vice versa. The results on five datasets demonstrate that the proposed DGEDT outperforms all state-of-the-art alternatives with a large margin. © 2020 Association for Computational Linguistics"
Can Network Analysis Techniques Help to Predict Design Dependencies? An Initial Study,"The degree of dependencies among the modules of a software system is a key attribute to characterize its design structure and its ability to evolve over time. Several design problems are often correlated with undesired dependencies among modules. Being able to anticipate those problems is important for developers, so they can plan early for maintenance and refactoring efforts. However, existing tools are limited to detecting undesired dependencies once they appeared in the system. In this work, we investigate whether module dependencies can be predicted (before they actually appear). Since the module structure can be regarded as a network, i.e, a dependency graph, we leverage on network features to analyze the dynamics of such a structure. In particular, we apply link prediction techniques for this task. We conducted an evaluation on two Java projects across several versions, using link prediction and machine learning techniques, and assessed their performance for identifying new dependencies from a project version to the next one. The results, although preliminary, show that the link prediction approach is feasible for package dependencies. Also, this work opens opportunities for further development of software-specific strategies for dependency prediction. © 2018 IEEE."
