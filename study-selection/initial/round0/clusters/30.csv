Title,Abstract
Resnet Video 3D for Gait Retrieval: A Deep Learning Approach to Human Identification,"Gait, the distinctive way a person walks, is a useful biometric trait for various applications such as crime prevention, forensic identification, and social security. Gait retrieval, which aims to find the person who matches a given gait, is an active research area, its research has drawn a significant increase. However, learning discriminative temporal features from gait data is difficult due to the subtle variations in the spatial domain of the silhouette. Recent deep learning methods have demonstrated their effectiveness for gait retrieval by learning more robust features from raw video data. In this paper, we propose a baseline network based on ResNet video R3D-18, which can capture both spatial and temporal information from the data, to address the gait retrieval problem. Our experimental results show that our optimized backbone network can extract powerful vector representations of gait and achieve high performance in retrieving the person who matches the gait from the database. On CASIA-B dataset, we obtain Rank-1 accuracy of 97.09% and Rank-10 accuracy of 99.27% under normal walking condition. The source code will be available at.  © 2023 ACM."
Knowledge transduction for cross-domain few-shot learning,"Cross-Domain Few-Shot Learning (CDFSL) aims to classify new categories from new domains with few samples. It confronts a greater domain shift than Few-Shot Learning (FSL). Based on the transfer learning framework, we propose a Knowledge Transduction method (KT) to alleviate domain shift and achieve few-shot recognition. First, a feature adaptation module based on feed-forward attention is constructed to learn domain-adapted features. The feature adaptation module weakens domain shift by transducing knowledge from an auxiliary dataset to the new dataset. Second, a feature transduction module based on deep sparse representation is developed to gather class semantics from limited support images. The feature transduction module transduces knowledge from support images to query images for few-shot recognition. In addition, a stochastic image augmentation method is proposed for FSL to train a more generalized model through consistency representation learning. Our method achieves competitive accuracy on four CDFSL datasets and four FSL datasets compared to state-of-the-art methods. The source code is available at https://github.com/XDUpfLi/KT. © 2023"
Decomposed adversarial domain generalization,"We tackle the problem of generalizing a predictor trained on a set of source domains to an unseen target domain, where the source and target domains are different but related to one another, i.e., the domain generalization problem. Prior adversarial methods rely on solving the minimax problems to align in the neural network embedding space the components of the domains (i.e., a set of marginal distributions, a set of marginal distributions and multiple sets of class-conditional distributions). However, these methods introduce additional parameters (for each set of distributions) to the network predictor and are difficult to train. In this work, we propose to directly align the domains themselves via solving a minimax problem that can be decomposed and converted into a min one. Particularly, we analytically solve the max problem with respect to (w.r.t.) the domain discriminators, and convert the minimax problem into a min one w.r.t. the embedding function. This is more advantageous since in the end our approach introduces no additional network parameters and simplifies the training procedure. We evaluate our approach on several multi-domain datasets and testify its superiority over the relevant methods. The source code is available at https://github.com/sentaochen/Decomposed-Adversarial-Domain-Generalization. © 2023 The Author(s)"
Self-Adaptive Driving in Nonstationary Environments through Conjectural Online Lookahead Adaptation,"Powered by deep representation learning, re-inforcement learning (RL) provides an end-to-end learning framework capable of solving self-driving (SD) tasks without manual designs. However, time-varying nonstationary environments cause proficient but specialized RL policies to fail at execution time. For example, an RL-based SD policy trained under sunny days does not generalize well to rainy weather. Even though meta learning enables the RL agent to adapt to new tasks/environments, its offline operation fails to equip the agent with online adaptation ability when facing nonstationary environments. This work proposes an online meta reinforcement learning algorithm based on the conjectural online lookahead adaptation (COLA). COLA determines the online adaptation at every step by maximizing the agent's conjecture of the future performance in a lookahead horizon. Experimental results demonstrate that under dynamically changing weather and lighting conditions, the COLA-based self-adaptive driving outperforms the baseline policies regarding online adaptability. A demo video, source code, and appendixes are available at https://github.com/Panshark/COLA © 2023 IEEE."
Towards Online Domain Adaptive Object Detection,"Existing object detection models assume both the training and test data are sampled from the same source do-main. This assumption does not hold true when these detectors are deployed in real-world applications, where they en-counter new visual domains. Unsupervised Domain Adaptation (UDA) methods are generally employed to mitigate the adverse effects caused by domain shift. Existing UDA methods operate in an offline manner where the model is first adapted toward the target domain and then deployed in real-world applications. However, this offline adaptation strategy is not suitable for real-world applications as the model frequently encounters new domain shifts. Hence, it is critical to develop a feasible UDA method that generalizes to the new domain shifts encountered during deployment time in a continuous online manner. To this end, we propose a novel unified adaptation framework that adapts and improves generalization on the target domain in both offline and online settings. Specifically, we introduce MemXformer - a cross-attention transformer-based memory module where items in the memory take advantage of domain shifts and record prototypical patterns of the target distribution. Further, MemXformer produces strong positive and negative pairs to guide a novel contrastive loss, which enhances target-specific representation learning. Experiments on diverse detection benchmarks show that the proposed strategy producs state-of-the-art performance in both offline and online settings. To the best of our knowledge, this is the first work to address online and offline adaptation settings for object detection. Source code: https://github.com/Vibashan/memXformer-online-da © 2023 IEEE."
Generalized few-shot object detection in remote sensing images,"Recently few-shot object detection (FSOD) in remote sensing images (RSIs) has drawn increasing attention. However, the current FSOD methods in RSIs merely focus on the detection performance of few-shot novel classes while ignoring the severe degradation of the base class performance. Generalized few-shot object detection (G-FSOD) aims to solve the FSOD problem without forgetting previous knowledge. In this paper, we focus on the G-FSOD in RSIs and propose a Generalized Few-Shot Detector (G-FSDet) that can learn novel knowledge without forgetting. Through the comprehensive analysis of each component in the detector, a novel efficient transfer-learning framework is presented as the foundation of our G-FSDet, which is more suitable for FSOD in remote sensing scenes. Considering the greater intra-class diversity and lower inter-class separability of geospatial objects, we design a metric-based discriminative loss to learn a more discriminative classifier in the few-shot fine-tuning stage. Furthermore, a representation compensation module is proposed to alleviate the catastrophic forgetting problem by decoupling the representation learning of previous and novel knowledge. Extensive experiments on DIOR and NWPU VHR-10.v2 datasets demonstrate that our proposed G-FSDet achieves competitive novel class performance with minor degradation in the base class, reaching state-of-the-art overall performance among all few-shot settings. The source code is available at (https://github.com/RSer-XDU/G-FSDet). © 2022 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)"
ASA-Net: Deep representation learning between object silhouette and attributes,"Object silhouette and semantic attributes are respectively verified for their effectiveness as auxiliary supervision in image recognition. It encourages us to propose a novel zero-shot recognition model, Attribute-Segmentation-Attribute network (ASA-Net), which jointly conducts object segmentation, attribute prediction and recognition in a multi-task learning manner. Firstly, a feature extraction module is pre-trained based on smooth attribute and category annotations. This module is then adopted to initialize the feature encoding module of a multi-scale segmentation CNN to generate coarse-to-fine object silhouettes. Finally, the segments are multiplied with the original image to obtain regions of interest, and semantic features of these regions are extracted and combined to predict attributes. The obtained attribute prediction is further projected into the category space to accomplish the zero-shot recognition task. Experimental results on two public benchmarks indicate that our ASA-Net performs better than baseline and existing methods in attribute prediction and segmentation tasks, as well as the unseen object recognition. The source code is publicly available online (https://github.com/YsSue/ASA-Net.git). © 2022 Elsevier B.V."
Graph-Based Surgical Instrument Adaptive Segmentation via Domain-Common Knowledge,"Unsupervised domain adaptation (UDA), aiming to adapt the model to an unseen domain without annotations, has drawn sustained attention in surgical instrument segmentation. Existing UDA methods neglect the domain-common knowledge of two datasets, thus failing to grasp the inter-category relationship in the target domain and leading to poor performance. To address these issues, we propose a graph-based unsupervised domain adaptation framework, named Interactive Graph Network (IGNet), to effectively adapt a model to an unlabeled new domain in surgical instrument segmentation tasks. In detail, the Domain-common Prototype Constructor (DPC) is first advanced to adaptively aggregate the feature map into domain-common prototypes using the probability mixture model, and construct a prototypical graph to interact the information among prototypes from the global perspective. In this way, DPC can grasp the co-occurrent and long-range relationship for both domains. To further narrow down the domain gap, we design a Domain-common Knowledge Incorporator (DKI) to guide the evolution of feature maps towards domain-common direction via a common-knowledge guidance graph and category-attentive graph reasoning. At last, the Cross-category Mismatch Estimator (CME) is developed to evaluate the category-level alignment from a graph perspective and assign each pixel with different adversarial weights, so as to refine the feature distribution alignment. The extensive experiments on three types of tasks demonstrate the feasibility and superiority of IGNet compared with other state-of-the-art methods. Furthermore, ablation studies verify the effectiveness of each component of IGNet. The source code is available at https://github.com/CityU-AIM-Group/Prototypical-Graph-DA.  © 1982-2012 IEEE."
Facilitating Radar-Based Gesture Recognition With Self-Supervised Learning,"With deep learning, millimeter-wave radar-based gesture recognition applications have achieved satisfactory results. However, most existing approaches highly rely on highquality labeled data, and they suffer from severe over-fitting when labeled data are scarce. To end this, we present RadarAE, a novel representation learning framework for radar sensing applications. RadarAE learns sophisticated representations from massive low-cost unlabeled radar data, which enables accurate gesture recognition with few labeled data. To achieve this goal, we first meticulously observe the characteristics of raw radar data and extract an effective feature, Spatio-Temporal Motion Map (STMM). Then we borrow the key principle of Masked Autoencoders (MAE), a self-supervised learning technique for images, and propose an MAE-like model to learn useful representations from STMM. To adapt RadarAE to radar sensing applications, we present a series of customization techniques, including data augmentation, optimized model structure, and adaptive pretraining method. With the learned high-level representations, gesture recognition models can achieve superior performance in few-shot scenarios. Experiment results show that our model can achieve 79.1%, 92.1%, 97.8%, and 99.5% recognition accuracy in the 1, 2, 4, and 8-shot scenarios, respectively, where x-shot refers to the number of labeled samples for each gesture type. The source codes and dataset are made publicly available11https://githuh.com/Ela-Boska/RadarAE.  © 2022 IEEE."
Zero-Shot Dense Retrieval with Momentum Adversarial Domain Invariant Representations,"Dense retrieval (DR) methods conduct text retrieval by first encoding texts in the embedding space and then matching them by nearest neighbor search. This requires strong locality properties from the representation space, e.g., close allocations of each small group of relevant texts, which are hard to generalize to domains without sufficient training data. In this paper, we aim to improve the generalization ability of DR models from source training domains with rich supervision signals to target domains without any relevance label, in the zero-shot setting. To achieve that, we propose Momentum adversarial Domain Invariant Representation learning (MoDIR), which introduces a momentum method to train a domain classifier that distinguishes source versus target domains, and then adversarially updates the DR encoder to learn domain invariant representations. Our experiments show that MoDIR robustly outperforms its baselines on 10+ ranking datasets collected in the BEIR benchmark in the zero-shot setup, with more than 10% relative gains on datasets with enough sensitivity for DR models' evaluation. Source code is available at https://github.com/ji-xin/modir. © 2022 Association for Computational Linguistics."
Self-Supervised Autoregressive Domain Adaptation for Time Series Data,"Unsupervised domain adaptation (UDA) has successfully addressed the domain shift problem for visual applications. Yet, these approaches may have limited performance for time series data due to the following reasons. First, they mainly rely on the large-scale dataset (i.e., ImageNet) for source pretraining, which is not applicable for time series data. Second, they ignore the temporal dimension on the feature space of the source and target domains during the domain alignment step. Finally, most of the prior UDA methods can only align the global features without considering the fine-grained class distribution of the target domain. To address these limitations, we propose a <bold>S</bold>e<bold>L</bold>f-supervised <bold>A</bold>uto<bold>R</bold>egressive <bold>D</bold>omain <bold>A</bold>daptation (SLARDA) framework. In particular, we first design a self-supervised (SL) learning module that uses forecasting as an auxiliary task to improve the transferability of source features. Second, we propose a novel autoregressive domain adaptation technique that incorporates temporal dependence of both source and target features during domain alignment. Finally, we develop an ensemble teacher model to align class-wise distribution in the target domain via a confident pseudo labeling approach. Extensive experiments have been conducted on three real-world time series applications with 30 cross-domain scenarios. The results demonstrate that our proposed SLARDA method significantly outperforms the state-of-the-art approaches for time series domain adaptation. Our source code is available at: https://github.com/mohamedr002/SLARDA. IEEE"
Shaping Visual Representations with Attributes for Few-Shot Recognition,"Few-shot recognition aims to recognize novel categories under low-data regimes. Some recent few-shot recognition methods introduce auxiliary semantic modality, i.e., category attribute information, into representation learning, which enhances the feature discrimination and improves the recognition performance. Most of these existing methods only consider the attribute information of support set while ignoring the query set, resulting in a potential loss of performance. In this letter, we propose a novel attribute-shaped learning (ASL) framework, which can jointly perform query attributes generation and discriminative visual representation learning for few-shot recognition. Specifically, a visual-attribute predictor (VAP) is constructed to predict the attributes of queries. By leveraging the attributes information, an attribute-visual attention module (AVAM) is designed, which can adaptively utilize attributes and visual representations to learn more discriminative features. Under the guidance of attribute modality, our method can learn enhanced semantic-aware representation for classification. Experiments demonstrate that our method can achieve competitive results on CUB and SUN benchmarks. Our source code is available at: https://github.com/chenhaoxing/ASL.  © 1994-2012 IEEE."
Joint local and statistical discriminant learning via feature alignment,"Image processing has attracted increasing attention in recent researches to solve domain shift problem where machine learning algorithms are applied to sets of unseen images. Domain shift problem occurs when the training (source domain) and test (target domain) sets are collected in different environmental conditions but in related domains. In this way, the adaptation across data distributions of the source and target datasets are suggested as domain adaptation framework to overcome the performance degradation. In this paper, a novel domain adaptation method referred as joint local and statistical discriminant learning via feature alignment (LSA), is proposed to find a cross-domain subspace by matching cross-domain distribution shift and adapting the class structures of the local and statistical distributions across the source and target domains, during the dimensionality reduction. Specifically, LSA projects samples into an embedded subspace in which the distances across the samples from same class are minimized and the distances across samples from different classes are maximized, at each local and statistical area, during alignment of marginal and conditional distributions. Furthermore, the class densities of samples based on manifold structure in different classes are preserved to provide more separability across various classes. To evaluate the proposed method, comprehensive experiments have been conducted on benchmark cross-domain object and digit recognition datasets. Experimental results have verified the superiority of LSA with a large margin in average classification accuracy against several state-of-the-art distribution matching and discriminant learning methods of domain adaptation. Moreover, the results have demonstrated the effectiveness of our proposed representation learning. Our source code is available at https://github.com/jtahmores/LSA. © 2019, Springer-Verlag London Ltd., part of Springer Nature."
Selfgait: A spatiotemporal representation learning method for self-supervised gait recognition,"Gait recognition plays a vital role in human identification since gait is a unique biometric feature that can be perceived at a distance. Although existing gait recognition methods can learn gait features from gait sequences in different ways, the performance of gait recognition suffers from insufficient labeled data, especially in some practical scenarios associated with short gait sequences or various clothing styles. It is unpractical to label the numerous gait data. In this work, we propose a self-supervised gait recognition method, termed SelfGait, which takes advantage of the massive, diverse, unlabeled gait data as a pre-training process to improve the representation abilities of spatiotemporal backbones. Specifically, we employ the horizontal pyramid mapping (HPM) and micro-motion template builder (MTB) as our spatiotemporal backbones to capture the multi-scale spatiotemporal representations. Experiments on CASIA-B and OU-MVLP benchmark gait datasets demonstrate the effectiveness of the proposed SelfGait compared with four state-of-the-art gait recognition methods. The source code has been released at https://github.com/EchoItLiu/SelfGait. © 2021 IEEE"
Central moment discrepancy (CMD) for domain-invariant representation learning,"The learning of domain-invariant representations in the context of domain adaptation with neural networks is considered. We propose a new regularization method that minimizes the domain-specific latent feature representations directly in the hidden activation space. Although some standard distribution matching approaches exist that can be interpreted as the matching of weighted sums of moments, e.g. Maximum Mean Discrepancy, an explicit order-wise matching of higher order moments has not been considered before. We propose to match the higher order central moments of probability distributions by means of order-wise moment differences. Our model does not require computationally expensive distance and kernel matrix computations. We utilize the equivalent representation of probability distributions by moment sequences to define a new distance function, called Central Moment Discrepancy (CMD). We prove that CMD is a metric on the set of probability distributions on a compact interval. We further prove that convergence of probability distributions on compact intervals w. r. t. the new metric implies convergence in distribution of the respective random variables. We test our approach on two different benchmark data sets for object recognition (Office) and sentiment analysis of product reviews (Amazon reviews). CMD achieves a new state-of-the-art performance on most domain adaptation tasks of Office and outperforms networks trained with Maximum Mean Discrepancy, Variational Fair Autoencoders and Domain Adversarial Neural Networks on Amazon reviews. In addition, a post-hoc parameter sensitivity analysis shows that the new approach is stable w. r. t. parameter changes in a certain interval. The source code of the experiments is publicly available. © ICLR 2019 - Conference Track Proceedings. All rights reserved."
