Title,Abstract
Role-aware random walk for network embedding,"Network embedding is a fundamental part of many network analysis tasks, including node classification and link prediction. The existing random walk-based embedding methods aim to learn node embedding that preserves information on either node proximity or structural similarity. However, the information on both role and community is important to network nodes. To address the shortcomings of the existing methods, this paper proposes a novel method for network embedding called the RARE, which can be used for the analysis of different types of networks and even disconnected networks. The proposed method uses the role and community information of nodes to preserve both node proximity and structural similarity in the learned node embeddings. The walks generated through the role-aware random walk can capture the role and community information of nodes. The obtained walks are input to the Skip-gram model to learn the final embedding of nodes. In addition, the RARE is extended to the CRARE that adds the sampling of high-order community members to the customized random walk so that the node's representation can preserve more structural information of the network. The performances of the proposed methods are evaluated on multi-class node classification, link prediction, and network visualization tasks. Experimental results on different domain datasets indicate that the proposed methods outperform the baseline methods. The proposed methods can be further accelerated using parallelization in the random walk generation process. The source code: https://github.com/HeguiZhang/RARE. © 2023"
A subspace constraint based approach for fast hierarchical graph embedding,"Hierarchy network, as a type of complex graphs, is widely used in many application scenarios such as social network analysis in web, human resource analysis in e-government, and product recommendation in e-commerce. Hierarchy preserving network embedding is a representation learning method that project nodes into feature space by preserving the hierarchy property of networks. Recently, researches on network embedding are devoted to mining hierarchical structures and profit a lot form it. Among these works, SpaceNE stands out of preserving hierarchy with the help of subspace constraint on the hierarchical subspace system. However, like all other existing works, SpaceNE is based on transductive learning method and is hard to generalize to new nodes. Besides, they have high time complexity and hard to be scalable to large-scale networks. This paper proposes an inductive method, FastHGE to learn node representation more efficiently and generalize to new nodes more easily. As SpaceNE, a hierarchy network is embedded into a hierarchical subspace tree. For upper communities, we exploit transductive learning by preserving inner-subspace proximity of subspace from the same ancestor. For extending to new nodes, we adopt inductive learning to learn representations of leaf nodes. The overall representation of a node is retrieved by concatenating the embedding vectors of all its ancestor communities and the leaf node. By learning the basis vectors of subspace, the computing cost is alleviated from updating many parameters of projection matrices as in SpaceNE. The performance evaluation experiments show that FastHGE outperforms with much fast speed and the same accuracy. For example, in the node classification, FastHGE is nearly 30 times faster than SpaceNE. The source code of FastHGE is available online. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature."
Generating post-hoc explanations for Skip-gram-based node embeddings by identifying important nodes with bridgeness,"Node representation learning in a network is an important machine learning technique for encoding relational information in a continuous vector space while preserving the inherent properties and structures of the network. Recently, unsupervised node embedding methods such as DeepWalk (Perozzi et al., 2014), LINE (Tang et al., 2015), struc2vec (Ribeiro et al., 2017), PTE (Tang et al., 2015), UserItem2vec (Wu et al., 2020), and RWJBG (Li et al., 2021) have emerged from the Skip-gram model (Mikolov et al., 2013) and perform better performance in several downstream tasks such as node classification and link prediction than the existing relational models. However, providing post-hoc explanations of unsupervised embeddings remains a challenging problem because of the lack of explanation methods and theoretical studies applicable for embeddings. In this paper, we first show that global explanations to the Skip-gram-based embeddings can be found by computing bridgeness under a spectral cluster-aware local perturbation. Moreover, a novel gradient-based explanation method, which we call GRAPH-wGD, is proposed that allows the top-q global explanations about learned graph embedding vectors more efficiently. Experiments show that the ranking of nodes by scores using GRAPH-wGD is highly correlated with true bridgeness scores. We also observe that the top-q node-level explanations selected by GRAPH-wGD have higher importance scores and produce more changes in class label prediction when perturbed, compared with the nodes selected by recent alternatives, using five real-world graphs. © 2023 Elsevier Ltd"
Deep embedded clustering with distribution consistency preservation for attributed networks,"Many complex systems in the real world can be characterized as attributed networks. To mine the potential information in these networks, deep embedded clustering, which obtains node representations and clusters simultaneously, has been given much attention in recent years. Under the assumption of consistency for data in different views, the cluster structure of network topology and that of node attributes should be consistent for an attributed network. However, many existing methods ignore this property, even though they separately encode node representations from network topology and node attributes and cluster nodes on representation vectors learned from one of the views. Therefore, in this study, we propose an end-to-end deep embedded clustering model for attributed networks. It utilizes graph autoencoder and node attribute autoencoder to learn node representations and cluster assignments. In addition, a distribution consistency constraint is introduced to maintain the latent consistency of cluster distributions in two views. Extensive experiments on several datasets demonstrate that the proposed model achieves significantly better or competitive performance compared with the state-of-the-art methods. The source code can be found at https://github.com/Zhengymm/DCP. © 2023"
Community preserving adaptive graph convolutional networks for link prediction in attributed networks,"Link prediction in attributed networks has attracted increasing attention recently due to its valuable real-world applications. Various related methods have been proposed, but most of them cannot effectively utilize community structure, neither can they well fuse attribute information and link information to improve the performance. Inspired by our empirical observations on how community structure affects the generation of links, we propose a novel Community Preserving Adaptive Graph Convolutional Networks (CPAGCN) method to tackle the link prediction task in attributed networks. Specifically, CPAGCN is composed of two core modules: network embedding and link prediction. Network embedding module utilizes AGCN to seamlessly fuse link information and attribute information to obtain node representations, which are simultaneously driven to preserve community structure via an appropriate community detection model. Taking these node representations as the input, link prediction module applies multilayer perception (MLP) to directly learn the prediction scores for potential links. Through combining the graph reconstruction loss with the prediction loss to train AGCN and MLP jointly, CPAGCN can learn node representations that are more beneficial to predicting links. To verify the effectiveness of CPAGCN, we conduct extensive experiments on six real-world attributed networks. The results demonstrate that CPAGCN performs better than several strong competitors in link prediction. The source code is available at https://github.com/GDM-SCNU/CPAGCN. © 2023 Elsevier B.V."
Detecting Vulnerable Nodes in Urban Infrastructure Interdependent Network,"Understanding and characterizing the vulnerability of urban infrastructures, which refers to the engineering facilities essential for the regular running of cities and that exist naturally in the form of networks, is of great value to us. Potential applications include protecting fragile facilities and designing robust topologies, etc. Due to the strong correlation between different topological characteristics and infrastructure vulnerability and their complicated evolution mechanisms, some heuristic and machine assisted analysis fall short in addressing such a scenario. In this paper, we model the interdependent network as a heterogeneous graph and propose a system based on graph neural network with reinforcement learning, which can be trained on real-world data, to characterize the vulnerability of the city system accurately. The presented system leverages deep learning techniques to understand and analyze the heterogeneous graph, which enables us to capture the risk of cascade failure and discover vulnerable infrastructures of cities. Extensive experiments with various requests demonstrate not only the expressive power of our system but also transferring ability and necessity of the specific components. All source codes and models including those that can reproduce all figures analyzed in this work are publicly available at this link: https://github.com/tsinghua-fib-lab/KDD2023-ID546-UrbanInfra.  © 2023 Owner/Author."
HyperDNE: Enhanced hypergraph neural network for dynamic network embedding,"Representation learning provides an attractive opportunity to model the evolution of dynamic networks. However, the existing methods have two limitations: (1) most graph neural network-based methods fail to utilize the high-order proximity of nodes that captures the important properties of a network topology; (2) evolutionary dynamics-based methods are much fine-grained in modeling time information but neglect the coherence of dynamic networks, which leads to the model being susceptible to subtle noise. In this paper, we propose an enhanced hypergraph neural network framework for dynamic network embedding (HyperDNE) to tackle these issues. Specifically, we innovatively design a sequential hypergraph with dual-stream output to explore the group properties of nodes and edges, and a line graph neural network is added as an auxiliary enhancement scheme to further aggregate social influence from the degree of social convergence. Then, we compute the final embedding through attentions along the node and hyperedge levels to fuse multi-level variations in the network structure. The experimental results on six real networks demonstrate significant gains for HyperDNE over several state-of-the-art network embedding baselines. The dataset and source code of HyperDNE are publicly available at https://github.com/qhgz2013/HyperDNE. © 2023 Elsevier B.V."
Link Predictability Classes in Complex Networks,"In this paper, we study how the observed quality of a network link prediction method applied to a part of a network can be further used for the analysis of the whole network. Namely, we first show that it can be determined for a part of the network which topological features of node pairs lead to a certain level of link prediction quality. Based on it, we construct a link predictability (prediction quality) classifier for the network links. This is further used in the other part of the network for controlling the link prediction quality typical for the method and the network. The actual link prediction method is not used then already. Experiments with synthetic and real-world networks show a good performance of the proposed pipeline. The source code, the datasets and the results related to our study are publicly available on GitHub. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG."
Link Prediction with Multiple Structural Attentions in Multiplex Networks,"Many real networks can be viewed as multiplex networks with more than one layers. As different layers are usually not independent from each other, they can provide complementary information in the task of link prediction. In this paper, with the help of attention mechanism, we dig the structural correlations among different layers of the multiplex network as well as the network structural information of the target layer to make more precise link predictions. Specifically, we introduce three different attentions, namely the intra-layer distance/degree attention, the intra-layer neighbourhood attention, and the interlayer structural attention, to calculate both the influence among nodes in the same layer and the link correlations in different layers. Compared with other state-of-the art methods which usually require the information of node attributes or edge types, we only utilize the topological information of the network and thus provide a more general link prediction solution for multiplex network. We conduct comprehensive experiments on several real-world datatsets of different scales. By comparing with the state-of-the-art link prediction algorithms, we show the advantages of our algorithm, and the effectiveness of different attentions. Also, through visual case studies we uncover some intuitions about the relationship between the graph structure and the existence of a link. We make our source code anonymously available at: (will be released after review) © 2021 IEEE."
Network Embedding on Hierarchical Community Structure Network,"Network embedding is a method of learning a low-dimensional vector representation of network vertices under the condition of preserving different types of network properties. Previous studies mainly focus on preserving structural information of vertices at a particular scale, like neighbor information or community information, but cannot preserve the hierarchical community structure, which would enable the network to be easily analyzed at various scales. Inspired by the hierarchical structure of galaxies, we propose the Galaxy Network Embedding (GNE) model, which formulates an optimization problem with spherical constraints to describe the hierarchical community structure preserving network embedding. More specifically, we present an approach of embedding communities into a low-dimensional spherical surface, the center of which represents the parent community they belong to. Our experiments reveal that the representations from GNE preserve the hierarchical community structure and show advantages in several applications such as vertex multi-class classification, network visualization, and link prediction. The source code of GNE is available online.  © 2021 ACM."
Motif-preserving dynamic attributed network embedding,"Network embedding has emerged as a new learning paradigm to embed complex network into a low-dimensional vector space while preserving node proximities in both network structures and properties. It advances various network mining tasks, ranging from link prediction to node classification. However, most existing works primarily focus on static networks while many networks in real-life evolve over time with addition/deletion of links and nodes, naturally with associated attribute evolution. In this work, we present Motif-preserving Temporal Shift Network (MTSN), a novel dynamic network embedding framework that simultaneously models the local high-order structures and temporal evolution for dynamic attributed networks. Specifically, MTSN learns node representations by stacking the proposed TIME module to capture both local high-order structural proximities and node attributes by motif-preserving encoder and temporal dynamics by temporal shift operation in a dynamic attributed network. Finally, we perform extensive experiments on four real-world network datasets to demonstrate the superiority of MTSN against state-of-the-art network embedding baselines in terms of both effectiveness and efficiency. The source code of our method is available at: https://github.com/ZhijunLiu95/MTSN.  Â© 2021 ACM."
Search Efficient Binary Network Embedding,"Traditional network embedding primarily focuses on learning a continuous vector representation for each node, preserving network structure and/or node content information, such that off-the-shelf machine learning algorithms can be easily applied to the vector-format node representations for network analysis. However, the learned continuous vector representations are inefficient for large-scale similarity search, which often involves finding nearest neighbors measured by distance or similarity in a continuous vector space. In this article, we propose a search efficient binary network embedding algorithm called BinaryNE to learn a binary code for each node, by simultaneously modeling node context relations and node attribute relations through a three-layer neural network. BinaryNE learns binary node representations using a stochastic gradient descent-based online learning algorithm. The learned binary encoding not only reduces memory usage to represent each node, but also allows fast bit-wise comparisons to support faster node similarity search than using Euclidean or other distance measures. Extensive experiments and comparisons demonstrate that BinaryNE not only delivers more than 25 times faster search speed, but also provides comparable or better search quality than traditional continuous vector based network embedding methods. The binary codes learned by BinaryNE also render competitive performance on node classification and node clustering tasks. The source code of the BinaryNE algorithm is available at https://github.com/daokunzhang/BinaryNE.  © 2021 ACM."
Deep multiplex graph infomax: Attentive multiplex network embedding using global information,"Network embedding has recently garnered attention due to the ubiquity of the networked data in the real-world. A network is useful for representing the relationships among objects, and these network include social network, publication network, and protein–protein interaction network. Most existing network embedding methods assume that only a single type of relation exists between nodes. However, we focus on the fact that two nodes in a network can be connected by multiple types of relations; such a network is called multi-view network or multiplex network. Although several existing work consider the multiplexity of a network, they overlook node attributes, resort to node labels for training, and fail to model the global properties of a graph. In this work, we present an unsupervised network embedding method for attributed multiplex network called DMGI, inspired by Deep Graph Infomax (DGI) that maximizes the mutual information between local patches of a graph, and the global representation of the entire graph. Building on top of DGI, we devise a systematic way to jointly integrate the node embeddings from multiple graphs by introducing (1) the consensus regularization framework that minimizes the disagreements among the relation-type specific node embeddings, and (2) the universal discriminator that discriminates true samples regardless of the relation types. We also show that the attention mechanism infers the importance of each relation type, and thus can be useful for filtering unnecessary relation types as a preprocessing step. We perform comprehensive experiments not only on unsupervised downstream tasks, such as clustering and similarity search, but also a supervised downstream task, i.e., node classification, and demonstrate that DMGI outperforms the state-of-the-art methods, even though DMGI is fully unsupervised. The source code is can be found here https://github.com/pcy1302/DMGI. © 2020 Elsevier B.V."
Enhancing knowledge graph embedding by composite neighbors for link prediction,"Knowledge graph embedding (KGE) aims to represent entities and relations in a low-dimensional continuous vector space. Recent KGE works focus on incorporating additional information, such as local neighbors and textual descriptions, to learn valuable representations. However, the non-uniformity and redundancy hinder the effectiveness of entity features from those information sources. In this paper, we propose a novel end-to-end framework, called composite neighborhood embedding (CoNE), utilizing composite neighbors to enhance the existing KGE methods. To ease past problems, the new composite neighbors are gathered from both entity descriptions and local neighbors. We design a novel Graph Memory Networks to extract entity features from composite neighbors, and fulfill the entity representation in the target KGE method. The experimental results show that CoNE effectively enhances three different KGE methods, TransE, ConvE, and RotatE, and achieves the state-of-the-art results on four real-world large datasets. Furthermore, our approach outperforms the recent text-enhanced models with fewer parameters and calculation. The source code of our work can be obtained from https://github.com/KyneWang/CoNE. © 2020, Springer-Verlag GmbH Austria, part of Springer Nature."
A multilayered informative randomwalk for attributed social network embedding,"Network representation learning (also known as Graph embedding) is a technique to map the nodes of a network to a lower dimensional vector space. Random walk based representation techniques are found to be efficient as they can easily preserve different orders of proximities between the nodes in the embedding space. Most of the social networks now-a-days have some content (or attributes) associated with each node. These attributes can provide complementary information along with the link structure of the network. But in a real life network, the information carried by the link structure and that by the attributes vary significantly over the nodes. Most of the existing unsupervised attributed network embedding algorithms do not distinguish between the link structure and the attributes of a node depending on their informativeness. In this work, we propose an unsupervised node embedding technique that exploits both the structure and attributes by intelligently prioritizing one of them, in the random walk, for each node separately. We convert the network into a multi-layered graph and propose a novel random walk based on the informativeness of a node in different layers. This unified approach is simple and computationally fast, yet able to use the content as a complement to structure and viceversa. Experimental evaluations on four real world publicly available datasets show the merit of our approach (up to 168.75% improvement) compared to the state-of-the-art algorithms in the domain. We make the source code available to download. © 2020 The authors and IOS Press."
ACE: Ant Colony Based Multi-Level Network Embedding for Hierarchical Graph Representation Learning,"As a popularly used technique for feature learning in graphs, network embedding aims to represent each node as a low-dimensional vector to support efficient graph analytic tasks, such as node classification, link prediction, and visualization. The key to this representation method is that the embedding vector of a node should preserve its properties in the graph as much as possible. Most traditional network embedding algorithms only consider the local neighborhood as the context to build the node representation and fail to capture the important hierarchical clustering property ubiquitous in real-world graphs. To solve this problem, we propose ACE, a novel network embedding method, to preserve the features of hierarchical clustering structures. ACE works by using an ant colony-based graph coarsening algorithm to group the nodes according to their relationship to achieve a multi-level clustering pyramid of the input graph. Then, we generate the embedding vectors from multiple layers of the graph pyramid and blend these multi-level vectors into the final representation of nodes based on the PCA dimension reduction algorithm. We demonstrate the effectiveness of ACE over state-of-the-art network embedding algorithms on the node classification tasks in several real-world graph datasets. The experiments show that ACE is easy to be integrated with other network embedding algorithms, such as DeepWalk, Line, node2vec, and SDNE, to significantly improve their performance by up to 22% on Macro F1. The source code and the datasets used in this paper are available on Github (https://github.com/so-link/ACE-Embedding). © 2013 IEEE."
Content-Aware Anomaly Detection with Network Representation Learning,"Given a network with node descriptions or labels, how to identify anomalous nodes and anomalous links in it? Existing methods (e.g., non-negative matrix factorization) mostly focuses on structural anomalies, without taking node descriptions or labels seriously into account. However, such information is obviously valuable for detecting anomalous nodes and links. On the other hand, network representation learning aims to represent the nodes and links in a network as low-dimensional, real-valued and dense vectors, so that the resulting vectors have representation and reasoning ability. It is straightforward that the reconstruction errors between normal node representations are small, while anomaly ones are not. Therefore, we propose a novel Content-Aware Anomaly Detection (CAAD) method based on network representation learning and encoder-decoder. The CAAD method learns structural and content representations with convolutional neural networks. By using the learned low-dimensional node representations, an encoder-decoder model is trained to perform anomaly detection in terms of reconstruction errors. Experiments on two synthetic datasets and one real-world dataset demonstrate that CAAD consistently outperforms the existing baseline methods. For more information and source codes of this study please visit https://github.com/lizhong2613/CAAD. © 2020, Springer Nature Switzerland AG."
Attributed network embedding via subspace discovery,"Network embedding aims to learn a latent, low-dimensional vector representations of network nodes, effective in supporting various network analytic tasks. While prior arts on network embedding focus primarily on preserving network topology structure to learn node representations, recently proposed attributed network embedding algorithms attempt to integrate rich node content information with network topological structure for enhancing the quality of network embedding. In reality, networks often have sparse content, incomplete node attributes, as well as the discrepancy between node attribute feature space and network structure space, which severely deteriorates the performance of existing methods. In this paper, we propose a unified framework for attributed network embedding–attri2vec—that learns node embeddings by discovering a latent node attribute subspace via a network structure guided transformation performed on the original attribute space. The resultant latent subspace can respect network structure in a more consistent way towards learning high-quality node representations. We formulate an optimization problem which is solved by an efficient stochastic gradient descent algorithm, with linear time complexity to the number of nodes. We investigate a series of linear and non-linear transformations performed on node attributes and empirically validate their effectiveness on various types of networks. Another advantage of attri2vec is its ability to solve out-of-sample problems, where embeddings of new coming nodes can be inferred from their node attributes through the learned mapping function. Experiments on various types of networks confirm that attri2vec is superior to state-of-the-art baselines for node classification, node clustering, as well as out-of-sample link prediction tasks. The source code of this paper is available at https://github.com/daokunzhang/attri2vec. © 2019, The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature."
CANE: Context-aware network embedding for relation modeling,"Network embedding (NE) is playing a critical role in network analysis, due to its ability to represent vertices with efficient low-dimensional embedding vectors. However, existing NE models aim to learn a fixed context-free embedding for each vertex and neglect the diverse roles when interacting with other vertices. In this paper, we assume that one vertex usually shows different aspects when interacting with different neighbor vertices, and should own different embeddings respectively. Therefore, we present Context-Aware Network Embedding (CANE), a novel NE model to address this issue. CANE learns context-aware embeddings for vertices with mutual attention mechanism and is expected to model the semantic relationships between vertices more precisely. In experiments, we compare our model with existing NE models on three real-world datasets. Experimental results show that CANE achieves significant improvement than state-of-the-art methods on link prediction and comparable performance on vertex classification. The source code and datasets can be obtained from https://github.com/thunlp/CANE. © 2017 Association for Computational Linguistics."
Fast network embedding enhancement via high order proximity approximation,"Many Network Representation Learning (NRL) methods have been proposed to learn vector representations for vertices in a network recently. In this paper, we summarize most existing NRL methods into a unified two-step framework, including proximity matrix construction and dimension reduction. We focus on the analysis of proximity matrix construction step and conclude that an NRL method can be improved by exploring higher order proximities when building the proximity matrix. We propose Network Embedding Update (NEU) algorithm which implicitly approximates higher order proximities with theoretical approximation bound and can be applied on any NRL methods to enhance their performances. We conduct experiments on multi-label classification and link prediction tasks. Experimental results show that NEU can make a consistent and significant improvement over a number of NRL methods with almost negligible running time on all three publicly available datasets. The source code of this paper can be obtained from https://github.com/thunlp/NEU."
LINE: Large-scale information network embedding,"This paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the ""LINE,"" which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online."
