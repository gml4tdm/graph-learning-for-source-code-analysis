Title,Abstract
Graph Neural Networks in IoT: A Survey,"The Internet of Things (IoT) boom has revolutionized almost every corner of people's daily lives: healthcare, environment, transportation, manufacturing, supply chain, and so on. With the recent development of sensor and communication technology, IoT artifacts, including smart wearables, cameras, smartwatches, and autonomous systems can accurately measure and perceive their surrounding environment. Continuous sensing generates massive amounts of data and presents challenges for machine learning. Deep learning models (e.g., convolution neural networks and recurrent neural networks) have been extensively employed in solving IoT tasks by learning patterns from multi-modal sensory data. Graph neural networks (GNNs), an emerging and fast-growing family of neural network models, can capture complex interactions within sensor topology and have been demonstrated to achieve state-of-The-Art results in numerous IoT learning tasks. In this survey, we present a comprehensive review of recent advances in the application of GNNs to the IoT field, including a deep dive analysis of GNN design in various IoT sensing environments, an overarching list of public data and source codes from the collected publications, and future research directions. To keep track of newly published works, we collect representative papers and their open-source implementations and create a Github repository at GNN4IoT.  © 2023 Association for Computing Machinery."
Deep learning algorithms applied to computational chemistry,"Recently, there has been a significant increase in the use of deep learning techniques in the molecular sciences, which have shown high performance on datasets and the ability to generalize across data. However, no model has achieved perfect performance in solving all problems, and the pros and cons of each approach remain unclear to those new to the field. Therefore, this paper aims to review deep learning algorithms that have been applied to solve molecular challenges in computational chemistry. We proposed a comprehensive categorization that encompasses two primary approaches; conventional deep learning and geometric deep learning models. This classification takes into account the distinct techniques employed by the algorithms within each approach. We present an up-to-date analysis of these algorithms, emphasizing their key features and open issues. This includes details of input descriptors, datasets used, open-source code availability, task solutions, and actual research applications, focusing on general applications rather than specific ones such as drug discovery. Furthermore, our report discusses trends and future directions in molecular algorithm design, including the input descriptors used for each deep learning model, GPU usage, training and forward processing time, model parameters, the most commonly used datasets, libraries, and optimization schemes. This information aids in identifying the most suitable algorithms for a given task. It also serves as a reference for the datasets and input data frequently used for each algorithm technique. In addition, it provides insights into the benefits and open issues of each technique, and supports the development of novel computational chemistry systems. © 2023, The Author(s), under exclusive licence to Springer Nature Switzerland AG."
Graph Neural Networks for Natural Language Processing: A Survey,"Deep learning has become the dominant approach in addressing various tasks in Natural Language Processing (NLP). Although text inputs are typically represented as a sequence of tokens, there is a rich variety of NLP problems that can be best expressed with a graph structure. As a result, there is a surge of interest in developing new deep learning techniques on graphs for a large number of NLP tasks. In this survey, we present a comprehensive overview on Graph Neural Networks (GNNs) for Natural Language Processing. We propose a new taxonomy of GNNs for NLP, which systematically organizes existing research of GNNs for NLP along three axes: graph construction, graph representation learning, and graph based encoder-decoder models. We further introduce a large number of NLP applications that exploits the power of GNNs and summarize the corresponding benchmark datasets, evaluation metrics, and open-source codes. Finally, we discuss various outstanding challenges for making the full use of GNNs for NLP as well as future research directions. To the best of our knowledge, this is the first comprehensive overview of Graph Neural Networks for Natural Language Processing. © 2023 Now Publishers Inc. All rights reserved."
Ensembles of knowledge graph embedding models improve predictions for drug discovery,"Recent advances in Knowledge Graphs (KGs) and Knowledge Graph Embedding Models (KGEMs) have led to their adoption in a broad range of fields and applications. The current publishing system in machine learning requires newly introduced KGEMs to achieve state-of-the-art performance, surpassing at least one benchmark in order to be published. Despite this, dozens of novel architectures are published every year, making it challenging for users, even within the field, to deduce the most suitable configuration for a given application. A typical biomedical application of KGEMs is drug–disease prediction in the context of drug discovery, in which a KGEM is trained to predict triples linking drugs and diseases. These predictions can be later tested in clinical trials following extensive experimental validation. However, given the infeasibility of evaluating each of these predictions and that only a minimal number of candidates can be experimentally tested, models that yield higher precision on the top prioritized triples are preferred. In this paper, we apply the concept of ensemble learning on KGEMs for drug discovery to assess whether combining the predictions of several models can lead to an overall improvement in predictive performance. First, we trained and benchmarked 10 KGEMs to predict drug–disease triples on two independent biomedical KGs designed for drug discovery. Following, we applied different ensemble methods that aggregate the predictions of these models by leveraging the distribution or the position of the predicted triple scores. We then demonstrate how the ensemble models can achieve better results than the original KGEMs by benchmarking the precision (i.e., number of true positives prioritized) of their top predictions. Lastly, we released the source code presented in this work at https://github.com/enveda/kgemensembles-in-drug-discovery. © The Author(s) 2022. Published by Oxford University Press."
Graph Learning Indexer: A Contributor-Friendly and Metadata-Rich Platform for Graph Learning Benchmarks,"Establishing open and general benchmarks has been a critical driving force behind the success of modern machine learning techniques. As machine learning is being applied to broader domains and tasks, there is a need to establish richer and more diverse benchmarks to better reflect the reality of the application scenarios. Graph learning is an emerging field of machine learning that urgently needs more and better benchmarks. To accommodate the need, we introduce Graph Learning Indexer (GLI), a benchmark curation platform for graph learning. In comparison to existing graph learning benchmark libraries, GLI highlights two novel design objectives. First, GLI is designed to incentivize dataset contributors. In particular, we incorporate various measures to minimize the effort of contributing and maintaining a dataset, increase the usability of the contributed dataset, as well as encourage attributions to different contributors of the dataset. Second, GLI is designed to curate a knowledge base, instead of a plain collection, of benchmark datasets. We use multiple sources of meta information to augment the benchmark datasets with rich characteristics, so that they can be easily selected and used in downstream research or development. The source code of GLI is available at https://github.com/Graph-Learning-Benchmarks/gli. © 2022 Proceedings of Machine Learning Research. All rights reserved."
A Comprehensive Survey on Graph Neural Networks,"Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-The-Art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial-Temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing field. © 2012 IEEE."
Deep Graph Generators: A Survey,"Deep generative models have achieved great success in areas such as image, speech, and natural language processing in the past few years. Thanks to the advances in graph-based deep learning, and in particular graph representation learning, deep graph generation methods have recently emerged with new applications ranging from discovering novel molecular structures to modeling social networks. This paper conducts a comprehensive survey on deep learning-based graph generation approaches and classifies them into five broad categories, namely, autoregressive, autoencoder-based, reinforcement learning-based, adversarial, and flow-based graph generators, providing the readers a detailed description of the methods in each class. We also present publicly available source codes, commonly used datasets, and the most widely utilized evaluation metrics. Finally, we review current trends and suggest future research directions based on the existing challenges. © 2013 IEEE."
DIG: A turnkey library for diving into graph deep learning research,"Although there exist several libraries for deep learning on graphs, they are aiming at implementing basic operations for graph deep learning. In the research community, implementing and benchmarking various advanced tasks are still painful and time-consuming with existing libraries. To facilitate graph deep learning research, we introduce DIG: Dive into Graphs, a turnkey library that provides a unified testbed for higher level, research-oriented graph deep learning tasks. Currently, we consider graph generation, self-supervised learning on graphs, explainability of graph neural networks, and deep learning on 3D graphs. For each direction, we provide unified implementations of data interfaces, common algorithms, and evaluation metrics. Altogether, DIG is an extensible, open-source, and turnkey library for researchers to develop new methods and effortlessly compare with common baselines using widely used datasets and evaluation metrics. Source code is available at https://github.com/divelab/DIG. © 2021 Meng Liu, Youzhi Luo, Limei Wang, Yaochen Xie, Hao Yuan, Shurui Gui, Haiyang Yu, Zhao Xu, Jingtun Zhang, Yi Liu, Keqiang Yan, Haoran Liu, Cong Fu, Bora Oztekin, Xuan Zhang, and Shuiwang Ji."
DeepGraph: A PyCharm Tool for Visualizing and Understanding Deep Learning Models,"As more and more domain specific big data become available, there comes a strong need on the fast development and deployment of deep learning (DL) systems with high quality for domain specific applications, including many safety-critical scenarios. In traditional software engineering, software visualization plays an important role to enhance developers' performance with many tools available. However, there are limited visualization supports existing for DL systems, especially in integrated development environments (IDEs) that allow a developer to visualize the source code of a deep neural network (DNN) and its graph architecture. In this paper, we propose DeepGraph, a visualization tool for visualizing and understanding a deep neural network. DeepGraph analyzes the training program to construct the graph representation of a DNN, and establishes and maintains the linkage (mapping) between the source code of the training program and its corresponding neural network architecture. We implemented DeepGraph as a PyCharm plugin and performed preliminary empirical study to demonstrate its usefulness for understanding deep nueral networks. © 2018 IEEE."
Open graph benchmark: Datasets for machine learning on graphs,"We present the OPEN GRAPH BENCHMARK (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale, encompass multiple important graph ML tasks, and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using meaningful application-specific data splits and evaluation metrics. In addition to building the datasets, we also perform extensive benchmark experiments for each dataset. Our experiments suggest that OGB datasets present significant challenges of scalability to large-scale graphs and out-of-distribution generalization under realistic data splits, indicating fruitful opportunities for future research. Finally, OGB provides an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation. OGB will be regularly updated and welcomes inputs from the community. OGB datasets as well as data loaders, evaluation scripts, baseline code, and leaderboards are publicly available at https://ogb.stanford.edu. © 2020 Neural information processing systems foundation. All rights reserved."
Data modeling in DELAB,"As the size and complexity of processing and manufacturing systems increases, the need for Database Management Systems (DBMS) that meet the special needs of studies that experiment with such systems becomes more current. System analysts who study the performance of modern processing systems have to manipulate large amounts of data in order to profile the behavior of the system. They have to identify the relationship between the properties of a compound system and a wide spectrum of performance metrics. In a recent study in which we have analyzed a set of distributed concurrency control algorithms, we performed more than 1400 simulation experiments. Each experiment was characterized by more than 6000 input parameters and generated more than 400 output values. It is thus clear that powerful means for defining the structure and properties of complex systems are needed, as well as efficient tools to retrieve the data accumulated in the course of the study. We are currently engaged in an effort to develop and implement the DELAB simulation laboratory that aims to provide such means and tools for simulation studies. The goal of the first phase of this effort was to design and implement a simulation language. It ended in 1986 when the DENET (Discrete Event NETwork) simulation language became operational. The language is based on the concept of Discrete Event System Specifications (DEVS). It views the simulator as a collection of self contained objects that communicate via Discrete Event Connectors that provide a unified synchronization protocol In the past two years the language has been used in a number of real life studies. It was used to simulate distributed processing environments, communication protocols, and production lines Several tools have been developed around the language. All tools adhere to the same modeling methodology and thus create a cohesive simulation environment. In the second phase of the DELAB project we have been addressing the data management problem DENET has been interfaced to a special purpose relational DBMS that can store descriptions of simulation runs and provides access to the stored data Based on our experience with thus DBMS, we have reached the conclusion that system analysts need to be provided with a view of the data that differs from the way the DENET program views the data, and thus decided to develop a data model that meets their needs. The M@@@@SE data model, which is the result of this effort, has an object oriented flavor. It was developed with the guidance of potential users and was tested on a number of real life simulation studies. Although the conception of M@@@@SE was motivated by the specific needs of a simulation laboratory, we believe that it addresses the representational needs of many other environments We have decided to support the notion of an object. Every object is assigned a unique identifier. Depending on their properties (attributes), objects can simultaneously belong to several classes, inheriting properties from all of them. Among these classes, one is characterized as the primary class of the object. The notion of a primary class helps achieving a “conceptual” as well as a physical clustering among similar objects. Collections of objects are supported as regular objects in M@@@@SE in the form of sets, multisets (bags), and arrays. The extent of a class, i.e., the objects that are known members of the class, is explicitly stored in the database. Every M@@@@SE database schema has a straightforward directed graph representation. Each node represents a class of objects and is labeled by the class name. Relationships between the classes in the schema are captured by the arcs of the graph. Similarly to most object-oriented data models, M@@@@SE has two major types of arcs component arcs and inheritance arcs. The former capture structural relationships (part-of), whereas the latter capture semantic relationships (is-a) between classes of objects. Although a component arc (A → B) has a direction from the parent to the child class, it relates the two classes in both directions. An object in A has a part that is in B, an object in B is part of an object that is in A. The values of the attributes of an object may be explicitly assigned by the user or derived by the system through rules associated with the attribute. Although not restricted to those, aggregates of collections are the dominant kind of such derived attributes. The values assigned to derived attributes may be explicitly stored in the database (forward application of rules), or may be inferred on demand (backward application of rules). Null values are supported in M@@@@SE and are interpreted as “no related object.” Thus, null is distinct from any other value. Also, default values are supported in their full generality M@@@@SE supports four types of user-defined structural constraints that can be used to control sharing or existence dependence between objects. These are (a) sharing of objects among collections, (b) sharing of objects among their parents, (c) sharing of objects along different paths in the component graph, and (d) existence dependence of a child to its parents. An inheritance arc (A → B) implies that every object in B is in A also B(X) → A(X). This rule is called a generalization rule and is implicitly assumed for every inheritance arc. In addition to an implicit generalization rule, an inheritance arc may be explicitly associated with a specialization rule, which specifies which elements of the parent class belong to the child class A specialized class can be instantiated at all times, or its objects can be retrieved on demand, by applying the corresponding rule(s) on an as-needed basis. Although the semantics of simple specialization rules could be captured by typing information and inheritance, specialization rules can be arbitrarily complex, thus allowing the necessary generality to capture the level of abstraction needed for experiment management. We are currently designing a query language for M@@@@SE that will take advantage of its features and will give the system analyst the capability to express complex queries easily. Multiple inheritance will be a significant feature of the language, and one of the key sources of its power and ease of use. Work planned for the future includes building a graphics user-interface to the DBMS that will take advantage of the graphic representation of a M@@@@SE schema and will allow the user to express queries as paths on the graph. The ability to express all types of constraints in a graphic form will then become very important. Some preliminary work on the subject has shown that focusing on different parts of the database establishes different contexts, within which the same constraint can be expressed in different ways. We are currently studying this relationship between constraints and contexts and plan to incorporate it in the query language as well as in the graphics interface. © 1988, ACM. All rights reserved."
