Title,Abstract
Multi-modal semantics fusion model for domain relation extraction via information bottleneck,"Domain relation extraction (DRE) aims to understand domain semantics of unstructured text to mine structural knowledge. However, most existing DRE models may fail to fully represent the domain entity that is usually absent in the corpus of pre-trained language models. In addition, almost all these models directly use contextual semantics for relation classification that ignore purifying the task relevant features. To address these challenging problems, we propose a novel and effective Multi-Modal Semantics Fusion (MMSF) model, which can automatically capture domain semantics to discover the important semantics contained in images, thus enhancing the representations of the domain entity by exploiting the multi-modal semantics. Afterwards, we introduce heterogeneous graph neural networks to learn contextual semantics. To obtain the task relevant features for DRE, we design a new purified feature architecture by exploring the mutual information between contextual semantics and the labels of domain relation. With the enhanced representations of the domain entity and purified the task relevant features, the satisfactory results of relation classification can be guaranteed. Extensive experiments on two real domain relation extraction datasets demonstrate the superiority of our proposed model over several state-of-the-art models. The source code and experiment details of this paper can be obtained from https://github.com/SWT-AITeam/MMSF. © 2023 Elsevier Ltd"
Deep purified feature mining model for joint named entity recognition and relation extraction,"Table filling based joint named entity recognition and relation extraction task aims to share representation of subtasks in a table to extract structured knowledge. However, most of existing studies need additional labels and dedicated deep neural networks to learn shared representation, imposing heavy burdens to decoders. More seriously, almost all these models suffer from feature confusion problem, failing to capture purified task-specific features from shared representation to perform subtasks. To address these challenging problems, in this paper we propose a novel and effective Deep puRified fEAture Mining (DREAM) model for joint named entity recognition and relation extraction task, which can automatically capture purified task-specific features to improve the classification performance of subtasks. Specifically, unlike introducing additional labels or dedicated network architectures, we design a new lightweight shared representation learning (LSRL) module by the plainest labels of joint task and thus encodes context by the hybrid convolutional neural networks. Afterwards, a task-aware information bottleneck (TIB) module is proposed to explore the relation between the mutual information of the joint distribution of each subtask and its task-specific features. With the above two modules well obtain shared representation and purified task-specific features, the satisfactory classification results of both subtasks can be guaranteed. Experiment results show that the proposed model is highly effective, obtaining the promising results on three different benchmarks: CoNNL04 (general text), ADE (biomedical text) and SciERC (scientific text). For example, DREAM respectively achieves F1-scores of 78.18%, 80.28% and 44.60% in performing the relation extraction subtask on the CoNNL04, ADE and SciERC datasets. The promising performance indicates that the proposed model can be applied to many practical applications such as biomedical information extraction. The source code is publicly available at https://github.com/SWT-AITeam/DREAM. © 2023 Elsevier Ltd"
TDN: Triplet Distributor Network for Knowledge Graph Completion,"Conventional Knowledge Graph Completion (KGC) methods typically map entities and relations to a unified space through the shared mapping matrix, and then interact with entities and relations to infer the missing items in the knowledge graph. Although this shared mapping matrix considers the suitability of all triplets, it neglects the specificity of each triplet. To solve this problem, we dynamically learn one information distributor for each triplet to exchange its specific information. In this paper, we propose a novel Triplet Distributor Network (TDN) for the knowledge graph completion task. Specifically, we adaptively learn one Triplet Distributor (TD) for each triplet to assist the interaction between the entity and relation. Furthermore, on the basis of TD, we creatively design the information exchange layer to dynamically propagate the information of the entity and relation, thus mutually enhancing entity and relation representations. Except for several commonly-used knowledge graph datasets, we still implement the link prediction task on the social-relational and medical datasets to test the proposed method. Experimental results demonstrate that the proposed method performs better than existing state-of-the-art KGC methods. The source codes of this paper are available at https://github.com/TDN for Knowledge Graph Completion.git.  © 1989-2012 IEEE."
SelfLRE: Self-refining Representation Learning for Low-resource Relation Extraction,"Low-resource relation extraction (LRE) aims to extract potential relations from limited labeled corpus to handle the problem of scarcity of human annotations. Previous works mainly consist of two categories of methods: (1) Self-training methods, which improve themselves through the models' predictions, thus suffering from confirmation bias when the predictions are wrong. (2) Self-ensembling methods, which learn task-agnostic representations, therefore, generally do not work well for specific tasks. In our work, we propose a novel LRE architecture named SelfLRE, which leverages two complementary modules, one module uses self-training to obtain pseudo-labels for unlabeled data, and the other module uses self-ensembling learning to obtain the task-agnostic representations, and leverages the existing pseudo-labels to refine the better task-specific representations on unlabeled data. The two models are jointly trained through multi-task learning to iteratively improve the effect of LRE task. Experiments on three public datasets show that SelfLRE achieves 1.81% performance gain over the SOTA baseline. Source code is available at: https://github.com/THU-BPM/SelfLRE. © 2023 Copyright held by the owner/author(s)."
Cross-platform product matching based on entity alignment of knowledge graph with raea model,"Product matching aims to identify identical or similar products sold on different platforms. By building knowledge graphs (KGs), the product matching problem can be converted to the Entity Alignment (EA) task, which aims to discover the equivalent entities from diverse KGs. The existing EA methods inadequately utilize both attribute triples and relation triples simultaneously, especially the interactions between them. This paper introduces a two-stage pipeline consisting of rough filter and fine filter to match products from eBay and Amazon. For fine filtering, a new framework for Entity Alignment, R elation-aware and A ttribute-aware Graph Attention Networks for E ntity A lignment (RAEA), is employed. RAEA focuses on the interactions between attribute triples and relation triples, where the entity representation aggregates the alignment signals from attributes and relations with Attribute-aware Entity Encoder and Relation-aware Graph Attention Networks. The experimental results indicate that the RAEA model achieves significant improvements over 12 baselines on EA task in the cross-lingual dataset DBP15K (6.59% on average Hits@1) and delivers competitive results in the monolingual dataset DWY100K. The source code for experiments on DBP15K and DWY100K is available at github (https://github.com/Mockingjay-liu/RAEA-model-for-Entity-Alignment). © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature."
Duet Representation Learning with Entity Multi-attribute Information in Knowledge Graphs,"Representation Learning (RL) of knowledge graphs aims to project both entities and relations into a continuous low-dimension space. Most methods concentrate on learning entities’ representations with structure information indicating the relations between entities (Trans- methods), while the utilization of entity multi-attribute information is insufficient for some scenarios, such as cold start issues or zero-shot problems. How to utilize the complex and diverse multi-attribute information for RL is still a challenging problem for enhancing knowledge graph embedding research. In this paper, we propose a novel RL model Duet Entity Representation Learning (DERL) for knowledge graphs, which takes advantage of entity multi-attribute information. Specifically, we devise a novel encoder Entity Attribute Encoder (EAE), which encodes both entity attribute types and values to generate the entities’ attribute-based representations. We further learn the entities’ representations with both structure information and multi-attribute information in DERL. We evaluate our method on two tasks: the knowledge graph completion task and the zero-shot task. Experimental results on real-world datasets show that our method outperforms other baselines on two downstream tasks by building effective representations for entities from their multi-attribute information. The source code of this paper can be obtained from https://anonymous.4open.science/r/DUET-adma2023/. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG."
AutoAlign: Fully Automatic and Effective Knowledge Graph Alignment Enabled by Large Language Models,"The task of entity alignment between knowledge graphs (KGs) aims to identify every pair of entities from two different KGs that represent the same entity. Many machine learning-based methods have been proposed for this task. However, to our best knowledge, existing methods all require <italic>manually crafted</italic> seed alignments, which are expensive to obtain. In this paper, we propose the first fully automatic alignment method named AutoAlign, which does not require any manually crafted seed alignments. Specifically, for predicate embeddings, AutoAlign constructs a predicate-proximity-graph with the help of large language models to automatically capture the similarity between predicates across two KGs. For entity embeddings, AutoAlign first computes the entity embeddings of each KG independently using TransE, and then shifts the two KGs&#x0027; entity embeddings into the same vector space by computing the similarity between entities based on their attributes. Thus, both predicate alignment and entity alignment can be done without manually crafted seed alignments. AutoAlign is not only fully automatic, but also highly effective. Experiments using real-world KGs show that AutoAlign improves the performance of entity alignment significantly compared to state-of-the-art methods. Our source code is available at ruizhang-ai/AutoAlign. IEEE"
Learning Knowledge Representation with Entity Concept Information,"The goal of Knowledge Representation Learning (KRL) is to learn an accurate knowledge representation that conforms to human understanding. Currently, many works have used entity multi-source information to improve the entity representation semantic precision, such as entity description, attribute, and visual information. However, few methods consider the timeliness in KRL, which significantly affects representation learning performance. In this paper, we attempt to utilize concept information with human understanding to learn an accurate, time-stable knowledge representation. Specifically, we first build a novel Knowledge Graph (KG) - Structure Concept Graph (SCG), which can provide entity structure and concept information jointly. Based on the SCG, we devise a novel KRL model that can embed entity concept information to ensure accuracy and timeliness of improving the KRL’s effect with entity structure information. We evaluate our method on two downstream tasks: the knowledge graph completion task and the zero-shot task. Experimental results on real-world datasets show that our method outperforms other baselines by building effective entities’ representations from their concept information. The source code of this paper can be obtained from https://anonymous.4open.science/r/CKRL-adma2023. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023."
Knowledge Graph Embedding with Relation Rotation and Entity Adjustment by Quaternions,"Recent knowledge graph embedding models have shown promising results on link prediction, by employing operations on quaternion space to capture correlations between entities. However, they only used three quaternion embeddings for rotation calculation that fails to capture the interaction between entities and relations. The single relation quaternion to rotate the head entity also makes the connection between the head and tail entities weak. To address the problem, this paper proposes a novel knowledge graph embedding model denoted as QuatPE, to utilize paired relations to simultaneously rotate the head and tail entities in a triple. We employ the adjustment vectors to adjust the position of the same entity in a quaternion space when facing different triples. With paired relations, QuatPE can strengthen the connection between the head and tail entities which enhances the representation capabilities. By using the adjustment vectors, QuatPE also helps to better handle complex relation patterns, such as 1-to-N, N-to-1, and N-to-N. Experimental results show that QuatPE can achieve significant performance on well-known datasets for link prediction. Researchers can reproduce our results by following the source codes at https://github.com/galaxysunwen/QuatPE-master. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023."
Document-level Relation Extraction with Entity Interaction and Commonsense Knowledge,"Document-Level Relation Extraction(DLRE) is a more challenging task than sentence-level relation extraction because of the characteristics such as more extended context, more interactions between entities, and the need for common sense to help the relation inference. In this paper, we propose an effective model to address the problems of complex entity interactions and the lack of commonsense knowledge. Specifically, we propose a Transformer-based entity interaction module instead of graph neural networks to model the correlation across entities, thus avoiding the information loss problem triggered by predefined edge-building rules. In addition, the initial word vector from the word embedding layer of a pre-trained language model is injected into entity representation to boost the performance in the extraction of relational facts that need commonsense knowledge. Experiments show that our model obtains competitive performance, especially compared with graph-based methods, which is faster and more effective. The source code, trained checkpoint files, and the commit results will be released to the public. © 2023 IEEE."
REMS: Recommending Extract Method Refactoring Opportunities via Multi-view Representation of Code Property Graph,"Extract Method is one of the most frequently performed refactoring operations for the decomposition of large and complex methods, which can also be combined with other refactoring operations to remove a variety of design flaws. Several Extract Method refactoring tools have been proposed based on the quantification of extraction criteria. To the best of our knowledge, state-of-the-art related techniques can be broadly divided into two categories: the first line is non-machine-learning-based approaches built on heuristics, and the second line is machine learning-based approaches built on historical data. Most of these approaches characterize the extraction criteria by deriving software metrics from fine-grained code properties. However, in most cases, these metrics can be challenging to concretize, and their selections and thresholds also largely rely on expert knowledge. Thus, in this paper, we propose an approach to automatically recommend Extract Method refactoring opportunities named REMS via mining multi-view representations from code property graph. We fuse various representations together using compact bilinear pooling and further train machine learning classifiers to guide the extraction of suitable lines of code as new method. We evaluate our approach on two publicly available datasets. The results show that our approach outperforms five state-of-the-art refactoring tools including GEMS, JExtract, SEMI, JDeodorant, and Segmentation in effectiveness and usefulness. Our approach demonstrates an increase of 29% in precision, 15% in recall, and 23% in f1-measure. The results also unveil practical suggestions and provide new insights that benefit additional extract-related refactoring techniques.  © 2023 IEEE."
Event Detection Based on Multilingual Information Enhanced Syntactic Dependency GCN,"Event detection is a hot and difficult problem in information extraction. It is widely used in automatic news extraction, financial event analysis and other fields. However, most of the existing event detection methods only focus on a single language, ignoring the event information provided by other languages, and can not solve the problem of polysemy in a single language, which makes it difficult to improve the performance of event detection methods. To solve these problems, this paper proposes a new Event Detection based on Multilingual Information Enhanced Syntactic Dependency GCN. Specifically, the model translates the original language and aligns words, takes multilingual data as input, and constructs syntactic dependency diagrams for initial language sentences. Then, a graph neural network is constructed based on the syntactic dependency graph, and combined with the attention mechanism, the nodes of the syntactic dependency graph are enhanced by the translated language. Finally, the classifier finds the trigger and judges the event type. The model effectively improves the recognition efficiency of polysemous words by using multilingual information, and makes full use of sentence structure information by using syntactic dependency graph. Experiments on ace2005 benchmark data set show that the model can detect events effectively and is obviously superior to the existing event detection methods. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG."
"Joint Extraction of Entities, Relations, and Events via Modeling Inter-Instance and Inter-Label Dependencies","Event trigger detection, entity mention recognition, event argument extraction, and relation extraction are the four important tasks in information extraction that have been performed jointly (Joint Information Extraction - JointIE) to avoid error propagation and leverage dependencies between the task instances (i.e., event triggers, entity mentions, relations, and event arguments). However, previous JointIE models often assume heuristic manually-designed dependency between the task instances and mean-field factorization for the joint distribution of instance labels, thus unable to capture optimal dependencies among instances and labels to improve representation learning and IE performance. To overcome these limitations, we propose to induce a dependency graph among task instances from data to boost representation learning. To better capture dependencies between instance labels, we propose to directly estimate their joint distribution via Conditional Random Fields. Noise Contrastive Estimation is introduced to address the maximization of the intractable joint likelihood for model training. Finally, to improve the decoding with greedy or beam search in prior work, we present Simulated Annealing to better find the globally optimal assignment for instance labels at decoding time. Experimental results show that our proposed model outperforms previous models on multiple IE tasks across 5 datasets and 2 languages. © 2022 Association for Computational Linguistics."
"Understand Me, if You Refer to Aspect Knowledge: Knowledge-Aware Gated Recurrent Memory Network","Aspect-level sentiment classification (ASC) aims to predict the fine-grained sentiment polarity towards a given aspect mentioned in a review. Despite recent advances in ASC, enabling machines to preciously infer aspect sentiments is still challenging. This paper tackles two challenges in ASC: (1) due to lack of aspect knowledge, aspect representation derived in prior works is inadequate to represent aspect&#x2019;s exact meaning and property information; (2) prior works only capture either local syntactic information or global relational information, thus missing either one of them leads to insufficient syntactic information. To tackle these challenges, we propose a novel ASC model which not only end-to-end embeds and leverages aspect knowledge but also marries the two kinds of syntactic information and lets them compensate for each other. Our model includes four key components: (1) a knowledge-aware gated recurrent memory network recurrently integrates dynamically summarized aspect knowledge; (2) a dual syntax graph network combines both kinds of syntactic information to comprehensively capture sufficient syntactic information; (3) a knowledge integrating gate re-enhances the final representation with further needed aspect knowledge; (4) an aspect-to-context attention mechanism aggregates the aspect-related semantics from all hidden states into the final representation. Experimental results on several benchmark datasets demonstrate the effectiveness of our model, which overpass previous state-of-the-art models by large margins in terms of both Accuracy and Macro-F1. To facilitate further research in the community, we have released our source code at https://github.com/XingBowen714/KaGRMN-DSG_ABSA. IEEE"
Efficient multiple biomedical events extraction via reinforcement learning,"Motivation: Multiple events extraction from biomedical literature is a challenging task for biomedical community. Usually, biomedical event extraction is modeled as two sub-tasks, trigger identification and argument detection. Most existing methods perform these two sub-tasks sequentially, and fail to make full use of the interaction between them, leading to suboptimal results for multiple biomedical events extraction. Results: We propose a novel framework of reinforcement learning (RL) for the task of multiple biomedical events extraction. More specifically, trigger identification and argument detection are treated as main-task and subsidiary-task, respectively. Assigning the event type of triggers (in the main-task) is viewed as the action taken in RL, and the result of corresponding argument detection (i.e. the subsidiary-task) for the identified trigger is used for computing the reward of the taken action. Moreover, the result of the subsidiary-task is modeled as part of environment information in RL to help the procedure of trigger identification. In addition, external biomedical knowledge bases are employed for representation learning of biomedical text, which can improve the performance of biomedical event extraction. Results on two widely used biomedical corpora demonstrate that the proposed framework performs better than the selected baselines on the task of multiple events extraction. The ablation test indicates the contributions of RL and external KBs to the performance improvement in the proposed method. In addition, by modeling multiple events extraction under the RL framework, the supervised information is exploited more effectively than the classical supervised learning paradigm. Availability  and implementation Source codes will be available at: https://github.com/David-WZhao/BioEE-RL.  © 2021 The Author(s) 2021. Published by Oxford University Press. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com."
Kepler: A unified model for knowledge embedding and pre-trained language representation,"Pre-trained language representation models (PLMs) cannot well capture factual knowledge from text. In contrast, knowledge embedding (KE) methods can effectively represent the relational facts in knowledge graphs (KGs) with informative entity embeddings, but conventional KE models cannot take full advantage of the abundant textual information. In this paper, we propose a unified model for Knowledge Embedding and Pre-trained LanguagE Representation (KEPLER), which can not only better integrate factual knowledge into PLMs but also produce effective text-enhanced KE with the strong PLMs. In KEPLER, we encode textual entity descriptions with a PLM as their embeddings, and then jointly optimize the KE and language modeling objectives. Experimental results show that KEPLER achieves state-of-the-art performances on various NLP tasks, and also works remarkably well as an inductive KE model on KG link prediction. Furthermore, for pre-training and evaluating KEPLER, we construct Wikidata5M1, a large-scale KG dataset with aligned entity descriptions, and benchmark state-of-the-art KE methods on it. It shall serve as a new KE benchmark and facilitate the research on large KG, inductive KE, and KG with text. The source code can be obtained from https://github.com/THU-KEG /KEPLER. © 2021, MIT Press Journals. All rights reserved."
Cross-Task Instance Representation Interactions and Label Dependencies for Joint Information Extraction with Graph Convolutional Networks,"Existing works on information extraction (IE) have mainly solved the four main tasks separately (entity mention recognition, relation extraction, event trigger detection, and argument extraction), thus failing to benefit from inter-dependencies between tasks. This paper presents a novel deep learning model to simultaneously solve the four tasks of IE in a single model (called FourIE). Compared to few prior work on jointly performing four IE tasks, FourIE features two novel contributions to capture inter-dependencies between tasks. First, at the representation level, we introduce an interaction graph between instances of the four tasks that is used to enrich the prediction representation for one instance with those from related instances of other tasks. Second, at the label level, we propose a dependency graph for the information types in the four IE tasks that captures the connections between the types expressed in an input sentence. A new regularization mechanism is introduced to enforce the consistency between the golden and predicted type dependency graphs to improve representation learning. We show that the proposed model achieves the state-of-the-art performance for joint IE on both monolingual and multilingual learning settings with three different languages. © 2021 Association for Computational Linguistics."
Multi-channel graph neural network for entity alignment,"Entity alignment typically suffers from the issues of structural heterogeneity and limited seed alignments. In this paper, we propose a novel Multi-channel Graph Neural Network model (MuGNN) to learn alignment-oriented knowledge graph (KG) embeddings by robustly encoding two KGs via multiple channels. Each channel encodes KGs via different relation weighting schemes with respect to self-attention towards KG completion and cross-KG attention for pruning exclusive entities respectively, which are further combined via pooling techniques. Moreover, we also infer and transfer rule knowledge for completing two KGs consistently. MuGNN is expected to reconcile the structural differences of two KGs, and thus make better use of seed alignments. Extensive experiments on five publicly available datasets demonstrate our superior performance (5% Hits@1 up on average). Source code and data used in the experiments can be accessed at https://github.com/thunlp/MuGNN. © 2019 Association for Computational Linguistics"
Adaptive attentional network for few-shot knowledge graph completion,"Few-shot Knowledge Graph (KG) completion is a focus of current research, where each task aims at querying unseen facts of a relation given its few-shot reference entity pairs. Recent attempts solve this problem by learning static representations of entities and references, ignoring their dynamic properties, i.e., entities may exhibit diverse roles within task relations, and references may make different contributions to queries. This work proposes an adaptive attentional network for few-shot KG completion by learning adaptive entity and reference representations. Specifically, entities are modeled by an adaptive neighbor encoder to discern their task-oriented roles, while references are modeled by an adaptive query-aware aggregator to differentiate their contributions. Through the attention mechanism, both entities and references can capture their fine-grained semantic meanings, and thus render more expressive representations. This will be more predictive for knowledge acquisition in the few-shot scenario. Evaluation in link prediction on two public datasets shows that our approach achieves new state-of-the-art results with different few-shot sizes. The source code is available at https://github.com/JiaweiSheng/FAAN. © 2020 Association for Computational Linguistics"
InteractE: Improving convolution-based knowledge graph embeddings by increasing feature interactions,"Most existing knowledge graphs suffer from incompleteness, which can be alleviated by inferring missing links based on known facts. One popular way to accomplish this is to generate low-dimensional embeddings of entities and relations, and use these to make inferences. ConvE, a recently proposed approach, applies convolutional filters on 2D reshapings of entity and relation embeddings in order to capture rich interactions between their components. However, the number of interactions that ConvE can capture is limited. In this paper, we analyze how increasing the number of these interactions affects link prediction performance, and utilize our observations to propose InteractE. InteractE is based on three key ideas – feature permutation, a novel feature reshaping, and circular convolution. Through extensive experiments, we find that InteractE outperforms state-of-the-art convolutional link prediction baselines on FB15k-237. Further, InteractE achieves an MRR score that is 9%, 7.5%, and 23% better than ConvE on the FB15k-237, WN18RR and YAGO3-10 datasets respectively. The results validate our central hypothesis – that increasing feature interaction is beneficial to link prediction performance. We make the source code of InteractE available to encourage reproducible research. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved."
TransT: Type-Based Multiple Embedding Representations for Knowledge Graph Completion,"Knowledge graph completion with representation learning predicts new entity-relation triples from the existing knowledge graphs by embedding entities and relations into a vector space. Most existing methods focus on the structured information of triples and maximize the likelihood of them. However, they neglect semantic information contained in most knowledge graphs and the prior knowledge indicated by the semantic information. To overcome this drawback, we propose an approach that integrates the structured information and entity types which describe the categories of entities. Our approach constructs relation types from entity types and utilizes type-based semantic similarity of the related entities and relations to capture prior distributions of entities and relations. With the type-based prior distributions, our approach generates multiple embedding representations of each entity in different contexts and estimates the posterior probability of entity and relation prediction. Extensive experiments show that our approach outperforms previous semantics-based methods. The source code of this paper can be obtained from https://github.com/shh/transt. © 2017, Springer International Publishing AG."
Representation learning of knowledge graphs with entity descriptions,"Representation learning (RL) of knowledge graphs aims to project both entities and relations into a continuous lowdimensional space. Most methods concentrate on learning representations with knowledge triples indicating relations between entities. In fact, in most knowledge graphs there are usually concise descriptions for entities, which cannot be well utilized by existing methods. In this paper, we propose a novel RL method for knowledge graphs taking advantages of entity descriptions. More specifically, we explore two encoders, including continuous bag-of-words and deep convolutional neural models to encode semantics of entity descriptions. We further learn knowledge representations with both triples and descriptions.We evaluate our method on two tasks, including knowledge graph completion and entity classification. Experimental results on real-world datasets show that, our method outperforms other baselines on the two tasks, especially under the zero-shot setting, which indicates that our method is capable of building representations for novel entities according to their descriptions. The source code of this paper can be obtained from https://github.com/xrb92/DKRL. © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved."
Modeling relation paths for representation learning of knowledge bases,"Representation learning of knowledge bases aims to embed both entities and relations into a low-dimensional space. Most existing methods only consider direct relations in representation learning. We argue that multiple-step relation paths also contain rich inference patterns between entities, and propose a path-based representation learning model. This model considers relation paths as translations between entities for representation learning, and addresses two key challenges: (1) Since not all relation paths are reliable, we design a path-constraint resource allocation algorithm to measure the reliability of relation paths. (2) We represent relation paths via semantic composition of relation embeddings. Experimental results on real-world datasets show that, as compared with baselines, our model achieves significant and consistent improvements on knowledge base completion and relation extraction from text. The source code of this paper can be obtained from https://github.com/mrlyk423/relation-extraction. © 2015 Association for Computational Linguistics."
Transnet: Translation-based network representation learning for social relation extraction,"Conventional network representation learning (NRL) models learn low-dimensional vertex representations by simply regarding each edge as a binary or continuous value. However, there exists rich semantic information on edges and the interactions between vertices usually preserve distinct meanings, which are largely neglected by most existing NRL models. In this work, we present a novel Translation-based NRL model, TransNet, by regarding the interactions between vertices as a translation operation. Moreover, we formalize the task of Social Relation Extraction (SRE) to evaluate the capability of NRL methods on modeling the relations between vertices. Experimental results on SRE demonstrate that TransNet significantly outperforms other baseline methods by 10% to 20% on hits@1. The source code and datasets can be obtained from https://github.com/thunlp/TransNet."
"Knowledge representation learning with entities, attributes and relations","Distributed knowledge representation (KR) encodes both entities and relations in a lowdimensional semantic space, which has significantly promoted the performance of relation extraction and knowledge reasoning. In many knowledge graphs (KG), some relations indicate attributes of entities (attributes) and others indicate relations between entities (relations). Existing KR models regard all relations equally, and usually suffer from poor accuracies when modeling one-to-many and many-to-one relations, mostly composed of attribute. In this paper, we distinguish existing KGrelations into attributes and relations, and propose a new KR model with entities, attributes and relations (KR-EAR). The experiment results show that, by special modeling of attribute, KR-EAR can significantly outperform state-of-the-art KR models in prediction of entities, attributes and relations. The source code of this paper can be obtained from https://github.com/thunlp/KR-EAR."
Representation learning of knowledge graphs with hierarchical types,"Representation learning of knowledge graphs aims to encode both entities and relations into a continuous low-dimensional vector space. Most existing methods only concentrate on learning representations with structured information located in triples, regardless of the rich information located in hierarchical types of entities, which could be collected in most knowledge graphs. In this paper, we propose a novel method named Type-embodied Knowledge Representation Learning (TKRL) to take advantages of hierarchical entity types. We suggest that entities should have multiple representations in different types. More specifically, we consider hierarchical types as projection matrices for entities, with two type encoders designed to model hierarchical structures. Meanwhile, type information is also utilized as relation-specific type constraints. We evaluate our models on two tasks including knowledge graph completion and triple classification, and further explore the performances on long-tail dataset. Experimental results show that our models significantly outperform all baselines on both tasks, especially with long-tail distribution. It indicates that our models are capable of capturing hierarchical type information which is significant when constructing representations of knowledge graphs. The source code of this paper can be obtained from https://github.com/thunlp/TKRL."
Neural knowledge acquisition via mutual attention between knowledge graph and text,"We propose a general joint representation learning framework for knowledge acquisition (KA) on two tasks, knowledge graph completion (KGC) and relation extraction (RE) from text. In this framework, we learn representations of knowledge graphs (KGs) and text within a unified parameter sharing semantic space. To achieve better fusion, we propose an effective mutual attention between KGs and text. The reciprocal attention mechanism enables us to highlight important features and perform better KGC and RE. Different from conventional joint models, no complicated linguistic analysis or strict alignments between KGs and text are required to train our models. Experiments on relation extraction and entity link prediction show that models trained under our joint framework are significantly improved in comparison with other baselines. Most existing methods for KGC and RE can be easily integrated into our framework due to its flexible architectures. The source code of this paper can be obtained from https://github.com/thunlp/JointNRE. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved."
Learning entity and relation embeddings for knowledge graph completion,"Knowledge graph completion aims to perform link prediction between entities. In this paper, we consider the approach of knowledge graph embeddings. Recently, models such as TransE and TransH build entity and relation embeddings by regarding a relation as translation from head entity to tail entity. We note that these models simply put both entities and relations within the same semantic space. In fact, an entity may have multiple aspects and various relations may focus on different aspects of entities, which makes a common space insufficient for modeling. In this paper, we propose TransR to build entity and relation embeddings in separate entity space and relation spaces. Afterwards, we learn embeddings by first projecting entities from entity space to corresponding relation space and then building translations between projected entities. In experiments, we evaluate our models on three tasks including link prediction, triple classification and relational fact extraction. Experimental results show significant and consistent improvements compared to state-of-the-art baselines including TransE and TransH. The source code of this paper can be obtained from https://github.com/mrlyk423/relation-extraction. © Copyright 2015, Association for the Advancement of Artificial Intelligence (www.aaa1.org). All rights reserved."
