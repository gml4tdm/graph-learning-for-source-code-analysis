Authors,Title,Abstract,Document Type,Year,Link,Source title,Round 3 ID,Included/Excluded,Reason,Notes
Mi Q.; Zhan Y.; Weng H.; Bao Q.; Cui L.; Ma W.,A graph-based code representation method to improve code readability classification,"Context: Code readability is crucial for developers since it is closely related to code maintenance and affects developers’ work efficiency. Code readability classification refers to the source code being classified as pre-defined certain levels according to its readability. So far, many code readability classification models have been proposed in existing studies, including deep learning networks that have achieved relatively high accuracy and good performance. Objective: However, in terms of representation, these methods lack effective preservation of the syntactic and semantic structure of the source code. To extract these features, we propose a graph-based code representation method. Method: Firstly, the source code is parsed into a graph containing its abstract syntax tree (AST) combined with control and data flow edges to reserve the semantic structural information and then we convert the graph nodes’ source code and type information into vectors. Finally, we train our graph neural networks model composing Graph Convolutional Network (GCN), DMoNPooling, and K-dimensional Graph Neural Networks (k-GNNs) layers to extract these features from the program graph. Result: We evaluate our approach to the task of code readability classification using a Java dataset provided by Scalabrino et al. (2016). The results show that our method achieves 72.5% and 88% in three-class and two-class classification accuracy, respectively. Conclusion: We are the first to introduce graph-based representation into code readability classification. Our method outperforms state-of-the-art readability models, which suggests that the graph-based code representation method is effective in extracting syntactic and semantic information from source code, and ultimately improves code readability classification. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160003449&doi=10.1007%2fs10664-023-10319-6&partnerID=40&md5=123f5324dfc79038a0d3244e8c791cab,Empirical Software Engineering,1,Include,I1.2,The network architecture is not reported consistently. 
Pian W.; Peng H.; Tang X.; Sun T.; Tian H.; Habib A.; Klein J.; Bissyandé T.F.,MetaTPTrans: A Meta Learning Approach for Multilingual Code Representation Learning,"Representation learning of source code is essential for applying machine learning to software engineering tasks. Learning code representation from a multilingual source code dataset has been shown to be more effective than learning from single-language datasets separately, since more training data from multilingual dataset improves the model’s ability to extract language-agnostic information from source code. However, existing multilingual training overlooks the language-specific information which is crucial for modeling source code across different programming languages, while only focusing on learning a unified model with shared parameters among different languages for language-agnostic information modeling. To address this problem, we propose MetaTPTrans, a meta learning approach for multilingual code representation learning. MetaTPTrans generates different parameters for the feature extractor according to the specific programming language type of the input code snippet, enabling the model to learn both language-agnostic and language-specific information with dynamic parameters in the feature extractor. We conduct experiments on the code summarization and code completion tasks to verify the effectiveness of our approach. The results demonstrate the superiority of our approach with significant improvements on state-of-the-art baselines. p g . Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167864360&partnerID=40&md5=1daa985a31f853e55cc239b7c4f9cdc2,"Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",2,Exclude,E1.3,
Ding Z.; Li H.; Shang W.; Chen T.-H.P.,Towards Learning Generalizable Code Embeddings Using Task-agnostic Graph Convolutional Networks,"Code embeddings have seen increasing applications in software engineering (SE) research and practice recently. Despite the advances in embedding techniques applied in SE research, one of the main challenges is their generalizability. A recent study finds that code embeddings may not be readily leveraged for the downstream tasks that the embeddings are not particularly trained for. Therefore, in this article, we propose GraphCodeVec, which represents the source code as graphs and leverages the Graph Convolutional Networks to learn more generalizable code embeddings in a task-agnostic manner. The edges in the graph representation are automatically constructed from the paths in the abstract syntax trees, and the nodes from the tokens in the source code. To evaluate the effectiveness of GraphCodeVec , we consider three downstream benchmark tasks (i.e., code comment generation, code authorship identification, and code clones detection) that are used in a prior benchmarking of code embeddings and add three new downstream tasks (i.e., source code classification, logging statements prediction, and software defect prediction), resulting in a total of six downstream tasks that are considered in our evaluation. For each downstream task, we apply the embeddings learned by GraphCodeVec and the embeddings learned from four baseline approaches and compare their respective performance. We find that GraphCodeVec outperforms all the baselines in five out of the six downstream tasks, and its performance is relatively stable across different tasks and datasets. In addition, we perform ablation experiments to understand the impacts of the training context (i.e., the graph context extracted from the abstract syntax trees) and the training model (i.e., the Graph Convolutional Networks) on the effectiveness of the generated embeddings. The results show that both the graph context and the Graph Convolutional Networks can benefit GraphCodeVec in producing high-quality embeddings for the downstream tasks, while the improvement by Graph Convolutional Networks is more robust across different downstream tasks and datasets. Our findings suggest that future research and practice may consider using graph-based deep learning methods to capture the structural information of the source code for SE tasks.  © 2023 Association for Computing Machinery.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153731394&doi=10.1145%2f3542944&partnerID=40&md5=5579536a2ca56d11845228acae273057,ACM Transactions on Software Engineering and Methodology,3,Include,I1.2/I1.1,
Dong Z.; Hu Q.; Zhang Z.; Zhao J.,On the Effectiveness of Graph Data Augmentation for Source Code Learning,"The methodology that uses deep learning to solve software engineering tasks, such as bug detection, is known as source code learning. Due to the graph nature of source code, graph learning, empowered by graph neural networks (GNNs), has been increasingly adopted for source code learning. Like other deep learning contexts, source code learning also relies on massive high-quality training data, and the shortage of such data has become the main performance bottleneck. In practice, data augmentation is often used as a countermeasure to mitigate this issue, by synthesizing additional training data based on existing ones. However, most existing practice of data augmentation in source code learning limits simple code refactoring methods and is not sufficiently effective. In this work, in light of the graph nature of source code, we propose to apply the data augmentation methods used for graph-structured data in graph learning to the tasks of source code learning, and we conduct a comprehensive empirical study to evaluate whether such new ways of data augmentation are more effective than the existing simple code refactoring methods. Specifically, we evaluate 4 critical software engineering tasks and 7 neural network architectures to assess the effectiveness of 5 data augmentation methods. Experimental results identify that, compared to other methods, Manifold-Mixup can greatly improve the accuracy of the trained models for source code learning.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179522132&doi=10.1109%2fDSA59317.2023.00124&partnerID=40&md5=86fc4890726e94127df716a7a57d61d1,"Proceedings - 2023 10th International Conference on Dependable Systems and Their Applications, DSA 2023",4,Exclude,E3.1,
Pan W.; Ming H.; Kim D.-K.; Yang Z.,Pride: Prioritizing Documentation Effort Based on a PageRank-Like Algorithm and Simple Filtering Rules,"Code documentation can be helpful in many software quality assurance tasks. However, due to resource constraints (e.g., time, human resources, and budget), programmers often cannot document their work completely and timely. In the literature, two approaches (one is supervised and the other is unsupervised) have been proposed to prioritize documentation effort to ensure the most important classes to be documented first. However, both of them contain several limitations. The supervised approach overly relies on a difficult-to-obtain labeled data set and has high computation cost. The unsupervised one depends on a graph representation of the software structure, which is inaccurate since it neglects many important couplings between classes. In this paper, we propose an improved approach, named Pride, to prioritize documentation effort. First, Pride uses a weighted directed class coupling network to precisely describe classes and their couplings. Second, we propose a PageRank-like algorithm to quantify the importance of classes in the whole class coupling network. Third, we use a set of software metrics to quantify source code complexity and further propose a simple but easy-to-operate filtering rule. Fourth, we sort all the classes according to their importance in descending order and use the filtering rule to filter out unimportant classes. Finally, a threshold kk is utilized, and the top-kk% ranked classes are the identified important classes to be documented first. Empirical results on a set of nine software systems show that, according to the average ranking of the Friedman test, Pride is superior to the existing approaches in the whole data set.  © 2022 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129670613&doi=10.1109%2fTSE.2022.3171469&partnerID=40&md5=346cf30e57b601387a769a9b0f781a8d,IEEE Transactions on Software Engineering,230,Include,,
Cassagne J.; Merlo E.; Branco P.; Jourdan G.-V.; Onut I.-V.,Unsupervised Graph Neural Networks for Source Code Similarity Detection,"In this paper, we propose a novel unsupervised approach for code similarity and clone detection that is based on Graph Neural Networks. We propose a hybrid approach to detect similarities within source code, using centroid distances and a Graph Auto-Encoder that uses a raw abstract syntax trees as input. When compared to RTVNN [33], the state-of-the-art unsupervised approach for code similarity and clone detection, our method improves significantly training and inference time efficiency, while preserving or improving precision. In our experiments, our algorithm is on average 77 times faster during training and 21 times faster during inference. This shows that using Graph Auto-Encoders in the domain of source code similarity analysis is the better option in an industrial context or in a production environment. We illustrate this by using our approach to compute source code similarity within a large dataset of phishing kits written in PHP provided by our industry partner. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174316921&doi=10.1007%2f978-3-031-45275-8_36&partnerID=40&md5=aee61debb36b07fa4fc6b014d2bd824f,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),5,Include,I1.1,
Liu J.; Zeng J.; Wang X.; Liang Z.,Learning Graph-based Code Representations for Source-level Functional Similarity Detection,"Detecting code functional similarity forms the basis of various software engineering tasks. However, the detection is challenging as functionally similar code fragments can be implemented differently, e.g., with irrelevant syntax. Recent studies incorporate program dependencies as semantics to identify syntactically different yet semantically similar programs, but they often focus only on local neighborhoods (e.g., one-hop dependencies), limiting the expressiveness of program semantics in modeling functionalities. In this paper, we present Tailor that explicitly exploits deep graph-structured code features for functional similarity detection. Given source-level programs, Tailor first represents them into code property graphs (CPGs) - which combine abstract syntax trees, control flow graphs, and data flow graphs - to collectively reason about program syntax and semantics. Then, Tailor learns representations of CPGs by applying a CPG-based neural network (CPGNN) to iteratively propagate information on them. It improves over prior work on code representation learning through a new graph neural network (GNN) tailored to CPG structures instead of the off-the-shelf GNNs used previously. We systematically evaluate Tailor on C and Java programs using two public benchmarks. Experimental results show that Tailor outperforms the state-of-the-art approaches, achieving 99.8% and 99.9% F-scores in code clone detection and 98.3% accuracy in source code classification. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171745038&doi=10.1109%2fICSE48619.2023.00040&partnerID=40&md5=53a3e46dcfc8d8ebf0487b07fc1986f7,Proceedings - International Conference on Software Engineering,6,Include,I1.1,
Das D.; Mathews N.S.; Mathai A.; Tamilselvam S.; Sedamaki K.; Chimalakonda S.; Kumar A.,COMEX: A Tool for Generating Customized Source Code Representations,"Learning effective representations of source code is critical for any Machine Learning for Software Engineering (ML4SE) system. Inspired by natural language processing, large language models (LLMs) like Codex and CodeGen treat code as generic sequences of text and are trained on huge corpora of code data, achieving state of the art performance on several software engineering (SE) tasks. However, valid source code, unlike natural language, follows a strict structure and pattern governed by the underlying grammar of the programming language. Current LLMs do not exploit this property of the source code as they treat code like a sequence of tokens and overlook key structural and semantic properties of code that can be extracted from code-views like the Control Flow Graph (CFG), Data Flow Graph (DFG), Abstract Syntax Tree (AST), etc. Unfortunately, the process of generating and integrating code-views for every programming language is cumbersome and time consuming. To overcome this barrier, we propose our tool COMEX - a framework that allows researchers and developers to create and combine multiple code-views which can be used by machine learning (ML) models for various SE tasks. Some salient features of our tool are: (i) it works directly on source code (which need not be compilable), (ii) it currently supports Java and C#, (iii) it can analyze both method-level snippets and program-level snippets by using both intra-procedural and inter-procedural analysis, and (iv) it is easily extendable to other languages as it is built on tree-sitter - a widely used incremental parser that supports over 40 languages. We believe this easy-to-use code-view generation and customization tool will give impetus to research in source code representation learning methods and ML4SE. The source code and demonstration of our tool can be found at https://github.com/IBM/tree-sitter-codeviews and https://youtu.be/GER6U87FVbU, respectively.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178994775&doi=10.1109%2fASE56229.2023.00010&partnerID=40&md5=1a70ee5b1443473ceb8605a0a5bd21b9,"Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023",7,Exclude,E1.1,
Nashid N.; Sintaha M.; Mesbah A.,Embedding Context as Code Dependencies for Neural Program Repair,"Deep learning-based program repair has received significant attention from the research community lately. Most existing techniques treat source code as a sequence of tokens or abstract syntax trees. Consequently, they cannot incorporate semantic contextual information pertaining to a buggy line of code and its fix. In this work, we propose a program repair technique called GLANCE that combines static program analysis with graph-to-sequence learning for capturing contextual information. To represent contextual information, we introduce a graph representation that can encode information about the buggy code and its repair ingredients by embedding control and data flow information. We employ a fine-grained graphical code representation, which explicitly describes code change context and embeds semantic relationships between code elements. GLANCE leverages a graph neural network and a sequence-based decoder to learn from this semantic code representation. We evaluated our work against six state-of-the-art techniques, and our results show that GLANCE fixes 52% more bugs than the best performing technique.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161949341&doi=10.1109%2fICST57152.2023.00018&partnerID=40&md5=c0ba7521813481c648b352b9f7768f43,"Proceedings - 2023 IEEE 16th International Conference on Software Testing, Verification and Validation, ICST 2023",8,Include,I1.2,
Wang W.; Zhang K.; Li G.; Liu S.; Li A.; Jin Z.; Liu Y.,Learning Program Representations with a Tree-Structured Transformer,"Learning vector representations for programs is a critical step in applying deep learning techniques for program understanding tasks. Various neural network models are proposed to learn from tree-structured program representations, e.g., abstract syntax tree (AST) and concrete syntax tree (CST). However, most neural architectures either fail to capture long-range dependencies which are ubiquitous in programs, or cannot learn effective representations for syntax tree nodes, making them incapable of performing the node-level prediction tasks, e.g., bug localization. In this paper, we propose Tree-Transformer, a novel recursive tree-structured neural network to learn the vector representations for source codes. We propose a multi-head attention mechanism to model the dependency between siblings and parent-children node pairs. Moreover, we propose a bi-directional propagation strategy to allow node information passing in two directions, bottom-up and top-down along trees. In this way, Tree-Transformer can learn the information of the node features as well as the global contextual information. The extensive experimental results show that our Tree-Transformer significantly outperforms the existing tree-based and graph-based program representation learning approaches in both the tree-level and node-level prediction tasks. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160553032&doi=10.1109%2fSANER56733.2023.00032&partnerID=40&md5=026c96d9f2a353f6e064483c12951584,"Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",9,Include,I1.1,
Sukur N.; Milošević N.; Pracner D.; Budimac Z.,Automated program improvement with reinforcement learning and graph neural networks,"Automated software transformations and the process of automated program repair and improvement are an important aspect of modern software engineering practices. In this paper, we describe a system which uses a graph-based deep learning model that can be trained to automatically transform and improve computer programs. By operating on language-agnostic, universal graph-like structures easily extractable from source code files (abstract syntax trees), the deep learning agent learns which transformations should be effectively applied to various structures recognized in the source code in order to improve it. By defining a metric which we want to improve and introducing an optimization task—a reinforcement learning setting, an agent learns to automatically apply a chain of transformations to the program, drastically improving it. While similar program improvement processes exist, they exclusively use exhaustive search algorithms to try all the possible code transformations which is a long process susceptible to local optimum issues. Our solution aims to model and embed structural knowledge about the programs being transformed which greatly helps the agent to choose best possible code transformations to apply. Elements of the approach we present in this paper are further applicable not just to automatic software improvement tasks, but also to other code-related tasks. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160861647&doi=10.1007%2fs00500-023-08559-1&partnerID=40&md5=8f31b665e0a0762d68a81c3d84e68699,Soft Computing,10,Include,,"Double check: does this operate on byte code? (given that this was done in the scope of fermat, which operates on bytecode)"
Chen C.; Peng X.; Xing Z.; Sun J.; Wang X.; Zhao Y.; Zhao W.,Holistic Combination of Structural and Textual Code Information for Context Based API Recommendation,"Context based API recommendation is an important way to help developers find the needed APIs effectively and efficiently. For effective API recommendation, we need not only a joint view of both structural and textual code information, but also a holistic view of correlated API usage in control and data flow graph as a whole. Unfortunately, existing API recommendation methods exploit structural or textual code information separately. In this work, we propose a novel API recommendation approach called APIRec-CST (API Recommendation by Combining Structural and Textual code information). APIRec-CST is a deep learning model that combines the API usage with the text information in the source code based on an API Context Graph Network and a Code Token Network that simultaneously learn structural and textual features for API recommendation. We apply APIRec-CST to train a model for JDK library based on 1,914 open-source Java projects and evaluate the accuracy and MRR (Mean Reciprocal Rank) of API recommendation with another 6 open-source projects. The results show that our approach achieves respectively a top-1, top-5, top-10 accuracy and MRR of 60.3, 81.5, 87.7 and 69.4 percent, and significantly outperforms an existing graph-based statistical approach and a tree-based deep learning approach for API recommendation. A further analysis shows that textual code information makes sense and improves the accuracy and MRR. The sensitivity analysis shows that the top-k accuracy and MRR of APIRec-CST are insensitive to the number of APIs to be recommended in a hole. We also conduct a user study in which two groups of students are asked to finish 6 programming tasks with or without our APIRec-CST plugin. The results show that APIRec-CST can help the students to finish the tasks faster and more accurately and the feedback on the usability is overwhelmingly positive. © 1976-2012 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104636235&doi=10.1109%2fTSE.2021.3074309&partnerID=40&md5=673fd9afacf9ce76e19fed9b164bd0b9,IEEE Transactions on Software Engineering,11,Include,"I1.1,I1.2",
Alon Y.; David C.,Using graph neural networks for program termination,"Termination analyses investigate the termination behavior of programs, intending to detect nontermination, which is known to cause a variety of program bugs (e.g. hanging programs, denial-of-service vulnerabilities). Beyond formal approaches, various attempts have been made to estimate the termination behavior of programs using neural networks. However, the majority of these approaches continue to rely on formal methods to provide strong soundness guarantees and consequently suffer from similar limitations. In this paper, we move away from formal methods and embrace the stochastic nature of machine learning models. Instead of aiming for rigorous guarantees that can be interpreted by solvers, our objective is to provide an estimation of a program's termination behavior and of the likely reason for nontermination (when applicable) that a programmer can use for debugging purposes. Compared to previous approaches using neural networks for program termination, we also take advantage of the graph representation of programs by employing Graph Neural Networks. To further assist programmers in understanding and debugging nontermination bugs, we adapt the notions of attention and semantic segmentation, previously used for other application domains, to programs. Overall, we designed and implemented classifiers for program termination based on Graph Convolutional Networks and Graph Attention Networks, as well as a semantic segmentation Graph Neural Network that localizes AST nodes likely to cause nontermination. We also illustrated how the information provided by semantic segmentation can be combined with program slicing to further aid debugging.  © 2022 Owner/Author.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143064932&doi=10.1145%2f3540250.3549095&partnerID=40&md5=9156908b690ba90af862a39222ba7ecb,ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,12,Include,I1.2,
Liu J.; Zeng J.; Wang X.; Ji K.; Liang Z.,TeLL: Log level suggestions via modeling multi-level code block information,"Developers insert logging statements into source code to monitor system execution, which forms the basis for software debugging and maintenance. For distinguishing diverse runtime information, each software log is assigned with a separate verbosity level (e.g., trace and error). However, choosing an appropriate verbosity level is a challenging and error-prone task due to the lack of specifications for log level usages. Prior solutions aim to suggest log levels based on the code block in which a logging statement resides (i.e., intra-block features). Such suggestions, however, do not consider information from surrounding blocks (i.e., inter-block features), which also plays an important role in revealing logging characteristics. To address this issue, we combine multiple levels of code block information (i.e., intra-block and inter-block features) into a joint graph structure called Flow of Abstract Syntax Tree (FAST). To explicitly exploit multi-level block features, we design a new neural architecture, Hierarchical Block Graph Network (HBGN), on the FAST. In particular, it leverages graph neural networks to encode both the intra-block and inter-block features into code block representations and guide log level suggestions. We implement a prototype system, TeLL, and evaluate its effectiveness on nine large-scale software systems. Experimental results showcase TeLL's advantage in predicting log levels over the state-of-the-art approaches.  © 2022 Owner/Author.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136803982&doi=10.1145%2f3533767.3534379&partnerID=40&md5=2e89b0ce740145a39cccfbfc5c613c53,ISSTA 2022 - Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis,13,Include,I1.2,
Qian Y.; Zhang Y.; Wen Q.; Ye Y.; Zhang C.,Rep2Vec: Repository Embedding via Heterogeneous Graph Adversarial Contrastive Learning,"Driven by the exponential increase of software and the advent of the pull-based development system Git, a large amount of open-source software has emerged on various social coding platforms. GitHub, as the largest platform, not only attracts developers and researchers to contribute legitimate software and research-related source code but has also become a popular platform for an increasing number of cybercriminals to perform continuous cyberattacks. Hence, some tools have been developed to learn representations of repositories on GitHub for various related applications (e.g., malicious repository detection) recently. However, most of them merely focus on code content while ignoring the rich relational data among repositories. In addition, they usually require a mass of resources to obtain sufficient labeled data for model training while ignoring the usefully handy unlabeled data. To this end, we propose a novel model Rep2Vec which integrates the code content, the structural relations, and the unlabeled data to learn the repository representations. First, to comprehensively model the repository data, we build a repository heterogeneous graph (Rep-HG) which is encoded by a graph neural network. Afterwards, to fully exploit unlabeled data in Rep-HG, we introduce adversarial attacks to generate more challenging contrastive pairs for the contrastive learning module to train the encoder in node view and meta-path view simultaneously. To alleviate the workload of the encoder against attacks, we further design a dual-stream contrastive learning module that integrates contrastive learning on adversarial graph and original graph together. Finally, the pre-trained encoder is fine-tuned to the downstream task, and further enhanced by a knowledge distillation module. Extensive experiments on the collected dataset from GitHub demonstrate the effectiveness of Rep2Vec in comparison with state-of-the-art methods for multiple repository tasks.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137142998&doi=10.1145%2f3534678.3539324&partnerID=40&md5=c3c7c70d0cdcdb6b01b1b244a0b4d5a9,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,14,Include,,
Ardimento P.; Aversano L.; Bernardi M.L.; Cimitile M.,Design patterns mining using neural sub-graph matching,"Design Patterns detection in Object-Oriented software systems is essential for effectively supporting program comprehension and re-engineering tasks. It helps to recover, from source code, the developers' design decisions and trade-offs that could be not up-to-date or even not documented. Several approaches to mine design patterns from source code have been defined in the last twelve years and they are all based on the analysis of object-oriented systems components, their relationships, and behaviors to identify the roles played in the patterns. Both static and dynamic approaches need to perform matching between data captured from the system with the design patterns specification that encodes the structure and the behavior of the micro-architectural solution. The matching process, in principle, can be formulated as a sub-graph matching problem that is NP-complete. This problem has been addressed in the literature using heuristics designed to produce good solutions in an acceptable time, but the task is still expensive with a significant trade-off between accuracy and performance. This work proposes the adoption of a neural-based approach that exploits graph neural networks to perform detection using a more efficient sub-graph matching step outperforming existing heuristics proposed for this task. The pattern detection approach has been assessed on several open-source systems widely used to perform design pattern detection obtaining very good results for both detection performances and efficiency. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130388510&doi=10.1145%2f3477314.3507073&partnerID=40&md5=b0ba92c528295442e80c974754fde807,Proceedings of the ACM Symposium on Applied Computing,15,Include,I1.1,
Xiao D.; Hang D.; Ai L.; Li S.; Liang H.,Path context augmented statement and network for learning programs,"Applying machine learning techniques in program analysis has attracted much attention. Recent research efforts in detecting code clones and classifying code have shown that neural models based on abstract syntax trees (ASTs) can better represent source code than other approaches. However, existing AST-based approaches do not take into account contextual information of a program, like statement context. To address this issue, we propose a novel approach path context to capture the context of statements, and a path context augmented network (PCAN) to learn a program. We evaluate PCAN on code clone detection, source code classification, and method naming. The results show that compared to state-of-the-art approaches, PCAN performs the best on code clone detection and has comparable performance on code classification and method naming. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122668648&doi=10.1007%2fs10664-021-10098-y&partnerID=40&md5=50bf30a064322a3cb94a24b84246e28c,Empirical Software Engineering,16,Include,"I1.2,I1.1",
Zhao Z.; Yang B.; Li G.; Liu H.; Jin Z.,Precise Learning of Source Code Contextual Semantics via Hierarchical Dependence Structure and Graph Attention Networks,"Deep learning is being used extensively in a variety of software engineering tasks, e.g., program classification and defect prediction. Although the technique eliminates the required process of feature engineering, the construction of source code model significantly affects the performance on those tasks. Most recent works was mainly focused on complementing AST-based source code models by introducing contextual dependencies extracted from CFG. However, all of them pay little attention to the representation of basic blocks, which are the basis of contextual dependencies. In this paper, we integrated AST and CFG and proposed a novel source code model embedded with hierarchical dependencies. Based on that, we also designed a neural network that depends on the graph attention mechanism. Specifically, we introduced the syntactic structural of the basic block, i.e., its corresponding AST, in source code model to provide sufficient information and fill the gap. We have evaluated this model on three practical software engineering tasks and compared it with other state-of-the-art methods. The results show that our model can significantly improve the performance. For example, compared to the best performing baseline, our model reduces the scale of parameters by 50% and achieves 4% improvement on accuracy on program classification task. © 2021 Elsevier Inc.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118759414&doi=10.1016%2fj.jss.2021.111108&partnerID=40&md5=b2e6deb1d8c0668848a5d5f83bc18516,Journal of Systems and Software,17,Include,"I1.1,I1.2",
Romanov V.; Ivanov V.,Prediction of Types in Python with Pre-Trained Graph Neural Networks,"The application of Graph Neural Networks for pre-Training models for source code is not well studied. We experimented with pre-Training a Graph Neural Network model for Python on tasks of Name Prediction and Edge Prediction. Then, we used pre-Trained weights to initialize a model for variable type prediction. Our preliminary results suggest that pre-Training on these tasks brings neither improvements in type prediction performance nor training dynamics. Possible ways to fix this are discussed in the concluding section of the paper. Additionally, we performed an ablation study to see whether type prediction is overreliant on some parts of the graph. Results suggest, that type prediction model does not significantly rely on obvious shortcuts and could be a useful proxy for evaluating pre-Trained graph embeddings.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146265787&doi=10.1109%2fIVMEM57067.2022.9983956&partnerID=40&md5=6d2dc784677e91f5f7fdf1c6e5a298f4,"Proceedings - 2022 Ivannikov Memorial Workshop, IVMEM 2022",18,Include,"I1.2,I1.1",
Nguyen H.H.; Nguyen N.-M.; Xie C.; Ahmadi Z.; Kudendo D.; Doan T.-N.; Jiang L.,MANDO: Multi-Level Heterogeneous Graph Embeddings for Fine-Grained Detection of Smart Contract Vulnerabilities,"Learning heterogeneous graphs consisting of different types of nodes and edges enhances the results of homogeneous graph techniques. An interesting example of such graphs is control-flow graphs representing possible software code execution flows. As such graphs represent more semantic information of code, developing techniques and tools for such graphs can be highly beneficial for detecting vulnerabilities in software for its reliability. However, existing heterogeneous graph techniques are still insufficient in handling complex graphs where the number of different types of nodes and edges is large and variable. This paper concentrates on the Ethereum smart contracts as a sample of software codes represented by heterogeneous contract graphs built upon both control-flow graphs and call graphs containing different types of nodes and links. We propose MANDO, a new heterogeneous graph representation to learn such heterogeneous contract graphs' structures. MANDO extracts customized meta-paths, which compose relational connections between different types of nodes and their neighbors. Moreover, it develops a multi-metapath heterogeneous graph attention network to learn multi-level embeddings of different types of nodes and their metapaths in the heterogeneous contract graphs, which can capture the code semantics of smart contracts more accurately and facilitate both fine-grained line-level and coarse-grained contract-level vulnerability detection. Our extensive evaluation of large smart contract datasets shows that MANDO improves the vulnerability detection results of other techniques at the coarse-grained contract level. More importantly, it is the first learning-based approach capable of identifying vulnerabilities at the fine-grained line-level, and significantly improves the traditional code analysis-based vulnerability detection approaches by 11.35% to 70.81% in terms of F1-score. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143075291&doi=10.1109%2fDSAA54385.2022.10032337&partnerID=40&md5=a50173fabedbf7977331fc2f6d90f0d3,"Proceedings - 2022 IEEE 9th International Conference on Data Science and Advanced Analytics, DSAA 2022",19,Include,"I1.2,I1.1",
Ma W.; Zhao M.; Soremekun E.; Hu Q.; Zhang J.M.; Papadakis M.; Cordy M.; Xie X.; Le Traon Y.,GraphCode2Vec: Generic Code Embedding via Lexical and Program Dependence Analyses,"Code embedding is a keystone in the application of machine learning on several Software Engineering (SE) tasks. To effectively support a plethora of SE tasks, the embedding needs to capture program syntax and semantics in a way that is generic. To this end, we propose the first self-supervised pre-training approach (called Graphcode2vec) which produces task-agnostic embedding of lexical and program dependence features. Graphcode2vec achieves this via a synergistic combination of code analysis and Graph Neural Networks. Graphcode2vec is generic, it allows pre-training, and it is applicable to several SE downstream tasks. We evaluate the effectiveness of Graphcode2vec on four (4) tasks (method name prediction, solution classification, mutation testing and overfitted patch classification), and compare it with four (4) similarly generic code embedding baselines (Code2Seq, Code2Vec, CodeBERT, Graph-CodeBERT) and seven (7) task-specific, learning-based methods. In particular, Graphcode2vec is more effective than both generic and task-specific learning-based baselines. It is also complementary and comparable to GraphCodeBERT (a larger and more complex model). We also demonstrate through a probing and ablation study that Graphcode2vec learns lexical and program dependence features and that self-supervised pre-training improves effectiveness. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134018448&doi=10.1145%2f3524842.3528456&partnerID=40&md5=8de7aa869994647081c414a65aa27259,"Proceedings - 2022 Mining Software Repositories Conference, MSR 2022",20,Include,I1.1,
Samoaa H.P.; Longa A.; Mohamad M.; Chehreghani M.H.; Leitner P.,TEP-GNN: Accurate Execution Time Prediction of Functional Tests Using Graph Neural Networks,"Predicting the performance of production code prior to actual execution is known to be highly challenging. In this paper, we propose a predictive model, dubbed TEP-GNN, which demonstrates that high-accuracy performance prediction is possible for the special case of predicting unit test execution times. TEP-GNN uses FA-ASTs, or flow-augmented ASTs, as a graph-based code representation approach, and predicts test execution times using a powerful graph neural network (GNN) deep learning model. We evaluate TEP-GNN using four real-life Java open source programs, based on 922 test files mined from the projects’ public repositories. We find that our approach achieves a high Pearson correlation of 0.789, considerable outperforming a baseline deep learning model. Our work demonstrates that FA-ASTs and GNNs are a feasible approach for predicting absolute performance values, and serves as an important intermediary step towards being able to predict the performance of arbitrary code prior to execution. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142682048&doi=10.1007%2f978-3-031-21388-5_32&partnerID=40&md5=135963edc383a2020c19681c88c0d89f,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),21,Include,I1.1,
Zhu R.; Yuan L.; Li X.; Gao M.; Cai W.,A Neural Network Architecture for Program Understanding Inspired by Human Behaviors,"Program understanding is a fundamental task in program language processing. Despite the success, existing works fail to take human behaviors as reference in understanding programs. In this paper, we consider human behaviors and propose the PGNN-EK model that consists of two main components. On the one hand, inspired by the “divide-and-conquer” reading behaviors of humans, we present a partitioning-based graph neural network model PGNN on the upgraded AST of codes. On the other hand, to characterize human behaviors of resorting to other resources to help code comprehension, we transform raw codes with external knowledge and apply pre-training techniques for information extraction. Finally, we combine the two embeddings generated from the two components to output code embeddings. We conduct extensive experiments to show the superior performance of PGNN-EK on the code summarization and code clone detection tasks. In particular, to show the generalization ability of our model, we release a new dataset that is more challenging for code clone detection and could advance the development of the community. Our codes and data are publicly available at https://github.com/RecklessRonan/PGNN-EK. © 2022 Association for Computational Linguistics.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140398484&partnerID=40&md5=9020473919331f9676604d8e85374f6c,Proceedings of the Annual Meeting of the Association for Computational Linguistics,22,Include,I1.2,
Xue Y.; Guo J.; Zhang L.; Song H.,Message Passing Graph Neural Networks for Software Security Vulnerability Detection,"With the booming development of deep learning and machine learning, the use of neural networks for software source code security vulnerability detection has become a hot pot in the field of software security. As a data structure, graphs can adequately represent the complex syntactic information, semantic information, and dependencies in software source code. In this paper, we propose the MPGVD model based on the idea of text classification in natural language processing. The model uses BERT for source code pre-training, transforms graphs into corresponding feature vectors, uses MPNN (Message Passing Neural Networks) based on graph neural networks in the feature extraction phase, and finally outputs the detection results. Our proposed MPGVD, compared with other existing vulnerability detection models on the same dataset CodeXGLUE, obtain the highest detection accuracy of 64.34%.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142506108&doi=10.1109%2fICCNEA57056.2022.00041&partnerID=40&md5=b9f59e156dd72ddaaacc337da4ce9342,"Proceedings - 2022 International Conference on Computer Network, Electronic and Automation, ICCNEA 2022",23,Include,I1.1,Unclear how exactly the graph is constructed 
Nguyen H.V.; Zheng J.; Inomata A.; Uehara T.,Code Aggregate Graph: Effective Representation for Graph Neural Networks to Detect Vulnerable Code,"Deep learning, especially graph neural networks (GNNs), provides efficient, fast, and automated methods to detect vulnerable code. However, the accuracy could be improved as previous studies were limited by existing code representations. Additionally, the diversity of embedding techniques and GNN models can make selecting the appropriate method challenging. Herein we propose Code Aggregate Graph (CAG) to improve vulnerability detection efficiency. CAG combines the principles of different code analyses such as abstract syntax tree, control flow graph, and program dependence graph with dominator and post-dominator trees. This extensive representation empowers deep graph networks for enhanced classification. We also implement different data encoding methods and neural networks to provide a multidimensional view of the system performance. Specifically, three word embedding approaches and three deep GNNs are utilized to build classifiers. Then CAG is evaluated using two datasets: a real-world open-source dataset and the software assurance reference dataset. CAG is also compared with seven state-of-the-art methods and six classic representations. CAG shows the best performance. Compared to previous studies, CAG has an increased accuracy (5.4%) and F1-score (5.1%). Additionally, experiments confirm that encoding has a positive impact on accuracy (4-6%) but the network type does not. The study should contribute to a meaningful benchmark for future research on code representations, data encoding, and GNNs.  © 2013 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140708573&doi=10.1109%2fACCESS.2022.3216395&partnerID=40&md5=1a5ef9149269d7bcb295558d4263f64a,IEEE Access,24,Include,I1.2,"Unclear which exact experiments were performed, unless I missed something"
Petukhov M.; Gudauskayte E.; Kaliyev A.; Oskin M.; Ivanov D.; Wang Q.,Method Name Prediction for Automatically Generated Unit Tests,"Writing intuitively understandable method names is an important aspect of good programming practice. The method names have to summarize the codes' behavior such that software engineers would easily understand their purpose. Modern automatic testing tools are able to generate potentially unlimited number of unit tests for a project under test. However, these tests suffers from unintelligible unit test names as it is quite difficult to understand what each test triggers and checks. This inspired us to adapt the state-of-the-art method name prediction approaches for automatically generated unit tests. We have developed a graph extraction pipeline with prediction models based on Graph Neural Networks (GNNs). Extracted graphs contain information about the structure of unit tests and their called functions. The experiment results have shown that the proposed work outperforms other models with precision = 0.48, recall = 0.42 and F1 = 0.45 results. The dataset and source codes are released for wide public access.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130020877&doi=10.1109%2fICCQ53703.2022.9763112&partnerID=40&md5=ed0fff791e84806977f36e384166f1e4,ICCQ 2022 - Proceedings of the 2nd International Conference on Code Quality,25,Include,I1.1,
Chen Z.; Zhang T.; Peng X.,A Novel API Recommendation Approach By Using Graph Attention Network,"Although the use of APIs (Application Programming Interfaces) in software program development can effectively improve development efficiency, developers still need to spend more time in finding suitable APIs. To improve the overall development efficiency, many API recommendation approaches have been proposed. However, they could not make good use of the information in the source code, especially for the structural information. The PDG (Program Dependence Graph) of source code can contain both syntactic and structural information, which can be great representations of the source code. Based on the PDG, we propose a new approach, called JARST (Java API Recommendation combining Structural with Textual code information), which recommends the appropriate APIs by analyzing the structure information and text information of the source code. The JARST approach uses a graph neural network to learn source code structure information of PDG and uses a multi-modal approach to learn the text information in the source code. Finally, we combine the structural and textual information of the source code to implement API recommendations. We collect 625 open source Java projects from Github as our experimental objects. The experimental results show that JARST can provide accurate APIs to help software developers facilitate development activities. Moreover, it performs better than the cutting-edge studies including APIRes-CST and APIREC with higher top-k accuracy values. In detail, the improvement achieves up to 35.3%. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146199902&doi=10.1109%2fQRS54544.2021.00082&partnerID=40&md5=cef4668a79de071a6550072240aef8be,"IEEE International Conference on Software Quality, Reliability and Security, QRS",26,Include,I1.1,
Jain P.; Jain A.; Zhang T.; Abbeel P.; Gonzalez J.E.; Stoica I.,Contrastive Code Representation Learning,"Recent work learns contextual representations of source code by reconstructing tokens from their context. For downstream semantic understanding tasks like code clone detection, these representations should ideally capture program functionality. However, we show that the popular reconstruction-based RoBERTa model is sensitive to source code edits, even when the edits preserve semantics. We propose ContraCode: a contrastive pre-training task that learns code functionality, not form. ContraCode pre-trains a neural network to identify functionally similar variants of a program among many non-equivalent distractors. We scalably generate these variants using an automated source-to-source compiler as a form of data augmentation. Contrastive pretraining outperforms RoBERTa on an adversarial code clone detection benchmark by 39% AUROC. Surprisingly, improved adversarial robustness translates to better accuracy over natural code; ContraCode improves summarization and TypeScript type inference accuracy by 2 to 13 percentage points over competitive baselines. All source is available at https://github.com/parasj/contracode. © 2021 Association for Computational Linguistics",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123338103&partnerID=40&md5=c4c75db6d4500c1998722ed2b782410a,"EMNLP 2021 - 2021 Conference on Empirical Methods in Natural Language Processing, Proceedings",27,Exclude,E1.1,
Paaßen B.; McBroom J.; Jeffries B.; Yacef K.; Koprinska I.,Mapping Python Programs to Vectors using Recursive Neural Encodings,"Educational data mining involves the application of data mining techniques to student activity. However, in the context of computer programming, many data mining techniques can not be applied because they require vector-shaped input, whereas computer programs have the form of syntax trees. In this paper, we present ast2vec, a neural network that maps Python syntax trees to vectors and back, thereby enabling about a hundred data mining techniques that were previously not applicable. Ast2vec has been trained on almost half a million programs of novice programmers and is designed to be applied across learning tasks without re-training, meaning that users can apply it without any need for deep learning. We demonstrate the generality of ast2vec in three settings. First, we provide example analyses using ast2vec on a classroom-sized dataset, involving two novel techniques, namely progress-variance projection for visualization and a dynamical systems analysis for prediction. In these examples, we also explain how ast2vec can be utilized for educational decisions. Second, we consider the ability of ast2vec to recover the original syntax tree from its vector representation on the training data and two other large-scale programming datasets. Finally, we evaluate the predictive capability of a linear dynamical system on top of ast2vec, obtaining similar results to techniques that work directly on syntax trees while being much faster (constant- instead of linear-time processing). We hope ast2vec can augment the educational data mining toolkit by making analyses of computer programs easier, richer, and more efficient. © 2021. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132630551&doi=10.5281%2fzenodo.5634224&partnerID=40&md5=7aa89301e2e8d1ae526fd13f58e9cd3f,Journal of Educational Data Mining,28,Include,I1.1,
Ivanov V.; Romanov V.; Succi G.,Predicting Type Annotations for Python using Embeddings from Graph Neural Networks,"An intelligent tool for type annotations in Python would increase the productivity of developers. Python is a dynamic programming language, and predicting types using static analysis is difficult. Existing techniques for type prediction use deep learning models originated in the area of Natural Language Processing. These models depend on the quality of embeddings for source code tokens. We compared approaches for pre-training embeddings for source code. Specifically, we compared FastText embeddings to embeddings trained with Graph Neural Networks (GNN). Our experiments showed that GNN embeddings outperformed FastText embeddings on the task of type prediction. Moreover, they seem to encode complementary information since the prediction quality increases when both types of embeddings are used. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137946240&partnerID=40&md5=ab98f6d51366117e312176dbdc39bd0f,"International Conference on Enterprise Information Systems, ICEIS - Proceedings",29,Include,"I1.2,I1.1",Graph construction not fully clear to me. GNN training setup is unclear
Ramadan T.; Islam T.Z.; Phelps C.; Pinnow N.; Thiagarajan J.J.,Comparative Code Structure Analysis using Deep Learning for Performance Prediction,"Performance analysis has always been an afterthought during the application development process, focusing on application correctness first. The learning curve of the existing static and dynamic analysis tools are steep, which requires understanding low-level details to interpret the findings for actionable optimizations. Additionally, application performance is a function of a number of unknowns stemming from the application-, runtime-, and interactions between the OS and underlying hardware, making it difficult to model using any deep learning technique, especially without a large labeled dataset. In this paper, we address both of these problems by presenting a large corpus of a labeled dataset for the community and take a comparative analysis approach to mitigate all unknowns except their source code differences between different correct implementations of the same problem. We put the power of deep learning to the test for automatically extracting information from the hierarchical structure of abstract syntax trees to represent source code. This paper aims to assess the feasibility of using purely static information (e.g., abstract syntax tree or AST) of applications to predict performance change based on the change in code structure. This research will enable performance-aware application development since every version of the application will continue to contribute to the corpora, which will enhance the performance of the model. We evaluate several deep learning-based representation learning techniques for source code. Our results show that tree-based Long Short-Term Memory (LSTM) models can leverage source code's hierarchical structure to discover latent representations. Specifically, LSTM-based predictive models built using a single problem and a combination of multiple problems can correctly predict if a source code will perform better or worse up to 84% and 73% of the time, respectively.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105381706&doi=10.1109%2fISPASS51385.2021.00032&partnerID=40&md5=63fe68357a1b32bc8ca94c6f9bdb3311,"Proceedings - 2021 IEEE International Symposium on Performance Analysis of Systems and Software, ISPASS 2021",30,Include,I1.1,
Romanov V.,Evaluating importance of edge types when using graph neural network for predicting return types of Python functions,"The static prediction of types for dynamic programming languages is a challenging and important problem. Some success for Python was demonstrated by analyzing docstrings, still, a large portion of code comes without thorough documentation. To target this problem in this work we attempt to predict return type annotations for Python functions by looking at function usage patterns. We analyzed a collection of Python packages and created a graph that captures global relationships between source code elements such as imports, calls, and definitions. Moreover, we train embeddings for functions and evaluate how the performance of predicting return types is affected by removing one of the relationship types from the dataset.  © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097709365&doi=10.1145%2f3426430.3428135&partnerID=40&md5=aaec256bd65fc3a29df25994889df992,"SPLASH Companion 2020 - Companion Proceedings of the 2020 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity",31,Exclude,I1.1,"Doesn't really propose a new method, but evaluates some aspects. Might need to be excluded"
Wang W.; Li G.; Shen S.; Xia X.; Jin Z.,Modular Tree Network for Source Code Representation Learning,"Learning representation for source code is a foundation of many program analysis tasks. In recent years, neural networks have already shown success in this area, but most existing models did not make full use of the unique structural information of programs. Although abstract syntax tree (AST)-based neural models can handle the tree structure in the source code, they cannot capture the richness of different types of substructure in programs. In this article, we propose a modular tree network that dynamically composes different neural network units into tree structures based on the input AST. Different from previous tree-structural neural network models, a modular tree network can capture the semantic differences between types of AST substructures. We evaluate our model on two tasks: program classification and code clone detection. Our model achieves the best performance compared with state-of-the-art approaches in both tasks, showing the advantage of leveraging more elaborate structure information of the source code.  © 2020 ACM.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092714268&doi=10.1145%2f3409331&partnerID=40&md5=d905cdf7f3fff0be2096f74ffa0ca9ba,ACM Transactions on Software Engineering and Methodology,32,Include,I1.1,
Ye G.; Tang Z.; Wang H.; Fang D.; Fang J.; Huang S.; Wang Z.,Deep program structure modeling through multi-relational graph-based learning,"Deep learning is emerging as a promising technique for buildingpredictive models to support code-related tasks like performanceoptimization and code vulnerability detection. One of the criticalaspects of building a successful predictive model is having theright representation to characterize the model input for the giventask. Existing approaches in the area typically treat the programstructure as a sequential sequence but fail to capitalize on the richsemantics of data and control flow information, for which graphsare a proven representation structure.We present Poem1, a novel framework that automatically learnsuseful code representations from graph-based program structures.At the core of Poem is a graph neural network (GNN) that is specially designed for capturing the syntax and semantic informationfrom the program abstract syntax tree and the control and dataflow graph. As a departure from existing GNN-based code modeling techniques, our network simultaneously learns over multiplerelations of a program graph. This capability enables the learningframework to distinguish and reason about the diverse code relationships, be it a data or a control flow or any other relationshipsthat may be important for the downstream processing task.We apply Poem to four representative tasks that require a strongability to reason about the program structure: heterogeneous devicemapping, parallel thread coarsening, loop vectorization and codevulnerability detection. We evaluate Poem on programs written inOpenCL, C, Java and Swift, and compare it against nine learningbased methods. Experimental results show that Poem consistentlyoutperforms all competing methods across evaluation settings.  © 2020 Association for Computing Machinery.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094208858&doi=10.1145%2f3410463.3414670&partnerID=40&md5=7e53d7f68569e46dadc23171ed2dae04,"Parallel Architectures and Compilation Techniques - Conference Proceedings, PACT",33,Include,"I1.1,I1.2",
Richter C.; Hüllermeier E.; Jakobs M.-C.; Wehrheim H.,Algorithm selection for software validation based on graph kernels,"Algorithm selection is the task of choosing an algorithm from a given set of candidate algorithms when faced with a particular problem instance. Algorithm selection via machine learning (ML) has recently been successfully applied for various problem classes, including computationally hard problems such as SAT. In this paper, we study algorithm selection for software validation, i.e., the task of choosing a software validation tool for a given validation instance. A validation instance consists of a program plus properties to be checked on it. The application of machine learning techniques to this task first of all requires an appropriate representation of software. To this end,we propose a dedicated kernel function, which compares two programs in terms of their similarity, thus making the algorithm selection task amenable to kernel-based machine learning methods. Our kernel operates on a graph representation of source code mixing elements of control-flow and program-dependence graphs with abstract syntax trees.Thus, given two such representations as input, the kernel function yields a real-valued score that can be interpreted as a degree of similarity. We experimentally evaluate our kernel in two learning scenarios, namely a classification and a ranking problem: (1) selecting between a verification and a testing tool for bug finding (i.e., property violation), and (2) ranking several verification tools,from presumably best to worst, for property proving. The evaluation, which is based on data sets from the annual software verification competition SV-COMP, demonstrates our kernel to generalize well and to achieve rather high prediction accuracy, both for the classification and the ranking task. © 2020, The Author(s).",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083878337&doi=10.1007%2fs10515-020-00270-x&partnerID=40&md5=cf9df51fce68c365deb53d95201ca5b3,Automated Software Engineering,34,Include,I1.1,
Rodrigues G.E.D.P.; Braga A.M.; Dahab R.,Using Graph Embeddings and Machine Learning to Detect Cryptography Misuse in Source Code,"Cryptography is an essential aspect of software development. Nevertheless, software developers have limited knowledge of cryptography primitives, and support tools are limited. In this work, we present a comparison between graph embedding techniques, node2vec and Bag of Graphs, as embedding generators of source code graph representations. We combined these techniques with machine learning models in order to detect cryptography misuses in source codes. We show that Bag of Graphs outperforms node2vec in this task; also, both techniques outperform previously evaluated tools. © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102530771&doi=10.1109%2fICMLA51294.2020.00171&partnerID=40&md5=25e315d337ac391c396b4291e7741021,"Proceedings - 19th IEEE International Conference on Machine Learning and Applications, ICMLA 2020",35,Include,I1.1,
Wang Y.; Wang K.; Gao F.; Wang L.,Learning semantic program embeddings with graph interval neural network,"Learning distributed representations of source code has been a challenging task for machine learning models. Earlier works treated programs as text so that natural language methods can be readily applied. Unfortunately, such approaches do not capitalize on the rich structural information possessed by source code. Of late, Graph Neural Network (GNN) was proposed to learn embeddings of programs from their graph representations. Due to the homogeneous (i.e. do not take advantage of the program-specific graph characteristics) and expensive (i.e. require heavy information exchange among nodes in the graph) message-passing procedure, GNN can suffer from precision issues, especially when dealing with programs rendered into large graphs. In this paper, we present a new graph neural architecture, called Graph Interval Neural Network (GINN), to tackle the weaknesses of the existing GNN. Unlike the standard GNN, GINN generalizes from a curated graph representation obtained through an abstraction method designed to aid models to learn. In particular, GINN focuses exclusively on intervals (generally manifested in looping construct) for mining the feature representation of a program, furthermore, GINN operates on a hierarchy of intervals for scaling the learning to large graphs. We evaluate GINN for two popular downstream applications: variable misuse prediction and method name prediction. Results show in both cases GINN outperforms the state-of-the-art models by a comfortable margin. We have also created a neural bug detector based on GINN to catch null pointer deference bugs in Java code. While learning from the same 9,000 methods extracted from 64 projects, GINN-based bug detector significantly outperforms GNN-based bug detector on 13 unseen test projects. Next, we deploy our trained GINN-based bug detector and Facebook Infer, arguably the state-of-the-art static analysis tool, to scan the codebase of 20 highly starred projects on GitHub. Through our manual inspection, we confirm 38 bugs out of 102 warnings raised by GINN-based bug detector compared to 34 bugs out of 129 warnings for Facebook Infer. We have reported 38 bugs GINN caught to developers, among which 11 have been fixed and 12 have been confirmed (fix pending). GINN has shown to be a general, powerful deep neural network for learning precise, semantic program embeddings. © 2020 Owner/Author.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097576154&doi=10.1145%2f3428205&partnerID=40&md5=e25d55bad2a851b1147a5f865acc5153,Proceedings of the ACM on Programming Languages,36,Include,I1.1,Unclear what kind of model is used for the last task
Wang D.; Dong W.; Li S.,A multi-Task representation learning approach for source code,"Representation learning has shown impressive results for a multitude of tasks in software engineering. However, most researches still focus on a single problem. As a result, the learned representations cannot be applied to other problems and lack generalizability and interpretability. In this paper, we propose a Multi-Task learning approach for representation learning across multiple downstream tasks of software engineering. From the perspective of generalization, we build a shared sequence encoder with a pretrained BERT for the token sequence and a structure encoder with a Tree-LSTM for the abstract syntax tree of code. From the perspective of interpretability, we integrate attention mechanism to focus on different representations and set learnable parameters to adjust the relationship between tasks. We also present the early results of our model. The learning process analysis shows our model has a significant improvement over strong baselines.  © 2020 Owner/Author.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096999195&doi=10.1145%2f3416506.3423575&partnerID=40&md5=90838a9e9cff8ebedea3fa270f9fc249,"RL+SE and PL 2020 - Proceedings of the 1st ACM SIGSOFT International Workshop on Representation Learning for Software Engineering and Program Languages, Co-located with ESEC/FSE 2020",37,Include,I1.1,
Wei J.; Goyal M.; Durrett G.; Dillig I.,LAMBDANET: PROBABILISTIC TYPE INFERENCE USING GRAPH NEURAL NETWORKS,"As gradual typing becomes increasingly popular in languages like Python and TypeScript, there is a growing need to infer type annotations automatically. While type annotations help with tasks like code completion and static error catching, these annotations cannot be fully determined by compilers and are tedious to annotate by hand. This paper proposes a probabilistic type inference scheme for TypeScript based on a graph neural network. Our approach first uses lightweight source code analysis to generate a program abstraction called a type dependency graph, which links type variables with logical constraints as well as name and usage information. Given this program abstraction, we then use a graph neural network to propagate information between related type variables and eventually make type predictions. Our neural architecture can predict both standard types, like number or string, as well as user-defined types that have not been encountered during training. Our experimental results show that our approach outperforms prior work in this space by 14% (absolute) on library types, while having the ability to make type predictions that are out of scope for existing techniques. © 2020 8th International Conference on Learning Representations, ICLR 2020. All rights reserved.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136028933&partnerID=40&md5=def38a1ee95a887c65c0df9dc70d4a25,"8th International Conference on Learning Representations, ICLR 2020",38,Include,"I1.1,I1.2",Perhaps double check task granularity/description
Brauckmann A.; Goens A.; Ertel S.; Castrillon J.,Compiler-based graph representations for deep learning models of code,"In natural language processing, novel methods in deep learning, like recurrent neural networks (RNNs) on sequences of words, have been very successful. In contrast to natural languages, programming languages usually have a well-defined structure. With this structure compilers can reason about programs, using graphs such as abstract syntax trees (ASTs) or control-data flow graphs (CDFGs). In this paper, we argue that we should use these graph structures instead of sequences for learning compiler optimization tasks. To this end, we use graph neural networks (GNNs) for learning predictive compiler tasks on two representations based on ASTs and CDFGs. Experiments show that this improves upon the state-of-the-art in the task of heterogeneous OpenCL mapping, while providing orders of magnitude faster inference times, crucial for compiler optimizations. When testing on benchmark suites not included for training, our AST-based model significantly outperforms the state-of-the-art by over 12 percentage points in terms of accuracy. It is the only one to perform clearly better than a random mapping. On the task of predicting thread coarsening factors, we show that all of the methods fail to produce an overall speedup. © 2020 Association for Computing Machinery.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082029510&doi=10.1145%2f3377555.3377894&partnerID=40&md5=2b6ac90a73bc967e9ed2e3c34a9e86df,CC 2020 - Proceedings of the 29th International Conference on Compiler Construction,39,Include,I1.1,
Takesue Y.; Mashima Y.; Takeuchi K.,Analysis and Visualization of Patterns in Answers to Programming Problems,"It is not an easy task for teachers to make students' answers for programming exercises. In scoring such a student program, the teacher needs to evaluate not only the degree of program achievement but also which way the program achieve the requirements. In order to solve such problems, we propose a supporting method to evaluate the program using 'prog2vec', which is software that converts a program into its feature vector representation. Specifically, our method estimates whether a programming problem needs certain ways to achieve its purpose or not. The input of the method is a set of the programs that are made as answer for the problem. If the method estimates that specific ways are needed to achieve the given problem, it also visualizes these programing ways in structural graph representation. In this way, our proposed method helps teachers that have a lot of and various answers for a programming problem to define evaluation criteria for those answers. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080898612&doi=10.1109%2fIIAI-AAI.2019.00213&partnerID=40&md5=92bf16e1b0b4ede6627f6e51509299f3,"Proceedings - 2019 8th International Congress on Advanced Applied Informatics, IIAI-AAI 2019",40,Exclude,E2.1,
Chen L.; Ye W.; Zhang S.,Capturing Source Code Semantics via Tree-based Convolution over API-enhanced AST,"When deep learning meets big code, a key question is how to efficiently learn a distributed representation for source code that can capture its semantics effectively. We propose to use tree-based convolution over API-enhanced AST. To demonstrate the effectiveness of our approach, we apply it to detect semantic clones-code fragments with similar semantics but dissimilar syntax. Experiment results show that our approach outperforms an existing state-of-the-art approach that uses tree-based LSTM, with an increase of 0.39 and 0.12 in F1-score on OJClone and BigCloneBench respectively. We further propose architectures that incorporate our approach for code search and code summarization. © 2019 Association for Computing Machinery.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066012156&doi=10.1145%2f3310273.3321560&partnerID=40&md5=f82f46e1227a2748179f7d71d5072443,"ACM International Conference on Computing Frontiers 2019, CF 2019 - Proceedings",41,Include,"I1.2,I1.1",
Azcona D.; Hsiao I.-H.; Arora P.; Smeaton A.,User2Code2vec: Embeddings for profiling students based on distributional representations of source code,"In this work, we propose a new methodology to profile individual students of computer science based on their programming design using a technique called embeddings. We investigate different approaches to analyze user source code submissions in the Python language. We compare the performances of different source code vectorization techniques to predict the correctness of a code submission. In addition, we propose a new mechanism to represent students based on their code submissions for a given set of laboratory tasks on a particular course. This way, we can make deeper recommendations for programming solutions and pathways to support student learning and progression in computer programming modules effectively at a Higher Education Institution. Recent work using Deep Learning tends to work better when more and more data is provided. However, in Learning Analytics, the number of students in a course is an unavoidable limit. Thus we cannot simply generate more data as is done in other domains such as FinTech or Social Network Analysis. Our findings indicate there is a need to learn and develop better mechanisms to extract and learn effective data features from students so as to analyze the students' progression and performance effectively. © 2019 Association for Computing Machinery.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062775545&doi=10.1145%2f3303772.3303813&partnerID=40&md5=57afdeb344c75f39f57c3e0cf6dd2c24,ACM International Conference Proceeding Series,42,Include,,
Xia X.; Lo D.; Wang X.; Zhou B.,Build system analysis with link prediction,"Compilation is an important step in building working software system. To compile large systems, typically build systems, such as make, are used. In this paper, we investigate a new research problem for build configuration file (e.g., Makefile) analysis: how to predict missed dependencies in a build configuration file. We refer to this problem as dependency mining. Based on a Makefile, we build a dependency graph capturing various relationships defined in the Makefile. By representing a Makefile as a dependency graph, we map the dependency mining problem to a link prediction problem, and leverage 9 state-of-the-art link prediction algorithms to solve it. We collected Makefiles from 7 open source projects to evaluate the effectiveness of the algorithms. Copyright 2014 ACM.",Conference paper,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905650920&doi=10.1145%2f2554850.2555134&partnerID=40&md5=05ed5d20675511553cdb8c6e229847e7,Proceedings of the ACM Symposium on Applied Computing,43,Exclude,E1.1,"Bit of an edge case, but it's not really machine learning I think?"
Czech M.; Hüllermeier E.; Jakobs M.-C.; Wehrheim H.,Predicting rankings of software verification tools,"Today, software verification tools have reached the maturity to be used for large scale programs. Different tools perform differently well on varying code. A software developer is hence faced with the problem of choosing a tool appropriate for her program at hand. A ranking of tools on programs could facilitate the choice. Such rankings can, however, so far only be obtained by running all considered tools on the program. In this paper, we present a machine learning approach to predicting rankings of tools on programs. The method builds upon so-called label ranking algorithms, which we complement with appropriate kernels providing a similarity measure for programs. Our kernels employ a graph representation for software source code that mixes elements of control flow and program dependence graphs with abstract syntax trees. Using data sets from the software verification competition SV-COMP, we demonstrate our rank prediction technique to generalize well and achieve a rather high predictive accuracy (rank correlation > 0.6). © 2017 Copyright held by the owner/author(s).",Conference paper,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052882315&doi=10.1145%2f3121257.3121262&partnerID=40&md5=18b8a9acd060494963e86062f6f2ed90,"SWAN 2017 - Proceedings of the 3rd ACM SIGSOFT International Workshop on Software Analytics, Co-located with FSE 2017",44,Exclude,E1.10,
Loyola P.; Matsuo Y.,Learning graph representations for defect prediction,"We propose to study the impact of the representation of the data in defect prediction models. For this study, we focus on the use of developer activity data, from which we structure dependency graphs. Then, instead of manually generating features, such as network metrics, we propose a model inspired in recent advances in Representation Learning which are able to automatically learn representations from graph data. These new representations are compared against manually crafted features for defect prediction in real world software projects. © 2017 IEEE.",Conference paper,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026781427&doi=10.1109%2fICSE-C.2017.68&partnerID=40&md5=5cf4f2e227d3a6f76fe196552721c144,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",45,Exclude,E1.8,
Zhou B.; Xia X.; Lo D.; Wang X.,Build predictor: More accurate missed dependency prediction in build configuration files,"Software build system (e.g., Make) plays an important role in compiling human-readable source code into an executable program. One feature of build system such as make-based system is that it would use a build configuration file (e.g., Make file) to record the dependencies among different target and source code files. However, sometimes important dependencies would be missed in a build configuration file, which would cause additional debugging effort to fix it. In this paper, we propose a novel algorithm named Build Predictor to mine the missed dependncies. We first analyze dependencies in a build configuration file (e.g., Make file), and establish a dependency graph which captures various dependencies in the build configuration file. Next, considering that a build configuration file is constructed based on the source code dependency relationship, we establish a code dependency graph (code graph). Build Predictor is a composite model, which combines both dependency graph and code graph, to achieve a high prediction performance. We collected 7 build configuration files from various open source projects, which are Zlib, putty, vim, Apache Portable Runtime (APR), memcached, nginx, and Tengine, to evaluate the effectiveness of our algorithm. The experiment results show that compared with the state-of-the-art link prediction algorithms used by Xia et al., our Build Predictor achieves the best performance in predicting the missed dependencies. © 2014 IEEE.",Conference paper,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928640876&doi=10.1109%2fCOMPSAC.2014.12&partnerID=40&md5=a3241e7a46466f48c08d33704bc5e9dd,Proceedings - International Computer Software and Applications Conference,46,Exclude,E1.1,Exact same as 43/62
Jin Y.; Bai Y.; Zhu Y.; Sun Y.; Wang W.,Code Recommendation for Open Source Software Developers,"Open Source Software (OSS) is forming the spines of technology infrastructures, attracting millions of talents to contribute. Notably, it is challenging and critical to consider both the developers' interests and the semantic features of the project code to recommend appropriate development tasks to OSS developers. In this paper, we formulate the novel problem of code recommendation, whose purpose is to predict the future contribution behaviors of developers given their interaction history, the semantic features of source code, and the hierarchical file structures of projects. We introduce CODER, a novel graph-based CODE Recommendation framework for open source software developers, which accounts for the complex interactions among multiple parties within the system. CODER jointly models microscopic user-code interactions and macroscopic user-project interactions via a heterogeneous graph and further bridges the two levels of information through aggregation on file-structure graphs that reflect the project hierarchy. Moreover, to overcome the lack of reliable benchmarks, we construct three large-scale datasets to facilitate future research in this direction. Extensive experiments show that our CODER framework achieves superior performance under various experimental settings, including intra-project, cross-project, and cold-start recommendation. © 2023 Owner/Author.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159264141&doi=10.1145%2f3543507.3583503&partnerID=40&md5=32b2da1f0f6ea3e64ea2d6f6b9e24913,"ACM Web Conference 2023 - Proceedings of the World Wide Web Conference, WWW 2023",47,Include,"I1.1,I1.2",
Ye Z.; Feng Z.; Xiao J.; Gao Y.; Fan G.; Zhang H.; Chen S.,Heterogeneous Graph Neural Network-Based Software Developer Recommendation,"In software maintenance, it is critical for project managers to assign software issues to the appropriate developers. However, finding suitable developers is challenging due to the general sparsity and the long-tail of developer-issue interactions. In this paper, we propose a novel Heterogeneous Graph Neural Network-based method for Developer Recommendation (called HGDR), in which text information embedding and self-supervised learning (SSL) are incorporated. Specifically, to alleviate the sparsity of developer-issue interactions, we unify developer-issue interactions, developer-source code file interactions and issue-source code file relations into a heterogeneous graph, and we embed text descriptions to graph nodes as information supplements. In addition, to mitigate the long-tail influence, e.g., recommendation bias, the proficiency weight suppression link supplementation is proposed to complement the tail developers by adjusting proficiency weights. Finally, to fully utilize rich structural information of heterogeneous graph, we use the joint learning of metapath-guided heterogeneous graph neural network and SSL to learn the embedding representation. Extensive comparison experiments on three real-world datasets show that HGDR outperforms the state-of-the-art methods by 6.02% to 44.27% on recommended metric. The experimental results also demonstrate the efficacy of HGDR in the sparse and long-tail scenario. Our code is available at https://github.com/1qweasdzxc/HGDR. © 2022, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149873121&doi=10.1007%2f978-3-031-24383-7_24&partnerID=40&md5=ecf48c7bba6e98f18bb9a9e0c0705a55,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",48,Include,,
Yerramreddy S.; Mordahl A.; Koc U.; Wei S.; Foster J.S.; Carpuat M.; Porter A.A.,An empirical assessment of machine learning approaches for triaging reports of static analysis tools,"Despite their ability to detect critical bugs in software, static analysis tools’ high false positive rates are a key barrier to their adoption in real-world settings. To improve the usability of these tools, researchers have recently begun to apply machine learning techniques to classify and filter incorrect analysis reports. Although initial results have been promising, the long-term potential and best practices for this line of research are unclear due to the lack of detailed, large-scale empirical evaluation. To partially address this knowledge gap, we present a comparative empirical study of three machine learning techniques—traditional models, recurrent neural networks (RNNs), and graph neural networks (GNNs)—for classifying correct and incorrect results in three static analysis tools—FindSecBugs, CBMC, and JBMC—using multiple datasets. These tools represent different techniques of static analysis, namely taint analysis and model-checking. We also introduce and evaluate new data preparation routines for RNNs and node representations for GNNs. We find that overall classification accuracy reaches a high of 80%–99% for different datasets and application scenarios. We observe that data preparation routines have a positive impact on classification accuracy, with an improvement of up to 5% for RNNs and 16% for GNNs. Overall, our results suggest that neural networks (RNNs or GNNs) that learn over a program’s source code outperform traditional models, although interesting tradeoffs are present among all techniques. Our observations provide insight into the future research needed to speed the adoption of machine learning approaches for static analysis tools in practice. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146111753&doi=10.1007%2fs10664-022-10253-z&partnerID=40&md5=aca50e2d5282663af0b1c5a20fba98c0,Empirical Software Engineering,49,Include,I1.1,"Also regular GGNN, aside from lineairsation"
Tommasel A.; Diaz-Pace J.A.,Identifying emerging smells in software designs based on predicting package dependencies,"Software systems naturally evolve, and this evolution often brings design problems that contribute to system degradation. Architectural smells are typical symptoms of such problems, and several of these smells are related to undesired dependencies among packages. The early detection of smells is essential for software engineers to plan ahead for maintenance or refactoring efforts. Although tools for identifying smells exist, they detect the smells once they already exist in the source code when their undesired dependencies are already created. In this work, we explore a forward-looking approach for identifying smells that can emerge in the next system version based on inferring package dependencies that are likely to appear in the system. Our approach takes the current design structure of the system as a network, along with information from previous versions, and applies link prediction techniques from the field of social network analysis. In particular, we consider a group of smells known as instability smells (cyclic dependency, hub-like dependency, and unstable dependency), which fit well with the link prediction model. The approach includes a feedback mechanism to progressively reduce false positives in predictions. An evaluation based on six open-source projects showed that, under certain considerations, the proposed approach can satisfactorily predict missing dependencies and smell configurations thereof. The feedback mechanism led to improvements of up to three times the initial precision values. Furthermore, we have developed a tool for practitioners to apply the approach in their projects. © 2022 Elsevier Ltd",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135130833&doi=10.1016%2fj.engappai.2022.105209&partnerID=40&md5=dfeac6767cd0654f1ee0925e2fe7c8ef,Engineering Applications of Artificial Intelligence,50,Include,I1.1,
Li Y.,Improving Bug Detection and Fixing via Code Representation Learning,"The software quality and reliability have been proved to be important during the program development. There are many existing studies trying to help improve it on bug detection and automated program repair processes. However, each of them has its own limitation and the overall performance still have some improvement space. In this paper, we proposed a deep learning framework to improve the software quality and reliability on these two detectfix processes. We used advanced code modeling and AI models to have some improvements on the state-of-the-art approaches. The evaluation results show that our approach can have a relative improvement up to 206% in terms of F-1 score when comparing with baselines on bug detection and can have a relative improvement up to 19.8 times on the correct bug-fixing amount when comparing with baselines on automated program repair. These results can prove that our framework can have an outstanding performance on improving software quality and reliability in bug detection and automated program repair processes.  © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098558215&doi=10.1145%2f3377812.3382172&partnerID=40&md5=65b8a72829424d72c849d3f3da912067,"Proceedings - 2020 ACM/IEEE 42nd International Conference on Software Engineering: Companion, ICSE-Companion 2020",51,Exclude,E1.10,
Koc U.; Wei S.; Foster J.S.; Carpuat M.; Porter A.A.,An empirical assessment of machine learning approaches for triaging reports of a Java static analysis tool,"Despite their ability to detect critical bugs in software, developers consider high false positive rates to be a key barrier to using static analysis tools in practice. To improve the usability of these tools, researchers have recently begun to apply machine learning techniques to classify and filter false positive analysis reports. Although initial results have been promising, the long-term potential and best practices for this line of research are unclear due to the lack of detailed, large-scale empirical evaluation. To partially address this knowledge gap, we present a comparative empirical study of four machine learning techniques, namely hand-engineered features, bag of words, recurrent neural networks, and graph neural networks, for classifying false positives, using multiple ground-truth program sets. We also introduce and evaluate new data preparation routines for recurrent neural networks and node representations for graph neural networks, and show that these routines can have a substantial positive impact on classification accuracy. Overall, our results suggest that recurrent neural networks (which learn over a program's source code) outperform the other subject techniques, although interesting tradeoffs are present among all techniques. Our observations provide insight into the future research needed to speed the adoption of machine learning approaches in practice. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067964497&doi=10.1109%2fICST.2019.00036&partnerID=40&md5=4a03f036f9e8002482aee7dfc82d5482,"Proceedings - 2019 IEEE 12th International Conference on Software Testing, Verification and Validation, ICST 2019",52,Exclude,E1.10,Can this truely be considered a duplicate (earlier version) of paper 49?
Li Y.; Wang S.; Nguyen T.N.; Van Nguyen S.,Improving bug detection via context-based code representation learning and attention-based neural networks,"Bug detection has been shown to be an effective way to help developers in detecting bugs early, thus, saving much effort and time in software development process. Recently, deep learning-based bug detection approaches have gained successes over the traditional machine learning-based approaches, the rule-based program analysis approaches, and mining-based approaches. However, they are still limited in detecting bugs that involve multiple methods and suffer high rate of false positives. In this paper, we propose a combination approach with the use of contexts and attention neural network to overcome those limitations. We propose to use as the global context the Program Dependence Graph (PDG) and Data Flow Graph (DFG) to connect the method under investigation with the other relevant methods that might contribute to the buggy code. The global context is complemented by the local context extracted from the path on the AST built from the method's body. The use of PDG and DFG enables our model to reduce the false positive rate, while to complement for the potential reduction in recall, we make use of the attention neural network mechanism to put more weights on the buggy paths in the source code. That is, the paths that are similar to the buggy paths will be ranked higher, thus, improving the recall of our model. We have conducted several experiments to evaluate our approach on a very large dataset with +4.973M methods in 92 different project versions. The results show that our tool can have a relative improvement up to 160% on F-score when comparing with the state-of-the-art bug detection approaches. Our tool can detect 48 true bugs in the list of top 100 reported bugs, which is 24 more true bugs when comparing with the baseline approaches. We also reported that our representation is better suitable for bug detection and relatively improves over the other representations up to 206% in accuracy. © 2019 Association for Computing Machinery. All rights reserved.",Article,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120130347&doi=10.1145%2f3360588&partnerID=40&md5=c59c9874585380c66a93a3079e51cc7d,Proceedings of the ACM on Programming Languages,53,Include,,Very close to being a linearised AST 
Diaz-Pace J.A.; Tommasel A.; Godoy D.,Towards anticipation of architectural smells using link prediction techniques,"Software systems naturally evolve, and this evolution often brings design problems that cause system degradation. Architectural smells are typical symptoms of such problems, and several of these smells are related to undesired dependencies among modules. The early detection of these smells is important for developers, because they can plan ahead for maintenance or refactoring efforts, thus preventing system degradation. Existing tools for identifying architectural smells can detect the smells once they exist in the source code. This means that their undesired dependencies are already created. In this work, we explore a forward-looking approach that is able to infer groups of likely module dependencies that can anticipate architectural smells in a future system version. Our approach considers the current module structure as a network, along with information from previous versions, and applies link prediction techniques (from the field of social network analysis). In particular, we focus on dependency-related smells, such as Cyclic Dependency and Hub-like Dependency, which fit well with the link prediction model. An initial evaluation with two open-source projects shows that, under certain considerations, the predictions of our approach are satisfactory. Furthermore, the approach can be extended to other types of dependency-based smells or metrics. © 2018 IEEE.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058275146&doi=10.1109%2fSCAM.2018.00015&partnerID=40&md5=735f0c987e0c433b10f67a72f9f2a97b,"Proceedings - 18th IEEE International Working Conference on Source Code Analysis and Manipulation, SCAM 2018",54,Exclude,E1.10,Double check; can this be considered an earlier version of paper 50
Hadj-Kacem M.; Bouassida N.,Deep Representation Learning for Code Smells Detection using Variational Auto-Encoder,"Detecting code smells is an important research problem in the software maintenance. It assists the subsequent steps of the refactoring process so as to improve the quality of the software system. However, most of existing approaches have been limited to the use of structural information. There have been few researches to detect code smells using semantic information although its proven effectiveness in many software engineering problems. In addition, they do not capture entirely the semantic embedded in the source code. This paper attempts to fill this gap by proposing a semantic-based approach that detects bad smells which are scattered at different levels of granularity in the source code. To this end, we use an Abstract Syntax Tree with a Variational Auto-Encoder in the detection of three code smells. The code smells are Blob, Feature Envy and Long Method. We have performed our experimental evaluation on nine open-source projects and the results have achieved a considerable overall accuracy. To further evaluate the performance of our approach, we compare our results with a state-of-the-art method on the same publicly available dataset. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073195905&doi=10.1109%2fIJCNN.2019.8851854&partnerID=40&md5=2eaf6624f11a6ef208211dabcb36df5f,Proceedings of the International Joint Conference on Neural Networks,55,Include,I1.1,
Wu B.; Liu S.; Xiao Y.; Li Z.; Sun J.; Lin S.-W.,Learning Program Semantics for Vulnerability Detection via Vulnerability-Specific Inter-procedural Slicing,"Learning-based approaches that learn code representations for software vulnerability detection have been proven to produce inspiring results. However, they still fail to capture complete and precise vulnerability semantics for code representations. To address the limitations, in this work, we propose a learning-based approach namely SnapVuln, which first utilizes multiple vulnerability-specific inter-procedural slicing algorithms to capture vulnerability semantics of various types and then employs a Gated Graph Neural Network (GGNN) with an attention mechanism to learn vulnerability semantics. We compare SnapVuln with state-of-the-art learning-based approaches on two public datasets, and confirm that SnapVuln outperforms them. We further perform an ablation study and demonstrate that the completeness and precision of vulnerability semantics captured by SnapVuln contribute to the performance improvement. © 2023 Owner/Author.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180555589&doi=10.1145%2f3611643.3616351&partnerID=40&md5=692aaffa5f587038352bbcc822a1a86b,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,56,Include,I1.1,
Hao J.; Luo S.; Pan L.,A novel vulnerability severity assessment method for source code based on a graph neural network,"Context: Vulnerability severity assessment is an important part of vulnerability management that can help security personnel determine the priority of vulnerability repair work. Objective: Aiming at the problems of low evaluation efficiency and poor timeliness in the existing method, a vulnerability severity evaluation method combining a function call graph and vulnerability attribute graph is proposed. Method: This method constructs a function call graph centered on vulnerable functions and uses the call relationship between vulnerable functions and sensitive API functions to reflect the severity of the damage of the vulnerable functions. The graph attention neural network algorithm is used to mine the key vulnerability characteristics in the function call graph and the vulnerability attribute graph to realize the assessment of vulnerability severity. Results: The ablation experiment results showed that the combined vulnerability attribute graph and function call graph had higher evaluation accuracy than the vulnerability attribute graph or function call graph alone, which increased by 6.85% and 32.90%, respectively. Compared with other existing methods, our method has achieved a better evaluation effect, and the evaluation accuracy has increased by 10%. Conclusion: The vulnerability severity assessment method incorporating function call graphs and vulnerability property graphs demonstrates an enhancement in the ability to represent the severity of vulnerabilities and increases the efficiency of vulnerability severity evaluation through elimination of the requirement for manual analysis. © 2023",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159789401&doi=10.1016%2fj.infsof.2023.107247&partnerID=40&md5=595dd25f95f5a584f70f056f531a35a0,Information and Software Technology,57,Include,I1.1,There are some things with regards to the features which are unclear
Tang G.; Yang L.; Zhang L.; Cao W.; Meng L.; He H.; Kuang H.; Yang F.; Wang H.,An attention-based automatic vulnerability detection approach with GGNN,"Vulnerability detection has long been an important issue in software security. The existing methods mainly define the rules and features of vulnerabilities through experts, which are time-consuming and laborious, and usually with poor accuracy. Thus automatic vulnerability detection methods based on code representation graph and Graph Neural Network (GNN) have been proposed with the advantage of effectively capture both the semantics and structure information of the source code, showing a better performance. However, these methods ignore the redundant information in the graph and the GNN model, leading to a still unsatisfactory performance. To alleviate this problem, we propose a attention-based automatic vulnerability detection approach with Gated Graph Sequence Neural Network (GGNN). Firstly, we introduce two preprocessing methods namely pruning and symbolization representation to reduce the redundant information of the input code representation graph, and then put the graph into the GGNN layer to update the node features. Next, the key subgraph extraction and global feature aggregation are realized through the attention-based Pooling layers. Finally, the classification result is obtained through a linear classifier. The experimental results show the effectiveness of our proposed preprocessing methods and attention-based Pooling layers, especially the higher Accuracy and F1-score gains compared with the state-of-the-art automatic vulnerability detection approaches. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152895909&doi=10.1007%2fs13042-023-01824-7&partnerID=40&md5=addd333bf03eebcb80f6b62c16ad9400,International Journal of Machine Learning and Cybernetics,58,Include,I1.1,
Zhang C.; Yu T.; Liu B.; Xin Y.,Vulnerability detection based on federated learning,"Context: Detecting potential vulnerabilities is a key step in defending against network attacks. However, manual detection is time-consuming and requires expertise. Therefore, vulnerability detection must require automated techniques. Objective: Vulnerability detection methods based on deep learning need to rely on sufficient vulnerable code samples. However, the problem of code islands has not been extensively researched. For example, in the case of multi-party vulnerability data, how to securely combine multi-party data to improve vulnerability detection performance. From the perspectives of data augmentation and data security, we propose a vulnerability detection framework based on federated learning (VDBFL). VDBFL is a new model for vulnerability code detection that combines multi-party data. Method: Firstly, VDBFL utilizes the code property graph as a code representation. The code property graph contains various semantic dependencies of the code. Secondly, VDBFL utilizes graph neural networks and convolutional neural networks as the code feature extractor. VDBFL utilizes the jump-structured graph attention network to aggregate node information of important neighbors. Finally, VDBFL utilizes horizontal federated learning to train a local vulnerability detection model for the client. Result: In the real world, VDBFL improves F1-Score by 37.4% compared to the vulnerability detection method Reveal. Among the 5401 vulnerability samples, VDBFL detected 11.8 times more vulnerabilities than Reveal. Conclusion: Under different datasets, VDBFL has shown better performance than advanced vulnerability detection methods in multiple metrics. In addition, the federated learning stage of VDBFL can be expanded on top of the feature extraction stage of any vulnerable detection method. © 2023",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178012067&doi=10.1016%2fj.infsof.2023.107371&partnerID=40&md5=a4a4d156a7de399955acc40c2eb449b6,Information and Software Technology,59,Include,I1.1,
Tang M.; Tang W.; Gui Q.; Hu J.; Zhao M.,A vulnerability detection algorithm based on residual graph attention networks for source code imbalance (RGAN),"It is essential to detect potential vulnerabilities in software to ensure its safety. As software systems become more complex, traditional static vulnerability detection methods perform poorly. Currently, deep learning-based vulnerability detection models only extract source code vulnerability features using sequences or graphs. Sequential neural networks ignore structural information in the code, such as control flow diagrams and data flow diagrams. Additionally, graph neural networks cannot accurately extract features due to the lack of effective methods for extracting nodes’ features and aggregating global information. To address the above issue, we propose a vulnerability detection algorithm based on residual graph attention networks for source code imbalance (RGAN). Firstly, a local feature extraction module (PE-BL-A module) is designed. Using the sequence neural network, the module extracts various useful features, including node features in a control flow diagram based on local semantic features. Secondly, we present the Residual Graph Attention Network module (RGAT). To learn and update node features along the control flow direction, the module uses a graph attention network with residual connections. In this module, a mean biaffine attention pooling mechanism is proposed that can extract total graph vulnerability features more effectively. Thirdly, a dynamic cross-entropy loss function is designed. Using this function, it can handle sample imbalances during training. Finally, experiments conducted on several benchmark datasets demonstrate that the proposed model achieves state-of-the-art results. © 2023",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174739465&doi=10.1016%2fj.eswa.2023.122216&partnerID=40&md5=94e2526ac216a9a47dc35d30db8111a8,Expert Systems with Applications,60,Include,I1.1,
Fan Y.; Wan C.; Fu C.; Han L.; Xu H.,VDoTR: Vulnerability detection based on tensor representation of comprehensive code graphs,"Code vulnerability detection has long been a critical issue due to its potential threat to computer systems. It is imperative to detect source code vulnerabilities in software and remediate them to avoid cyber attacks. To automate detection and reduce labor costs, many deep learning-based methods have been proposed. However, these approaches have been found to be either ineffective in detecting multiple classes of vulnerabilities or limited by treating original source code as a natural language sequence without exploiting the structural information of code. In this paper, we propose VDoTR, a model that leverages a new tensor representation of comprehensive code graphs, including AST, CFG, DFG, and NCS, to detect multiple types of vulnerabilities. Firstly, a tensor structure is introduced to represent the structured information of code, which deeply captures code features. Secondly, a new Circle Gated Graph Neural Network (CircleGGNN) is designed based on tensor for hidden state embedding of nodes. CircleGGNN can perform heterogeneous graph information fusion more directly and effectively. Lastly, a 1-D convolution-based output layer is applied to hidden embedding features for classification. The experimental results demonstrate that the detection performance of VDoTR is superior to other approaches with higher accuracy, precision, recall, and F1-measure on multiple datasets for vulnerability detection. Moreover, we illustrate which code graph contributes the most to the performance of VDoTR and which code graph is more sensitive to represent vulnerability features for different types of vulnerabilities through ablation experiments. © 2023",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152599286&doi=10.1016%2fj.cose.2023.103247&partnerID=40&md5=b08c018dcb6c1cbaa89c8808b2af2a6c,Computers and Security,61,Include,"I1.1,I1.2",
Sachdeva A.; Lazarine B.; Zhu H.; Samtani S.,User Profiling and Vulnerability Introduction Prediction in Social Coding Repositories: A Dynamic Graph Embedding Approach: Vulnerability Introduction Prediction in Social Coding Repositories,"Social Coding Repositories (SCRs) such as GitHub host open-source code that is significant to the global economy. However, open-source code is especially vulnerable, with most vulnerabilities being introduced due to human error. An important mitigation strategy is preventing the introduction of vulnerabilities. One of the ways this can be achieved is through targeted developer security training, which necessitates the identification of high-risk actors and predicting the introduction of vulnerabilities. In this study, we propose a novel framework for predicting the introduction of vulnerabilities in SCRs by users, with a novel dynamic graph representation learning model, security continuous propagation, and evolution (seCoPE). The proposed seCoPE framework addresses the limitations of existing methods by incorporating the relative influence of nodes on the propagation of information to generate high-quality nodal embeddings. We systematically evaluate seCoPE against prevailing Recurrent Neural Network (RNN) based and Attention-based models on a vulnerability introduction dataset. The proposed framework has important implications for cybersecurity providers, firms, and software developers.  © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171448656&doi=10.1145%2f3607505.3607512&partnerID=40&md5=5e5eed1da91608cfff8e39fbf2bbaef2,ACM International Conference Proceeding Series,62,Include,"I1.1,I1.2",
Wang S.; Huang C.; Yu D.; Chen X.,VulGraB: Graph-embedding-based code vulnerability detection with bi-directional gated graph neural network,"Code vulnerabilities can have serious consequences such as system attacks and data leakage, making it crucial to perform code vulnerability detection during the software development phase. Deep learning is an emerging approach for vulnerability detection tasks. Existing deep learning-based code vulnerability detection methods are usually based on word2vec embedding of linear sequences of source code, followed by code vulnerability detection through RNNs network. However, such methods can only capture the superficial structural or syntactic information of the source code text, which is not suitable for modeling the complex control flow and data flow and miss edge information in the graph structure constructed by the source code, with limited effect of neural network model. To solve the above problems, this article proposes a code vulnerability detection method, named VulGraB, which is based on graph embedding and bidirectional gated graph neural networks. VulGraB uses node2vec to convert the program-dependent graphs into graph embeddings of the code, which contain rich structure information of the source code, improving the ability of features to express nonlinear information to a certain extent. Then the BiGGNN is used for training, and finally the accuracy of the detection results is evaluated using target program. The bi-directional gated neural network utilizes a bi-directional recurrent structure, which is beneficial to global information aggregation. The experimental results show that the accuracy of VulGraB is significantly improved over the baseline models on two datasets, with F1 scores of 85.89% and 97.24% being the highest, demonstrating that VulGraB consistently outperforms other effective vulnerability detection models. © 2023 John Wiley & Sons Ltd.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152473653&doi=10.1002%2fspe.3205&partnerID=40&md5=d2796319b2e3f7249116999d618965af,Software - Practice and Experience,63,Include,I1.1,
Yang Y.; Bo X.; Wang Z.; Shao X.; Xie X.,Graph representation learning and software homology matching based A study of JAVA code vulnerability detection techniques,"In nowadays using different tools and apps is a basic need of people's behavior in life, but the security issues arising from the existence of source code plagiarism among tools and apps are likely to bring huge losses to companies and even countries, so detecting the existence of vulnerabilities or malicious code in software becomes an important part of protecting information and detecting software security. This project is based on the aspect of JAVA code vulnerability detection based on graph representation learning and software homology comparison to carry out research. This project will be based on the content of deep learning, using a large number of vulnerable source code, extracting its features, and transforming it into a graph so that it can be tested source code for comparison and report the vulnerability content. The main work and results of this project are as follows: 1.By extracting the example dataset and generating json files to save the feature information of relevant java code; by generating vector files, bytecode files and dot files, and batch extracting nodes and edges based on the contents of the dot files for subsequent machine learning use, the before and after steps and operations form a logical self-consistency to ensure the integrity of the project. 2.Through the study of graph neural networks and graph convolutional neural networks, relevant models are selected for machine learning using predecessor files and manual model tuning is performed to ensure good learning results and feedback for the machine learning part of the project. 3.This project training dataset negative samples for sard above the shared dataset, which contains 46636 java vulnerability source code, and dataset support environment, test dataset negative samples dataset also from sard, positive samples dataset are generated from the relevant person in charge. 4.Based on Graph Neural Network (GNN) and Graph Convolutional Neural Network (GCN), this project will design and implement a whole set of automated vulnerability detection system for java code. 5. All the related contents of this project, after the human extensive search of domestic and foreign related papers and materials, there are not all projects or contents similar to this project, the same papers and materials appear, all the problems involved in this project and related ideas are for the project this group of people thinking, looking for solutions.  © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162926361&doi=10.1145%2f3590003.3590028&partnerID=40&md5=fe0ccfba626f94562c12fb8a65ecc1ad,ACM International Conference Proceeding Series,64,Exclude,E2.6,
Şahin C.B.,Semantic-based vulnerability detection by functional connectivity of gated graph sequence neural networks,"In computer security, semantic learning is helpful in understanding vulnerability requirements, realizing source code semantics, and constructing vulnerability knowledge. Nevertheless, learning how to extract and select the most valuable features for software vulnerability detection remains difficult. In this paper, we first derive a subset of vulnerability knowledge representations from the Functional Connectivity (FC) of Graph Gated Sequence Neural Networks (GGNNs). The Gated Graph Sequence Neural Networks can be utilized to capture the long-term dependency to understand a high-level representation of potential vulnerabilities in order to detect vulnerabilities on a target project. Studying functional connectivity-based Graph Neural Networks ensures our deep understanding of the operation of sequence graph networks as highly complex interconnected systems. This ensures that the model focuses on vulnerability-related code, which makes it more appropriate for vulnerability mining tasks. Which constructs a composite semantic code property graph for code representation based on the causes of vulnerabilities. The experimental findings indicate that the suggested Model can select relevant discriminative features and achieve superior performance than benchmark methods. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145500304&doi=10.1007%2fs00500-022-07777-3&partnerID=40&md5=df0914786b4bd21b14ee00081fc4155e,Soft Computing,65,Exclude,E3.3,Don't quite understand it 
Wang M.; Tao C.; Guo H.,LCVD: Loop-oriented code vulnerability detection via graph neural network,"Due to the unique mechanism and complex structure, loops in programs can easily lead to various vulnerabilities such as dead loops, memory leaks, resource depletion, etc. Traditional approaches to loop-oriented program analysis (e.g. loop summarization) are costly with a high rate of false positives in complex software systems. To address the issues above, recent works have applied deep learning (DL) techniques to vulnerability detection. However, existing DL-based approaches mainly focused on the general characteristics of most vulnerabilities without considering the semantic information of specific vulnerabilities. As a typical structure in programs, loops are highly iterative with multi-paths. Currently, there is a lack of available approaches to represent loops, as well as useful methods to extract the implicit vulnerability patterns. Therefore, this paper introduces LCVD, an automated loop-oriented code vulnerability detection approach. LCVD represents the source code as the Loop-flow Abstract Syntax Tree (LFAST), which focuses on interleaving multi-paths around loop structures. Then a novel Loop-flow Graph Neural Network (LFGNN) is proposed to learn both the local and overall structure of loop-oriented vulnerabilities. The experimental results demonstrate that LCVD outperforms the three static analysis-based and four state-of-the-art DL-based vulnerability detection approaches across evaluation settings. © 2023 Elsevier Inc.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85157985357&doi=10.1016%2fj.jss.2023.111706&partnerID=40&md5=9d08c9e5a66deffd43cab0392ed9ed3c,Journal of Systems and Software,66,Include,I1.1,
Tang W.; Tang M.; Ban M.; Zhao Z.; Feng M.,CSGVD: A deep learning approach combining sequence and graph embedding for source code vulnerability detection,"In order to secure software, it is critical to detect potential vulnerabilities. The performance of traditional static vulnerability detection methods is limited by predefined rules, which rely heavily on the expertise of developers. Existing deep learning-based vulnerability detection models usually use only a single sequence or graph embedding approach to extract vulnerability features. Sequence embedding-based models ignore the structured information inherent in the code, and graph embedding-based models lack effective node and graph embedding methods. As a result, we propose a novel deep learning-based approach, CSGVD (Combining Sequence and Graph embedding for Vulnerability Detection), which considers function-level vulnerability detection as a graph binary classification task. Firstly, we propose a PE-BL module, which inherits and enhances the knowledge from the pre-trained language model. It extracts the code's local semantic features as node embedding in the control flow graph by using sequence embedding. Secondly, CSGVD uses graph neural networks to extract the structured information of the graph. Finally, we propose a mean biaffine attention pooling, M-BFA, to better aggregate node information as a graph's feature representation. The experimental results show that CSGVD outperforms the existing state-of-the-art models and obtains 64.46% accuracy on the real-world benchmark dataset from CodeXGLUE for vulnerability detection. © 2023 Elsevier Inc.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147191808&doi=10.1016%2fj.jss.2023.111623&partnerID=40&md5=35cd17dd043c1d9487c1e1b02c7a2420,Journal of Systems and Software,67,Include,I1.1,
Nguyen S.; Vu T.T.; Vo H.D.,VFFINDER: A Graph-Based Approach for Automated Silent Vulnerability-Fix Identification,"The increasing reliance of software projects on third-party libraries has raised concerns about the security of these libraries due to hidden vulnerabilities. Managing these vul-nerabilities is challenging due to the time gap between fixes and public disclosures. Moreover, a significant portion of open-source projects silently fix vulnerabilities without disclosure, impacting vulnerability management. Existing tools like OWASP heavily rely on public disclosures, hindering their effectiveness in detecting unknown vulnerabilities. To tackle this problem, automated identification of vulnerability-fixing commits has emerged. However, identifying silent vulnerability fixes remains challenging. This paper presents VFFINDER, a novel graph-based approach for automated silent vulnerability fix identification. VFFINDER captures structural changes using Abstract Syntax Trees (ASTs) and represents them in annotated ASTs. VFFINDER distinguishes vulnerability-fixing commits from non-fixing ones using attention-based graph neural network models to extract structural features. We conducted experiments to evaluate VFFINDER on a dataset of 36K+ fixing and non-fixing commits in 507 real-world C/C++ projects. Our results show that VFFINDER significantly improves the state-of-the-art methods by 39-83% in Precision, 19-148% in Recall, and 30%-109% in F1. Especially, VFFINDER speeds up the silent fix identification process by up to 47% with the same review effort of 5% compared to the existing approaches.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173098270&doi=10.1109%2fKSE59128.2023.10299438&partnerID=40&md5=32132664d3df53b29a7ef7891aaaeca6,"Proceedings - International Conference on Knowledge and Systems Engineering, KSE",68,Include,"I1.1,I1.2",
Yang J.; Ruan O.; Zhang J.,Tensor-based gated graph neural network for automatic vulnerability detection in source code,"The rapid expansion of smart devices leads to the increasing demand for vulnerability detection in the cyber security field. Writing secure source codes is crucial to protect applications and software. Recent vulnerability detection methods are mainly using machine learning and deep learning. However, there are still some challenges, how to learn accurate source code semantic embedding at the function level, how to effectively perform vulnerability detection using the learned semantic embedding of source code and how to solve the overfitting problem of learning-based models. In this paper, we consider codes as various graphs with node features and propose a tensor-based gated graph neural network called TensorGNN to produce code embedding for function-level vulnerability detection. First, we propose a high-dimensional tensor for combining different code graph representations. Second, inspired by the work of tensor technology, we propose the TensorGNN model to produce accurate code representations using the graph tensor. We evaluate our model on 7 C and C++ large open-source code corpus (e.g. SARD&NVD, Debian, SATE IV, FFmpeg, libpng&LibTiff, Wireshark and Github datasets), which contains 13 types of vulnerabilities. Our TensorGNN model improves on existing state-of-the-art works by 10%–30% on average in terms of vulnerability detection accuracy and F1, while our TensorGNN model needs less training time and model parameters. Specifically, compared with other existing works, our model reduces 25–47 times of the number of parameters and decreases 3–10 times of training time. Results of evaluations show that TensorGNN has better performance while using fewer training parameters and less training time. © 2023 John Wiley & Sons, Ltd.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177856805&doi=10.1002%2fstvr.1867&partnerID=40&md5=1a569590b2491578fb19b6dbb6a325d8,Software Testing Verification and Reliability,69,Include,I1.1,
Cheng X.,Vulnerability Detection via Typestate-Guided Code Representation Learning,"Machine learning, including deep learning, has found success in various domains. Recently, the focus has shifted to using deep learning, like graph neural networks, for static vulnerability detection. Existing methods represent code as an embedding vector and train models on safe and vulnerable code patterns to predict vulnerabilities. However, these models lack precise bug detection, as they prioritize coarse-grained classification over understanding vulnerability semantics, such as typestate properties. This paper introduces an innovative typestate-guided code embedding technique for accurate static vulnerability detection. We select and retain feasible typestate sequences extracted from typestate analysis using self-supervised contrastive learning in a pretrained path embedding model. This reduces the need for labeled data in training downstream models for vulnerability detection. Evaluation on real-world projects showcases our approach’s superiority over recent learning-based approaches. It outperforms them by substantial margins across various metrics like precision, recall and F1 Score. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177163808&doi=10.1007%2f978-981-99-7584-6_22&partnerID=40&md5=d29b35db1d99029cafefb87159254b23,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),70,Exclude,E1.1,
Li W.; Li X.; Feng W.; Jin G.; Liu Z.; Jia J.,Vulnerability Detection Based on Unified Code Property Graph,"As the number of source codes grows rapidly, detecting source code vulnerabilities in current software has become an important study. Most current deep learning-based vulnerability detection technologies treat source code as a sequence, which loses the source code’s structural information, leading to many false positives in the detection results. We propose a novel source code vulnerability detection model, named UCPGVul, based on the Unified Code Property Graph (UCPG). A new graph representation, UCPG, is proposed to extract semantic features from the source code. By extracting features from UCPG, our proposed UCPGVul model can capture more vulnerability features. Experimental results on a publicly available dataset show that UCPGVul can achieve more accurate and stable detection results compared to five state-of-the-art methods. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172249628&doi=10.1007%2f978-981-99-6222-8_30&partnerID=40&md5=33ae0e4b5456900bb0974d21eb318e95,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),71,Include,I1.1,
Li X.; Xin Y.; Zhu H.; Yang Y.; Chen Y.,Cross-domain vulnerability detection using graph embedding and domain adaptation,"Vulnerability detection is an effective means to maintain cyberspace security. Machine learning methods have risen much attention in software security due to their advantage of accuracy and automation. However, current researches mainly focus on in-domain vulnerability detection where the training data and test data belong to the same domain. Due to application scenarios, coding habits, and other factors, vulnerabilities in different software projects may obey different probability distributions. This discrepancy compromises the performance of machine learning methods when they are applied to a brand-new project. To address this cold start problem, we propose a cross-domain vulnerability detection framework using graph embedding and deep domain adaption (VulGDA). It works in a variety of cross-domain fashions, including the Zero-Shot fashion that no labeled data in the target domain is available for training. VulGDA is decomposed to graph embedding and domain adaptation. At the graph embedding stage, we transform the samples in source code into graph representations where elements are directly concatenated according to their syntactic and semantic relationships. Then, we aggregate information from neighbors and edges defined in the graph into real-valued vectors. By graph embedding, VulGDA extracts comprehensive vulnerability features and compromises the challenge of long-term dependency. Aiming at the discrepancy between training data and test data, domain adaption is used to train a feature generator. This feature generator maps the graph embedding to a “deep” feature that is discriminative for vulnerability detection, and invariant to the shift between domains. We perform a systematic experiment to validate the effectiveness of VulGDA. The results show that combining graph embedding and deep domain adaptation promotes VulGDA's performance in cross-domain vulnerability detection. Compared with the state-of-the-art methods, our method has better performance under the cold start condition. © 2022",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145617321&doi=10.1016%2fj.cose.2022.103017&partnerID=40&md5=15b2ba79fa4afd2aa82af96a915df12e,Computers and Security,72,Include,I1.1,
Ni C.; Guo X.; Zhu Y.; Xu X.; Yang X.,Function-Level Vulnerability Detection Through Fusing Multi-Modal Knowledge,"Software vulnerabilities damage the functionality of software systems. Recently, many deep learning-based approaches have been proposed to detect vulnerabilities at the function level by using one or a few different modalities (e.g., text representation, graph-based representation) of the function and have achieved promising performance. However, some of these existing studies have not completely leveraged these diverse modalities, particularly the underutilized image modality, and the others using images to represent functions for vulnerability detection have not made adequate use of the significant graph structure underlying the images. In this paper, we propose MVulD, a multi-modal-based function-level vulnerability detection approach, which utilizes multi-modal features of the function (i.e., text representation, graph representation, and image representation) to detect vulnerabilities. Specifically, MVulD utilizes a pre-trained model (i.e., UniXcoder) to learn the semantic information of the textual source code, employs the graph neural network to distill graph-based representation, and makes use of computer vision techniques to obtain the image representation while retaining the graph structure of the function. We conducted a large-scale experiment on 25,816 functions. The experimental results show that MVulD improves four state-of-the-art baselines by 30.8%-81.3%, 12.8%-27.4%, 48.8%-115%, and 22.9%-141% in terms of F1-score, Accuracy, Precision, and PR-AUC respectively.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179002505&doi=10.1109%2fASE56229.2023.00084&partnerID=40&md5=c4ca6b4d197b1c4cef905dbb95bbf33d,"Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023",73,Include,I1.1,
Xue J.; Yu Z.; Song Y.; Qin Z.; Sun X.; Wang W.,VulSAT: Source Code Vulnerability Detection Scheme Based on SAT Structure,"The number of software vulnerabilities have increased rapidly, and their forms have shown the characteristics of complexity and diversity, which has brought severe challenges to software systems. Deep learning can automatically learn the features of code and is widely used in source code vulnerability detection. Some studies treat codes as text sequences, ignoring the structural relationship between lines of code. Other studies extract the code as a graph structure, but ignore the order relationship of code lines and do not make full use of the dependencies between code lines. This paper proposes a C/C++ source code vulnerability detection scheme based on SAT (Structure-Aware Transformer) structure. It first standardizes the source code, then extracts the PDG (program dependency graph) representation of source code, next convert each node into a vector representation using sentence embedding, which retains the dependencies between nodes. Finally input it into the SAT architecture model for training, and judge whether the input program contains vulnerabilities according to the output results. We compared VulSAT with a variety of vulnerability detection methods (i.e., Devign, SySeVR, VulCNN, Checkmarx, VulDeePecker), and selected C/C++ functions in the SARD vulnerability dataset as experimental objects. The performance of accuracy rate and false positive rate has been improved to a certain extent.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174681667&doi=10.1109%2fICSIP57908.2023.10271020&partnerID=40&md5=6303903a0553b7309b1e4efac7d12f2d,"2023 8th International Conference on Signal and Image Processing, ICSIP 2023",74,Include,I1.1,
Li Q.; Guo Z.; Li X.; Chen Q.; Zhou S.; Hu R.; Jiang Y.; Chen H.,Vulnerability Detection Based on Attention Mechanism and Deep Graph Convolutional Network,"To address the problem of incomplete graph structure features due to the lack of contextual information in existing graph neural network-based vulnerability mining methods and the problem of over-smoothing that prevents the model from learning higher-order features of the graph structure resulting in poor prediction performance, a vulnerability detection method based on deep graph convolutional networks and attention mechanism, PSG-GCNIIAT, is proposed. PSG fuses order relational graphs on the basis of program dependency graphs so that code statements have the ability to sense their contextual information, and generates embedding vectors of code lines by abstracting syntax trees to achieve deep structure feature extraction of graph nodes. GCNIIAT uses a deep graph convolutional network, GCNII, combined with a graph attention mechanism to more effectively identify graph structure features of program slices associated with vulnerabilities. The experimental results show that the vulnerability detection model GCNIIAT proposed in this paper has obvious advantages over Vuldeepecker, GCN and GGNN in accuracy and F1 value indicators, and can effectively improve the performance of program vulnerability detection. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175201336&doi=10.1109%2fSCSET58950.2023.00037&partnerID=40&md5=54036ac7d25a07f8ac86a89905b3af33,"Proceedings - 2023 International Seminar on Computer Science and Engineering Technology, SCSET 2023",75,Exclude,E3.3,Missing information about graph. Details about network are unclear
Ganz T.; Imgrund E.; Härterich M.; Rieck K.,CodeGraphSMOTE - Data Augmentation for Vulnerability Discovery,"The automated discovery of vulnerabilities at scale is a crucial area of research in software security. While numerous machine learning models for detecting vulnerabilities are known, recent studies show that their generalizability and transferability heavily depend on the quality of the training data. Due to the scarcity of real vulnerabilities, available datasets are highly imbalanced, making it difficult for deep learning models to learn and generalize effectively. Based on the fact that programs can inherently be represented by graphs and to leverage recent advances in graph neural networks, we propose a novel method to generate synthetic code graphs for data augmentation to enhance vulnerability discovery. Our method includes two significant contributions: a novel approach for generating synthetic code graphs and a graph-to-code transformer to convert code graphs into their code representation. Applying our augmentation strategy to vulnerability discovery models achieves the same originally reported F1-score with less than 20 % of the original dataset and we outperform the F1-score of prior work on augmentation strategies by up to 25.6 % in detection performance. © 2023, IFIP International Federation for Information Processing.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169070482&doi=10.1007%2f978-3-031-37586-6_17&partnerID=40&md5=c330a7e55e690a560e961818f726fea0,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),76,Include,I1.1,
Wang S.; Wang X.; Sun K.; Jajodia S.; Wang H.; Li Q.,GraphSPD: Graph-Based Security Patch Detection with Enriched Code Semantics,"With the increasing popularity of open-source software, embedded vulnerabilities have been widely propagating to downstream software. Due to different maintenance policies, software vendors may silently release security patches without providing sufficient advisories (e.g., CVE). This leaves users unaware of security patches and provides attackers good chances to exploit unpatched vulnerabilities. Thus, detecting those silent security patches becomes imperative for secure software maintenance. In this paper, we propose a graph neural network based security patch detection system named GraphSPD, which represents patches as graphs with richer semantics and utilizes a patch-tailored graph model for detection. We first develop a novel graph structure called PatchCPG to represent software patches by merging two code property graphs (CPGs) for the pre-patch and post-patch source code as well as retaining the context, deleted, and added components for the patch. By applying a slicing technique, we retain the most relevant context and reduce the size of PatchCPG. Then, we develop the first end-to-end deep learning model called PatchGNN to determine if a patch is security-related directly from its graph-structured PatchCPG. PatchGNN includes a new embedding process to convert PatchCPG into a numeric format and a new multi-attributed graph convolution mechanism to adapt diverse relationships in PatchCPG. The experimental results show GraphSPD can significantly outperform the state-of-the-art approaches on security patch detection.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166049487&doi=10.1109%2fSP46215.2023.10179479&partnerID=40&md5=7406fabfa206c6c0509c0e2a440c0d44,Proceedings - IEEE Symposium on Security and Privacy,77,Include,"I1.1,I1.2",
Zhou X.; Pang J.; Zhang C.; Yue F.; Wang J.; Liu G.,TS-GGNN: Combining Graph and Sequence Features for Vulnerability Detection in Source Code,"Software vulnerability detection is crucial for maintaining the security and stability of software systems. In this paper, we propose a novel neural network model called TS-GGNN to address the problem of vulnerability detection in source code slices. The TS-GGNN model effectively captures both local and global features of vulnerable code by fusing sequence features with graph features. To achieve this, we utilize graph structure and sequence structure learning approaches to comprehensively extract valuable information from the source code slices. Our experiments are conducted on the SARD dataset, which consists of 61,638 code samples annotated for the presence or absence of vulnerabilities. The results demonstrate that TS-GGNN has the best vulnerability detection performance, with an accuracy of 99.4%, a precision of 98.81%, and an F1 score as high as 99.4% thereby validating the effectiveness of the TS-GGNN model in capturing features relevant to software vulnerabilities.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163405645&doi=10.1109%2fCISCE58541.2023.10142859&partnerID=40&md5=858b0ff35c1046eeefb38744e97cc35f,"2023 5th International Conference on Communications, Information System and Computer Engineering, CISCE 2023",78,Include,"I1.1,I1.2",
Kraker W.D.; Vranken H.; Hommmersom A.,GLICE: Combining Graph Neural Networks and Program Slicing to Improve Software Vulnerability Detection,"This paper introduces the GLICE (Graph Neural Network with program slice) model for static code analysis to detect vulnerabilities in source code. GLICE combines inter-procedural program slicing with a Graph Neural Network. It builds upon and extends prior work that applies program slicing (as in the SySeVR model) and Graph Neural Networks (as in the FUNDED model) for vulnerability detection. We apply GLICE on a data set of C/C++ code samples with out-of-bounds write (CWE-787) and out-of-bounds read (CWE-125) butter overflow vulnerabilities. We perform experiments with GLICE to evaluate trade-offs in the depth of the inter-procedural analysis, and to compare GLICE with prior models by evaluating the effectiveness for vulnerability detection and the usage of resources. Our experimental results show that detection accuracy of GLICE improves up to 13% when compared to FUNDED, while the time required to train the GLICE model is about 9 times smaller. GLICE allows configuring the depth of the interprocedural analysis. Our experimental results show that increasing the depth will improve detection, which however requires more computing resources. This allows a user of GLICE to steer the trade-off between detection accuracy and computational efficiency.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168239975&doi=10.1109%2fEuroSPW59978.2023.00009&partnerID=40&md5=8defe123556105593a18ef221e5cdfa6,"Proceedings - 8th IEEE European Symposium on Security and Privacy Workshops, Euro S and PW 2023",79,Exclude,E3.2,
Wang J.; Huang M.; Nie Y.; Kuang X.; Li X.; Zhong W.,Fine-Grained Source Code Vulnerability Detection via Graph Neural Networks,"Although the number of exploitable vulnerabilities in software continues to increase, the speed of bug fixes and software updates have not increased accordingly. It is therefore crucial to analyze the source code and identify vulnerabilities in the early phase of software development. However, vulnerability location in most of the current machine learning-based methods tends to concentrate at the function level. It undoubtedly imposes a burden on further manual code audits when faced with large-scale source code projects. In this paper, a fine-grained source code vulnerability detection model based on Graph Neural Networks (GNNs) is proposed with the aim of locating vulnerabilities at the function level and line level. Our empirical evaluation on different C/C++ datasets demonstrated that our proposed model outperforms the state-of-the-art methods and achieves significant improvements even when faced with more complex, real-project source code. © 2023 Knowledge Systems Institute Graduate School. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170065533&doi=10.18293%2fSEKE2023-115&partnerID=40&md5=0394a3677f82786986e04fcdec1fee65,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",80,Include,I1.1,
Zhang H.; Kishi T.,Long Method Detection Using Graph Convolutional Networks,"Long Method is a code smell that frequently happens in software development, which refers to the com-plex method with multiple functions. Detecting and refactoring such problems has been a popular topic in software refactoring, and many detection approaches have been proposed. In past years, the approaches based on metrics or rules have been the leading way in long method detection. However, the approach based on deep learning has also attracted extensive attention in recent studies. In this paper, we propose a graph-based deep learning approach to de-tect Long Method. The key point of our approach is that we extended the PDG (Program Dependency Graph) into a Directed-Heterogeneous Graph as the input graph and used the GCN (Graph Convolutional Network) to build a graph neural network for Long Method detection. Moreover, to get substantial data samples for the deep learning task, we propose a novel semi-automatic approach to generate a large number of data samples. Finally, to prove the validity of our approach, we compared our approach with the existing approaches based on five groups of datasets manually reviewed. The evaluation result shows that our approach achieved a good performance in Long Method detection. © 2023, Information Processing Society of Japan. All rights reserved.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169480537&doi=10.2197%2fipsjjip.31.469&partnerID=40&md5=64c615bceca1579d612103656725e595,Journal of Information Processing,81,Include,"I1.1,I1.2",
Guo W.; Fang Y.; Huang C.; Ou H.; Lin C.; Guo Y.,HyVulDect: A hybrid semantic vulnerability mining system based on graph neural network,"In recent years, software programs tend to be large and complex, software has become the infrastructure of modern society, but software security issues can not be ignored. software vulnerabilities have become one of the main threats to computer security. There are countless cases of exploiting source code vulnerabilities to launch attacks. At the same time, the development of open source software has made source code vulnerability detection more and more critical. Traditional vulnerability mining methods have been unable to meet the security analysis needs of complex software because of the high false-positive rate and false-negative rate. To resolve the existing problems, we propose a graph neural network vulnerability mining system named HyVulDect based on hybrid semantics, which constructs a composite semantic code property graph for code representation based on the causes of vulnerabilities. A gated graph neural network is used to extract deep semantic information. Since most of the vulnerabilities are data flow associated, we use taint analysis to extract the taint propagation chain, use the BiLSTM model to extract the token-level features of the context, and finally use the classifier to classify the fusion features. We introduce a dual-attention mechanism that allows the model to focus on vulnerability-related code, making it more suitable for vulnerability mining tasks. The experimental results show that HyVulDect outperforms existing state-of-the-art methods and can achieve an accuracy rate of 92% on the benchmark dataset. Compared with the rule-based static mining tools Flawfinder, RATS, and Cppcheck, it has better performance and can effectively detect the actual CVE source code vulnerabilities. © 2022 Elsevier Ltd",Review,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134880709&doi=10.1016%2fj.cose.2022.102823&partnerID=40&md5=7c0d39840ad714fb2d4762a2437aa558,Computers and Security,82,Include,"I1.1,I1.2",Not entirely sure about model and tasks
Luo Y.; Xu W.; Xu D.,Compact Abstract Graphs for Detecting Code Vulnerability with GNN Models,"Source code representation is critical to the machine-learning-based approach to detecting code vulnerability. This paper proposes Compact Abstract Graphs (CAGs) of source code in different programming languages for predicting a broad range of code vulnerabilities with Graph Neural Network (GNN) models. CAGs make the source code representation aligned with the task of vulnerability classification and reduce the graph size to accelerate model training with minimum impact on the prediction performance. We have applied CAGs to six GNN models and large Java/C datasets with 114 vulnerability types in Java programs and 106 vulnerability types in C programs. The experiment results show that the GNN models have performed well, with accuracy ranging from 94.7% to 96.3% on the Java dataset and from 91.6% to 93.2% on the C dataset. The resultant GNN models have achieved promising performance when applied to more than 2,500 vulnerabilities collected from real-world software projects. The results also show that using CAGs for GNN models is significantly better than ASTs, CFGs (Control Flow Graphs), and PDGs (Program Dependence Graphs). A comparative study has demonstrated that the CAG-based GNN models can outperform the existing methods for machine learning-based vulnerability detection.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144086642&doi=10.1145%2f3564625.3564655&partnerID=40&md5=a8df527c9c6a10e7f895ff4800eb4fc9,ACM International Conference Proceeding Series,83,Include,"I1.1,I1.2",
Liu Z.; Fang Y.; Huang C.; Xu Y.,MFXSS: An effective XSS vulnerability detection method in JavaScript based on multi-feature model,"The widespread use of web applications has also made them more vulnerable to hackers, resulting in the leakage of large amounts of application and personal privacy data. Cross-site scripting (XSS) attacks are one of the most significant threats to web applications. Attackers can inject scripts to control the victim's browser to send data or execute commands, leading to the theft of privacy or the hijacking of login tokens. Therefore, we proposed a multi-feature fusion-based neural network vulnerability detection model for detecting XSS vulnerabilities in the JavaScript source code of websites (We termed our implementation of this approach MFXSS). We combine abstract syntax tree (AST) and code control flow graph (CFG) to convert the generalized sample data into graph structure and code string structure. Then, through the graph convolutional neural network, weighted aggregation, and the bidirectional recurrent neural network, the logical call features and the context execution relationship features of the source code are extracted and fused respectively. Finally, the fused feature vectors are used to detect and predict XSS vulnerabilities in JavaScript. In the experiment, we designed multiple control experiments to verify that the model construction is optimal, and the accuracy rates in the standard and variant datasets are 0.997 and 0.986. Moreover, in comparing similar detection schemes, MFXSS also performs better. Applying the model to an actual web environment, we successfully detected the presence of XSS vulnerabilities in websites. © 2022 Elsevier Ltd",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142136187&doi=10.1016%2fj.cose.2022.103015&partnerID=40&md5=eb1a928fab60b2f8770f3043b3edb47f,Computers and Security,84,Include,I1.1,
Cheng X.; Zhang G.; Wang H.; Sui Y.,Path-sensitive code embedding via contrastive learning for software vulnerability detection,"Machine learning and its promising branch deep learning have shown success in a wide range of application domains. Recently, much effort has been expended on applying deep learning techniques (e.g., graph neural networks) to static vulnerability detection as an alternative to conventional bug detection methods. To obtain the structural information of code, current learning approaches typically abstract a program in the form of graphs (e.g., data-flow graphs, abstract syntax trees), and then train an underlying classification model based on the (sub)graphs of safe and vulnerable code fragments for vulnerability prediction. However, these models are still insufficient for precise bug detection, because the objective of these models is to produce classification results rather than comprehending the semantics of vulnerabilities, e.g., pinpoint bug triggering paths, which are essential for static bug detection. This paper presents ContraFlow, a selective yet precise contrastive value-flow embedding approach to statically detect software vulnerabilities. The novelty of ContraFlow lies in selecting and preserving feasible value-flow (aka program dependence) paths through a pretrained path embedding model using self-supervised contrastive learning, thus significantly reducing the amount of labeled data required for training expensive downstream models for path-based vulnerability detection. We evaluated ContraFlow using 288 real-world projects by comparing eight recent learning-based approaches. ContraFlow outperforms these eight baselines by up to 334.1%, 317.9%, 58.3% for informedness, markedness and F1 Score, and achieves up to 450.0%, 192.3%, 450.0% improvement for mean statement recall, mean statement precision and mean IoU respectively in terms of locating buggy statements.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136799873&doi=10.1145%2f3533767.3534371&partnerID=40&md5=e74c09d0c019b5dec610654bd695b380,ISSTA 2022 - Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis,85,Include,I1.1,Discuss inclusion
Lin C.; Xu Y.; Fang Y.; Liu Z.,VulEye: A Novel Graph Neural Network Vulnerability Detection Approach for PHP Application,"Following advances in machine learning and deep learning processing, cyber security experts are committed to creating deep intelligent approaches for automatically detecting software vulnerabilities. Nowadays, many practices are for C and C++ programs, and methods rarely target PHP application. Moreover, many of these methods use LSTM (Long Short-Term Memory) but not GNN (Graph Neural Networks) to learn the token dependencies within the source code through different transformations. That may lose a lot of semantic information in terms of code representation. This article presents a novel Graph Neural Network vulnerability detection approach, VulEye, for PHP applications. VulEye can assist security researchers in finding vulnerabilities in PHP projects quickly. VulEye first constructs the PDG (Program Dependence Graph) of the PHP source code, slices PDG with sensitive functions contained in the source code into sub-graphs called SDG (Sub-Dependence Graph), and then makes SDG the model input to train with a Graph Neural Network model which contains three stack units with a GCN layer, Top-k pooling layer, and attention layer, and finally uses MLP (Multi-Layer Perceptron) and softmax as a classifier to predict if the SDG is vulnerable. We evaluated VulEye on the PHP vulnerability test suite in Software Assurance Reference Dataset. The experiment reports show that the best macro-average F1 score of the VulEye reached 99% in the binary classification task and 95% in the multi-classes classification task. VulEye achieved the best result compared with the existing open-source vulnerability detection implements and other state-of-art deep learning models. Moreover, VulEye can also locate the precise area of the flaw, since our SDG contains code slices closely related to vulnerabilities with a key triggering sensitive/sink function. © 2023 by the authors.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146468835&doi=10.3390%2fapp13020825&partnerID=40&md5=18e5279034f59365a34fda512d5d2da2,Applied Sciences (Switzerland),86,Include,"I1.1,I1.2",
Şahin S.E.; Özyedierler E.M.; Tosun A.,Predicting vulnerability inducing function versions using node embeddings and graph neural networks,"Context: Predicting software vulnerabilities over code changes is a difficult task due to obtaining real vulnerability data and their associated code fixes from software projects as software organizations are often reluctant to report those. Objective: We aim to propose a vulnerability prediction model that runs after every code change, and identifies vulnerability inducing functions in that version. We also would like to assess the success of node and token based source code representations over abstract syntax trees (ASTs) on predicting vulnerability inducing functions. Method: We train neural networks to represent node embeddings and token embeddings over ASTs in order to obtain feature representations. Then, we build two Graph Neural Networks (GNNs) with node embeddings, and compare them against Convolutional Neural Network (CNN) and Support Vector Machine (SVM) with token representations. Results: We report our empirical analysis over the change history of vulnerability inducing functions of Wireshark project. GraphSAGE model using source code representation via ASTs achieves the highest AUC rate, while CNN models using token representations achieves the highest recall, precision and F1 measure. Conclusion: Representing functions with their structural information extracted from ASTs, either in token form or in complete graph form, is great at predicting vulnerability inducing function versions. Transforming source code into token frequencies as a natural language text fails to build successful models for vulnerability prediction in a real software project. © 2022 Elsevier B.V.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123002701&doi=10.1016%2fj.infsof.2022.106822&partnerID=40&md5=faca0fa5b8ecb873804f1428477ad855,Information and Software Technology,87,Include,I1.1,
Hin D.; Kan A.; Chen H.; Babar M.A.,LineVD: Statement-level Vulnerability Detection using Graph Neural Networks,"Current machine-learning based software vulnerability detection methods are primarily conducted at the function-level. However, a key limitation of these methods is that they do not indicate the specific lines of code contributing to vulnerabilities. This limits the ability of developers to efficiently inspect and interpret the predictions from a learnt model, which is crucial for integrating machine-learning based tools into the software development work-flow. Graph-based models have shown promising performance in function-level vulnerability detection, but their capability for statement-level vulnerability detection has not been extensively explored. While interpreting function-level predictions through explainable AI is one promising direction, we herein consider the statement-level software vulnerability detection task from a fully supervised learning perspective. We propose a novel deep learning framework, LineVD, which formulates statement-level vulnerability detection as a node classification task. LineVD leverages control and data dependencies between statements using graph neural networks, and a transformer-based model to encode the raw source code tokens. In particular, by addressing the conflicting outputs between function-level and statement-level information, LineVD significantly improve the prediction performance without vulnerability status for function code. We have conducted extensive experi-ments against a large-scale collection of real-world C/C++ vulnerabilities obtained from multiple real-world projects, and demonstrate an increase of 105% in F1-score over the current state-of-the-art. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134019413&doi=10.1145%2f3524842.3527949&partnerID=40&md5=5148d83b0082ec460c9f6f5ef06cd8e1,"Proceedings - 2022 Mining Software Repositories Conference, MSR 2022",88,Include,I1.1,
Li R.; Chen B.; Zhang F.; Sun C.; Peng X.,Detecting Runtime Exceptions by Deep Code Representation Learning with Attention-Based Graph Neural Networks,"Uncaught runtime exceptions have been recognized as one of the commonest root causes of real-life exception bugs in Java applications. However, existing runtime exception detection techniques rely on symbolic execution or random testing, which may suffer the scalability or coverage problem. Rule-based bug detectors (e.g., SpotBugs) provide limited rule support for runtime exceptions. Inspired by the recent successes in applying deep learning to bug detection, we propose a deep learning-based technique, named Drex, to identify not only the types of runtime exceptions that a method might signal but also the statement scopes that might signal the detected runtime exceptions. It is realized by graph-based code representation learning with (i) a lightweight analysis to construct a joint graph of CFG, DFG and AST for each method without requiring a build environment so as to comprehensively characterize statement syntax and semantics and (ii) an attention-based graph neural network to learn statement embeddings in order to distinguish different types of potentially signaled runtime exceptions with interpretability. Our evaluation on 54,255 methods with caught runtime exceptions and 54,255 methods without caught runtime exceptions from 5,996 GitHub Java projects has indicated that Drex improves baseline approaches by up to 18.2% in exact accuracy and 41.6% in F1-score. Drex detects 20 new uncaught runtime exceptions in 13 real-life pro-jects, 7 of them have been fixed, while none of them is detected by rule-based bug detectors (i.e., SpotBugs and PMD).  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134875978&doi=10.1109%2fSANER53432.2022.00053&partnerID=40&md5=8cd8ed205b17dc752c7516483d7b729d,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",89,Include,"I1.1,I1.2",
Zou D.; Hu Y.; Li W.; Wu Y.; Zhao H.; Jin H.,mVulPreter: A Multi-Granularity Vulnerability Detection System With Interpretations,"Due to the powerful automatic feature extraction, deep learning-based vulnerability detection methods have evolved significantly in recent years. However, almost all current work focuses on detecting vulnerabilities at a single granularity (<italic>i.e</italic>., slice-level or function-level). In practice, slice-level vulnerability detection is fine-grained but may contain incomplete vulnerability details. Function-level vulnerability detection includes full vulnerability semantics but may contain vulnerability-unrelated statements. Meanwhile, they pay more attention to predicting whether the source code is vulnerable and cannot pinpoint which statements are more likely to be vulnerable. In this paper, we design <italic>mVulPreter</italic>, a multi-granularity vulnerability detector that can provide interpretations of detection results. Specifically, we propose a novel technique to effectively blend the advantages of function-level and slice-level vulnerability detection models and output the detection results&#x0027; interpretation only by the model itself. We evaluate <italic>mVulPreter</italic> on a dataset containing 5,310 vulnerable functions and 7,601 non-vulnerable functions. The experimental results indicate that <italic>mVulPreter</italic> outperforms existing state-of-the-art vulnerability detection approaches (<italic>i.e</italic>., <italic>Checkmarx</italic>, <italic>FlawFinder</italic>, <italic>RATS</italic>, <italic>TokenCNN</italic>, <italic>StatementLSTM</italic>, <italic>SySeVR</italic>, and <italic>Devign</italic>). IEEE",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137554035&doi=10.1109%2fTDSC.2022.3199769&partnerID=40&md5=d4831c43be79246dab220be2e289fcae,IEEE Transactions on Dependable and Secure Computing,90,Include,I1.1,
Yan G.; Chen S.; Bail Y.; Li X.,Can Deep Learning Models Learn the Vulnerable Patterns for Vulnerability Detection?,"Deep learning has been widely used for the security issue of vulnerability prediction. However, it is confusing to explain how a deep learning model makes decisions on the prediction, although such a model achieves a good performance. Meanwhile, it is also difficult to discover which part of the source code is concentrated on by this black-box model. To this end, we present an empirical evaluation to explore how the deep learning model works on predicting vulnerability and whether it precisely captures the critical code segments to represent the vulnerable patterns. First of all, we build a new vulnerability dataset, called Juliet+, in which vulnerability-related code lines of both positive (bad) and negative (good) samples are labeled manually with substantial efforts, based on the Juliet Test Suite. After that, four deep learning models by leveraging attention mechanisms are empirically implemented to detect vulnerability through mining vulnerable patterns from the source code. We conduct extensive experiments to evaluate the effectiveness of such four models and to analyze the interpretability with evaluation metrics such as Hit@k. The empirical experiment results reveal that the deep learning models with attention, to some extent, can focus on the vulnerability-related code segments that are profitable to interpret the result of vulnerability detection, especially when we adopt the graph neural network model. We further investigate what factors affect the interpretability of models including the class distribution, the number of samples, and the differences of sample features. We find the graph neural network model performs better on part of the dataset which contains balanced and sufficient samples with obvious differences between vulnerable and non-vulnerable patterns. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136989786&doi=10.1109%2fCOMPSAC54236.2022.00142&partnerID=40&md5=7dae859cbf5309de1a4c77fa15eb9138,"Proceedings - 2022 IEEE 46th Annual Computers, Software, and Applications Conference, COMPSAC 2022",91,Include,I1.1,
Wu B.; Liu S.; Feng R.; Xie X.; Siow J.; Lin S.,Enhancing Security Patch Identification by Capturing Structures in Commits,"With the rapid increasing number of open source software (OSS), the majority of the software vulnerabilities in the open source components are fixed silently, which leads to the deployed software that integrated them being unable to get a timely update. Hence, it is critical to design a security patch identification system to ensure the security of the utilized software. However, most of the existing works for security patch identification just consider the changed code and the commit message of a commit as a flat sequence of tokens with simple neural networks to learn its semantics, while the structure information is ignored. To address these limitations, in this paper, we propose our well-designed approach E-SPI, which extracts the structure information hidden in a commit for effective identification. Specifically, it consists of the code change encoder to extract the syntactic of the changed code with the BiLSTM to learn the code representation and the message encoder to construct the dependency graph for the commit message with the graph neural network (GNN) to learn the message representation. We further enhance the code change encoder by embedding contextual information related to the changed code. To demonstrate the effectiveness of our approach, we conduct the extensive experiments against six state-of-the-art approaches on the existing dataset and from the real deployment environment. The experimental results confirm that our approach can significantly outperform current state-of-the-art baselines. IEEE",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135750651&doi=10.1109%2fTDSC.2022.3192631&partnerID=40&md5=03faa8fe5f35a1bdcf6a280e89552e9d,IEEE Transactions on Dependable and Secure Computing,92,Include,I1.1,
Yang H.; Yang H.; Zhang L.,VDHGT: A Source Code Vulnerability Detection Method Based on Heterogeneous Graph Transformer,"Vulnerability detection is still a challenging problem. The source code representation method used by the existing vulnerability detection methods cannot fully contain the context information of the vulnerability occurrence statement, and the vulnerability detection model does not fully consider the importance of the context statement to the vulnerability occurrence statement. Aiming at the problems raised above, this paper proposes a source code vulnerability detection method based on the heterogeneous graph transformer. The method proposed in this paper adopts a novel source code representation method—the vulnerability dependence representation graph, which includes the control dependence of the vulnerability occurrence statement and the data dependence of the variables involved in the statement. At the same time, this paper builds a graph learning network for vulnerability dependence representation graph based on the heterogeneous graph transformer, which can automatically learn the importance of contextual sentences for vulnerable sentences. To prove the effectiveness of the method in this paper, experiments were carried out on the SARD data set, and the average accuracy rate was 95.4% and the recall rate was 92.4%. The average performance is improved by 4.1%–62.7%. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140476757&doi=10.1007%2f978-3-031-18067-5_16&partnerID=40&md5=f7aa123f037071d1b10aa98db66facd0,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),93,Include,"I1.1,I1.2",
Rabheru R.; Hanif H.; Maffeis S.,A Hybrid Graph Neural Network Approach for Detecting PHP Vulnerabilities,"We validate our approach in the wild by discovering 4 novel vulnerabilities in established WordPress plugins. This paper presents DeepTective, a deep learning-based approach to detect vulnerabilities in PHP source code. Our approach implements a novel hybrid technique that combines Gated Recurrent Units and Graph Convolutional Networks to detect SQLi, XSS and OSCI vulnerabilities leveraging both syntactic and semantic information. We evaluate DeepTective and compare it to the state of the art on an established synthetic dataset and on a novel real-world dataset collected from GitHub. Experimental results show that DeepTective outperformed other solutions, including recent machine learning-based vulnerability detection approaches, on both datasets. The gap is noticeable on the synthetic dataset, where our approach achieves very high classification performance, but grows even wider on the realistic dataset, where most existing tools fail to transfer their detection ability, whereas DeepTective achieves an F1 score of 88.12%.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141069074&doi=10.1109%2fDSC54232.2022.9888816&partnerID=40&md5=cfd7e321bea4879cb5fcb78b57af4ac6,"5th IEEE Conference on Dependable and Secure Computing, DSC 2022 and SECSOC 2022 Workshop, PASS4IoT 2022 Workshop SICSA International Paper/Poster Competition in Cybersecurity",94,Include,I1.1,
Cao S.; Sun X.; Bo L.; Wu R.; Li B.; Tao C.,MVD: Memory-Related Vulnerability Detection Based on Flow-Sensitive Graph Neural Networks,"Memory-related vulnerabilities constitute severe threats to the security of modern software. Despite the success of deep learning-based approaches to generic vulnerability detection, they are still limited by the underutilization of flow information when applied for detecting memory-related vulnerabilities, leading to high false positives. In this paper, we propose MVD, a statement-level Memory-related Vulnerability Detection approach based on flow-sensitive graph neural networks (FS-GNN). FS-GNN is employed to jointly embed both unstructured information (i.e., source code) and structured information (i.e., control- and data-flow) to capture implicit memory-related vulnerability patterns. We evaluate MVD on the dataset which contains 4,353 real-world memory-related vulnerabilities, and compare our approach with three state-of-the-art deep learning-based approaches as well as five popular static analysis-based memory detectors. The experiment results show that MVD achieves better detection accuracy, outperforming both state-of-the-art DL-based and static analysis-based approaches. Furthermore, MVD makes a great trade-off between accuracy and efficiency. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133519100&doi=10.1145%2f3510003.3510219&partnerID=40&md5=1f1c9a8b53c4e5850c9714d51db35d49,Proceedings - International Conference on Software Engineering,95,Include,I1.1,
Cao S.; Sun X.; Bo L.; Wei Y.; Li B.,BGNN4VD: Constructing Bidirectional Graph Neural-Network for Vulnerability Detection,"Context: Previous studies have shown that existing deep learning-based approaches can significantly improve the performance of vulnerability detection. They represent code in various forms and mine vulnerability features with deep learning models. However, the differences of code representation forms and deep learning models make various approaches still have some limitations. In practice, their false-positive rate (FPR) and false-negative rate (FNR) are still high. Objective: To address the limitations of existing deep learning-based vulnerability detection approaches, we propose BGNN4VD (Bidirectional Graph Neural Network for Vulnerability Detection), a vulnerability detection approach by constructing a Bidirectional Graph Neural-Network (BGNN). Method: In Phase 1, we extract the syntax and semantic information of source code through abstract syntax tree (AST), control flow graph (CFG), and data flow graph (DFG). Then in Phase 2, we use vectorized source code as input to Bidirectional Graph Neural-Network (BGNN). In Phase 3, we learn the different features between vulnerable code and non-vulnerable code by introducing backward edges on the basis of traditional Graph Neural-Network (GNN). Finally in Phase 4, a Convolutional Neural-Network (CNN) is used to further extract features and detect vulnerabilities through a classifier. Results: We evaluate BGNN4VD on four popular C/C++ projects from NVD and GitHub, and compare it with four state-of-the-art (Flawfinder, RATS, SySeVR, and VUDDY) vulnerab ility detection approaches. Experiment results show that, when compared these baselines, BGNN4VD achieves 4.9%, 11.0%, and 8.4% improvement in F1-measure, accuracy and precision, respectively. Conclusion: The proposed BGNN4VD achieves a higher precision and accuracy than the state-of-the-art methods. In addition, when applied on the latest vulnerabilities reported by CVE, BGNN4VD can still achieve a precision at 45.1%, which demonstrates the feasibility of BGNN4VD in practical application. © 2021",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103334174&doi=10.1016%2fj.infsof.2021.106576&partnerID=40&md5=649f46166db76c21002626593f04ce4b,Information and Software Technology,96,Include,I1.1,
Song Z.; Wang J.; Liu S.; Fang Z.; Yang K.,HGVul: A Code Vulnerability Detection Method Based on Heterogeneous Source-Level Intermediate Representation,"Vulnerability detection on source code can prevent the risk of cyber-attacks as early as possible. However, lacking fine-grained analysis of the code has rendered the existing solutions still suffering from low performance; besides, the explosive growth of open-source projects has dramatically increased the complexity and diversity of the source code. This paper presents HGVul, a code vulnerability detection method based on heterogeneous intermediate representation of source code. The key of the proposed method is the fine-grained handling on heterogeneous source-level intermediate representation (SIR) without expert knowledge. It first extracts graph SIR of code with multiple syntactic-semantic information. Then, HGVul splits the SIR into different subgraphs according to various semantic relations, which are used to obtain semantic information conveyed by different types of edges. Next, a graph neural network with attention operations is deployed on each subgraph to learn representation, which captures the subtle effects from node neighbors on their representation. Finally, the learned code feature representations are utilized to perform vulnerability detection. Experiments are conducted on multiple datasets. The F1 of HGVul reaches 96.1% on the sample-balanced Big-Vul-VP dataset and 88.3% on the unbalanced Big-Vul dataset. Further experiments on actual open-source project datasets prove the better performance of HGVul.  © 2022 Zihua Song et al.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129314783&doi=10.1155%2f2022%2f1919907&partnerID=40&md5=acfe9a476db18fb89687d385fa8fdd90,Security and Communication Networks,97,Include,I1.1,
Ding Y.; Suneja S.; Zheng Y.; Laredo J.; Morari A.; Kaiser G.; Ray B.,VELVET: A noVel Ensemble Learning approach to automatically locate VulnErable sTatements,"Automatically locating vulnerable statements in source code is crucial to assure software security and alleviate developers' debugging efforts. This becomes even more important in today's software ecosystem, where vulnerable code can flow easily and unwittingly within and across software repositories like GitHub. Across such millions of lines of code, traditional static and dynamic approaches struggle to scale. Although existing machine-learning-based approaches look promising in such a setting, most work detects vulnerable code at a higher granularity - at the method or file level. Thus, developers still need to inspect a significant amount of code to locate the vulnerable statement(s) that need to be fixed. This paper presents Velvet, a novel ensemble learning approach to locate vulnerable statements. Our model combines graph-based and sequence-based neural networks to successfully capture the local and global context of a program graph and effectively understand code semantics and vulnerable patterns. To study Velvet's effectiveness, we use an off-the-shelf synthetic dataset and a recently published real-world dataset. In the static analysis setting, where vulnerable functions are not detected in advance, Velvet achieves 4.5× better performance than the baseline static analyzers on the real-world data. For the isolated vulnerability localization task, where we assume the vulnerability of a function is known while the specific vulnerable statement is unknown, we compare Velvet with several neural networks that also attend to local and global context of code. Velvet achieves 99.6% and 43.6% top-1 accuracy over synthetic data and real-world data, respectively, outperforming the baseline deep learning models by 5.3-29.0%.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127031754&doi=10.1109%2fSANER53432.2022.00114&partnerID=40&md5=52f8fa0cd17e6cd221bc2a6f6b90c2e5,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",98,Include,I1.1,
Nguyen V.-A.; Nguyen D.Q.; Nguyen V.; Le T.; Tran Q.H.; Phung D.,ReGVD: Revisiting Graph Neural Networks for Vulnerability Detection,"Identifying vulnerabilities in the source code is essential to protect the software systems from cyber security attacks. It, however, is also a challenging step that requires specialized expertise in security and code representation. To this end, we aim to develop a general, practical, and programming language-independent model capable of running on various source codes and libraries without difficulty. Therefore, we consider vulnerability detection as an inductive text classification problem and propose ReGVD, a simple yet effective graph neural network-based model for the problem. In particular, ReGVD views each raw source code as a flat sequence of tokens to build a graph, wherein node features are initialized by only the token embedding layer of a pre-trained programming language (PL) model. ReGVD then leverages residual connection among GNN layers and examines a mixture of graph-level sum and max poolings to return a graph embedding for the source code. ReGVD outperforms the existing state-of-the-art models and obtains the highest accuracy on the real-world benchmark dataset from CodeXGLUE for vulnerability detection. Our code is available at: https://github.com/daiquocnguyen/GNN-ReGVD. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128155921&doi=10.1109%2fICSE-Companion55297.2022.9793807&partnerID=40&md5=ead1f06fa683209f9301b928840b5491,Proceedings - International Conference on Software Engineering,99,Include,I1.1,
Wu T.; Chen L.; Du G.; Zhu C.; Cui N.; Shi G.,Inductive Vulnerability Detection via Gated Graph Neural Network,"Vulnerability detection is an essential means to ensure the normal operation of various software tools and system security. The Recurrent Neural Networks (RNNs) have achieved remarkable results in vulnerability detection, but the sequence-based code representation has great limitations in feature expression and propagation. In this paper, we propose a fine-grained code vulnerability detection framework based on Gated Graph Neural Network (GGNN). Firstly, we process the source code into fine-grained slices. Secondly, graph embedding of code slices is constructed by clustering neighborhood information. Finally, GGNN is used to learn the syntax and semantic information of vulnerability codes for graph-level classification. Furthermore, we theoretically analyze that GGNN has a strong inductive learning ability. This means that the model requires only a small amount of training data to obtain sufficient advanced features, which is significant for vulnerability detection tasks that are difficult to collect data sets. We carry out conventional experiments and inductive experiments with manually collected data sets, and the results show that the framework is superior to RNNs in vulnerability detection performance. Moreover, our framework performs better than RNNs under inductive conditions. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130846469&doi=10.1109%2fCSCWD54268.2022.9776051&partnerID=40&md5=6896f26785fbfbf10fba33ae7844bd52,"2022 IEEE 25th International Conference on Computer Supported Cooperative Work in Design, CSCWD 2022",100,Include,I1.1,
Qian J.; Ju X.; Chen X.; Shen H.; Shen Y.,AGFL: A Graph Convolutional Neural Network-Based Method for Fault Localization,"Fault localization techniques have been developed for decades. Spectrum Based Fault Localization (SBFL) is a popular strategy in this research topic. However, SBFL is well known for low accuracy, mainly due to simply using a coverage matrix of program executions. In this paper, we propose a method based on graph neural network (AGFL), characterized by the adjacent matrix of the abstract syntax tree and the word vector of each program token. Referring to the Dstar, we calculate the suspiciousness of the statements and rank these statements. The experiment carried on Defects4J, a widely used benchmark, reveals that AGFL can locate 178 of the 262 studied bugs within Top-1, while state-of-the-art techniques at most locate 148 within Top-1. We also investigate the impacts of hyper-parameters (e.g., epoch and learning rate). The results show that AGFL has the best effect when the epoch is 100 and the learning rate is 0.0001. This value of epoch and learning rate increases by 66% compared to the worst on Top-1. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138900023&doi=10.1109%2fQRS54544.2021.00077&partnerID=40&md5=4d8c8936839e1d46ec0184447d0afc82,"IEEE International Conference on Software Quality, Reliability and Security, QRS",101,Include,I1.1,
Wu Y.; Lu J.; Zhang Y.; Jin S.,Vulnerability Detection in C/C++ Source Code with Graph Representation Learning,"An open challenge in software vulnerability detection is how to identify potential vulnerabilities of source code at a fine-grained level automatically. This paper proposes an approach to automate vulnerability detection in source code at the software function level based on graph representation learning without the efforts of security experts. The proposed approach firstly represents software functions as Simplified Code Property Graphs (SCPG), which can conserve syntactic and semantic information of source code while keeping itself small enough for computing. It then utilizes graph neural network and multi layer perceptrons to learn graph representations and extract features automatically, saving efforts of feature engineering. The comparison experiments demonstrate the effectiveness of the proposed approach. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103439913&doi=10.1109%2fCCWC51732.2021.9376145&partnerID=40&md5=a7e6b3ad521d4c8c52f4acfa3f048dbd,"2021 IEEE 11th Annual Computing and Communication Workshop and Conference, CCWC 2021",102,Include,I1.1,
Zheng W.; Jiang Y.; Su X.,Vu1SPG: Vulnerability detection based on slice property graph representation learning,"Vulnerability detection is an important issue in software security. Although various data-driven vulnerability detection methods have been proposed, the task remains challenging since the diversity and complexity of real-world vulnerable code in syntax and semantics make it difficult to extract vulnerable features with regular deep learning models, especially in analyzing a large program. Moreover, the fact that real-world vulnerable codes contain a lot of redundant information unrelated to vulnerabilities will further aggravate the above problem. To mitigate such challenges, we define a novel code representation named Slice Property Graph (SPG), and then propose VulSPG, a new vulnerability detection approach using the improved R-GCN model with triple attention mechanism to identify potential vulnerabilities in SPG. Our approach has at least two advantages over other methods. First, our proposed SPG can reflect the rich semantics and explicit structural information that may be relevance to vulnerabilities, while eliminating as much irrelevant information as possible to reduce the complexity of graph. Second, VulSPG incorporates triple attention mechanism in R-GCNs to achieve more effective learning of vulnerability patterns from SPG. We have extensively evaluated VulSPG on two large-scale datasets with programs from SARD and real-world projects. Experimental results prove the effectiveness and efficiency of VulSPG.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126394310&doi=10.1109%2fISSRE52982.2021.00054&partnerID=40&md5=43007b746f7d6abcaf08fab52274f36d,"Proceedings - International Symposium on Software Reliability Engineering, ISSRE",103,Include,"I1.1,I1.2",
Xia X.; Wang Y.; Yang Y.,Source Code Vulnerability Detection Based on SAR-GIN,"With the development of the Internet era, software technology is being used more and more commonly, and the detection of vulnerabilities in the corresponding software must be efficient and accurate. However, software vulnerabilities are diverse, and mining vulnerabilities through source code requires a high level of professional experience for developers. Previous vulnerability detection solutions either relied on expert-defined features or used recursive neural networks only for code sequences, making it difficult to extract complex features of vulnerabilities in the traditional code space. In recent years, with the booming development of artificial intelligence technology, some scholars have started to try to combine graph neural networks to extract graph structure information of source code for software vulnerability detection. In this paper, by introducing a method based on Graph Isomorphism Network (GIN) combined with a self-attention aggregation mechanism for vulnerability detection, we achieve superior detection results. By assigning different attention weights to each layer, the self-attention mechanism helps to solve the problem of too smooth node representation and poor comprehensive performance of graph-level output. In this paper, we propose Self Attention Readout Graph Isomorphism Network (SAR-GIN), which efficiently extracts and utilizes global information at all depths by combining GIN with a self-attention mechanism in generating global graph-level features. Meanwhile, the experimental results on CWE-400, CWE-190 datasets, combined with the discrete Fourier transform, show that the modeling approach in this paper achieves superior results compared to other models.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128636129&doi=10.1109%2fCECIT53797.2021.00202&partnerID=40&md5=a8ed7158323cb10544edad6bc36b66ec,"Proceedings - 2021 2nd International Conference on Electronics, Communications and Information Technology, CECIT 2021",104,Include,I1.1,
Cheng X.; Wang H.; Hua J.; Xu G.; Sui Y.,DeepWukong: Statically Detecting Software Vulnerabilities Using Deep Graph Neural Network,"Static bug detection has shown its effectiveness in detecting well-defined memory errors, e.g., memory leaks, buffer overflows, and null dereference. However, modern software systems have a wide variety of vulnerabilities. These vulnerabilities are extremely complicated with sophisticated programming logic, and these bugs are often caused by different bad programming practices, challenging existing bug detection solutions. It is hard and labor-intensive to develop precise and efficient static analysis solutions for different types of vulnerabilities, particularly for those that may not have a clear specification as the traditional well-defined vulnerabilities. This article presents DeepWukong, a new deep-learning-based embedding approach to static detection of software vulnerabilities for C/C++ programs. Our approach makes a new attempt by leveraging advanced recent graph neural networks to embed code fragments in a compact and low-dimensional representation, producing a new code representation that preserves high-level programming logic (in the form of control-and data-flows) together with the natural language information of a program. Our evaluation studies the top 10 most common C/C++ vulnerabilities during the past 3 years. We have conducted our experiments using 105,428 real-world programs by comparing our approach with four well-known traditional static vulnerability detectors and three state-of-the-art deep-learning-based approaches. The experimental results demonstrate the effectiveness of our research and have shed light on the promising direction of combining program analysis with deep learning techniques to address the general static code analysis challenges.  © 2021 ACM.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105713814&doi=10.1145%2f3436877&partnerID=40&md5=f2f88288533288e48de75486035787b6,ACM Transactions on Software Engineering and Methodology,105,Include,I1.1,
Rabheru R.; Hanif H.; Maffeis S.,DeepTective: Detection of PHP vulnerabilities using hybrid graph neural networks,"This paper presents DeepTective, a deep learning-based approach to detect vulnerabilities in PHP source code. DeepTective implements a novel hybrid technique that combines Gated Recurrent Units and Graph Convolutional Networks to detect SQLi, XSS and OSCI vulnerabilities leveraging both syntactic and semantic information. Experimental results show that our model outperformed related solutions on both synthetic and realistic datasets, and was able to discover 4 novel vulnerabilities in established WordPress plugins. © 2021 Owner/Author.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100455359&doi=10.1145%2f3412841.3442132&partnerID=40&md5=1370ecafe97d6cc5c719ae62f9a97786,Proceedings of the ACM Symposium on Applied Computing,106,Exclude,E1.10,Already included as part of paper 94
Wang L.; Li X.; Wang R.; Xin Y.; Gao M.; Chen Y.,Prennsem: A heterogeneous ensemble learning framework for vulnerability detection in software,"Automated vulnerability detection is one of the critical issues in the realm of software security. Existing solutions to this problem are mostly based on features that are defined by human experts and directly lead to missed potential vulnerability. Deep learning is an effective method for automating the extraction of vulnerability characteristics. Our paper proposes intelligent and automated vulnerability detection while using deep representation learning and heterogeneous ensemble learning. Firstly, we transform sample data from source code by removing segments that are unrelated to the vulnerability in order to reduce code analysis and improve detection efficiency in our experiments. Secondly, we represent the sample data as real vectors by pre-training on the corpus and maintaining its semantic information. Thirdly, the vectors are fed to a deep learning model to obtain the features of vulnerability. Lastly, we train a heterogeneous ensemble classifier. We analyze the effectiveness and resource consumption of different network models, pre-training methods, classifiers, and vulnerabilities separately in order to evaluate the detection method. We also compare our approach with some well-known vulnerability detection commercial tools and academic methods. The experimental results show that our proposed method provides improvements in false positive rate, false negative rate, precision, recall, and F1 score. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096027213&doi=10.3390%2fapp10227954&partnerID=40&md5=03bc504a1a2f1180eaeade249a8e409a,Applied Sciences (Switzerland),107,Exclude,E1.1,
Zhang Y.; Liu X.; Du D.,Static detection of vulnerabilities via graph attention hierarchically,"With the rapid growth of the software industry, the risks of vulnerabilities are inevitably increasing. Deep learning based methods have been widely used in vulnerability detection in recent years. Since the inherent graph structure of source code contains rich semantics, many deep learning works have exploited graph neural networks to enhance code representation. Despite their novel design, learning the structural information in the graph hierarchically and focusing on important nodes are still problems to better capture vulnerability semantics. To tackle this bottleneck, we propose a novel neural model for vulnerability detection. A SAGPool module is designed to automatically chooses important nodes to retain hierarchically in each graph convolution layer. Our model is trained and tested over the REVEAL dataset built on two popular and well-maintained open-source projects. The experimental results demonstrate that our model outperforms the state-of-the-art methods. © 2021 11th International Workshop on Computer Science and Engineering, WCSE 2021. All Rights Reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114202299&doi=10.18178%2fwcse.2021.06.002&partnerID=40&md5=6d5bf4b6f0666309c54e4ed8eca9d669,"2021 11th International Workshop on Computer Science and Engineering, WCSE 2021",108,Include,I1.1,
Feng Q.; Feng C.; Hong W.,Graph Neural Network-based Vulnerability Predication,framework,Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096658254&doi=10.1109%2fICSME46990.2020.00096&partnerID=40&md5=c5b9c0290496d31a4e99dd5ec5ba325a,"Proceedings - 2020 IEEE International Conference on Software Maintenance and Evolution, ICSME 2020",109,Exclude,E1.8,Just some quick initial results; Unsure if this should be included
Zeng J.; Nie X.; Chen L.; Li J.; Du G.; Shi G.,An efficient vulnerability extrapolation using similarity of graph kernel of PDGs,"Discovering the potential vulnerabilities in software plays a crucial role in ensuring the security of computer system. This paper proposes a method that can assist security auditors with the analysis of source code. When security auditors identify new vulnerabilities, our method can be adopted to make a list of recommendations that may have the same vulnerabilities for the security auditors. Our method relies on graph representation to automatically extract the mode of PDG(program dependence graph, a structure composed of control dependence and data dependence). Besides, it can be applied to the vulnerability extrapolation scenario, thus reducing the amount of audit code. We worked on an open-source vulnerability test set called Juliet. According to the evaluation results, the clustering effect produced is satisfactory, so that the feature vectors extracted by the Graph2Vec model are applied to labeling and supervised learning indicators are adopted to assess the model for its ability to extract features. On a total of 12, 000 small data sets, the training score of the model can reach up to 99.2%, and the test score can reach a maximum of 85.2%. Finally, the recommendation effect of our work is verified as satisfactory. © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101273031&doi=10.1109%2fTrustCom50675.2020.00229&partnerID=40&md5=9f0915ad6ce62a2cf52be8a097ca8ed3,"Proceedings - 2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications, TrustCom 2020",110,Exclude,E3.2,Really nothing new graph learning wise I think?
Zhou Y.; Liu S.; Siow J.; Du X.; Liu Y.,Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks,"Vulnerability identification is crucial to protect the software systems from attacks for cyber security. It is especially important to localize the vulnerable functions among the source code to facilitate the fix. However, it is a challenging and tedious process, and also requires specialized security expertise. Inspired by the work on manually-defined patterns of vulnerabilities from various code representation graphs and the recent advance on graph neural networks, we propose Devign, a general graph neural network based model for graph-level classification through learning on a rich set of code semantic representations. It includes a novel Conv module to efficiently extract useful features in the learned rich node representations for graph-level classification. The model is trained over manually labeled datasets built on 4 diversified large-scale open-source C projects that incorporate high complexity and variety of real source code instead of synthesis code used in previous works. The results of the extensive evaluation on the datasets demonstrate that Devign outperforms the state of the arts significantly with an average of 10.51% higher accuracy and 8.68% F1 score, increases averagely 4.66% accuracy and 6.37% F1 by the Conv module. © 2019 Neural information processing systems foundation. All rights reserved.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089940996&partnerID=40&md5=360e4ac4b80f50a82fbee08b6e8712d6,Advances in Neural Information Processing Systems,111,Include,I1.1,
Morgachev G.; Ignatyev V.; Belevantsev A.,Detection of variable misuse using static analysis combined with machine learning,"Industrial static analyzers are able to detect only several narrow classes of algorithmic errors, for example actual arguments order swapped with formal parameters, forgotten renaming of variable after copy-paste. However, even for these categories essential part of errors is lost because of heuristical design of a checker. We propose the generalization of specified errors in the form of variable misuse problem and deal with it using machine learning. The proposed method uses message propagation through the program model represented as a graph, combining data from multiple analysis levels, including AST, dataflow. We introduce several error criteria, which were evaluated on the set of open source projects with millions of LoC. Testing in close to industrial conditions shows good false positive and missed errors ratio comparable with remaining detectors and allows to include developed checker (after a minor rework) into a general purpose production static analyzer for error detection. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081319485&doi=10.1109%2fISPRAS47671.2019.00009&partnerID=40&md5=c20c1b1eee9c4f56e23317ce1c8773fb,"Proceedings - 2019 Ivannikov Ispras Open Conference, ISPRAS 2019",112,Include,I1.1,
Wang H.; Ye G.; Tang Z.; Tan S.H.; Huang S.; Fang D.; Feng Y.; Bian L.; Wang Z.,Combining Graph-Based Learning with Automated Data Collection for Code Vulnerability Detection,"This paper presents FUNDED (Flow-sensitive vUl-Nerability coDE Detection), a novel learning framework for building vulnerability detection models. Funded leverages the advances in graph neural networks (GNNs) to develop a novel graph-based learning method to capture and reason about the program's control, data, and call dependencies. Unlike prior work that treats the program as a sequential sequence or an untyped graph, Funded learns and operates on a graph representation of the program source code, in which individual statements are connected to other statements through relational edges. By capturing the program syntax, semantics and flows, Funded finds better code representation for the downstream software vulnerability detection task. To provide sufficient training data to build an effective deep learning model, we combine probabilistic learning and statistical assessments to automatically gather high-quality training samples from open-source projects. This provides many real-life vulnerable code training samples to complement the limited vulnerable code samples available in standard vulnerability databases. We apply Funded to identify software vulnerabilities at the function level from program source code. We evaluate Funded on large real-world datasets with programs written in C, Java, Swift and Php, and compare it against six state-of-the-art code vulnerability detection models. Experimental results show that Funded significantly outperforms alternative approaches across evaluation settings. © 2005-2012 IEEE.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098786569&doi=10.1109%2fTIFS.2020.3044773&partnerID=40&md5=38482a134182eb97d899b34ee5f5e116,IEEE Transactions on Information Forensics and Security,113,Include,I1.1,
Liu S.; Lin G.; Han Q.-L.; Wen S.; Zhang J.; Xiang Y.,DeepBalance: Deep-Learning and Fuzzy Oversampling for Vulnerability Detection,"Software vulnerability has long been an important but critical research issue in cybersecurity. Recently, the machine learning (ML)-based approach has attracted increasing interest in the research of software vulnerability detection. However, the detection performance of existing ML-based methods require further improvement. There are two challenges: one is code representation for ML and the other is class imbalance between vulnerable code and nonvulnerable code. To overcome these challenges, this article develops a DeepBalance system, which combines the new ideas of deep code representation learning and fuzzy-based class rebalancing. We design a deep neural network with bidirectional long short-term memory to learn invariant and discriminative code representations from labeled vulnerable and nonvulnerable code. Then, a new fuzzy oversampling method is employed to rebalance the training data by generating synthetic samples for the class of vulnerable code. To evaluate the performance of the new system, we carry out a series of experiments in a real-world ground-truth dataset that consists of the code from the projects of LibTIFF, LibPNG, and FFmpeg. The results show that the proposed new system can significantly improve the vulnerability detection performance. For example, the improvement is 15% in terms of F-measure. © 1993-2012 IEEE.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087818690&doi=10.1109%2fTFUZZ.2019.2958558&partnerID=40&md5=1d6e91446ab3e47e3b789368129fd877,IEEE Transactions on Fuzzy Systems,114,Include,I1.1,Include 
Russell R.; Kim L.; Hamilton L.; Lazovich T.; Harer J.; Ozdemir O.; Ellingwood P.; McConley M.,Automated Vulnerability Detection in Source Code Using Deep Representation Learning,"Increasing numbers of software vulnerabilities are discovered every year whether they are reported publicly or discovered internally in proprietary code. These vulnerabilities can pose serious risk of exploit and result in system compromise, information leaks, or denial of service. We leveraged the wealth of C and C++ open-source code available to develop a largescale function-level vulnerability detection system using machine learning. To supplement existing labeled vulnerability datasets, we compiled a vast dataset of millions of open-source functions and labeled it with carefully-selected findings from three different static analyzers that indicate potential exploits. Using these datasets, we developed a fast and scalable vulnerability detection tool based on deep feature representation learning that directly interprets lexed source code. We evaluated our tool on code from both real software packages and the NIST SATE IV benchmark dataset. Our results demonstrate that deep feature representation learning on source code is a promising approach for automated software vulnerability detection. © 2018 IEEE.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062238891&doi=10.1109%2fICMLA.2018.00120&partnerID=40&md5=8615995e948557980d3ccd0c31eb28e4,"Proceedings - 17th IEEE International Conference on Machine Learning and Applications, ICMLA 2018",115,Exclude,E1.1,
Lin G.; Zhang J.; Luo W.; Pan L.; Xiang Y.,Poster: Vulnerability discovery with function representation learning from unlabeled projects,"In cybersecurity, vulnerability discovery in source code is a fundamental problem. To automate vulnerability discovery, Machine learning (ML) based techniques has attracted tremendous attention. However, existing ML-based techniques focus on the component or file level detection, and thus considerable human effort is still required to pinpoint the vulnerable code fragments. Using source code files also limit the generalisability of the ML models across projects. To address such challenges, this paper targets at the function-level vulnerability discovery in the cross-project scenario. A function representation learning method is proposed to obtain the high-level and generalizable function representations from the abstract syntax tree (AST). First, the serialized ASTs are used to learn project independence features. Then, a customized bi-directional LSTM neural network is devised to learn the sequential AST representations from the large number of raw features. The new function-level representation demonstrated promising performance gain, using a unique dataset where we manually labeled 6000+ functions from three open-source projects. The results confirm that the huge potential of the new AST-based function representation learning. © 2017 author(s).",Conference paper,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041433336&doi=10.1145%2f3133956.3138840&partnerID=40&md5=8b6e92bb5d8442d175adc77d8de43b50,Proceedings of the ACM Conference on Computer and Communications Security,116,Include,I1.1,
He Y.; Wang L.; Wang K.; Zhang Y.; Zhang H.; Li Z.,COME: Commit Message Generation with Modification Embedding,"Commit messages concisely describe code changes in natural language and are important for program comprehension and maintenance. Previous studies proposed some approaches for automatic commit message generation, but their performance is limited due to inappropriate representation of code changes and improper combination of translation-based and retrieval-based approaches. To address these problems, this paper introduces a novel framework named COME, in which modification embeddings are used to represent code changes in a fine-grained way, a self-supervised generative task is designed to learn contextualized code change representation, and retrieval-based and translation-based methods are combined through a decision algorithm. The average improvement of COME over the state-of-the-art approaches is 9.2% on automatic evaluation metrics and 8.0% on human evaluation metrics. We also analyse the effectiveness of COME's three main components and each of them results in an improvement of 8.6%, 8.7% and 5.2%.  © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167710827&doi=10.1145%2f3597926.3598096&partnerID=40&md5=b883dadfbb5393cdedf588457d62c203,ISSTA 2023 - Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis,117,Exclude,E1.1,
Zhang F.; Chen B.; Zhao Y.; Peng X.,Slice-Based Code Change Representation Learning,"Code changes are at the very core of software development and maintenance. Deep learning techniques have been used to build a model from a massive number of code changes to solve software engineering tasks, e.g., commit message generation and bug-fix commit identification. However, existing code change representation learning approaches represent code change as lexical tokens or syntactical AST (abstract syntax tree) paths, limiting the capability to learn semantics of code changes. Besides, they mostly do not consider noisy or tangled code change, hurting the accuracy of solved tasks. To address the above problems, we first propose a slice-based code change representation approach which considers data and control dependencies between changed code and unchanged code. Then, we propose a pre-trained sparse Transformer model, named CCS2VEC, to learn code change representations with three pre-training tasks. Our experiments by fine-tuning our pre-trained model on three downstream tasks have demonstrated the improvement of CCS2VEC over the state-of-the-art CC2VEC. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160563876&doi=10.1109%2fSANER56733.2023.00038&partnerID=40&md5=e44fc443ec0fa0c3f87ee88b0feecbe4,"Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",118,Include,,"Fairly tricky paper, but I think the data extraction is correct"
Zhang J.; Maddila C.; Bairi R.; Bird C.; Raizada U.; Agrawal A.; Jhawar Y.; Herzig K.; Van Deursen A.,Using Large-scale Heterogeneous Graph Representation Learning for Code Review Recommendations at Microsoft,"Code review is an integral part of any mature software development process, and identifying the best reviewer for a code change is a well-accepted problem within the software engineering community. Selecting a reviewer who lacks expertise and understanding can slow development or result in more defects. To date, most reviewer recommendation systems rely primarily on historical file change and review information; those who changed or reviewed a file in the past are the best positioned to review in the future.We posit that while these approaches are able to identify and suggest qualified reviewers, they may be blind to reviewers who have the needed expertise and have simply never interacted with the changed files before. Fortunately, at Microsoft, we have a wealth of work artifacts across many repositories that can yield valuable information about our developers. To address the aforementioned problem, we present Coral, a novel approach to reviewer recommendation that leverages a socio-technical graph built from the rich set of entities (developers, repositories, files, pull requests (PRs), work items, etc.) and their relationships in modern source code management systems. We employ a graph convolutional neural network on this graph and train it on two and a half years of history on 332 repositories within Microsoft.We show that Coral is able to model the manual history of reviewer selection remarkably well. Further, based on an extensive user study, we demonstrate that this approach identifies relevant and qualified reviewers who traditional reviewer recommenders miss, and that these developers desire to be included in the review process. Finally, we find that ""classical""reviewer recommendation systems perform better on smaller (in terms of developers) software projects while Coral excels on larger projects, suggesting that there is ""no one model to rule them all."" © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167921721&doi=10.1109%2fICSE-SEIP58684.2023.00020&partnerID=40&md5=a0274a779711b1042772bf9e7a85e888,Proceedings - International Conference on Software Engineering,119,Include,"I1.1,I1.2",Node embedding (initial) is slightly unclear to me
Dong J.; Lou Y.; Zhu Q.; Sun Z.; Li Z.; Zhang W.; Hao D.,FIRA: Fine-Grained Graph-Based Code Change Representation for Automated Commit Message Generation,"Commit messages summarize code changes of each commit in nat-ural language, which help developers understand code changes without digging into detailed implementations and play an essen-tial role in comprehending software evolution. To alleviate human efforts in writing commit messages, researchers have proposed var-ious automated techniques to generate commit messages, including template-based, information retrieval-based, and learning-based techniques. Although promising, previous techniques have limited effectiveness due to their coarse-grained code change representations. This work proposes a novel commit message generation technique, FIRA, which first represents code changes via fine-grained graphs and then learns to generate commit messages automati-cally. Different from previous techniques, FIRA represents the code changes with fine-grained graphs, which explicitly describe the code edit operations between the old version and the new version, and code tokens at different granularities (i.e., sub-tokens and integral tokens). Based on the graph-based representation, FIRA generates commit messages by a generation model, which includes a graph-neural-network-based encoder and a transformer-based decoder. To make both sub-tokens and integral tokens as available ingredients for commit message generation, the decoder is further incorporated with a novel dual copy mechanism. We further per-form an extensive study to evaluate the effectiveness of FIRA. Our quantitative results show that FIRA outperforms state-of-the-art techniques in terms of BLEU, ROUGE-L, and METEOR; and our ablation analysis further shows that major components in our technique both positively contribute to the effectiveness of FIRA. In addition, we further perform a human study to evaluate the quality of generated commit messages from the perspective of developers, and the results consistently show the effectiveness of FIRA over the compared techniques. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133555793&doi=10.1145%2f3510003.3510069&partnerID=40&md5=0b410951296235c34ca7d23bcda92d56,Proceedings - International Conference on Software Engineering,120,Include,"I1.1,I1.2",
Yousofvand L.; Soleimani S.; Rafe V.,Automatic bug localization using a combination of deep learning and model transformation through node classification,"Bug localization is the task of automatically locating suspicious commands in the source code. Many automated bug localization approaches have been proposed for reducing costs and speeding up the bug localization process. These approaches allow developers to focus on critical commands. In this paper, we propose to treat the bug localization problem as a node classification problem. As in the existing training sets, where whole graphs are labeled as buggy and bug-free, it is required first to label all nodes in each graph. To do this, we use the Gumtree algorithm, which labels the nodes by comparing the buggy graphs with their corresponding fixed graphs. In classification, we propose to use a type of graph neural networks (GNNs), GraphSAGE. The used dataset for training and testing is JavaScript buggy code and their corresponding fixed code. The results demonstrate that the proposed method outperforms other related methods. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150659552&doi=10.1007%2fs11219-023-09625-5&partnerID=40&md5=ca9ae9885894b791b4c68c220de3be7f,Software Quality Journal,121,Include,I1.1,Very unclear what features are used
Xu Z.; Lu K.; Sheng V.S.,Logic Error Localization and Correction with Machine Learning,"We aim to propose a system repairing programs with logic errors to be functionally correct among different programming languages. Logic error program repair has always been a thorny problem: First, a logic error is usually harder to repair than a syntax error in a program because it has no diagnostic feedback from compilers. Second, it requires inferring in different ranges (i.e., the distance of related code lines) and tracking symbols across its pseudocode, source code, and test cases. Third, the logic error datasets are scarce, since an ideal logic error dataset should contain lots of components during the development procedure of a program, including a program specification, pseudocode, source code, test cases, and test reports (i.e., test case failure report). In our work, we propose novel solutions to these challenges. First, we introduce pseudocode information to assist logic error localization and correction. We construct a code-pseudocode graph to connect symbols across a source code and its pseudocode and then apply a graph neural network to localize and correct logic errors. Second, we collect logic errors generated in the process of syntax error repairing via DrRepair from 500 programs in the SPoC dataset and reconstruct them to our single logic error dataset, which we leverage to train and evaluate our models. Our experimental results show that we achieve 99.39% localization accuracy and 19.20% full repair accuracy on logic errors with five-fold cross-validation. Based on our current work, we will replenish and construct more complete public logic error datasets and propose a novel system to comprehend different programming languages from several perspectives and correct logic errors to be functionally correct. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168252069&partnerID=40&md5=92f6a907b8224915ea20b1e8a8e10b1e,"Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",122,Exclude,E1.8,I'm just going to say this is not a proper primary study
Zhang J.; Wang X.; Zhang H.; Sun H.; Liu X.; Hu C.; Liu Y.,Detecting Condition-Related Bugs with Control Flow Graph Neural Network,"Automated bug detection is essential for high-quality software development and has attracted much attention over the years. Among the various bugs, previous studies show that the condition expressions are quite error-prone and the condition-related bugs are commonly found in practice. Traditional approaches to automated bug detection are usually limited to compilable code and require tedious manual effort. Recent deep learning-based work tends to learn general syntactic features based on Abstract Syntax Tree (AST) or apply the existing Graph Neural Networks over program graphs. However, AST-based neural models may miss important control flow information of source code, and existing Graph Neural Networks for bug detection tend to learn local neighbourhood structure information. Generally, the condition-related bugs are highly influenced by control flow knowledge, therefore we propose a novel CFG-based Graph Neural Network (CFGNN) to automatically detect condition-related bugs, which includes a graph-structured LSTM unit to efficiently learn the control flow knowledge and long-distance context information. We also adopt the API-usage attention mechanism to leverage the API knowledge. To evaluate the proposed approach, we collect real-world bugs in popular GitHub repositories and build a large-scale condition-related bug dataset. The experimental results show that our proposed approach significantly outperforms the state-of-the-art methods for detecting condition-related bugs.  © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167727229&doi=10.1145%2f3597926.3598142&partnerID=40&md5=d1528e96d16abc5373ecd30bb07bcb45,ISSTA 2023 - Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis,123,Include,I1.1,
Tian H.; Liu K.; Li Y.; Kaboré A.K.; Koyuncu A.; Habib A.; Li L.; Wen J.; Klein J.; Bissyandé T.F.,The Best of Both Worlds: Combining Learned Embeddings with Engineered Features for Accurate Prediction of Correct Patches,"A large body of the literature on automated program repair develops approaches where patches are automatically generated to be validated against an oracle (e.g., a test suite). Because such an oracle can be imperfect, the generated patches, although validated by the oracle, may actually be incorrect. While the state-of-the-art explores research directions that require dynamic information or rely on manually-crafted heuristics, we study the benefit of learning code representations in order to learn deep features that may encode the properties of patch correctness. Our empirical work investigates different representation learning approaches for code changes to derive embeddings that are amenable to similarity computations of patch correctness identification, and assess the possibility of accurate classification of correct patch by combining learned embeddings with engineered features. Experimental results demonstrate the potential of learned embeddings to empower Leopard (a patch correctness predicting framework implemented in this work) with learning algorithms in reasoning about patch correctness: a machine learning predictor with BERT transformer-based learned embeddings associated with XGBoost achieves an AUC value of about 0.803 in the prediction of patch correctness on a new dataset of 2,147 labeled patches that we collected for the experiments. Our investigations show that deep learned embeddings can lead to complementary/better performance when comparing against the state-of-the-art, PATCH-SIM, which relies on dynamic information. By combining deep learned embeddings and engineered features, Panther (the upgraded version of Leopard implemented in this work) outperforms Leopard with higher scores in terms of AUC, +Recall and -Recall, and can accurately identify more (in)correct patches that cannot be predicted by the classifiers only with learned embeddings or engineered features. Finally, we use an explainable ML technique, SHAP, to empirically interpret how the learned embeddings and engineered features are contributed to the patch correctness prediction. © 2023 Copyright held by the owner/author(s).",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164237362&doi=10.1145%2f3576039&partnerID=40&md5=c5699fa7328a6c7f276d39f9de22523e,ACM Transactions on Software Engineering and Methodology,124,Exclude,E3.2,Does not use graphs itself; code2vec just happens to use them
Tang F.; He P.,Software Defect Prediction using Multi-scale Structural Information,"In recent years, most researches have used the sequence of nodes in the abstract syntax tree (AST) of code to extract features for software defect prediction (SDP). While the AST is a kind of graph data, it may ignore some part of the structural information to use the original graph data as a sequence for input. Thus, Graph neural network (GNN) has been used to extract structural information in SDP. However, existing researches ignore that GNN learning is inherently local. It is difficult to interact between remote nodes and to capture long-term dependencies in source code. We apply a combination model of GNN Transformer to predict the software defects. Using an AST directly as the input, GNN extracts local features and structural information between the node and its neighbors. We then encode the relative and absolute positions of the nodes in the AST. The position encodings are passed into the Transformer along with the feature information extracted by GNN to extract the global features, which are the long-term dependencies between nodes. Finally, the extracted fused features are used in the SDP. Experiments on the PROMISE dataset have shown that our method achieves higher F-measure and better identification of defective features in source code than the state-of-the-art SDP method. © 2023 Copyright held by the owner/author(s).",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168248665&doi=10.1145%2f3594315.3594371&partnerID=40&md5=eebaffafd0ee850460b3597b2d4f44c6,ACM International Conference Proceeding Series,125,Include,I1.1,
Yin Y.; Shi Y.; Zhao Y.; Wahab F.,Multi-graph learning-based software defect location,"Software quality is key to the success of software systems. Modern software systems are growing in their worth based on industry needs and becoming more complex, which inevitably increases the possibility of more defects in software systems. Software repairing is time-consuming, especially locating the source files related to specific software defect reports. To locate defective source files more quickly and accurately, automated software defect location technology is generated and has a huge application value. The existing deep learning-based software defect location method focuses on extracting the semantic correlation between the source file and the corresponding defect reports. However, the extensive code structure information contained in the source files is ignored. To this end, we propose a software defect location method, namely, multi-graph learning-based software defect location (MGSDL). By extracting the program dependency graphs for functions, each source file is converted into a graph bag containing multiple graphs (i.e., multi-graph). Further, a multi-graph learning method is proposed, which learns code structure information from multi-graph to establish the semantic association between source files and software defect reports. Experiments' results on four publicly available datasets, AspectJ, Tomcat, Eclipse UI, and SWT, show that MGSDL improves on average 3.88%, 5.66%, 13.23%, 9.47%, and 3.26% over the competitive methods in five evaluation metrics, rank@10, rank@5, MRR, MAP, and AUC, respectively. © 2023 John Wiley & Sons Ltd.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152077576&doi=10.1002%2fsmr.2552&partnerID=40&md5=05fae7aae53840e8e104ebbedbcab80e,Journal of Software: Evolution and Process,126,Include,I1.1,Borderline; only uses graph2vec
Ma Y.-F.; Du Y.; Li M.,Capturing the Long-Distance Dependency in the Control Flow Graph via Structural-Guided Attention for Bug Localization,"To alleviate the burden of software maintenance, bug localization, which aims to automatically locate the buggy source files based on the bug report, has drawn significant attention in the software mining community. Recent studies indicate that the program structure in source code carries more semantics reflecting the program behavior, which is beneficial for bug localization. Benefiting from the rich structural information in the Control Flow Graph (CFG), CFG-based bug localization methods have achieved the state-of-the-art performance. Existing CFG-based methods extract the semantic feature from the CFG via the graph neural network. However, the step-wise feature propagation in the graph neural network suffers from the problem of information loss when the propagation distance is long, while the long-distance dependency is rather common in the CFG. In this paper, we argue that the long-distance dependency is crucial for feature extraction from the CFG, and propose a novel bug localization model named sgAttention. In sgAttention, a particularly designed structural-guided attention is employed to globally capture the information in the CFG, where features of irrelevant nodes are masked for each node to facilitate better feature extraction from the CFG. Experimental results on four widely-used open-source software projects indicate that sgAttention averagely improves the state-of-the-art bug localization methods by 32.9% and 29.2% and the state-of-the-art pre-trained models by 5.8% and 4.9% in terms of MAP and MRR, respectively. © 2023 International Joint Conferences on Artificial Intelligence. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170357286&partnerID=40&md5=a91320049d84720a0f4e3003c8bc9486,IJCAI International Joint Conference on Artificial Intelligence,127,Include,I1.1,
Lin B.; Wang S.; Wen M.; Mao X.,Context-Aware Code Change Embedding for Better Patch Correctness Assessment,"Despite the capability in successfully fixing more and more real-world bugs, existing Automated Program Repair (APR) techniques are still challenged by the long-standing overfitting problem (i.e., a generated patch that passes all tests is actually incorrect). Plenty of approaches have been proposed for automated patch correctness assessment (APCA). Nonetheless, dynamic ones (i.e., those that needed to execute tests) are time-consuming while static ones (i.e., those built on top of static code features) are less precise. Therefore, embedding techniques have been proposed recently, which assess patch correctness via embedding token sequences extracted from the changed code of a generated patch. However, existing techniques rarely considered the context information and program structures of a generated patch, which are crucial for patch correctness assessment as revealed by existing studies. In this study, we explore the idea of context-Aware code change embedding considering program structures for patch correctness assessment. Specifically, given a patch, we not only focus on the changed code but also take the correlated unchanged part into consideration, through which the context information can be extracted and leveraged. We then utilize the AST path technique for representation where the structure information from AST node can be captured. Finally, based on several pre-defined heuristics, we build a deep learning based classifier to predict the correctness of the patch. We implemented this idea as Cache and performed extensive experiments to assess its effectiveness. Our results demonstrate that Cache can (1) perform better than previous representation learning based techniques (e.g., Cache relatively outperforms existing techniques by 6%, 3%, and 16%, respectively under three diverse experiment settings), and (2) achieve overall higher performance than existing APCA techniques while even being more precise than certain dynamic ones including PATCH-SIM (92.9% vs. 83.0%). Further results reveal that the context information and program structures leveraged by Cache contributed significantly to its outstanding performance.  © 2022 Association for Computing Machinery.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130752121&doi=10.1145%2f3505247&partnerID=40&md5=896d9827ba64bf2c9e1c335c5f5a6100,ACM Transactions on Software Engineering and Methodology,128,Include,I1.1,
Zhou C.; He P.; Zeng C.; Ma J.,Software defect prediction with semantic and structural information of codes based on Graph Neural Networks,"Context: Most defect prediction methods consider a series of traditional manually designed static code metrics. However, only using these hand-crafted features is impractical. Some researchers use the Convolutional Neural Network (CNN) to capture the potential semantic information based on the program's Syntax Trees (ASTs). In recent years, leveraging the dependency relationships between software modules to construct a software network and using network embedding models to capture the structural information have been helpful in defect prediction. This paper simultaneously takes the semantic and structural information into account and proposes a method called CGCN. Objective: This study aims to validate the feasibility and performance of the proposed method in software defect prediction. Method: Abstract Syntax Trees and a Class Dependency Network (CDN) are first generated based on the source code. For ASTs, symbolic tokens are extracted and encoded into vectors. The numerical vectors are then used as input to the CNN to capture the semantic information. For CDN, a Graph Convolutional Network (GCN) is used to learn the structural information of the network automatically. Afterward, the learned semantic and structural information are combined with different weights. Finally, we concatenate the learned features with traditional hand-crafted features to train a classifier for more accurate defect prediction. Results: The proposed method outperforms the state-of-the-art defect prediction models for both within-project prediction (including within-version and cross-version) and cross-project prediction on 21 open-source projects. In general, within-version prediction achieves better performance in the three prediction tasks. Conclusion: The proposed method of combining semantic and structural information can improve the performance of software defect prediction. © 2022 Elsevier B.V.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137157816&doi=10.1016%2fj.infsof.2022.107057&partnerID=40&md5=740103e40f40a306ecea8e7469a5306f,Information and Software Technology,129,Include,I1.1,
Zhu Z.; Tong H.; Wang Y.; Li Y.,Enhancing bug localization with bug report decomposition and code hierarchical network,"Bug localization, which aims to locate buggy source code files for given bug reports, is a crucial yet challenging software-mining task. Despite remarkable success, the state of the art falls short in handling (1) bug reports with diverse characteristics and (2) programs with wildly different behaviors. In response, this paper proposes a graph-based neural model BLOCO for automated bug localization. To be specific, our proposed model decomposes bug reports into several bug clues to capture bug-related information from various perspectives for highly diverse bug reports. To understand the program in depth, we first design a code hierarchical network structure, Code-NoN, based on basic blocks to represent source code files. Correspondingly, a multilayer graph neural network is tailored to capture program behaviors from the Code-NoN structure of each source code file. Finally, BLOCO further incorporates a bi-affine classifier to comprehensively predict the relationship between the bug reports and source files. Extensive experiments on five large-scale real-world projects demonstrate that the proposed model significantly outperforms existing techniques. © 2022 Elsevier B.V.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129970669&doi=10.1016%2fj.knosys.2022.108741&partnerID=40&md5=dcf53451ff1638c350a605c6a6f43b2a,Knowledge-Based Systems,130,Include,I1.1,
Ma Y.-F.; Li M.,The flowing nature matters: feature learning from the control flow graph of source code for bug localization,"Bug localization plays an important role in software maintenance. Traditional works treat the source code from the lexical perspective, while some recent researches indicate that exploiting the program structure is beneficial for improving bug localization. Control flow graph (CFG) is a widely used graph representation, which essentially represents the program structure. Although using graph neural network for feature learning is a straightforward way and has been proven effective in various software mining problems, this approach is inappropriate since adjacent nodes in the CFG could be totally unrelated in semantics. On the other hand, previous statements may affect the semantics of subsequent statements along the execution path, which we call the flowing nature of control flow graph. In this paper, we claim that the flowing nature should be explicitly considered and propose a novel model named cFlow for bug localization, which employs a particular designed flow-based GRU for feature learning from the CFG. The flow-based GRU exploits the program structure represented by the CFG to transmit the semantics of statements along the execution path, which reflects the flowing nature. Experimental results on widely-used real-world software projects show that cFlow significantly outperforms the state-of-the-art bug localization methods, indicating that exploiting the program structure from the CFG with respect to the flowing nature is beneficial for improving bug localization. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124741118&doi=10.1007%2fs10994-021-06078-4&partnerID=40&md5=0b5e48501b89aea5d491f3dc8a1b3770,Machine Learning,131,Include,,
Deng X.; He P.; Zhou C.Y.,Data Selection for Cross-Project Defect Prediction with Local and Global Features of Source Code,"An open challenge for cross-project defect prediction (CPDP) is how to select the most appropriate training data for target project to build quality predictor. To our knowledge, existing methods are mostly dominated by traditional hand-crafted features, which do not fully encode the global structure between codes nor the semantics of code tokens. This work is to propose an improved method which is capable of automatically learning features for representing source code, and uses these feataures for training data selection. First, we propose a framework ALGoF to automatically learn the local semantic and global structural features of code files. Then, we analyze the feasibility of the learned features for data selection. Besides, we also validate the effectiveness of ALGoF by comparing with the traditional method. The experiments have been conducted on six defect datasets available at the PROMISE repository. The results show that ALGoF method helps to guide the training data selection for CPDP, and achieves a 48.31% improvement rate of F-measure. Meanwhile, our method has statistically significant advantages over the traditional method, especially when using both the local semantic and global structural features as the representation of code files. The maximum improvement of F-measure can reach 42.6%. © 2022 Knowledge Systems Institute Graduate School. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137158661&doi=10.18293%2fSEKE2022-086&partnerID=40&md5=4ea2bcb83fee6ceea53c18fb4ca971e3,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",132,Include,I1.1,"Some large details are unclear, but I believe they're simply not in the paper"
Sikic L.; Kurdija A.S.; Vladimir K.; Silic M.,Graph Neural Network for Source Code Defect Prediction,"Predicting defective software modules before testing is a useful operation that ensures that the time and cost of software testing can be reduced. In recent years, several models have been proposed for this purpose, most of which are built using deep learning-based methods. However, most of these models do not take full advantage of a source code as they ignore its tree structure or they focus only on a small part of a code. To investigate whether and to what extent information from this structure can be beneficial in predicting defective source code, we developed an end-to-end model based on a convolutional graph neural network (GCNN) for defect prediction, whose architecture can be adapted to the analyzed software, so that projects of different sizes can be processed with the same level of detail. The model processes the information of the nodes and edges from the abstract syntax tree (AST) of the source code of a software module and classifies the module as defective or not defective based on this information. Experiments on open source projects written in Java have shown that the proposed model performs significantly better than traditional defect prediction models in terms of AUC and F-score. Based on the F-scores of the existing <italic>state-of-the-art</italic> models, the model has shown comparable predictive capabilities for the analyzed projects. © 2022 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123383541&doi=10.1109%2fACCESS.2022.3144598&partnerID=40&md5=6f026f26f6828fe3c1f1e28156cf823d,IEEE Access,133,Include,I1.1,
Shi K.; Lu Y.; Liu G.; Wei Z.; Chang J.,MPT-embedding: An unsupervised representation learning of code for software defect prediction,"Software project defect prediction can help developers allocate debugging resources. Existing software defect prediction models are usually based on machine learning methods, especially deep learning. Deep learning-based methods tend to build end-to-end models that directly use source code-based abstract syntax trees (ASTs) as input. They do not pay enough attention to the front-end data representation. In this paper, we propose a new framework to represent source code called multiperspective tree embedding (MPT-embedding), which is an unsupervised representation learning method. MPT-embedding parses the nodes of ASTs from multiple perspectives and encodes the structural information of a tree into a vector sequence. Experiments on both cross-project defect prediction (CPDP) and within-project defect prediction (WPDP) show that, on average, MPT-embedding provides improvements over the state-of-the-art method. © 2020 John Wiley & Sons, Ltd.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097534520&doi=10.1002%2fsmr.2330&partnerID=40&md5=8dab33d2af777d2aa2c02a0486aa036e,Journal of Software: Evolution and Process,134,Include,I1.1,
Xu J.; Ai J.; Shi T.,Software Defect Prediction for Specific Defect Types based on Augmented Code Graph Representation,"In a software life cycle, improving quality and identifying and repairing defects has become an important research topic. Previous studies have proposed defect prediction based on artificial measurement features, a method whose quality is unfortunately difficult to guarantee. On the other hand, many current studies have attempted to predict all types of defects using a single model, which is difficult to achieve. In this paper, Augmented-CPG, a new code graph representation, is proposed. Based on this representation, a defect region candidate extraction method related to the defect type is proposed. Graphic neural networks are introduced to learn defect features. We carried out experiments on three different types of defects, and the results show that our method can effectively predict specific types of defects. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123502800&doi=10.1109%2fDSA52907.2021.00097&partnerID=40&md5=5212e2ef64a23438c28141c1e4289fd2,"Proceedings - 2021 8th International Conference on Dependable Systems and Their Applications, DSA 2021",135,Include,I1.1,
Tian H.; Liu K.; Kabore A.K.; Koyuncu A.; Li L.; Klein J.; Bissyande T.F.,Evaluating Representation Learning of Code Changes for Predicting Patch Correctness in Program Repair,"A large body of the literature of automated program repair develops approaches where patches are generated to be validated against an oracle (e.g., a test suite). Because such an oracle can be imperfect, the generated patches, although validated by the oracle, may actually be incorrect. While the state of the art explore research directions that require dynamic information or that rely on manually-crafted heuristics, we study the benefit of learning code representations in order to learn deep features that may encode the properties of patch correctness. Our empirical work mainly investigates different representation learning approaches for code changes to derive embeddings that are amenable to similarity computations. We report on findings based on embeddings produced by pre-trained and re-trained neural networks. Experimental results demonstrate the potential of embeddings to empower learning algorithms in reasoning about patch correctness: a machine learning predictor with BERT transformer-based embeddings associated with logistic regression yielded an AUC value of about 0.8 in the prediction of patch correctness on a deduplicated dataset of 1000 labeled patches. Our investigations show that learned representations can lead to reasonable performance when comparing against the state-of-the-art, PATCH-SIM, which relies on dynamic information. These representations may further be complementary to features that were carefully (manually) engineered in the literature. © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090838760&doi=10.1145%2f3324884.3416532&partnerID=40&md5=807aa80dc39926ee3a76b026cd76a328,"Proceedings - 2020 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020",136,Exclude,E1.1,Does not use graphs itself; code2vec just happens to use them
Shi K.; Lu Y.; Chang J.; Wei Z.,PathPair2Vec: An AST path pair-based code representation method for defect prediction,"Software project defect prediction (SDP) can predict the bug probability of software by their features and allocate their testing efforts. The existing software defect prediction methods can be divided into two categories: methods based on traditional handcrafted features and methods based on automatically made abstract features, especially those made by deep learning. The current research indicates that deep learning-based automatic features can achieve better performance than handcrafted features. Code2vec (Alon et al. 2019) is one of the best source code representation models, which leverages deep learning to learn automatic representations from code. In this paper, inspired by code2vec, we propose a new AST path pair-based source code representation method (PathPair2Vec) and apply it to software project defect prediction. We first propose the concept of the short path to describe each terminal node and its control logic. Then, we design a new sequence encoding method to code the different parts of the terminal node and its control logic. Finally, by pairs of short paths, we describe the semantic information of code and fuse them by an attention mechanism. Experiments on the PROMISE dataset show that our method improves the F1 score by 17.88% over the state-of-the-art SDP method, and the AST path pair-based source code representation can better identify the defect features of the source code. © 2020 Elsevier Ltd",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085928963&doi=10.1016%2fj.cola.2020.100979&partnerID=40&md5=2f38eee29116449336d8e934062d0794,Journal of Computer Languages,137,Include,I1.1,
Zhang X.; Lu Y.; Shi K.,CB-Path2Vec: A Cross Block Path Based Representation for Software Defect Prediction,"Software defects are common in software projects and threaten the security of software. Software defect prediction has been proven to be an effective method to solve software security problems, assisting developers in finding potential errors and effectively allocating test resources, in the early stage of the software life cycle. Traditional defect prediction models are designed based on hand-designed metric features, but these features usually cannot capture the semantic and structural information of code. In order to solve this problem, this paper proposes a novel software defect prediction model called CB-Path2Vec, which can automatically learn features composed of Cross Block path for representing source code and use them for software defect prediction. An evaluation on the public PROMISE dataset shows that on average CB-Path2Vec improvements over the state-of-the-art method both on within-project defect prediction (WPDP) and cross-project defect prediction (CPDP). © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101683378&doi=10.1109%2fICCC51575.2020.9344956&partnerID=40&md5=168573d2392fdb2ab881db7e179d77a4,"2020 IEEE 6th International Conference on Computer and Communications, ICCC 2020",138,Include,I1.1,
Yasunaga M.; Liang P.,"Graph-based, self-supervised program repair from diagnostic feedback","We consider the problem of learning to repair programs from diagnostic feedback (e.g., compiler error messages). Program repair is challenging for two reasons: First, it requires reasoning and tracking symbols across source code and diagnostic feedback. Second, labeled datasets available for program repair are relatively small. In this work, we propose novel solutions to these two challenges. First, we introduce a program-feedback graph, which connects symbols relevant to program repair in source code and diagnostic feedback, and then apply a graph neural network on top to model the reasoning process. Second, we present a self-supervised learning paradigm for program repair that leverages unlabeled programs available online to create a large amount of extra program repair examples, which we use to pre-train our models. We evaluate our proposed approach on two applications: correcting introductory programming assignments (DeepFix dataset) and correcting the outputs of program synthesis (SPoC dataset). Our final system, DrRepair, significantly outperforms prior work, achieving 68.2% full repair rate on DeepFix (+22.9% over the prior best), and 48.4% synthesis success rate on SPoC (+3.7% over the prior best). Copyright 2020 by the author(s).",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094774454&partnerID=40&md5=8d54ec79554fc63afde98c2a36893a75,"37th International Conference on Machine Learning, ICML 2020",139,Include,"I1.1,I1.2",
Loyola P.; Matsuo Y.,Learning Feature Representations from Change Dependency Graphs for Defect Prediction,"Given the heterogeneity of the data that can be extracted from the software development process, defect prediction techniques have focused on associating different sources of data with the introduction of faulty code, usually relying on handcrafted features. While these efforts have generated considerable progress over the years, little attention has been given to the fact that the performance of any predictive model depends heavily on the representation of the data used, and that different representations can lead to different results. We consider this a relevant problem, as it could be affecting directly the efforts towards generating safer software systems. Therefore, we propose to study the impact of the representation of the data in defect prediction models. To this end, we focus on the use of developer activity data, from which we structure dependency graphs. Then, instead of manually generating features, such as network metrics, we propose two models inspired by recent advances in representation learning which are able to automatically generate feature representations from graph data. These new representations are compared against manually crafted features for defect prediction in real world software projects. Our results show that automatically learned features are competitive, reaching increments in prediction performance up to 13%. © 2017 IEEE.",Conference paper,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040798659&doi=10.1109%2fISSRE.2017.30&partnerID=40&md5=1717868172cec4ce3bd9499ccd62e29c,"Proceedings - International Symposium on Software Reliability Engineering, ISSRE",140,Include,I1.1,
Orvalho P.; Piepenbrock J.; Janota M.; Manquinho V.,Graph Neural Networks for Mapping Variables Between Programs,"Automated program analysis is a pivotal research domain in many areas of Computer Science - Formal Methods and Artificial Intelligence, in particular. Due to the undecidability of the problem of program equivalence, comparing two programs is highly challenging. Typically, in order to compare two programs, a relation between both programs' sets of variables is required. Thus, mapping variables between two programs is useful for a panoply of tasks such as program equivalence, program analysis, program repair, and clone detection. In this work, we propose using graph neural networks (GNNs) to map the set of variables between two programs based on both programs' abstract syntax trees (ASTs). To demonstrate the strength of variable mappings, we present three use-cases of these mappings on the task of program repair to fix well-studied and recurrent bugs among novice programmers in introductory programming assignments (IPAs). Experimental results on a dataset of 4166 pairs of incorrect/correct programs show that our approach correctly maps 83% of the evaluation dataset. Moreover, our experiments show that the current state-of-the-art on program repair, greatly dependent on the programs' structure, can only repair about 72% of the incorrect programs. In contrast, our approach, which is solely based on variable mappings, can repair around 88.5%. © 2023 The Authors.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175817799&doi=10.3233%2fFAIA230468&partnerID=40&md5=bad761c4241bb9c0564fa129bd2312a8,Frontiers in Artificial Intelligence and Applications,141,Include,"I1.1,I1.2",
Romanov V.; Ivanov V.,Assessing the Importance of Global Relationships for Source Code Analysis Using Graph Neural Networks,"Representing the source code as a sequence of tokens does not capture long-distance dependencies and inter-project dependencies. In this study, we analyze to which extent inter-project (global) relationships can be used in machine learning tasks related to source code analysis. Our findings show that information implicitly stored in inter-project relationships can be used to select the next called function among candidates with an accuracy of 92%. We demonstrate that source code embeddings achieve the best performance on transfer learning tasks when they are computed with graph neural networks in a multitask mode. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164256776&doi=10.1007%2f978-3-031-35501-1_44&partnerID=40&md5=a05fe0297af81215f9c24d1f6f3e2057,Lecture Notes in Networks and Systems,142,Include,,Don't understand the classification tasks
Vytovtov P.; Chuvilin K.,Unsupervised classifying of software source code using graph neural networks,Usually automated programming systems consist of two parts: Source code analysis and source code generation. This paper is focused on the first part. Automated source code analysis can be useful for errors and vulnerabilities searching and for representing source code snippets for further investigating. Also gotten representations can be used for synthesizing source code snippets of certain types. A machine learning approach is used in this work. The training set is formed by augmented abstract syntax trees of Java classes. A graph autoencoder is trained and a latent representation of Java classes graphs is inspected. Experiments showed that the proposed model can split Java classes graphs to common classes with some business logic implementation and interfaces and utility classes. The results are good enough be used for more accurate software source code generation. © 2019 FRUCT.,Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066427020&doi=10.23919%2fFRUCT.2019.8711909&partnerID=40&md5=321504e348d93cb779e51a5c899811fc,"Conference of Open Innovation Association, FRUCT",143,Include,I1.1,Unclear how their networks works _exactly_
Allamanis M.; Brockschmidt M.; Khademi M.,Learning to represent programs with graphs,"Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code’s known sematics. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures. In this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VARNAMING, in which a network attempts to predict the name of a variable given its usage, and VARMISUSE, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VARMISUSE task in many cases. Additionally, our testing showed that VARMISUSE identifies a number of bugs in mature open-source projects. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",Conference paper,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083951710&partnerID=40&md5=db31acc270c475e5034bdd2dae64f154,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",144,Include,I1.1,
Guo J.; Liu J.; Liu X.; Wan Y.; Li L.,Summarizing source code with Heterogeneous Syntax Graph and dual position,"Code summarization attempts to summarize the semantics of source code by automatically producing brief natural-language descriptions. Most existing work proposes to learn from the Abstract Syntax Tree (AST) and plain text of source code for summary generation. However, little attention has been paid to the structural heterogeneity and layout features of source code. In this paper, we present a novel framework titled HETSUM to address these issues. Specifically, a Heterogeneous Syntax Graph (HSG) is first built by designing six types of augmented edges in AST, which indicates the heterogeneous structure of source code. Meanwhile, a dual position is designed for each token in the source code by considering the layout information. Moreover, we develop a heterogeneous graph neural network in HETSUM to encode the HSG while extracting the code layout features with the Transformer encoder. By assimilating the learned code token vectors into the HSG encoder, HETSUM can capture the relations between its two encoders for improved code representation. To facilitate the generation of high-quality summaries, we integrate a copying mechanism into the decoding procedure while expanding the Transformer decoding sublayer. Extensive experiments on the Java and Python datasets prove that HETSUM is superior to seventeen state-of-the-art baselines. To promote reproducibility studies, we make the implementation of HETSUM available at https://github.com/GJCEXP/HETSUM. © 2023 Elsevier Ltd",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166740779&doi=10.1016%2fj.ipm.2023.103415&partnerID=40&md5=dc4459ca66428a5d71d2096ab6bda77c,Information Processing and Management,145,Include,"I1.1,I1.2",
Guo J.; Liu J.; Liu X.; Li L.,Summarizing source code through heterogeneous feature fusion and extraction,"Code summarization, which seeks to automatically produce a succinct natural-language description to summarize the functionality of source code, plays an essential role in maintaining the software. Currently, plentiful approaches have been proposed to first encode the source code based on its Abstract Syntax Tree (AST), and then decode it into a textual summary. However, most existing works interpret the AST-based syntax structure as a homogeneous graph, without discriminating the different relations between graph nodes (e.g., the parent–child and sibling relations) in a heterogeneous way. To mitigate this issue, this paper proposes HETCOS to extract the syntactic and sequential features of source code by exploring its inherent heterogeneity for code summarization. Specifically, we first build a Heterogeneous Code Graph (HCG) that fuses the syntax structure and code sequence with eight types of edges/relations designed between graph nodes. Moreover, we present a heterogeneous graph neural network for capturing the diverse relations in HCG. The represented HCG is then fed into a Transformer decoder, followed by a multi-head attention-based copying mechanism to support high-quality summary generation. Extensive experiments on the major Java and Python datasets illustrate the superiority of our approach over sixteen state-of-the-art baselines. To promote reproducibility studies, we make the implementation of HETCOS publicly accessible at https://github.com/GJCEXP/HETCOS. © 2023 Elsevier B.V.",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175065989&doi=10.1016%2fj.inffus.2023.102058&partnerID=40&md5=09eece79fe63cf31d6e773c7b9b352cd,Information Fusion,146,Include,"I1.1,I1.2",
Shi C.; Cai B.; Zhao Y.; Gao L.; Sood K.; Xiang Y.,CoSS: Leveraging Statement Semantics for Code Summarization,"Automated code summarization tools allow generating descriptions for code snippets in natural language, which benefits software development and maintenance. Recent studies demonstrate that the quality of generated summaries can be improved by using additional code representations beyond token sequences. The majority of contemporary approaches mainly focus on extracting code syntactic and structural information from abstract syntax trees (ASTs). However, from the view of macro-structures, it is challenging to identify and capture semantically meaningful features due to fine-grained syntactic nodes involved in ASTs. To fill this gap, we investigate how to learn more code semantics and control flow features from the perspective of code statements. Accordingly, we propose a novel model entitled CoSS for code summarization. CoSS adopts a Transformer-based encoder and a graph attention network-based encoder to capture token-level and statement-level semantics from code token sequence and control flow graph, respectively. Then, after receiving two-level embeddings from encoders, a joint decoder with a multi-head attention mechanism predicts output sequences verbatim. Performance evaluations on Java, Python, and Solidity datasets validate that CoSS outperforms nine state-of-the-art (SOTA) neural code summarization models in effectiveness and is competitive in execution efficiency. Further, the ablation study reveals the contribution of each model component.  © 1976-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151331220&doi=10.1109%2fTSE.2023.3256362&partnerID=40&md5=f688da43a2e74f73561d98236d57f320,IEEE Transactions on Software Engineering,147,Include,I1.1,
Zeng J.; Qu Z.; Cai B.,Structure and Sequence Aligned Code Summarization with Prefix and Suffix Balanced Strategy,"Source code summarization focuses on generating qualified natural language descriptions of a code snippet (e.g., functionality, usage and version). In an actual development environment, descriptions of the code are missing or not consistent with the code due to human factors, which makes it difficult for developers to comprehend and conduct subsequent maintenance. Some existing methods generate summaries from the sequence information of code without considering the structural information. Recently, researchers have adopted the Graph Neural Networks (GNNs) to capture the structural information with modified Abstract Syntax Trees (ASTs) to comprehensively represent a source code, but the alignment method of the two information encoder is hard to decide. In this paper, we propose a source code summarization model named SSCS, a unified transformer-based encoder–decoder architecture, for capturing structural and sequence information. SSCS is designed upon a structure-induced transformer with three main novel improvements. SSCS captures the structural information in a multi-scale aspect with an adapted fusion strategy and adopts a hierarchical encoding strategy to capture the textual information from the perspective of the document. Moreover, SSCS utilizes a bidirectional decoder which generates a summary from opposite direction to balance the generation performance between prefix and suffix. We conduct experiments on two public Java and Python datasets to evaluate our method and the result show that SSCS outperforms the state-of-art code summarization methods. © 2023 by the authors.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156244162&doi=10.3390%2fe25040570&partnerID=40&md5=e6b87370ba5285c63b699000de0567f2,Entropy,148,Include,I1.1,
Guo J.; Liu J.; Liu X.; Wan Y.; Zhao Y.; Li L.; Liu K.; Klein J.; Bissyandé T.F.,PyScribe–Learning to describe python code,"Code comment generation, which attempts to summarize the functionality of source code in textual descriptions, plays an important role in automatic software development research. Currently, several structural neural networks have been exploited to preserve the syntax structure of source code based on abstract syntax trees (ASTs). However, they can not well capture both the long-distance and local relations between nodes while retaining the overall structural information of AST. To mitigate this problem, we present a prototype tool titled PyScribe, which extends the Transformer model to a new encoder-decoder-based framework. Particularly, the triplet position is designed and integrated into the node-level and edge-level structural features of AST for producing Python code comments automatically. This paper, to the best of our knowledge, makes the first effort to model the edges of AST as an explicit component for improved code representation. By specifying triplet positions for each node and edge, the overall structural information can be well preserved in the learning process. Moreover, the captured node and edge features go through a two-stage decoding process to yield higher qualified comments. To evaluate the effectiveness of PyScribe, we resort to a large dataset of code-comment pairs by mining Jupyter Notebooks from GitHub, for which we have made it publicly available to support further studies. The experimental results reveal that PyScribe is indeed effective, outperforming the state-ofthe-art by achieving an average BLEU score (i.e., av-BLEU) of (Formula presented.) 0.28. © 2023 The Authors. Software: Practice and Experience published by John Wiley & Sons Ltd.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179352137&doi=10.1002%2fspe.3291&partnerID=40&md5=a6f06e9e93298b54afb8224fcc63ac0b,Software - Practice and Experience,149,Include,I1.1,
Zeng J.; He Y.; Zhang T.; Xu Z.; Han Q.,CLG-Trans: Contrastive learning for code summarization via graph attention-based transformer,"Automated code summarization is the task of automatically generating natural language descriptions of source code, which is an important research topic in the software engineering field. Many methods in recent studies were based on deep learning techniques, which effectively improve the performance of code summarization. Most of the existing code summarization methods use different kinds of neural networks to learn source code information. Some methods use graph neural network (GNN) to represent abstract syntax tree (AST) and fuse the structural information of source code. However, these methods still have two important issues: 1) they cannot solve the Out-Of-Vocabulary (OOV) problem effectively; 2) the structural information of source code they can capture is limited. In order to address the above-mentioned challenges, we propose a novel automated code summarization model named CLG-Trans in this work. This model uses the Byte Pair Encoding (BPE) algorithm and pointer-generator network to tackle the OOV problem. Then it utilizes the fusion of contrastive learning strategy and dynamic graph attention mechanism to effectively capture rich structure information of source code sequences. Experimental results on Funcom dataset show that CLG-Trans outperforms seven state-of-the-art models (i.e., Hybrid-DRL, Ast-Attendgru, Transformer, codeGnn, Rencos, CodeBERT and SIT) by averagely increasing 19.48% and 13.17% on BLEU scores and ROUGUE-L score, respectively. In addition, CLG-Trans achieves an improvement of 16.14% and 4.70% in BLEU scores and ROUGE-L score compared with our previously proposed model DG-Trans. © 2023 Elsevier B.V.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146339240&doi=10.1016%2fj.scico.2023.102925&partnerID=40&md5=4eafb730187cf493a6ec32d10b197f44,Science of Computer Programming,150,Include,I1.1,
Li J.; Wang X.; Lyu C.,ACAGNN: Source Code Representation Based on Fine-Grained Multi-view Program Features,"Existing program comprehension models represent a single code feature and coarse code granularity. They tend to consider the shal- low features of source code (e.g., method names, characters, etc.) and ignore the structured features of source code such as Abstract Syntax Tree (AST), Control Flow Graph (CFG), and Application Programming Interface Dependency Graph (ADG), resulting in an incomplete representation of the source code. Although there are approaches to model ASTs, ASTs are efficient in representing code structure information. They have shortcomings in capturing the calling relationships of methods in the code for the entire class library, which does not allow the model to represent the global program accurately. To address these issues, we propose a multi-view source code representation model called ACAGNN, which uses a designed matching mechanism to learn multi-view code structure representation at the node-level and apply it to downstream code classification tasks. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161117660&doi=10.1007%2f978-981-99-2385-4_36&partnerID=40&md5=06b6e73732a56c7c7766badf6fe78300,Communications in Computer and Information Science,151,Include,I1.1,
Hou S.; Chen L.; Ju M.; Ye Y.,Leveraging Comment Retrieval for Code Summarization,"Open-source code often suffers from mismatched or missing comments, leading to difficult code comprehension, and burdening software development and maintenance. In this paper, we design a novel code summarization model CodeFiD to address this laborious challenge. Inspired by retrieval-augmented methods for open-domain question answering, CodeFiD first retrieves a set of relevant comments from code collections for a given code, and then aggregates presentations of code and these comments to produce a natural language sentence that summarizes the code behaviors. Different from current code summarization works that focus on improving code representations, our model resorts to external knowledge to enhance code summarizing performance. Extensive experiments on public code collections demonstrate the effectiveness of CodeFiD by outperforming state-of-the-art counterparts across all programming languages. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150987296&doi=10.1007%2f978-3-031-28238-6_34&partnerID=40&md5=6b4efb2dcea0bc40895b46fe4b046810,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),152,Exclude,E3.3,
Lu X.; Niu J.,Enhancing source code summarization from structure and semantics,"Source code summarization aims to generate concise and high-quality natural language descriptions for code snippets. High-quality code summaries can help developers better understand source codes. Researchers have made great efforts to generate more accurate summaries; however, due to the lack of preservation of source code structure and semantics, previous approaches have struggled to generate summaries that accurately describe the functionality or other major characteristics of codes. In this paper, we propose a novel approach called Code Structure and Semantic Fusion (CSSF) for automatically generating summaries for source code. CSSF can utilize both the structural and semantic information of source codes. To achieve this, we extract the overall structure of the Abstract Syntax Tree (AST) by expanding the AST and using a heterogeneous graph attention network. Furthermore, we use an additional sequence model to obtain the semantic information of the code fragment. Finally, we fuse the two kinds of information through a novel modality fusion method. We evaluate our approach on a widely used Java dataset; experimental results confirm that our approach outperforms existing methods. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169592244&doi=10.1109%2fIJCNN54540.2023.10191872&partnerID=40&md5=04716b0190a2fc92ed349a9eef4cdb7e,Proceedings of the International Joint Conference on Neural Networks,153,Include,I1.1,
Kuang L.; Zhou C.; Yang X.,Code comment generation based on graph neural network enhanced transformer model for code understanding in open-source software ecosystems,"In open-source software ecosystems, the scale of source code is getting larger and larger, and developers often use various methods (good code comments or method names, etc.) to make the code easier to read and understand. However, high-quality code comments or method names are often unavailable due to tight project schedules or other reasons in open-source software ecosystems such as Github. Therefore, in this work, we try to use deep learning models to generate appropriate code comments or method names to help software development and maintenance, which requires a non-trivial understanding of the code. Therefore, we propose a Graph neural network enhanced Transformer model (GTrans for short) to learn code representation to understand code better. Specifically, GTrans learns code representation from code sequences and graphs. We use a Transformer encoder to capture the global representation from code sequence and a graph neural network (GNN) encoder to focus on the local details in the code graph, and then use a decoder to combine both global and local representations by attention mechanism. We use three public datasets collected from GitHub to evaluate our model. In an extensive evaluation, we show that GTrans outperforms the state-of-the-art models up to 3.8% increase in METEOR metrics on code comment generation and outperforms the state-of-the-art models by margins of 5.8%–9.4% in ROUGE metrics on method name generation after some adjustments on the structure. Empirically, we find the method name generation task depends on more local information than global, and the code comment generation task is in contrast. Our data and code are available at https://github.com/zc-work/GTrans. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132075222&doi=10.1007%2fs10515-022-00341-1&partnerID=40&md5=92dc28fb349520100fd5fb371068b6b3,Automated Software Engineering,154,Include,I1.1,
Kuang L.; Ge F.; Zhang L.,Suggesting method names based on graph neural network with salient information modelling,"Descriptive method names have a great impact on improving program readability and facilitating software maintenance. Recently, due to high similarity between the task of method naming and text summarization, large amount of research based on natural language processing has been conducted to generate method names. However, method names are much shorter compared to long source code sequences. The salient information of the whole code snippet account for an relatively small part. Additionally, unlike natural language, source code has complicated structure information. Thus, modelling the salient information from highly structured input presents a great challenge. To tackle this problem, we propose a graph neural network (GNN)-based model with a novel salient information selection layer. Specifically, to comprehensively encode the tokens of the source code, we employ a GNN-based encoder, which can be directly applied to the code graph to ensure that the syntactic information of code structure and semantic information of code sequence can be modelled sufficiently. To effectively discriminate the salient information, we introduce an information selection layer which contains two parts: a global filter gate used to filter irrelevant information, and a semantic-aware convolutional layer used to focus on the semantic information contained in code sequence. To improve the precision of the copy mechanism when decoding, we introduce a salient feature enhanced attention mechanism to facilitate the accuracy of copying tokens from input. Experimental results on an open source dataset indicate that our proposed model, equipped with the salient information selection layer, can effectively improve method naming performance compared to other state-of-the-art models. © 2022 John Wiley & Sons Ltd.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129806202&doi=10.1111%2fexsy.13030&partnerID=40&md5=8030820388d4b8b9471db9601604bba6,Expert Systems,155,Include,I1.1,
Wu B.; Liang B.; Zhang X.,Turn tree into graph: Automatic code review via simplified AST driven graph convolutional network,"Automatic code review (ACR), which can relieve the costs of manual inspection, is an indispensable and essential task in software engineering. To deal with ACR, existing work is to serialize the abstract syntax tree (AST). However, making sense of the whole AST with sequence encoding approach is a daunting task, mostly due to some redundant nodes in AST hinder the transmission of node information. Not to mention that the serialized representation is inadequate to grasp the information of tree structure in AST. In this paper, we first present a new large-scale Apache Automatic Code Review (AACR) dataset for ACR task since there is still no publicly available dataset in this task. The release of this dataset would push forward the research in this field. Based on it, we propose a novel Simplified AST based Graph Convolutional Network (SimAST-GCN) to deal with ACR task. Concretely, to improve the efficiency of node information dissemination, we first simplify the AST of code by deleting the redundant nodes that do not contain connection attributes, and thus deriving a Simplified AST. Then, we construct a relation graph for each code based on the Simplified AST to properly embody the relations among code fragments of the tree structure into the graph. Subsequently, in the light of the merit of graph structure, we explore a graph convolution networks architecture that follows an attention mechanism to leverage the crucial implications of code fragments to derive code representations. Finally, we exploit a simple but effective subtraction operation in the representations between the original and revised code, enabling the revised difference to be preferably learned for deciding the results of ACR. Experimental results on the AACR dataset illustrate that our proposed model outperforms the state-of-the-art methods. © 2022 Elsevier B.V.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134877579&doi=10.1016%2fj.knosys.2022.109450&partnerID=40&md5=ca398d0bbf9b948417125efb4f7e9d55,Knowledge-Based Systems,156,Include,I1.1,
Zhou Y.; Shen J.; Zhang X.; Yang W.; Han T.; Chen T.,Automatic source code summarization with graph attention networks,"Source code summarization aims to generate concise descriptions for code snippets in a natural language, thereby facilitates program comprehension and software maintenance. In this paper, we propose a novel approach–GSCS–to automatically generate summaries for Java methods, which leverages both semantic and structural information of the code snippets. To this end, GSCS utilizes Graph Attention Networks to process the tokenized abstract syntax tree of the program, which employ a multi-head attention mechanism to learn node features in diverse representation sub-spaces, and aggregate features by assigning different weights to its neighbor nodes. GSCS further harnesses an additional RNN-based sequence model to obtain the semantic features and optimizes the structure by combining its output with a transformed embedding layer. We evaluate our approach on two widely-adopted Java datasets; the experiment results confirm that GSCS outperforms the state-of-the-art baselines. © 2022 Elsevier Inc.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126290388&doi=10.1016%2fj.jss.2022.111257&partnerID=40&md5=e3f7e6aa4ea01ae7593bda0c338965ec,Journal of Systems and Software,157,Include,I1.1,
Qu Z.; Hu Y.; Zeng J.; Cai B.; Yang S.,Method Name Generation Based on Code Structure Guidance,"The proper names of software engineering functions and methods can greatly assist developers in understanding and maintaining the code. Most researchers convert the method name generation task into the text summarization task. They take the token sequence and the abstract syntax tree (AST) of source code as input, and generate method names with a decoder. However, most proposed models learn semantic and structural features of the source code separately, resulting in poor performance in the method name generation task. Actually, each token in source code must have a corresponding node in its AST. Inspired by this observation, we propose SGMNG, a structure-guided method name generation model that learns the representation of two combined features. Additionally, we build a code graph called code relation graph (CRG) to describe the code structure clearly. CRG retains the structure of the AST of source code and contains data flows and control flows. SGMNG captures the semantic features of the code by encoding the token sequence and captures the structural features of the code by encoding the CRG. Then, SGMNG matches tokens in the sequence and nodes in the CRG to construct the combination of two features. We demonstrate the effectiveness of the proposed approach on the public dataset Java-Small with 700K samples, which indicates that our approach achieves significant improvement over the state-of-the-art baseline models in the ROUGE metric.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135770882&doi=10.1109%2fSANER53432.2022.00127&partnerID=40&md5=900a09371c404e9dc1383cf4e06642b7,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",158,Include,was TODO,
Guo J.; Liu J.; Wan Y.; Li L.; Zhou P.,Modeling Hierarchical Syntax Structure with Triplet Position for Source Code Summarization,"Automatic code summarization, which aims to describe the source code in natural language, has become an essential task in software maintenance. Our fellow researchers have attempted to achieve such a purpose through various machine learning-based approaches. One key challenge keeping these approaches from being practical lies in the lacking of retaining the semantic structure of source code, which has unfortunately been overlooked by the state-of-the-art methods. Existing approaches resort to representing the syntax structure of code by modeling the Abstract Syntax Trees (ASTs). However, the hierarchical structures of ASTs have not been well explored. In this paper, we propose CODESCRIBE to model the hierarchical syntax structure of code by introducing a novel triplet position for code summarization. Specifically, CODESCRIBE leverages the graph neural network and Transformer to preserve the structural and sequential information of code, respectively. In addition, we propose a pointer-generator network that pays attention to both the structure and sequential tokens of code for a better summary generation. Experiments on two real-world datasets in Java and Python demonstrate the effectiveness of our proposed approach when compared with several state-of-the-art baselines. © 2022 Association for Computational Linguistics.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139035948&partnerID=40&md5=75c1f5cac559ddb1ae026364e3707e4a,Proceedings of the Annual Meeting of the Association for Computational Linguistics,159,Include,Borderline not an earlier version of 149/198,
Wang X.; Wu Q.; Zhang H.; Lyu C.; Jiang X.; Zheng Z.; Lyu L.; Hu S.,HELoC: Hierarchical Contrastive Learning of Source Code Representation,"Abstract syntax trees (ASTs) play a crucial role in source code representation. However, due to the large number of nodes in an AST and the typically deep AST hierarchy, it is challenging to learn the hierarchical structure of an AST effectively. In this paper, we propose HELoC, a hierarchical contrastive learning model for source code representation. To effectively learn the AST hierarchy, we use contrastive learning to allow the network to predict the AST node level and learn the hierarchical relationships between nodes in a self-supervised manner, which makes the representation vectors of nodes with greater differences in AST levels farther apart in the embedding space. By using such vectors, the structural similarities between code snippets can be measured more precisely. In the learning process, a novel GNN (called Residual Self-attention Graph Neural Network, RSGNN) is designed, which enables HELoC to focus on embedding the local structure of an AST while capturing its overall structure. HELoC is self-supervised and can be applied to many source code related downstream tasks such as code classification, code clone detection, and code clustering after pre-training. Our extensive experiments demonstrate that HELoC outperforms the state-of-the-art source code representation models.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133210433&doi=10.1145%2f3524610.3527896&partnerID=40&md5=d8f8aab6c1c776d3d977371794cf1a1c,IEEE International Conference on Program Comprehension,160,Include,I1.1,
Hou S.; Chen L.; Ye Y.,Summarizing Source Code from Structure and Context,"Modern software developers tend to engage in social coding platforms to reuse code snippets to expedite the development process, while the codes on such platforms are often suffering from comments being mismatched, missing or outdated. This puts the code search and comprehension in difficulty, and increases the burden of maintenance for software building upon these codes. As summarizing code is beneficial yet it is very expensive for manual operation, in this paper, we elaborate an automatic and effective code summarization paradigm to address this laborious challenge. We represent a given code snippet as an abstract syntax tree (AST), and generate a set of compositional root-to-leaf paths to make the AST accessible regarding code context and structure in a less complex yet expressive way. Accordingly, we design a tree-based transformer model, called TreeXFMR, on these paths to summarize source code in a hierarchical attention operation. This yields two advantages on code representation learning: (1) attention mechanisms at token-and path-level attend the semantics and interactions of source code from different aspects; (2) bi-level positional encodings introduced reveal the intra- and inter-path structure of AST and improve the unambiguity of the representations. During decoding, TreeXFMR attends such learned representations to produce each output of natural language word. We further pre-train the transformer to achieve faster and better training convergence results. Extensive experiments on the code collection from GitHub demonstrate the effectiveness of TreeXFMR, which significantly outperforms state-of-the-art baselines. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140713399&doi=10.1109%2fIJCNN55064.2022.9892013&partnerID=40&md5=5f620b70d83f1491fb0fcaeaf72aadaf,Proceedings of the International Joint Conference on Neural Networks,161,Include,I1.1,
Jin D.; Liu P.; Zhu Z.,Automatically Generating Code Comment Using Heterogeneous Graph Neural Networks,"Code summarization aims to generate readable summaries that describe the functionality of source code pieces. The main purpose of the code summarization is to help software developers understand the code and save their precious time. However, since programming languages are highly structured, it is challenging to generate high-quality code summaries. For this reason, this paper proposes a new approach named CCHG to automatically generate code comments. Compared to recent models that use additional information such as Abstract Syntax Trees as input, our proposed method only uses the most original code as input. We believe that programming languages are the same as natural languages. Each line of code is equivalent to a sentence, representing an independent meaning. Therefore, we split the entire code snippet into several sentence-level code. Coupled with token-level code, there are two types of code that need to be processed. So we propose heterogeneous graph networks to process the sentence-level and token-level code. Even though we do not introduce additional structural knowledge, the experimental results show that our model has a considerable performance, which indicates that our model can fully learn structural information and sequence information from code snippets.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135841227&doi=10.1109%2fSANER53432.2022.00125&partnerID=40&md5=ca88a884cb1bb226fb8db79ee007e615,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",162,Include,"I1.1,I1.2?",
Zhang F.; Chen B.; Li R.; Peng X.,A hybrid code representation learning approach for predicting method names,"Program semantic properties such as class names, method names, and variable names and types play an important role in software development and maintenance. Method names are of particular importance because they provide the cornerstone of abstraction for developers to communicate with each other for various purposes (e.g., code review and program comprehension). Existing method name prediction approaches often represent code as lexical tokens or syntactical AST (abstract syntax tree) paths, making them difficult to learn code semantics and hindering their effectiveness in predicting method names. Initial attempts have been made to represent code as execution traces to capture code semantics, but suffer scalability in collecting execution traces. In this paper, we propose a hybrid code representation learning approach, named METH2SEQ, to encode a method as a sequence of distributed vectors. METH2SEQ represents a method as (1) a bag of paths on the program dependence graph, (2) a sequence of typed intermediate representation statements and (3) a sentence of natural language comment, to scalably capture code semantics. The learned sequence of vectors of a method is fed to a decoder model to predict method names. Our evaluation with a dataset of 280.5K methods in 67 Java projects has demonstrated that METH2SEQ outperforms the two state-of-the-art code representation learning approaches in F1-score by 92.6% and 36.6%, while also outperforming two state-of-the-art method name prediction approaches in F1-score by 85.6% and 178.1%. © 2021 Elsevier Inc.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107616552&doi=10.1016%2fj.jss.2021.111011&partnerID=40&md5=e96fd839823d7d7ff6490f49b2347f9b,Journal of Systems and Software,163,Include,I1.1,
Ge F.; Kuang L.,Keywords Guided Method Name Generation,"High quality method names are descriptive and readable, which are helpful for code development and maintenance. The majority of recent research suggest method names based on the text summarization approach. They take the token sequence and abstract syntax tree of the source code as input, and generate method names through a powerful neural network based model. However, the tokens composing the method name are closely related to the entity name within its method implementation. Actually, high proportions of the tokens in method name can be found in its corresponding method implementation, which makes it possible for incorporating these common shared token information to improve the performance of method naming task. Inspired by this key observation, we propose a two-stage keywords guided method name generation approach to suggest method names. Specifically, we decompose the method naming task into two subtasks, including keywords extraction task and method name generation task. For the keywords extraction task, we apply a graph neural network based model to extract the keywords from source code. For the method name generation task, we utilize the extracted keywords to guide the method name generation model. We apply a dual selective gate in encoder to control the information flow, and a dual attention mechanism in decoder to combine the semantics of input code sequence and keywords. Experiment results on an open source dataset demonstrate that keywords guidance can facilitate method naming task, which enables our model to outperform the competitive state-of-The-Art models by margins of 1.5%-3.5% in ROUGE metrics. Especially when programs share one common token with method names, our approach improves the absolute ROUGE-1 score by 7.8%.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113196338&doi=10.1109%2fICPC52881.2021.00027&partnerID=40&md5=3fd814c4f9f0acd066e3e0edeede365e,IEEE International Conference on Program Comprehension,164,Include,I1.1,
Liu S.; Chen Y.; Xie X.; Siow J.; Liu Y.,RETRIEVAL-AUGMENTED GENERATION FOR CODE SUMMARIZATION VIA HYBRID GNN,"Source code summarization aims to generate natural language summaries from structured code snippets for better understanding code functionalities. However, automatic code summarization is challenging due to the complexity of the source code and the language gap between the source code and natural language summaries. Most previous approaches either rely on retrieval-based (which can take advantage of similar examples seen from the retrieval database, but have low generalization performance) or generation-based methods (which have better generalization performance, but cannot take advantage of similar examples). This paper proposes a novel retrieval-augmented mechanism to combine the benefits of both worlds. Furthermore, to mitigate the limitation of Graph Neural Networks (GNNs) on capturing global graph structure information of source code, we propose a novel attention-based dynamic graph to complement the static graph representation of the source code, and design a hybrid message passing GNN for capturing both the local and global structural information. To evaluate the proposed approach, we release a new challenging benchmark, crawled from diversified large-scale open-source C projects (total 95k+ unique functions in the dataset). Our method achieves the state-of-the-art performance, improving existing methods by 1.42, 2.44 and 1.29 in terms of BLEU-4, ROUGE-L and METEOR. © 2021 ICLR 2021 - 9th International Conference on Learning Representations. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121205001&partnerID=40&md5=a4d297a0cd465773b6670095c2fff13e,ICLR 2021 - 9th International Conference on Learning Representations,165,Include,I1.1,
Zhang X.; Yang S.; Duan L.; Lang Z.; Shi Z.; Sun L.,Transformer-XL with Graph Neural Network for Source Code Summarization,"Source code summarization is the task of generating a readable natural language to describe the functionality of source code. Code summarization is rapidly expanding, especially as the research takes great advantage of advances in neural networks and artificial intelligence technologies. Some mainstream methods input the structural information (abstract syntax tree (AST)) of the source code into the language model to generate relatively satisfactory comments. However, existing methods can not capture code's long dependencies from AST for effective code summarization. In this paper, we provide a novel way to generate code summaries by combining a graph-based neural network and a Transformer-XL network. We utilize the graph-based neural network to better capture the structure information of AST, and the Transformer-XL network to learn important tokens in the AST and alleviate the problem of long dependency. We evaluate our technique on the standard Java dataset. The experimental results show that the effectiveness of our model is remarkable. It pushes the precision score to 60.73% (5.21% absolute improvement) and the F1 score to 51.06%.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124318560&doi=10.1109%2fSMC52423.2021.9658619&partnerID=40&md5=03ee09ce85de4e698cecdde03bb3d2ba,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",166,Include,I1.1,
Zeng J.; Zhang T.; Xu Z.,DG-Trans: Automatic Code Summarization via Dynamic Graph Attention-based Transformer,"Automatic code summarization is an important topic in the software engineering field, which aims to automatically generate the description for the source code. Based on Graph Neural Networks (GNN), most existing methods apply them to Abstract Syntax Tree (AST) to achieve code summarization. However, these methods face two major challenges: 1) they can only capture limited structural information of the source code; 2) they did not effectively solve Out-Of-Vocabulary (OOV) problems by reducing vocabulary size. In order to resolve these problems, in this paper, we propose a novel code summarization model named Dynamic Graph attention-based Transformer (DG-Trans for short), which effectively captures abundant information of the code subword sequence and utilizes the fusion of dynamic graph attention mechanism and Transformer. Extensive experiments show that DG-Trans is able to outperform state-of-the-art models (such as Ast-Attendgru, Transformer, and CodeGNN) by averagely increasing 8.39% and 8.86% on BLEU scores and ROUGUE-L, respectively. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146199326&doi=10.1109%2fQRS54544.2021.00088&partnerID=40&md5=1d7eda6868c42c29189049d9fd3a7224,"IEEE International Conference on Software Quality, Reliability and Security, QRS",167,Include,I1.1,Very similar to 150/199; small difference in the encoder
Lu M.; Liu Y.; Li H.; Tan D.; He X.; Bi W.; Li W.,Hyperbolic function embedding: Learning hierarchical representation for functions of source code in hyperbolic space,"Recently, source code mining has received increasing attention due to the rapid increase of open-sourced code repositories and the tremendous values implied in this large dataset, which can help us understand the organization of functions or classes in different software and analyze the impact of these organized patterns on the software behaviors. Hence, learning an effective representation model for the functions of source code, from a modern view, is a crucial problem. Considering the inherent hierarchy of functions, we propose a novel hyperbolic function embedding (HFE) method, which can learn a distributed and hierarchical representation for each function via the Poincaré ball model. To achieve this, a function call graph (FCG) is first constructed to model the call relationship among functions. To verify the underlying geometry of FCG, the Ricci curvature model is used. Finally, an HFE model is built to learn the representations that can capture the latent hierarchy of functions in the hyperbolic space, instead of the Euclidean space, which are usually used in those state-of-the-art methods. Moreover, HFE is more compact in terms of lower dimensionality than the existing graph embedding methods. Thus, HFE is more effective in terms of computation and storage. To experimentally evaluate the performance of HFE, two application scenarios, namely, function classification and link prediction, have been applied. HFE achieves up to 7.6% performance improvement compared to the chosen state-of-the-art methods, namely, Node2vec and Struc2vec. © 2019 by the authors.",Article,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061872138&doi=10.3390%2fsym11020254&partnerID=40&md5=6c5c53d9c208b17eb6077ad1121a8f2b,Symmetry,168,Include,I1.1,
Du C.; Li Y.; Wang Y.; Yu J.,Study on Automatic Code Summary Generation Method based on Graph Neural Network,"Automatic code summary generation techniques can help developers and other technical personnel to understand and comprehend the functions and structure of code more quickly. In existing methods of automatic code abstraction generation, there is a problem of poor utilization of code structure information, therefore, a model of automatic code abstraction generation based on graph neural network is proposed. Firstly, the abstract syntax tree is extracted from the code, and then the abstract syntax tree of the code is transformed into a graph representation using control flow statements in the data stream, which is trained by a graph convolutional neural network, and the obtained training results are fused with the original sequence representation to finally obtain a source code representation that incorporates the semantic information of the code context and structural information. Meanwhile, to improve the stability of the summary generation model, a deep learning model based on a multi-headed self-attentive mechanism is used to improve the existing sequence-to-sequence summary generation model. The accuracy and stability of the model-generated summaries are improved. Validation was performed on publicly available datasets, and experimental results show that the method achieves better results on BLEU-4, METEOR, and ROUGE-L metrics compared to other baseline models.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179505390&doi=10.1109%2fDSA59317.2023.00015&partnerID=40&md5=0ec978da5b42e327c8a031c00cb980f3,"Proceedings - 2023 10th International Conference on Dependable Systems and Their Applications, DSA 2023",169,Include,I1.1,was TODO
Yang G.; Jin T.; Dou L.,Heterogeneous Directed Hypergraph Neural Network over abstract syntax tree (AST) for Code Classification,"Code classification is a difficult issue in program understanding and automatic coding. Due to the elusive syntax and complicated semantics in programs, most existing studies use techniques based on abstract syntax tree (AST) and graph neural network (GNN) to create code representations for code classification. These techniques utilize the structure and semantic information of the code, but they only take into account pairwise associations and neglect the high-order correlations that already exist between nodes in the AST, which may result in the loss of code structural information. On the other hand, while a general hypergraph can encode high-order data correlations, it is homogeneous and undirected which will result in a lack of semantic and structural information such as node types, edge types, and directions between child nodes and parent nodes when modeling AST. In this study, we propose to represent AST as a heterogeneous directed hypergraph (HDHG) and process the graph by heterogeneous directed hypergraph neural network (HDHGN) for code classification. Our method improves code understanding and can represent high-order data correlations beyond paired interactions. We assess heterogeneous directed hypergraph neural network (HDHGN) on public datasets of Python and Java programs. Our method outperforms previous AST-based and GNN-based methods, which demonstrates the capability of our model. © 2023 Knowledge Systems Institute Graduate School. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170092438&doi=10.18293%2fSEKE2023-136&partnerID=40&md5=0db69ae8a2a9b72d28c356d2d0fef154,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",170,Include,"I1.1,I1.2",
Long T.; Xie Y.; Chen X.; Zhang W.; Cao Q.; Yu Y.,Multi-View Graph Representation for Programming Language Processing: An Investigation into Algorithm Detection,"Program representation, which aims at converting program source code into vectors with automatically extracted features, is a fundamental problem in programming language processing (PLP). Recent work tries to represent programs with neural networks based on source code structures. However, such methods often focus on the syntax and consider only one single perspective of programs, limiting the representation power of models. This paper proposes a multi-view graph (MVG) program representation method. MVG pays more attention to code semantics and simultaneously includes both data flow and control flow as multiple views. These views are then combined and processed by a graph neural network (GNN) to obtain a comprehensive program representation that covers various aspects. We thoroughly evaluate our proposed MVG approach in the context of algorithm detection, an important and challenging subfield of PLP. Specifically, we use a public dataset POJ-104 and also construct a new challenging dataset ALG-109 to test our method. In experiments, MVG outperforms previous methods significantly, demonstrating our model's strong capability of representing source code. © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147550181&partnerID=40&md5=59c88dcae8e71c3b1db0eb1776516e66,"Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022",171,Include,"I1.1,I1.2",
Zhang K.; Wang W.; Zhang H.; Li G.; Jin Z.,Learning to Represent Programs with Heterogeneous Graphs,"Code representation, which transforms programs into vectors with semantics, is essential for source code processing. We have witnessed the effectiveness of incorporating structural information (i.e., graph) into code representations in recent years. Specifically, the abstract syntax tree (AST) and the AST-augmented graph of the program contain much structural and semantic information, and most existing studies apply them for code representation. The graph adopted by existing approaches is homogeneous, i.e., it discards the type information of the edges and the nodes lying within AST. That may cause plausible obstruction to the representation model. In this paper, we propose to leverage the type information in the graph for code representation. To be specific, we propose the heterogeneous program graph (HPG), which provides the types of the nodes and the edges explicitly. Furthermore, we employ the heterogeneous graph transformer (HGT) architecture to generate representations based on HPG, considering the type of information during processing. With the additional types in HPG, our approach can capture complex structural information, produce accurate and delicate representations, and finally perform well on certain tasks. Our in-depth evaluations upon four classic datasets for two typical tasks (i.e., method name prediction and code classification) demonstrate that the heterogeneous types in HPG benefit the representation models. Our proposed HPG+HGT also outperforms the SOTA baselines on the subject tasks and datasets.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133172400&doi=10.1145%2f3524610.3527905&partnerID=40&md5=67576308d1c90ff9f1cafa4129a545ce,IEEE International Conference on Program Comprehension,172,Include,"I1.1,I1.2",
Wu Q.; Jiang X.; Zheng Z.; Gao X.; Lyu C.; Lyu L.,Code Representation Based on Hybrid Graph Modelling,"Several sequence- or abstract syntax tree (AST)-based models have been proposed for modelling lexical-level and syntactic-level information of source code. However, an effective method of learning code semantic information is still lacking. Thus, we propose a novel code representation method based on hybrid graph modelling, called HGCR. HGCR is a code information extraction model. Specifically, in HGCR, two novel graphs, the Structure Graph (SG) and the Execution Data Flow Graph (EDFG), are first extracted from AST to model the syntactic structural and semantic information of source code, respectively. Then, two improved graph neural networks are applied to learn the graphs to obtain an effective code representation. We demonstrate the effectiveness of our model on two common code understanding tasks: code classification and code clone detection. Empirically, our model outperforms state-of-the-art models. © 2021, Springer Nature Switzerland AG.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121904967&doi=10.1007%2f978-3-030-92307-5_35&partnerID=40&md5=b4be88d3b89f31e430c408dceff98715,Communications in Computer and Information Science,173,Include,"I1.1,I1.2",
Bhuiyan M.H.M.,The Call Graph Chronicles: Unleashing the Power Within,"Call graph generation is critical for program understanding and analysis, but achieving both accuracy and precision is challenging. Existing methods trade off one for the other, particularly in dy- namic languages like JavaScript. This paper introduces ""Graphia,""an approach that combines structural and semantic information using a Graph Neural Network (GNN) to enhance call graph accu- racy. Graphia's two-step process employs an initial call graph as training data for the GNN, which then uncovers true call edges in new programs. Experimental results show Graphia significantly improves true positive rates in vulnerability detection, achieving up to 95%. This approach advances call graph accuracy by effectively incorporating code structure and context, particularly in complex dynamic language scenarios. © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180550989&doi=10.1145%2f3611643.3617854&partnerID=40&md5=35176d270a32379943dcc133e5f657ac,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,174,Exclude,E1.8,
Wen X.-C.; Chen Y.; Gao C.; Zhang H.; Zhang J.M.; Liao Q.,Vulnerability Detection with Graph Simplification and Enhanced Graph Representation Learning,"Prior studies have demonstrated the effectiveness of Deep Learning (DL) in automated software vulnerability detection. Graph Neural Networks (GNNs) have proven effective in learning the graph representations of source code and are commonly adopted by existing DL-based vulnerability detection methods. However, the existing methods are still limited by the fact that GNNs are essentially difficult to handle the connections between long-distance nodes in a code structure graph. Besides, they do not well exploit the multiple types of edges in a code structure graph (such as edges representing data flow and control flow). Consequently, despite achieving state-of-the-art performance, the existing GNN-based methods tend to fail to capture global information (i.e., long-range dependencies among nodes) of code graphs. To mitigate these issues, in this paper, we propose a novel vulnerability detection framework with grAph siMplification and enhanced graph rePresentation LEarning, named AMPLE. AMPLE mainly contains two parts: 1) graph simplification, which aims at reducing the distances between nodes by shrinking the node sizes of code structure graphs; 2) enhanced graph representation learning, which involves one edge-aware graph convolutional network module for fusing heterogeneous edge information into node representations and one kernel-scaled representation module for well capturing the relations between distant graph nodes. Experiments on three public benchmark datasets show that AMPLE outperforms the state-of-the-art methods by 0.39%-35.32% and 7.64%-199.81% with respect to the accuracy and F1 score metrics, respectively. The results demonstrate the effectiveness of AMPLE in learning global information of code graphs for vulnerability detection. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171196046&doi=10.1109%2fICSE48619.2023.00191&partnerID=40&md5=10fc8fedd7bbaa32d682dafa677fb841,Proceedings - International Conference on Software Engineering,175,Include,I1.1,
Wang K.; Yan M.; Zhang H.; Hu H.,Unified Abstract Syntax Tree Representation Learning for Cross-Language Program Classification,"Program classification can be regarded as a high-level abstraction of code, laying a foundation for various tasks related to source code comprehension, and has a very wide range of applications in the field of software engineering, such as code clone detection, code smell classification, defects classification, etc. The cross-language program classification can realize code transfer in different programming languages, and can also promote cross-language code reuse, thereby helping developers to write code quickly and reduce the development time of code transfer. Most of the existing studies focus on the semantic learning of the code, whilst few studies are devoted to cross-language tasks. The main challenge of cross-language program classification is how to extract semantic features of different programming languages. In order to cope with this difficulty, we propose a Unified Abstract Syntax Tree (namely UAST in this paper) neural network. In detail, the core idea of UAST consists of two unified mechanisms. First, UAST learns an AST representation by unifying the AST traversal sequence and graph-like AST structure for capturing semantic code features. Second, we construct a mechanism called unified vocabulary, which can reduce the feature gap between different programming languages, so it can achieve the role of cross-language program classification. Besides, we collect a dataset containing 20,000 files of five programming languages, which can be used as a benchmark dataset for the cross-language program classification task. We have done experiments on two datasets, and the results show that our proposed approach out-performs the state-of-the-art baselines in terms of four evaluation metrics (Precision, Recall, F1-score, and Accuracy).  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133153756&doi=10.1145%2f3524610.3527915&partnerID=40&md5=39053c8e722b50b94b0c9375c39fd15b,IEEE International Conference on Program Comprehension,176,Include,I1.1,
Lu M.; Wang Y.; Tan D.; Zhao L.,Student Program Classification Using Gated Graph Attention Neural Network,"Source code mining has received increasing attention, among which code classification plays a significant role in code understanding and automatic coding. Most source code mining efforts aim at the source code of projects, which are usually large and standardized, but less for student programs. There are two differences between project codes and student programs. On the one hand, some work on project codes is based on relatively single information, which is far from enough for student programs. Because student programs are relatively small, which makes them contain less information. Consequently, it is necessary to mine as much information as possible in student programs. On the other hand, the variable or function naming and the structure of the student programs are usually irregular, as compared with the source codes of projects. To learn from student programs, we proposed a Graph Neural Network (GNN) based model, which integrates data flow and function call information to the Abstract Syntax Tree (AST), and applies an improved GNN model to the integrated graph to achieve the state-of-art student program classification accuracy. The experiment results have shown that the proposed work can classify student programs with accuracy over 97%. © 2013 IEEE.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117607455&doi=10.1109%2fACCESS.2021.3063475&partnerID=40&md5=26575eb8c4dfa836f1de5454370cb284,IEEE Access,177,Include,I1.1,
Shi E.; Wang Y.; Du L.; Zhang H.; Han S.; Zhang D.; Sun H.,CoCoAST: Representing Source Code via Hierarchical Splitting and Reconstruction of Abstract Syntax Trees,"Recently, machine learning techniques especially deep learning techniques have made substantial progress on some code intelligence tasks such as code summarization, code search, clone detection, etc. How to represent source code to effectively capture the syntactic, structural, and semantic information is a key challenge. Recent studies show that the information extracted from abstract syntax trees (ASTs) is conducive to code representation learning. However, existing approaches fail to fully capture the rich information in ASTs due to the large size/depth of ASTs. In this paper, we propose a novel model CoCoAST that hierarchically splits and reconstructs ASTs to comprehensively capture the syntactic and semantic information of code without the loss of AST structural information. First, we hierarchically split a large AST into a set of subtrees and utilize a recursive neural network to encode the subtrees. Then, we aggregate the embeddings of subtrees by reconstructing the split ASTs to get the representation of the complete AST. Finally, we combine AST representation carrying the syntactic and structural information and source code embedding representing the lexical information to obtain the final neural code representation. We have applied our source code representation to two common program comprehension tasks, code summarization and code search. Extensive experiments have demonstrated the superiority of CoCoAST. To facilitate reproducibility, our data and code are available https://github.com/s1530129650/CoCoAST . © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173621153&doi=10.1007%2fs10664-023-10378-9&partnerID=40&md5=c13a0a2c7d54cce36d56f84297dc75a7,Empirical Software Engineering,178,Include,I1.1,
Yang J.; Fu C.; Deng F.; Wen M.; Guo X.; Wan C.,Toward Interpretable Graph Tensor Convolution Neural Network for Code Semantics Embedding,"Intelligent deep learning-based models have made significant progress for automated source code semantics embedding, and current research works mainly leverage natural language-based methods and graph-based methods. However, natural language-based methods do not capture the rich semantic structural information of source code, and graph-based methods do not utilize rich distant information of source code due to the high cost of message-passing steps.In this article, we propose a novel interpretable model, called graph tensor convolution neural network (GTCN), to generate accurate code embedding, which is capable of comprehensively capturing the distant information of code sequences and rich code semantics structural information. First, we propose to utilize a high-dimensional tensor to integrate various heterogeneous code graphs with node sequence features, such as control flow, data flow. Second, inspired by the current advantages of graph-based deep learning and efficient tensor computations, we propose a novel interpretable graph tensor convolution neural network for learning accurate code semantic embedding from the code graph tensor. Finally, we evaluate three popular applications on the GTCN model: variable misuse detection, source code prediction, and vulnerability detection. Compared with current state-of-the-art methods, our model achieves higher scores with respect to the top-1 accuracy while costing less training time.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168769136&doi=10.1145%2f3582574&partnerID=40&md5=ba7fac921dc538ffe1e6a93800dcd2d5,ACM Transactions on Software Engineering and Methodology,179,Include,I1.1,
Zhang G.; Merrill M.A.; Liu Y.; Heer J.; Althoff T.,CORAL: COde RepresentAtion learning with weakly-supervised transformers for analyzing data analysis,"Large scale analysis of source code, and in particular scientific source code, holds the promise of better understanding the data science process, identifying analytical best practices, and providing insights to the builders of scientific toolkits. However, large corpora have remained unanalyzed in depth, as descriptive labels are absent and require expert domain knowledge to generate. We propose a novel weakly supervised transformer-based architecture for computing joint representations of code from both abstract syntax trees and surrounding natural language comments. We then evaluate the model on a new classification task for labeling computational notebook cells as stages in the data analysis process from data import to wrangling, exploration, modeling, and evaluation. We show that our model, leveraging only easily-available weak supervision, achieves a 38% increase in accuracy over expert-supplied heuristics and outperforms a suite of baselines. Our model enables us to examine a set of 118,000 Jupyter Notebooks to uncover common data analysis patterns. Focusing on notebooks with relationships to academic articles, we conduct the largest study of scientific code to date and find that notebooks which devote an higher fraction of code to the typically labor-intensive process of wrangling data in expectation exhibit decreased citation counts for corresponding papers. We also show significant differences between academic and non-academic notebooks, including that academic notebooks devote substantially more code to wrangling and exploring data, and less on modeling. © 2022, The Author(s).",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126774781&doi=10.1140%2fepjds%2fs13688-022-00327-9&partnerID=40&md5=a8e32194694d6166b5290864d0fc7867,EPJ Data Science,180,Include,"I1.1,I1.2",
Yang K.; Yu H.; Fan G.; Yang X.; Huang Z.,A graph sequence neural architecture for code completion with semantic structure features,"Code completion plays an important role in intelligent software development for accelerating coding efficiency. Recently, the prediction models based on deep learning have achieved good performance in code completion task. However, the existing models cannot avoid three drawbacks: (i) In the existing models, the code representation loses the information (parent–child information between nodes) and lacks many effective features (orientation between nodes). (ii) The known code structure information is not fully utilized, which will cause the model to generate completely irrelevant results. (iii) Simple sequence modeling ignores repeated patterns and structural information. Besides, previous works cannot capture the characteristics of correlation and directionality between nodes. In this paper, we propose a Code Completion approach named CC-GGNN, which is graph model based on Gated Graph Neural Networks (GGNNs) to address the problems. We introduce a new architecture to obtain the effective code features from code representation. In order to utilize the known information, we propose Classification Mechanism, which classifies the representation of the node using the known parent node and constructs training graph in the model. The experimental results show that our model outperforms the state-of-the-art methods MRR@5 at most 9.2% and ACC at most 11.4% in datasets. © 2022 John Wiley & Sons, Ltd.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122136280&doi=10.1002%2fsmr.2414&partnerID=40&md5=970b6c7fa148f561f4d2147c0e4ad322,Journal of Software: Evolution and Process,181,Exclude,We don´t understand the graph construction in the paper,don't understand the graph construction 
Zügner D.; Kirschstein T.; Catasta M.; Leskovec J.; Günnemann S.,LANGUAGE-AGNOSTIC REPRESENTATION LEARNING OF SOURCE CODE FROM STRUCTURE AND CONTEXT,"Source code (Context) and its parsed abstract syntax tree (AST; Structure) are two complementary representations of the same computer program. Traditionally, designers of machine learning models have relied predominantly either on Structure or Context. We propose a new model, which jointly learns on Context and Structure of source code. In contrast to previous approaches, our model uses only language-agnostic features, i.e., source code and features that can be computed directly from the AST. Besides obtaining state-of-the-art on monolingual code summarization on all five programming languages considered in this work, we propose the first multilingual code summarization model. We show that jointly training on non-parallel data from multiple programming languages improves results on all individual languages, where the strongest gains are on low-resource languages. Remarkably, multilingual training only from Context does not lead to the same improvements, highlighting the benefits of combining Structure and Context for representation learning on code. © 2021 ICLR 2021 - 9th International Conference on Learning Representations. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149138769&partnerID=40&md5=4e233116ed104a3bb5d58e031d653e5b,ICLR 2021 - 9th International Conference on Learning Representations,182,Include,,code summarization
Tang B.; Li B.; Bo L.; Wu X.; Cao S.; Sun X.,GrasP: Graph-to-Sequence Learning for Automated Program Repair,"Many deep learning models, for example, neural machine translation (NMT) models, have been developed for Automated Program Repair (APR). Due to the advantages of NMT model's strong generalization ability and less manual in-tervention, NMT-based methods perform well in APR. However, previous NMT-based APR approaches regard a code snippet as a sequence of tokens, which ignores the inherent structure of code. In this paper, we propose a novel end-to-end approach with Graph-to-Sequence learning, GrasP, to generate patches for buggy methods. To better represent the buggy method, we use a graph based on abstract syntax tree (AST) to represent the source code. In order to learn complex graph representation, we introduce the attention-based encoder-decoder model for graph-to-sequence learning. The empirical evaluation on the popular benchmark Defects4J shows that GrasP can generate compilable patches for 75 bugs, of which 34 patches are correct. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146199863&doi=10.1109%2fQRS54544.2021.00091&partnerID=40&md5=6bc06b1dda865890b178f523886edc45,"IEEE International Conference on Software Quality, Reliability and Security, QRS",183,Include,,
Liu L.; Nguyen H.; Karypis G.; Sengamedu S.,Universal Representation for Code,"Learning from source code usually requires a large amount of labeled data. Despite the possible scarcity of labeled data, the trained model is highly task-specific and lacks transferability to different tasks. In this work, we present effective pre-training strategies on top of a novel graph-based code representation, to produce universal representations for code. Specifically, our graph-based representation captures important semantics between code elements (e.g., control flow and data flow). We pre-train graph neural networks on the representation to extract universal code properties. The pre-trained model then enables the possibility of fine-tuning to support various downstream applications. We evaluate our model on two real-world datasets – spanning over 30M Java methods and 770K Python methods. Through visualization, we reveal discriminative properties in our universal code representation. By comparing multiple benchmarks, we demonstrate that the proposed framework achieves state-of-the-art results on method name prediction and code graph link prediction. © 2021, Springer Nature Switzerland AG.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111035967&doi=10.1007%2f978-3-030-75768-7_2&partnerID=40&md5=4ef743435f71959828255e3974d6b29c,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),184,Include,"I1.1,I1.2",
Du Y.; Yu Z.,Pre-training Code Representation with Semantic Flow Graph for Effective Bug Localization,"Enlightened by the big success of pre-training in natural language processing, pre-trained models for programming languages have been widely used to promote code intelligence in recent years. In particular, BERT has been used for bug localization tasks and impressive results have been obtained. However, these BERT-based bug localization techniques suffer from two issues. First, the pre-trained BERT model on source code does not adequately capture the deep semantics of program code. Second, the overall bug localization models neglect the necessity of large-scale negative samples in contrastive learning for representations of changesets and ignore the lexical similarity between bug reports and changesets during similarity estimation. We address these two issues by 1) proposing a novel directed, multiple-label code graph representation named Semantic Flow Graph (SFG), which compactly and adequately captures code semantics, 2) designing and training SemanticCodeBERT based on SFG, and 3) designing a novel Hierarchical Momentum Contrastive Bug Localization technique (HMCBL). Evaluation results show that our method achieves state-of-the-art performance in bug localization. © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171247925&doi=10.1145%2f3611643.3616338&partnerID=40&md5=e08baefee4d93ec33ea9e8ad9a0cf336,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,185,Include,I1.1,
Lin Z.; Li G.; Zhang J.; Deng Y.; Zeng X.; Zhang Y.; Wan Y.,XCode: Towards Cross-Language Code Representation with Large-Scale Pre-Training,"Source code representation learning is the basis of applying artificial intelligence to many software engineering tasks such as code clone detection, algorithm classification, and code summarization. Recently, many works have tried to improve the performance of source code representation from various perspectives, e.g., introducing the structural information of programs into latent representation. However, when dealing with rapidly expanded unlabeled cross-language source code datasets from the Internet, there are still two issues. Firstly, deep learning models for many code-specific tasks still suffer from the lack of high-quality labels. Secondly, the structural differences among programming languages make it more difficult to process multiple languages in a single neural architecture.To address these issues, in this article, we propose a novel Cross-language Code representation with a large-scale pre-Training (XCode) method. Concretely, we propose to use several abstract syntax trees and ELMo-enhanced variational autoencoders to obtain multiple pre-Trained source code language models trained on about 1.5 million code snippets. To fully utilize the knowledge across programming languages, we further propose a Shared Encoder-Decoder (SED) architecture which uses the multi-Teacher single-student method to transfer knowledge from the aforementioned pre-Trained models to the distilled SED. The pre-Trained models and SED will cooperate to better represent the source code. For evaluation, we examine our approach on three typical downstream cross-language tasks, i.e., source code translation, code clone detection, and code-To-code search, on a real-world dataset composed of programming exercises with multiple solutions. Experimental results demonstrate the effectiveness of our proposed approach on cross-language code representations. Meanwhile, our approach performs significantly better than several code representation baselines on different downstream tasks in terms of multiple automatic evaluation metrics.  © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130754433&doi=10.1145%2f3506696&partnerID=40&md5=b2c60159ed514b3de7d7cdd2aaa6e896,ACM Transactions on Software Engineering and Methodology,186,Include,I1.1,don't fully understand code search task
Wang D.; Yu Y.; Li S.; Dong W.; Wang J.; Qing L.,MulCode: A Multi-task Learning Approach for Source Code Understanding,"Recent years have witnessed the significant rise of Deep Learning (DL) techniques applied to source code. Researchers exploit DL for a multitude of tasks and achieve impressive results. However, most tasks are explored separately, resulting in a lack of generalization of the solutions. In this work, we propose MulCode, a multi-task learning approach for source code understanding that learns unified representation space for tasks, with the pre-trained BERT model for the token sequence and the Tree-LSTM model for abstract syntax trees. Furthermore, we integrate two source code views into a hybrid representation via the attention mechanism and set learnable uncertainty parameters to adjust the tasks' relationship.We train and evaluate MulCode in three downstream tasks: comment classification, author attribution, and duplicate function detection. In all tasks, MulCode outperforms the state-of-the-art techniques. Moreover, experiments on three unseen tasks demonstrate the generalization ability of MulCode compared with state-of-the-art embedding methods. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106562192&doi=10.1109%2fSANER50967.2021.00014&partnerID=40&md5=19013a3e0211265450216dfea0cf9212,"Proceedings - 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2021",187,Include,I1.1,
Liu S.; Xie X.; Siow J.; Ma L.; Meng G.; Liu Y.,GraphSearchNet: Enhancing GNNs via Capturing Global Dependencies for Semantic Code Search,"Code search aims to retrieve accurate code snippets based on a natural language query to improve software productivity and quality. With the massive amount of available programs such as (on GitHub or Stack Overflow), identifying and localizing the precise code is critical for the software developers. In addition, Deep learning has recently been widely applied to different code-related scenarios, e.g., vulnerability detection, source code summarization. However, automated deep code search is still challenging since it requires a high-level semantic mapping between code and natural language queries. Most existing deep learning-based approaches for code search rely on the sequential text i.e., feeding the program and the query as a flat sequence of tokens to learn the program semantics while the structural information is not fully considered. Furthermore, the widely adopted Graph Neural Networks (GNNs) have proved their effectiveness in learning program semantics, however, they also suffer the problem of capturing the global dependencies in the constructed graph, which limits the model learning capacity. To address these challenges, in this paper, we design a novel neural network framework, named GraphSearchNet, to enable an effective and accurate source code search by jointly learning the rich semantics of both source code and natural language queries. Specifically, we propose to construct graphs for the source code and queries with bidirectional GGNN (BiGGNN) to capture the local structural information of the source code and queries. Furthermore, we enhance BiGGNN by utilizing the multi-head attention module to supplement the global dependencies that BiGGNN missed to improve the model learning capacity. The extensive experiments on Java and Python programming language from the public benchmark CodeSearchNet confirm that GraphSearchNet outperforms current state-of-the-art works by a significant margin.  © 1976-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147215823&doi=10.1109%2fTSE.2022.3233901&partnerID=40&md5=4f9fb5cff1da1852cf94db76ca82598e,IEEE Transactions on Software Engineering,188,Include,I1.1,
Cai B.; Yu Y.; Hu Y.,CSSAM: Code Search via Attention Matching of Code Semantics and Structures,"Code search greatly improves developers' coding efficiency by retrieving reusable code segments with natural language queries. Despite the continuous efforts in improving both the effectiveness and efficiency of code search, two issues remained unsolved. First, programming languages have inherent strong structural linkages, and feature mining of code as text form would omit the structural information contained inside it. Second, there is a potential semantic relationship between code and query, it is challenging to align code and text across sequences so that vectors are spatially consistent during similarity matching.To tackle both issues, in this paper, a code search model named CSSAM (Code Semantics and Structures Attention Matching) is proposed. By introducing semantic and structural matching mechanisms, CSSAM effectively extracts and fuses multidimensional code features. Specifically, the cross and co-attention layer was developed to facilitate high-latitude spatial alignment of code and query at the token level. By leveraging the residual interaction, a matching module is designed to preserve more code semantics and descriptive features, which enhances the relevance between the code and its corresponding query text. Besides, to improve the model's comprehension of the code's inherent structure, a code representation structure named CSRG (Code Semantic Representation Graph) is proposed for jointly representing abstract syntax tree nodes and the data flow of the codes. According to the experimental results on two publicly available datasets containing 475k and 330k code segments, CSSAM significantly outperforms the baselines in terms of achieving the highest SR@1/5/10, MRR, and NDCG@50 on both datasets, respectively. Moreover, the ablation study is conducted to quantitatively measure the impact of each key component of CSSAM on the efficiency and effectiveness of code search, which offers insights into the improvement of advanced code search solutions. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160518672&doi=10.1109%2fSANER56733.2023.00045&partnerID=40&md5=7e48b84e94fed7f1284f7dfb216876a4,"Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",189,Include,"I1.1,I1.2",
Bibi N.; Maqbool A.; Rana T.; Afzal F.; Akgul A.; Eldin S.M.,Enhancing Semantic Code Search With Deep Graph Matching,"The job of discovering appropriate code snippets against a natural language query is an important task for software developers. Appropriate code retrieval increases software productivity and quality as well. In contrast to traditional information retrieval techniques, code search necessitates bridging the semantic breach between programming languages and natural language to search code fragments. Deep neural networks for search codes have recently been a hot topic in research. The standard neural code quest approaches present source code and query in the form of text as independent embedding, then calculate the semantic similarity between them using vector distance (e.g., using cosine similarity). Although recent research utilized query and code snippets during code search, it overlooked the contained rich semantic information and deep structural features between them. In this study, we are also dealing with the problem of code search by providing a deep neural solution that facilitates software developers during software development. Our proposed model effectively used neural graph matching and a searching approach for semantic code retrieval. It first converts both query and code fragments in graph format and then the semantic matching module is used to facilitate the process of matching that will retrieve the best-matched code snippets. It not only exploits the enriched semantic meanings and features, but it also uses the cross-attention mechanism to learn the fine-grained similarity that exists between query and code. The proposed model's evaluation is done using the Codesearchnet dataset with six representative programming languages. It provides comparatively good results as compared to existing baselines. It enables users to find required code snippets, and ranking is used to retrieve top 10 results. The accuracy of the proposed system is approximately 97%.  © 2013 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153339400&doi=10.1109%2fACCESS.2023.3263878&partnerID=40&md5=21f77dc33aad580599fa5861d5673b96,IEEE Access,190,Include,I1.1,
Shi Y.; Yin Y.; Wang Z.; Lo D.; Zhang T.; Xia X.; Zhao Y.; Xu B.,How to better utilize code graphs in semantic code search?,"Semantic code search greatly facilitates software reuse, which enables users to find code snippets highly matching user-specified natural language queries. Due to the rich expressive power of code graphs (e.g., control-flow graph and program dependency graph), both of the two mainstream research works (i.e., multi-modal models and pre-trained models) have attempted to incorporate code graphs for code modelling. However, they still have some limitations: First, there is still much room for improvement in terms of search effectiveness. Second, they have not fully considered the unique features of code graphs. In this paper, we propose a Graph-to-Sequence Converter, namely G2SC. Through converting the code graphs into lossless sequences, G2SC enables to address the problem of small graph learning using sequence feature learning and capture both the edges and nodes attribute information of code graphs. Thus, the effectiveness of code search can be greatly improved. In particular, G2SC first converts the code graph into a unique corresponding node sequence by a specific graph traversal strategy. Then, it gets a statement sequence by replacing each node with its corresponding statement. A set of carefully designed graph traversal strategies guarantee that the process is one-to-one and reversible. G2SC enables capturing rich semantic relationships (i.e., control flow, data flow, node/relationship properties) and provides learning model-friendly data transformation. It can be flexibly integrated with existing models to better utilize the code graphs. As a proof-of-concept application, we present two G2SC enabled models: GSMM (G2SC enabled multi-modal model) and GSCodeBERT (G2SC enabled CodeBERT model). Extensive experiment results on two real large-scale datasets demonstrate that GSMM and GSCodeBERT can greatly improve the state-of-the-art models MMAN and GraphCodeBERT by 92% and 22% on R@1, and 63% and 11.5% on MRR, respectively.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143074294&doi=10.1145%2f3540250.3549087&partnerID=40&md5=3fff757818bd06978797e83b1081d809,ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,191,Include,I1.2,
Zhao W.; Liu Y.,Utilizing Edge Attention in Graph-Based Code Search,"Code search refers to searching code snippets with specific functions in a large codebase according to natural language description. Classic code search approaches, using information retrieval technologies, fail to utilize code semantics and bring noisy and irrelevant. During the last recent years, there has been an ample increase in the number of deep learning-based approaches, which embeds lexical semantics into unified vectors to achieve higher-level mapping between natural language queries and source code. However, these approaches are struggling with how to mine and utilize deep code semantics. In this work, we study how to leverage deeper source code semantics in graph-based source code search, given graph-based representation is a promising way of capturing program and has rich explainability. We propose a novel code search approach called EAGCS (Edge Attention-based Graph Code Search), which is composed of a novel code graph representation method called APDG (Advanced Program Dependence Graph) and a graph neural network called EAGGNN (Edge Attention-based GGNN) which can learn the latent code semantics of APDG. Experiment results demonstrate that our model outperforms the GGNN-based search model and DeepCS. Moreover, our comparison study shows that different edge enhancement strategies have different contributions to learning the code semantics. © 2022 Knowledge Systems Institute Graduate School. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137157657&doi=10.18293%2fSEKE2022-078&partnerID=40&md5=5a5fdb1837e9cbd46a4d24033f0e7cb9,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",192,Include,"I1.1,I1.2",
Ling X.; Wu L.; Wang S.; Pan G.; Ma T.; Xu F.; Liu A.X.; Wu C.; Ji S.,Deep Graph Matching and Searching for Semantic Code Retrieval,"Code retrieval is to find the code snippet from a large corpus of source code repositories that highly matches the query of natural language description. Recent work mainly uses natural language processing techniques to process both query texts (i.e., human natural language) and code snippets (i.e., machine programming language), however, neglecting the deep structured features of query texts and source codes, both of which contain rich semantic information. In this article, we propose an end-to-end deep graph matching and searching (DGMS) model based on graph neural networks for the task of semantic code retrieval. To this end, we first represent both natural language query texts and programming language code snippets with the unified graph-structured data, and then use the proposed graph matching and searching model to retrieve the best matching code snippet. In particular, DGMS not only captures more structural information for individual query texts or code snippets, but also learns the fine-grained similarity between them by cross-attention based semantic matching operations. We evaluate the proposed DGMS model on two public code retrieval datasets with two representative programming languages (i.e., Java and Python). Experiment results demonstrate that DGMS significantly outperforms state-of-the-art baseline models by a large margin on both datasets. Moreover, our extensive ablation studies systematically investigate and illustrate the impact of each part of DGMS. © 2021 ACM.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108944290&doi=10.1145%2f3447571&partnerID=40&md5=14c8a672080f2758dab68933fd5645df,ACM Transactions on Knowledge Discovery from Data,193,Include,Continues work from 190/253,
Wan Y.; Shu J.; Sui Y.; Xu G.; Zhao Z.; Wu J.; Yu P.,Multi-modal attention network learning for semantic source code retrieval,"Code retrieval techniques and tools have been playing a key role in facilitating software developers to retrieve existing code fragments from available open-source repositories given a user query (e.g., a short natural language text describing the functionality for retrieving a particular code snippet). Despite the existing efforts in improving the effectiveness of code retrieval, there are still two main issues hindering them from being used to accurately retrieve satisfiable code fragments from large-scale repositories when answering complicated queries. First, the existing approaches only consider shallow features of source code such as method names and code tokens, but ignoring structured features such as abstract syntax trees (ASTs) and control-flow graphs (CFGs) of source code, which contains rich and well-defined semantics of source code. Second, although the deep learning-based approach performs well on the representation of source code, it lacks the explainability, making it hard to interpret the retrieval results and almost impossible to understand which features of source code contribute more to the final results. To tackle the two aforementioned issues, this paper proposes MMAN, a novel Multi-Modal Attention Network for semantic source code retrieval. A comprehensive multi-modal representation is developed for representing unstructured and structured features of source code, with one LSTM for the sequential tokens of code, a Tree-LSTM for the AST of code and a GGNN (Gated Graph Neural Network) for the CFG of code. Furthermore, a multi-modal attention fusion layer is applied to assign weights to different parts of each modality of source code and then integrate them into a single hybrid representation. Comprehensive experiments and analysis on a large-scale real-world dataset show that our proposed model can accurately retrieve code snippets and outperforms the state-of-the-art methods. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074667252&doi=10.1109%2fASE.2019.00012&partnerID=40&md5=091ed6e4921d176bf474c05372e6bc36,"Proceedings - 2019 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019",194,Include,I1.1,
Mehrotra N.; Sharma A.; Jindal A.; Purandare R.,Improving Cross-Language Code Clone Detection via Code Representation Learning and Graph Neural Networks,"Code clone detection is an important aspect of software development and maintenance. The extensive research in this domain has helped reduce the complexity and increase the robustness of source code, thereby assisting bug detection tools. However, the majority of the clone detection literature is confined to a single language. With the increasing prevalence of cross-platform applications, functionality replication across multiple languages is common, resulting in code fragments having similar functionality but belonging to different languages. Since such clones are syntactically unrelated, single language clone detection tools are not applicable in their case. In this article, we propose a semi-supervised deep learning-based tool Rubhus, capable of detecting clones across different programming languages. Rubhus uses the control and data flow enriched abstract syntax trees (ASTs) of code fragments to leverage their syntactic and structural information and then applies graph neural networks (GNNs) to extract this information for the task of clone detection. We demonstrate the effectiveness of our proposed system through experiments conducted over datasets consisting of Java, C, and Python programs and evaluate its performance in terms of precision, recall, and F1 score. Our results indicate that Rubhus outperforms the state-of-the-art cross-language clone detection tools.  © 1976-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171552856&doi=10.1109%2fTSE.2023.3311796&partnerID=40&md5=184af2dea409f1cc30a0e20bdf4e97d8,IEEE Transactions on Software Engineering,195,Include,I1.1,
Yu D.; Yang Q.; Chen X.; Chen J.; Xu Y.,Graph-based code semantics learning for efficient semantic code clone detection,"Recent studies have shown that high-quality code semantics learning can effectively improve the performance of code clone detection. However, existing approaches suffer from two major drawbacks: (a) insufficient utilization of code representations, leading to inefficient semantics learning, and (b) low efficiency of clone detection, resulting in massive detection time. Therefore, we are motivated to propose an efficient semantics learning method while speeding up the detection process. Specifically, to address the first one, we adopt either CFG (Control Flow Graph) or PDG (Program Dependency Graph) as our initial code representation because of their rich semantic information. Further, we propose a novel graph-based code semantics learning method, which can capture critical information at token, statement, edge, and graph levels. To address the second one, we design a Siamese graph-matching network based on attention mechanisms. It can uniformly generate graph embeddings for code fragments and facilitate parallel detection of semantic clones, thus significantly boosting the speed of semantic clone detection. We evaluated our approach on two Java benchmark datasets, Google Code Jam and BigCloneBench. The experimental results show that our model outperforms the SOTA (State-Of-The-Art) lightweight models and is over 20x faster in detection. In addition, our model performs on par with the large Bert-based models and is over 110x faster in detection. Our code and dataset are available online at: https://github.com/HduDBSI/CodeGraph4CCDetector. © 2022",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144452421&doi=10.1016%2fj.infsof.2022.107130&partnerID=40&md5=6e1b8c80ca04b3a15872a41e4d6a3a30,Information and Software Technology,196,Include,I1.1,
Dai L.,A study on the application of graph neural network in code clone detection: Improving the performance of code clone detection through graph neural networks and attention mechanisms,"With the increasing scale of software and the growing number of software developers, code cloning has become an important issue in software engineering. To detect code clones, this paper proposes a new method that converts source code into an Abstract Syntax Tree (AST), then adds edges from the Control Flow Graph (CFG) and Data Flow Graph (DFG) to the AST to form a graph. We then feed the graph into the Graph Matching Network (GMN) model and Pairwise Node Comparison (PNC) captures the edge and node information of the graph to calculate the graph similarity, thus converting code clone detection into a binary classification problem. Finally, experiments are conducted on the public dataset BigCloneBench, and the results show that the proposed method has high accuracy and scalability in code clone detection relative to other methods. © 2023 ACM.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169707859&doi=10.1145%2f3605801.3605834&partnerID=40&md5=c24ef0d4d173cbc93d0289bd51b243ab,ACM International Conference Proceeding Series,197,Include,I1.1,
Mehrotra N.; Agarwal N.; Gupta P.; Anand S.; Lo D.; Purandare R.,Modeling Functional Similarity in Source Code With Graph-Based Siamese Networks,"Code clones are duplicate code fragments that share (nearly) similar syntax or semantics. Code clone detection plays an important role in software maintenance, code refactoring, and reuse. A substantial amount of research has been conducted in the past to detect clones. A majority of these approaches use lexical and syntactic information to detect clones. However, only a few of them target semantic clones. Recently, motivated by the success of deep learning models in other fields, including natural language processing and computer vision, researchers have attempted to adopt deep learning techniques to detect code clones. These approaches use lexical information (tokens) and(or) syntactic structures like abstract syntax trees (ASTs) to detect code clones. However, they do not make sufficient use of the available structural and semantic information, hence limiting their capabilities. This paper addresses the problem of semantic code clone detection using program dependency graphs and geometric neural networks, leveraging the structured syntactic and semantic information. We have developed a prototype tool Holmes, based on our novel approach and empirically evaluated it on popular code clone benchmarks. Our results show that Holmes performs considerably better than the other state-of-the-art tool, TBCCD. We also assessed Holmes on unseen projects and performed cross dataset experiments to evaluate the generalizability of Holmes. Our results affirm that Holmes outperforms TBCCD since most of the pairs that Holmes detected were either undetected or suboptimally reported by TBCCD. © 1976-2012 IEEE.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113236624&doi=10.1109%2fTSE.2021.3105556&partnerID=40&md5=23c76e79cd41b745e2448d8240e34e32,IEEE Transactions on Software Engineering,198,Include,I1.1,
Hu Y.; Zou D.; Peng J.; Wu Y.; Shan J.; Jin H.,TreeCen: Building Tree Graph for Scalable Semantic Code Clone Detection,"Code clone detection is an important research problem that has attracted wide attention in software engineering. Many methods have been proposed for detecting code clone, among which text-based and token-based approaches are scalable but lack consideration of code semantics, thus resulting in the inability to detect semantic code clones. Methods based on intermediate representations of codes can solve the problem of semantic code clone detection. However, graph-based methods are not practicable due to code compilation, and existing tree-based approaches are limited by the scale of trees for scalable code clone detection. In this paper, we propose TreeCen, a scalable tree-based code clone detector, which satisfies scalability while detecting semantic clones effectively. Given the source code of a method, we first extract its abstract syntax tree (AST) based on static analysis and transform it into a simple graph representation (i.e., tree graph) according to the node type, rather than using traditional heavyweight tree matching. We then treat the tree graph as a social network and adopt centrality analysis on each node to maintain the tree details. By this, the original complex tree can be converted into a 72-dimensional vector while containing comprehensive structural information of the AST. Finally, these vectors are fed into a machine learning model to train a detector and use it to find code clones. We conduct comparative evaluations on effectiveness and scalability. The experimental results show that TreeCen maintains the best performance of the other six state-of-the-art methods (i.e., SourcererCC, RtvNN, DeepSim, SCDetector, Deckard, and ASTNN) with F1 scores of 0.99 and 0.95 on BigCloneBench and Google Code Jam datasets, respectively. In terms of scalability, TreeCen is about 79 times faster than the other state-of-the-art tree-based semantic code clone detector (ASTNN), about 13 times faster than the fastest graph-based approach (SCDetector), and even about 22 times faster than the one-time trained token-based detector (RtvNN).  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146924679&doi=10.1145%2f3551349.3556927&partnerID=40&md5=276d014d1c9463673e20d8750580700a,ACM International Conference Proceeding Series,199,Include,"I1.1,I1.2",
Liu H.; Zhao H.; Han C.; Hou L.,Low-Complexity Code Clone Detection using Graph-based Neural Networks,"Code clone detection is of great significance for intellectual property protection and software maintenance. Deep learning has been applied in some research and achieved better performance than traditional methods. To adapt to more application scenarios and improve the detection efficiency, this paper proposes a low-complex code clone detection with the graph- based neural network. As the input of the neural network, code features are represented by abstract syntax trees (ASTs), in which the redundant edges are removed. The operation of pruning avoids interference in the message passing of the network and reduces the size of the graph. Then, the graph pairs for the code clone detection are sent into the message passing neural networks (MPNN). In addition, the gated recurrent unit (GRU) is used to learn the information between graph pairs to avoid the operation of Graph mapping. After multiple iterations, the attention mechanism is used to read out the graph vector, and the cosine similarity is calculated on the graph vector to obtain the code similarity. Through the experiments on two datasets, the results show that the proposed clone detection scheme removes about 20 % of the redundant edges and reduces 25 % of model weights, 16% of multiply-accumulate operations (MACs). In the end, the proposed method effectively reduces the training time of graph neural network while presenting a similar performance to the baseline network. © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152299989&doi=10.1109%2fMSN57253.2022.00129&partnerID=40&md5=9f953d397742cd6b27e23a5711dbace7,"Proceedings - 2022 18th International Conference on Mobility, Sensing and Networking, MSN 2022",200,Include,"I1.1,I1.2",
Hu B.; Wu Y.; Peng X.; Sha C.; Wang X.; Fu B.; Zhao W.,Predicting Change Propagation between Code Clone Instances by Graph-based Deep Learning,"Code clones widely exist in open-source and industrial software projects and are still recognized as a threat to software main-tenance due to the additional effort required for the simultaneous maintenance of multiple clone instances and potential defects caused by inconsistent changes in clone instances. To alleviate the threat, it is essential to accurately and efficiently make the decisions of change propagation between clone instances. Based on an exploratory study on clone change propagation with five famous open-source projects, we find that a clone class can have both propagation-required changes and propagation-free changes and thus fine-grained change propagation decision is required. Based on the findings, we propose a graph-based deep learning approach to predict the change propagation requirements of clone instances. We develop a graph representation, named Fused Clone Program Dependency Graph (FC-PDG), to capture the textual and structural code contexts of a pair of clone instances along with the changes on one of them. Based on the representation, we design a deep learning model that uses a Relational Graph Convolutional Network (R-GCN) to predict the change propagation requirement. We evaluate the approach with a dataset constructed based on 51 open-source Java projects, which includes 24,672 pairs of matched changes and 38,041 non-matched changes. The results show that the approach achieves high precision (83.1%), recall (81.2%), and F1-score (82.1%). Our further evaluation with three other open-source projects confirms the generality of the trained clone change propagation prediction model.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133200335&doi=10.1145%2f3524610.3527766&partnerID=40&md5=8c8aeedb22b2c682a2e4551b6716b887,IEEE International Conference on Program Comprehension,201,Include,"I1.1,I1.2",
Lu Z.; Li R.; Hu H.; Zhou W.-A.,A code clone detection algorithm based on graph convolution network with AST tree edge,"Detecting code cloning will prevent it from bringing risks such as vulnerabilities and intellectual property disputes in complex software systems such as large-scale defense software systems and commercial software systems. In the field of deep code clone detection, neural networks such as Tree-CNN and Tree-LSTM, which extract features from AST (abstract syntax tree), can't collect global information of upper and lower nodes, and information can't flow globally, but graph neural network can avoid this problem. This paper presents a method of edging AST, and uses GCN (Graph Convolutional Network) and GAT(Graph Attention Networks) to extract code feature vector. Finally, the experiment is carried out on BigCloneBench data set, using several common binary classification indexes, and analyzing the time consumption, it is concluded that the effect and time efficiency of using graph neural network for code clone detection are significantly improved, especially for the code fragments with completely different semantics.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140923450&doi=10.1109%2fQRS-C55045.2021.00156&partnerID=40&md5=cdb1920d1758a453955a77a6c54f6ec9,"Proceedings - 2021 21st International Conference on Software Quality, Reliability and Security Companion, QRS-C 2021",202,Include,"I1.1,I1.2",
Xu K.; Liu Y.,SCCD-GAN: An Enhanced Semantic Code Clone Detection Model Using GAN,"Code clone refers to a pair of semantically similar but syntactically similar or different code fragments that exist in code base. Excessive code clones in software system will cause a negative impact on system development and maintenance. In recent years, as deep learning has become a hot research area of machine learning, researchers have tried to apply deep learning techniques to code clone detection tasks. They have proposed a series of detection techniques using including unstructured (code in the form of sequential tokens) and structured (code in the form of abstract syntax trees and control-flow graphs) information to detect semantically similar but syntactically different code clone, which is the most difïîcult-to-detect clone type. However, although these methods have achieved an important improvement in the precision of semantic code clone detection, the corresponding false positive rate(FPR) is also at a very high level, making these methods unable to be effectively applied to real-world code bases. This paper proposed S C C D - G A N, an enhanced semantic code clone detection model which based on a graph representation form of programs and uses Graph Attention Network to measure the similarity of code pairs and achieved a lower detection F P R than existing methods. We built the graph representation of the code by expanding the control flow and data flow information to the original abstract syntax tree, and equipped with an attention mechanism to our model that focuses on the most important code parts and features which contribute much to the final detection precision. We implemented and evaluated our proposed method based on the benchmark dataset in the field of code clone detectionBigCloneBench2 and Google Code Jam. S C C D - G A N performed better than the existing state-of-the-art methods in terms of precision and false positive rate. ©2021 IEEE",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125205818&doi=10.1109%2fICECE54449.2021.9674552&partnerID=40&md5=f22e2f0159ad2ce1329266e99268e3e1,"2021 IEEE 4th International Conference on Electronics and Communication Engineering, ICECE 2021",203,Include,"I1.1,I1.2",
Wu Y.; Zou D.; Dou S.; Yang S.; Yang W.; Cheng F.; Liang H.; Jin H.,SCDetector: Software Functional Clone Detection Based on Semantic Tokens Analysis,"Code clone detection is to find out code fragments with similar functionalities, which has been more and more important in software engineering. Many approaches have been proposed to detect code clones, in which token-based methods are the most scalable but cannot handle semantic clones because of the lack of consideration of program semantics. To address the issue, researchers conduct program analysis to distill the program semantics into a graph representation and detect clones by matching the graphs. However, such approaches suffer from low scalability since graph matching is typically time-consuming. In this paper, we propose SCDetector to combine the scalability of token-based methods with the accuracy of graph-based methods for software functional clone detection. Given a function source code, we first extract the control flow graph by static analysis. Instead of using traditional heavyweight graph matching, we treat the graph as a social network and apply social-network-centrality analysis to dig out the centrality of each basic block. Then we assign the centrality to each token in a basic block and sum the centrality ofthe same token in different basic blocks. By this, a graph is turned into certain tokens with graph details (i.e., centrality), called semantic tokens. Finally, these semantic tokens are fed into a Siamese architecture neural network to train a code clone detector. We evaluate SCDetector on two large datasets of functionally similar code. Experimental results indicate that our system is superior to four state-of-the-art methods (i.e., SourcererCC, Deckard, RtvNN, and ASTNN) and the time cost of SCDetector is 14 times less than a traditional graph-based method (i.e., CCSharp) on detecting semantic clones. © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099212810&doi=10.1145%2f3324884.3416562&partnerID=40&md5=7637baf6c518b1c7013ceb5c4b83a3ee,"Proceedings - 2020 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020",204,Include,I1.1,
Wang W.; Li G.; Ma B.; Xia X.; Jin Z.,Detecting Code Clones with Graph Neural Network and Flow-Augmented Abstract Syntax Tree,"Code clones are semantically similar code fragments pairs that are syntactically similar or different. Detection of code clones can help to reduce the cost of software maintenance and prevent bugs. Numerous approaches of detecting code clones have been proposed previously, but most of them focus on detecting syntactic clones and do not work well on semantic clones with different syntactic features. To detect semantic clones, researchers have tried to adopt deep learning for code clone detection to automatically learn latent semantic features from data. Especially, to leverage grammar information, several approaches used abstract syntax trees (AST) as input and achieved significant progress on code clone benchmarks in various programming languages. However, these AST-based approaches still can not fully leverage the structural information of code fragments, especially semantic information such as control flow and data flow. To leverage control and data flow information, in this paper, we build a graph representation of programs called flow-augmented abstract syntax tree (FA-AST). We construct FA-AST by augmenting original ASTs with explicit control and data flow edges. Then we apply two different types of graph neural networks (GNN) on FA-AST to measure the similarity of code pairs. As far as we have concerned, we are the first to apply graph neural networks on the domain of code clone detection. We apply our FA-AST and graph neural networks on two Java datasets: Google Code Jam and BigCloneBench. Our approach outperforms the state-of-the-art approaches on both Google Code Jam and BigCloneBench tasks. © 2020 IEEE.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083565137&doi=10.1109%2fSANER48275.2020.9054857&partnerID=40&md5=bf82acc679eee5776a729dba7d685a8d,"SANER 2020 - Proceedings of the 2020 IEEE 27th International Conference on Software Analysis, Evolution, and Reengineering",205,Include,"I1.1,I1.2",
Cai J.; Li B.; Zhang T.; Zhang J.; Sun X.,Fine-grained smart contract vulnerability detection by heterogeneous code feature learning and automated dataset construction,"Context: Recently, several deep learning based smart contract vulnerability detection approaches have been proposed. However, challenges still exist in applying deep learning for fine-grained vulnerability detection in smart contracts, including the lack of the dataset with sufficient statement-level labeled smart contract samples and neglect of heterogeneity between syntax and semantic features during code feature learning. Objective: To utilize deep learning for fine-grained smart contract vulnerability detection, we propose a security best practices (SBP) based dataset construction approach to address the scarcity of datasets. Moreover, we propose a syntax-sensitive graph neural network to address the challenge of heterogeneous code feature learning. Method: The dataset construction approach is motivated by the insight that smart contract code fragments guarded by security best practices may contain vulnerabilities in their original unguarded code form. Thus, we locate and strip security best practices from the smart contract code to recover its original vulnerable code form and perform sample labeling. Meanwhile, as the heterogeneity between tree-structured syntax features embodied inside the abstract syntax tree (AST) and graph-structured semantic features reflected by relations between statements, we propose a code graph whose nodes are each statement's AST subtree with a syntax-sensitive graph neural network that enhances the graph neural network by a child-sum tree-LSTM cell to learn these heterogeneous features for fine-grained smart contract vulnerability detection. Results: We compare our approach with three state-of-the-art deep learning-based approaches that only support contract-level vulnerability detection and two popular static analysis-based approaches that support fine detection granularity. The experiment results show that our approach outperforms the baselines at both coarse and fine granularities. Conclusion: In this paper, we propose utilizing security best practices inside the smart contract code to construct the dataset with statement-level labels. To learn both tree-structured syntax and graph-structured semantic code features, we propose a syntax-sensitive graph neural network. The experimental results show that our approach outperforms the baselines. © 2023 Elsevier Inc.",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180003952&doi=10.1016%2fj.jss.2023.111919&partnerID=40&md5=f8c6ac95fe3f1d112dae245ff2f18316,Journal of Systems and Software,206,Include,"I1.1,I1.2",
Lin X.; Zhou M.; Cao S.; Wang J.; Sun X.,The Best of Both Worlds: Integrating Semantic Features with Expert Features for Smart Contract Vulnerability Detection,"Over the past few years, smart contract suffers from serious security threats of vulnerabilities, resulting in enormous economic losses. What’s worse, due to the immutable and irreversible features, vulnerable smart contracts which have been deployed in the the blockchain can only be detected rather than fixed. Conventional approaches heavily rely on hand-crafted vulnerability rules, which is time-consuming and difficult to cover all the cases. Recent deep learning approaches alleviate this issue but fail to explore the integration of them together to boost the smart contract vulnerability detection yet. Therefore, we propose to build a novel model, SmartFuSE, for the smart contract vulnerability detection by leveraging the best of semantic features and expert features. SmartFuSE performs static analysis to respectively extract vulnerability-specific expert patterns and joint graph structures at the function-level to frame the rich program semantics of vulnerable code, and leverages a novel graph neural network with the hybrid attention pooling layer to focus on critical vulnerability features. To evaluate the effectiveness of our proposed SmartFuSE, we conducted extensive experiments on 40k contracts in two benchmarks. The experimental results demonstrate that SmartFuSE can significantly outperform state-of-the-art analysis-based and DL-based detectors. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178561279&doi=10.1007%2f978-981-99-8104-5_2&partnerID=40&md5=f8a3114024c599eb4600438405b97f26,Communications in Computer and Information Science,207,Include,I1.1,
Jin S.; Zhai Y.; Zhong Y.; Cui J.; Xu L.; Sun H.; Lei Y.,Securing Blockchain Using Propagation Chain Learning,"Smart contract vulnerabilities are the most common and severe type of blockchain vulnerability, which may result in very serious economic and property losses. Vulnerability detection and repair are necessary to ensure the security of the blockchain. Currently, the-state-of-art smart contract vulnerability detection methods (e.g. Oyente and Securify) use heuristics based on human-designed algorithms, which have certain shortcomings in different application scenarios. Therefore, this paper proposes a smart contract vulnerability detection method, i.e. CuVuD, which uses Propagation Chain Learning to solve the current vulnerability detection problem. This method first parses the source code, then obtains and trims the propagation chain of smart contracts, and finally detects vulnerabilities in smart contracts. To verify the effectiveness of CuVuD, this paper compares the CuVuD method with seven the-state-of-art smart contract vulnerability detection methods on a large-scale smart contract dataset based on the Solidity language. The experimental results show that CuVuD’s effectiveness in detecting smart contract vulnerabilities is significantly higher than seven the-state-of-art smart contract vulnerability detection methods, significantly improving the ability to detect vulnerabilities. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178555785&doi=10.1007%2f978-981-99-8101-4_8&partnerID=40&md5=d10b162261ba84eb31e50767ce0658e7,Communications in Computer and Information Science,208,Include,"I1.1,I1.2",
Zou L.; Gong C.; Wu Z.; Tan J.; Tang J.; Jiang Z.; Li D.,A General Smart Contract Vulnerability Detection Framework with Self-attention Graph Pooling,"In recent years, the increasing development of Web 3.0 has generated growing attention toward blockchain and smart contracts. However, due to their immutability, smart contracts still exhibit various vulnerabilities that hackers can exploit, resulting in significant losses. Numerous smart contracts on various blockchains, including Ethereum, have been attacked due to various vulnerabilities. The inefficiency of detecting these vulnerabilities has become a major bottleneck in advancing blockchain and smart contracts. Although detecting smart contract vulnerabilities has attracted much attention, most existing machine learning-based methods rely on adequate expert knowledge and target only specific known vulnerabilities via binary classification models. To address this limitation, our proposed approach introduced a general vulnerability detection method that can be applied to identify various common vulnerabilities via a uniform framework. We leveraged the Abstract Syntax Trees (AST) and self-attention-based graph pooling models to generate topological graphs from smart contract code analysis. We adopted Graph Neural Networks for vulnerability detection. Experimental results demonstrated that the proposed approach exhibited satisfactory performance in detecting multiple and unseen vulnerabilities compared to traditional methods. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",Conference paper,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178549654&doi=10.1007%2f978-981-99-8104-5_1&partnerID=40&md5=8591d0a411982e39de09c9421fa30b06,Communications in Computer and Information Science,209,Include,"I1.1,I1.2",
Gong P.; Yang W.; Wang L.; Wei F.; HaiLaTi K.; Liao Y.,GRATDet: Smart Contract Vulnerability Detector Based on Graph Representation and Transformer,"Smart contracts have led to more efficient development in finance and healthcare, but vulnerabilities in contracts pose high risks to their future applications. The current vulnerability detection methods for contracts are either based on fixed expert rules, which are inefficient, or rely on simplistic deep learning techniques that do not fully leverage contract semantic information. Therefore, there is ample room for improvement in terms of detection precision. To solve these problems, this paper proposes a vulnerability detector based on deep learning techniques, graph representation, and Transformer, called GRATDet. The method first performs swapping, insertion, and symbolization operations for contract functions, increasing the amount of small sample data. Each line of code is then treated as a basic semantic element, and information such as control and data relationships is extracted to construct a new representation in the form of a Line Graph (LG), which shows more structural features that differ from the serialized presentation of the contract. Finally, the node information and edge information of the graph are jointly learned using an improved Transformer–GP model to extract information globally and locally, and the fused features are used for vulnerability detection. The effectiveness of the method in reentrancy vulnerability detection is verified in experiments, where the F1 score reaches 95.16%, exceeding state-of-the-art methods. © 2023 Tech Science Press. All rights reserved.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173516910&doi=10.32604%2fcmc.2023.038878&partnerID=40&md5=37853fef490b5fe9dc00287a0e0e8bf6,"Computers, Materials and Continua",210,Include,"I1.1,I1.2",
Liu Z.; Qian P.; Wang X.; Zhuang Y.; Qiu L.; Wang X.,Combining Graph Neural Networks with Expert Knowledge for Smart Contract Vulnerability Detection,"Smart contract vulnerability detection draws extensive attention in recent years due to the substantial losses caused by hacker attacks. Existing efforts for contract security analysis heavily rely on rigid rules defined by experts, which are labor-intensive and non-scalable. More importantly, expert-defined rules tend to be error-prone and suffer the inherent risk of being cheated by crafty attackers. Recent researches focus on the symbolic execution and formal analysis of smart contracts for vulnerability detection, yet to achieve a precise and scalable solution. Although several methods have been proposed to detect vulnerabilities in smart contracts, there is still a lack of effort that considers combining expert-defined security patterns with deep neural networks. In this paper, we explore using graph neural networks and expert knowledge for smart contract vulnerability detection. Specifically, we cast the rich control- and data- flow semantics of the source code into a contract graph. To highlight the critical nodes in the graph, we further design a node elimination phase to normalize the graph. Then, we propose a novel temporal message propagation network to extract the graph feature from the normalized graph, and combine the graph feature with designed expert patterns to yield a final detection system. Extensive experiments are conducted on all the smart contracts that have source code in Ethereum and VNT Chain platforms. Empirical results show significant accuracy improvements over the state-of-the-art methods on three types of vulnerabilities, where the detection accuracy of our method reaches 89.15, 89.02, and 83.21 percent for reentrancy, timestamp dependence, and infinite loop vulnerabilities, respectively. © 1989-2012 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109397423&doi=10.1109%2fTKDE.2021.3095196&partnerID=40&md5=7bd04392f0c0af5571c7a03762d62919,IEEE Transactions on Knowledge and Data Engineering,211,Include,"I1.1,I1.2",
Cai J.; Li B.; Zhangv J.; Sun X.; Chen B.,Extended Abstract of Combine Sliced Joint Graph with Graph Neural Networks for Smart Contract Vulnerability Detection,"Existing smart contract vulnerability detection efforts heavily rely on fixed rules defined by experts, which are inefficient and inflexible. To overcome the limitations of existing vulnerability detection approaches, we propose a GNN based approach. First, we construct a graph representation for a smart contract function with syntactic and semantic features by combining abstract syntax tree (AST), control flow graph (CFG), and program dependency graph (PDG). To further strengthen the presentation ability of our approach, we perform program slicing to normalize the graph and eliminate the redundant information unrelated to vulnerabilities. Then, we use a Bidirectional Gated Graph Neural-Network model with hybrid attention pooling to identify potential vulnerabilities in smart contract functions. Experiment results show that our approach can achieve 89.2% precision and 92.9% recall in smart contract vulnerability detection on our dataset and reveal the effectiveness and efficiency of our approach. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160566114&doi=10.1109%2fSANER56733.2023.00101&partnerID=40&md5=c0e6c95589b1dd3c88aca141cf69d969,"Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",212,Exclude,E1.8,
Nguyen H.H.; Nguyen N.-M.; Xie C.; Ahmadi Z.; Kudendo D.; Doan T.-N.; Jiang L.,MANDO-HGT: Heterogeneous Graph Transformers for Smart Contract Vulnerability Detection,"Smart contracts in blockchains have been increasingly used for high-value business applications. It is essential to check smart contracts' reliability before and after deployment. Although various program analysis and deep learning techniques have been proposed to detect vulnerabilities in either Ethereum smart contract source code or bytecode, their detection accuracy and scalability are still limited. This paper presents a novel framework named MANDO-HGT for detecting smart contract vulnerabilities. Given Ethereum smart contracts, either in source code or bytecode form, and vulnerable or clean, MANDO-HGT custom-builds heterogeneous contract graphs (HCGs) to represent control-flow and/or function-call information of the code. It then adapts heterogeneous graph transformers (HGTs) with customized meta relations for graph nodes and edges to learn their embeddings and train classifiers for detecting various vulnerability types in the nodes and graphs of the contracts more accurately. We have collected more than 55K Ethereum smart contracts from various data sources and verified the labels for 423 buggy and 2,742 clean contracts to evaluate MANDO-HGT. Our empirical results show that MANDO-HGT can significantly improve the detection accuracy of other state-of-the-art vulnerability detection techniques that are based on either machine learning or conventional analysis techniques. The accuracy improvements in terms of F1-score range from 0.7% to more than 76% at either the coarse-grained contract level or the fine-grained line level for various vulnerability types in either source code or bytecode. Our method is general and can be retrained easily for different vulnerability types without the need for manually defined vulnerability patterns.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166351291&doi=10.1109%2fMSR59073.2023.00052&partnerID=40&md5=f758ad7d33f8d0cc7ac1d0b7bb8e088c,"Proceedings - 2023 IEEE/ACM 20th International Conference on Mining Software Repositories, MSR 2023",213,Include,I1.1,
Zhang Y.; Liu D.,Toward Vulnerability Detection for Ethereum Smart Contracts Using Graph-Matching Network,"With the blooming of blockchain-based smart contracts in decentralized applications, the security problem of smart contracts has become a critical issue, as vulnerable contracts have resulted in severe financial losses. Existing research works have explored vulnerability detection methods based on fuzzing, symbolic execution, formal verification, and static analysis. In this paper, we propose two static analysis approaches called ASGVulDetector and BASGVulDetector for detecting vulnerabilities in Ethereum smart contacts from source-code and bytecode perspectives, respectively. First, we design a novel intermediate representation called abstract semantic graph (ASG) to capture both syntactic and semantic features from the program. ASG is based on syntax information but enriched by code structures, such as control flow and data flow. Then, we apply two different training models, i.e., graph neural network (GNN) and graph matching network (GMN), to learn the embedding of ASG and measure the similarity of the contract pairs. In this way, vulnerable smart contracts can be identified by calculating the similarity to labeled ones. We conduct extensive experiments to evaluate the superiority of our approaches to state-of-the-art competitors. Specifically, ASGVulDetector improves the best of three source-code-only static analysis tools (i.e., SmartCheck, Slither, and DR-GCN) regarding the F1 score by 12.6% on average, while BASGVulDetector improves that of the three detection tools supporting bytecode (i.e., ContractFuzzer, Oyente, and Securify) regarding the F1 score by 25.6% on average. We also investigate the effectiveness and advantages of the GMN model for detecting vulnerabilities in smart contracts. © 2022 by the authors.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147411558&doi=10.3390%2ffi14110326&partnerID=40&md5=6170681772b53722d0bebb4332e655c7,Future Internet,214,Include,I1.1,
Cai J.; Li B.; Zhang J.; Sun X.; Chen B.,Combine sliced joint graph with graph neural networks for smart contract vulnerability detection,"Smart contract security has drawn extensive attention in recent years because of the enormous economic losses caused by vulnerabilities. Even worse, fixing bugs in a deployed smart contract is difficult, so developers must detect security vulnerabilities in a smart contract before deployment. Existing smart contract vulnerability detection efforts heavily rely on fixed rules defined by experts, which are inefficient and inflexible. To overcome the limitations of existing vulnerability detection approaches, we propose a GNN based approach for smart contract vulnerability detection. First, we construct a graph representation for a smart contract function with syntactic and semantic features by combining abstract syntax tree (AST), control flow graph (CFG), and program dependency graph (PDG). To further strengthen the presentation ability of our approach, we perform program slicing to normalize the graph and eliminate the redundant information unrelated to vulnerabilities. Then, we use a Bidirectional Gated Graph Neural-Network model with hybrid attention pooling to identify potential vulnerabilities in smart contract functions. Empirical results show that our approach can achieve 89.2% precision and 92.9% recall in smart contract vulnerability detection on our dataset and reveal the effectiveness and efficiency of our approach. © 2022 Elsevier Inc.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141321797&doi=10.1016%2fj.jss.2022.111550&partnerID=40&md5=71e722ea23da022d024f0445104f170d,Journal of Systems and Software,215,Include,I1.1,
Han D.; Li Q.; Zhang L.; Xu T.,A Smart Contract Vulnerability Detection Model Based on Syntactic and Semantic Fusion Learning,"As a trusted decentralized application, smart contracts manage a large number of digital assets on the blockchain. Vulnerability detection of smart contracts is an important part of ensuring the security of digital assets. At present, many researchers extract features of smart contract source code for vulnerability detection based on deep learning methods. However, the current research mainly focuses on the single representation form of the source code, which cannot fully obtain the rich semantic and structural information contained in the source code, so it is not conducive to the detection of various and complex smart contract vulnerabilities. Aiming at this problem, this paper proposes a vulnerability detection model based on the fusion of syntax and semantic features. The syntactic and semantic representation of the source code is obtained from the abstract syntax tree and control flow graph of the smart contract through TextCNN and Graph Neural Network. The syntactic and semantic features are fused, and the fused features are used to detect vulnerabilities. Experiments show that the detection accuracy and recall rate of this model have been improved on the detection tasks of five types of vulnerabilities, with an average precision of 96% and a recall rate of 90%, which can effectively identify smart contract vulnerabilities.  © 2023 Daojun Han et al.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148101619&doi=10.1155%2f2023%2f9212269&partnerID=40&md5=4adcc873283819266ee40faf9bb4c941,Wireless Communications and Mobile Computing,216,Include,I1.1,
Nguyen H.H.; Nguyen N.-M.; Doan H.-P.; Ahmadi Z.; Doan T.-N.; Jiang L.,MANDO-GURU: vulnerability detection for smart contract source code by heterogeneous graph embeddings,"Smart contracts are increasingly used with blockchain systems for high-value applications. It is highly desired to ensure the quality of smart contract source code before they are deployed. This paper proposes a new deep learning-based tool, MANDO-GURU, that aims to accurately detect vulnerabilities in smart contracts at both coarse-grained contract-level and fine-grained line-level. Using a combination of control-flow graphs and call graphs of Solidity code, we design new heterogeneous graph attention neural networks to encode more structural and potentially semantic relations among different types of nodes and edges of such graphs and use the encoded embeddings of the graphs and nodes to detect vulnerabilities. Our validation of real-world smart contract datasets shows that MANDO-GURU can significantly improve many other vulnerability detection techniques by up to 24% in terms of the F1-score at the contract level, depending on vulnerability types. It is the first learning-based tool for Ethereum smart contracts that identify vulnerabilities at the line level and significantly improves the traditional code analysis-based techniques by up to 63.4%. Our tool is publicly available at https://github.com/MANDO-Project/ge-sc-machine. A test version is currently deployed at http://mandoguru.com, and a demo video of our tool is available at http://mandoguru.com/demo-video.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143053694&doi=10.1145%2f3540250.3558927&partnerID=40&md5=3c64b411740bd09da4dabb3f6a448a86,ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,217,Exclude,E3.3,
Han D.; Li Q.; Zhang L.; Xu T.,A smart contract vulnerability detection model based on graph neural networks,"In recent years, smart contract vulnerability detection methods mostly view smart contract source code as natural language for processing, which cannot fully capture the semantic and structural features of the source code and has a high rate of false positives and missing positives. To improve the accuracy of vulnerability detection, this paper uses Graph Neural Network to obtain the semantic and structural information of the source code and Convolutional Neural Network to assist learning. We propose a graph neural network-based vulnerability detection model for smart contracts, which transforms smart contracts into control flow graphs, learns graph embedding using graph neural networks, and introduces Convolutional Neural Networks to learn the node order information of control flow graphs, and finally performs vulnerability detection using graph embedding and node order information. Experimenting on real datasets, our accuracy and F1 values are improved and the model can effectively detect smart contract vulnerabilities.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152192949&doi=10.1109%2fICFTIC57696.2022.10075325&partnerID=40&md5=f0465ad00d8a06b470ad570a20b799cc,"2022 4th International Conference on Frontiers Technology of Information and Computer, ICFTIC 2022",218,Include,I1.1,
Miao H.; Bao H.; Tang Z.; Li W.; Wang W.; Chen H.; Liu F.; Sun Y.,AST2Vec: A Robust Neural Code Representation for Malicious PowerShell Detection,"In recent years, PowerShell has become a commonly used carrier to wage cyber attacks. As a script, PowerShell is easy to obfuscate to evade detection. Thus, they are difficult to detect directly using traditional anti-virus software. Existing advanced detection methods generally recover obfuscated scripts before detection. However, most deobfuscation tools can not achieve precise recovery on obfuscated scripts due to emerging obfuscation techniques. To solve the problem, we propose a robust neural code representation method, namely AST2Vec, to detect malicious PowerShell without de-obfuscating scripts. 6 Abstract Syntax Tree (AST) recovery-related statement nodes are defined to identify obfuscated subtrees. Then AST2Vec splits the large AST of entire PowerShell scripts into a set of small subtrees rooted by these 6 types of nodes and performs tree-based neural embeddings on all extracted subtrees by capturing lexical and syntactical knowledge of statement nodes. Based on the sequence of statement vectors, a bidirectional recursive neural network (Bi-RNN) is modeled to leverage the context of statements and finally produce vector representation of scripts. We evaluate the proposed method for malicious PowerShell detection through extensive experiments. Experimental results indicate that our model outperforms the state-of-the-art approaches. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178514641&doi=10.1007%2f978-3-031-45933-7_13&partnerID=40&md5=4494d55ff52abdbd18f1100ae2f6fd97,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),219,Include,I1.1,
Rozi M.F.; Ban T.; Ozawa S.; Yamada A.; Takahashi T.; Kim S.; Inoue D.,Detecting Malicious JavaScript Using Structure-Based Analysis of Graph Representation,"Malicious JavaScript code in web applications poses a significant threat as cyber attackers exploit it to perform various malicious activities. Detecting these malicious scripts is challenging, given their diverse nature and the continuous evolution of attack techniques. Most approaches formulate this task as a static or sequential feature of the script, which is insufficient in terms of flexibility to various attack techniques and the ability to capture the script's semantic meaning. To address this issue, we propose an alternative approach that leverages JavaScript code's abstract syntax tree (AST) representation, focusing on distinctive syntactic structure features. The proposed approach uses graph neural networks to extract structural features from the AST graph while considering the attribute features of individual nodes, which uses neural message passing with neighborhood aggregation. The proposed method encodes both the local AST graph structure and attributes of the nodes. It enables capturing the source code's semantic meaning and exploits the signature structure in the AST representations. The proposed method consistently achieved high detection performance in extensive experiments on two different datasets, with accuracy scores of 99.4% and 96.92%. The obtained evaluation metrics demonstrate the effectiveness of our approach in accurately detecting malicious JavaScript code, with our proposed method successfully detecting more than 81% for various attack types and achieving an almost twofold performance improvement on JS-Droppers compared to the sequence-based approach. In addition, we observed that the AST graph structure represented the code's semantic meaning, exhibiting distinctive patterns and signatures that could be effectively captured using the proposed method.  © 2013 IEEE.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172989806&doi=10.1109%2fACCESS.2023.3317266&partnerID=40&md5=bbd56b60ec2e4b7191116403b187c21e,IEEE Access,220,Include,I1.1,
Zhu J.; Yao Y.; Deng X.; Yong Y.; Wang Y.; Chen L.; Xue Z.; Zhao R.,SAWD: Structural-Aware Webshell Detection System with Control Flow Graph,"With the increasing prevalence of web servers, protecting them from cyber attacks has become a crucial task for online service providers. Webshells, which are backdoors to websites, are commonly used by hackers to gain unauthorized access to web servers. However, traditional methods for detecting webshells often fail to produce satisfactory results due to the use of obfuscation or encryption to conceal their characteristics. In recent years, webshell detection methods based on deep learning (DL) have received significant attention, but they struggle to preserve the syntax and semantic information contained in the source code. In this paper, we propose a structural-aware webshell detection system to address these problems, denoted as SAWD. Specifically, we first generate the control flow graph (CFG) with syntax and semantic information from the PHP source code. Then, we leverage CFG to build our graph representation, which consists of the adjacency matrix and keywords-based basic block features. Finally, based on our graph representation, we adopt convolutional neural networks (GCN) combined with graph pooling to detect webshells more efficiently. Experimental results demonstrate that our method outperforms state-of-the-art webshell detection systems on the collected dataset. © 2023 Knowledge Systems Institute Graduate School. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170088196&doi=10.18293%2fSEKE2023-205&partnerID=40&md5=17552b54f84adbc66130e38cb0079c34,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",221,Include,I1.1,
Malhotra V.; Potika K.; Stamp M.,A comparison of graph neural networks for malware classification,"Managing the threat posed by malware requires accurate detection and classification techniques. Traditional detection strategies, such as signature scanning, rely on manual analysis of malware to extract relevant features, which is labor intensive and requires expert knowledge. Function call graphs consist of a set of program functions and their inter-procedural calls, providing a rich source of information that can be leveraged to classify malware without the labor intensive feature extraction step of traditional techniques. In this research, we treat malware classification as a graph classification problem. Based on Local Degree Profile features, we train a wide range of Graph Neural Network (GNN) architectures to generate embeddings which we then classify. We find that our best GNN models outperform previous comparable research involving the well-known MalNet-Tiny Android malware dataset. In addition, our GNN models do not suffer from the overfitting issues that commonly afflict non-GNN techniques, although GNN models require longer training times. © 2023, The Author(s), under exclusive licence to Springer-Verlag France SAS, part of Springer Nature.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165906021&doi=10.1007%2fs11416-023-00493-y&partnerID=40&md5=1daf672a23b8d2e77b4834eb80e8f981,Journal of Computer Virology and Hacking Techniques,222,Exclude,E1.5,android malware
Fang Y.; Huang C.; Zeng M.; Zhao Z.; Huang C.,JStrong: Malicious JavaScript detection based on code semantic representation and graph neural network,"Web development technology has experienced significant progress. The creation of JavaScript has highly enriched the interactive ability of the client. However, the attacker uses the dynamic characteristics of the JavaScript language to embed malicious code into web pages to achieve the purpose of smuggling, redirection, and so on. Traditional methods based on static feature detection are therefore difficult to detect malicious code after confusion, and the method based on dynamic analysis is inefficient. To meet these challenges, this paper proposes a static detection model JStrong based on graph neural network. The model first generates an abstract syntax tree from the JavaScript source code, and then adds data flow and control flow information into the program dependency graph. In addition, we embed the nodes and edges of the graph into the feature vector and fully learn the features of the whole graph through the graph neural network. We take advantage of a real-world dataset collected from the top website and GitHub to evaluate JStrong and compare it to the state-of-the-art method. Experimental results show that JStrong achieves near-perfect classification performance and is superior to the state-of-the-art method. © 2022 Elsevier Ltd",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128369219&doi=10.1016%2fj.cose.2022.102715&partnerID=40&md5=4f6874e954626fa4d1fe9d83d50e7502,Computers and Security,223,Include,I1.1,don't understand energy funtion
Jiang C.; Yin K.; Xia C.; Huang W.,FedHGCDroid: An Adaptive Multi-Dimensional Federated Learning for Privacy-Preserving Android Malware Classification,"With the popularity of Android and its open source, the Android platform has become an attractive target for hackers, and the detection and classification of malware has become a research hotspot. Existing malware classification methods rely on complex manual operation or large-volume high-quality training data. However, malware data collected by security providers contains user privacy information, such as user identity and behavior habit information. The increasing concern for user privacy poses a challenge to the current malware classification scheme. Based on this problem, we propose a new android malware classification scheme based on Federated learning, named FedHGCDroid, which classifies malware on Android clients in a privacy-protected manner. Firstly, we use a convolutional neural network and graph neural network to design a novel multi-dimensional malware classification model HGCDroid, which can effectively extract malicious behavior features to classify the malware accurately. Secondly, we introduce an FL framework to enable distributed Android clients to collaboratively train a comprehensive Android malware classification model in a privacy-preserving way. Finally, to adapt to the non-IID distribution of malware on Android clients, we propose a contribution degree-based adaptive classifier training mechanism FedAdapt to improve the adaptability of the malware classifier based on Federated learning. Comprehensive experimental studies on the Androzoo dataset (under different non-IID data settings) show that the FedHGCDroid achieves more adaptability and higher accuracy than the other state-of-the-art methods. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133730316&doi=10.3390%2fe24070919&partnerID=40&md5=8d8a25388d51d5e08cfc934e0d266e62,Entropy,224,Exclude,E1.5,android malware
Hu J.L.; Ebrahimi M.; Li W.; Li X.; Chen H.,Multi-view Representation Learning from Malware to Defend Against Adversarial Variants,"Deep learning-based adversarial malware detectors have yielded promising results in detecting never-before-seen malware executables without relying on expensive dynamic behavior analysis and sandbox. Despite their abilities, these detectors have been shown to be vulnerable to adversarial malware variants - meticulously modified, functionality-preserving versions of original malware executables generated by machine learning. Due to the nature of these adversarial modifications, these adversarial methods often use a single view of malware executables (i.e., the binary/hexadecimal view) to generate adversarial malware variants. This provides an opportunity for the defenders (i.e., malware detectors) to detect the adversarial variants by utilizing more than one view of a malware file (e.g., source code view in addition to the binary view). The rationale behind this idea is that while the adversary focuses on the binary view, certain characteristics of the malware file in the source code view remain untouched which leads to the detection of the adversarial malware variants. To capitalize on this opportunity, we propose Adversarially Robust Multiview Malware Defense (ARMD), a novel multi-view learning framework to improve the robustness of DL-based malware detectors against adversarial variants. Our experiments on three renowned open-source deep learning-based malware detectors across six common malware categories show that ARMD is able to improve the adversarial robustness by up to seven times on these malware detectors.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148453933&doi=10.1109%2fICDMW58026.2022.00066&partnerID=40&md5=857e415b9f41782fd619468754e1864c,"IEEE International Conference on Data Mining Workshops, ICDMW",225,Exclude,E1.4,
Zheng R.; Wang Q.; He J.; Fu J.; Suri G.; Jiang Z.,Cryptocurrency Mining Malware Detection Based on Behavior Pattern and Graph Neural Network,"Miner malware has been steadily increasing in recent years as the value of cryptocurrency rises, which poses a considerable threat to users' device security. Miner malware has obvious behavior patterns in order to participate in blockchain computing. However, most miner malware detection methods use raw bytes feature and sequential opcode as detection features. It is difficult for these methods to obtain better detection results due to not modeling robust features. In this paper, a miner malware identification method based on graph classification network is designed by analyzing the features of function call graph and control flow graph of miner malware, called MBGINet. MBGINet can model the behavior graph relationship of miner malware by extracting the connection features of critical nodes in the behavior graph. Finally, MBGINet transforms these node features into the feature vectors of the graph for miner malware identification. In the test experiments, datasets with different volumes are used for simulating real-world scenarios. The experimental results show that the MBGINet method achieves a leading and stable performance compared to the dedicated opcode detection method and obtains an accuracy improvement of 3.08% on the simulated in-the-wild dataset. Meanwhile, MBGINet gains an advantage over the general malware detection method Malconv. These experimental results demonstrate the superiority of the MBGINet method, which has excellent characteristics in adapting to realistic scenarios.  © 2022 Rui Zheng et al.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128269189&doi=10.1155%2f2022%2f9453797&partnerID=40&md5=fb6fdf3fb825610b598fc123cd270985,Security and Communication Networks,226,Exclude,E1.4,
Renjith G.; Aji S.,Vulnerability Analysis and Detection Using Graph Neural Networks for Android Operating System,"Android operating system approximately contains around 93 million lines of code, mainly consisting of C, C++ and Java languages. There is no strict software engineering life-cycle followed during Android software development, and hence the design flaws and vulnerabilities are largely reported. Rising security attacks targeting Android manifests the importance of early detection of vulnerabilities in Android operating system. The existing mechanisms either focus on Android Apps or short code differences of the Android framework, and hence they are less effective for Android operating system. In this work, we extracted all the officially reported publicly accessible Android Java vulnerabilities in application and framework layers from 2015 till June 2021. The extracted vulnerable and corresponding fixed (secure) code are then converted into the graphical form using different intermediate graph representations, and then graph features are extracted. Vectorization techniques are used for converting node features of the graph into numerical formats. A vulnerability detection mechanism based on Graph Neural Network is designed and achieved an F1-score of 0.92. To the best of our knowledge, this will be one of the first works for Android operating system source code vulnerability detection technique exploiting the potential of Graph Neural Networks. © 2021, Springer Nature Switzerland AG.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122043434&doi=10.1007%2f978-3-030-92571-0_4&partnerID=40&md5=4572538ed90c4cfd6eb83138ffd7e4e1,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),227,Include,I1.1,
Errica F.; Iadarola G.; Martinelli F.; Mercaldo F.; Micheli A.,Robust Malware Classification via Deep Graph Networks on Call Graph Topologies,"We propose a malware classification system that is shown to be robust to some common intra-procedural obfuscation techniques. Indeed, by training the Contextual Graph Markov Model on the call graph representation of a program, we classify it using only topological information, which is unaffected by such obfuscations. In particular, we show that the structure of the call graph is sufficient to achieve good accuracy on a multi-class classification benchmark. © 2021 ESANN Intelligence and Machine Learning. All rights reserved.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126084314&doi=10.14428%2fesann%2f2021.ES2021-82&partnerID=40&md5=b4f128b93a501718cc0f334bf55a2add,"ESANN 2021  Proceedings - 29th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning",228,Exclude,E1.5,android malware
Rozi M.F.; Ban T.; Ozawa S.; Kim S.; Takahashi T.; Inoue D.,JStrack: Enriching Malicious JavaScript Detection Based on AST Graph Analysis and Attention Mechanism,"Malicious JavaScript is one of the most common tools for attackers to exploit the vulnerability of web applications. It can carry potential risks such as spreading malware, phishing, or collecting sensitive information. Though there are numerous types of malicious JavaScript that are difficult to detect, generalizing the malicious script’s signature can help catch more complex JavaScripts that use obfuscation techniques. This paper aims at detecting malicious JavaScripts based on structure and attribute analysis of abstract syntax trees (ASTs) that capture the generalized semantic meaning of the source code. We apply a graph convolutional neural network (GCN) to process the AST features and get a graph representation via neural message passing with neighborhood aggregation. The attention layer enriches our method to track pertinent parts of scripts that may contain the signature of malicious intent. We comprehensively evaluate the performance of our proposed approach on a real-world dataset to detect malicious websites. The proposed method demonstrates promising performance in terms of detection accuracy and robustness against obfuscated samples. © 2021, Springer Nature Switzerland AG.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121913208&doi=10.1007%2f978-3-030-92270-2_57&partnerID=40&md5=f5447afcae093e424ec42d6ba4e49536,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),229,Include,I1.1,
Cao S.; Sun X.; Bo L.; Wu R.; Li B.; Wu X.; Tao C.; Zhang T.; Liu W.,Learning to Detect Memory-related Vulnerabilities,"Memory-related vulnerabilities can result in performance degradation or even program crashes, constituting severe threats to the security of modern software. Despite the promising results of deep learning (DL)-based vulnerability detectors, there exist three main limitations: (1) rich contextual program semantics related to vulnerabilities have not yet been fully modeled; (2) multi-granularity vulnerability features in hierarchical code structure are still hard to be captured; and (3) heterogeneous flow information is not well utilized. To address these limitations, in this article, we propose a novel DL-based approach, called MVD+, to detect memory-related vulnerabilities at the statement-level. Specifically, it conducts both intraprocedural and interprocedural analysis to model vulnerability features, and adopts a hierarchical representation learning strategy, which performs syntax-aware neural embedding within statements and captures structured context information across statements based on a novel Flow-Sensitive Graph Neural Networks, to learn both syntactic and semantic features of vulnerable code. To demonstrate the performance, we conducted extensive experiments against eight state-of-the-art DL-based approaches as well as five well-known static analyzers on our constructed dataset with 6,879 vulnerabilities in 12 popular C/C++ applications. The experimental results confirmed that MVD+ can significantly outperform current state-of-the-art baselines and make a great trade-off between effectiveness and efficiency.  © 2023 Copyright held by the owner/author(s).",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183325353&doi=10.1145%2f3624744&partnerID=40&md5=ada411ab2849e459230c34255ab66df2,ACM Transactions on Software Engineering and Methodology,231,Include,I1.1,
Zeng C.; Zhou B.; Dong H.; Wu H.; Xie P.; Guan Z.,A General Source Code Vulnerability Detection Method via Ensemble of Graph Neural Networks,"Deep neural networks have been recently utilized in source code vulnerability detection methods due to their automated feature learning capabilities. However, current deep vulnerability detection models heavily rely on fixed code static analysis tools, limiting their applicability to a single programming language. Furthermore, the existing models often fail to fully extract semantic features from the source code, leading to limited generalization capabilities. To address these challenges, this paper proposes a language-agnostic code vulnerability detection framework based on ensemble of graph neural networks. Our approach considers the source program as a linear token sequence and constructs an initial graph representation by capturing the co-occurrence relationships between tokens. The model’s hidden layers leverage a combination of graph convolutional module and gated graph neural networks to extract semantic features from vulnerable code. To adaptively learn the importance of each vulnerability feature, we introduce a self-attention layer after the hidden layer. Additionally, to enhance model stability and prevent overfitting, we incorporate residual connections and flooding regularization techniques. Experimental results on real-world vulnerability datasets demonstrate our approach surpasses previous SOTA approaches by a margin of over 2.37% in terms of detection accuracy. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2024.",Conference paper,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181976167&doi=10.1007%2f978-981-99-9331-4_37&partnerID=40&md5=233bc7479f4f344bcafc23a298b5134f,Communications in Computer and Information Science,232,Include,I1.1,
Zhou D.; Wu Y.; Peng X.; Zhang J.; Li Z.,Revealing code change propagation channels by evolution history mining,"Changes on source code may propagate to distant code entities through various kinds of relationships, which may form up change propagation channels. It is however difficult for developers to reveal code change propagate channels due to sophisticated interrelationships among code entities. In this work, we propose a novel graph representation for the changed code entities and related code entities changed within a range of space and time so that the types of relationships along which the changes are propagated can be explicitly presented. Then a subgraph mining technique is used to find the frequent change propagation channels. We finally reveal 40 types of frequent change propagation channels that cover over 98% cases of code change propagation in five well-known open-source Java projects. We find evidence that the code changes propagated through an unchanged intermediate code entity consume more time than those through a changed one, indicating the difficulties in maintaining code entities that related through indirect relationships. We find that a small proportion of code entities frequently appear in the FCPCs, and confirm the semantic relationships between code entities covered by 50 instances of FCPCs, indicating potential usefulness for developers to explain the range of change impact from given source code changes. © 2023 Elsevier Inc.",Article,2024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182227254&doi=10.1016%2fj.jss.2023.111912&partnerID=40&md5=dea6dc9ea39b04ebffd934c96940f2bd,Journal of Systems and Software,233,Exclude,E1.1,
Chen N.; Sun Q.; Wang J.; Li X.; Gao M.,Pass-Tuning: Towards Structure-Aware Parameter-Efficient Tuning for Code Representation Learning,"Code pre-trained models (CodePTMs) have recently become the de-facto paradigm for various tasks in the domain of code intelligence. To achieve excellent performance, the widely used strategy is to fine-tune all the parameters of CodePTMs. However, as the model size increases along with the number of downstream tasks, this strategy becomes excessively expensive. There are also some prior works that utilize Parameter-Efficient Learning (PEL) methods for model tuning in natural language processing to mitigate similar problems, but applying them directly to CodePTMs fails to capture the inherent structural characteristics of codes. To address the problem, in this paper, we propose Pass-Tuning for structure-aware Parameter-Efficient code representation learning. Specifically, a plug-and-play graph neural network module that can learn from Abstract Syntax Tree (AST) is employed as a tunable prefix. On the one hand, Pass-Tuning can further exploit the structural information of source code. On the other hand, it could serve as a replacement for full fine-tuning. We evaluate our method on multiple tasks across eight programming languages, including code understanding and generation. These results demonstrate the effectiveness, robustness, and universality of our method. Our codes and resources are available at https://github.com/nchen909/Pass-Tuning. © 2023 Association for Computational Linguistics.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183291258&partnerID=40&md5=130096fe208ad4c87992e14275cc752b,Findings of the Association for Computational Linguistics: EMNLP 2023,234,Include,I1.1,
Wang R.; Xu Y.; Wu Y.,Python Open-Source Code Traceability Model Based on Graph Neural Networks,"When programmers write project code, they may copy or reference some open-source code, which may include defective code, causing vulnerabilities in the project. This causes a potential threat to the project and threatens the security of the software supply chain. Therefore, to protect the code security, the Python open-source code traceability model based on graph neural networks is proposed to calculate the similarity between the programmers' Python code and the Python open-source code. Firstly, each function in Python code is parsed into one Type Abstract Syntax Tree. Secondly, graph neural networks are used to calculate the function similarity between the two Type Abstract Syntax Trees of the original code and open-source code. Thirdly, the overall similarity of a Python project that consists of many functions is calculated based on the function similarity following the maximum retention principle. The experiment was conducted on three datasets: StudentWork, GitDown, and Obfuscated-GitDown. The experiment shows that the results calculated by our model are more reasonable, which places more emphasis on similarity in code structure than on code text. Taking the Pyobfuscate obfuscation scenario as an example, our model considering code structure gets similarity 18.12%39.54% higher than other methods that calculate similarity based on the code text.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182602964&doi=10.1109%2fDASC%2fPiCom%2fCBDCom%2fCy59711.2023.10361385&partnerID=40&md5=27f6abcf2cadb5d3996750d3f7c403bc,"2023 IEEE International Conference on Dependable, Autonomic and Secure Computing, International Conference on Pervasive Intelligence and Computing, International Conference on Cloud and Big Data Computing, International Conference on Cyber Science and Technology Congress, DASC/PiCom/CBDCom/CyberSciTech 2023",235,Include,I1.1,
Wen X.; Gao C.; Ye J.; Li Y.; Tian Z.; Jia Y.; Wang X.,Meta-Path Based Attentional Graph Learning Model for Vulnerability Detection,"In recent years, deep learning (DL)-based methods have been widely used in code vulnerability detection. The DL-based methods typically extract structural information from source code, e.g., code structure graph, and adopt neural networks such as Graph Neural Networks (GNNs) to learn the graph representations. However, these methods fail to consider the heterogeneous relations in the code structure graph, i.e., the heterogeneous relations mean that the different types of edges connect different types of nodes in the graph, which may obstruct the graph representation learning. Besides, these methods are limited in capturing long-range dependencies due to the deep levels in the code structure graph. In this paper, we propose a <bold>M</bold>eta-path based <bold>A</bold>ttentional <bold>G</bold>raph learning model for code vul<bold>NE</bold>rability de<bold>T</bold>ection, called <bold>MAGNET</bold>. MAGNET constructs a multi-granularity meta-path graph for each code snippet, in which the heterogeneous relations are denoted as meta-paths to represent the structural information. A meta-path based hierarchical attentional graph neural network is also proposed to capture the relations between distant nodes in the graph. We evaluate MAGNET on three public datasets and the results show that MAGNET outperforms the best baseline method in terms of F1 score by 6.32&#x0025;, 21.50&#x0025;, and 25.40&#x0025;, respectively. MAGNET also achieves the best performance among all the baseline methods in detecting Top-25 most dangerous Common Weakness Enumerations (CWEs), further demonstrating its effectiveness in vulnerability detection. IEEE",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181565485&doi=10.1109%2fTSE.2023.3340267&partnerID=40&md5=9c9216204be8bcbf11c14281c7e7a27f,IEEE Transactions on Software Engineering,236,Include,I1.1,
Zhang Z.; Liu L.; Chang J.; Wang L.; Liao L.,Commit Classification via Diff-Code GCN based on System Dependency Graph,"Commit Classification, an automated process of classifying Diff-Code based on their purpose, plays a crucial role in enhancing comprehension and the quality of software. Some previous studies only used commit messages or code metrics to represent diff-code but lacked code context structure characterization. Alternatively, other studies have used Abstract Syntax Trees (ASTs) tokens to represent diff-code but did not consider contextual information like data dependency and control dependency. In this paper, we propose a new commit classification model called Diff-Code GCN (Graph Convolutional Network). Specifically, we firstly build a more detailed system dependency graph (SDG) of the commit, and secondly use program slicing to search the impact scope of diff-code. Thirdly, we extract the scope as a Change Impact Graph (CIG). We utilize GCN to extract contextual information from CIG and combine it with syntactic changed information of ASTs to represent the commit. Finally, we classify the commit into three maintenance categories (corrective, perfective, and adaptive). We evaluate our model based on commonly used datasets and compare our model with popular commit classification approaches. The experiment result well shows that both in within-project and cross-project prediction tasks, our model performs better than baseline models.  © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182520712&doi=10.1109%2fQRS60937.2023.00053&partnerID=40&md5=eaee00d90d1ca5c9b7f9598b67000bfb,"IEEE International Conference on Software Quality, Reliability and Security, QRS",237,Include,"I1.1,I1.2",
Chen S.; Xu S.; Yao Y.; Xu F.,Untangling Composite Commits by Attributed Graph Clustering,"During software development, it is considered to be a best practice if each commit represents one distinct concern, such as fixing a bug or adding a new feature. However, developers may not always follow this practice and sometimes tangle multiple concerns into a single composite commit. This makes automatic commit untangling a necessary task, and recent approaches mainly untangle commits via applying graph clustering on the code dependency graph. In this paper, we propose a new commit untangling approach, ComUnt, to decompose the composite commits into atomic ones. Different from existing approaches, ComUnt is built upon the observation that both the textual content of code statements and the dependencies between code statements contain useful semantic information so as to better comprehend the committed code changes. Based on this observation, ComUnt first constructs an attributed graph for each commit, where code statements and various code dependencies are modeled as nodes and edges, respectively, and the textual body of code statements are maintained as node attributes. It then conducts attributed graph clustering on the constructed graph. The used attributed graph clustering algorithm can simultaneously encode both graph structure and node attributes so as to better separate the code changes into clusters with distinct concerns. We evaluate our approach on nine C# projects, and the experimental result shows that ComUnt improves the state-of-the-art by 7.8% in terms of untangling accuracy, and meanwhile it is more than 6 times faster.  © 2022 Association for Computing Machinery.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139556972&doi=10.1145%2f3545258.3545267&partnerID=40&md5=243fc68212f7e1da0843bdafb29510f9,ACM International Conference Proceeding Series,238,Include,I1.1,
Savidis A.; Savaki C.,Software Architecture Mining from Source Code with Dependency Graph Clustering and Visualization,"The software architecture represents an important asset, constituting a shared vision amongst the software engineers of the various system components. Good architectures link to modular design, with loose coupling and cohesion defining which operations are grouped together to form a modular architectural entity. Modularity is achieved by practice otherwise we may observe a mismatch where the source code diverges from the primary architectural vision. In fact, class groups with dense interdependencies denote the real architectural entities as derived and implied directly from source code. In this work, we created a tool to assist in mining the actual system architecture. We extract all sorts of dependencies by processing all source files, and then using graph clustering, we capture and interactively visualize strongly coupled class groups with configurable weights. We also support forced clustering on namespaces, packages and folders. © 2022 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174876755&doi=10.5220%2f0010896800003124&partnerID=40&md5=11b2876a6a5a73299d54c0b747250869,"Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications",239,Exclude,E1.1,
Chourasia P.; Ramakrishnan G.; Apte V.; Kumar S.,Algorithm Identification in Programming Assignments,"Current autograders of programming assignments are typically program output based; they fall short in many ways: e.g. they do not carry out subjective evaluations such as code quality, or whether the code has followed any instructor specified constraints; this is still done manually by teaching assistants. In this paper, we tackle a specific aspect of such evaluation: to verify whether a program implements a specific algorithm that the instructor specified. An algorithm, e.g. bubble sort, can be coded in myriad different ways, but a human can always understand the code and spot, say a bubble sort, vs. a selection sort. We develop and compare four approaches to do precisely this: given the source code of a program known to implement a certain functionality, identify the algorithm used, among a known set of algorithms. The approaches are based on code similarity, Support Vector Machine (SVM) with tree or graph kernels, and transformer neural architectures based only source code (CodeBERT), and the extension of this that includes code structure (GraphCodeBERT). Furthermore, we use a model for explainability (LIME) to generate insights into why certain programs get certain labels. Results based on our datasets of sorting, searching and shortest path codes, show that GraphCodeBERT, fine-tuned with scrambled source code, i.e., where identifiers are replaced consistently with arbitrary words, gives the best performance in algorithm identification, with accuracy of 96-99% depending on the functionality. Additionally, we add uncalled function source code elimination to our pre-processing pipeline of test programs, to improve the accuracy of classification of obfuscated source code.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133208644&doi=10.1145%2f3524610.3527914&partnerID=40&md5=6a56c84be9f2726f6427bcd02ca3cbe6,IEEE International Conference on Program Comprehension,240,Include,I1.1,Very borderline
Al-Debagy O.; Martinek P.,Dependencies-based microservices decomposition method,"A microservices identification method was proposed by this research paper. The proposed method consists of two parts; the first part is representing the source code of the monolithic application as a class dependency graph. This graph represents the structure of the monolithic application and the relationships between the classes of the application. The second part of the method is a graph clustering algorithm to identify the microservices through analyzing the dependencies between the classes of the monolithic application and cluster classes with solid relationships to generate microservice candidates. The method was tested with 8 different applications and 11 clustering algorithms were examined to find the most accurate and efficient algorithm. The proposed method produced promising results when compared to other methods in the literature with 0.8 averaged F-Measure ‘F1’ score and 0.44 averaged NGM score. The F1 score shows that the proposed method has good accuracy in detecting microservices candidates. Newman Girvan Modularity metric ‘NGM’ score shows that the generated microservices candidates are properly structured and that there are well-defined relationships among the clustered classes of the generated microservices. © 2021 Informa UK Limited, trading as Taylor & Francis Group.",Article,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105020336&doi=10.1080%2f1206212X.2021.1915444&partnerID=40&md5=08cedd231472d717ede187789604a42e,International Journal of Computers and Applications,241,Include,I1.1,Very borderline
Pourasghar B.; Izadkhah H.; Isazadeh A.; Lotfi S.,A graph-based clustering algorithm for software systems modularization,"Context: Clustering algorithms, as a modularization technique, are used to modularize a program aiming to understand large software systems as well as software refactoring. These algorithms partition the source code of the software system into smaller and easy-to-manage modules (clusters). The resulting decomposition is called the software system structure (or software architecture). Due to the NP-hardness of the modularization problem, evolutionary clustering approaches such as the genetic algorithm have been used to solve this problem. These methods do not make much use of the information and knowledge available in the artifact dependency graph which is extracted from the source code. Objective: To overcome the limitations of the existing modularization techniques, this paper presents a new modularization technique named GMA (Graph-based Modularization Algorithm). Methods: In this paper, a new graph-based clustering algorithm is presented for software modularization. To this end, the depth of relationships is used to compute the similarity between artifacts, as well as seven new criteria are proposed to evaluate the quality of a modularization. The similarity presented in this paper enables the algorithm to use graph-theoretic information. Results: To demonstrate the applicability of the proposed algorithm, ten folders of Mozilla Firefox with different domains and functions, along with four other applications, are selected. The experimental results demonstrate that the proposed algorithm produces modularization closer to the human expert's decomposition (i.e., directory structure) than the other existing algorithms. Conclusion: The proposed algorithm is expected to help a software designer in the software reverse engineering process to extract easy-to-manage and understandable modules from source code. © 2020 Elsevier B.V.",Article,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095748789&doi=10.1016%2fj.infsof.2020.106469&partnerID=40&md5=23bafc7abded00db06bb72f18870e788,Information and Software Technology,242,Include,I1.1,
Zou Y.; Ban B.; Xue Y.; Xu Y.,CCGraph: a PDG-based code clone detector with approximate graph matching,"Software clone detection is an active research area, which is very important for software maintenance, bug detection, etc. The two pieces of cloned code reflect some similarities or equivalents in the syntax or structure of the code representations. There are many representations of code like AST, token, PDG, etc. The PDG (Program Dependency Graph) of source code can contain both syntactic and structural information. However, most existing PDG-based tools are quite time-consuming and miss many clones because they detect code clones with exact graph matching by using subgraph isomorphism. In this paper, we propose a novel PDG-based code clone detector, CCGraph, that uses graph kernels. Firstly, we normalize the structure of PDGs and design a two-stage filtering strategy by measuring the characteristic vectors of codes. Then we detect the code clones by using an approximate graph matching algorithm based on the reforming WL (Weisfeiler-Lehman) graph kernel. Experiment results show that CCGraph retains a high accuracy, has both better recall and F1-score values, and detects more semantic clones than other two related state-of-the-art tools. Besides, CCGraph is much more efficient than the existing PDG-based tools. © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099266573&doi=10.1145%2f3324884.3416541&partnerID=40&md5=e9649945fd8d1b9486b8b22bb1db30f9,"Proceedings - 2020 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020",243,Exclude,E1.1,
Pârtachi P.-P.; Dash S.K.; Allamanis M.; Barr E.T.,Flexeme: Untangling commits using lexical flows,"Today, most developers bundle changes into commits that they submit to a shared code repository. Tangled commits intermix distinct concerns, such as a bug fix and a new feature. They cause issues for developers, reviewers, and researchers alike: they restrict the usability of tools such as git bisect, make patch comprehension more difficult, and force researchers who mine software repositories to contend with noise. We present a novel data structure, the -NFG, a multiversion Program Dependency Graph augmented with name flows. A -NFG directly and simultaneously encodes different program versions, thereby capturing commits, and annotates data flow edges with the names/lexemes that flow across them. Our technique, Flexeme, builds a -NFG from commits, then applies Agglomerative Clustering using Graph Similarity to that -NFG to untangle its commits. At the untangling task on a C# corpus, our implementation, Heddle, improves the state-of-the-art on accuracy by 0.14, achieving 0.81, in a fraction of the time: Heddle is 32 times faster than the previous state-of-the-art. © 2020 ACM.",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097194961&doi=10.1145%2f3368089.3409693&partnerID=40&md5=3655a2d95887a2382e1a1056ae653ae3,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,244,Include,"I1.1,I1.2",
Höppner F.; Jahnke M.,Enriched Weisfeiler-Lehman Kernel for Improved Graph Clustering of Source Code,"To perform cluster analysis on graphs we utilize graph kernels, Weisfeiler-Lehman kernel in particular, to transform graphs into a vector representation. Despite good results, these kernels have been criticized in the literature for high dimensionality and high sensitivity, so we propose an efficient subtree distance measure that is subsequently used to enrich the vector representations and enables more sensitive distance measurements. We demonstrate the usefulness in an application, where the graphs represent different source code snapshots, and a cluster analysis of these snapshots provides the lecturer an overview about the overall performance of a group of students. © 2020, The Author(s).",Conference paper,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084262556&doi=10.1007%2f978-3-030-44584-3_20&partnerID=40&md5=21eef57863f917b964b0b50d656747bf,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),245,Include,I1.1,
Zhang F.; Li G.; Liu C.; Song Q.,Flowchart-based cross-language source code similarity detection,"Source code similarity detection has various applications in code plagiarism detection and software intellectual property protection. In computer programming teaching, students may convert the source code written in one programming language into another language for their code assignment submission. Existing similarity measures of source code written in the same language are not applicable for the cross-language code similarity detection because of syntactic differences among different programming languages. Meanwhile, existing cross-language source similarity detection approaches are susceptible to complex code obfuscation techniques, such as replacing equivalent control structure and adding redundant statements. To solve this problem, we propose a cross-language code similarity detection (CLCSD) approach based on code flowcharts. In general, two source code fragments written in different programming languages are transformed into standardized code flowcharts (SCFC), and their similarity is obtained by measuring their corresponding SCFC. More specifically, we first introduce the standardized code flowchart (SCFC) model to be the uniform flowcharts representation of source code written in different languages. SCFC is language-independent, and therefore, it can be used as the intermediate structure for source code similarity detection. Meanwhile, transformation techniques are given to transform source code written in a specific programming language into an SCFC. Second, we propose the SCFC-SPGK algorithm based on the shortest path graph kernel to measure the similarity between two SCFCs. Thus, the similarity between two pieces of source code in different programming languages is given by the similarity between SCFCs. Experimental results show that compared with existing approaches, CLCSD has higher accuracy in cross-language source code similarity detection. Furthermore, CLCSD cannot only handle common source code obfuscation techniques used by students in computer programming teaching but also obtain nearly 90% accuracy in dealing with some complex obfuscation techniques. © 2020 Feng Zhang et al.",Article,2020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098566906&doi=10.1155%2f2020%2f8835310&partnerID=40&md5=3c21b3a43795466aaa3c8c8e0b211872,Scientific Programming,246,Exclude,E1.1,
Gu X.; Zhang H.; Kim S.,CodeKernel: A graph kernel based approach to the selection of API usage examples,"Developers often want to find out how to use a certain API (e.g., FileReader.read in JDK library). API usage examples are very helpful in this regard. Over the years, many automated methods have been proposed to generate code examples by clustering and summarizing relevant code snippets extracted from a code corpus. These approaches simplify source code as method invocation sequences or feature vectors. Such simplifications only model partial aspects of the code and tend to yield inaccurate examples. We propose CodeKernel, a graph kernel based approach to the selection of API usage examples. Instead of approximating source code as method invocation sequences or feature vectors, CodeKernel represents source code as object usage graphs. Then, it clusters graphs by embedding them into a continuous space using a graph kernel. Finally, it outputs code examples by selecting a representative graph from each cluster using designed ranking metrics. Our empirical evaluation shows that CodeKernel selects more accurate code examples than the related work (MUSE and eXoaDocs). A user study involving 25 developers in a multinational company also confirms the usefulness of CodeKernel in selecting API usage examples. © 2019 IEEE.",Conference paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078952975&doi=10.1109%2fASE.2019.00061&partnerID=40&md5=85dbd8c1cccc076ea3a48f8a8e86118c,"Proceedings - 2019 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019",247,Include,I1.1,
Siddik S.; Gias A.U.; Khaled S.M.,Optimizing software design migration from structured programming to object oriented paradigm,"Several industries are using legacy softwares, developed with Structured Programming (SP) approach, that should be migrated to Object Oriented Paradigm (OOP) for ensuring better software quality parameters like modularity, manageability and extendability. Automating SP to OOP migration is pivotal as it could reduce time that take in the manual process. Given this potential benefit, the issue is yet to be addressed by researchers. This paper addresses the scenario by modeling this problem as a graph clustering problem where SP functions and function calls are vertices and edges respectively. The challenge evolving the problem is to find optimized clusters from graphs. To aid this problem, certain heuristic algorithms based on Monte Carlo and Greedy approaches are being developed. The proposed algorithms have been tested against a collection of real and synthetic data. The numerical results show that greedy algorithms are faster and produced better results than the average performance of Monte Carlo based approaches. © 2014 IEEE.",Conference paper,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905036062&doi=10.1109%2fICCITechn.2014.6997320&partnerID=40&md5=d9270341cfe747f6a60e076323a6220e,"2013 16th International Conference on Computer and Information Technology, ICCIT 2013",248,Include,I1.1,
Siddik Md.S.; Ul Gias A.; Selim Md.; Khaled S.M.; Sakib K.,A direction of migrating procedural paradigm to object based architecture by forming cluster of functions using local search heuristics,"In contrast to procedural programming, object oriented design provides better modularity, manageability and extensibility. Some legacy softwares written in procedural languages phase out of upgrading and support due to an unmanageable design. This paper proposes two variations of local search based heuristic to discover clues for object oriented design from the underlying structure of procedural languages. This has the potential to help a semi-automated migration of legacy software to a new object based design. The scheme was applied on three data instances which were generated from synthetic and real life software. In terms of optimal cluster finding, results show that the proposed technique improves 24.714% and 5.66% more than Greedy and Genetic approaches respectively. © 2014 IEEE.",Conference paper,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904965622&doi=10.1109%2fICIEV.2014.6850767&partnerID=40&md5=74063c4ab0ff8022b93490fc96d539e7,"2014 International Conference on Informatics, Electronics and Vision, ICIEV 2014",249,Exclude,E3.2,
Bavota G.; De Lucia A.; Marcus A.; Oliveto R.,Automating extract class refactoring: an improved method and its evaluation,"During software evolution the internal structure of the system undergoes continuous modifications. These continuous changes push away the source code from its original design, often reducing its quality, including class cohesion. In this paper we propose a method for automating the Extract Class refactoring. The proposed approach analyzes (structural and semantic) relationships between the methods in a class to identify chains of strongly related methods. The identified method chains are used to define new classes with higher cohesion than the original class, while preserving the overall coupling between the new classes and the classes interacting with the original class. The proposed approach has been first assessed in an artificial scenario in order to calibrate the parameters of the approach. The data was also used to compare the new approach with previous work. Then it has been empirically evaluated on real Blobs from existing open source systems in order to assess how good and useful the proposed refactoring solutions are considered by software engineers and how well the proposed refactorings approximate refactorings done by the original developers. We found that the new approach outperforms a previously proposed approach and that developers find the proposed solutions useful in guiding refactorings. © 2013, Springer Science+Business Media New York.",Article,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84909999876&doi=10.1007%2fs10664-013-9256-x&partnerID=40&md5=a9c97552aca1cd265b4034330f680669,Empirical Software Engineering,250,Exclude,E1.1,
Zhong L.-H.; Xu L.; Ye M.-S.; Zheng Y.; Xie B.,An approach for software architecture refactoring based on clustering of extended component dependency graph,"For improving the evolvability of software architecture, the paper proposes a software architecture refactoring strategy based on extended clustering of component dependency relation, which consists of logical relation and evolution relation among components. By using the graph clustering algorithm, the software architecture can be restructured according to the software quality of ""high cohesion and low coupling"" under the control of our refactoring algorithm. Moreover, an example is shown for explaining its usability.",Conference paper,2009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949700560&doi=10.1109%2fCISE.2009.5362854&partnerID=40&md5=7adc7879dea903a9d4b6ad1babc5c55e,"Proceedings - 2009 International Conference on Computational Intelligence and Software Engineering, CiSE 2009",251,Include,"I1.1,I1.2",
Qiu D.; Zhang Q.; Fang S.,Reconstructing Software High-Level Architecture by Clustering Weighted Directed Class Graph,"Software architecture reconstruction plays an important role in software reuse, evolution and maintenance. Clustering is a promising technique for software architecture reconstruction. However, the representation of software, which serves as clustering input, and the clustering algorithm need to be improved in real applications. The representation should contain appropriate and adequate information of software. Furthermore, the clustering algorithm should be adapted to the particular demands of software architecture reconstruction well. In this paper, we first extract Weighted Directed Class Graph (WDCG) to represent object-oriented software. WDCG is a structural and quantitative representation of software, which contains not only the static information of software source code but also the dynamic information of software execution. Then we propose a WDCG-based Clustering Algorithm (WDCG-CA) to reconstruct high-level software architecture. WDCG-CA makes full use of the structural and quantitative information of WDCG, and avoids wrong compositions and arbitrary partitions successfully in the process of reconstructing software architecture. We introduce four metrics to evaluate the performance of WDCG-CA. The results of the comparative experiments show that WDCG-CA outperforms the comparative approaches in most cases in terms of the four metrics. © 2015 World Scientific Publishing Company.",Article,2015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941884483&doi=10.1142%2fS0218194015500072&partnerID=40&md5=ac56e15253d0402f32dac893408a22ad,International Journal of Software Engineering and Knowledge Engineering,252,Include,I1.1,
Selim M.; Siddik M.S.; Rahman T.; Gias A.U.; Khaled S.M.,Approximating object based architecture for legacy software written in procedural languages using Variable Neighborhood Search,"Legacy software, often written in procedural languages, could be a major concern for organizations due to low maintainability. A possible way out could be migrating the software to object oriented architecture, which is easier to maintain due to better modularity. However, a manual migration could take significant time and thus an automated process is required. This migration problem has been modeled as an optimal graph clustering problem where vertices and edges are represented by function and function calls respectively. Solution to this problem is NP-hard and thus meta-heuristic base approaches are potential to get near optimal result. This paper presents a Variable Neighborhood Search (VNS) approach for addressing the modeled graph clustering problem. The method provides a set of clusters that gives a clue for possible structure of the object oriented architecture. This approach is based on the objective to minimize the coupling and maximize the cohesion within the clusters. The proposed algorithm was implemented and its performance was compared with state of the art techniques. It is observed that the proposed method produced 37.15% and 12.02% better results in contrast to genetic algorithm and local search heuristics. © 2014 IEEE.",Conference paper,2014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949924477&doi=10.1109%2fSKIMA.2014.7083558&partnerID=40&md5=fa5870a96cd8c14d04b26a176d463d65,"SKIMA 2014 - 8th International Conference on Software, Knowledge, Information Management and Applications",253,Exclude,E3.2,
Chirila C.-B.; Sora I.,The Optimization of a Page Rank Based Key Classes Classifier using Simulated Annealing with ROC-AUC and Recall Metrics,"Nowadays, software projects from different industrial sectors tend to grow from tens of classes towards sizes of hundreds or even thousands of classes. Key classes or hotspots are the most important classes in a project. They represent the starting point for any maintenance operation. In this context key classes detection is an important software engineering task, especially in projects where documentation is poor or missing totally. In the state of the art there are several key classes classifiers based on different representations and algorithms. We focus on the empirical parameters of a classifier based on weighted graph representation of the source code combined with a Page Rank algorithm which give the best results compared to previous works results available online. The empirical parameters represent weights assigned to several relations between classes like: inheritance between two classes, interface implementation between a class and an interface etc. Initially the parameters were manually set, having empirical values. It is not known if other sets of values for the parameters will not give better diagnostic abilities to the classifier. To test the entire parameters state space is virtually impossible for 12 Java software projects and 15 parameters with values varying in the integer range. Using the Simulated Annealing optimization algorithm we start with the manually set values for the parameters and we optimize the objective functions based on ROC-AUC and Recall metrics. © 2019 IEEE.",Conference Paper,2019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075065323&doi=10.1109%2fSACI46893.2019.9111601&partnerID=40&md5=1156fad3845e01b6654b7b6870f54408,"SACI 2019 - IEEE 13th International Symposium on Applied Computational Intelligence and Informatics, Proceedings",254,Include,I1.1,
Tao W.; Su X.; Wan J.; Wei H.; Zheng W.,Vulnerability detection through cross-modal feature enhancement and fusion,"Software vulnerability detection is critical to computer security. Most existing vulnerability detection methods use single modal-based vulnerability detection models, which cannot effectively extract cross-modal features. To solve this problem, we propose a new multimodal deep learning based vulnerability detection method through a cross-modal feature enhancement and fusion. Firstly, we utilize a special compilation and debugging method to obtain the alignment relationship between source code statements and assembly instructions, as well as between source code variables and assembly code registers. Based on this alignment relationship and program slicing technology, we propose a cross-slicing method to generate bimodal program slices. Then, we propose a cross-modal feature enhanced code representation learning model to capture the fine-grained semantic correlation between source code and assembly code by using the co-attention mechanisms. Finally, vulnerability detection is achieved by feature level fusion of semantic features captured in fine-grained aligned source code and assembly code. Extensive experiments show that our method improves the performance of vulnerability detection compared with state-of-the-art methods. Specifically, our method achieves an accuracy of 97.4% and an F1-measure of 93.4% on the SARD dataset. An average accuracy of 95.4% and an F1-measure of 89.1% on two real-world software projects (i.e., FFmpeg and OpenSSL) is also achieved by our method, improving over SOTA method 4.5% and 2.9%. © 2023 Elsevier Ltd",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164226069&doi=10.1016%2fj.cose.2023.103341&partnerID=40&md5=ca46f4fe4e03e4bca2666a232984994d,Computers and Security,255,Exclude,E1.1,
Mirsky Y.; MacOn G.; Brown M.; Yagemann C.; Pruett M.; Downing E.; Mertoguno S.; Lee W.,VulChecker: Graph-based Vulnerability Localization in Source Code,"In software development, it is critical to detect vulnerabilities in a project as early as possible. Although, deep learning has shown promise in this task, current state-of-the-art methods cannot classify and identify the line on which the vulnerability occurs. Instead, the developer is tasked with searching for an arbitrary bug in an entire function or even larger region of code. In this paper, we propose VulChecker: a tool that can precisely locate vulnerabilities in source code (down to the exact instruction) as well as classify their type (CWE). To accomplish this, we propose a new program representation, program slicing strategy, and the use of a message-passing graph neural network to utilize all of code's semantics and improve the reach between a vulnerability's root cause and manifestation points. We also propose a novel data augmentation strategy for cheaply creating strong datasets for vulnerability detection in the wild, using free synthetic samples available online.With this training strategy,VulCheckerwas able to identify 24 CVEs (10 from 2019&2020) in 19 projects taken from the wild, with nearly zero false positives compared to a commercial tool that could only detect 4. VulChecker also discovered an exploitable zero-day vulnerability, which has been reported to developers for responsible disclosure. © 2023 32nd USENIX Security Symposium, USENIX Security 2023. All rights reserved.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172385383&partnerID=40&md5=b65bb84e01429db78bbf2ec291d6097f,"32nd USENIX Security Symposium, USENIX Security 2023",256,Include,I1.1,
Viet Phan A.; Le Nguyen M.; Thu Bui L.,Convolutional neural networks over control flow graphs for software defect prediction,"Existing defects in software components is unavoidable and leads to not only a waste of time and money but also many serious consequences. To build predictive models, previous studies focus on manually extracting features or using tree representations of programs, and exploiting different machine learning algorithms. However, the performance of the models is not high since the existing features and tree structures often fail to capture the semantics of programs. To explore deeply programs' semantics, this paper proposes to leverage precise graphs representing program execution flows, and deep neural networks for automatically learning defect features. Firstly, control flow graphs are constructed from the assembly instructions obtained by compiling source code; we thereafter apply multi-view multi-layer directed graph-based convolutional neural networks (DGCNNs) to learn semantic features. The experiments on four real-world datasets show that our method significantly outperforms the baselines including several other deep learning approaches. © 2017 IEEE.",Conference paper,2017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048483561&doi=10.1109%2fICTAI.2017.00019&partnerID=40&md5=707b5b2e13cd2bb78a670a75996004a4,"Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI",257,Include,I1.1,
Zeng C.; Yu Y.; Li S.; Xia X.; Wang Z.; Geng M.; Bai L.; Dong W.; Liao X.,deGraphCS: Embedding Variable-based Flow Graph for Neural Code Search,"With the rapid increase of public code repositories, developers maintain a great desire to retrieve precise code snippets by using natural language. Despite existing deep learning-based approaches that provide end-to-end solutions (i.e., accept natural language as queries and show related code fragments), the performance of code search in the large-scale repositories is still low in accuracy because of the code representation (e.g., AST) and modeling (e.g., directly fusing features in the attention stage). In this paper, we propose a novel learnable deep Graph for Code Search (called deGraphCS) to transfer source code into variable-based flow graphs based on an intermediate representation technique, which can model code semantics more precisely than directly processing the code as text or using the syntax tree representation. Furthermore, we propose a graph optimization mechanism to refine the code representation and apply an improved gated graph neural network to model variable-based flow graphs. To evaluate the effectiveness of deGraphCS, we collect a large-scale dataset from GitHub containing 41,152 code snippets written in the C language and reproduce several typical deep code search methods for comparison. The experimental results show that deGraphCS can achieve state-of-the-art performance and accurately retrieve code snippets satisfying the needs of the users.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153750091&doi=10.1145%2f3546066&partnerID=40&md5=bd8b4bfceb84f7efe993d499261fbcd2,ACM Transactions on Software Engineering and Methodology,258,Include,"I1.1,I1.2",
Ma Y.; Yu Y.; Li S.; Jia Z.; Ma J.; Xu R.; Dong W.; Liao X.,MulCS: Towards a Unified Deep Representation for Multilingual Code Search,"Code search aims to search for relevant code snippets through queries, which has become an essential requirement to assist programmers in software development. With the availability of large and rapidly growing source code repositories covering various languages, multilingual code search can leverage more training data to learn complementary information across languages. Contrastive learning can naturally understand the similarity between functionally equivalent code across different languages by narrowing the distance between objects with the same function while keeping dissimilar objects further apart. Some works exist addressing monolingual code search problems with contrastive learning, however, they mainly exploit every specific programming language's textual semantics or syntactic structures for code representation. Due to the high diversity of different languages in terms of syntax, format, and structure, these methods limit the performance of contrastive learning in multilingual training. To bridge this gap, we propose a unified semantic graph representation approach toward multilingual code search called MulCS. Specifically, we first design a general semantic graph construction strategy across different languages by Intermediate Representation (IR). Furthermore, we introduce the contrastive learning module integrated into a gated graph neural network (GGNN) to enhance query-multilingual code matching. The extensive experiments on three representative languages illustrate that our method outperforms state-of-the-art models by 10.7% to 77.5% in terms of MRR on average. © 2023 IEEE.",Conference paper,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160560651&doi=10.1109%2fSANER56733.2023.00021&partnerID=40&md5=7891f2c53d03c2ddb212c471a64458da,"Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023",259,Include,I1.1,
Chen Z.,Semantic based Cross-Language Clone Related Bug Detection,"Code clones are widespread in software since programmers always reuse code to reduce programming effort. As programming languages are continuing to evolve and morph, code clones also widely exist across different languages for platform compatibility and adoption. Although code clones can improve development efficiency, they are prone to introducing bugs. Existing code clone detection technologies, however, mainly focused on single programming language or syntactical features of code. The syntax of different programming language are diverse because of syntax sugar, and many cloning pairs are semantic related instead of syntactic similar, such as Type 4 clones. To bridge the gap between syntax and semantic, and detect clone-related bugs more accurately, we explore an IR (Intermediate Representation) based method to represent code semantic representation information of multiple language code. We utilize graph neural network to learn code semantic representation. Through the semantic representation, we can detect more cross-language clone related bugs across multiple language.  © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127493196&doi=10.1109%2fAINIT54228.2021.00101&partnerID=40&md5=6ced2448716044d6fed75c1d1331ad66,"Proceedings - 2021 2nd International Seminar on Artificial Intelligence, Networking and Information Technology, AINIT 2021",260,Include,I1.1,
Lin G.; Zhang J.; Luo W.; Pan L.; Xiang Y.; De Vel O.; Montague P.,Cross-Project Transfer Representation Learning for Vulnerable Function Discovery,"Machine learning is now widely used to detect security vulnerabilities in the software, even before the software is released. But its potential is often severely compromised at the early stage of a software project when we face a shortage of high-quality training data and have to rely on overly generic hand-crafted features. This paper addresses this cold-start problem of machine learning, by learning rich features that generalize across similar projects. To reach an optimal balance between feature-richness and generalizability, we devise a data-driven method including the following innovative ideas. First, the code semantics are revealed through serialized abstract syntax trees (ASTs), with tokens encoded by Continuous Bag-of-Words neural embeddings. Next, the serialized ASTs are fed to a sequential deep learning classifier (Bi-LSTM) to obtain a representation indicative of software vulnerability. Finally, the neural representation obtained from existing software projects is then transferred to the new project to enable early vulnerability detection even with a small set of training labels. To validate this vulnerability detection approach, we manually labeled 457 vulnerable functions and collected 30 000+ nonvulnerable functions from six open-source projects. The empirical results confirmed that the trained model is capable of generating representations that are indicative of program vulnerability and is adaptable across multiple projects. Compared with the traditional code metrics, our transfer-learned representations are more effective for predicting vulnerable functions, both within a project and across multiple projects. © 2005-2012 IEEE.",Article,2018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044759580&doi=10.1109%2fTII.2018.2821768&partnerID=40&md5=7b39cae920b250cce5566de38edd8f68,IEEE Transactions on Industrial Informatics,261,Include,I1.1,lin ast 
Zhang C.; Xin Y.,VulGAI: vulnerability detection based on graphs and images,"Deep learning models have been widely used in the field of vulnerability detection. Deep learning-based vulnerability detection methods can automatically learn code patterns. Some methods consider processing codes as text sequences to achieve scalable vulnerability detection. They leverage natural language processing models to extract code features. These methods do not consider the code's semantic structure and treat code slices as text. Vulnerability detection methods based on graph structures and graph neural networks are more accurate than text-based methods. However, these methods lack scalability in practice. Both graph generation and graph neural network training are all time-consuming. We propose a vulnerability detection method based on graphs and images (VulGAI). VulGAI choose the more reasonable node centrality to generate the image. It can preserve program details and distinguish node importance from different perspectives. In addition, we design a more efficient CNN model, which reduces computational overhead and improves detection performance (Time and Accuracy). We implement VulGAI and evaluate six methods (VulDePecker, SySeVR, Devign, VulCNN, mVulPreter, and VulGAI) on 40,657 functions. Experimental results show that VulGAI achieves higher Accuracy, TPR, and F1-Score than the others. In addition, we compare VulGAI and VulCNN on 30270 real-world functions. VulGAI outperforms VulCNN by 1.48 times in the number of TP. VulGAI is about 3.9 times faster than VulCNN in detection time. © 2023 Elsevier Ltd",Article,2023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173161023&doi=10.1016%2fj.cose.2023.103501&partnerID=40&md5=9e57107e2986651d8ddcf8caabc908fc,Computers and Security,262,Include,I1.1,
Wu Y.; Zou D.; Dou S.; Yang W.; Xu D.; Jin H.,VulCNN: An Image-inspired Scalable Vulnerability Detection System,"Since deep learning (DL) can automatically learn features from source code, it has been widely used to detect source code vulnerability. To achieve scalable vulnerability scanning, some prior studies intend to process the source code directly by treating them as text. To achieve accurate vulnerability detection, other approaches consider distilling the program semantics into graph representations and using them to detect vulnerability. In practice, text-based techniques are scalable but not accurate due to the lack of program semantics. Graph-based methods are accurate but not scalable since graph analysis is typically time-consuming. In this paper, we aim to achieve both scalability and accuracy on scanning large-scale source code vulnerabilities. Inspired by existing DL-based image classification which has the ability to analyze millions of images accurately, we prefer to use these techniques to accomplish our purpose. Specifically, we propose a novel idea that can efficiently convert the source code of a function into an image while preserving the program details. We implement Vul-CNN and evaluate it on a dataset of 13,687 vulnerable functions and 26,970 non-vulnerable functions. Experimental results report that VulCNN can achieve better accuracy than eight state-of-the-art vul-nerability detectors (i.e., Checkmarx, FlawFinder, RATS, TokenCNN, VulDeePecker, SySeVR, VulDeeLocator, and Devign). As for scalability, VulCNN is about four times faster than VulDeePecker and SySeVR, about 15 times faster than VulDeeLocator, and about six times faster than Devign. Furthermore, we conduct a case study on more than 25 million lines of code and the result indicates that VulCNN can detect large-scale vulnerability. Through the scanning reports, we finally discover 73 vulnerabilities that are not reported in NVD. © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133506161&doi=10.1145%2f3510003.3510229&partnerID=40&md5=5067c6763020b702bf6f767155caf849,Proceedings - International Conference on Software Engineering,263,Include,I1.1,
Jinpa T.; Gao Y.,Code Representation Learning Using Prüfer Sequences (Student Abstract),"An effective and efficient encoding of the source code of a computer program is critical to the success of sequence-to-sequence deep neural network models for code representation learning. In this study, we propose to use the Prüfer sequence of the Abstract Syntax Tree (AST) of a computer program to design a sequential representation scheme that preserves the structural information in an AST. Our representation makes it possible to develop deep-learning models in which signals carried by lexical tokens in the training examples can be exploited automatically and selectively based on their syntactic role and importance. Unlike other recently-proposed approaches, our representation is concise and lossless in terms of the structural information of the AST. Results from our experiment show that prüfersequence-based representation is indeed highly effective and efficient. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147607636&partnerID=40&md5=fde81c806a8d45c389e74d6a5a2580b9,"Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022",264,Exclude,I1.8,
Deng Z.; Xu L.; Liu C.; Yan M.; Xu Z.; Lei Y.,Fine-grained Co-Attentive Representation Learning for Semantic Code Search,"Code search aims to find code snippets from large-scale code repositories based on the developer's query intent. A significant challenge for code search is the semantic gap between programming language and natural language. Recent works have indicated that deep learning (DL) techniques can perform well by automatically learning the relationships between query and code. Among these DL-based approaches, the state-of-the-art model is TabCS, a two-stage attention-based model for code search. However, TabCS still has two limitations: semantic loss and semantic confusion. TabCS breaks the structural information of code into token-level words of abstract syntax tree (AST), which loses the sequential semantics between words in programming statements, and it uses a co-attention mechanism to build the semantic correlation of code-query after fusing all features, which may confuse the correlations between individual code features and query. In this paper, we propose a code search model named FcarCS (Fine-grained Co-Attentive Representation Learning Model for Semantic Code Search). FcarCS extracts code textual features (i.e., method name, API sequence, and tokens) and structural features that introduce a statement-level code structure. Unlike TabCS, FcarCS splits AST into a series of subtrees corresponding to code statements and treats each subtree as a whole to preserve sequential semantics between words in code statements. FcarCS constructs a new fine-grained co-attention mechanism to learn interdependent representations for each code feature and query, respectively, instead of performing one co-attention process for the fused code features like TabCS. Generally, this mechanism leverages row/column-wise CNN to enable our model to focus on the strongly correlated local information between code feature and Query. We train and evaluate FcarCS on an open Java dataset with 475k and 10k code/query pairs, respectively. Experimental results show that FcarCS achieves an MRR of 0.613, outperforming three state-of-the-art models DeepCS, UNIF, and TabCS, by 117.38%, 16.76%, and 12.68%, respectively. We also performed a user study for each model with 50 real-world queries, and the results show that FcarCS returned code snippets that are more relevant than the baseline models.  © 2022 IEEE.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135793766&doi=10.1109%2fSANER53432.2022.00055&partnerID=40&md5=1795969acdea1df7b7ad47fcfce02acd,"Proceedings - 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022",265,Include,I1.1,lin ast 
Xu L.; Yang H.; Liu C.; Shuai J.; Yan M.; Lei Y.; Xu Z.,Two-Stage Attention-Based Model for Code Search with Textual and Structural Features,"Searching and reusing existing code from a large scale codebase can largely improve developers' programming efficiency. To support code reuse, early code search models leverage information retrieval (IR) techniques to index a large-scale code corpus and return relevant code according to developers' search query. However, IR-based models fail to capture the semantics in code and query. To tackle this issue, developers applied deep learning (DL) techniques to code search models. However, these models either are too complex to determine an effective method efficiently or learning for semantic correlation between code and query inadequately.To bridge the semantic gap between code and query effectively and efficiently, we propose a code search model TabCS (Two-stage Attention-Based model for Code Search) in this study. TabCS extracts code and query information from the code textual features (i.e., method name, API sequence, and tokens), the code structural feature (i.e., abstract syntax tree), and the query feature (i.e., tokens). TabCS performs a two-stage attention net-work structure. The first stage leverages attention mechanisms to extract semantics from code and query considering their semantic gap. The second stage leverages a co-attention mechanism to capture their semantic correlation and learn better code/query representation. We evaluate the performance of TabCS on two existing large-scale datasets with 485k and 542k code snippets, respectively. Experimental results show that TabCS achieves an MRR of 0.57 on Hu et al.'s dataset, outperforming three state-of-the-art models CARLCS-CNN, DeepCS, and UNIF by 18%, 70%, 12%, respectively. Meanwhile, TabCS gains an MRR of 0.54 on Husain et al.'s, outperforming CARLCS-CNN, DeepCS, and UNIF by 32%, 76%, 29%, respectively. © 2021 IEEE.",Conference paper,2021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106570287&doi=10.1109%2fSANER50967.2021.00039&partnerID=40&md5=a2919fe897a6c6adecf47a4796258956,"Proceedings - 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2021",266,Include,I1.1,lin ast 
Yang S.; Gu X.; Shen B.,Self-Supervised Learning of Smart Contract Representations,"Learning smart contract representations can greatly facilitate the development of smart contracts in many tasks such as bug detection and clone detection. Existing approaches for learning program representations are difficult to apply to smart contracts which have insufficient data and significant homogenization. To overcome these challenges, in this paper, we propose SRCL, a novel, self-supervised approach for learning smart contract representations. Unlike ex-isting supervised methods, which are tied on task-specific data labels, SRCL leverages large-scale unlabeled data by self-supervised learning of both local and global information of smart contracts. It automatically extracts structural sequences from abstract syntax trees (ASTs). Then, two discriminators are designed to guide the Transformer encoder to learn local and global semantic features of smart contracts. We evaluate SRCL on a dataset of 75,006 smart contracts collected from Etherscan. Experimental results show that SRCL considerably outperforms the state-of-the-art code represen-tation models on three downstream tasks.  © 2022 ACM.",Conference paper,2022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133158808&doi=10.1145%2f3524610.3527894&partnerID=40&md5=8ca8720f70660086fafd22863769106d,IEEE International Conference on Program Comprehension,267,Include,I1.1,lin ast
