Title,Full Reference
api2com: on the improvement of automatically generated code comments using api documentations,"Shahbazi R., Sharma R., Fard F.H., API2Com: On the improvement of automatically generated code comments using api documentations, International Conference on Program Comprehension. IEEE, pp. 411-421, (2021)"
an extractive-and-abstractive framework for source code summarization,"Sun W., Fang C., Chen Y., Zhang Q., Tao G., Han T., Et al., An extractive-and-abstractive framework for source code summarization, (2022)"
foundations of statistical natural language processing,"Manning C.D., Schutze H., Foundations of Statistical Natural Language Processing, (1999)"
a statistical semantic language model for source code,"Nguyen T.T., Nguyen A.T., Nguyen H.A., Nguyen T.N., A statistical semantic language model for source code, Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering (ESEC/FSE 2013), (2013)"
comments are more important than code,"Raskin J., Comments Are More Important Than Code, ACM Queue, 3, (2005)"
unixcoder: unified cross-modal pre-training for code representation,"Guo D., Lu S., Duan N., Wang Y., Zhou M., Yin J., UniXcoder: Unified cross-modal pre-training for code representation, Proceedings of the annual meeting of the Association for Computational Linguistics, pp. 7212-7225, (2022)"
exploring the limits of transfer learning with a unified text-to-text transformer,"Raffel C., Shazeer N., Roberts A., Lee K., Narang S., Matena M., Zhou Y., Li W., Liu P.J., Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer, Journal of Machine Learning Research, 21, 140, pp. 1-67, (2020)"
treegen: a tree-based transformer architecture for code generation,"Sun Z., Zhu Q., Xiong Y., Sun Y., Mou L., Zhang L., TreeGen: A tree-based transformer architecture for code generation, AAAI, (2020)"
codeattention: translating source code to comments by exploiting the code constructs,"Zheng W., Zhou H., Li M., Wu J., Codeattention: Translating source code to comments by exploiting the code constructs, Frontiers of Computer Science, 13, pp. 565-578, (2019)"
codegen: an open large language model for code with multi-turn program synthesis,"Nijkamp E., Et al., Codegen: An open large language model for code with multi-turn program synthesis, The Eleventh International Conference on Learning Representations, (2023)"
towards automatically generating summary comments for java methods,"Sridhara G., Hill E., Muppaneni D., Pollock L., Vijay-Shanker K., Towards automatically generating summary comments for Java methods, Proceedings of the IEEE/ACM international conference on Automated software engineering, pp. 43-52, (2010)"
automatic documentation generation via source code summarization of method context,"McBurney P.W., McMillan C., Automatic documentation generation via source code summarization of method context, 22nd International Conference on Program Comprehension, ICPC 2014, Hyderabad, India, June 2-3, 2014, pp. 279-290, (2014)"
a deep neural network language model with contexts for source code,"Nguyen A.T., Nguyen T.D., Phan H.D., Nguyen T.N., A deep neural network language model with contexts for source code, SANER, pp. 323-334, (2018)"
multi-task learning based pretrained language model for code completion,"Liu F., Li G., Zhao Y., Jin Z., Multi-task learning based pretrained language model for code completion, Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering., pp. 473-485, (2020)"
code completion with statistical language models,"Raychev V., Vechev M., Yahav E., Code completion with statistical language models, Proc. of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation, (2014)"
neural code comprehension: a learnable representation of code semantics,"Ben-Nun T., Jakobovits A. S., Hoefler T., Neural code comprehension: a learnable representation of code semantics, Advances in Neural Information Processing Systems, pp. 3585-3597, (2018)"
codebert: a pre-trained model for programming and natural languages. arxiv preprint arxiv,"Feng Z., Guo D., Tang D., Et al., Codebert: A Pre-Trained Model for Programming and Natural Languages. Arxiv Preprint Arxiv, 2002, (2020)"
a synopsis of linguistic theory,"Firth J.R., A Synopsis of Linguistic Theory, 1930-1955, (1957)"
tener: adapting transformer encoder for named entity recognition,"Yan H., Deng B., Li X., Qiu X., Tener: Adapting transformer encoder for named entity recognition, (2019)"
2019 roberta: a robustly optimized bert pretraining approach,"Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., 2019 RoBERTa: A Robustly Optimized BERT Pretraining Approach, CoRR abs/1907 11692, (2019)"
the small world of human language,"Cancho R.F.I., Sole R.V., The small world of human language, Proceedings of the Royal Society of London B: Biological Sciences, 268, 1482, pp. 2261-2265, (2001)"
deep learning on graphs for natural language processing. acm,"Wu L., Chen Y., Ji H., Liu B., Deep Learning on Graphs for Natural Language Processing. ACM, pp. 2651-2653, (2021)"
a neural probabilistic language model,"Bengio Y., Ducharme R., Vincent P., Janvin C., A neural probabilistic language model, The Journal of Machine Learning Research, 3, pp. 1137-1155, (2003)"
neural symbolic machines: learning semantic parsers on freebase with weak supervision,"Liang C., Berant J., Le Q., Forbus K.D., Lao N., Neural symbolic machines: Learning semantic parsers on freebase with weak supervision, Arxiv Preprint Arxiv, 1611, (2016)"
automatic source code summarization with extended treelstm,"Shido Y., Kobayashi Y., Yamamoto A., Miyamoto A., Matsumura T., Automatic Source Code Summarization with Extended Treelstm, (2019)"
a tutorial on hidden markov models and selected applications in speech recognition,"Rabiner L.R., A tutorial on hidden markov models and selected applications in speech recognition, Proceedings of The IEEE, 77, 2, pp. 257-286, (1989)"
code-bert: a pre-trained model for programming and natural languages,"Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Code-BERT: A Pre-Trained Model for Programming and Natural Languages, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, pp. 1536-1547, (2020)"
transformer-xl: attentive language models beyond a fixed-length context,"Dai Z., Yang Z., Yang Y., Carbonell J., Le Q., Salakhutdinov R., Transformer-xl: Attentive language models beyond a fixed-length context, Acl, pp. 2978-2988, (2019)"
automatic code summarization via multi-dimensional semantic fusing in gnn,"Liu S., Chen Y., Xie X., Siow J., Liu Y., Automatic code summarization via multi-dimensional semantic fusing in GNN, CoRR, (2020)"
a canonicalizing model for building programming tutors,"RIVERS K., KOEDINGER K. R., A canonicalizing model for building programming tutors, Proceedings of the 11th International Conference on Intelligent Tutoring Systems, (ITS 2012), pp. 591-593, (2012)"
a survey of automatic source code summarization,"Zhang C., Wang J., Zhou Q., Xu T., Tang K., Gui H., Liu F., A survey of automatic source code summarization, Symmetry, 14, (2022)"
summarizing source code with transferred api knowledge,"Hu X., Li G., Xia X., Lo D., Lu S., Jin Z., Summarizing Source Code with Transferred API Knowledge, Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018, pp. 2269-2275"
a structural model for contextual code changes,"Brody S., Alon U., Yahav E., A structural model for contextual code changes, Proceedings of the ACM on Programming Languages, 4, pp. 1-28, (2020)"
m2trec: metadata-aware multi-task transformer for large-scale and cold-start free session-based recommendations,"Shalaby W., Oh S., Afsharinejad A., Kumar S., Cui X., M2TRec: Metadata-aware Multi-task Transformer for Large-scale and Cold-start free Session-based Recommendations, RecSys, pp. 573-578, (2022)"
using stereotypes in the automatic generation of natural language summaries for c++ methods,"Abid N.J., Dragan N., Collard M.L., Maletic J.I., Using stereotypes in the automatic generation of natural language summaries for C++ methods, Proc. IEEE Int. Conf. Softw. Maintenance Evol, pp. 561-565, (2015)"
sensory: leveraging code statement sequence information for code snippets recommendation,"Ai L., Huang Z., Li W., Zhou Y., Yu Y., SENSORY: Leveraging code statement sequence information for code snippets recommendation, Proc. IEEE 43rd Annu. Comput. Softw. Appl. Conf., pp. 27-36, (2019)"
semantic scaffolds for pseudocode-to-code generation,"Zhong R., Stern M., Klein D., Semantic scaffolds for pseudocode-to-code generation, (2020)"
phog: probabilistic model for code,"Bielik P., Raychev V., Vechev M., Phog: Probabilistic model for code, Proceedings of the 33rd International Conference on Machine Learning (Proceedings of Machine Learning Research), 48, pp. 2933-2942, (2016)"
re_trans: combined retrieval and transformer model for source code summarization,"Zhang C., Zhou Q., Qiao M., Tang K., Xu L., Liu F., Re_trans: Combined retrieval and transformer model for source code summarization, (2022)"
a survey on pretrained language models for neural code intelligence,"Xu Y., Zhu Y., A Survey on Pretrained Language Models for Neural Code Intelligence, (2022)"
tranx: a transition-based neural abstract syntax parser for semantic parsing and code generation,"Yin P., Neubig G., TRANX: A Transition-based Neural Abstract Syntax Parser for Semantic Parsing and Code Generation, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pp. 7-12, (2018)"
learning human-written commit messages to document code changes,"Huang Y., Jia N., Zhou H., Chen X., Zheng Z., Tang M., Learning human-written commit messages to document code changes, Journal of Computer Science and Technology, 35, 6, pp. 1258-1277, (2020)"
polyhedral code generation in the real world,"Vasilache N., Bastoul C., Cohen A., Polyhedral code generation in the real world, Compiler Construction, pp. 185-201, (2006)"
generating commit messages from diffs using pointer-generator network,"Liu Q., Liu Z., Zhu H., Fan H., Du B., Qian Y., Generating commit messages from diffs using pointer-generator network, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR). IEEE, pp. 299-309, (2019)"
retrieve and refine: exemplarbased neural comment generation,"Wei B., Li Y., Li G., Xia X., Jin Z., Retrieve and refine: Exemplarbased neural comment generation, Proc. IEEE/ACM 35th Int. Conf. Automated Softw. Eng, pp. 349-360, (2020)"
code summarization with structure-induced transformer,"Wu H., Zhao H., Zhang M., Code summarization with structure-induced transformer, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pp. 1078-1090, (2021)"
learning scalable and precise representation of program semantics,"Wang K., Learning Scalable and Precise Representation of Program Semantics, (2019)"
probabilistic model for code with decision trees,"Raychev V., Bielik P., Vechev M.T., Probabilistic model for code with decision trees, Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2016, Part of SPLASH 2016, Amsterdam, the Netherlands, October 30 - November 4, 2016. ACM, pp. 731-747, (2016)"
learning continuous semantic representations of symbolic expressions,"Allamaras M., Chanthirasegaran P., Kohli P., Sutton C., Learning continuous semantic representations of symbolic expressions, 34th International Conference on Machine Learning, ICML 2017, 1, pp. 118-131, (2017)"
english stop words,"English stop words, (2021)"
representation learning for natural language processing,"Liu Z., Lin Y., Sun M., Representation Learning for Natural Language Processing, (2020)"
nltk: the natural language toolkit,"Bird S., NLTK: the natural language toolkit, ACL 2006, 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, pp. 69-72, (2006)"
a dual framework for implicit and explicit emotion recognition: an ensemble of language models and computational linguistics,"Khoshnam F., Baraani-Dastjerdi A., A dual framework for implicit and explicit emotion recognition: An ensemble of language models and computational linguistics, Expert Systems with Applications, 198, (2022)"
adaptivepaste: code adaptation through learning semantics-aware variable usage representations,"Liu X., Jang J., Sundaresan N., Allamanis M., Svyatkovskiy A., Adaptivepaste: Code adaptation through learning semantics-aware variable usage representations, (2022)"
towards context-aware code comment generation,"Yu X., Huang Q., Wang Z., Feng Y., Zhao D., Towards context-aware code comment generation, Findings of the Association for Computational Linguistics: EMNLP, pp. 3938-3947, (2020)"
on automatic summarization of what and why information in source code changes,"Shen J., Sun X., Li B., Yang H., Hu J., On automatic summarization of what and why information in source code changes, 2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC), 1, pp. 103-112, (2016)"
realformer: transformer likes residual attention,"He R., Ravula A., Kanagal B., Ainslie J., Realformer: Transformer likes residual attention, (2020)"
a multilingual bpe embedding space for universal sentiment lexicon induction,"Zhao M., Schutze H., A Multilingual BPE Embedding Space for Universal Sentiment Lexicon Induction, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics., pp. 3506-3517, (2019)"
self-documenting code: 67–90,"Stueben M., Self-DOCUMENTING CODE: 67–90, (2018)"
learning to update natural language comments based on code changes,"Panthaplackel S., Nie P., Gligoric M., Li J.J., Mooney R.J., Learning to update natural language comments based on code changes, Arxiv: Cs.Cl/2004.12169, (2020)"
codesum: translate program language to natural language,"Hu X., Wei Y., Li G., Jin Z., CodeSum: Translate Program Language to Natural Language, (2017)"
a deep language model for software code,"Dam H.K., Tran T., Pham T.T.M., A deep language model for software code, FSE 2016: Proceedings of the Foundations Software Engineering International Symposium, pp. 1-4, (2016)"
hadamard matrices and their applications,"Horadam K.J., Hadamard matrices and their applications, (2012)"
automatically generating natural language descriptions for object-related statement sequences,"Wang X., Pollock L., Vijay-Shanker K., Automatically generating natural language descriptions for object-related statement sequences, 2017 IEEE 24th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 205-216, (2017)"
structured programming and structured design as art forms,"Yourdon E., Structured programming and structured design as art forms, Proceedings of the May 19-22, 1975, National Computer Conference and Exposition (AFIPS '75), pp. 277-277, (1975)"
unsupervised translation of programming languages,"Roziere B., Lachaux M., Chanussot L., Lample G., Unsupervised translation of programming languages, Proceedings of the Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, (2020)"
a scalable hierarchical distributed language model,"Mnih A., Hinton G.E., A scalable hierarchical distributed language model, Proceedings of the 22nd Annual Conference on Neural Information Processing Systems, pp. 1081-1088, (2008)"
graph-based statistical language model for code,"Nguyen A. T., Nguyen T. N., Graph-based statistical language model for code, Proceedings of the 2015 37th IEEE International Conference on Software Engineering, 1, pp. 858-868, (2015)"
a neural model for generating natural language summaries of program subroutines,"LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, Icse, pp. 795-806, (2019)"
nl2bash: a corpus and semantic parser for natural language interface to the linux operating system,"Victoria Lin X., Wang C., Zettlemoyer L., Ernst M.D., Nl2bash: A corpus and semantic parser for natural language interface to the linux operating system, LREC, (2018)"
class-based n-gram models of natural language,"Brown P. F., Della Pietra V. J., Desouza P. V., Lai J. C., Mercer R. L., Class-based n-gram models of natural language, Computational Linguistics, 18, 4, pp. 467-480, (1992)"
neural network methods in natural language processing,"Goldberg Y., Hirst G., Neural Network Methods in Natural Language Processing, (2017)"
neural networks for modeling source code edits,"Zhao R., Bieber D., Swersky K., Tarlow D., Neural networks for modeling source code edits, (2019)"
evaluating large language models trained on code,"Chen M., Tworek J., Jun H., Yuan Q., Pinto H.P.D.O., Kaplan J., Et al., Evaluating large language models trained on code, (2021)"
automatically generating commit messages from diffs using neural machine translation,"Jiang S., Armaly A., McMillan C., Automatically generating commit messages from diffs using neural machine translation, 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 135-146, (2017)"
trex: learning execution semantics from micro-traces for binary similarity,"Pei K., Xuan Z., Yang J., Jana S., Ray B., Trex: Learning execution semantics from micro-traces for binary similarity, (2020)"
context-aware retrieval-based deep commit message generation,"Wang H., Xia X., Lo D., He Q., Wang X., Grundy J., Context-aware retrieval-based deep commit message generation, ACM Transactions on Software Engineering and Methodology (TOSEM), 30, 4, pp. 1-30, (2021)"
summarizing source code with hierarchical code representation,"Zhou Z., Yu H., Fan G., Huang Z., Yang X., Summarizing source code with hierarchical code representation, Inf. Softw. Technol., 143, (2022)"
neural models of automated documentation generation for source code. dissertation. university of notre dame,"Alexander L., Neural Models of Automated Documentation Generation for Source Code. Dissertation. University of Notre Dame"
assemble foundation models for automatic code summarization,"Gu J., Salza P., Gall H.C., Assemble foundation models for automatic code summarization, IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022, Honolulu, HI, USA, March 15-18, 2022, pp. 935-946, (2022)"
tag: type auxiliary guiding for code comment generation,"Cai R., Liang Z., Xu B., Li Z., Hao Y., Chen Y., TAG: Type Auxiliary Guiding for Code Comment Generation, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 291-301, (2020)"
code2seq: generating sequences from structured representations of code[c],"Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating sequences from structured representations of code[C], International Conference on Learning Representations, (2019)"
exploring software naturalness through neural language models,"Buratti L., Pujar S., Bornea M., McCarley S., Zheng Y., Rossiello G., Morari A., Laredo J., Thost V., Zhuang Y., Et al., Exploring software naturalness through neural language models, (2020)"
natural language is a programming language: applying natural language processing to software development,"Ernst M.D., Natural language is a programming language: Applying natural language processing to software development, SNAPL, pp. 1-14, (2017)"
summarization techniques for code,"Panichella S., Summarization techniques for code, change, testing, and user feedback, 2018 IEEE Workshop on Validation, Analysis and Evolution of Software Tests (VST), pp. 1-5, (2018)"
transformers: state-of-the-art natural language processing,"Wolf Thomas, Debut Lysandre, Sanh Victor, Chaumond Julien, Delangue Clement, Moi Anthony, Cistac Pierric, Rault Tim, Louf Remi, Funtowicz Morgan, Davison Joe, Shleifer Sam, von Platen Patrick, Ma Clara, Jernite Yacine, Plu Julien, Xu Canwen, Le Scao Teven, Gugger Sylvain, Drame Mariama, Lhoest Quentin, Rush Alexander M., Transformers: State-of-the-art natural language processing, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pp. 38-45, (2020)"
automatic generation of text descriptive comments for code blocks,"Liang Y., Zhu K.Q., Automatic generation of text descriptive comments for code blocks, Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), pp. 5229-5236, (2018)"
towards automatic generation of short summaries of commits,"Jiang S., McMillan C., Towards automatic generation of short summaries of commits, 2017 IEEE/ACM 25th International Conference on Program Comprehension (ICPC). IEEE, pp. 320-323, (2017)"
source code summarization with structural relative position guided transformer,"Gong Z., Gao C., Wang Y., Gu W., Peng Y., Xu Z., Source code summarization with structural relative position guided transformer, (2022)"
commit message generation for source code changes,"Xu S., Yao Y., Xu F., Gu T., Tong H., Lu J., Commit message generation for source code changes, IJCAI, pp. 3975-3981, (2019)"
global relational models of source code,"Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, International Conference on Learning Representations, (2020)"
code comments generation with data flow-guided transformer,"Zhou W., Junhua W., Code comments generation with data flow-guided transformer, Web Information Systems and Applications: 19Th International Conference, WISA 2022, Dalian, China, September 16–18, 2022, Proceedings, pp. 168-180, (2022)"
adversarial examples for models of code,"Yefet N., Alon U., Yahav E., Adversarial examples for models of code, Proc. ACM Program. Lang., 4, OOPSLA, (2020)"
automating just-in-time comment updating,"Liu Z., Xia X., Yan M., Li S., Automating just-in-Time comment updating, Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering. ACM, (2020)"
supporting program comprehension with source code summarization,"Haiduc S., Aponte J., Marcus A., Supporting program comprehension with source code summarization, 2010 ACM/IEEE 32nd International Conference on Software Engineering, pp. 223-226, (2010)"
bart: denoising sequence-tosequence pre-training for natural language generation,"Lewis M., Liu Y., Goyal N., Ghazvininejad M., Mohamed A., Levy O., Stoyanov V., Zettlemoyer L., BART: Denoising sequence-tosequence pre-training for natural language generation, translation, and comprehension, ACL, pp. 7871-7880, (2020)"
code to comment “translation”: data,"Gros D., Sezhiyan H., Devanbu P., Yu Z., Code to comment “translation”: Data, metrics, baselining & evaluation, Arxiv: Cs.Se/2010.01410, (2020)"
federated learning based multi-task feature fusion framework for code expressive semantic extraction,"Deng F., Fu C., Qian Y., Yang J., He S., Xu H., Federated learning based multi-task feature fusion framework for code expressive semantic extraction, Softw Pract Exper, 52, 8, pp. 1849-1866, (2022)"
neural guided constraint logic programming for program synthesis,"Zhang L., Rosenblatt G., Fetaya E., Liao R., Byrd W., Might M., Urtasun R., Zemel R., Neural guided constraint logic programming for program synthesis, Adv Neural Inf Process Syst, (2018)"
graphcodebert: pre-training code representations with data-ow,"Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Et al., Graphcodebert: Pre-training code representations with data-ow, (2020)"
towards automatically generating block comments for code snippets,"Huang Y., Huang S., Chen H., Chen X., Zheng Z., Luo X., Jia N., Hu X., Zhou X., Towards automatically generating block comments for code snippets, Information and Software Technology, (2020)"
code vectors: understanding programs through embedded abstracted symbolic traces,"Henkel J., Lahiri S.K., Liblit B., Reps T., Code vectors: Understanding programs through embedded abstracted symbolic traces, ESEC/FSE, pp. 163-174, (2018)"
tranŝ3: a transformer-based framework for unifying code summarization and code search,"Wang W., Zhang Y., Zeng Z., Xu G., Tranŝ3: A transformer-based framework for unifying code summarization and code search, (2020)"
gypsum: learning hybrid representations for code summarization,"Wang Y., Dong Y., Lu X., Zhou A., Gypsum: Learning hybrid representations for code summarization, Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension, pp. 12-23, (2022)"
treebert: a tree-based pre-trained model for programming language,"Jiang X., Zheng Z., Lyu C., Li L., Lyu L., Treebert: A tree-based pre-trained model for programming language, UAI 2021: Uncertainty in Artificial Intelligence, (2021)"
on the use of automated text summarization techniques for summarizing source code,"Haiduc S., Aponte J., Moreno L., Marcus A., On the Use of Automated Text Summarization Techniques for Summarizing Source Code, Proceedings of the 17th Working Conference on Reverse Engineering, WCRE 2010, pp. 35-44, (2010)"
bert: pre-training of deep bidirectional transformers for language understanding,"Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, pp. 4171-4186, (2019)"
language models are few-shot learners,"Brown T., Mann B., Ryder N., Subbiah M., Kaplan J.D., Dhariwal P., Et al., Language models are few-shot learners, Advances in Neural Information Processing Systems, 33, pp. 1877-1901, (2020)"
a syntactic neural model for general-purpose code generation,"Yin P., Neubig G., A syntactic neural model for general-purpose code generation, Proc. 55th Annu. Meeting Assoc. Comput. Linguistics, pp. 440-450, (2017)"
a neural architecture for generating natural language descriptions from source code changes,"Loyola P., Marrese-Taylor E., Matsuo Y., A neural architecture for generating natural language descriptions from source code changes, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pp. 287-292, (2017)"
code structure guided transformer for source code summarization,"Gao S., Gao C., He Y., Zeng J., Nie L.Y., Xia X., Code structure guided transformer for source code summarization, Arxiv Preprint Arxiv:210409340, (2021)"
structured generative models of natural source code,"Maddison C.J., Tarlow D., Structured generative models of natural source code, International Conference on Machine Learning (ICML), (2014)"
novel natural language summarization of program code via leveraging multiple input representations,"Chen F., Kim M., Choo J., Novel natural language summarization of program code via leveraging multiple input representations, Findings of the Association for Computational Linguistics: EMNLP 2021, pp. 2510-2520, (2021)"
speech & language processing.,"Jurafsky D., Martin J.H., Speech & Language Processing., (2021)"
codet5: identifier-aware unified pre-trained encoder-decoder models for code understanding and generation,"Wang Y., Wang W., Joty S., Hoi S.C., CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, Proceedings of the 2021 conference on empirical methods in natural language processing, pp. 8696-8708, (2021)"
studying the usage of text-to-text transfer transformer to support code-related tasks,"Mastropaolo A., Scalabrino S., Cooper N., Palacio D.N., Poshyvanyk D., Oliveto R., Bavota G., Studying the usage of text-to-text transfer transformer to support code-related tasks, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, pp. 336-347, (2021)"
electra: pre-training text encoders as discriminators rather than generators,"Clark Kevin, Luong Minh-Thang, Le Quoc V., Manning Christopher D., ELECTRA: pre-training text encoders as discriminators rather than generators, 8th International Conference on Learning Representations, ICLR 2020, (2020)"
data-driven domain models for problem solving,"BARNES T., MOSTAFAVI B., EAGLE M. J., Data-driven domain models for problem solving, Design Recommendations for Intelligent Tutoring Systems, 4, pp. 137-145, (2016)"
keyword-guided abstractive code summarization via incorporating structural and contextual information,"Cheng W., Hu P., Wei S., Mo R., Keyword-guided abstractive code summarization via incorporating structural and contextual information, Inf. Softw. Technol., 150, (2022)"
clocom: mining existing source code for automatic comment generation,"Wong E., Liu T., Tan L., CloCom: Mining existing source code for automatic comment generation, 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER), pp. 380-389, (2015)"
infercode: self-supervised learning of code representations by predicting subtrees,"Bui N.D.Q., Yu Y., Jiang L., InferCode: Self-Supervised Learning of Code Representations by Predicting Subtrees, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)., pp. 1186-1197, (2021)"
learning sequential and structural information for source code summarization,"Choi Y.S., Bak J.Y., Na C.W., Lee J.H., Learning sequential and structural information for source code summarization, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pp. 2842-2851, (2021)"
fret: functional reinforced transformer with bert for code summarization,"Wang R., Zhang H., Lu G., Lyu L., Lyu C., Fret: Functional reinforced transformer with bert for code summarization, Ieee Access, 8, pp. 135591-135604, (2020)"
program synthesis for character level language modelling,"Bielik P., Raychev V., Vechev M., Program synthesis for character level language modelling, International conference on learning representations, (2017)"
a survey of automatic generation of source code comments: algorithms and techniques,"Song X., Sun H., Wang X., Yan J., A survey of automatic generation of source code comments: Algorithms and techniques, IEEE Access, 7, pp. 111411-111428, (2019)"
on the sentence embeddings from pre-trained language models,"Bohan L., Hao Z., Junxian H., Mingxuan W., Yiming Y., Lei L., On the sentence embeddings from pre-trained language models, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pp. 9119-9130, (2020)"
on automatically generating commit messages via summarization of source code changes,"Fernando Cortes-Coy L., Linares-Vasquez M., Aponte J., Poshyvanyk D., On automatically generating commit messages via summarization of source code changes, 2014 IEEE 14th International Working Conference on Source Code Analysis and Manipulation. IEEE, pp. 275-284, (2014)"
syncobert: syntax-guided multi-modal contrastive pre-training for code representation,"Wang X., Wang Y., Mi F., Zhou P., Wan Y., Liu X., Li L., Wu H., Liu J., Jiang X., Syncobert: Syntax-guided multi-modal contrastive pre-training for code representation, (2021)"
cotext: multi-task learning with code-text transformer,"Phan L., Tran H., Le D., Nguyen H., Annibal J., Peltekian A., Et al., CoTexT: Multi-task learning with code-text transformer, Proceedings of the 1st workshop on natural language processing for programming, pp. 40-47, (2021)"
mudablue: an automatic categorization system for open source repositories,"Kawaguchi S., Garg P.K., Matsushita M., Inoue K., MUDABlue: An automatic categorization system for open source repositories, J. Syst. Softw., 79, 7, pp. 939-953, (2006)"
language models are unsupervised multitask learners,"Radford Alec, Wu Jeffrey, Child Rewon, Luan David, Amodei Dario, Sutskever Ilya, Language models are unsupervised multitask learners, OpenAI Blog, 1, 8, (2019)"
structural language models of code,"Alon U., Sadaka R., Levy O., Yahav E., Structural language models of code, Proceedings of the Thirty-seventh International Conference on Machine Learning. PMLR, Virtual Event, pp. 245-256, (2020)"
a transformer-based approach for source code summarization,"Ahmad W., Chakraborty S., Ray B., Chang K., A Transformer-based Approach for Source Code Summarization, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 4998-5007, (2020)"
mpnet: masked and permuted pre-training for language understanding,"Song K., Tan X., Qin T., Lu J., Liu T., Mpnet: Masked and permuted pre-training for language understanding, Advances in Neural Information Processing Systems, 33, pp. 16857-16867, (2020)"
two decades of statistical language modeling: where do we go from here?,"Rosenfeld R., Two decades of statistical language modeling: Where do we go from here?, Proc. IEEE, 88, 8, pp. 1270-1278, (2000)"
natural language processing (almost) from scratch,"Collobert R., Weston J., Bottou L., Karlen M., Kavukcuoglu K., Kuksa P., Natural language processing (almost) from scratch, Journal of machine learning research, 12, ARTICLE, pp. 2493-2537, (2011)"
assessing the effectiveness of syntactic structure to learn code edit representations,"Qureshi S.A., Mehta S., Bhagwan R., Kumar R., Assessing the effectiveness of syntactic structure to learn code edit representations, (2021)"
a mocktail of source code representations,"Vagavolu D., Swarna K. C., Chimalakonda S., A mocktail of source code representations, ASE, (2021)"
xlnet: generalized autoregressive pretraining for language understanding,"Yang Zhilin, Dai Zihang, Yang Yiming, Carbonell Jaime, Salakhutdinov Russ R, Le Quoc V, Xlnet: Generalized autoregressive pretraining for language understanding, Advances in neural information processing systems, pp. 5754-5764, (2019)"
integrating tree path in transformer for code representation,"Peng H., Li G., Wang W., Zhao Y., Jin Z., Integrating tree path in transformer for code representation, Thirty-Fifth Conference on Neural Information Processing Systems, (2021)"
swin transformer v2: scaling up capacity and resolution,"Liu Z., Hu H., Lin Y., Yao Z., Xie Z., Wei Y., Ning J., Cao Y., Zhang Z., Dong L., Et al., Swin transformer v2: Scaling up capacity and resolution, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 12009-12019, (2022)"
horn clause queries and generalizations,"Chandra A.K., Harel D., Horn clause queries and generalizations, J. Log. Program, 2, 1, pp. 1-15, (1985)"
m2ts: multi-scale multi-modal approach based on transformer for source code summarization,"Gao Y., Lyu C., M2ts: Multi-scale multi-modal approach based on transformer for source code summarization, Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension, pp. 24-35, (2022)"
a primer in bertology: what we know about how bert works,"Rogers A., Kovaleva O., Rumshisky A., A Primer in BERTology: What We Know about How BERT Works, Transactions of the Association for Computational Linguistics, 8, pp. 842-866, (2020)"
reinforcement-learning-guided source code summarization using hierarchical attention,"Wang Wenhua, Zhang Yuqun, Sui Yulei, Wan Yao, Zhao Zhou, Wu Jian, Yu Philip S., Xu Guandong, Reinforcement-learning-guided source code summarization using hierarchical attention, IEEE Trans. Software Eng, 48, 2, pp. 102-119, (2022)"
recommendations for datasets for source code summarization,"LeClair A., McMillan C., Recommendations for datasets for source code summarization, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, pp. 3931-3937, (2019)"
abstract syntax networks for code generation and semantic parsing,"Rabinovich M., Stern M., Klein D., Abstract Syntax Networks for Code Generation and Semantic Parsing, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pp. 1139-1149, (2017)"
using semantic unification to generate regular expressions from natural language,"Kushman N., Barzilay R., Using semantic unification to generate regular expressions from natural language, Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 826-836, (2013)"
effective approaches to combining lexical and syntactical information for code summarization,"Zhou Z., Yu H., Fan G., Effective approaches to combining lexical and syntactical information for code summarization, Softw Pract Exp, 50, 12, pp. 2313-2336, (2020)"
deep code comment generation,"Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, 2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC). IEEE, pp. 200-20010, (2018)"
generating parameter comments and integrating with method summaries,"Sridhara G., Pollock L., Vijay-Shanker K., Generating parameter comments and integrating with method summaries, Proc. IEEE 19th Int. Conf. Prog. Comprehension, pp. 71-80, (2011)"
a grammar- based structural cnn decoder for code generation,"Sun Z., Zhu Q., Mou L., Xiong Y., Li G., Zhang L., A grammar- based structural CNN decoder for code generation, (2018)"
learning to generate comments for api-based code snippets,"Lu Y., Zhao Z., Li G., Jin Z., Learning to generate comments for api-based code snippets, Software Engineering and Methodology for Emerging Domains, pp. 3-14, (2017)"
mining semantic loop idioms,"Allamanis M., Barr E.T., Bird C., Devanbu P., Marron M., Sutton C., Mining semantic loop idioms, IEEE Trans. Softw. Eng., 44, 7, pp. 651-668, (2018)"
pathminer: a library formining of path-based representations of code,"Kovalenko V., Bogomolov E., Bryksin T., Bacchelli A., PathMiner: A library formining of path-based representations of code, 2019 IEEE/ACM16th International Conference on Mining Software Repositories MSR, pp. 13-17, (2019)"
parsing natural scenes and natural language with recursive neural networks,"Socher R., Lin C.C., Manning C., Ng A.Y., Parsing natural scenes and natural language with recursive neural networks, Proceedings of the 28th International Conference on Machine Learning (ICML'11)., pp. 129-136, (2011)"
